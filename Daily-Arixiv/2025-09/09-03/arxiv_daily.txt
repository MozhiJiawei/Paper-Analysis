Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 10004a1 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月5日 11:43
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Wed  3 Sep 25 18:00:00 GMT  to  Thu  4 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.03536
Date: Wed, 27 Aug 2025 12:31:37 GMT   (3153kb)

Title: PG-Agent: An Agent Powered by Page Graph
Authors: Weizhi Chen, Ziwei Wang, Leyang Yang, Sheng Zhou, Xiaoxuan Tang,
  Jiajun Bu, Yong Li, Wei Jiang
Categories: cs.AI cs.HC
Comments: Paper accepted to ACM MM 2025
\\
  Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.
\\ ( https://arxiv.org/abs/2509.03536 ,  3153kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03548
Date: Tue, 2 Sep 2025 17:51:34 GMT   (48kb)

Title: Multilinear and Linear Programs for Partially Identifiable Queries in
  Quasi-Markovian Structural Causal Models
Authors: Jo\~ao P. Arroyo, Jo\~ao G. Rodrigues, Daniel Lawand, Denis D. Mau\'a,
  Junkyu Lee, Radu Marinescu, Alex Gray, Eduardo R. Laurentino, Fabio G. Cozman
Categories: cs.AI
Comments: Accepted at the Causal Abstractions and Representations (CAR)
  workshop of the 41st Conference on Uncertainty in Artificial Intelligence
  (UAI 2025)
\\
  We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.
\\ ( https://arxiv.org/abs/2509.03548 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03550
Date: Tue, 2 Sep 2025 23:17:46 GMT   (1911kb)

Title: Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method
Authors: Tonghe Li, Jixin Liu, Weili Zeng, Hao Jiang
Categories: cs.AI
Comments: 59 pages,13 figures, 3 tables
\\
  In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.
\\ ( https://arxiv.org/abs/2509.03550 ,  1911kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03581
Date: Wed, 3 Sep 2025 18:00:13 GMT   (20083kb)

Title: Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM
  Agents
Authors: Davide Paglieri, Bart{\l}omiej Cupia{\l}, Jonathan Cook, Ulyana
  Piterbarg, Jens Tuyls, Edward Grefenstette, Jakob Nicolaus Foerster, Jack
  Parker-Holder, Tim Rockt\"aschel
Categories: cs.AI
\\
  Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.
\\ ( https://arxiv.org/abs/2509.03581 ,  20083kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03626
Date: Wed, 3 Sep 2025 18:29:30 GMT   (1773kb)

Title: Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with
  KG-SMILE
Authors: Zahra Zehtabi Sabeti Moghaddam, Zeinab Dehghani, Maneeha Rani, Koorosh
  Aslansefat, Bhupesh Kumar Mishra, Rameez Raja Kureshi, Dhavalkumar Thakker
Categories: cs.AI
\\
  Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.
\\ ( https://arxiv.org/abs/2509.03626 ,  1773kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03636
Date: Wed, 3 Sep 2025 18:37:36 GMT   (4760kb)

Title: CausalARC: Abstract Reasoning with Causal World Models
Authors: Jacqueline Maasch, John Kalantari, Kia Khezeli
Categories: cs.AI cs.CL cs.LG
\\
  Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.
\\ ( https://arxiv.org/abs/2509.03636 ,  4760kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03644
Date: Wed, 3 Sep 2025 18:50:18 GMT   (587kb)

Title: Towards a Neurosymbolic Reasoning System Grounded in Schematic
  Representations
Authors: Fran\c{c}ois Olivier, Zied Bouraoui
Categories: cs.AI cs.CL
Comments: To appear in Proceedings of Machine Learning Research, 19th
  Conference on Neurosymbolic Learning and Reasoning, 2025
\\
  Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.
\\ ( https://arxiv.org/abs/2509.03644 ,  587kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03646
Date: Wed, 3 Sep 2025 18:52:49 GMT   (847kb)

Title: Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning
Authors: Haozhe Wang, Qixin Xu, Che Liu, Junhong Wu, Fangzhen Lin, Wenhu Chen
Categories: cs.AI cs.CL
Comments: Preprint
\\
  Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.
\\ ( https://arxiv.org/abs/2509.03646 ,  847kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03649
Date: Wed, 3 Sep 2025 18:55:23 GMT   (1618kb)

Title: An Empirical Evaluation of Factors Affecting SHAP Explanation of Time
  Series Classification
Authors: Davide Italo Serramazza, Nikos Papadeas, Zahraa Abdallah, Georgiana
  Ifrim
Categories: cs.AI
\\
  Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.
\\ ( https://arxiv.org/abs/2509.03649 ,  1618kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03728
Date: Wed, 3 Sep 2025 21:20:38 GMT   (88kb)

Title: PersonaTeaming: Exploring How Introducing Personas Can Improve Automated
  AI Red-Teaming
Authors: Wesley Hanwen Deng, Sunnie S. Y. Kim, Akshita Jha, Ken Holstein,
  Motahhare Eslami, Lauren Wilcox, Leon A Gatys
Categories: cs.AI cs.HC
\\
  Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.
\\ ( https://arxiv.org/abs/2509.03728 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03730
Date: Wed, 3 Sep 2025 21:27:10 GMT   (2476kb)

Title: The Personality Illusion: Revealing Dissociation Between Self-Reports &
  Behavior in LLMs
Authors: Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs,
  Anima Anandkumar, R. Michael Alvarez
Categories: cs.AI cs.CL cs.CY cs.LG stat.ML
Comments: We make public all code and source data at
  https://github.com/psychology-of-AI/Personality-Illusion
\\
  Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.
\\ ( https://arxiv.org/abs/2509.03730 ,  2476kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03736
Date: Wed, 3 Sep 2025 21:55:29 GMT   (1179kb)

Title: Are LLM Agents Behaviorally Coherent? Latent Profiles for Social
  Simulation
Authors: James Mooney, Josef Woldense, Zheng Robert Jia, Shirley Anugrah
  Hayati, My Ha Nguyen, Vipul Raheja, Dongyeop Kang
Categories: cs.AI
Comments: 25 pages, 9 figures, 7 tables
\\
  The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.
\\ ( https://arxiv.org/abs/2509.03736 ,  1179kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03768
Date: Wed, 3 Sep 2025 23:24:17 GMT   (409kb)

Title: RAGuard: A Novel Approach for in-context Safe Retrieval Augmented
  Generation for LLMs
Authors: Connor Walker, Koorosh Aslansefat, Mohammad Naveed Akram, Yiannis
  Papadopoulos
Categories: cs.AI stat.ML
\\
  Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.
\\ ( https://arxiv.org/abs/2509.03768 ,  409kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03811
Date: Thu, 4 Sep 2025 01:55:58 GMT   (307kb)

Title: Leveraging LLM-Based Agents for Intelligent Supply Chain Planning
Authors: Yongzhi Qi, Jiaheng Yin, Jianshen Zhang, Dongyang Geng, Zhengyu Chen,
  Hao Hu, Wei Qi, Zuo-Jun Max Shen
Categories: cs.AI
\\
  In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.
\\ ( https://arxiv.org/abs/2509.03811 ,  307kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03817
Date: Thu, 4 Sep 2025 02:06:06 GMT   (2371kb)

Title: Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with
  Multi-agent Reinforcement Learning
Authors: Wei Yang, Jesse Thomason
Categories: cs.AI cs.MA
\\
  Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.
\\ ( https://arxiv.org/abs/2509.03817 ,  2371kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03827
Date: Thu, 4 Sep 2025 02:28:58 GMT   (4498kb)

Title: What Would an LLM Do? Evaluating Policymaking Capabilities of Large
  Language Models
Authors: Pierre Le Coz, Jia An Liu, Debarun Bhattacharjya, Georgina Curto,
  Serge Stinckwich
Categories: cs.AI
\\
  Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.
\\ ( https://arxiv.org/abs/2509.03827 ,  4498kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03828
Date: Thu, 4 Sep 2025 02:32:22 GMT   (556kb)

Title: An Agentic Model Context Protocol Framework for Medical Concept
  Standardization
Authors: Jaerong Ahn, Andrew Wen, Nan Wang, Heling Jia, Zhiyi Yue, Sunyang Fu
  and Hongfang Liu
Categories: cs.AI
\\
  The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.
\\ ( https://arxiv.org/abs/2509.03828 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03830
Date: Thu, 4 Sep 2025 02:35:14 GMT   (2423kb)

Title: A Multidimensional AI-powered Framework for Analyzing Tourist Perception
  in Historic Urban Quarters: A Case Study in Shanghai
Authors: Kaizhen Tan, Yufan Wu, Yuxuan Liu, Haoran Zeng
Categories: cs.AI cs.CV cs.CY
\\
  Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.
\\ ( https://arxiv.org/abs/2509.03830 ,  2423kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03857
Date: Thu, 4 Sep 2025 03:34:49 GMT   (966kb)

Title: Continuous Monitoring of Large-Scale Generative AI via Deterministic
  Knowledge Graph Structures
Authors: Kishor Datta Gupta, Mohd Ariful Haque, Hasmot Ali, Marufa Kamal, Syed
  Bahauddin Alam, and Mohammad Ashiqur Rahman
Categories: cs.AI
\\
  Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.
\\ ( https://arxiv.org/abs/2509.03857 ,  966kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03863
Date: Thu, 4 Sep 2025 03:44:44 GMT   (12876kb)

Title: Expedition & Expansion: Leveraging Semantic Representations for
  Goal-Directed Exploration in Continuous Cellular Automata
Authors: Sina Khajehabdollahi, Gautier Hamon, Marko Cvjetko, Pierre-Yves
  Oudeyer, Cl\'ement Moulin-Frier, C\'edric Colas
Categories: cs.AI
\\
  Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.
\\ ( https://arxiv.org/abs/2509.03863 ,  12876kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03890
Date: Thu, 4 Sep 2025 05:22:25 GMT   (1217kb)

Title: FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer
  Marketplace
Authors: Yineng Yan, Xidong Wang, Jin Seng Cheng, Ran Hu, Wentao Guan, Nahid
  Farahmand, Hengte Lin, Yue Li
Categories: cs.AI
\\
  The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.
\\ ( https://arxiv.org/abs/2509.03890 ,  1217kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03906
Date: Thu, 4 Sep 2025 06:00:04 GMT   (3930kb)

Title: A Foundation Model for Chest X-ray Interpretation with Grounded
  Reasoning via Online Reinforcement Learning
Authors: Qika Lin, Yifan Zhu, Bin Pu, Ling Huang, Haoran Luo, Jingying Ma, Zhen
  Peng, Tianzhe Zhao, Fangzhi Xu, Jian Zhang, Kai He, Zhonghong Ou, Swapnil
  Mishra, Mengling Feng
Categories: cs.AI
Comments: 15 pages
\\
  Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.
\\ ( https://arxiv.org/abs/2509.03906 ,  3930kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03953
Date: Thu, 4 Sep 2025 07:27:27 GMT   (932kb)

Title: Handling Infinite Domain Parameters in Planning Through Best-First
  Search with Delayed Partial Expansions
Authors: \'Angel Aso-Mollar and Diego Aineto and Enrico Scala and Eva Onaindia
Categories: cs.AI cs.SC cs.SY eess.SY
Comments: To appear in the Proceedings of the Thirty-Fourth International Joint
  Conference on Artificial Intelligence (IJCAI 2025)
\\
  In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.
\\ ( https://arxiv.org/abs/2509.03953 ,  932kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03956
Date: Thu, 4 Sep 2025 07:32:16 GMT   (1290kb)

Title: World Model Implanting for Test-time Adaptation of Embodied Agents
Authors: Minjong Yoo, Jinwoo Jang, Sihyung Yoon, Honguk Woo
Categories: cs.AI
Journal-ref: Forty-second International Conference on Machine Learning, 2025
\\
  In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.
\\ ( https://arxiv.org/abs/2509.03956 ,  1290kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03990
Date: Thu, 4 Sep 2025 08:18:39 GMT   (10kb)

Title: Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility
  for Resource-Efficient LLM Agent
Authors: Chunlong Wu and Zhibo Qu
Categories: cs.AI
\\
  Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.
\\ ( https://arxiv.org/abs/2509.03990 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04007
Date: Thu, 4 Sep 2025 08:38:42 GMT   (860kb)

Title: AutoPBO: LLM-powered Optimization for Local Search PBO Solvers
Authors: Jinyuan Li, Yi Chu, Yiwen Sun, Mengchuan Zou and Shaowei Cai
Categories: cs.AI
\\
  Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.
\\ ( https://arxiv.org/abs/2509.04007 ,  860kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04027
Date: Thu, 4 Sep 2025 09:02:16 GMT   (1755kb)

Title: CoT-Space: A Theoretical Framework for Internal Slow-Thinking via
  Reinforcement Learning
Authors: Zeyu Gan, Hao Yi, Yong Liu
Categories: cs.AI cs.CL
Comments: Preprint Edition
\\
  Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.
\\ ( https://arxiv.org/abs/2509.04027 ,  1755kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04041
Date: Thu, 4 Sep 2025 09:21:57 GMT   (100kb)

Title: Oruga: An Avatar of Representational Systems Theory
Authors: Daniel Raggi, Gem Stapleton, Mateja Jamnik, Aaron Stockdill, Grecia
  Garcia Garcia, Peter C-H. Cheng
Categories: cs.AI cs.LO
MSC-class: 68T30, 68T27, 03B35
ACM-class: I.2.4; I.2.3; F.4.1; F.4.3
\\
  Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.
\\ ( https://arxiv.org/abs/2509.04041 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04083
Date: Thu, 4 Sep 2025 10:25:50 GMT   (210kb)

Title: Intermediate Languages Matter: Formal Languages and LLMs affect
  Neurosymbolic Reasoning
Authors: Alexander Beiser, David Penz, Nysret Musliu
Categories: cs.AI
Comments: To appear in the proceedings of The Second Workshop on Knowledge
  Graphs and Neurosymbolic AI (KG-NeSy) Co-located with SEMANTiCS 2025
  Conference, Vienna, Austria - September 3rd, 2025
\\
  Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.
\\ ( https://arxiv.org/abs/2509.04083 ,  210kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04100
Date: Thu, 4 Sep 2025 11:01:43 GMT   (259kb)

Title: Hybrid Reinforcement Learning and Search for Flight Trajectory Planning
Authors: Alberto Luise, Michele Lombardi, Florent Teichteil Koenigsbuch
Categories: cs.AI
\\
  This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.
\\ ( https://arxiv.org/abs/2509.04100 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04125
Date: Thu, 4 Sep 2025 11:40:24 GMT   (1065kb)

Title: Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker
Authors: Tarik Zaciragic, Aske Plaat, and K. Joost Batenburg
Categories: cs.AI
\\
  In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.
\\ ( https://arxiv.org/abs/2509.04125 ,  1065kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04130
Date: Thu, 4 Sep 2025 11:54:27 GMT   (27kb)

Title: The human biological advantage over AI
Authors: William Stewart
Categories: cs.AI cs.CY
Comments: 12 pages
ACM-class: I.2.0
Journal-ref: AI & Society 40, 2181-2190, 2025
DOI: 10.1007/s00146-024-02112-w
\\
  Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.
\\ ( https://arxiv.org/abs/2509.04130 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04159
Date: Thu, 4 Sep 2025 12:34:56 GMT   (178kb)

Title: Towards an Action-Centric Ontology for Cooking Procedures Using Temporal
  Graphs
Authors: Aarush Kumbhakern, Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das
Categories: cs.AI cs.CL
Comments: 6 pages, 3 figures, 1 table, 11 references, ACM International
  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop
DOI: 10.1145/3746264.3760499
\\
  Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.
\\ ( https://arxiv.org/abs/2509.04159 ,  178kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04192
Date: Thu, 4 Sep 2025 13:15:02 GMT   (33kb)

Title: Domain size asymptotics for Markov logic networks
Authors: Vera Koponen
Categories: cs.AI cs.LO math.LO
MSC-class: 68T27, 68T30, 68T37, 03C13
ACM-class: I.2; F.4; G.3
\\
  A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.
\\ ( https://arxiv.org/abs/2509.04192 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04239
Date: Thu, 4 Sep 2025 14:13:42 GMT   (656kb)

Title: Evaluating Quality of Gaming Narratives Co-created with AI
Authors: Arturo Valdivia, Paolo Burelli
Categories: cs.AI
DOI: 10.1109/CoG64752.2025.11114354
\\
  This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.
\\ ( https://arxiv.org/abs/2509.04239 ,  656kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04310
Date: Thu, 4 Sep 2025 15:23:58 GMT   (3028kb)

Title: EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn
  Negotiation
Authors: Yunbo Long, Liming Xu, Lukas Beckenbauer, Yuhan Liu, Alexandra
  Brintrup
Categories: cs.AI
\\
  Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.
\\ ( https://arxiv.org/abs/2509.04310 ,  3028kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04317
Date: Thu, 4 Sep 2025 15:38:37 GMT   (1153kb)

Title: Improving Robustness of AlphaZero Algorithms to Test-Time Environment
  Changes
Authors: Isidoro Tamassia and Wendelin B\"ohmer
Categories: cs.AI cs.LG
\\
  The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.
\\ ( https://arxiv.org/abs/2509.04317 ,  1153kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04343
Date: Thu, 4 Sep 2025 16:03:03 GMT   (4406kb)

Title: Psychologically Enhanced AI Agents
Authors: Maciej Besta, Shriram Chandran, Robert Gerstenberger, Mathis Lindner,
  Marcin Chrapek, Sebastian Hermann Martschat, Taraneh Ghandi, Patrick Iff,
  Hubert Niewiadomski, Piotr Nyczyk, J\"urgen M\"uller, Torsten Hoefler
Categories: cs.AI cs.CL cs.CY cs.HC cs.MA
\\
  We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.
\\ ( https://arxiv.org/abs/2509.04343 ,  4406kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04439
Date: Thu, 4 Sep 2025 17:54:19 GMT   (1024kb)

Title: ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory
Authors: Matthew Ho, Chen Si, Zhaoxiang Feng, Fangxu Yu, Zhijian Liu, Zhiting
  Hu, Lianhui Qin
Categories: cs.AI cs.CL cs.LG
\\
  While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.
\\ ( https://arxiv.org/abs/2509.04439 ,  1024kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03525
Date: Sun, 24 Aug 2025 13:15:28 GMT   (2387kb)

Title: Speech-Based Cognitive Screening: A Systematic Evaluation of LLM
  Adaptation Strategies
Authors: Fatemeh Taherinezhad, Mohamad Javad Momeni Nezhad, Sepehr Karimi, Sina
  Rashidi, Ali Zolnour, Maryam Dadkhah, Yasaman Haghbin, Hossein AzadMaleki,
  Maryam Zolnoori
Categories: cs.CL cs.AI eess.AS
\\
  Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.
\\ ( https://arxiv.org/abs/2509.03525 ,  2387kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03526
Date: Mon, 25 Aug 2025 07:31:48 GMT   (916kb)

Title: Enhancing Speech Large Language Models through Reinforced Behavior
  Alignment
Authors: Yansong Liu, Jiateng Li and Yuan Liu
Categories: cs.CL eess.AS
\\
  The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.
\\ ( https://arxiv.org/abs/2509.03526 ,  916kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03527
Date: Mon, 25 Aug 2025 08:17:08 GMT   (27kb)

Title: Multilevel Analysis of Cryptocurrency News using RAG Approach with
  Fine-Tuned Mistral Large Language Model
Authors: Bohdan M. Pavlyshenko
Categories: cs.CL cs.AI
\\
  In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.
\\ ( https://arxiv.org/abs/2509.03527 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03528
Date: Mon, 25 Aug 2025 09:00:12 GMT   (273kb)

Title: The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking
  Process
Authors: Matilde Contestabile, Chiara Ferrara, Alberto Giovannetti, Giovanni
  Parrillo, Andrea Vandin
Categories: cs.CL cs.CY cs.LG
\\
  Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.
\\ ( https://arxiv.org/abs/2509.03528 ,  273kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03529
Date: Mon, 25 Aug 2025 11:47:56 GMT   (7897kb)

Title: Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of
  Messages
Authors: Alejandro \'Alvarez Castro and Joaqu\'in Ordieres-Mer\'e
Categories: cs.CL cs.AI eess.AS
Comments: Presented at NLMLT2025 (https://airccse.org/csit/V15N16.html), 15
  pages, 5 figures
\\
  Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.
\\ ( https://arxiv.org/abs/2509.03529 ,  7897kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03530
Date: Mon, 25 Aug 2025 13:32:49 GMT   (196kb)

Title: Reading Between the Signs: Predicting Future Suicidal Ideation from
  Adolescent Social Media Texts
Authors: Paul Blum, Enrico Liscio, Ruixuan Zhang, Caroline Figueroa, Pradeep K.
  Murukannaiah
Categories: cs.CL
\\
  Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.
\\ ( https://arxiv.org/abs/2509.03530 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03531
Date: Tue, 26 Aug 2025 01:51:41 GMT   (2025kb)

Title: Real-Time Detection of Hallucinated Entities in Long-Form Generation
Authors: Oscar Obeso, Andy Arditi, Javier Ferrando, Joshua Freeman, Cameron
  Holmes, Neel Nanda
Categories: cs.CL cs.AI cs.LG
\\
  Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.
\\ ( https://arxiv.org/abs/2509.03531 ,  2025kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03533
Date: Tue, 26 Aug 2025 20:00:51 GMT   (1687kb)

Title: Topic Identification in LLM Input-Output Pairs through the Lens of
  Information Bottleneck
Authors: Igor Halperin
Categories: cs.CL cs.LG q-fin.GN
Comments: 26 pages, 4 figures
\\
  Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.
\\ ( https://arxiv.org/abs/2509.03533 ,  1687kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03535
Date: Wed, 27 Aug 2025 10:45:39 GMT   (5171kb)

Title: QuesGenie: Intelligent Multimodal Question Generation
Authors: Ahmed Mubarak, Amna Ahmed, Amira Nasser, Aya Mohamed, Fares El-Sadek,
  Mohammed Ahmed, Ahmed Salah, Youssef Sobhy
Categories: cs.CL cs.AI
Comments: 7 pages, 8 figures, 12 tables. Supervised by Dr. Ahmed Salah and TA
  Youssef Sobhy
\\
  In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.
\\ ( https://arxiv.org/abs/2509.03535 ,  5171kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03537
Date: Wed, 27 Aug 2025 17:26:44 GMT   (257kb)

Title: AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in
  Large Language Models
Authors: Cheng-Kai Yeh, Hsing-Wang Lee, Chung-Hung Kuo, Hen-Hsen Huang
Categories: cs.CL cs.AI cs.LG
Comments: 7 pages, accepted by CIKM 2025 as a short paper
DOI: 10.1145/3746252.3760850
\\
  Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.
\\ ( https://arxiv.org/abs/2509.03537 ,  257kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03540
Date: Sun, 31 Aug 2025 16:36:40 GMT   (702kb)

Title: Improving Factuality in LLMs via Inference-Time Knowledge Graph
  Construction
Authors: Shanglin Wu, Lihui Liu, Jinho D. Choi, Kai Shu
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.
\\ ( https://arxiv.org/abs/2509.03540 ,  702kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03565
Date: Wed, 3 Sep 2025 15:45:03 GMT   (4761kb)

Title: ResearchPulse: Building Method-Experiment Chains through Multi-Document
  Scientific Inference
Authors: Qi Chen, Jingxuan Wei, Zhuoya Yao, Haiguang Wang, Gaowei Wu, Bihui Yu,
  Siyuan Li, Cheng Tan
Categories: cs.CL cs.MM
Comments: Accepted to ACM MM 2025
\\
  Understanding how scientific ideas evolve requires more than summarizing
individual papers-it demands structured, cross-document reasoning over
thematically related research. In this work, we formalize multi-document
scientific inference, a new task that extracts and aligns motivation,
methodology, and experimental results across related papers to reconstruct
research development chains. This task introduces key challenges, including
temporally aligning loosely structured methods and standardizing heterogeneous
experimental tables. We present ResearchPulse, an agent-based framework that
integrates instruction planning, scientific content extraction, and structured
visualization. It consists of three coordinated agents: a Plan Agent for task
decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a
Lchart-Agent that synthesizes experimental line charts. To support this task,
we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper
clusters. Experiments show that our system, despite using 7B-scale agents,
consistently outperforms strong baselines like GPT-4o in semantic alignment,
structural consistency, and visual fidelity. The dataset are available in
https://huggingface.co/datasets/ResearchPulse/ResearchPulse-Bench.
\\ ( https://arxiv.org/abs/2509.03565 ,  4761kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03610
Date: Wed, 3 Sep 2025 18:05:42 GMT   (994kb)

Title: NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge
  Management
Authors: Josh Wisoff, Yao Tang, Zhengyu Fang, Jordan Guzman, YuTang Wang, Alex
  Yu
Categories: cs.CL
\\
  Note-taking is a critical practice for capturing, organizing, and reflecting
on information in both academic and professional settings. The recent success
of large language models has accelerated the development of AI-assisted tools,
yet existing solutions often struggle with efficiency. We present NoteBar, an
AI-assisted note-taking tool that leverages persona information and efficient
language models to automatically organize notes into multiple categories and
better support user workflows. To support research and evaluation in this
space, we further introduce a novel persona-conditioned dataset of 3,173 notes
and 8,494 annotated concepts across 16 MBTI personas, offering both diversity
and semantic richness for downstream tasks. Finally, we demonstrate that
NoteBar can be deployed in a practical and cost-effective manner, enabling
interactive use without reliance on heavy infrastructure. Together, NoteBar and
its accompanying dataset provide a scalable and extensible foundation for
advancing AI-assisted personal knowledge management.
\\ ( https://arxiv.org/abs/2509.03610 ,  994kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03615
Date: Wed, 3 Sep 2025 18:08:41 GMT   (5644kb)

Title: E-ARMOR: Edge case Assessment and Review of Multilingual Optical
  Character Recognition
Authors: Aryan Gupta, Anupam Purwar
Categories: cs.CL cs.AI
Comments: Sprinklr OCR provides a fast and compute light way of performing OCR
\\
  Optical Character Recognition (OCR) in multilingual, noisy, and diverse
real-world images remains a significant challenge for optical character
recognition systems. With the rise of Large Vision-Language Models (LVLMs),
there is growing interest in their ability to generalize and reason beyond
fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR
system built specifically optimized for edge deployment in resource-constrained
environments. We present a large-scale comparative evaluation of five
state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two
traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly
hand annotated dataset of multilingual (54 languages) images. Our benchmark
covers a broad range of metrics including accuracy, semantic consistency,
language coverage, computational efficiency (latency, memory, GPU usage), and
deployment cost. To better reflect real-world applicability, we also conducted
edge case deployment analysis, evaluating model performance on CPU only
environments. Among the results, Qwen achieved the highest precision (0.54),
while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and
outperformed others in efficiency, processing images 35 faster (0.17 seconds
per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000
images) compared to LVLM. Our findings demonstrate that the most optimal OCR
systems for edge deployment are the traditional ones even in the era of LLMs
due to their low compute requirements, low latency, and very high
affordability.
\\ ( https://arxiv.org/abs/2509.03615 ,  5644kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03647
Date: Wed, 3 Sep 2025 18:52:55 GMT   (176kb)

Title: Breaking the Mirror: Activation-Based Mitigation of Self-Preference in
  LLM Evaluators
Authors: Dani Roytburg, Matthew Bozoukov, Matthew Nguyen, Jou Barzdukas, Simon
  Fu, Narmeen Oozeer
Categories: cs.CL cs.AI cs.LG
\\
  Large language models (LLMs) increasingly serve as automated evaluators, yet
they suffer from "self-preference bias": a tendency to favor their own outputs
over those of other models. This bias undermines fairness and reliability in
evaluation pipelines, particularly for tasks like preference tuning and model
routing. We investigate whether lightweight steering vectors can mitigate this
problem at inference time without retraining. We introduce a curated dataset
that distinguishes self-preference bias into justified examples of
self-preference and unjustified examples of self-preference, and we construct
steering vectors using two methods: Contrastive Activation Addition (CAA) and
an optimization-based approach. Our results show that steering vectors can
reduce unjustified self-preference bias by up to 97\%, substantially
outperforming prompting and direct preference optimization baselines. Yet
steering vectors are unstable on legitimate self-preference and unbiased
agreement, implying self-preference spans multiple or nonlinear directions.
This underscores both their promise and limits as safeguards for LLM-as-judges
and motivates more robust interventions.
\\ ( https://arxiv.org/abs/2509.03647 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03662
Date: Wed, 3 Sep 2025 19:25:14 GMT   (547kb)

Title: Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical
  Documentation using MIMIC-IV
Authors: Ali Noori, Somya Mohanty and Prashanti Manda
Categories: cs.CL
\\
  Clinical notes contain rich clinical narratives but their unstructured format
poses challenges for large-scale analysis. Standardized terminologies such as
SNOMED CT improve interoperability, yet understanding how concepts relate
through co-occurrence and semantic similarity remains underexplored. In this
study, we leverage the MIMIC-IV database to investigate the relationship
between SNOMED CT concept co-occurrence patterns and embedding-based semantic
similarity. Using Normalized Pointwise Mutual Information (NPMI) and pretrained
embeddings (e.g., ClinicalBERT, BioBERT), we examine whether frequently
co-occurring concepts are also semantically close, whether embeddings can
suggest missing concepts, and how these relationships evolve temporally and
across specialties. Our analyses reveal that while co-occurrence and semantic
similarity are weakly correlated, embeddings capture clinically meaningful
associations not always reflected in documentation frequency. Embedding-based
suggestions frequently matched concepts later documented, supporting their
utility for augmenting clinical annotations. Clustering of concept embeddings
yielded coherent clinical themes (symptoms, labs, diagnoses, cardiovascular
conditions) that map to patient phenotypes and care patterns. Finally,
co-occurrence patterns linked to outcomes such as mortality and readmission
demonstrate the practical utility of this approach. Collectively, our findings
highlight the complementary value of co-occurrence statistics and semantic
embeddings in improving documentation completeness, uncovering latent clinical
relationships, and informing decision support and phenotyping applications.
\\ ( https://arxiv.org/abs/2509.03662 ,  547kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03725
Date: Wed, 3 Sep 2025 21:12:07 GMT   (1905kb)

Title: MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and
  Cross-Domain Stance Detection
Authors: Parush Gera, Tempestt Neal
Categories: cs.CL cs.AI cs.LG
\\
  We present the novel approach for stance detection across domains and
targets, Metric Learning-Based Few-Shot Learning for Cross-Target and
Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with
triplet loss to capture semantic similarities and differences between stance
targets, enhancing domain adaptation. By constructing a discriminative
embedding space, MLSD allows a cross-target or cross-domain stance detection
model to acquire useful examples from new target domains. We evaluate MLSD in
multiple cross-target and cross-domain scenarios across two datasets, showing
statistically significant improvement in stance detection performance across
six widely used stance detection models.
\\ ( https://arxiv.org/abs/2509.03725 ,  1905kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03791
Date: Thu, 4 Sep 2025 00:58:43 GMT   (1796kb)

Title: SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation
  Evaluation
Authors: Saki Imai, Mert \.Inan, Anthony Sicilia, Malihe Alikhani
Categories: cs.CL cs.AI
\\
  Evaluating sign language generation is often done through back-translation,
where generated signs are first recognized back to text and then compared to a
reference using text-based metrics. However, this two-step evaluation pipeline
introduces ambiguity: it not only fails to capture the multimodal nature of
sign language-such as facial expressions, spatial grammar, and prosody-but also
makes it hard to pinpoint whether evaluation errors come from sign generation
model or the translation system used to assess it. In this work, we propose
SiLVERScore, a novel semantically-aware embedding-based evaluation metric that
assesses sign language generation in a joint embedding space. Our contributions
include: (1) identifying limitations of existing metrics, (2) introducing
SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness
to semantic and prosodic variations, and (4) exploring generalization
challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore
achieves near-perfect discrimination between correct and random pairs (ROC AUC
= 0.99, overlap < 7%), substantially outperforming traditional metrics.
\\ ( https://arxiv.org/abs/2509.03791 ,  1796kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03805
Date: Thu, 4 Sep 2025 01:43:49 GMT   (8433kb)

Title: Measuring How (Not Just Whether) VLMs Build Common Ground
Authors: Saki Imai, Mert \.Inan, Anthony Sicilia, Malihe Alikhani
Categories: cs.CL cs.AI
\\
  Large vision language models (VLMs) increasingly claim reasoning skills, yet
current benchmarks evaluate them in single-turn or question answering settings.
However, grounding is an interactive process in which people gradually develop
shared understanding through ongoing communication. We introduce a four-metric
suite (grounding efficiency, content alignment, lexical adaptation, and
human-likeness) to systematically evaluate VLM performance in interactive
grounding contexts. We deploy the suite on 150 self-play sessions of
interactive referential games between three proprietary VLMs and compare them
with human dyads. All three models diverge from human patterns on at least
three metrics, while GPT4o-mini is the closest overall. We find that (i) task
success scores do not indicate successful grounding and (ii) high
image-utterance alignment does not necessarily predict task success. Our metric
suite and findings offer a framework for future research on VLM grounding.
\\ ( https://arxiv.org/abs/2509.03805 ,  8433kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03809
Date: Thu, 4 Sep 2025 01:50:20 GMT   (557kb)

Title: Align-then-Slide: A complete evaluation framework for Ultra-Long
  Document-Level Machine Translation
Authors: Jiaxin Guo, Daimeng Wei, Yuanchang Luo, Xiaoyu Chen, Zhanglin Wu, Huan
  Yang, Hengchao Shang, Zongyao Li, Zhiqiang Rao, Jinlong Yang and Hao Yang
Categories: cs.CL cs.AI
Comments: under preview
\\
  Large language models (LLMs) have ushered in a new era for document-level
machine translation (\textit{doc}-mt), yet their whole-document outputs
challenge existing evaluation methods that assume sentence-by-sentence
alignment. We introduce \textit{\textbf{Align-then-Slide}}, a complete
evaluation framework for ultra-long doc-mt. In the Align stage, we
automatically infer sentence-level source-target correspondences and rebuild
the target to match the source sentence number, resolving omissions and
many-to-one/one-to-many mappings. In the n-Chunk Sliding Evaluate stage, we
calculate averaged metric scores under 1-, 2-, 3- and 4-chunk for
multi-granularity assessment. Experiments on the WMT benchmark show a Pearson
correlation of 0.929 between our method with expert MQM rankings. On a newly
curated real-world test set, our method again aligns closely with human
judgments. Furthermore, preference data produced by Align-then-Slide enables
effective CPO training and its direct use as a reward model for GRPO, both
yielding translations preferred over a vanilla SFT baseline. The results
validate our framework as an accurate, robust, and actionable evaluation tool
for doc-mt systems.
\\ ( https://arxiv.org/abs/2509.03809 ,  557kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03829
Date: Thu, 4 Sep 2025 02:33:00 GMT   (947kb)

Title: NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio
  Deepfake Detection via Attention Aggregation
Authors: Huhong Xian, Rui Liu, Berrak Sisman and Haizhou Li
Categories: cs.CL
\\
  Different from traditional sentence-level audio deepfake detection (ADD),
partial audio deepfake detection (PADD) requires frame-level positioning of the
location of fake speech. While some progress has been made in this area,
leveraging semantic information from audio, especially named entities, remains
an underexplored aspect. To this end, we propose NE-PADD, a novel method for
Partial Audio Deepfake Detection (PADD) that leverages named entity knowledge
through two parallel branches: Speech Name Entity Recognition (SpeechNER) and
PADD. The approach incorporates two attention aggregation mechanisms: Attention
Fusion (AF) for combining attention weights and Attention Transfer (AT) for
guiding PADD with named entity semantics using an auxiliary loss. Built on the
PartialSpoof-NER dataset, experiments show our method outperforms existing
baselines, proving the effectiveness of integrating named entity knowledge in
PADD. The code is available at https://github.com/AI-S2-Lab/NE-PADD.
\\ ( https://arxiv.org/abs/2509.03829 ,  947kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03867
Date: Thu, 4 Sep 2025 03:58:55 GMT   (501kb)

Title: Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth
Authors: Yang Wang, Chenghao Xiao, Chia-Yi Hsiao, Zi Yan Chang, Chi-Li Chen,
  Tyler Loakman, Chenghua Lin
Categories: cs.CL
Comments: Accepted for oral presentation at the EMNLP 2025 Main Conference
\\
  We introduce Drivelology, a unique linguistic phenomenon characterised as
"nonsense with depth", utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit meaning requiring contextual inference, moral reasoning, or emotional
interpretation. We find that current large language models (LLMs), despite
excelling at many natural language processing (NLP) tasks, consistently fail to
grasp the layered semantics of Drivelological text. To investigate this, we
construct a small but diverse benchmark dataset of over 1,200 meticulously
curated examples, with select instances in English, Mandarin, Spanish, French,
Japanese, and Korean. Annotation was especially challenging: each of the
examples required careful expert review to verify that it truly reflected
Drivelological characteristics. The process involved multiple rounds of
discussion and adjudication to address disagreements, highlighting the subtle
and subjective nature of the Drivelology. We evaluate a range of LLMs on
classification, generation, and reasoning tasks. Our results reveal clear
limitations of LLMs: models often confuse Drivelology with shallow nonsense,
produce incoherent justifications, or miss the implied rhetorical function
altogether. These findings highlight a deeper representational gap in LLMs'
pragmatic understanding and challenge the assumption that statistical fluency
implies cognitive comprehension. We release our dataset and code to facilitate
further research in modelling linguistic depth beyond surface-level coherence.
\\ ( https://arxiv.org/abs/2509.03867 ,  501kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03871
Date: Thu, 4 Sep 2025 04:12:31 GMT   (162kb)

Title: A Comprehensive Survey on Trustworthiness in Reasoning with Large
  Language Models
Authors: Yanbo Wang, Yongcan Yu, Jian Liang, Ran He
Categories: cs.CL cs.AI cs.CR
Comments: 38 pages. This survey considers papers published up to June 30, 2025.
  Work in progress
\\
  The development of Long-CoT reasoning has advanced LLM performance across
various tasks, including language understanding, complex problem solving, and
code generation. This paradigm enables models to generate intermediate
reasoning steps, thereby improving both accuracy and interpretability. However,
despite these advancements, a comprehensive understanding of how CoT-based
reasoning affects the trustworthiness of language models remains
underdeveloped. In this paper, we survey recent work on reasoning models and
CoT techniques, focusing on five core dimensions of trustworthy reasoning:
truthfulness, safety, robustness, fairness, and privacy. For each aspect, we
provide a clear and structured overview of recent studies in chronological
order, along with detailed analyses of their methodologies, findings, and
limitations. Future research directions are also appended at the end for
reference and discussion. Overall, while reasoning techniques hold promise for
enhancing model trustworthiness through hallucination mitigation, harmful
content detection, and robustness improvement, cutting-edge reasoning models
themselves often suffer from comparable or even greater vulnerabilities in
safety, robustness, and privacy. By synthesizing these insights, we hope this
work serves as a valuable and timely resource for the AI safety community to
stay informed on the latest progress in reasoning trustworthiness. A full list
of related papers can be found at
\href{https://github.com/ybwang119/Awesome-reasoning-safety}{https://github.com/ybwang119/Awesome-reasoning-safety}.
\\ ( https://arxiv.org/abs/2509.03871 ,  162kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03888
Date: Thu, 4 Sep 2025 05:15:55 GMT   (338kb)

Title: False Sense of Security: Why Probing-based Malicious Input Detection
  Fails to Generalize
Authors: Cheng Wang, Zeming Wei, Qin Liu, Muhao Chen
Categories: cs.CL
\\
  Large Language Models (LLMs) can comply with harmful instructions, raising
serious safety concerns despite their impressive capabilities. Recent work has
leveraged probing-based approaches to study the separability of malicious and
benign inputs in LLMs' internal representations, and researchers have proposed
using such probing methods for safety detection. We systematically re-examine
this paradigm. Motivated by poor out-of-distribution performance, we
hypothesize that probes learn superficial patterns rather than semantic
harmfulness. Through controlled experiments, we confirm this hypothesis and
identify the specific patterns learned: instructional patterns and trigger
words. Our investigation follows a systematic approach, progressing from
demonstrating comparable performance of simple n-gram methods, to controlled
experiments with semantically cleaned datasets, to detailed analysis of pattern
dependencies. These results reveal a false sense of security around current
probing-based approaches and highlight the need to redesign both models and
evaluation protocols, for which we provide further discussions in the hope of
suggesting responsible further research in this direction. We have open-sourced
the project at https://github.com/WangCheng0116/Why-Probe-Fails.
\\ ( https://arxiv.org/abs/2509.03888 ,  338kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03891
Date: Thu, 4 Sep 2025 05:22:42 GMT   (33843kb)

Title: MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation
Authors: Gowen Loo, Chang Liu, Qinghong Yin, Xiang Chen, Jiawei Chen, Jingyuan
  Zhang, Yu Tian
Categories: cs.CL cs.CV
\\
  Smartphones have become indispensable in people's daily lives, permeating
nearly every aspect of modern society. With the continuous advancement of large
language models (LLMs), numerous LLM-based mobile agents have emerged. These
agents are capable of accurately parsing diverse user queries and automatically
assisting users in completing complex or repetitive operations. However,
current agents 1) heavily rely on the comprehension ability of LLMs, which can
lead to errors caused by misoperations or omitted steps during tasks, 2) lack
interaction with the external environment, often terminating tasks when an app
cannot fulfill user queries, and 3) lack memory capabilities, requiring each
instruction to reconstruct the interface and being unable to learn from and
correct previous mistakes. To alleviate the above issues, we propose MobileRAG,
a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG),
which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly
and accurately identify user queries and accomplish complex and long-sequence
mobile tasks. Additionally, to more comprehensively assess the performance of
MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark
characterized by numerous complex, real-world mobile tasks that require
external knowledge assistance. Extensive experimental results on MobileRAG-Eval
demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving
10.3\% improvement over state-of-the-art methods with fewer operational steps.
Our code is publicly available at:
https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv
\\ ( https://arxiv.org/abs/2509.03891 ,  33843kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03918
Date: Thu, 4 Sep 2025 06:13:28 GMT   (1414kb)

Title: MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question
  Answering
Authors: Fengxiao Tang, Yufeng Li, Zongzong Wu, Ming Zhao
Categories: cs.CL cs.AI
\\
  Complex Question Answering (QA) is a fundamental and challenging task in NLP.
While large language models (LLMs) exhibit impressive performance in QA, they
suffer from significant performance degradation when facing complex and
abstract QA tasks due to insufficient reasoning capabilities. Works such as
Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning
abilities, but they face issues such as in-layer redundancy in tree structures
and single paths in chain structures. Although some studies utilize
Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the
challenge of effectively utilizing large amounts of information involving
multiple entities and hops remains critical. To address this, we propose the
Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT
explores the problem in both horizontal and vertical dimensions through the
"column-cell communication" mechanism, enabling LLMs to actively engage in
multi-strategy and deep-level thinking, reducing redundancy within the column
cells and enhancing reasoning capabilities. Furthermore, we develop a
fact-correction mechanism by constructing knowledge units from retrieved
knowledge graph triples and raw text to enhance the initial knowledge for LLM
reasoning and correct erroneous answers. This leads to the development of an
efficient and accurate QA framework (MTQA). Experimental results show that our
framework outperforms state-of-the-art methods on four widely-used datasets in
terms of F1 and EM scores, with reasoning time only 14.4\% of the baseline
methods, demonstrating both its efficiency and accuracy. The code for this
framework is available at https://github.com/lyfiter/mtqa.
\\ ( https://arxiv.org/abs/2509.03918 ,  1414kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03932
Date: Thu, 4 Sep 2025 06:45:39 GMT   (1140kb)

Title: Decoding the Poetic Language of Emotion in Korean Modern Poetry:
  Insights from a Human-Labeled Dataset and AI Modeling
Authors: Iro Lim, Haein Ji, and Byungjun Kim
Categories: cs.CL cs.CY cs.LG
Comments: 30 pages, 13 tables, 2 figures, Digital Humanities and Social
  Sciences Korea Conference, James Joo-Jin Kim Center for Korean Studies,
  University of Pennsylvania, Philadelphia, USA
\\
  This study introduces KPoEM (Korean Poetry Emotion Mapping) , a novel dataset
for computational emotion analysis in modern Korean poetry. Despite remarkable
progress in text-based emotion classification using large language models,
poetry-particularly Korean poetry-remains underexplored due to its figurative
language and cultural specificity. We built a multi-label emotion dataset of
7,662 entries, including 7,007 line-level entries from 483 poems and 615
work-level entries, annotated with 44 fine-grained emotion categories from five
influential Korean poets. A state-of-the-art Korean language model fine-tuned
on this dataset significantly outperformed previous models, achieving 0.60
F1-micro compared to 0.34 from models trained on general corpora. The KPoEM
model, trained through sequential fine-tuning-first on general corpora and then
on the KPoEM dataset-demonstrates not only an enhanced ability to identify
temporally and culturally specific emotional expressions, but also a strong
capacity to preserve the core sentiments of modern Korean poetry. This study
bridges computational methods and literary analysis, presenting new
possibilities for the quantitative exploration of poetic emotions through
structured data that faithfully retains the emotional and cultural nuances of
Korean literature.
\\ ( https://arxiv.org/abs/2509.03932 ,  1140kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03934
Date: Thu, 4 Sep 2025 06:50:47 GMT   (1464kb)

Title: SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented
  Generation via Distribution Self-Alignment
Authors: Yuqing Huang, Rongyang Zhang, Qimeng Wang, Chengqiang Lu, Yan Gao, Yi
  Wu, Yao Hu, Xuyang Zhi, Guiquan Liu, Xin Li, Hao Wang, Enhong Chen
Categories: cs.CL cs.AI
\\
  Recent advancements in large language models (LLMs) have revolutionized
natural language processing through their remarkable capabilities in
understanding and executing diverse tasks. While supervised fine-tuning,
particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively
enhances task-specific performance, it often leads to catastrophic forgetting,
where models lose their previously acquired knowledge and general capabilities.
Existing solutions either require access to general instruction data or face
limitations in preserving the model's original distribution. To overcome these
limitations, we propose SelfAug, a self-distribution alignment method that
aligns input sequence logits to preserve the model's semantic distribution,
thereby mitigating catastrophic forgetting and improving downstream
performance. Extensive experiments demonstrate that SelfAug achieves a superior
balance between downstream learning and general capability retention. Our
comprehensive empirical analysis reveals a direct correlation between
distribution shifts and the severity of catastrophic forgetting in RAG
scenarios, highlighting how the absence of RAG capabilities in general
instruction tuning leads to significant distribution shifts during fine-tuning.
Our findings not only advance the understanding of catastrophic forgetting in
RAG contexts but also provide a practical solution applicable across diverse
fine-tuning scenarios. Our code is publicly available at
https://github.com/USTC-StarTeam/SelfAug.
\\ ( https://arxiv.org/abs/2509.03934 ,  1464kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03937
Date: Thu, 4 Sep 2025 06:55:46 GMT   (354kb)

Title: SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by
  Self-Play Fine-Tuning
Authors: Yuhao Zhang, Shaoming Duan, Jinhang Su, Chuanyi Liu, Peiyi Han
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Findings
\\
  Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new information, and
the large number of correct SQL queries produced by the opponent model during
self-play reduces the main model's ability to generate accurate SQL queries. To
address this challenge, we propose a new self-play fine-tuning method tailored
for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a
verification-based iterative fine-tuning approach, which synthesizes
high-quality fine-tuning data iteratively based on the database schema and
validation feedback to enhance model performance, while building a model base
with varying capabilities. During the self-play fine-tuning phase, we propose
an error-driven loss method that incentivizes incorrect outputs from the
opponent model, enabling the main model to distinguish between correct SQL and
erroneous SQL generated by the opponent model, thereby improving its ability to
generate correct SQL. Extensive experiments and in-depth analyses on six
open-source LLMs and five widely used benchmarks demonstrate that our approach
outperforms existing state-of-the-art (SOTA) methods.
\\ ( https://arxiv.org/abs/2509.03937 ,  354kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03940
Date: Thu, 4 Sep 2025 07:03:46 GMT   (1109kb)

Title: VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based
  Role-Playing Agents
Authors: Weihao Wu, Liang Cao, Xinyu Wu, Zhiwei Lin, Rui Niu, Jingbei Li,
  Zhiyong Wu
Categories: cs.CL cs.AI cs.SD
\\
  Recent significant advancements in Large Language Models (LLMs) have greatly
propelled the development of Role-Playing Conversational Agents (RPCAs). These
systems aim to create immersive user experiences through consistent persona
adoption. However, current RPCA research faces dual limitations. First,
existing work predominantly focuses on the textual modality, entirely
overlooking critical paralinguistic features including intonation, prosody, and
rhythm in speech, which are essential for conveying character emotions and
shaping vivid identities. Second, the speech-based role-playing domain suffers
from a long-standing lack of standardized evaluation benchmarks. Most current
spoken dialogue datasets target only fundamental capability assessments,
featuring thinly sketched or ill-defined character profiles. Consequently, they
fail to effectively quantify model performance on core competencies like
long-term persona consistency. To address this critical gap, we introduce
VoxRole, the first comprehensive benchmark specifically designed for the
evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn
dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261
movies. To construct this resource, we propose a novel two-stage automated
pipeline that first aligns movie audio with scripts and subsequently employs an
LLM to systematically build multi-dimensional profiles for each character.
Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary
spoken dialogue models, revealing crucial insights into their respective
strengths and limitations in maintaining persona consistency.
\\ ( https://arxiv.org/abs/2509.03940 ,  1109kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03957
Date: Thu, 4 Sep 2025 07:33:44 GMT   (8273kb)

Title: CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese
  Misinformation Fact-Checking
Authors: Ruiling Guo, Xinwei Yang, Chen Huang, Tong Zhang, Yong Hu
Categories: cs.CL cs.AI
Comments: Findings of EMNLP 2025
\\
  The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
we curate a carefully annotated dataset of ~20k instances. Our analysis shows
that current LLMs exhibit limitations in generating accurate fact-checking
conclusions, even when enhanced with chain-of-thought reasoning and few-shot
prompting. To understand these limitations, we develop a taxonomy to categorize
flawed LLM-generated explanations for their conclusions and identify factual
fabrication as the most common failure mode. Although LLMs alone are unreliable
for fact-checking, our findings indicate their considerable potential to
augment human performance when deployed as assistive tools in scenarios. Our
dataset and code can be accessed at https://github.com/SCUNLP/CANDY
\\ ( https://arxiv.org/abs/2509.03957 ,  8273kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03962
Date: Thu, 4 Sep 2025 07:41:23 GMT   (583kb)

Title: Exploring NLP Benchmarks in an Extremely Low-Resource Setting
Authors: Ulin Nuha, Adam Jatowt
Categories: cs.CL
\\
  The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remains limited,
making it difficult to develop robust language technologies. This paper
addresses such gap by focusing on Ladin, an endangered Romance language,
specifically targeting the Val Badia variant. Leveraging a small set of
parallel Ladin-Italian sentence pairs, we create synthetic datasets for
sentiment analysis and multiple-choice question answering (MCQA) by translating
monolingual Italian data. To ensure linguistic quality and reliability, we
apply rigorous filtering and back-translation procedures in our method. We
further demonstrate that incorporating these synthetic datasets into machine
translation training leads to substantial improvements over existing
Italian-Ladin translation baselines. Our contributions include the first
publicly available sentiment analysis and MCQA datasets for Ladin, establishing
foundational resources that can support broader NLP research and downstream
applications for this underrepresented language.
\\ ( https://arxiv.org/abs/2509.03962 ,  583kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03972
Date: Thu, 4 Sep 2025 07:56:24 GMT   (15kb)

Title: Expanding Foundational Language Capabilities in Open-Source LLMs through
  a Korean Case Study
Authors: Junghwan Lim, Gangwon Jo, Sungmin Lee, Jiyoung Park, Dongseok Kim,
  Jihwan Kim, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Kibong Choi, Jaeyeon
  Huh, Beomgyu Kim, Jangwoong Kim, Taehyun Kim, Haesol Lee, Jeesoo Lee, Dongpin
  Oh, Changseok Song, Daewon Suh
Categories: cs.CL cs.AI cs.LG
\\
  We introduce Llama-3-Motif, a language model consisting of 102 billion
parameters, specifically designed to enhance Korean capabilities while
retaining strong performance in English. Developed on the Llama 3 architecture,
Llama-3-Motif employs advanced training techniques, including LlamaPro and
Masked Structure Growth, to effectively scale the model without altering its
core Transformer architecture. Using the MoAI platform for efficient training
across hyperscale GPU clusters, we optimized Llama-3-Motif using a carefully
curated dataset that maintains a balanced ratio of Korean and English data.
Llama-3-Motif shows decent performance on Korean-specific benchmarks,
outperforming existing models and achieving results comparable to GPT-4.
\\ ( https://arxiv.org/abs/2509.03972 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03995
Date: Thu, 4 Sep 2025 08:25:01 GMT   (637kb)

Title: RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question
  Answering with Large Language Models
Authors: Zhaoyan Gong, Juan Li, Zhiqiang Liu, Lei Liang, Huajun Chen, Wen Zhang
Categories: cs.CL cs.AI
Comments: EMNLP 2025
\\
  Current temporal knowledge graph question answering (TKGQA) methods primarily
focus on implicit temporal constraints, lacking the capability of handling more
complex temporal queries, and struggle with limited reasoning abilities and
error propagation in decomposition frameworks. We propose RTQA, a novel
framework to address these challenges by enhancing reasoning over TKGs without
requiring training. Following recursive thinking, RTQA recursively decomposes
questions into sub-problems, solves them bottom-up using LLMs and TKG
knowledge, and employs multi-path answer aggregation to improve fault
tolerance. RTQA consists of three core components: the Temporal Question
Decomposer, the Recursive Solver, and the Answer Aggregator. Experiments on
MultiTQ and TimelineKGQA benchmarks demonstrate significant Hits@1 improvements
in "Multiple" and "Complex" categories, outperforming state-of-the-art methods.
Our code and data are available at https://github.com/zjukg/RTQA.
\\ ( https://arxiv.org/abs/2509.03995 ,  637kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04013
Date: Thu, 4 Sep 2025 08:43:27 GMT   (106kb)

Title: On Robustness and Reliability of Benchmark-Based Evaluation of LLMs
Authors: Riccardo Lunardi, Vincenzo Della Mea, Stefano Mizzaro, Kevin Roitero
Categories: cs.CL cs.AI
Comments: Accepted at ECAI 2025
\\
  Large Language Models (LLMs) effectiveness is usually evaluated by means of
benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in
their original wording, thus in a fixed, standardized format. However,
real-world applications involve linguistic variability, requiring models to
maintain their effectiveness across diverse rewordings of the same question or
query. In this study, we systematically assess the robustness of LLMs to
paraphrased benchmark questions and investigate whether benchmark-based
evaluations provide a reliable measure of model capabilities. We systematically
generate various paraphrases of all the questions across six different common
benchmarks, and measure the resulting variations in effectiveness of 34
state-of-the-art LLMs, of different size and effectiveness. Our findings reveal
that while LLM rankings remain relatively stable across paraphrased inputs,
absolute effectiveness scores change, and decline significantly. This suggests
that LLMs struggle with linguistic variability, raising concerns about their
generalization abilities and evaluation methodologies. Furthermore, the
observed performance drop challenges the reliability of benchmark-based
evaluations, indicating that high benchmark scores may not fully capture a
model's robustness to real-world input variations. We discuss the implications
of these findings for LLM evaluation methodologies, emphasizing the need for
robustness-aware benchmarks that better reflect practical deployment scenarios.
\\ ( https://arxiv.org/abs/2509.04013 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04032
Date: Thu, 4 Sep 2025 09:08:39 GMT   (786kb)

Title: What if I ask in \textit{alia lingua}? Measuring Functional Similarity
  Across Languages
Authors: Debangan Mishra, Arihant Rastogi, Agyeya Negi, Shashwat Goel,
  Ponnurangam Kumaraguru
Categories: cs.CL cs.LG
Comments: Preprint, 11 Pages
\\
  How similar are model outputs across languages? In this work, we study this
question using a recently proposed model similarity metric $\kappa_p$ applied
to 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that a
model's responses become increasingly consistent across languages as its size
and capability grow. Interestingly, models exhibit greater cross-lingual
consistency within themselves than agreement with other models prompted in the
same language. These results highlight not only the value of $\kappa_p$ as a
practical tool for evaluating multilingual reliability, but also its potential
to guide the development of more consistent multilingual systems.
\\ ( https://arxiv.org/abs/2509.04032 ,  786kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04046
Date: Thu, 4 Sep 2025 09:27:40 GMT   (772kb)

Title: A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts
Authors: Han Xiaohui, Zhang Yunlong, Guo Yuxi
Categories: cs.CL
Comments: The paper includes 10 pages, 6 tables, and 4 figures. This project is
  completed with the assistance of National Center for Language Technology and
  Digital Economy Research (No. GJLX20250002), and is funded by Heilongjiang
  Language Research Committee Project Construction of an Adaptive Intelligent
  Chinese Learning Platform for International Students in China (No. G2025Y003)
ACM-class: I.2.7
\\
  Systemic Functional Grammar and its branch, Cardiff Grammar, have been widely
applied to discourse analysis, semantic function research, and other tasks
across various languages and texts. However, an automatic annotation system
based on this theory for Chinese texts has not yet been developed, which
significantly constrains the application and promotion of relevant theories. To
fill this gap, this research introduces a functional syntax annotation model
for Chinese based on RoBERTa (Robustly Optimized BERT Pretraining Approach).
The study randomly selected 4,100 sentences from the People's Daily 2014 corpus
and annotated them according to functional syntax theory to establish a dataset
for training. The study then fine-tuned the RoBERTa-Chinese wwm-ext model based
on the dataset to implement the named entity recognition task, achieving an F1
score of 0.852 on the test set that significantly outperforms other comparative
models. The model demonstrated excellent performance in identifying core
syntactic elements such as Subject (S), Main Verb (M), and Complement (C).
Nevertheless, there remains room for improvement in recognizing entities with
imbalanced label samples. As the first integration of functional syntax with
attention-based NLP models, this research provides a new method for automated
Chinese functional syntax analysis and lays a solid foundation for subsequent
studies.
\\ ( https://arxiv.org/abs/2509.04046 ,  772kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04059
Date: Thu, 4 Sep 2025 09:42:17 GMT   (1565kb)

Title: Synthesizing Sheet Music Problems for Evaluation and Reinforcement
  Learning
Authors: Zhilin Wang, Zhe Yang, Yun Luo, Yafu Li, Haoran Zhang, Runzhe Zhan,
  Derek F. Wong, Jizhe Zhou, Yu Cheng
Categories: cs.CL
Comments: 11 pages
\\
  Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
propose the idea of synthesizing sheet music problems grounded in music theory,
which can serve both as evaluation benchmarks and as training data for
reinforcement learning with verifiable rewards (RLVR). We introduce a data
synthesis framework that generates verifiable sheet music questions in both
textual and visual modalities, leading to the Synthetic Sheet Music Reasoning
Benchmark (SSMR-Bench) and a complementary training set. Evaluation results on
SSMR-Bench show the importance of models' reasoning abilities in interpreting
sheet music. At the same time, the poor performance of Gemini 2.5-Pro
highlights the challenges that MLLMs still face in interpreting sheet music in
a visual format. By leveraging synthetic data for RLVR, Qwen3-8B-Base and
Qwen2.5-VL-Instruct achieve improvements on the SSMR-Bench. Besides, the
trained Qwen3-8B-Base surpasses GPT-4 in overall performance on
MusicTheoryBench and achieves reasoning performance comparable to GPT-4 with
the strategies of Role play and Chain-of-Thought. Notably, its performance on
math problems also improves relative to the original Qwen3-8B-Base.
Furthermore, our results show that the enhanced reasoning ability can also
facilitate music composition. In conclusion, we are the first to propose the
idea of synthesizing sheet music problems based on music theory rules, and
demonstrate its effectiveness not only in advancing model reasoning for sheet
music understanding but also in unlocking new possibilities for AI-assisted
music creation.
\\ ( https://arxiv.org/abs/2509.04059 ,  1565kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04066
Date: Thu, 4 Sep 2025 09:55:16 GMT   (122kb)

Title: Arabic Chatbot Technologies in Education: An Overview
Authors: Hicham Bourhil, Yacine El Younoussi
Categories: cs.CL
Comments: Published as a book chapter in: Transformaci\'on Digital en la
  Educaci\'on: Innovaciones y Desaf\'ios desde los Campus Virtuales (UA
  Journals, 2024), pp. 11-14
Journal-ref: In: Transformaci\'on Digital en la Educaci\'on: Innovaciones y
  Desaf\'ios desde los Campus Virtuales. UA Journals, 2024. pp. 11-14
DOI: 10.54988/uaj.000027.001
\\
  The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-19
pandemic, there has been an increasing interest in these digital technologies
to allow and enhance remote access. In education, e-learning systems have been
massively adopted worldwide. The emergence of Large Language Models (LLM) such
as BERT (Bidirectional Encoder Representations from Transformers) and GPT
(Generative Pre-trained Transformers) made chatbots even more popular. In this
study, we present a survey on existing Arabic chatbots in education and their
different characteristics such as the adopted approaches, language variety, and
metrics used to measure their performance. We were able to identified some
research gaps when we discovered that, despite the success of chatbots in other
languages such as English, only a few educational Arabic chatbots used modern
techniques. Finally, we discuss future directions of research in this field.
\\ ( https://arxiv.org/abs/2509.04066 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04077
Date: Thu, 4 Sep 2025 10:12:31 GMT   (19kb)

Title: Improving Narrative Classification and Explanation via Fine Tuned
  Language Models
Authors: Rishit Tyagi, Rahul Bouri, Mohit Gupta
Categories: cs.CL
\\
  Understanding covert narratives and implicit messaging is essential for
analyzing bias and sentiment. Traditional NLP methods struggle with detecting
subtle phrasing and hidden agendas. This study tackles two key challenges: (1)
multi-label classification of narratives and sub-narratives in news articles,
and (2) generating concise, evidence-based explanations for dominant
narratives. We fine-tune a BERT model with a recall-oriented approach for
comprehensive narrative detection, refining predictions using a GPT-4o pipeline
for consistency. For narrative explanation, we propose a ReACT (Reasoning +
Acting) framework with semantic retrieval-based few-shot prompting, ensuring
grounded and relevant justifications. To enhance factual accuracy and reduce
hallucinations, we incorporate a structured taxonomy table as an auxiliary
knowledge base. Our results show that integrating auxiliary knowledge in
prompts improves classification accuracy and justification reliability, with
applications in media analysis, education, and intelligence gathering.
\\ ( https://arxiv.org/abs/2509.04077 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04104
Date: Thu, 4 Sep 2025 11:07:27 GMT   (574kb)

Title: Towards Stable and Personalised Profiles for Lexical Alignment in Spoken
  Human-Agent Dialogue
Authors: Keara Schaaij, Roel Boumans, Tibor Bosse, Iris Hendrickx
Categories: cs.CL cs.HC
Comments: Accepted for TSD 2025
DOI: 10.1007/978-3-032-02548-7_5
\\
  Lexical alignment, where speakers start to use similar words across
conversation, is known to contribute to successful communication. However, its
implementation in conversational agents remains underexplored, particularly
considering the recent advancements in large language models (LLMs). As a first
step towards enabling lexical alignment in human-agent dialogue, this study
draws on strategies for personalising conversational agents and investigates
the construction of stable, personalised lexical profiles as a basis for
lexical alignment. Specifically, we varied the amounts of transcribed spoken
data used for construction as well as the number of items included in the
profiles per part-of-speech (POS) category and evaluated profile performance
across time using recall, coverage, and cosine similarity metrics. It was shown
that smaller and more compact profiles, created after 10 min of transcribed
speech containing 5 items for adjectives, 5 items for conjunctions, and 10
items for adverbs, nouns, pronouns, and verbs each, offered the best balance in
both performance and data efficiency. In conclusion, this study offers
practical insights into constructing stable, personalised lexical profiles,
taking into account minimal data requirements, serving as a foundational step
toward lexical alignment strategies in conversational agents.
\\ ( https://arxiv.org/abs/2509.04104 ,  574kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04111
Date: Thu, 4 Sep 2025 11:20:53 GMT   (595kb)

Title: MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages
Authors: Dan Saattrup Smart
Categories: cs.CL
\\
  We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which
covers 306 languages. The context data comes from Wikipedia articles, with
questions generated by an LLM and the answers appearing verbatim in the
Wikipedia articles. We conduct a crowdsourced human evaluation of the fluency
of the generated questions across 30 of the languages, providing evidence that
the questions are of good quality. We evaluate 6 different language models,
both decoder and encoder models of varying sizes, showing that the benchmark is
sufficiently difficult and that there is a large performance discrepancy
amongst the languages. The dataset and survey evaluations are freely available.
\\ ( https://arxiv.org/abs/2509.04111 ,  595kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04182
Date: Thu, 4 Sep 2025 12:58:37 GMT   (790kb)

Title: Joint Modeling of Entities and Discourse Relations for Coherence
  Assessment
Authors: Wei Liu and Michael Strube
Categories: cs.CL
Comments: EMNLP 2025
\\
  In linguistics, coherence can be achieved by different means, such as by
maintaining reference to the same set of entities across sentences and by
establishing discourse relations between them. However, most existing work on
coherence modeling focuses exclusively on either entity features or discourse
relation features, with little attention given to combining the two. In this
study, we explore two methods for jointly modeling entities and discourse
relations for coherence assessment. Experiments on three benchmark datasets
show that integrating both types of features significantly enhances the
performance of coherence models, highlighting the benefits of modeling both
simultaneously for coherence evaluation.
\\ ( https://arxiv.org/abs/2509.04182 ,  790kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04183
Date: Thu, 4 Sep 2025 12:59:24 GMT   (2213kb)

Title: MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn
  Mental Health Counseling Sessions
Authors: Aishik Mandal, Tanmoy Chakraborty, Iryna Gurevych
Categories: cs.CL cs.AI
Comments: 25 pages, 29 figures
\\
  The growing demand for scalable psychological counseling highlights the need
for fine-tuning open-source Large Language Models (LLMs) with high-quality,
privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,
a novel multi-agent framework for synthetic psychological counseling session
generation that decomposes counselor response generation into coordinated
sub-tasks handled by specialized LLM agents, each modeling a key psychological
technique. Unlike prior single-agent approaches, MAGneT better captures the
structure and nuance of real counseling. In addition, we address
inconsistencies in prior evaluation protocols by proposing a unified evaluation
framework integrating diverse automatic and expert metrics. Furthermore, we
expand the expert evaluations from four aspects of counseling in previous works
to nine aspects, enabling a more thorough and robust assessment of data
quality. Empirical results show that MAGneT significantly outperforms existing
methods in quality, diversity, and therapeutic alignment of the generated
counseling sessions, improving general counseling skills by 3.2% and
CBT-specific skills by 4.3% on average on cognitive therapy rating scale
(CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases
on average across all aspects. Moreover, fine-tuning an open-source model on
MAGneT-generated sessions shows better performance, with improvements of 6.3%
on general counseling skills and 7.3% on CBT-specific skills on average on CTRS
over those fine-tuned with sessions generated by baseline methods. We also make
our code and data public.
\\ ( https://arxiv.org/abs/2509.04183 ,  2213kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04202
Date: Thu, 4 Sep 2025 13:26:24 GMT   (636kb)

Title: Explicit and Implicit Data Augmentation for Social Event Detection
Authors: Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li,
  Hu Wang, Preslav Nakov
Categories: cs.CL cs.SI
\\
  Social event detection involves identifying and categorizing important events
from social media, which relies on labeled data, but annotation is costly and
labor-intensive. To address this problem, we propose Augmentation framework for
Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework,
which combines explicit text-based and implicit feature-space augmentation to
enhance data diversity and model robustness. The explicit augmentation utilizes
large language models to enhance textual information through five diverse
generation strategies. For implicit augmentation, we design five novel
perturbation techniques that operate in the feature space on structural fused
embeddings. These perturbations are crafted to keep the semantic and relational
properties of the embeddings and make them more diverse. Specifically, SED-Aug
outperforms the best baseline model by approximately 17.67% on the Twitter2012
dataset and by about 15.57% on the Twitter2018 dataset in terms of the average
F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.
\\ ( https://arxiv.org/abs/2509.04202 ,  636kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04292
Date: Thu, 4 Sep 2025 15:03:02 GMT   (9499kb)

Title: Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow
  Real Instructions?
Authors: Qinyan Zhang, Xinping Lei, Ruijie Miao, Yu Fu, Haojie Fan, Le Chang,
  Jiafan Hou, Dingling Zhang, Zhongfei Hou, Ziqiang Yang, Changxin Pu, Fei Hu,
  Jingkai Liu, Mengyun Liu, Yang Liu, Xiang Gao, Jiaheng Liu, Tong Yang,
  Zaiyuan Wang, Ge Zhang, Wenhao Huang
Categories: cs.CL
\\
  Large Language Models (LLMs) achieve strong performance on diverse tasks but
often exhibit cognitive inertia, struggling to follow instructions that
conflict with the standardized patterns learned during supervised fine-tuning
(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that
measures models Counter-intuitive Abilitytheir capacity to override
training-induced biases and comply with adversarial instructions. Inverse
IFEval introduces eight types of such challenges, including Question
Correction, Intentional Textual Flaws, Code without Comments, and
Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a
dataset of 1012 high-quality Chinese and English questions across 23 domains,
evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing
leading LLMs demonstrate the necessity of our proposed Inverse IFEval
benchmark. Our findings emphasize that future alignment efforts should not only
pursue fluency and factual correctness but also account for adaptability under
unconventional contexts. We hope that Inverse IFEval serves as both a
diagnostic tool and a foundation for developing methods that mitigate cognitive
inertia, reduce overfitting to narrow patterns, and ultimately enhance the
instruction-following reliability of LLMs in diverse and unpredictable
real-world scenarios.
\\ ( https://arxiv.org/abs/2509.04292 ,  9499kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04304
Date: Thu, 4 Sep 2025 15:17:50 GMT   (475kb)

Title: Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge
  in Large Language Models
Authors: Juraj Vladika, Mahdi Dhaini, Florian Matthes
Categories: cs.CL cs.AI
Comments: Accepted to Findings of EMNLP 2025
\\
  The growing capabilities of Large Language Models (LLMs) show significant
potential to enhance healthcare by assisting medical researchers and
physicians. However, their reliance on static training data is a major risk
when medical recommendations evolve with new research and developments. When
LLMs memorize outdated medical knowledge, they can provide harmful advice or
fail at clinical reasoning tasks. To investigate this problem, we introduce two
novel question-answering (QA) datasets derived from systematic reviews:
MedRevQA (16,501 QA pairs covering general biomedical knowledge) and
MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over
time). Our evaluation of eight prominent LLMs on the datasets reveals
consistent reliance on outdated knowledge across all models. We additionally
analyze the influence of obsolete pre-training data and training strategies to
explain this phenomenon and propose future directions for mitigation, laying
the groundwork for developing more current and reliable medical AI systems.
\\ ( https://arxiv.org/abs/2509.04304 ,  475kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04357
Date: Thu, 4 Sep 2025 16:18:34 GMT   (701kb)

Title: PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity
  Disambiguation
Authors: Jiajun He, Naoki Sawada, Koichi Miyazaki, Tomoki Toda
Categories: cs.CL cs.AI cs.LG cs.SD
Comments: Accepted by ASRU 2025
\\
  Automatic speech recognition (ASR) systems struggle with domain-specific
named entities, especially homophones. Contextual ASR improves recognition but
often fails to capture fine-grained phoneme variations due to limited entity
diversity. Moreover, prior methods treat entities as independent tokens,
leading to incomplete multi-token biasing. To address these issues, we propose
Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation
(PARCO), which integrates phoneme-aware encoding, contrastive entity
disambiguation, entity-level supervision, and hierarchical entity filtering.
These components enhance phonetic discrimination, ensure complete entity
retrieval, and reduce false positives under uncertainty. Experiments show that
PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English
DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO
also demonstrates robust gains on out-of-domain datasets like THCHS-30 and
LibriSpeech.
\\ ( https://arxiv.org/abs/2509.04357 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04373
Date: Thu, 4 Sep 2025 16:32:18 GMT   (479kb)

Title: Measuring Bias or Measuring the Task: Understanding the Brittle Nature
  of LLM Gender Biases
Authors: Bufan Gao, Elisa Kreiss
Categories: cs.CL
\\
  As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully constructed
task prompts that overtly or covertly signal the presence of gender
bias-related content. In this paper, we examine how signaling the evaluative
purpose of a task impacts measured gender bias in LLMs. Concretely, we test
models under prompt conditions that (1) make the testing context salient, and
(2) make gender-focused content salient. We then assess prompt sensitivity
across four task formats with both token-probability and discrete-choice
metrics. We find that even minor prompt changes can substantially alter bias
outcomes, sometimes reversing their direction entirely. Discrete-choice metrics
further tend to amplify bias relative to probabilistic measures. These findings
do not only highlight the brittleness of LLM gender bias evaluations but open a
new puzzle for the NLP benchmarking and development community: To what extent
can well-controlled testing designs trigger LLM ``testing mode'' performance,
and what does this mean for the ecological validity of future benchmarks.
\\ ( https://arxiv.org/abs/2509.04373 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04432
Date: Thu, 4 Sep 2025 17:52:00 GMT   (1683kb)

Title: Can Language Models Handle a Non-Gregorian Calendar?
Authors: Mutsumi Sasaki, Go Kamoda, Ryosuke Takahashi, Kosuke Sato, Kentaro
  Inui, Keisuke Sakaguchi, Benjamin Heinzerling
Categories: cs.CL
\\
  Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we present a systematic
evaluation of how well open-source LMs handle one such non-Gregorian system:
the Japanese calendar. For our evaluation, we create datasets for four tasks
that require both temporal knowledge and temporal reasoning. Evaluating a range
of English-centric and Japanese-centric LMs, we find that some models can
perform calendar conversions, but even Japanese-centric models struggle with
Japanese-calendar arithmetic and with maintaining consistency across calendars.
Our results highlight the importance of developing LMs that are better equipped
for culture-specific calendar understanding.
\\ ( https://arxiv.org/abs/2509.04432 ,  1683kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03609
Date: Wed, 3 Sep 2025 18:05:02 GMT   (146kb)

Title: Towards Efficient General Feature Prediction in Masked Skeleton Modeling
Authors: Shengkai Sun, Zefan Zhang, Jianfeng Dong, Zhiyong Cheng, Xiaojun
  Chang, Meng Wang
Categories: cs.CV
Comments: Accepted by ICCV 2025
\\
  Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.
\\ ( https://arxiv.org/abs/2509.03609 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03614
Date: Wed, 3 Sep 2025 18:08:11 GMT   (863kb)

Title: Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG
  2025 Challenge
Authors: Seungho Choe, Xiaoli Qin, Abubakr Shafique, Amanda Dy, Dimitri
  Androutsos, Susan Done, April Khademi
Categories: cs.CV
Comments: 4 pages, 1 figures, final submission for MIDOG 2025 challenge
\\
  Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.
\\ ( https://arxiv.org/abs/2509.03614 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03616
Date: Wed, 3 Sep 2025 18:08:59 GMT   (3330kb)

Title: Multi Attribute Bias Mitigation via Representation Learning
Authors: Rajeev Ranjan Dwivedi, Ankur Kumar, Vinod K Kurmi
Categories: cs.CV
Comments: ECAI 2025 (28th European Conference on Artificial Intelligence)
\\
  Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/
\\ ( https://arxiv.org/abs/2509.03616 ,  3330kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03631
Date: Wed, 3 Sep 2025 18:33:28 GMT   (1808kb)

Title: Lightweight image segmentation for echocardiography
Authors: Anders Kjelsrud, Lasse L{\o}vstakken, Erik Smistad, H{\aa}vard Dalen
  and Gilles Van De Vyver
Categories: cs.CV
Comments: 4 pages, 6 figures, The 2025 IEEE International Ultrasonics Symposium
\\
  Accurate segmentation of the left ventricle in echocardiography can enable
fully automatic extraction of clinical measurements such as volumes and
ejection fraction. While models configured by nnU-Net perform well, they are
large and slow, thus limiting real-time use. We identified the most effective
components of nnU-Net for cardiac segmentation through an ablation study,
incrementally evaluating data augmentation schemes, architectural
modifications, loss functions, and post-processing techniques. Our analysis
revealed that simple affine augmentations and deep supervision drive
performance, while complex augmentations and large model capacity offer
diminishing returns. Based on these insights, we developed a lightweight U-Net
(2M vs 33M parameters) that achieves statistically equivalent performance to
nnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89
for LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster
(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.
Cross-dataset evaluation on an internal dataset (N=311) confirms comparable
generalization.
\\ ( https://arxiv.org/abs/2509.03631 ,  1808kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03633
Date: Wed, 3 Sep 2025 18:35:20 GMT   (35935kb)

Title: treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point
  Clouds
Authors: Josafat-Mattias Burmeister, Andreas Tockner, Stefan Reder, Markus
  Engel, Rico Richter, Jan-Peter Mund, J\"urgen D\"ollner
Categories: cs.CV cs.AI
ACM-class: I.4.6; I.5.2; I.2.10
\\
  Close-range laser scanning provides detailed 3D captures of forest stands but
requires efficient software for processing 3D point cloud data and extracting
individual trees. Although recent studies have introduced deep learning methods
for tree instance segmentation, these approaches require large annotated
datasets and substantial computational resources. As a resource-efficient
alternative, we present a revised version of the treeX algorithm, an
unsupervised method that combines clustering-based stem detection with region
growing for crown delineation. While the original treeX algorithm was developed
for personal laser scanning (PLS) data, we provide two parameter presets, one
for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one
for UAV-borne laser scanning (ULS). We evaluated the method on six public
datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham
Woods) and compared it to six open-source methods (original treeX, treeiso,
RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original
treeX algorithm, our revision reduces runtime and improves accuracy, with
instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.
For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original
algorithm fails to segment any correct instances. For TLS and PLS data, our
algorithm achieves accuracy similar to recent open-source methods, including
deep learning. Given its algorithmic design, we see two main applications for
our method: (1) as a resource-efficient alternative to deep learning approaches
in scenarios where the data characteristics align with the method design
(sufficient stem visibility and point density), and (2) for the semi-automatic
generation of labels for deep learning models. To enable broader adoption, we
provide an open-source Python implementation in the pointtree package.
\\ ( https://arxiv.org/abs/2509.03633 ,  35935kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03635
Date: Wed, 3 Sep 2025 18:36:44 GMT   (3677kb)

Title: Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene
  Understanding
Authors: Hongpei Zheng, Lintao Xiang, Qijun Yang, Qian Lin, Hujun Yin
Categories: cs.CV
Comments: 16 pages, 6 figures
\\
  The rapid development of Large Multimodal Models (LMMs) has led to remarkable
progress in 2D visual understanding; however, extending these capabilities to
3D scene understanding remains a significant challenge. Existing approaches
predominantly rely on text-only supervision, which fails to provide the
geometric constraints required for learning robust 3D spatial representations.
In this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction
Tuning framework that addresses this limitation by incorporating geometry-aware
supervision directly into the training process. Our key insight is that
effective 3D understanding necessitates reconstructing underlying geometric
structures rather than merely describing them. Unlike existing methods that
inject 3D information solely at the input level, Reg3D adopts a
dual-supervision paradigm that leverages 3D geometric information both as input
and as explicit learning targets. Specifically, we design complementary
object-level and frame-level reconstruction tasks within a dual-encoder
architecture, enforcing geometric consistency to encourage the development of
spatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,
ScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance
improvements, establishing a new training paradigm for spatially aware
multimodal models.
\\ ( https://arxiv.org/abs/2509.03635 ,  3677kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03704
Date: Wed, 3 Sep 2025 20:39:03 GMT   (7108kb)

Title: QuantV2X: A Fully Quantized Multi-Agent System for Cooperative
  Perception
Authors: Seth Z. Zhao, Huizhi Zhang, Zhaowei Li, Juntong Peng, Anthony Chui,
  Zewei Zhou, Zonglin Meng, Hao Xiang, Zhiyu Huang, Fujia Wang, Ran Tian,
  Chenfeng Xu, Bolei Zhou, Jiaqi Ma
Categories: cs.CV
\\
  Cooperative perception through Vehicle-to-Everything (V2X) communication
offers significant potential for enhancing vehicle perception by mitigating
occlusions and expanding the field of view. However, past research has
predominantly focused on improving accuracy metrics without addressing the
crucial system-level considerations of efficiency, latency, and real-world
deployability. Noticeably, most existing systems rely on full-precision models,
which incur high computational and transmission costs, making them impractical
for real-time operation in resource-constrained environments. In this paper, we
introduce \textbf{QuantV2X}, the first fully quantized multi-agent system
designed specifically for efficient and scalable deployment of multi-modal,
multi-agent V2X cooperative perception. QuantV2X introduces a unified
end-to-end quantization strategy across both neural network models and
transmitted message representations that simultaneously reduces computational
load and transmission bandwidth. Remarkably, despite operating under low-bit
constraints, QuantV2X achieves accuracy comparable to full-precision systems.
More importantly, when evaluated under deployment-oriented metrics, QuantV2X
reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in
mAP30 over full-precision baselines. Furthermore, QuantV2X scales more
effectively, enabling larger and more capable models to fit within strict
memory budgets. These results highlight the viability of a fully quantized
multi-agent intermediate fusion system for real-world deployment. The system
will be publicly released to promote research in this field:
https://github.com/ucla-mobility/QuantV2X.
\\ ( https://arxiv.org/abs/2509.03704 ,  7108kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03729
Date: Wed, 3 Sep 2025 21:23:09 GMT   (1441kb)

Title: Transfer Learning-Based CNN Models for Plant Species Identification
  Using Leaf Venation Patterns
Authors: Bandita Bharadwaj, Ankur Mishra, Saurav Bharadwaj
Categories: cs.CV
\\
  This study evaluates the efficacy of three deep learning architectures:
ResNet50, MobileNetV2, and EfficientNetB0 for automated plant species
classification based on leaf venation patterns, a critical morphological
feature with high taxonomic relevance. Using the Swedish Leaf Dataset
comprising images from 15 distinct species (75 images per species, totalling
1,125 images), the models were demonstrated using standard performance metrics
during training and testing phases. ResNet50 achieved a training accuracy of
94.11% but exhibited overfitting, reflected by a reduced testing accuracy of
88.45% and an F1 score of 87.82%. MobileNetV2 demonstrated better
generalization capabilities, attaining a testing accuracy of 93.34% and an F1
score of 93.23%, indicating its suitability for lightweight, real-time
applications. EfficientNetB0 outperformed both models, achieving a testing
accuracy of 94.67% with precision, recall, and F1 scores exceeding 94.6%,
highlighting its robustness in venation-based classification. The findings
underscore the potential of deep learning, particularly EfficientNetB0, in
developing scalable and accurate tools for automated plant taxonomy using
venation traits.
\\ ( https://arxiv.org/abs/2509.03729 ,  1441kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03737
Date: Wed, 3 Sep 2025 21:56:16 GMT   (3058kb)

Title: LayoutGKN: Graph Similarity Learning of Floor Plans
Authors: Casper van Engelenburg, Jan van Gemert, Seyran Khademi
Categories: cs.CV
Comments: BMVC (2025)
\\
  Floor plans depict building layouts and are often represented as graphs to
capture the underlying spatial relationships. Comparison of these graphs is
critical for applications like search, clustering, and data visualization. The
most successful methods to compare graphs \ie, graph matching networks, rely on
costly intermediate cross-graph node-level interactions, therefore being slow
in inference time. We introduce \textbf{LayoutGKN}, a more efficient approach
that postpones the cross-graph node-level interactions to the end of the joint
embedding architecture. We do so by using a differentiable graph kernel as a
distance function on the final learned node-level embeddings. We show that
LayoutGKN computes similarity comparably or better than graph matching networks
while significantly increasing the speed.
\href{https://github.com/caspervanengelenburg/LayoutGKN}{Code and data} are
open.
\\ ( https://arxiv.org/abs/2509.03737 ,  3058kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03740
Date: Wed, 3 Sep 2025 22:00:23 GMT   (1806kb)

Title: Singular Value Few-shot Adaptation of Vision-Language Models
Authors: Taha Koleilat, Hassan Rivaz, Yiming Xiao
Categories: cs.CV cs.CL
Comments: 10 pages, 2 figures, 8 tables
\\
  Vision-language models (VLMs) like CLIP have shown impressive zero-shot and
few-shot learning capabilities across diverse applications. However, adapting
these models to new fine-grained domains remains difficult due to reliance on
prompt engineering and the high cost of full model fine-tuning. Existing
adaptation approaches rely on augmented components, such as prompt tokens and
adapter modules, which could limit adaptation quality, destabilize the model,
and compromise the rich knowledge learned during pretraining. In this work, we
present \textbf{CLIP-SVD}, a novel \textit{multi-modal} and
\textit{parameter-efficient} adaptation technique that leverages Singular Value
Decomposition (SVD) to modify the internal parameter space of CLIP without
injecting additional modules. Specifically, we fine-tune only the singular
values of the CLIP parameter matrices to rescale the basis vectors for domain
adaptation while retaining the pretrained model. This design enables enhanced
adaptation performance using only \textbf{0.04\%} of the model's total
parameters and better preservation of its generalization ability. CLIP-SVD
achieves state-of-the-art classification results on 11 natural and 10
biomedical datasets, outperforming previous methods in both accuracy and
generalization under few-shot settings. Additionally, we leverage a natural
language-based approach to analyze the effectiveness and dynamics of the CLIP
adaptation to allow interpretability of CLIP-SVD. The code is publicly
available at https://github.com/HealthX-Lab/CLIP-SVD.
\\ ( https://arxiv.org/abs/2509.03740 ,  1806kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03754
Date: Wed, 3 Sep 2025 22:46:20 GMT   (4104kb)

Title: STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight
  Plant Disease Classification
Authors: Zongsen Qiu
Categories: cs.CV cs.AI
\\
  Responding to rising global food security needs, precision agriculture and
deep learning-based plant disease diagnosis have become crucial. Yet, deploying
high-precision models on edge devices is challenging. Most lightweight networks
use attention mechanisms designed for generic object recognition, which poorly
capture subtle pathological features like irregular lesion shapes and complex
textures. To overcome this, we propose a twofold solution: first, using a
training-free neural architecture search method (DeepMAD) to create an
efficient network backbone for edge devices; second, introducing the
Shape-Texture Attention Module (STAM). STAM splits attention into two branches
-- one using deformable convolutions (DCNv4) for shape awareness and the other
using a Gabor filter bank for texture awareness. On the public CCMT plant
disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs)
reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm
STAM significantly improves performance over baseline and standard attention
models. Integrating domain knowledge via decoupled attention thus presents a
promising path for edge-deployed precision agriculture AI. The source code is
available at https://github.com/RzMY/STA-Net.
\\ ( https://arxiv.org/abs/2509.03754 ,  4104kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03786
Date: Thu, 4 Sep 2025 00:44:32 GMT   (2194kb)

Title: SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object
  Detection
Authors: Xinxin Wang, Han Sun, Ningzhong Liu, Huiyu Zhou, Yinan Yao
Categories: cs.CV
Comments: 14pages, accepted by PRCV2025
\\
  Underwater Camouflaged Object Detection (UCOD) aims to identify objects that
blend seamlessly into underwater environments. This task is critically
important to marine ecology. However, it remains largely underexplored and
accurate identification is severely hindered by optical distortions, water
turbidity, and the complex traits of marine organisms. To address these
challenges, we introduce the UCOD task and present DeepCamo, a benchmark
dataset designed for this domain. We also propose Semantic Localization and
Enhancement Network (SLENet), a novel framework for UCOD. We first benchmark
state-of-the-art COD models on DeepCamo to reveal key issues, upon which SLENet
is built. In particular, we incorporate Gamma-Asymmetric Enhancement (GAE)
module and a Localization Guidance Branch (LGB) to enhance multi-scale feature
representation while generating a location map enriched with global semantic
information. This map guides the Multi-Scale Supervised Decoder (MSSD) to
produce more accurate predictions. Experiments on our DeepCamo dataset and
three benchmark COD datasets confirm SLENet's superior performance over SOTA
methods, and underscore its high generality for the broader COD task.
\\ ( https://arxiv.org/abs/2509.03786 ,  2194kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03794
Date: Thu, 4 Sep 2025 01:04:54 GMT   (2756kb)

Title: Fitting Image Diffusion Models on Video Datasets
Authors: Juhun Lee, Simon S. Woo
Categories: cs.CV
Comments: ICCV25 Workshop
\\
  Image diffusion models are trained on independently sampled static images.
While this is the bedrock task protocol in generative modeling, capturing the
temporal world through the lens of static snapshots is information-deficient by
design. This limitation leads to slower convergence, limited distributional
coverage, and reduced generalization. In this work, we propose a simple and
effective training strategy that leverages the temporal inductive bias present
in continuous video frames to improve diffusion training. Notably, the proposed
method requires no architectural modification and can be seamlessly integrated
into standard diffusion training pipelines. We evaluate our method on the
HandCo dataset, where hand-object interactions exhibit dense temporal coherence
and subtle variations in finger articulation often result in semantically
distinct motions. Empirically, our method accelerates convergence by over
2$\text{x}$ faster and achieves lower FID on both training and validation
distributions. It also improves generative diversity by encouraging the model
to capture meaningful temporal variations. We further provide an optimization
analysis showing that our regularization reduces the gradient variance, which
contributes to faster convergence.
\\ ( https://arxiv.org/abs/2509.03794 ,  2756kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03800
Date: Thu, 4 Sep 2025 01:28:44 GMT   (24583kb)

Title: MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in
  3D CT Disease Detection, Understanding and Reporting
Authors: Yuheng Li, Yenho Chen, Yuxiang Lai, Jike Zhong, Vanessa Wildman and
  Xiaofeng Yang
Categories: cs.CV
\\
  Radiologic diagnostic errors-under-reading errors, inattentional blindness,
and communication failures-remain prevalent in clinical practice. These issues
often stem from missed localized abnormalities, limited global context, and
variability in report language. These challenges are amplified in 3D imaging,
where clinicians must examine hundreds of slices per scan. Addressing them
requires systems with precise localized detection, global volume-level
reasoning, and semantically consistent natural language reporting. However,
existing 3D vision-language models are unable to meet all three needs jointly,
lacking local-global understanding for spatial reasoning and struggling with
the variability and noise of uncurated radiology reports. We present
MedVista3D, a multi-scale semantic-enriched vision-language pretraining
framework for 3D CT analysis. To enable joint disease detection and holistic
interpretation, MedVista3D performs local and global image-text alignment for
fine-grained representation learning within full-volume context. To address
report variability, we apply language model rewrites and introduce a Radiology
Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves
state-of-the-art performance on zero-shot disease classification, report
retrieval, and medical visual question answering, while transferring well to
organ segmentation and prognosis prediction. Code and datasets will be
released.
\\ ( https://arxiv.org/abs/2509.03800 ,  24583kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03803
Date: Thu, 4 Sep 2025 01:40:41 GMT   (321kb)

Title: Causality-guided Prompt Learning for Vision-language Models via Visual
  Granulation
Authors: Mengyu Gao, Qiulei Dong
Categories: cs.CV
Comments: ICCV 2025 Accepted
\\
  Prompt learning has recently attracted much attention for adapting
pre-trained vision-language models (e.g., CLIP) to downstream recognition
tasks. However, most of the existing CLIP-based prompt learning methods only
show a limited ability for handling fine-grained datasets. To address this
issue, we propose a causality-guided text prompt learning method via visual
granulation for CLIP, called CaPL, where the explored visual granulation
technique could construct sets of visual granules for the text prompt to
capture subtle discrepancies among different fine-grained classes through
casual inference. The CaPL method contains the following two modules: (1) An
attribute disentanglement module is proposed to decompose visual features into
non-individualized attributes (shared by some classes) and individualized
attributes (specific to single classes) using a Brownian Bridge Diffusion
Model; (2) A granule learning module is proposed to construct visual granules
by integrating the aforementioned attributes for recognition under two causal
inference strategies. Thanks to the learned visual granules, more
discriminative text prompt is expected to be learned. Extensive experimental
results on 15 datasets demonstrate that our CaPL method significantly
outperforms the state-of-the-art prompt learning methods, especially on
fine-grained datasets.
\\ ( https://arxiv.org/abs/2509.03803 ,  321kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03808
Date: Thu, 4 Sep 2025 01:49:13 GMT   (2544kb)

Title: EGTM: Event-guided Efficient Turbulence Mitigation
Authors: Huanan Li, Rui Fan, Juntao Guan, Weidong Hao, Lai Rui, Tong Wu, Yikai
  Wang, Lin Gu
Categories: cs.CV
\\
  Turbulence mitigation (TM) aims to remove the stochastic distortions and
blurs introduced by atmospheric turbulence into frame cameras. Existing
state-of-the-art deep-learning TM methods extract turbulence cues from multiple
degraded frames to find the so-called "lucky'', not distorted patch, for "lucky
fusion''. However, it requires high-capacity network to learn from
coarse-grained turbulence dynamics between synchronous frames with limited
frame-rate, thus fall short in computational and storage efficiency. Event
cameras, with microsecond-level temporal resolution, have the potential to
fundamentally address this bottleneck with efficient sparse and asynchronous
imaging mechanism. In light of this, we (i) present the fundamental
\textbf{``event-lucky insight''} to reveal the correlation between turbulence
distortions and inverse spatiotemporal distribution of event streams. Then,
build upon this insight, we (ii) propose a novel EGTM framework that extracts
pixel-level reliable turbulence-free guidance from the explicit but noisy
turbulent events for temporal lucky fusion. Moreover, we (iii) build the first
turbulence data acquisition system to contribute the first real-world
event-driven TM dataset. Extensive experimental results demonstrate that our
approach significantly surpass the existing SOTA TM method by 710 times, 214
times and 224 times in model size, inference latency and model complexity
respectively, while achieving the state-of-the-art in restoration quality
(+0.94 PSNR and +0.08 SSIM) on our real-world EGTM dataset. This demonstrating
the great efficiency merit of introducing event modality into TM task. Demo
code and data have been uploaded in supplementary material and will be released
once accepted.
\\ ( https://arxiv.org/abs/2509.03808 ,  2544kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03872
Date: Thu, 4 Sep 2025 04:18:46 GMT   (3267kb)

Title: Focus Through Motion: RGB-Event Collaborative Token Sparsification for
  Efficient Object Detection
Authors: Nan Yang, Yang Wang, Zhanwen Liu, Yuchao Dai, Yang Liu, Xiangmo Zhao
Categories: cs.CV
\\
  Existing RGB-Event detection methods process the low-information regions of
both modalities (background in images and non-event regions in event data)
uniformly during feature extraction and fusion, resulting in high computational
costs and suboptimal performance. To mitigate the computational redundancy
during feature extraction, researchers have respectively proposed token
sparsification methods for the image and event modalities. However, these
methods employ a fixed number or threshold for token selection, hindering the
retention of informative tokens for samples with varying complexity. To achieve
a better balance between accuracy and efficiency, we propose FocusMamba, which
performs adaptive collaborative sparsification of multimodal features and
efficiently integrates complementary information. Specifically, an Event-Guided
Multimodal Sparsification (EGMS) strategy is designed to identify and
adaptively discard low-information regions within each modality by leveraging
scene content changes perceived by the event camera. Based on the
sparsification results, a Cross-Modality Focus Fusion (CMFF) module is proposed
to effectively capture and integrate complementary features from both
modalities. Experiments on the DSEC-Det and PKU-DAVIS-SOD datasets demonstrate
that the proposed method achieves superior performance in both accuracy and
efficiency compared to existing methods. The code will be available at
https://github.com/Zizzzzzzz/FocusMamba.
\\ ( https://arxiv.org/abs/2509.03872 ,  3267kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03873
Date: Thu, 4 Sep 2025 04:22:36 GMT   (2496kb)

Title: SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition
Authors: Jiajun Song, Xiaoou Liu
Categories: cs.CV cs.AI
Comments: 34th International Conference on Artificial Neural Networks - ICANN
  2025
\\
  Food recognition has gained significant attention, but the rapid emergence of
new dishes requires methods for recognizing unseen food categories, motivating
Zero-Shot Food Learning (ZSFL). We propose the task of Compositional Zero-Shot
Food Recognition (CZSFR), where cuisines and ingredients naturally align with
attributes and objects in Compositional Zero-Shot learning (CZSL). However,
CZSFR faces three challenges: (1) Redundant background information distracts
models from learning meaningful food features, (2) Role confusion between
staple and side dishes leads to misclassification, and (3) Semantic bias in a
single attribute can lead to confusion of understanding. Therefore, we propose
SalientFusion, a context-aware CZSFR method with two components: SalientFormer,
which removes background redundancy and uses depth features to resolve role
confusion; DebiasAT, which reduces the semantic bias by aligning prompts with
visual features. Using our proposed benchmarks, CZSFood-90 and CZSFood-164, we
show that SalientFusion achieves state-of-the-art results on these benchmarks
and the most popular general datasets for the general CZSL. The code is
avaliable at https://github.com/Jiajun-RUC/SalientFusion.
\\ ( https://arxiv.org/abs/2509.03873 ,  2496kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03883
Date: Thu, 4 Sep 2025 04:39:21 GMT   (4913kb)

Title: Human Motion Video Generation: A Survey
Authors: Haiwei Xue, Xiangyang Luo, Zhanghao Hu, Xin Zhang, Xunzhi Xiang, Yuqin
  Dai, Jianzhuang Liu, Zhensong Zhang, Minglei Li, Jian Yang, Fei Ma, Zhiyong
  Wu, Changpeng Yang, Zonghong Dai, and Fei Richard Yu
Categories: cs.CV cs.MM
Comments: Accepted by TPAMI. Github Repo:
  https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation IEEE Access:
  https://ieeexplore.ieee.org/document/11106267
Journal-ref: IEEE Transactions on Pattern Analysis and Machine Intelligence
  2025
DOI: 10.1109/TPAMI.2025.3594034
\\
  Human motion video generation has garnered significant research interest due
to its broad applications, enabling innovations such as photorealistic singing
heads or dynamic avatars that seamlessly dance to music. However, existing
surveys in this field focus on individual methods, lacking a comprehensive
overview of the entire generative process. This paper addresses this gap by
providing an in-depth survey of human motion video generation, encompassing
over ten sub-tasks, and detailing the five key phases of the generation
process: input, motion planning, motion video generation, refinement, and
output. Notably, this is the first survey that discusses the potential of large
language models in enhancing human motion video generation. Our survey reviews
the latest developments and technological trends in human motion video
generation across three primary modalities: vision, text, and audio. By
covering over two hundred papers, we offer a thorough overview of the field and
highlight milestone works that have driven significant technological
breakthroughs. Our goal for this survey is to unveil the prospects of human
motion video generation and serve as a valuable resource for advancing the
comprehensive applications of digital humans. A complete list of the models
examined in this survey is available in Our Repository
https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation.
\\ ( https://arxiv.org/abs/2509.03883 ,  4913kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03887
Date: Thu, 4 Sep 2025 05:06:47 GMT   (2427kb)

Title: OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction
Authors: Bu Jin, Songen Gu, Xiaotao Hu, Yupeng Zheng, Xiaoyang Guo, Qian Zhang,
  Xiaoxiao Long, Wei Yin
Categories: cs.CV
\\
  In this paper, we propose OccTENS, a generative occupancy world model that
enables controllable, high-fidelity long-term occupancy generation while
maintaining computational efficiency. Different from visual generation, the
occupancy world model must capture the fine-grained 3D geometry and dynamic
evolution of the 3D scenes, posing great challenges for the generative models.
Recent approaches based on autoregression (AR) have demonstrated the potential
to predict vehicle movement and future occupancy scenes simultaneously from
historical observations, but they typically suffer from \textbf{inefficiency},
\textbf{temporal degradation} in long-term generation and \textbf{lack of
controllability}. To holistically address these issues, we reformulate the
occupancy world model as a temporal next-scale prediction (TENS) task, which
decomposes the temporal sequence modeling problem into the modeling of spatial
scale-by-scale generation and temporal scene-by-scene prediction. With a
\textbf{TensFormer}, OccTENS can effectively manage the temporal causality and
spatial relationships of occupancy sequences in a flexible and scalable way. To
enhance the pose controllability, we further propose a holistic pose
aggregation strategy, which features a unified sequence modeling for occupancy
and ego-motion. Experiments show that OccTENS outperforms the state-of-the-art
method with both higher occupancy quality and faster inference time.
\\ ( https://arxiv.org/abs/2509.03887 ,  2427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03893
Date: Thu, 4 Sep 2025 05:39:16 GMT   (27504kb)

Title: Weakly-Supervised Learning of Dense Functional Correspondences
Authors: Stefan Stojanov, Linan Zhao, Yunzhi Zhang, Daniel L. K. Yamins, Jiajun
  Wu
Categories: cs.CV
Comments: Accepted at ICCV 2025. Project website:
  https://dense-functional-correspondence.github.io/
\\
  Establishing dense correspondences across image pairs is essential for tasks
such as shape reconstruction and robot manipulation. In the challenging setting
of matching across different categories, the function of an object, i.e., the
effect that an object can cause on other objects, can guide how correspondences
should be established. This is because object parts that enable specific
functions often share similarities in shape and appearance. We derive the
definition of dense functional correspondence based on this observation and
propose a weakly-supervised learning paradigm to tackle the prediction task.
The main insight behind our approach is that we can leverage vision-language
models to pseudo-label multi-view images to obtain functional parts. We then
integrate this with dense contrastive learning from pixel correspondences to
distill both functional and spatial knowledge into a new model that can
establish dense functional correspondence. Further, we curate synthetic and
real evaluation datasets as task benchmarks. Our results demonstrate the
advantages of our approach over baseline solutions consisting of off-the-shelf
self-supervised image representations and grounded vision language models.
\\ ( https://arxiv.org/abs/2509.03893 ,  27504kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03895
Date: Thu, 4 Sep 2025 05:42:02 GMT   (9576kb)

Title: Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of
  Vision-Language Model
Authors: Phuoc-Nguyen Bui, Khanh-Binh Nguyen, Hyunseung Choo
Categories: cs.CV
Comments: ICCV 2025 - LIMIT Workshop
\\
  Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learning
framework that enhances CLIP's adaptability via a dual attention mechanism. Our
design incorporates dataset-specific information through two components: the
Memory Attn-Adapter, which refines category embeddings using support examples,
and the Local-Global Attn-Adapter, which enriches image embeddings by
integrating local and global features. This architecture enables dynamic
adaptation from a few labeled samples without retraining the base model.
Attn-Adapter outperforms state-of-the-art methods in cross-category and
cross-dataset generalization, maintaining efficient inference and scaling
across CLIP backbones.
\\ ( https://arxiv.org/abs/2509.03895 ,  9576kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03897
Date: Thu, 4 Sep 2025 05:43:50 GMT   (392kb)

Title: SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation
Authors: Xiaofu Chen, Israfel Salazar, Yova Kementchedjhieva
Categories: cs.CV cs.CL
\\
  As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show strong correlation with human judgments,
but remain too expensive for iterative use during model development.
  We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS
metric tailored to long image captioning. SPECS modifies CLIP with a new
objective that emphasizes specificity: rewarding correct details and penalizing
incorrect ones. We show that SPECS matches the performance of open-source
LLM-based metrics in correlation to human judgments, while being far more
efficient. This makes it a practical alternative for iterative checkpoint
evaluation during image captioning model development.Our code can be found at
https://github.com/mbzuai-nlp/SPECS.
\\ ( https://arxiv.org/abs/2509.03897 ,  392kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03903
Date: Thu, 4 Sep 2025 05:53:58 GMT   (18996kb)

Title: A Generative Foundation Model for Chest Radiography
Authors: Yuanfeng Ji, Dan Lin, Xiyue Wang, Lu Zhang, Wenhui Zhou, Chongjian Ge,
  Ruihang Chu, Xiaoli Yang, Junhan Zhao, Junsong Chen, Xiangde Luo, Sen Yang,
  Jin Fang, Ping Luo, and Ruijiang Li
Categories: cs.CV
\\
  The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen', a generative vision-language foundation model that
introduces a unified framework for text-, mask-, and bounding box-guided
synthesis of chest radiographs. Built upon the latent diffusion transformer
architecture, ChexGen was pretrained on the largest curated chest X-ray dataset
to date, consisting of 960,000 radiograph-report pairs. ChexGen achieves
accurate synthesis of radiographs through expert evaluations and quantitative
metrics. We demonstrate the utility of ChexGen for training data augmentation
and supervised pretraining, which led to performance improvements across
disease classification, detection, and segmentation tasks using a small
fraction of training data. Further, our model enables the creation of diverse
patient cohorts that enhance model fairness by detecting and mitigating
demographic biases. Our study supports the transformative role of generative
foundation models in building more accurate, data-efficient, and equitable
medical AI systems.
\\ ( https://arxiv.org/abs/2509.03903 ,  18996kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03922
Date: Thu, 4 Sep 2025 06:15:41 GMT   (7059kb)

Title: LMVC: An End-to-End Learned Multiview Video Coding Framework
Authors: Xihua Sheng, Yingwen Zhang, Long Xu, Shiqi Wang
Categories: cs.CV
\\
  Multiview video is a key data source for volumetric video, enabling immersive
3D scene reconstruction but posing significant challenges in storage and
transmission due to its massive data volume. Recently, deep learning-based
end-to-end video coding has achieved great success, yet most focus on
single-view or stereo videos, leaving general multiview scenarios
underexplored. This paper proposes an end-to-end learned multiview video coding
(LMVC) framework that ensures random access and backward compatibility while
enhancing compression efficiency. Our key innovation lies in effectively
leveraging independent-view motion and content information to enhance
dependent-view compression. Specifically, to exploit the inter-view motion
correlation, we propose a feature-based inter-view motion vector prediction
method that conditions dependent-view motion encoding on decoded
independent-view motion features, along with an inter-view motion entropy model
that learns inter-view motion priors. To exploit the inter-view content
correlation, we propose a disparity-free inter-view context prediction module
that predicts inter-view contexts from decoded independent-view content
features, combined with an inter-view contextual entropy model that captures
inter-view context priors. Experimental results show that our proposed LMVC
framework outperforms the reference software of the traditional MV-HEVC
standard by a large margin, establishing a strong baseline for future research
in this field.
\\ ( https://arxiv.org/abs/2509.03922 ,  7059kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03938
Date: Thu, 4 Sep 2025 06:56:06 GMT   (8005kb)

Title: TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained
  Tubular Shapes
Authors: Minghui Zhang, Yaoyu Liu, Junyang Wu, Xin You, Hanxiao Zhang, Junjun
  He, Yun Gu
Categories: cs.CV
\\
  Medical tubular anatomical structures are inherently three-dimensional
conduits with lumens, enclosing walls, and complex branching topologies.
Accurate reconstruction of their geometry and topology is crucial for
applications such as bronchoscopic navigation and cerebral arterial
connectivity assessment. Existing methods often rely on voxel-wise overlap
measures, which fail to capture topological correctness and completeness.
Although topology-aware losses and persistent homology constraints have shown
promise, they are usually applied patch-wise and cannot guarantee global
preservation or correct geometric errors at inference. To address these
limitations, we propose a novel TopoSculpt, a framework for topological
refinement of 3D fine-grained tubular structures. TopoSculpt (i) adopts a
holistic whole-region modeling strategy to capture full spatial context, (ii)
first introduces a Topological Integrity Betti (TIB) constraint that jointly
enforces Betti number priors and global integrity, and (iii) employs a
curriculum refinement scheme with persistent homology to progressively correct
errors from coarse to fine scales. Extensive experiments on challenging
pulmonary airway and Circle of Willis datasets demonstrate substantial
improvements in both geometry and topology. For instance, $\beta_{0}$ errors
are reduced from 69.00 to 3.40 on the airway dataset and from 1.65 to 0.30 on
the CoW dataset, with Tree length detected and branch detected rates improving
by nearly 10\%. These results highlight the effectiveness of TopoSculpt in
correcting critical topological errors and advancing the high-fidelity modeling
of complex 3D tubular anatomy. The project homepage is available at:
https://github.com/Puzzled-Hui/TopoSculpt.
\\ ( https://arxiv.org/abs/2509.03938 ,  8005kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03950
Date: Thu, 4 Sep 2025 07:21:37 GMT   (755kb)

Title: Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer
  Learning in a U-Net Architecture
Authors: Alvaro Aranibar Roque, Helga Sebastian
Categories: cs.CV cs.AI
Comments: 10 page, 5 figures
\\
  Pneumothorax, the abnormal accumulation of air in the pleural space, can be
life-threatening if undetected. Chest X-rays are the first-line diagnostic
tool, but small cases may be subtle. We propose an automated deep-learning
pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax
regions. Trained on the SIIM-ACR dataset with data augmentation and a combined
binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and
Dice score of 0.8241 on the independent PTX-498 dataset. These results
demonstrate that the model can accurately localize pneumothoraces and support
radiologists.
\\ ( https://arxiv.org/abs/2509.03950 ,  755kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03951
Date: Thu, 4 Sep 2025 07:26:20 GMT   (1448kb)

Title: ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD
  Detection
Authors: Zhu Wenjie, Zhang Yabin, Xin Jin, Wenjun Zeng, Lei Zhang
Categories: cs.CV
\\
  The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
significantly degrades their near-OOD performance. To address these issues, we
propose shaping an Adaptive Negative Textual Space (ANTS) by leveraging the
understanding and reasoning capabilities of multimodal large language models
(MLLMs). Specifically, we identify images likely to be OOD samples as negative
images and prompt the MLLM to describe these images, generating expressive
negative sentences that precisely characterize the OOD distribution and enhance
far-OOD detection. For the near-OOD setting, where OOD samples resemble the
in-distribution (ID) subset, we first identify the subset of ID classes that
are visually similar to negative images and then leverage the reasoning
capability of MLLMs to generate visually similar negative labels tailored to
this subset, effectively reducing false negatives and improving near-OOD
detection. To balance these two types of negative textual spaces, we design an
adaptive weighted score that enables the method to handle different OOD task
settings (near-OOD and far-OOD) without relying on task-specific prior
knowledge, making it highly adaptable in open environments. On the ImageNet
benchmark, our ANTS significantly reduces the FPR95 by 4.2\%, establishing a
new state-of-the-art. Furthermore, our method is training-free and zero-shot,
enabling high scalability.
\\ ( https://arxiv.org/abs/2509.03951 ,  1448kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03961
Date: Thu, 4 Sep 2025 07:39:18 GMT   (1986kb)

Title: Multimodal Feature Fusion Network with Text Difference Enhancement for
  Remote Sensing Change Detection
Authors: Yijun Zhou, Yikui Zhai, Zilu Ying, Tingfeng Xian, Wenlve Zhou, Zhiheng
  Zhou, Xiaolin Tian, Xudong Jia, Hongsheng Zhang, C. L. Philip Chen
Categories: cs.CV cs.AI
\\
  Although deep learning has advanced remote sensing change detection (RSCD),
most methods rely solely on image modality, limiting feature representation,
change pattern modeling, and generalization especially under illumination and
noise disturbances. To address this, we propose MMChange, a multimodal RSCD
method that combines image and text modalities to enhance accuracy and
robustness. An Image Feature Refinement (IFR) module is introduced to highlight
key regions and suppress environmental noise. To overcome the semantic
limitations of image features, we employ a vision language model (VLM) to
generate semantic descriptions of bitemporal images. A Textual Difference
Enhancement (TDE) module then captures fine grained semantic shifts, guiding
the model toward meaningful changes. To bridge the heterogeneity between
modalities, we design an Image Text Feature Fusion (ITFF) module that enables
deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and
SYSUCD demonstrate that MMChange consistently surpasses state of the art
methods across multiple metrics, validating its effectiveness for multimodal
RSCD. Code is available at: https://github.com/yikuizhai/MMChange.
\\ ( https://arxiv.org/abs/2509.03961 ,  1986kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03973
Date: Thu, 4 Sep 2025 07:58:52 GMT   (7403kb)

Title: SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for
  Histopathology Whole Slide Image Classification
Authors: Yu Bai, Zitong Yu, Haowen Tian, Xijing Wang, Shuo Yan, Lin Wang,
  Honglin Li, Xitong Ling, Bo Zhang, Zheng Zhang, Wufan Wang, Hui Gao,
  Xiangyang Gong, Wendong Wang
Categories: cs.CV cs.AI
\\
  We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for
performing WSI classification. SAC-MIL consists of a positional encoding module
to encode position information and a SAC block to perform full instance
correlations. The positional encoding module utilizes the instance coordinates
within the slide to encode the spatial relationships instead of the instance
index in the input WSI sequence. The positional encoding module can also handle
the length extrapolation issue where the training and testing sequences have
different lengths. The SAC block is an MLP-based method that performs full
instance correlation in linear time complexity with respect to the sequence
length. Due to the simple structure of MLP, it is easy to deploy since it does
not require custom CUDA kernels, compared to Transformer-based methods for WSI
classification. SAC-MIL has achieved state-of-the-art performance on the
CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon
acceptance.
\\ ( https://arxiv.org/abs/2509.03973 ,  7403kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03975
Date: Thu, 4 Sep 2025 08:01:27 GMT   (592kb)

Title: Improving Vessel Segmentation with Multi-Task Learning and Auxiliary
  Data Available Only During Model Training
Authors: Daniel Sobotka, Alexander Herold, Matthias Perkonigg, Lucian Beer,
  Nina Bastati, Alina Sablatnig, Ahmed Ba-Ssalamah, Georg Langs
Categories: cs.CV
Journal-ref: Computerized Medical Imaging and Graphics Volume 114, June 2024,
  102369
DOI: 10.1016/j.compmedimag.2024.102369
\\
  Liver vessel segmentation in magnetic resonance imaging data is important for
the computational analysis of vascular remodelling, associated with a wide
spectrum of diffuse liver diseases. Existing approaches rely on contrast
enhanced imaging data, but the necessary dedicated imaging sequences are not
uniformly acquired. Images without contrast enhancement are acquired more
frequently, but vessel segmentation is challenging, and requires large-scale
annotated data. We propose a multi-task learning framework to segment vessels
in liver MRI without contrast. It exploits auxiliary contrast enhanced MRI data
available only during training to reduce the need for annotated training
examples. Our approach draws on paired native and contrast enhanced data with
and without vessel annotations for model training. Results show that auxiliary
data improves the accuracy of vessel segmentation, even if they are not
available during inference. The advantage is most pronounced if only few
annotations are available for training, since the feature representation
benefits from the shared task structure. A validation of this approach to
augment a model for brain tumor segmentation confirms its benefits across
different domains. An auxiliary informative imaging modality can augment expert
annotations even if it is only available during training.
\\ ( https://arxiv.org/abs/2509.03975 ,  592kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03986
Date: Thu, 4 Sep 2025 08:13:06 GMT   (6417kb)

Title: Promptception: How Sensitive Are Large Multimodal Models to Prompts?
Authors: Mohamed Insaf Ismithdeen, Muhammad Uzair Khattak, Salman Khan
Categories: cs.CV cs.AI cs.CL cs.LG
Comments: Accepted to EMNLP 2025
\\
  Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduce Promptception, a systematic framework
for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types,
spanning 15 categories and 6 supercategories, each targeting specific aspects
of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight
open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks:
MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit
greater sensitivity to prompt phrasing, reflecting tighter alignment with
instruction semantics, while open-source models are steadier but struggle with
nuanced and complex phrasing. Based on this analysis, we propose Prompting
Principles tailored to proprietary and open-source LMMs, enabling more robust
and fair model evaluation.
\\ ( https://arxiv.org/abs/2509.03986 ,  6417kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03999
Date: Thu, 4 Sep 2025 08:27:54 GMT   (516kb)

Title: SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy
  Representation
Authors: Han Huang, Han Sun, Ningzhong Liu, Huiyu Zhou, Jiaquan Shen
Categories: cs.CV
Comments: 14 pages, accepted by PRCV2025
\\
  Driven by autonomous driving's demands for precise 3D perception, 3D semantic
occupancy prediction has become a pivotal research topic. Unlike
bird's-eye-view (BEV) methods, which restrict scene representation to a 2D
plane, occupancy prediction leverages a complete 3D voxel grid to model spatial
structures in all dimensions, thereby capturing semantic variations along the
vertical axis. However, most existing approaches overlook height-axis
information when processing voxel features. And conventional SENet-style
channel attention assigns uniform weight across all height layers, limiting
their ability to emphasize features at different heights. To address these
limitations, we propose SliceSemOcc, a novel vertical slice based multimodal
framework for 3D semantic occupancy representation. Specifically, we extract
voxel features along the height-axis using both global and local vertical
slices. Then, a global local fusion module adaptively reconciles fine-grained
spatial details with holistic contextual information. Furthermore, we propose
the SEAttention3D module, which preserves height-wise resolution through
average pooling and assigns dynamic channel attention weights to each height
layer. Extensive experiments on nuScenes-SurroundOcc and nuScenes-OpenOccupancy
datasets verify that our method significantly enhances mean IoU, achieving
especially pronounced gains on most small-object categories. Detailed ablation
studies further validate the effectiveness of the proposed SliceSemOcc
framework.
\\ ( https://arxiv.org/abs/2509.03999 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04009
Date: Thu, 4 Sep 2025 08:40:40 GMT   (9916kb)

Title: Detecting Regional Spurious Correlations in Vision Transformers via
  Token Discarding
Authors: Solha Kang, Esla Timothy Anzaku, Wesley De Neve, Arnout Van Messem,
  Joris Vankerschaver, Francois Rameau, Utku Ozbulak
Categories: cs.CV cs.AI
\\
  Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues may
vary from simple color aberrations to small texts within the image. In
situations where these unintended signals align with the predictive task,
models can mistakenly link these features with the task and rely on them for
making predictions. This phenomenon is referred to as spurious correlations,
where patterns appear to be associated with the task but are actually
coincidental. As a result, detection and mitigation of spurious correlations
have become crucial tasks for building trustworthy, reliable, and generalizable
machine learning models. In this work, we present a novel method to detect
spurious correlations in vision transformers, a type of neural network
architecture that gained significant popularity in recent years. Using both
supervised and self-supervised trained models, we present large-scale
experiments on the ImageNet dataset demonstrating the ability of the proposed
method to identify spurious correlations. We also find that, even if the same
architecture is used, the training methodology has a significant impact on the
model's reliance on spurious correlations. Furthermore, we show that certain
classes in the ImageNet dataset contain spurious signals that are easily
detected by the models and discuss the underlying reasons for those spurious
signals. In light of our findings, we provide an exhaustive list of the
aforementioned images and call for caution in their use in future research
efforts. Lastly, we present a case study investigating spurious signals in
invasive breast mass classification, grounding our work in real-world
scenarios.
\\ ( https://arxiv.org/abs/2509.04009 ,  9916kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04023
Date: Thu, 4 Sep 2025 08:50:03 GMT   (906kb)

Title: Learning from Majority Label: A Novel Problem in Multi-class
  Multiple-Instance Learning
Authors: Shiku Kaito, Shinnosuke Matsuo, Daiki Suehiro, Ryoma Bise
Categories: cs.CV
Comments: 35 pages, 9 figures, Accepted in Pattern recognition
\\
  The paper proposes a novel multi-class Multiple-Instance Learning (MIL)
problem called Learning from Majority Label (LML). In LML, the majority class
of instances in a bag is assigned as the bag-level label. The goal of LML is to
train a classification model that estimates the class of each instance using
the majority label. This problem is valuable in a variety of applications,
including pathology image segmentation, political voting prediction, customer
sentiment analysis, and environmental monitoring. To solve LML, we propose a
Counting Network trained to produce bag-level majority labels, estimated by
counting the number of instances in each class. Furthermore, analysis
experiments on the characteristics of LML revealed that bags with a high
proportion of the majority class facilitate learning. Based on this result, we
developed a Majority Proportion Enhancement Module (MPEM) that increases the
proportion of the majority class by removing minority class instances within
the bags. Experiments demonstrate the superiority of the proposed method on
four datasets compared to conventional MIL methods. Moreover, ablation studies
confirmed the effectiveness of each module. The code is available at
\href{https://github.com/Shiku-Kaito/Learning-from-Majority-Label-A-Novel-Problem-in-Multi-class-Multiple-Instance-Learning}{here}.
\\ ( https://arxiv.org/abs/2509.04023 ,  906kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04043
Date: Thu, 4 Sep 2025 09:26:00 GMT   (906kb)

Title: Millisecond-Response Tracking and Gazing System for UAVs: A Domestic
  Solution Based on "Phytium + Cambricon"
Authors: Yuchen Zhu and Longxiang Yin and Kai Zhao
Categories: cs.CV
Comments: 16 pages,17 figures
\\
  In the frontier research and application of current video surveillance
technology, traditional camera systems exhibit significant limitations of
response delay exceeding 200 ms in dynamic scenarios due to the insufficient
deep feature extraction capability of automatic recognition algorithms and the
efficiency bottleneck of computing architectures, failing to meet the real-time
requirements in complex scenes. To address this issue, this study proposes a
heterogeneous computing architecture based on Phytium processors and Cambricon
accelerator cards, constructing a UAV tracking and gazing system with
millisecond-level response capability. At the hardware level, the system adopts
a collaborative computing architecture of Phytium FT-2000/4 processors and
MLU220 accelerator cards, enhancing computing power through multi-card
parallelism. At the software level, it innovatively integrates a lightweight
YOLOv5s detection network with a DeepSORT cascaded tracking algorithm, forming
a closed-loop control chain of "detection-tracking-feedback". Experimental
results demonstrate that the system achieves a stable single-frame
comprehensive processing delay of 50-100 ms in 1920*1080 resolution video
stream processing, with a multi-scale target recognition accuracy of over
98.5%, featuring both low latency and high precision. This study provides an
innovative solution for UAV monitoring and the application of domestic chips.
\\ ( https://arxiv.org/abs/2509.04043 ,  906kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04050
Date: Thu, 4 Sep 2025 09:29:25 GMT   (10545kb)

Title: A Re-ranking Method using K-nearest Weighted Fusion for Person
  Re-identification
Authors: Quang-Huy Che and Le-Chuong Nguyen and Gia-Nghia Tran and Dinh-Duy
  Phan and Vinh-Tiep Nguyen
Categories: cs.CV
Comments: Published in ICPRAM 2025, ISBN 978-989-758-730-6, ISSN 2184-4313
Journal-ref: Proceedings of the 14th International Conference on Pattern
  Recognition Applications and Methods - ICPRAM (2025) 79-90
DOI: 10.5220/0013176100003905
\\
  In person re-identification, re-ranking is a crucial step to enhance the
overall accuracy by refining the initial ranking of retrieved results. Previous
studies have mainly focused on features from single-view images, which can
cause view bias and issues like pose variation, viewpoint changes, and
occlusions. Using multi-view features to present a person can help reduce view
bias. In this work, we present an efficient re-ranking method that generates
multi-view features by aggregating neighbors' features using K-nearest Weighted
Fusion (KWF) method. Specifically, we hypothesize that features extracted from
re-identification models are highly similar when representing the same
identity. Thus, we select K neighboring features in an unsupervised manner to
generate multi-view features. Additionally, this study explores the weight
selection strategies during feature aggregation, allowing us to identify an
effective strategy. Our re-ranking approach does not require model fine-tuning
or extra annotations, making it applicable to large-scale datasets. We evaluate
our method on the person re-identification datasets Market1501, MSMT17, and
Occluded-DukeMTMC. The results show that our method significantly improves
Rank@1 and mAP when re-ranking the top M candidates from the initial ranking
results. Specifically, compared to the initial results, our re-ranking method
achieves improvements of 9.8%/22.0% in Rank@1 on the challenging datasets:
MSMT17 and Occluded-DukeMTMC, respectively. Furthermore, our approach
demonstrates substantial enhancements in computational efficiency compared to
other re-ranking methods.
\\ ( https://arxiv.org/abs/2509.04050 ,  10545kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04086
Date: Thu, 4 Sep 2025 10:32:40 GMT   (13241kb)

Title: TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale
  Category-Aware Temporal Graph
Authors: Yaru Chen, Faegheh Sardari, Peiliang Zhang, Ruohao Guo, Yang Xiang,
  Zhenbo Li, Wenwu Wang
Categories: cs.CV cs.MM
\\
  Audio-Visual Video Parsing (AVVP) task aims to identify event categories and
their occurrence times in a given video with weakly supervised labels. Existing
methods typically fall into two categories: (i) designing enhanced
architectures based on attention mechanism for better temporal modeling, and
(ii) generating richer pseudo-labels to compensate for the absence of
frame-level annotations. However, the first type methods treat noisy
segment-level pseudo labels as reliable supervision and the second type methods
let indiscriminate attention spread them across all frames, the initial errors
are repeatedly amplified during training. To address this issue, we propose a
method that combines the Bi-Directional Text Fusion (BiT) module and
Category-Aware Temporal Graph (CATS) module. Specifically, we integrate the
strengths and complementarity of the two previous research directions. We first
perform semantic injection and dynamic calibration on audio and visual modality
features through the BiT module, to locate and purify cleaner and richer
semantic cues. Then, we leverage the CATS module for semantic propagation and
connection to enable precise semantic information dissemination across time.
Experimental results demonstrate that our proposed method achieves
state-of-the-art (SOTA) performance in multiple key indicators on two benchmark
datasets, LLP and UnAV-100.
\\ ( https://arxiv.org/abs/2509.04086 ,  13241kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04092
Date: Thu, 4 Sep 2025 10:48:25 GMT   (17804kb)

Title: TriLiteNet: Lightweight Model for Multi-Task Visual Perception
Authors: Quang-Huy Che and Duc-Khai Lam
Categories: cs.CV
Journal-ref: IEEE Access 13 (2025) 50152-50166
DOI: 10.1109/ACCESS.2025.3552088
\\
  Efficient perception models are essential for Advanced Driver Assistance
Systems (ADAS), as these applications require rapid processing and response to
ensure safety and effectiveness in real-world environments. To address the
real-time execution needs of such perception models, this study introduces the
TriLiteNet model. This model can simultaneously manage multiple tasks related
to panoramic driving perception. TriLiteNet is designed to optimize performance
while maintaining low computational costs. Experimental results on the BDD100k
dataset demonstrate that the model achieves competitive performance across
three key tasks: vehicle detection, drivable area segmentation, and lane line
segmentation. Specifically, the TriLiteNet_{base} demonstrated a recall of
85.6% for vehicle detection, a mean Intersection over Union (mIoU) of 92.4% for
drivable area segmentation, and an Acc of 82.3% for lane line segmentation with
only 2.35M parameters and a computational cost of 7.72 GFLOPs. Our proposed
model includes a tiny configuration with just 0.14M parameters, which provides
a multi-task solution with minimal computational demand. Evaluated for latency
and power consumption on embedded devices, TriLiteNet in both configurations
shows low latency and reasonable power during inference. By balancing
performance, computational efficiency, and scalability, TriLiteNet offers a
practical and deployable solution for real-world autonomous driving
applications. Code is available at https://github.com/chequanghuy/TriLiteNet.
\\ ( https://arxiv.org/abs/2509.04092 ,  17804kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04117
Date: Thu, 4 Sep 2025 11:30:29 GMT   (6630kb)

Title: DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset
Authors: Mustafa Sakhai, Kaung Sithu, Min Khant Soe Oke, Maciej Wielgosz
Categories: cs.CV
Comments: 12 pages, 8 figures, 3 tables; dataset descriptor paper introducing
  DVS-PedX (synthetic-and-real event-based pedestrian dataset with baselines)
  External URL: https://doi.org/10.5281/zenodo.17030898
\\
  Event cameras like Dynamic Vision Sensors (DVS) report micro-timed brightness
changes instead of full frames, offering low latency, high dynamic range, and
motion robustness. DVS-PedX (Dynamic Vision Sensor Pedestrian eXploration) is a
neuromorphic dataset designed for pedestrian detection and crossing-intention
analysis in normal and adverse weather conditions across two complementary
sources: (1) synthetic event streams generated in the CARLA simulator for
controlled "approach-cross" scenes under varied weather and lighting; and (2)
real-world JAAD dash-cam videos converted to event streams using the v2e tool,
preserving natural behaviors and backgrounds. Each sequence includes paired RGB
frames, per-frame DVS "event frames" (33 ms accumulations), and frame-level
labels (crossing vs. not crossing). We also provide raw AEDAT 2.0/AEDAT 4.0
event files and AVI DVS video files and metadata for flexible re-processing.
Baseline spiking neural networks (SNNs) using SpikingJelly illustrate dataset
usability and reveal a sim-to-real gap, motivating domain adaptation and
multimodal fusion. DVS-PedX aims to accelerate research in event-based
pedestrian safety, intention prediction, and neuromorphic perception.
\\ ( https://arxiv.org/abs/2509.04117 ,  6630kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04123
Date: Thu, 4 Sep 2025 11:37:06 GMT   (176793kb)

Title: TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering
Authors: Ayan Banerjee, Josep Llad\'os, Umapada Pal, Anjan Dutta
Categories: cs.CV
\\
  Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response, we
introduce TaleDiffusion, a novel framework for generating multi-character
stories with an iterative process, maintaining character consistency, and
accurate dialogue assignment via postprocessing. Given a story, we use a
pre-trained LLM to generate per-frame descriptions, character details, and
dialogues via in-context learning, followed by a bounded attention-based
per-box mask technique to control character interactions and minimize
artifacts. We then apply an identity-consistent self-attention mechanism to
ensure character consistency across frames and region-aware cross-attention for
precise object placement. Dialogues are also rendered as bubbles and assigned
to characters via CLIPSeg. Experimental results demonstrate that TaleDiffusion
outperforms existing methods in consistency, noise reduction, and dialogue
rendering.
\\ ( https://arxiv.org/abs/2509.04123 ,  176793kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04126
Date: Thu, 4 Sep 2025 11:44:28 GMT   (43503kb)

Title: MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image
  Generation
Authors: Yuan Zhao, Liu Lin
Categories: cs.CV cs.AI
\\
  Text-to-image diffusion models have achieved remarkable image quality, but
they still struggle with complex, multiele ment prompts, and limited stylistic
diversity. To address these limitations, we propose a Multi-Expert Planning and
Gen eration Framework (MEPG) that synergistically integrates position- and
style-aware large language models (LLMs) with spatial-semantic expert modules.
The framework comprises two core components: (1) a Position-Style-Aware (PSA)
module that utilizes a supervised fine-tuned LLM to decom pose input prompts
into precise spatial coordinates and style encoded semantic instructions; and
(2) a Multi-Expert Dif fusion (MED) module that implements cross-region genera
tion through dynamic expert routing across both local regions and global areas.
During the generation process for each lo cal region, specialized models (e.g.,
realism experts, styliza tion specialists) are selectively activated for each
spatial par tition via attention-based gating mechanisms. The architec ture
supports lightweight integration and replacement of ex pert models, providing
strong extensibility. Additionally, an interactive interface enables real-time
spatial layout editing and per-region style selection from a portfolio of
experts. Ex periments show that MEPG significantly outperforms base line models
with the same backbone in both image quality
  and style diversity.
\\ ( https://arxiv.org/abs/2509.04126 ,  43503kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04150
Date: Thu, 4 Sep 2025 12:23:59 GMT   (2252kb)

Title: Revisiting Simple Baselines for In-The-Wild Deepfake Detection
Authors: Orlando Castaneda, Kevin So-Tang, Kshitij Gurung
Categories: cs.CV
\\
  The widespread adoption of synthetic media demands accessible deepfake
detectors and realistic benchmarks. While most existing research evaluates
deepfake detectors on highly controlled datasets, we focus on the recently
released "in-the-wild" benchmark, Deepfake-Eval-2024. Initial reporting on
Deepfake-Eval-2024 showed that three finetuned open-source models achieve
accuracies between 61% and 69%, significantly lagging behind the leading
commercial deepfake detector with 82% accuracy. Our work revisits one of these
baseline approaches, originally introduced by Ojha et al., which adapts
standard pretrained vision backbones to produce generalizable deepfake
detectors. We demonstrate that with better-tuned hyperparameters, this simple
approach actually yields much higher performance -- 81% accuracy on
Deepfake-Eval-2024 -- surpassing the previously reported accuracy of this
baseline approach by 18% and competing with commercial deepfake detectors. We
discuss tradeoffs in accuracy, computational costs, and interpretability,
focusing on how practical these deepfake detectors might be when deployed in
real-world settings. Our code can be found at
https://github.com/Deepfake-Detection-KKO/deepfake-detection.
\\ ( https://arxiv.org/abs/2509.04150 ,  2252kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04156
Date: Thu, 4 Sep 2025 12:32:04 GMT   (1889kb)

Title: YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind
  Turbine Components
Authors: Serhii Svystun and Pavlo Radiuk and Oleksandr Melnychenko and Oleg
  Savenko and Anatoliy Sachenko
Categories: cs.CV cs.AI cs.RO
Comments: The 13th IEEE International Conference on Intelligent Data
  Acquisition and Advanced Computing Systems: Technology and Applications, 4-6
  September, 2025, Gliwice, Poland
MSC-class: 68T07, 68T45, 68U10, 68T40
ACM-class: I.2.10; I.4.8; I.5.4; I.2.9
\\
  Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up
new opportunities for monitoring wind power plants, including blades, towers,
and other critical components. However, reliable defect detection requires
high-resolution data and efficient methods to process multispectral imagery. In
this research, we aim to enhance defect detection accuracy through the
development of an ensemble of YOLO-based deep learning models that integrate
both visible and thermal channels. We propose an ensemble approach that
integrates a general-purpose YOLOv8 model with a specialized thermal model,
using a sophisticated bounding box fusion algorithm to combine their
predictions. Our experiments show this approach achieves a mean Average
Precision (mAP@.5) of 0.93 and an F1-score of 0.90, outperforming a standalone
YOLOv8 model, which scored an mAP@.5 of 0.91. These findings demonstrate that
combining multiple YOLO architectures with fused multispectral data provides a
more reliable solution, improving the detection of both visual and thermal
defects.
\\ ( https://arxiv.org/abs/2509.04156 ,  1889kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04180
Date: Thu, 4 Sep 2025 12:54:32 GMT   (2090kb)

Title: VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer
  Vision
Authors: Safouane El Ghazouali, Umberto Michelucci
Categories: cs.CV cs.AI
\\
  AI models rely on annotated data to learn pattern and perform prediction.
Annotation is usually a labor-intensive step that require associating labels
ranging from a simple classification label to more complex tasks such as object
detection, oriented bounding box estimation, and instance segmentation.
Traditional tools often require extensive manual input, limiting scalability
for large datasets. To address this, we introduce VisioFirm, an open-source web
application designed to streamline image labeling through AI-assisted
automation. VisioFirm integrates state-of-the-art foundation models into an
interface with a filtering pipeline to reduce human-in-the-loop efforts. This
hybrid approach employs CLIP combined with pre-trained detectors like
Ultralytics models for common classes and zero-shot models such as Grounding
DINO for custom labels, generating initial annotations with low-confidence
thresholding to maximize recall. Through this framework, when tested on
COCO-type of classes, initial prediction have been proven to be mostly correct
though the users can refine these via interactive tools supporting bounding
boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has
on-the-fly segmentation powered by Segment Anything accelerated through WebGPU
for browser-side efficiency. The tool supports multiple export formats (YOLO,
COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing
accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort
through benchmarks on diverse datasets, while maintaining high annotation
accuracy via clustering of connected CLIP-based disambiguate components and
IoU-graph for redundant detection suppression. VisioFirm can be accessed from
\href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.
\\ ( https://arxiv.org/abs/2509.04180 ,  2090kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04193
Date: Thu, 4 Sep 2025 13:15:16 GMT   (6004kb)

Title: DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval
Authors: Ruohong Yang, Peng Hu, Yunfan Li, Xi Peng
Categories: cs.CV cs.LG
\\
  Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of
the same category across diverse domains without relying on annotations.
Existing UCIR methods, which align cross-domain features for the entire image,
often struggle with the domain gap, as the object features critical for
retrieval are frequently entangled with domain-specific styles. To address this
challenge, we propose DUDE, a novel UCIR method building upon feature
disentanglement. In brief, DUDE leverages a text-to-image generative model to
disentangle object features from domain-specific styles, thus facilitating
semantical image retrieval. To further achieve reliable alignment of the
disentangled object features, DUDE aligns mutual neighbors from within domains
to across domains in a progressive manner. Extensive experiments demonstrate
that DUDE achieves state-of-the-art performance across three benchmark datasets
over 13 domains. The code will be released.
\\ ( https://arxiv.org/abs/2509.04193 ,  6004kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04243
Date: Thu, 4 Sep 2025 14:17:01 GMT   (13304kb)

Title: Learning Active Perception via Self-Evolving Preference Optimization for
  GUI Grounding
Authors: Wanfu Wang, Qipeng Huang, Guangquan Xue, Xiaobo Liang, Juntao Li
Categories: cs.CV cs.AI
\\
  Vision Language Models (VLMs) have recently achieved significant progress in
bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model
introduced a zoom-in search strategy that effectively elicits active perception
capabilities in VLMs, improving downstream task performance. However, enabling
VLMs to reason effectively over appropriate image regions remains a core
challenge in GUI grounding, particularly under high-resolution inputs and
complex multi-element visual interactions. In this work, we propose LASER, a
self-evolving framework that progressively endows VLMs with multi-step
perception capabilities, enabling precise coordinate prediction. Specifically,
our approach integrate Monte Carlo quality estimation with
Intersection-over-Union (IoU)-based region quality evaluation to jointly
encourage both accuracy and diversity in constructing high-quality preference
data. This combination explicitly guides the model to focus on
instruction-relevant key regions while adaptively allocating reasoning steps
based on task complexity. Comprehensive experiments on the ScreenSpot Pro and
ScreenSpot-v2 benchmarks demonstrate consistent performance gains, validating
the effectiveness of our method. Furthermore, when fine-tuned on GTA1-7B, LASER
achieves a score of 55.7 on the ScreenSpot-Pro benchmark, establishing a new
state-of-the-art (SoTA) among 7B-scale models.
\\ ( https://arxiv.org/abs/2509.04243 ,  13304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04268
Date: Thu, 4 Sep 2025 14:44:18 GMT   (10727kb)

Title: Differential Morphological Profile Neural Networks for Semantic
  Segmentation
Authors: David Huangal, J. Alex Hurt
Categories: cs.CV
Comments: 14 pages, 7 figures
\\
  Semantic segmentation of overhead remote sensing imagery enables applications
in mapping, urban planning, and disaster response. State-of-the-art
segmentation networks are typically developed and tuned on ground-perspective
photographs and do not directly address remote sensing challenges such as
extreme scale variation, foreground-background imbalance, and large image
sizes. We explore the incorporation of the differential morphological profile
(DMP), a multi-scale shape extraction method based on grayscale morphology,
into modern segmentation networks. Prior studies have shown that the DMP can
provide critical shape information to Deep Neural Networks to enable superior
detection and classification performance in overhead imagery. In this work, we
extend prior DMPNet work beyond classification and object detection by
integrating DMP features into three state-of-the-art convolutional and
transformer semantic segmentation architectures. We utilize both direct input,
which adapts the input stem of feature extraction architectures to accept DMP
channels, and hybrid architectures, a dual-stream design that fuses RGB and DMP
encoders. Using the iSAID benchmark dataset, we evaluate a variety of DMP
differentials and structuring element shapes to more effectively provide shape
information to the model. Our results show that while non-DMP models generally
outperform the direct-input variants, hybrid DMP consistently outperforms
direct-input and is capable of surpassing a non-DMP model on mIoU, F1, and
Recall.
\\ ( https://arxiv.org/abs/2509.04268 ,  10727kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04269
Date: Thu, 4 Sep 2025 14:45:50 GMT   (15480kb)

Title: TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D
  Diffusion Models
Authors: Yuxin Gong, Se-in Jang, Wei Shao, Yi Su, Kuang Gong (for the
  Alzheimer's Disease Neuroimaging Initiative (ADNI))
Categories: cs.CV
Comments: 9 pages, 4 figures, submitted to IEEE Transactions on Radiation and
  Plasma Medical Sciences
\\
  Accurate quantification of tau pathology via tau positron emission tomography
(PET) scan is crucial for diagnosing and monitoring Alzheimer's disease (AD).
However, the high cost and limited availability of tau PET restrict its
widespread use. In contrast, structural magnetic resonance imaging (MRI) and
plasma-based biomarkers provide non-invasive and widely available complementary
information related to brain anatomy and disease progression. In this work, we
propose a text-guided 3D diffusion model for 3D tau PET image synthesis,
leveraging multimodal conditions from both structural MRI and plasma
measurement. Specifically, the textual prompt is from the plasma p-tau217
measurement, which is a key indicator of AD progression, while MRI provides
anatomical structure constraints. The proposed framework is trained and
evaluated using clinical AV1451 tau PET data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. Experimental results demonstrate that
our approach can generate realistic, clinically meaningful 3D tau PET across a
range of disease stages. The proposed framework can help perform tau PET data
augmentation under different settings, provide a non-invasive, cost-effective
alternative for visualizing tau pathology, and support the simulation of
disease progression under varying plasma biomarker levels and cognitive
conditions.
\\ ( https://arxiv.org/abs/2509.04269 ,  15480kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04273
Date: Thu, 4 Sep 2025 14:47:25 GMT   (5339kb)

Title: Dual-Scale Volume Priors with Wasserstein-Based Consistency for
  Semi-Supervised Medical Image Segmentation
Authors: Junying Meng and Gangxuan Zhou and Jun Liu and Weihong Guo
Categories: cs.CV
\\
  Despite signi cant progress in semi-supervised medical image segmentation,
most existing segmentation networks overlook e ective methodological guidance
for feature extraction and important prior information from
  datasets. In this paper, we develop a semi-supervised medical image
segmentation framework that e ectively integrates spatial regularization
methods and volume priors. Speci cally, our approach integrates a strong
explicit volume prior at the image scale and Threshold Dynamics spatial
regularization, both derived from variational models, into the backbone
segmentation network. The target region volumes for each unlabeled image are
estimated by a regression network, which e ectively regularizes the backbone
segmentation network through an image-scale Wasserstein distance constraint,
ensuring that the class ratios in the segmentation results for each unlabeled
image match those predicted by the regression network. Additionally, we design
a dataset-scale Wasserstein distance loss function based on a weak implicit
volume prior, which enforces that the volume distribution predicted for the
unlabeled dataset is similar to that of labeled dataset. Experimental results
on the 2017 ACDC dataset, PROMISE12 dataset, and thigh muscle MR image dataset
show the superiority of the proposed method.
\\ ( https://arxiv.org/abs/2509.04273 ,  5339kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04276
Date: Thu, 4 Sep 2025 14:51:03 GMT   (12386kb)

Title: PAOLI: Pose-free Articulated Object Learning from Sparse-view Images
Authors: Jianning Deng, Kartic Subr, Hakan Bilen
Categories: cs.CV
\\
  We present a novel self-supervised framework for learning articulated object
representations from sparse-view, unposed images. Unlike prior methods that
require dense multi-view observations and ground-truth camera poses, our
approach operates with as few as four views per articulation and no camera
supervision. To address the inherent challenges, we first reconstruct each
articulation independently using recent advances in sparse-view 3D
reconstruction, then learn a deformation field that establishes dense
correspondences across poses. A progressive disentanglement strategy further
separates static from moving parts, enabling robust separation of camera and
object motion. Finally, we jointly optimize geometry, appearance, and
kinematics with a self-supervised loss that enforces cross-view and cross-pose
consistency. Experiments on the standard benchmark and real-world examples
demonstrate that our method produces accurate and detailed articulated object
representations under significantly weaker input assumptions than existing
approaches.
\\ ( https://arxiv.org/abs/2509.04276 ,  12386kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04298
Date: Thu, 4 Sep 2025 15:13:29 GMT   (864kb)

Title: Noisy Label Refinement with Semantically Reliable Synthetic Images
Authors: Yingxuan Li, Jiafeng Mao, Yusuke Matsui
Categories: cs.CV
Comments: Accepted to ICIP2025
\\
  Semantic noise in image classification datasets, where visually similar
categories are frequently mislabeled, poses a significant challenge to
conventional supervised learning approaches. In this paper, we explore the
potential of using synthetic images generated by advanced text-to-image models
to address this issue. Although these high-quality synthetic images come with
reliable labels, their direct application in training is limited by domain gaps
and diversity constraints. Unlike conventional approaches, we propose a novel
method that leverages synthetic images as reliable reference points to identify
and correct mislabeled samples in noisy datasets. Extensive experiments across
multiple benchmark datasets show that our approach significantly improves
classification accuracy under various noise conditions, especially in
challenging scenarios with semantic label noise. Additionally, since our method
is orthogonal to existing noise-robust learning techniques, when combined with
state-of-the-art noise-robust training methods, it achieves superior
performance, improving accuracy by 30% on CIFAR-10 and by 11% on CIFAR-100
under 70% semantic noise, and by 24% on ImageNet-100 under real-world noise
conditions.
\\ ( https://arxiv.org/abs/2509.04298 ,  864kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04326
Date: Thu, 4 Sep 2025 15:44:37 GMT   (1817kb)

Title: Efficient Odd-One-Out Anomaly Detection
Authors: Silvio Chito, Paolo Rabino, Tatiana Tommasi
Categories: cs.CV
Comments: Accepted at ICIAP 2025
\\
  The recently introduced odd-one-out anomaly detection task involves
identifying the odd-looking instances within a multi-object scene. This problem
presents several challenges for modern deep learning models, demanding spatial
reasoning across multiple views and relational reasoning to understand context
and generalize across varying object categories and layouts. We argue that
these challenges must be addressed with efficiency in mind. To this end, we
propose a DINO-based model that reduces the number of parameters by one third
and shortens training time by a factor of three compared to the current
state-of-the-art, while maintaining competitive performance. Our experimental
evaluation also introduces a Multimodal Large Language Model baseline,
providing insights into its current limitations in structured visual reasoning
tasks. The project page can be found at
https://silviochito.github.io/EfficientOddOneOut/
\\ ( https://arxiv.org/abs/2509.04326 ,  1817kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04334
Date: Thu, 4 Sep 2025 15:52:04 GMT   (14391kb)

Title: GeoArena: An Open Platform for Benchmarking Large Vision-language Models
  on WorldWide Image Geolocalization
Authors: Pengyue Jia, Yingyi Zhang, Xiangyu Zhao, Yixuan Li
Categories: cs.CV
\\
  Image geolocalization aims to predict the geographic location of images
captured anywhere on Earth, but its global nature presents significant
challenges. Current evaluation methodologies suffer from two major limitations.
First, data leakage: advanced approaches often rely on large vision-language
models (LVLMs) to predict image locations, yet these models are frequently
pretrained on the test datasets, compromising the accuracy of evaluating a
model's actual geolocalization capability. Second, existing metrics primarily
rely on exact geographic coordinates to assess predictions, which not only
neglects the reasoning process but also raises privacy concerns when user-level
location data is required. To address these issues, we propose GeoArena, a
first open platform for evaluating LVLMs on worldwide image geolocalization
tasks, offering true in-the-wild and human-centered benchmarking. GeoArena
enables users to upload in-the-wild images for a more diverse evaluation
corpus, and it leverages pairwise human judgments to determine which model
output better aligns with human expectations. Our platform has been deployed
online for two months, during which we collected over thousands voting records.
Based on this data, we conduct a detailed analysis and establish a leaderboard
of different LVLMs on the image geolocalization task.
\\ ( https://arxiv.org/abs/2509.04334 ,  14391kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04338
Date: Thu, 4 Sep 2025 15:58:50 GMT   (9909kb)

Title: From Editor to Dense Geometry Estimator
Authors: JiYuan Wang, Chunyu Lin, Lei Sun, Rongying Liu, Lang Nie, Mingxing Li,
  Kang Liao, Xiangxiang Chu, Yao Zhao
Categories: cs.CV cs.AI
Comments: 20pages
\\
  Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-tuning.
  Motivated by this, we conduct a systematic analysis of the fine-tuning
behaviors of both editors and generators for dense geometry estimation. Our
findings show that editing models possess inherent structural priors, which
enable them to converge more stably by ``refining" their innate features, and
ultimately achieve higher performance than their generative counterparts.
  Based on these findings, we introduce \textbf{FE2E}, a framework that
pioneeringly adapts an advanced editing model based on Diffusion Transformer
(DiT) architecture for dense geometry prediction. Specifically, to tailor the
editor for this deterministic task, we reformulate the editor's original flow
matching loss into the ``consistent velocity" training objective. And we use
logarithmic quantization to resolve the precision conflict between the editor's
native BFloat16 format and the high precision demand of our tasks.
Additionally, we leverage the DiT's global attention for a cost-free joint
estimation of depth and normals in a single forward pass, enabling their
supervisory signals to mutually enhance each other.
  Without scaling up the training data, FE2E achieves impressive performance
improvements in zero-shot monocular depth and normal estimation across multiple
datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset
and outperforms the DepthAnything series, which is trained on 100$\times$ data.
The project page can be accessed \href{https://amap-ml.github.io/FE2E/}{here}.
\\ ( https://arxiv.org/abs/2509.04338 ,  9909kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04344
Date: Thu, 4 Sep 2025 16:03:14 GMT   (2435kb)

Title: MICACL: Multi-Instance Category-Aware Contrastive Learning for
  Long-Tailed Dynamic Facial Expression Recognition
Authors: Feng-Qi Cui, Zhen Lin, Xinlong Rao, Anyang Tong, Shiyao Li, Fei Wang,
  Changlin Chen, Bin Liu
Categories: cs.CV
Comments: Accepted by IEEE ISPA2025
\\
  Dynamic facial expression recognition (DFER) faces significant challenges due
to long-tailed category distributions and complexity of spatio-temporal feature
modeling. While existing deep learning-based methods have improved DFER
performance, they often fail to address these issues, resulting in severe model
induction bias. To overcome these limitations, we propose a novel
multi-instance learning framework called MICACL, which integrates
spatio-temporal dependency modeling and long-tailed contrastive learning
optimization. Specifically, we design the Graph-Enhanced Instance Interaction
Module (GEIIM) to capture intricate spatio-temporal between adjacent instances
relationships through adaptive adjacency matrices and multiscale convolutions.
To enhance instance-level feature aggregation, we develop the Weighted Instance
Aggregation Network (WIAN), which dynamically assigns weights based on instance
importance. Furthermore, we introduce a Multiscale Category-aware Contrastive
Learning (MCCL) strategy to balance training between major and minor
categories. Extensive experiments on in-the-wild datasets (i.e., DFEW and
FERV39k) demonstrate that MICACL achieves state-of-the-art performance with
superior robustness and generalization.
\\ ( https://arxiv.org/abs/2509.04344 ,  2435kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04370
Date: Thu, 4 Sep 2025 16:27:53 GMT   (437kb)

Title: Stitching the Story: Creating Panoramic Incident Summaries from
  Body-Worn Footage
Authors: Dor Cohen, Inga Efrosman, Yehudit Aperstein, Alexander Apartsin
Categories: cs.CV
Comments: 5 pages, 3 figures
\\
  First responders widely adopt body-worn cameras to document incident scenes
and support post-event analysis. However, reviewing lengthy video footage is
impractical in time-critical situations. Effective situational awareness
demands a concise visual summary that can be quickly interpreted. This work
presents a computer vision pipeline that transforms body-camera footage into
informative panoramic images summarizing the incident scene. Our method
leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate
camera trajectories and reconstruct the spatial layout of the environment. Key
viewpoints are identified by clustering camera poses along the trajectory, and
representative frames from each cluster are selected. These frames are fused
into spatially coherent panoramic images using multi-frame stitching
techniques. The resulting summaries enable rapid understanding of complex
environments and facilitate efficient decision-making and incident review.
\\ ( https://arxiv.org/abs/2509.04370 ,  437kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04376
Date: Thu, 4 Sep 2025 16:34:46 GMT   (1425kb)

Title: AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval
  for Text-Based Person Anomaly Search
Authors: Hao Ju, Hu Zhang, Zhedong Zheng
Categories: cs.CV
\\
  With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
alignment between textual anomalies and visual behaviors, and (2) anomaly
recognition under sparse real-world samples. While Large Multi-modal Models
(LMMs) excel in multi-modal understanding, their potential for fine-grained
anomaly retrieval remains underexplored, hindered by: (1) a domain gap between
generative knowledge and discriminative retrieval, and (2) the absence of
efficient adaptation strategies for deployment. In this work, we propose
AnomalyLMM, the first framework that harnesses LMMs for text-based person
anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline
integrating LMMs to bridge generative world knowledge with retrieval-centric
anomaly detection; (2) A training-free adaptation cookbook featuring masked
cross-modal prompting, behavioral saliency prediction, and knowledge-aware
re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study
to explore LMMs for this task, we conduct a rigorous evaluation on the PAB
dataset, the only publicly available benchmark for text-based person anomaly
search, with its curated real-world anomalies covering diverse scenarios (e.g.,
falling, collision, and being hit). Experiments show the effectiveness of the
proposed method, surpassing the competitive baseline by +0.96% Recall@1
accuracy. Notably, our method reveals interpretable alignment between textual
anomalies and visual behaviors, validated via qualitative analysis. Our code
and models will be released for future research.
\\ ( https://arxiv.org/abs/2509.04376 ,  1425kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04378
Date: Thu, 4 Sep 2025 16:40:15 GMT   (2854kb)

Title: Aesthetic Image Captioning with Saliency Enhanced MLLMs
Authors: Yilin Tao, Jiashui Huang, Huaze Xu, and Ling Shao
Categories: cs.CV
\\
  Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
image aesthetics research that integrates both visual and textual modalities.
However, most existing studies on image aesthetics primarily focus on
predicting aesthetic ratings and have shown limited application in AIC.
Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods
without specifically adapting MLLMs to focus on target aesthetic content. To
address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal
Large Language Model (ASE-MLLM), an end-to-end framework that explicitly
incorporates aesthetic saliency into MLLMs. Within this framework, we introduce
the Image Aesthetic Saliency Module (IASM), which efficiently and effectively
extracts aesthetic saliency features from images. Additionally, we design
IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency
features with original image features via a cross-attention mechanism. To the
best of our knowledge, ASE-MLLM is the first framework to integrate image
aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments
demonstrated that our approach significantly outperformed traditional methods
and generic MLLMs on current mainstream AIC benchmarks, achieving
state-of-the-art (SOTA) performance.
\\ ( https://arxiv.org/abs/2509.04378 ,  2854kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04379
Date: Thu, 4 Sep 2025 16:40:44 GMT   (4408kb)

Title: SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer
Authors: Jimin Xu, Bosheng Qin, Tao Jin, Zhou Zhao, Zhenhui Ye, Jun Yu, Fei Wu
Categories: cs.CV cs.AI
\\
  Recent advancements in neural representations, such as Neural Radiance Fields
and 3D Gaussian Splatting, have increased interest in applying style transfer
to 3D scenes. While existing methods can transfer style patterns onto
3D-consistent neural representations, they struggle to effectively extract and
transfer high-level style semantics from the reference style image.
Additionally, the stylized results often lack structural clarity and
separation, making it difficult to distinguish between different instances or
objects within the 3D scene. To address these limitations, we propose a novel
3D style transfer pipeline that effectively integrates prior knowledge from
pretrained 2D diffusion models. Our pipeline consists of two key stages: First,
we leverage diffusion priors to generate stylized renderings of key viewpoints.
Then, we transfer the stylized key views onto the 3D representation. This
process incorporates two innovative designs. The first is cross-view style
alignment, which inserts cross-view attention into the last upsampling block of
the UNet, allowing feature interactions across multiple key views. This ensures
that the diffusion model generates stylized key views that maintain both style
fidelity and instance-level consistency. The second is instance-level style
transfer, which effectively leverages instance-level consistency across
stylized key views and transfers it onto the 3D representation. This results in
a more structured, visually coherent, and artistically enriched stylization.
Extensive qualitative and quantitative experiments demonstrate that our 3D
style transfer pipeline significantly outperforms state-of-the-art methods
across a wide range of scenes, from forward-facing to challenging 360-degree
environments. Visit our project page https://jm-xu.github.io/SSGaussian for
immersive visualization.
\\ ( https://arxiv.org/abs/2509.04379 ,  4408kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04402
Date: Thu, 4 Sep 2025 17:13:19 GMT   (31135kb)

Title: Learning neural representations for X-ray ptychography reconstruction
  with unknown probes
Authors: Tingyou Li, Zixin Xu, Zirui Gao, Hanfei Yan, Xiaojing Huang, Jizhou Li
Categories: cs.CV
\\
  X-ray ptychography provides exceptional nanoscale resolution and is widely
applied in materials science, biology, and nanotechnology. However, its full
potential is constrained by the critical challenge of accurately reconstructing
images when the illuminating probe is unknown. Conventional iterative methods
and deep learning approaches are often suboptimal, particularly under the
low-signal conditions inherent to low-dose and high-speed experiments. These
limitations compromise reconstruction fidelity and restrict the broader
adoption of the technique. In this work, we introduce the Ptychographic
Implicit Neural Representation (PtyINR), a self-supervised framework that
simultaneously addresses the object and probe recovery problem. By
parameterizing both as continuous neural representations, PtyINR performs
end-to-end reconstruction directly from raw diffraction patterns without
requiring any pre-characterization of the probe. Extensive evaluations
demonstrate that PtyINR achieves superior reconstruction quality on both
simulated and experimental data, with remarkable robustness under challenging
low-signal conditions. Furthermore, PtyINR offers a generalizable,
physics-informed framework for addressing probe-dependent inverse problems,
making it applicable to a wide range of computational microscopy problems.
\\ ( https://arxiv.org/abs/2509.04402 ,  31135kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04403
Date: Thu, 4 Sep 2025 17:13:59 GMT   (1141kb)

Title: Self-adaptive Dataset Construction for Real-World Multimodal Safety
  Scenarios
Authors: Jingen Qu, Lijun Li, Bo Zhang, Yichen Yan, Jing Shao
Categories: cs.CV cs.CL cs.CR
Comments: Accepted at EMNLP 2025 Findings
\\
  Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end constructing paired text and guidance
responses. Using the image-oriented method, we automatically generate an RMS
dataset comprising 35k image-text pairs with guidance responses. Additionally,
we introduce a standardized safety dataset evaluation metric: fine-tuning a
safety judge model and evaluating its capabilities on other safety
datasets.Extensive experiments on various tasks demonstrate the effectiveness
of the proposed image-oriented pipeline. The results confirm the scalability
and effectiveness of the image-oriented approach, offering a new perspective
for the construction of real-world multimodal safety datasets.
\\ ( https://arxiv.org/abs/2509.04403 ,  1141kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04406
Date: Thu, 4 Sep 2025 17:24:31 GMT   (46227kb)

Title: Few-step Flow for 3D Generation via Marginal-Data Transport Distillation
Authors: Zanwei Zhou, Taoran Yi, Jiemin Fang, Chen Yang, Lingxi Xie, Xinggang
  Wang, Wei Shen, Qi Tian
Categories: cs.CV
Comments: Project page: https://github.com/Zanue/MDT-dist
\\
  Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Marginal-Data Transport. Directly
learning this objective needs to integrate the velocity fields, while this
integral is intractable to be implemented. Therefore, we propose two
optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD),
to equivalently convert the optimization target from the transport level to the
velocity and the distribution level respectively. Velocity Matching (VM) learns
to stably match the velocity fields between the student and the teacher, but
inevitably provides biased gradient estimates. Velocity Distillation (VD)
further enhances the optimization process by leveraging the learned velocity
fields to perform probability density distillation. When evaluated on the
pioneer 3D generation framework TRELLIS, our method reduces sampling steps of
each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s
(2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high
visual and geometric fidelity. Extensive experiments demonstrate that our
method significantly outperforms existing CM distillation methods, and enables
TRELLIS to achieve superior performance in few-step 3D generation.
\\ ( https://arxiv.org/abs/2509.04406 ,  46227kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04434
Date: Thu, 4 Sep 2025 17:53:03 GMT   (14604kb)

Title: Durian: Dual Reference-guided Portrait Animation with Attribute Transfer
Authors: Hyunsoo Cha, Byungjun Kim, Hanbyul Joo
Categories: cs.CV
Comments: Project Page: https://hyunsoocha.github.io/durian
\\
  We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames are sampled from the
same portrait video: one is treated as the attribute reference and the other as
the target portrait, and the remaining frames are reconstructed conditioned on
these inputs and their corresponding masks. To support the transfer of
attributes with varying spatial extent, we propose a mask expansion strategy
using keypoint-conditioned image generation for training. In addition, we
further augment the attribute and portrait images with spatial and
appearance-level transformations to improve robustness to positional
misalignment between them. These strategies allow the model to effectively
generalize across diverse attributes and in-the-wild reference combinations,
despite being trained without explicit triplet supervision. Durian achieves
state-of-the-art performance on portrait animation with attribute transfer, and
notably, its dual reference design enables multi-attribute composition in a
single generation pass without additional training.
\\ ( https://arxiv.org/abs/2509.04434 ,  14604kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04437
Date: Thu, 4 Sep 2025 17:53:45 GMT   (347kb)

Title: From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray
  Collimators via Hough Transform
Authors: Benjamin El-Zein, Dominik Eckert, Andreas Fieselmann, Christopher
  Syben, Ludwig Ritschl, Steffen Kappler, Sebastian Stober
Categories: cs.CV physics.med-ph
\\
  Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrained to its geometry. We
achieve this by incorporating a differentiable Hough transform-based network to
detect the collimation borders and enhance its capability to extract the
information about the ROI center. During inference, we combine the information
of both tasks to enable the generation of refined, line-constrained
segmentation masks. We demonstrate robust reconstruction of collimated regions
achieving median Hausdorff distances of 4.3-5.0mm on diverse test sets of real
Xray images. While this application involves at most four shadow borders, our
method is not fundamentally limited by a specific number of edges.
\\ ( https://arxiv.org/abs/2509.04437 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04438
Date: Thu, 4 Sep 2025 17:53:52 GMT   (4271kb)

Title: The Telephone Game: Evaluating Semantic Drift in Unified Models
Authors: Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir,
  Mubarak Shah
Categories: cs.CV cs.CL
\\
  Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and GenEval for T2I, and benchmarks such
as MME, MMBench for I2T. These single-pass metrics do not reveal whether a
model that understands a concept can also render it, nor whether meaning is
preserved when cycling between image and text modalities. To address this, we
introduce the Unified Consistency Framework for Unified Models (UCF-UM), a
cyclic evaluation protocol that alternates I2T and T2I over multiple
generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean
Cumulative Drift (MCD), an embedding-based measure of overall semantic loss;
(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)
Multi-Generation GenEval (MGG), an object-level compliance score extending
GenEval. To assess generalization beyond COCO, which is widely used in
training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and
evaluate on seven recent models. UCF-UM reveals substantial variation in
cross-modal stability: some models like BAGEL maintain semantics over many
alternations, whereas others like Vila-u drift quickly despite strong
single-pass scores. Our results highlight cyclic consistency as a necessary
complement to standard I2T and T2I evaluations, and provide practical metrics
to consistently assess unified model's cross-modal stability and strength of
their shared representations. Code:
https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models
\\ ( https://arxiv.org/abs/2509.04438 ,  4271kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04444
Date: Thu, 4 Sep 2025 17:59:10 GMT   (7708kb)

Title: One Flight Over the Gap: A Survey from Perspective to Panoramic Vision
Authors: Xin Lin, Xian Ge, Dizhe Zhang, Zhaoliang Wan, Xianshun Wang, Xiangtai
  Li, Wenjie Jiang, Bo Du, Dacheng Tao, Ming-Hsuan Yang, Lu Qi
Categories: cs.CV
\\
  Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct domain adaption from perspective methods. This
survey reviews recent panoramic vision techniques with a particular emphasis on
the perspective-to-panorama adaptation. We first revisit the panoramic imaging
pipeline and projection methods to build the prior knowledge required for
analyzing the structural disparities. Then, we summarize three challenges of
domain adaptation: severe geometric distortions near the poles, non-uniform
sampling in Equirectangular Projection (ERP), and periodic boundary continuity.
Building on this, we cover 20+ representative tasks drawn from more than 300
research papers in two dimensions. On one hand, we present a cross-method
analysis of representative strategies for addressing panoramic specific
challenges across different tasks. On the other hand, we conduct a cross-task
comparison and classify panoramic vision into four major categories: visual
quality enhancement and assessment, visual understanding, multimodal
understanding, and visual generation. In addition, we discuss open challenges
and future directions in data, models, and applications that will drive the
advancement of panoramic vision research. We hope that our work can provide new
insight and forward looking perspectives to advance the development of
panoramic vision technologies. Our project page is
https://insta360-research-team.github.io/Survey-of-Panorama
\\ ( https://arxiv.org/abs/2509.04444 ,  7708kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04446
Date: Thu, 4 Sep 2025 17:59:34 GMT   (47249kb)

Title: Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing
  with Text-to-Image Diffusion Models
Authors: Kiymet Akdemir, Jing Shi, Kushal Kafle, Brian Price, Pinar Yanardag
Categories: cs.CV
\\
  Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse edits while maintaining visual and
narrative consistency across multiple frames, preventing creators from
seamlessly crafting and refining their visual stories. To address these
challenges, we introduce Plot'n Polish, a zero-shot framework that enables
consistent story generation and provides fine-grained control over story
visualizations at various levels of detail.
\\ ( https://arxiv.org/abs/2509.04446 ,  47249kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04448
Date: Thu, 4 Sep 2025 17:59:43 GMT   (15340kb)

Title: TRUST-VL: An Explainable News Assistant for General Multimodal
  Misinformation Detection
Authors: Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee
Categories: cs.CV cs.MM
Comments: EMNLP 2025; Project Homepage: https://yanzehong.github.io/trust-vl/
\\
  Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and enhances the model's ability
to generalize. To this end, we introduce TRUST-VL, a unified and explainable
vision-language model for general multimodal misinformation detection. TRUST-VL
incorporates a novel Question-Aware Visual Amplifier module, designed to
extract task-specific visual features. To support training, we also construct
TRUST-Instruct, a large-scale instruction dataset containing 198K samples
featuring structured reasoning chains aligned with human fact-checking
workflows. Extensive experiments on both in-domain and zero-shot benchmarks
demonstrate that TRUST-VL achieves state-of-the-art performance, while also
offering strong generalization and interpretability.
\\ ( https://arxiv.org/abs/2509.04448 ,  15340kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04450
Date: Thu, 4 Sep 2025 17:59:55 GMT   (19283kb)

Title: Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual
  Try-On from a Single Image -- Technical Preview
Authors: Jun-Kun Chen, Aayush Bansal, Minh Phuoc Vo, Yu-Xiong Wang
Categories: cs.CV cs.LG
Comments: Project Page: https://immortalco.github.io/VirtualFittingRoom/
\\
  We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining global temporal consistency across different segments.
To address these challenges, we propose our VFR framework, which ensures
smoothness through a prefix video condition and enforces consistency with the
anchor video -- a 360-degree video that comprehensively captures the human's
wholebody appearance. Our VFR generates minute-scale virtual try-on videos with
both local smoothness and global temporal consistency under various motions,
making it a pioneering work in long virtual try-on video generation.
\\ ( https://arxiv.org/abs/2509.04450 ,  19283kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03653
Date: Wed, 3 Sep 2025 19:02:44 GMT   (196kb)

Title: Combining Performance and Productivity: Accelerating the Network Sensing
  Graph Challenge with GPUs and Commodity Data Science Software
Authors: Siddharth Samsi, Dan Campbell, Emanuel Scoullos, Oded Green
Categories: cs.DC
\\
  The HPEC Graph Challenge is a collection of benchmarks representing complex
workloads that test the hardware and software components of HPC systems, which
traditional benchmarks, such as LINPACK, do not. The first benchmark, Subgraph
Isomorphism, focused on several compute-bound and memory-bound kernels. The
most recent of the challenges, the Anonymized Network Sensing Graph Challenge,
represents a shift in direction, as it represents a longer end-to-end workload
that requires many more software components, including, but not limited to,
data I/O, data structures for representing graph data, and a wide range of
functions for data preparation and network analysis. A notable feature of this
new graph challenge is the use of GraphBLAS to represent the computational
aspects of the problem statement. In this paper, we show an alternative
interpretation of the GraphBLAS formulations using the language of data
science. With this formulation, we show that the new graph challenge can be
implemented using off-the-shelf ETL tools available in open-source, enterprise
software such as NVIDIA's RAPIDS ecosystem. Using off-the-shelf software,
RAPIDS cuDF and cupy, we enable significant software acceleration without
requiring any specific HPC code and show speedups, over the same code running
with Pandas on the CPU, of 147x-509x on an NVIDIA A100 GPU, 243x-1269X for an
NVIDIA H100 GPU, and 332X-2185X for an NVIDIA H200 GPU.
\\ ( https://arxiv.org/abs/2509.03653 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03755
Date: Wed, 3 Sep 2025 22:52:06 GMT   (292kb)

Title: Distributed Download from an External Data Source in Asynchronous Faulty
  Settings
Authors: John Augustine, Soumyottam Chatterjee, Valerie King, Manish Kumar,
  Shachar Meir, David Peleg
Categories: cs.DC
\\
  The distributedData Retrieval (DR) model consists of $k$ peers connected by a
complete peer-to-peer communication network, and a trusted external data source
that stores an array $\textbf{X}$ of $n$ bits ($n \gg k$). Up to $\beta k$ of
the peers might fail in any execution (for $\beta \in [0, 1)$). Peers can
obtain the information either by inexpensive messages passed among themselves
or through expensive queries to the source array $\textbf{X}$. In the DR model,
we focus on designing protocols that minimize the number of queries performed
by any nonfaulty peer (a measure referred to as query complexity) while
maximizing the resilience parameter $\beta$.
  The Download problem requires each nonfaulty peer to correctly learn the
entire array $\textbf{X}$. Earlier work on this problem focused on synchronous
communication networks and established several deterministic and randomized
upper and lower bounds. Our work is the first to extend the study of
distributed data retrieval to asynchronous communication networks. We address
the Download problem under both the Byzantine and crash failure models. We
present query-optimal deterministic solutions in an asynchronous model that can
tolerate any fixed fraction $\beta<1$ of crash faults. In the Byzantine failure
model, it is known that deterministic protocols incur a query complexity of
$\Omega(n)$ per peer, even under synchrony. We extend this lower bound to
randomized protocols in the asynchronous model for $\beta \geq 1/2$, and
further show that for $\beta < 1/2$, a randomized protocol exists with
near-optimal query complexity. To the best of our knowledge, this is the first
work to address the Download problem in asynchronous communication networks.
\\ ( https://arxiv.org/abs/2509.03755 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04004
Date: Thu, 4 Sep 2025 08:35:47 GMT   (83kb)

Title: Gathering of asynchronous robots on circle with limited visibility using
  finite communication
Authors: Avisek Sharma, Satakshi Ghosh, and Buddhadeb Sau
Categories: cs.DC
\\
  This work addresses the gathering problem for a set of autonomous, anonymous,
and homogeneous robots with limited visibility operating in a continuous
circle. The robots are initially placed at distinct positions, forming a
rotationally asymmetric configuration. The robots agree on the clockwise
direction. In the $\theta$-visibility model, a robot can only see those robots
on the circle that are at an angular distance $<\theta$ from it. Di Luna
\textit{et. al.} [DISC'20] have shown that, in $\pi/2$ visibility, gathering is
impossible. In addition, they provided an algorithm for robots with $\pi$
visibility, operating under a semi-synchronous scheduler. In the $\pi$
visibility model, only one point, the point at the angular distance $\pi$ is
removed from the visibility. Ghosh \textit{et. al.} [SSS'23] provided a
gathering algorithm for $\pi$ visibility model with robot having finite memory
($\mathcal{FSTA}$), operating under a special asynchronous scheduler.
  If the robots can see all points on the circle, then the gathering can be
done by electing a leader in the weakest robot model under a fully asynchronous
scheduler. However, previous works have shown that even the removal of one
point from the visibility makes gathering difficult. In both works, the robots
had rigid movement. In this work, we propose an algorithm that solves the
gathering problem under the $\pi$-visibility model for robots that have finite
communication ability ($\mathcal{FCOM}$). In this work the robot movement is
non-rigid and the robots work under a fully asynchronous scheduler.
\\ ( https://arxiv.org/abs/2509.04004 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04038
Date: Thu, 4 Sep 2025 09:15:21 GMT   (217kb)

Title: Counterfactual simulations for large scale systems with burnout
  variables
Authors: Benjamin Heymann
Categories: cs.DC math.OC stat.ME
\\
  We consider large-scale systems influenced by burnout variables - state
variables that start active, shape dynamics, and irreversibly deactivate once
certain conditions are met. Simulating what-if scenarios in such systems is
computationally demanding, as alternative trajectories often require sequential
processing, which does not scale very well. This challenge arises in settings
like online advertising, because of campaigns budgets, complicating
counterfactual analysis despite rich data availability. We introduce a new type
of algorithms based on what we refer to as uncertainty relaxation, that enables
efficient parallel computation, significantly improving scalability for
counterfactual estimation in systems with burnout variables.
\\ ( https://arxiv.org/abs/2509.04038 ,  217kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04084
Date: Thu, 4 Sep 2025 10:27:30 GMT   (662kb)

Title: LowDiff: Efficient Frequent Checkpointing via Low-Cost Differential for
  High-Performance Distributed Training Systems
Authors: Chenxuan Yao, Yuchong Hu, Feifan Liu, Zhengyu Liu, Dan Feng
Categories: cs.DC
\\
  Distributed training of large deep-learning models often leads to failures,
so checkpointing is commonly employed for recovery. State-of-the-art studies
focus on frequent checkpointing for fast recovery from failures. However, it
generates numerous checkpoints, incurring substantial costs and thus degrading
training performance. Recently, differential checkpointing has been proposed to
reduce costs, but it is limited to recommendation systems, so its application
to general distributed training systems remains unexplored.
  This paper proposes LowDiff, an efficient frequent checkpointing framework
that \textit{reuses} compressed gradients, serving as differential checkpoints
to reduce cost. Furthermore, LowDiff incorporates a batched gradient write
optimization to persist these differentials to storage efficiently. It also
dynamically tunes both the checkpoint frequency and the batching size to
maximize performance. We further enhance LowDiff with a layer-wise gradient
reusing and snapshotting approach and a CPU-based asynchronous persistence
strategy, enabling frequent checkpointing without gradient compression.
Experiments on various workloads show that LowDiff can achieve checkpointing
frequency up to per iteration with less than 3.1\% runtime overhead.
\\ ( https://arxiv.org/abs/2509.04084 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04085
Date: Thu, 4 Sep 2025 10:29:31 GMT   (1138kb)

Title: Trustworthy Second-hand Marketplace for Built Environment
Authors: Stanly Wilson, Kwabena Adu-Duodu, Yinhao Li, Ringo Sham, Yingli Wang,
  Ellis Solaiman, Charith Perera, Rajiv Ranjan, Omer Rana
Categories: cs.DC cs.ET
\\
  The construction industry faces significant challenges regarding material
waste and sustainable practices, necessitating innovative solutions that
integrate automation, traceability, and decentralised decision-making to enable
efficient material reuse. This paper presents a blockchain-enabled digital
marketplace for sustainable construction material reuse, ensuring transparency
and traceability using InterPlanetary File System (IPFS). The proposed
framework enhances trust and accountability in material exchange, addressing
key challenges in industrial automation and circular supply chains. A framework
has been developed to demonstrate the operational processes of the marketplace,
illustrating its practical application and effectiveness. Our contributions
show how the marketplace can facilitate the efficient and trustworthy exchange
of reusable materials, representing a substantial step towards more sustainable
construction practices.
\\ ( https://arxiv.org/abs/2509.04085 ,  1138kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04383
Date: Thu, 4 Sep 2025 16:42:49 GMT   (98kb)

Title: On the impact of unlimited computational power in OBLOT: consequences
  for synchronous robots on graphs
Authors: Serafino Cicerone and Alessia Di Fonso and Gabriele Di Stefano and
  Alfredo Navarra
Categories: cs.DC
Comments: 18 pages, 6 figures
\\
  The OBLOT model has been extensively studied in theoretical swarm robotics.
It assumes weak capabilities for the involved mobile robots, such as they are
anonymous, disoriented, no memory of past events (oblivious), and silent. Their
only means of (implicit) communication is transferred to their positioning,
i.e., stigmergic information. These limited capabilities make the design of
distributed algorithms a challenging task. Over the last two decades, numerous
research papers have addressed the question of which tasks can be accomplished
within this model. Nevertheless, as it usually happens in distributed
computing, also in OBLOT the computational power available to the robots is
neglected as the main cost measures for the designed algorithms refer to the
number of movements or the number of rounds required. In this paper, we prove
that for synchronous robots moving on finite graphs, the unlimited
computational power (other than finite time) has a significant impact. In fact,
by exploiting it, we provide a definitive resolution algorithm that applies to
a wide class of problems while guaranteeing the minimum number of moves and
rounds.
\\ ( https://arxiv.org/abs/2509.04383 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03793
Date: Thu, 4 Sep 2025 01:04:44 GMT   (368kb)

Title: SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation
  Dynamics in India
Authors: Prathamesh Devadiga, Omkaar Jayadev Shetty, Pooja Agarwal
Categories: cs.MA cs.AI
\\
  Understanding the complexities of judicial deliberation is crucial for
assessing the efficacy and fairness of a justice system. However, empirical
studies of judicial panels are constrained by significant ethical and practical
barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS)
designed to simulate the deliberation process within the framework of the
Indian justice system.
  Our system comprises agents representing key judicial roles: a Judge, a
Prosecution Counsel, a Defense Counsel, and multiple Adjudicators (simulating a
judicial bench), all powered by large language models (LLMs). A primary
contribution of this work is the integration of Retrieval-Augmented Generation
(RAG), grounded in a domain-specific knowledge base of landmark Indian legal
documents, including the Indian Penal Code and the Constitution of India. This
RAG functionality enables the Judge and Counsel agents to generate legally
sound instructions and arguments, complete with source citations, thereby
enhancing both the fidelity and transparency of the simulation.
  The Adjudicator agents engage in iterative deliberation rounds, processing
case facts, legal instructions, and arguments to reach a consensus-based
verdict. We detail the system architecture, agent communication protocols, the
RAG pipeline, the simulation workflow, and a comprehensive evaluation plan
designed to assess performance, deliberation quality, and outcome consistency.
  This work provides a configurable and explainable MAS platform for exploring
legal reasoning and group decision-making dynamics in judicial simulations,
specifically tailored to the Indian legal context and augmented with verifiable
legal grounding via RAG.
\\ ( https://arxiv.org/abs/2509.03793 ,  368kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2509.03521 (*cross-listing*)
Date: Tue, 19 Aug 2025 10:18:41 GMT   (2406kb)

Title: BiND: A Neural Discriminator-Decoder for Accurate Bimanual Trajectory
  Prediction in Brain-Computer Interfaces
Authors: Timothee Robert, MohammadAli Shaeri, Mahsa Shoaran
Categories: q-bio.NC cs.AI eess.SP
Comments: Accepted for publication in IEEE Neural Engineering (NER)
  Conference'25
\\
  Decoding bimanual hand movements from intracortical recordings remains a
critical challenge for brain-computer interfaces (BCIs), due to overlapping
neural representations and nonlinear interlimb interactions. We introduce BiND
(Bimanual Neural Discriminator-Decoder), a two-stage model that first
classifies motion type (unimanual left, unimanual right, or bimanual) and then
uses specialized GRU-based decoders, augmented with a trial-relative time
index, to predict continuous 2D hand velocities. We benchmark BiND against six
state-of-the-art models (SVR, XGBoost, FNN, CNN, Transformer, GRU) on a
publicly available 13-session intracortical dataset from a tetraplegic patient.
BiND achieves a mean $R^2$ of 0.76 ($\pm$0.01) for unimanual and 0.69
($\pm$0.03) for bimanual trajectory prediction, surpassing the next-best model
(GRU) by 2% in both tasks. It also demonstrates greater robustness to session
variability than all other benchmarked models, with accuracy improvements of up
to 4% compared to GRU in cross-session analyses. This highlights the
effectiveness of task-aware discrimination and temporal modeling in enhancing
bimanual decoding.
\\ ( https://arxiv.org/abs/2509.03521 ,  2406kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03545 (*cross-listing*)
Date: Tue, 2 Sep 2025 02:48:28 GMT   (523kb)

Title: A software security review on Uganda's Mobile Money Services: Dr. Jim
  Spire's tweets sentiment analysis
Authors: Nsengiyumva Wilberforce
Categories: cs.CY cs.AI cs.CR
Comments: 16 pages, 3 figures
\\
  The proliferation of mobile money in Uganda has been a cornerstone of
financial inclusion, yet its security mechanisms remain a critical concern.
This study investigates a significant public response to perceived security
failures: the #StopAirtelThefty Twitter campaign of August 2025 Sparked by an
incident publicized by Dr. Jim Spire Ssentongo where a phone thief accessed a
victim's account, withdrew funds, and procured a loan, the campaign revealed
deep seated public anxiety over the safety of mobile money. This research
employs qualitative analysis to systematically examine the complaints raised
during this campaign, extracting key themes related to security vulnerabilities
and user dissatisfaction. By synthesizing these public sentiments, the paper
provides crucial insights into the specific security gaps experienced by users
and situates these findings within the larger framework of Uganda's mobile
money regulatory and operational environment. The study concludes with
implications for providers, policymakers, and the future of secure digital
finance in Uganda.
\\ ( https://arxiv.org/abs/2509.03545 ,  523kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03594 (*cross-listing*)
Date: Wed, 3 Sep 2025 18:00:33 GMT   (1786kb)

Title: The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's
  Induced Metric
Authors: Thomas R. Harvey
Categories: cs.LG cs.AI math.OC
Comments: https://github.com/harveyThomas4692/Induced-Metric-Optimiser
\\
  We present a class of novel optimisers for training neural networks that
makes use of the Riemannian metric naturally induced when the loss landscape is
embedded in higher-dimensional space. This is the same metric that underlies
common visualisations of loss landscapes. By taking this geometric perspective
literally and using the induced metric, we develop a new optimiser and compare
it to existing methods, namely: SGD, Adam, AdamW, and Muon, across a range of
tasks and architectures. Empirically, we conclude that this new class of
optimisers is highly effective in low dimensional examples, and provides slight
improvement over state-of-the-art methods for training neural networks. These
new optimisers have theoretically desirable properties. In particular, the
effective learning rate is automatically decreased in regions of high curvature
acting as a smoothed out form of gradient clipping. Similarly, one variant of
these optimisers can also be viewed as inducing an effective scheduled learning
rate and decoupled weight decay is the natural choice from our geometric
perspective. The basic method can be used to modify any existing
preconditioning method. The new optimiser has a computational complexity
comparable to that of Adam.
\\ ( https://arxiv.org/abs/2509.03594 ,  1786kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03643 (*cross-listing*)
Date: Wed, 3 Sep 2025 18:50:03 GMT   (5244kb)

Title: CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health
  Records
Authors: Chao Pang, Jiheum Park, Xinzhuo Jiang, Nishanth Parameshwar
  Pavinkurve, Krishna S. Kalluri, Shalmali Joshi, No\'emie Elhadad, Karthik
  Natarajan
Categories: cs.LG cs.AI
\\
  Electronic Health Records (EHRs) provide a rich, longitudinal view of patient
health and hold significant potential for advancing clinical decision support,
risk prediction, and data-driven healthcare research. However, most artificial
intelligence (AI) models for EHRs are designed for narrow, single-purpose
tasks, limiting their generalizability and utility in real-world settings.
Here, we present CEHR-GPT, a general-purpose foundation model for EHR data that
unifies three essential capabilities - feature representation, zero-shot
prediction, and synthetic data generation - within a single architecture. To
support temporal reasoning over clinical sequences, \cehrgpt{} incorporates a
novel time-token-based learning framework that explicitly encodes patients'
dynamic timelines into the model structure. CEHR-GPT demonstrates strong
performance across all three tasks and generalizes effectively to external
datasets through vocabulary expansion and fine-tuning. Its versatility enables
rapid model development, cohort discovery, and patient outcome forecasting
without the need for task-specific retraining.
\\ ( https://arxiv.org/abs/2509.03643 ,  5244kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03658 (*cross-listing*)
Date: Wed, 3 Sep 2025 19:18:02 GMT   (3060kb)

Title: Efficient Virtuoso: A Latent Diffusion Transformer Model for
  Goal-Conditioned Trajectory Planning
Authors: Antonio Guillen-Perez
Categories: cs.RO cs.AI cs.LG
\\
  The ability to generate a diverse and plausible distribution of future
trajectories is a critical capability for autonomous vehicle planning systems.
While recent generative models have shown promise, achieving high fidelity,
computational efficiency, and precise control remains a significant challenge.
In this paper, we present the \textbf{Efficient Virtuoso}, a conditional latent
diffusion model for goal-conditioned trajectory planning. Our approach
introduces a novel two-stage normalization pipeline that first scales
trajectories to preserve their geometric aspect ratio and then normalizes the
resulting PCA latent space to ensure a stable training target. The denoising
process is performed efficiently in this low-dimensional latent space by a
simple MLP denoiser, which is conditioned on a rich scene context fused by a
powerful Transformer-based StateEncoder. We demonstrate that our method
achieves state-of-the-art performance on the Waymo Open Motion Dataset,
reaching a \textbf{minADE of 0.25}. Furthermore, through a rigorous ablation
study on goal representation, we provide a key insight: while a single endpoint
goal can resolve strategic ambiguity, a richer, multi-step sparse route is
essential for enabling the precise, high-fidelity tactical execution that
mirrors nuanced human driving behavior.
\\ ( https://arxiv.org/abs/2509.03658 ,  3060kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03677 (*cross-listing*)
Date: Wed, 3 Sep 2025 19:54:23 GMT   (1567kb)

Title: Insights from Gradient Dynamics: Gradient Autoscaled Normalization
Authors: Vincent-Daniel Yun
Categories: cs.LG cs.AI cs.CV cs.IT math.IT
\\
  Gradient dynamics play a central role in determining the stability and
generalization of deep neural networks. In this work, we provide an empirical
analysis of how variance and standard deviation of gradients evolve during
training, showing consistent changes across layers and at the global scale in
convolutional networks. Motivated by these observations, we propose a
hyperparameter-free gradient normalization method that aligns gradient scaling
with their natural evolution. This approach prevents unintended amplification,
stabilizes optimization, and preserves convergence guarantees. Experiments on
the challenging CIFAR-100 benchmark with ResNet-20, ResNet-56, and VGG-16-BN
demonstrate that our method maintains or improves test accuracy even under
strong generalization. Beyond practical performance, our study highlights the
importance of directly tracking gradient dynamics, aiming to bridge the gap
between theoretical expectations and empirical behaviors, and to provide
insights for future optimization research.
\\ ( https://arxiv.org/abs/2509.03677 ,  1567kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03680 (*cross-listing*)
Date: Wed, 3 Sep 2025 19:59:20 GMT   (29773kb)

Title: LuxDiT: Lighting Estimation with Video Diffusion Transformer
Authors: Ruofan Liang, Kai He, Zan Gojcic, Igor Gilitschenski, Sanja Fidler,
  Nandita Vijaykumar, Zian Wang
Categories: cs.GR cs.AI cs.CV
Comments: Project page: https://research.nvidia.com/labs/toronto-ai/LuxDiT/
\\
  Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.
\\ ( https://arxiv.org/abs/2509.03680 ,  29773kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03695 (*cross-listing*)
Date: Wed, 3 Sep 2025 20:23:19 GMT   (2821kb)

Title: Hierarchical Federated Foundation Models over Wireless Networks for
  Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with
  D2D/P2P-Enabled Fog Learning Architectures
Authors: Payam Abdisarabshali, Fardis Nadimi, Kasra Borazjani, Naji Khosravan,
  Minghui Liwang, Wei Ni, Dusit Niyato, Michael Langberg, Seyyedali
  Hosseinalipour
Categories: cs.LG cs.AI
Comments: 7 pages, 2 figures, 1 table
\\
  The rise of foundation models (FMs) has reshaped the landscape of machine
learning. As these models continued to grow, leveraging geo-distributed data
from wireless devices has become increasingly critical, giving rise to
federated foundation models (FFMs). More recently, FMs have evolved into
multi-modal multi-task (M3T) FMs (e.g., GPT-4) capable of processing diverse
modalities across multiple tasks, which motivates a new underexplored paradigm:
M3T FFMs. In this paper, we unveil an unexplored variation of M3T FFMs by
proposing hierarchical federated foundation models (HF-FMs), which in turn
expose two overlooked heterogeneity dimensions to fog/edge networks that have a
direct impact on these emerging models: (i) heterogeneity in collected
modalities and (ii) heterogeneity in executed tasks across fog/edge nodes.
HF-FMs strategically align the modular structure of M3T FMs, comprising
modality encoders, prompts, mixture-of-experts (MoEs), adapters, and task
heads, with the hierarchical nature of fog/edge infrastructures. Moreover,
HF-FMs enable the optional usage of device-to-device (D2D) communications,
enabling horizontal module relaying and localized cooperative training among
nodes when feasible. Through delving into the architectural design of HF-FMs,
we highlight their unique capabilities along with a series of tailored future
research directions. Finally, to demonstrate their potential, we prototype
HF-FMs in a wireless network setting and release the open-source code for the
development of HF-FMs with the goal of fostering exploration in this untapped
field (GitHub: https://github.com/payamsiabd/M3T-FFM).
\\ ( https://arxiv.org/abs/2509.03695 ,  2821kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03709 (*cross-listing*)
Date: Wed, 3 Sep 2025 20:48:41 GMT   (20882kb)

Title: From Federated Learning to $\mathbb{X}$-Learning: Breaking the Barriers
  of Decentrality Through Random Walks
Authors: Allan Salihovic, Payam Abdisarabshali, Michael Langberg, Seyyedali
  Hosseinalipour
Categories: cs.LG cs.AI
Comments: 6 figures, 12 pages
\\
  We provide our perspective on $\mathbb{X}$-Learning ($\mathbb{X}$L), a novel
distributed learning architecture that generalizes and extends the concept of
decentralization. Our goal is to present a vision for $\mathbb{X}$L,
introducing its unexplored design considerations and degrees of freedom. To
this end, we shed light on the intuitive yet non-trivial connections between
$\mathbb{X}$L, graph theory, and Markov chains. We also present a series of
open research directions to stimulate further research.
\\ ( https://arxiv.org/abs/2509.03709 ,  20882kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03733 (*cross-listing*)
Date: Wed, 3 Sep 2025 21:38:22 GMT   (121kb)

Title: Differentiable Entropy Regularization for Geometry and Neural Networks
Authors: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
Categories: cs.LG cs.AI
\\
  We introduce a differentiable estimator of range-partition entropy, a recent
concept from computational geometry that enables algorithms to adapt to the
"sortedness" of their input. While range-partition entropy provides strong
guarantees in algorithm design, it has not yet been made accessible to deep
learning. In this work, we (i) propose the first differentiable approximation
of range-partition entropy, enabling its use as a trainable loss or
regularizer; (ii) design EntropyNet, a neural module that restructures data
into low-entropy forms to accelerate downstream instance-optimal algorithms;
and (iii) extend this principle beyond geometry by applying entropy
regularization directly to Transformer attention. Across tasks, we demonstrate
that differentiable entropy improves efficiency without degrading correctness:
in geometry, our method achieves up to $4.1\times$ runtime speedups with
negligible error ($<0.2%$); in deep learning, it induces structured attention
patterns that yield 6% higher accuracy at 80% sparsity compared to L1
baselines. Our theoretical analysis provides approximation bounds for the
estimator, and extensive ablations validate design choices. These results
suggest that entropy-bounded computation is not only theoretically elegant but
also a practical mechanism for adaptive learning, efficiency, and structured
representation.
\\ ( https://arxiv.org/abs/2509.03733 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03738 (*cross-listing*)
Date: Wed, 3 Sep 2025 21:57:03 GMT   (1121kb)

Title: Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces
Authors: Bahareh Tolooshams, Ailsa Shen, Anima Anandkumar
Categories: cs.LG cs.AI eess.SP stat.ML
Comments: Tolooshams and Shen has equal contribution. preprint
\\
  We frame the problem of unifying representations in neural models as one of
sparse model recovery and introduce a framework that extends sparse
autoencoders (SAEs) to lifted spaces and infinite-dimensional function spaces,
enabling mechanistic interpretability of large neural operators (NO). While the
Platonic Representation Hypothesis suggests that neural networks converge to
similar representations across architectures, the representational properties
of neural operators remain underexplored despite their growing importance in
scientific computing. We compare the inference and training dynamics of SAEs,
lifted-SAE, and SAE neural operators. We highlight how lifting and operator
modules introduce beneficial inductive biases, enabling faster recovery,
improved recovery of smooth concepts, and robust inference across varying
resolutions, a property unique to neural operators.
\\ ( https://arxiv.org/abs/2509.03738 ,  1121kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03741 (*cross-listing*)
Date: Wed, 3 Sep 2025 22:01:14 GMT   (6290kb)

Title: Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard
  with Conversational AI Support
Authors: Eduardo Davalos, Yike Zhang, Shruti Jain, Namrata Srivastava, Trieu
  Truong, Nafees-ul Haque, Tristan Van, Jorge Salas, Sara McFadden, Sun-Joo
  Cho, Gautam Biswas, and Amanda Goodwin
Categories: cs.HC cs.AI
Comments: 22 pages, 9 figures, 3 tables, submitted to IUI2026
\\
  Eye-tracking offers rich insights into student cognition and engagement, but
remains underutilized in classroom-facing educational technology due to
challenges in data interpretation and accessibility. In this paper, we present
the iterative design and evaluation of a gaze-based learning analytics
dashboard for English Language Arts (ELA), developed through five studies
involving teachers and students. Guided by user-centered design and data
storytelling principles, we explored how gaze data can support reflection,
formative assessment, and instructional decision-making. Our findings
demonstrate that gaze analytics can be approachable and pedagogically valuable
when supported by familiar visualizations, layered explanations, and narrative
scaffolds. We further show how a conversational agent, powered by a large
language model (LLM), can lower cognitive barriers to interpreting gaze data by
enabling natural language interactions with multimodal learning analytics. We
conclude with design implications for future EdTech systems that aim to
integrate novel data modalities in classroom contexts.
\\ ( https://arxiv.org/abs/2509.03741 ,  6290kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03757 (*cross-listing*)
Date: Wed, 3 Sep 2025 22:54:12 GMT   (10kb)

Title: ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and
  Parabolic PDEs Based on Random Differences of Test Functions
Authors: Wei Cai, Andrew Qing He
Categories: math.NA cs.AI cs.NA
MSC-class: 35Q68, 65N99, 68T07, 76M99
\\
  We propose ARDO method for solving PDEs and PDE-related problems with deep
learning techniques. This method uses a weak adversarial formulation but
transfers the random difference operator onto the test function. The main
advantage of this framework is that it is fully derivative-free with respect to
the solution neural network. This framework is particularly suitable for
Fokker-Planck type second-order elliptic and parabolic PDEs.
\\ ( https://arxiv.org/abs/2509.03757 ,  10kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03771 (*cross-listing*)
Date: Wed, 3 Sep 2025 23:32:39 GMT   (6595kb)

Title: Learning an Adversarial World Model for Automated Curriculum Generation
  in MARL
Authors: Brennen Hill
Categories: cs.LG cs.AI cs.MA
MSC-class: 68T05, 91A26, 90C40
ACM-class: I.2.6; I.2.11
\\
  World models that infer and predict environmental dynamics are foundational
to embodied intelligence. However, their potential is often limited by the
finite complexity and implicit biases of hand-crafted training environments. To
develop truly generalizable and robust agents, we need environments that scale
in complexity alongside the agents learning within them. In this work, we
reframe the challenge of environment generation as the problem of learning a
goal-conditioned, generative world model. We propose a system where a
generative **Attacker** agent learns an implicit world model to synthesize
increasingly difficult challenges for a team of cooperative **Defender**
agents. The Attacker's objective is not passive prediction, but active,
goal-driven interaction: it models and generates world states (i.e.,
configurations of enemy units) specifically to exploit the Defenders'
weaknesses. Concurrently, the embodied Defender team learns a cooperative
policy to overcome these generated worlds. This co-evolutionary dynamic creates
a self-scaling curriculum where the world model continuously adapts to
challenge the decision-making policy of the agents, providing an effectively
infinite stream of novel and relevant training scenarios. We demonstrate that
this framework leads to the emergence of complex behaviors, such as the world
model learning to generate flanking and shielding formations, and the defenders
learning coordinated focus-fire and spreading tactics. Our findings position
adversarial co-evolution as a powerful method for learning instrumental world
models that drive agents toward greater strategic depth and robustness.
\\ ( https://arxiv.org/abs/2509.03771 ,  6595kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03780 (*cross-listing*)
Date: Thu, 4 Sep 2025 00:24:24 GMT   (976kb)

Title: Natural Latents: Latent Variables Stable Across Ontologies
Authors: John Wentworth, David Lorell
Categories: math.PR cs.AI cs.IT cs.LG math.IT
\\
  Suppose two Bayesian agents each learn a generative model of the same
environment. We will assume the two have converged on the predictive
distribution, i.e. distribution over some observables in the environment, but
may have different generative models containing different latent variables.
Under what conditions can one agent guarantee that their latents are a function
of the other agents latents?
  We give simple conditions under which such translation is guaranteed to be
possible: the natural latent conditions. We also show that, absent further
constraints, these are the most general conditions under which translatability
is guaranteed. Crucially for practical application, our theorems are robust to
approximation error in the natural latent conditions.
\\ ( https://arxiv.org/abs/2509.03780 ,  976kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03790 (*cross-listing*)
Date: Thu, 4 Sep 2025 00:53:02 GMT   (58kb)

Title: What Fundamental Structure in Reward Functions Enables Efficient
  Sparse-Reward Learning?
Authors: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
Categories: cs.LG cs.AI
\\
  What fundamental properties of reward functions enable efficient
sparse-reward reinforcement learning? We address this question through the lens
of low-rank structure in reward matrices, showing that such structure induces a
sharp transition from exponential to polynomial sample complexity, the first
result of this kind for sparse-reward RL. We introduce Policy-Aware Matrix
Completion (PAMC), which connects matrix completion theory with reinforcement
learning via a new analysis of policy-dependent sampling. Our framework
provides: (i) impossibility results for general sparse reward observation, (ii)
reward-free representation learning from dynamics, (iii) distribution-free
confidence sets via conformal prediction, and (iv) robust completion guarantees
that degrade gracefully when low-rank structure is only approximate.
Empirically, we conduct a pre-registered evaluation across 100 systematically
sampled domains, finding exploitable structure in over half. PAMC improves
sample efficiency by factors between 1.6 and 2.1 compared to strong
exploration, structured, and representation-learning baselines, while adding
only about 20 percent computational overhead.These results establish structural
reward learning as a promising new paradigm, with immediate implications for
robotics, healthcare, and other safety-critical, sample-expensive applications.
\\ ( https://arxiv.org/abs/2509.03790 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03832 (*cross-listing*)
Date: Thu, 4 Sep 2025 02:41:35 GMT   (834kb)

Title: Gravity Well Echo Chamber Modeling With An LLM-Based Confirmation Bias
  Model
Authors: Joseph Jackson, Georgiy Lapin, Jeremy E. Thompson
Categories: cs.SI cs.AI cs.CY
\\
  Social media echo chambers play a central role in the spread of
misinformation, yet existing models often overlook the influence of individual
confirmation bias. An existing model of echo chambers is the "gravity well"
model, which creates an analog between echo chambers and spatial gravity wells.
We extend this established model by introducing a dynamic confirmation bias
variable that adjusts the strength of pull based on a user's susceptibility to
belief-reinforcing content. This variable is calculated for each user through
comparisons between their posting history and their responses to posts of a
wide range of viewpoints.
  Incorporating this factor produces a confirmation-bias-integrated gravity
well model that more accurately identifies echo chambers and reveals
community-level markers of information health. We validated the approach on
nineteen Reddit communities, demonstrating improved detection of echo chambers.
  Our contribution is a framework for systematically capturing the role of
confirmation bias in online group dynamics, enabling more effective
identification of echo chambers. By flagging these high-risk environments, the
model supports efforts to curb the spread of misinformation at its most common
points of amplification.
\\ ( https://arxiv.org/abs/2509.03832 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03834 (*cross-listing*)
Date: Thu, 4 Sep 2025 02:50:54 GMT   (989kb)

Title: From Leiden to Pleasure Island: The Constant Potts Model for Community
  Detection as a Hedonic Game
Authors: Lucas Lopes Felipe and Konstantin Avrachenkov and Daniel Sadoc
  Menasche
Categories: cs.LG cs.AI cs.GT
Comments: Manuscript submitted to Physica A: Statistical Mechanics and its
  Applications
\\
  Community detection is one of the fundamental problems in data science which
consists of partitioning nodes into disjoint communities. We present a
game-theoretic perspective on the Constant Potts Model (CPM) for partitioning
networks into disjoint communities, emphasizing its efficiency, robustness, and
accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by
decomposing its global Hamiltonian into local utility functions, where the
local utility gain of each agent matches the corresponding increase in global
utility. Leveraging this equivalence, we prove that local optimization of the
CPM objective via better-response dynamics converges in pseudo-polynomial time
to an equilibrium partition. Robustness: We introduce and relate two stability
criteria: a strict criterion based on a novel notion of robustness, requiring
nodes to simultaneously maximize neighbors and minimize non-neighbors within
communities, and a relaxed utility function based on a weighted sum of these
objectives, controlled by a resolution parameter. Accuracy: In community
tracking scenarios, where initial partitions are used to bootstrap the Leiden
algorithm with partial ground-truth information, our experiments reveal that
robust partitions yield higher accuracy in recovering ground-truth communities.
\\ ( https://arxiv.org/abs/2509.03834 ,  989kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03842 (*cross-listing*)
Date: Thu, 4 Sep 2025 03:08:01 GMT   (13627kb)

Title: INGRID: Intelligent Generative Robotic Design Using Large Language
  Models
Authors: Guanglu Jia, Ceng Zhang, Gregory S. Chirikjian
Categories: cs.RO cs.AI
Comments: 15 pages, 6 figures
\\
  The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with reciprocal screw theory and kinematic
synthesis methods. We decompose the design challenge into four progressive
tasks: constraint analysis, kinematic joint generation, chain construction, and
complete mechanism design. INGRID demonstrates the ability to generate novel
parallel mechanisms with both fixed and variable mobility, discovering
kinematic configurations not previously documented in the literature. We
validate our approach through three case studies demonstrating how INGRID
assists users in designing task-specific parallel robots based on desired
mobility requirements. By bridging the gap between mechanism theory and machine
learning, INGRID enables researchers without specialized robotics training to
create custom parallel mechanisms, thereby decoupling advances in robotic
intelligence from hardware constraints. This work establishes a foundation for
mechanism intelligence, where AI systems actively design robotic hardware,
potentially transforming the development of embodied AI systems.
\\ ( https://arxiv.org/abs/2509.03842 ,  13627kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03845 (*cross-listing*)
Date: Thu, 4 Sep 2025 03:13:11 GMT   (2296kb)

Title: Meta-Inverse Reinforcement Learning for Mean Field Games via
  Probabilistic Context Variables
Authors: Yang Chen, Xiao Lin, Bo Yan, Libo Zhang, Jiamou Liu, Neset \"Ozkan
  Tan, Michael Witbrock
Categories: cs.LG cs.AI cs.GT
Comments: Accepted to AAAI 2024
\\
  Designing suitable reward functions for numerous interacting intelligent
agents is challenging in real-world applications. Inverse reinforcement
learning (IRL) in mean field games (MFGs) offers a practical framework to infer
reward functions from expert demonstrations. While promising, the assumption of
agent homogeneity limits the capability of existing methods to handle
demonstrations with heterogeneous and unknown objectives, which are common in
practice. To this end, we propose a deep latent variable MFG model and an
associated IRL method. Critically, our method can infer rewards from different
yet structurally similar tasks without prior knowledge about underlying
contexts or modifying the MFG model itself. Our experiments, conducted on
simulated scenarios and a real-world spatial taxi-ride pricing problem,
demonstrate the superiority of our approach over state-of-the-art IRL methods
in MFGs.
\\ ( https://arxiv.org/abs/2509.03845 ,  2296kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03852 (*cross-listing*)
Date: Thu, 4 Sep 2025 03:28:42 GMT   (1073kb)

Title: MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate
  Time Series Forecasting
Authors: Binqing Wu, Zongjiang Shang, Jianlong Huang, Ling Chen
Categories: cs.LG cs.AI
Comments: Accepted by CIKM 2025
\\
  Multi-variate time series (MTS) forecasting is crucial for various
applications. Existing methods have shown promising results owing to their
strong ability to capture intra- and inter-variate dependencies. However, these
methods often overlook lead-lag dependencies at multiple grouping scales,
failing to capture hierarchical lead-lag effects in complex systems. To this
end, we propose MillGNN, a novel \underline{g}raph \underline{n}eural
\underline{n}etwork-based method that learns \underline{m}ult\underline{i}ple
grouping scale \underline{l}ead-\underline{l}ag dependencies for MTS
forecasting, which can comprehensively capture lead-lag effects considering
variate-wise and group-wise dynamics and decays. Specifically, MillGNN
introduces two key innovations: (1) a scale-specific lead-lag graph learning
module that integrates cross-correlation coefficients and dynamic decaying
features derived from real-time inputs and time lags to learn lead-lag
dependencies for each scale, which can model evolving lead-lag dependencies
with statistical interpretability and data-driven flexibility; (2) a
hierarchical lead-lag message passing module that passes lead-lag messages at
multiple grouping scales in a structured way to simultaneously propagate intra-
and inter-scale lead-lag effects, which can capture multi-scale lead-lag
effects with a balance of comprehensiveness and efficiency. Experimental
results on 11 datasets demonstrate the superiority of MillGNN for long-term and
short-term MTS forecasting, compared with 16 state-of-the-art methods.
\\ ( https://arxiv.org/abs/2509.03852 ,  1073kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03884 (*cross-listing*)
Date: Thu, 4 Sep 2025 04:54:02 GMT   (593kb)

Title: Peptidomic-Based Prediction Model for Coronary Heart Disease Using a
  Multilayer Perceptron Neural Network
Authors: Jesus Celis-Porras
Categories: cs.LG cs.AI
Comments: 14 pages, 6 figures, Submitted to arXiv for public dissemination
\\
  Coronary heart disease (CHD) is a leading cause of death worldwide and
contributes significantly to annual healthcare expenditures. To develop a
non-invasive diagnostic approach, we designed a model based on a multilayer
perceptron (MLP) neural network, trained on 50 key urinary peptide biomarkers
selected via genetic algorithms. Treatment and control groups, each comprising
345 individuals, were balanced using the Synthetic Minority Over-sampling
Technique (SMOTE). The neural network was trained using a stratified validation
strategy. Using a network with three hidden layers of 60 neurons each and an
output layer of two neurons, the model achieved a precision, sensitivity, and
specificity of 95.67 percent, with an F1-score of 0.9565. The area under the
ROC curve (AUC) reached 0.9748 for both classes, while the Matthews correlation
coefficient (MCC) and Cohen's kappa coefficient were 0.9134 and 0.9131,
respectively, demonstrating its reliability in detecting CHD. These results
indicate that the model provides a highly accurate and robust non-invasive
diagnostic tool for coronary heart disease.
\\ ( https://arxiv.org/abs/2509.03884 ,  593kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03889 (*cross-listing*)
Date: Thu, 4 Sep 2025 05:16:56 GMT   (9056kb)

Title: Reactive In-Air Clothing Manipulation with Confidence-Aware Dense
  Correspondence and Visuotactile Affordance
Authors: Neha Sunil, Megha Tippur, Arnau Saumell, Edward Adelson, Alberto
  Rodriguez
Categories: cs.RO cs.AI cs.LG
Comments: Accepted at CoRL 2025. Project website:
  https://mhtippur.github.io/inairclothmanipulation/
\\
  Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributional loss that
captures cloth symmetries and generates correspondence confidence estimates.
These estimates guide a reactive state machine that adapts folding strategies
based on perceptual uncertainty. In parallel, a visuotactile grasp affordance
network, self-supervised using high-resolution tactile feedback, determines
which regions are physically graspable. The same tactile classifier is used
during execution for real-time grasp validation. By deferring action in
low-confidence states, the system handles highly occluded table-top and in-air
configurations. We demonstrate our task-agnostic grasp selection module in
folding and hanging tasks. Moreover, our dense descriptors provide a reusable
intermediate representation for other planning modalities, such as extracting
grasp targets from human video demonstrations, paving the way for more
generalizable and scalable garment manipulation.
\\ ( https://arxiv.org/abs/2509.03889 ,  9056kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03898 (*cross-listing*)
Date: Thu, 4 Sep 2025 05:45:06 GMT   (5797kb)

Title: Diffusion Generative Models Meet Compressed Sensing, with Applications
  to Image Data and Financial Time Series
Authors: Zhengyi Guo, Jiatu Li, Wenpin Tang, David D. Yao
Categories: stat.ML cs.AI cs.LG
\\
  This paper develops dimension reduction techniques for accelerating diffusion
model inference in the context of synthetic data generation. The idea is to
integrate compressed sensing into diffusion models: (i) compress the data into
a latent space, (ii) train a diffusion model in the latent space, and (iii)
apply a compressed sensing algorithm to the samples generated in the latent
space, facilitating the efficiency of both model training and inference. Under
suitable sparsity assumptions on data, the proposed algorithm is proved to
enjoy faster convergence by combining diffusion model inference with sparse
recovery. As a byproduct, we obtain an optimal value for the latent space
dimension. We also conduct numerical experiments on a range of datasets,
including image data (handwritten digits, medical images, and climate data) and
financial time series for stress testing.
\\ ( https://arxiv.org/abs/2509.03898 ,  5797kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03985 (*cross-listing*)
Date: Thu, 4 Sep 2025 08:12:06 GMT   (5038kb)

Title: NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language
  Models
Authors: Chuhan Zhang, Ye Zhang, Bowen Shi, Yuyou Gan, Tianyu Du, Shouling Ji,
  Dazhan Deng, Yingcai Wu
Categories: cs.CR cs.AI
Comments: 12 pages, 9 figures
\\
  In deployment and application, large language models (LLMs) typically undergo
safety alignment to prevent illegal and unethical outputs. However, the
continuous advancement of jailbreak attack techniques, designed to bypass
safety mechanisms with adversarial prompts, has placed increasing pressure on
the security defenses of LLMs. Strengthening resistance to jailbreak attacks
requires an in-depth understanding of the security mechanisms and
vulnerabilities of LLMs. However, the vast number of parameters and complex
structure of LLMs make analyzing security weaknesses from an internal
perspective a challenging task. This paper presents NeuroBreak, a top-down
jailbreak analysis system designed to analyze neuron-level safety mechanisms
and mitigate vulnerabilities. We carefully design system requirements through
collaboration with three experts in the field of AI security. The system
provides a comprehensive analysis of various jailbreak attack methods. By
incorporating layer-wise representation probing analysis, NeuroBreak offers a
novel perspective on the model's decision-making process throughout its
generation steps. Furthermore, the system supports the analysis of critical
neurons from both semantic and functional perspectives, facilitating a deeper
exploration of security mechanisms. We conduct quantitative evaluations and
case studies to verify the effectiveness of our system, offering mechanistic
insights for developing next-generation defense strategies against evolving
jailbreak attacks.
\\ ( https://arxiv.org/abs/2509.03985 ,  5038kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04011 (*cross-listing*)
Date: Thu, 4 Sep 2025 08:42:23 GMT   (2129kb)

Title: NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware
  Embeddings
Authors: Or Shachar, Uri Katz, Yoav Goldberg, Oren Glickman
Categories: cs.IR cs.AI cs.CL
Comments: Findings of EMNLP 2025
\\
  We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named
Entity Retrieval, a variant of Named Entity Recognition (NER), where the types
of interest are not provided in advance, and a user-defined type description is
used to retrieve documents mentioning entities of that type. Instead of relying
on fixed schemas or fine-tuned models, our method builds on internal
representations of large language models (LLMs) to embed both entity mentions
and user-provided open-ended type descriptions into a shared semantic space. We
show that internal representations, specifically the value vectors from
mid-layer transformer blocks, encode fine-grained type information more
effectively than commonly used top-layer embeddings. To refine these
representations, we train a lightweight contrastive projection network that
aligns type-compatible entities while separating unrelated types. The resulting
entity embeddings are compact, type-aware, and well-suited for nearest-neighbor
search. Evaluated on three benchmarks, NER Retriever significantly outperforms
both lexical and dense sentence-level retrieval baselines. Our findings provide
empirical support for representation selection within LLMs and demonstrate a
practical solution for scalable, schema-free entity retrieval. The NER
Retriever Codebase is publicly available at
https://github.com/ShacharOr100/ner_retriever
\\ ( https://arxiv.org/abs/2509.04011 ,  2129kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04051 (*cross-listing*)
Date: Thu, 4 Sep 2025 09:29:30 GMT   (7204kb)

Title: Neural Video Compression with In-Loop Contextual Filtering and
  Out-of-Loop Reconstruction Enhancement
Authors: Yaojun Wu, Chaoyi Lin, Yiming Wang, Semih Esenlik, Zhaobin Zhang, Kai
  Zhang, Li Zhang
Categories: eess.IV cs.AI
Comments: 9 pages, 8 figures, Accepted to ACMMM 2025
DOI: 10.1145/3746027.3755059
\\
  This paper explores the application of enhancement filtering techniques in
neural video compression. Specifically, we categorize these techniques into
in-loop contextual filtering and out-of-loop reconstruction enhancement based
on whether the enhanced representation affects the subsequent coding loop.
In-loop contextual filtering refines the temporal context by mitigating error
propagation during frame-by-frame encoding. However, its influence on both the
current and subsequent frames poses challenges in adaptively applying filtering
throughout the sequence. To address this, we introduce an adaptive coding
decision strategy that dynamically determines filtering application during
encoding. Additionally, out-of-loop reconstruction enhancement is employed to
refine the quality of reconstructed frames, providing a simple yet effective
improvement in coding efficiency. To the best of our knowledge, this work
presents the first systematic study of enhancement filtering in the context of
conditional-based neural video compression. Extensive experiments demonstrate a
7.71% reduction in bit rate compared to state-of-the-art neural video codecs,
validating the effectiveness of the proposed approach.
\\ ( https://arxiv.org/abs/2509.04051 ,  7204kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04076 (*cross-listing*)
Date: Thu, 4 Sep 2025 10:11:51 GMT   (1920kb)

Title: Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot
Authors: Lennart Clasmeier, Jan-Gerrit Habekost, Connor G\"ade, Philipp
  Allgeuer, and Stefan Wermter
Categories: cs.RO cs.AI
Comments: Submitted to ICANN 20255 Special Session on Neural Robotics
\\
  We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its output, we observed in our ablation study
that it remained challenging to condition the network on the point cloud
embeddings. We identified some biases in our dataset and refined it, which
improved the model's performance. Our model, even without the use of the point
cloud encodings, outperforms numerical models by an order of magnitude
regarding the runtime, while reaching a success rate of up to 90% of collision
free solutions on the test set.
\\ ( https://arxiv.org/abs/2509.04076 ,  1920kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04078 (*cross-listing*)
Date: Thu, 4 Sep 2025 10:13:21 GMT   (11597kb)

Title: RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging
  Evaluation of Large Language Models
Authors: Jingjing Liu, Zeming Liu, Zihao Cheng, Mengliang He, Xiaoming Shi,
  Yuhang Guo, Xiangrong Zhu, Yuanfang Guo, Yunhong Wang, Haifeng Wang
Categories: cs.SE cs.AI
Comments: 30 pages, 12 figures, EMNLP 2025 Findings
\\
  Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.
\\ ( https://arxiv.org/abs/2509.04078 ,  11597kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04118 (*cross-listing*)
Date: Thu, 4 Sep 2025 11:31:12 GMT   (377kb)

Title: EHVC: Efficient Hierarchical Reference and Quality Structure for Neural
  Video Coding
Authors: Junqi Liao, Yaojun Wu, Chaoyi Lin, Zhipin Deng, Li Li, Dong Liu,
  Xiaoyan Sun
Categories: eess.IV cs.AI
Comments: 9 pages, 8 figures, Accepted to ACMMM 2025
\\
  Neural video codecs (NVCs), leveraging the power of end-to-end learning, have
demonstrated remarkable coding efficiency improvements over traditional video
codecs. Recent research has begun to pay attention to the quality structures in
NVCs, optimizing them by introducing explicit hierarchical designs. However,
less attention has been paid to the reference structure design, which
fundamentally should be aligned with the hierarchical quality structure. In
addition, there is still significant room for further optimization of the
hierarchical quality structure. To address these challenges in NVCs, we propose
EHVC, an efficient hierarchical neural video codec featuring three key
innovations: (1) a hierarchical multi-reference scheme that draws on
traditional video codec design to align reference and quality structures,
thereby addressing the reference-quality mismatch; (2) a lookahead strategy to
utilize an encoder-side context from future frames to enhance the quality
structure; (3) a layer-wise quality scale with random quality training strategy
to stabilize quality structures during inference. With these improvements, EHVC
achieves significantly superior performance to the state-of-the-art NVCs. Code
will be released in: https://github.com/bytedance/NEVC.
\\ ( https://arxiv.org/abs/2509.04118 ,  377kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04129 (*cross-listing*)
Date: Thu, 4 Sep 2025 11:54:19 GMT   (43kb)

Title: Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on
  Controllers in Reactive Synthesis
Authors: Mickael Randour
Categories: cs.LO cs.AI cs.FL math.PR
Comments: Invited paper at RP 2025
\\
  In the game-theoretic approach to controller synthesis, we model the
interaction between a system to be controlled and its environment as a game
between these entities, and we seek an appropriate (e.g., winning or optimal)
strategy for the system. This strategy then serves as a formal blueprint for a
real-world controller. A common belief is that simple (e.g., using limited
memory) strategies are better: corresponding controllers are easier to conceive
and understand, and cheaper to produce and maintain.
  This invited contribution focuses on the complexity of strategies in a
variety of synthesis contexts. We discuss recent results concerning memory and
randomness, and take a brief look at what lies beyond our traditional notions
of complexity for strategies.
\\ ( https://arxiv.org/abs/2509.04129 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04139 (*cross-listing*)
Date: Thu, 4 Sep 2025 12:11:03 GMT   (779kb)

Title: Enhancing Technical Documents Retrieval for RAG
Authors: Songjiang Lai, Tsun-Hin Cheung, Ka-Chun Fung, Kaiwen Xue, Kwan-Ho Lin,
  Yan-Ming Choi, Vincent Ng, Kin-Man Lam
Categories: cs.IR cs.AI
\\
  In this paper, we introduce Technical-Embeddings, a novel framework designed
to optimize semantic retrieval in technical documentation, with applications in
both hardware and software development. Our approach addresses the challenges
of understanding and retrieving complex technical content by leveraging the
capabilities of Large Language Models (LLMs). First, we enhance user queries by
generating expanded representations that better capture user intent and improve
dataset diversity, thereby enriching the fine-tuning process for embedding
models. Second, we apply summary extraction techniques to encode essential
contextual information, refining the representation of technical documents. To
further enhance retrieval performance, we fine-tune a bi-encoder BERT model
using soft prompting, incorporating separate learning parameters for queries
and document context to capture fine-grained semantic nuances. We evaluate our
approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that
Technical-Embeddings significantly outperforms baseline models in both
precision and recall. Our findings highlight the effectiveness of integrating
query expansion and contextual summarization to enhance information access and
comprehension in technical domains. This work advances the state of
Retrieval-Augmented Generation (RAG) systems, offering new avenues for
efficient and accurate technical document retrieval in engineering and product
development workflows.
\\ ( https://arxiv.org/abs/2509.04139 ,  779kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04152 (*cross-listing*)
Date: Thu, 4 Sep 2025 12:25:14 GMT   (101kb)

Title: TAGAL: Tabular Data Generation using Agentic LLM Methods
Authors: Beno\^it Ronval, Pierre Dupont, Siegfried Nijssen
Categories: cs.LG cs.AI
\\
  The generation of data is a common approach to improve the performance of
machine learning tasks, among which is the training of models for
classification. In this paper, we present TAGAL, a collection of methods able
to generate synthetic tabular data using an agentic workflow. The methods
leverage Large Language Models (LLMs) for an automatic and iterative process
that uses feedback to improve the generated data without any further LLM
training. The use of LLMs also allows for the addition of external knowledge in
the generation process. We evaluate TAGAL across diverse datasets and different
aspects of quality for the generated data. We look at the utility of downstream
ML models, both by training classifiers on synthetic data only and by combining
real and synthetic data. Moreover, we compare the similarities between the real
and the generated data. We show that TAGAL is able to perform on par with
state-of-the-art approaches that require LLM training and generally outperforms
other training-free approaches. These findings highlight the potential of
agentic workflow and open new directions for LLM-based data generation methods.
\\ ( https://arxiv.org/abs/2509.04152 ,  101kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04154 (*cross-listing*)
Date: Thu, 4 Sep 2025 12:29:14 GMT   (2385kb)

Title: Attention as an Adaptive Filter
Authors: Peter Racioppo
Categories: cs.LG cs.AI
\\
  We introduce Adaptive Filter Attention (AFA), a novel attention mechanism
that incorporates a learnable dynamics model directly into the computation of
attention weights. Rather than comparing queries and keys directly, we model
the input sequence as discrete observations of a linear stochastic differential
equation (SDE). By imposing a linear dynamics model with simultaneously
diagonalizable state matrices and noise covariances, we can make use of a
closed-form solution to the differential Lyapunov equation to efficiently
propagate pairwise uncertainties through the dynamics. Attention naturally
arises as the maximum likelihood solution for this linear SDE, with attention
weights corresponding to robust residual-based reweightings of the propagated
pairwise precisions. Imposing an additional constraint on the state matrix's
eigenvalues leads to a simplified variant with the same computational and
memory complexity as standard attention. In the limit of vanishing dynamics and
process noise, and using a small-angle approximation, we recover ordinary
dot-product attention.
\\ ( https://arxiv.org/abs/2509.04154 ,  2385kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04166 (*cross-listing*)
Date: Thu, 4 Sep 2025 12:39:05 GMT   (5421kb)

Title: Crossing the Species Divide: Transfer Learning from Speech to Animal
  Sounds
Authors: Jules Cauzinille, Marius Miron, Olivier Pietquin, Masato Hagiwara,
  Ricard Marxer, Arnaud Rey and Benoit Favre
Categories: cs.LG cs.AI cs.CL cs.SD
Comments: 5 pages, 3 figures, uses dcase2025.sty, submitted to DCASE 2025
MSC-class: 68T07
ACM-class: I.5.4; I.2.6; H.5.5
\\
  Self-supervised speech models have demonstrated impressive performance in
speech processing, but their effectiveness on non-speech data remains
underexplored. We study the transfer learning capabilities of such models on
bioacoustic detection and classification tasks. We show that models such as
HuBERT, WavLM, and XEUS can generate rich latent representations of animal
sounds across taxa. We analyze the models properties with linear probing on
time-averaged representations. We then extend the approach to account for the
effect of time-wise information with other downstream architectures. Finally,
we study the implication of frequency range and noise on performance. Notably,
our results are competitive with fine-tuned bioacoustic pre-trained models and
show the impact of noise-robust pre-training setups. These findings highlight
the potential of speech-based self-supervised learning as an efficient
framework for advancing bioacoustic research.
\\ ( https://arxiv.org/abs/2509.04166 ,  5421kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04250 (*cross-listing*)
Date: Thu, 4 Sep 2025 14:23:35 GMT   (54kb)

Title: How many patients could we save with LLM priors?
Authors: Shota Arai, David Selby, Andrew Vargo, Sebastian Vollmer
Categories: stat.ME cs.AI cs.ET cs.IR stat.AP
Comments: 9 pages, 4 figures
\\
  Imagine a world where clinical trials need far fewer patients to achieve the
same statistical power, thanks to the knowledge encoded in large language
models (LLMs). We present a novel framework for hierarchical Bayesian modeling
of adverse events in multi-center clinical trials, leveraging LLM-informed
prior distributions. Unlike data augmentation approaches that generate
synthetic data points, our methodology directly obtains parametric priors from
the model. Our approach systematically elicits informative priors for
hyperparameters in hierarchical Bayesian models using a pre-trained LLM,
enabling the incorporation of external clinical expertise directly into
Bayesian safety modeling. Through comprehensive temperature sensitivity
analysis and rigorous cross-validation on real-world clinical trial data, we
demonstrate that LLM-derived priors consistently improve predictive performance
compared to traditional meta-analytical approaches. This methodology paves the
way for more efficient and expert-informed clinical trial design, enabling
substantial reductions in the number of patients required to achieve robust
safety assessment and with the potential to transform drug safety monitoring
and regulatory decision making.
\\ ( https://arxiv.org/abs/2509.04250 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04260 (*cross-listing*)
Date: Thu, 4 Sep 2025 14:38:28 GMT   (390kb)

Title: An Empirical Study of Vulnerabilities in Python Packages and Their
  Detection
Authors: Haowei Quan, Junjie Wang, Xinzhe Li, Terry Yue Zhuo, Xiao Chen,
  Xiaoning Du
Categories: cs.SE cs.AI cs.CR
\\
  In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.
\\ ( https://arxiv.org/abs/2509.04260 ,  390kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04288 (*cross-listing*)
Date: Thu, 4 Sep 2025 15:01:03 GMT   (2395kb)

Title: Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery
  Systems with Data-Driven Formal Verification
Authors: Rudi Coppola, Hovsep Touloujian, Pierfrancesco Ombrini, Manuel Mazo Jr
Categories: eess.SY cs.AI cs.SY
\\
  Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of
modern technology. In the last decades, the production and design of such
batteries and their adjacent embedded charging and safety protocols, denoted by
Battery Management Systems (BMS), has taken central stage. A fundamental
challenge to be addressed is the trade-off between the speed of charging and
the ageing behavior, resulting in the loss of capacity in the battery cell. We
rely on a high-fidelity physics-based battery model and propose an approach to
data-driven charging and safety protocol design. Following a
Counterexample-Guided Inductive Synthesis scheme, we combine Reinforcement
Learning (RL) with recent developments in data-driven formal methods to obtain
a hybrid control strategy: RL is used to synthesise the individual controllers,
and a data-driven abstraction guides their partitioning into a switched
structure, depending on the initial output measurements of the battery. The
resulting discrete selection among RL-based controllers, coupled with the
continuous battery dynamics, realises a hybrid system. When a design meets the
desired criteria, the abstraction provides probabilistic guarantees on the
closed-loop performance of the cell.
\\ ( https://arxiv.org/abs/2509.04288 ,  2395kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04303 (*cross-listing*)
Date: Thu, 4 Sep 2025 15:16:38 GMT   (454kb)

Title: HumAIne-Chatbot: Real-Time Personalized Conversational AI via
  Reinforcement Learning
Authors: Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira, Tomaz
  Saraiva, Philip Mavrepis, Georgios Fatouros, Dimosthenis Kyriazis
Categories: cs.HC cs.AI
Comments: 11 pages, 4 figures, IEEE conference format
\\
  Current conversational AI systems often provide generic, one-size-fits-all
interactions that overlook individual user characteristics and lack adaptive
dialogue management. To address this gap, we introduce
\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes
responses through a novel user profiling framework. The system is pre-trained
on a diverse set of GPT-generated virtual personas to establish a broad prior
over user types. During live interactions, an online reinforcement learning
agent refines per-user models by combining implicit signals (e.g. typing speed,
sentiment, engagement duration) with explicit feedback (e.g., likes and
dislikes). This profile dynamically informs the chatbot dialogue policy,
enabling real-time adaptation of both content and style. To evaluate the
system, we performed controlled experiments with 50 synthetic personas in
multiple conversation domains. The results showed consistent improvements in
user satisfaction, personalization accuracy, and task achievement when
personalization features were enabled. Statistical analysis confirmed
significant differences between personalized and nonpersonalized conditions,
with large effect sizes across key metrics. These findings highlight the
effectiveness of AI-driven user profiling and provide a strong foundation for
future real-world validation.
\\ ( https://arxiv.org/abs/2509.04303 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04337 (*cross-listing*)
Date: Thu, 4 Sep 2025 15:56:40 GMT   (295kb)

Title: Decoupled Entity Representation Learning for Pinterest Ads Ranking
Authors: Jie Liu, Yinrui Li, Jiankai Sun, Kungang Li, Han Sun, Sihan Wang,
  Huasen Wu, Siyuan Gao, Paulo Soares, Nan Li, Zhifang Liu, Haoyang Li, Siping
  Ji, Ling Leng, and Prathibha Deshikachar
Categories: cs.IR cs.AI cs.LG
\\
  In this paper, we introduce a novel framework following an
upstream-downstream paradigm to construct user and item (Pin) embeddings from
diverse data sources, which are essential for Pinterest to deliver personalized
Pins and ads effectively. Our upstream models are trained on extensive data
sources featuring varied signals, utilizing complex architectures to capture
intricate relationships between users and Pins on Pinterest. To ensure
scalability of the upstream models, entity embeddings are learned, and
regularly refreshed, rather than real-time computation, allowing for
asynchronous interaction between the upstream and downstream models. These
embeddings are then integrated as input features in numerous downstream tasks,
including ad retrieval and ranking models for CTR and CVR predictions. We
demonstrate that our framework achieves notable performance improvements in
both offline and online settings across various downstream tasks. This
framework has been deployed in Pinterest's production ad ranking systems,
resulting in significant gains in online metrics.
\\ ( https://arxiv.org/abs/2509.04337 ,  295kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04345 (*cross-listing*)
Date: Thu, 4 Sep 2025 16:03:44 GMT   (2029kb)

Title: AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open
  Worlds
Authors: Qizhou Wang, Hanxun Huang, Guansong Pang, Sarah Erfani, Christopher
  Leckie
Categories: cs.SD cs.AI cs.LG
\\
  Speech generation systems can produce remarkably realistic vocalisations that
are often indistinguishable from human speech, posing significant authenticity
challenges. Although numerous deepfake detection methods have been developed,
their effectiveness in real-world environments remains unrealiable due to the
domain shift between training and test samples arising from diverse human
speech and fast evolving speech synthesis systems. This is not adequately
addressed by current datasets, which lack real-world application challenges
with diverse and up-to-date audios in both real and deep-fake categories. To
fill this gap, we introduce AUDETER (AUdio DEepfake TEst Range), a large-scale,
highly diverse deepfake audio dataset for comprehensive evaluation and robust
development of generalised models for deepfake audio detection. It consists of
over 4,500 hours of synthetic audio generated by 11 recent TTS models and 10
vocoders with a broad range of TTS/vocoder patterns, totalling 3 million audio
clips, making it the largest deepfake audio dataset by scale. Through extensive
experiments with AUDETER, we reveal that i) state-of-the-art (SOTA) methods
trained on existing datasets struggle to generalise to novel deepfake audio
samples and suffer from high false positive rates on unseen human voice,
underscoring the need for a comprehensive dataset; and ii) these methods
trained on AUDETER achieve highly generalised detection performance and
significantly reduce detection error rate by 44.1% to 51.6%, achieving an error
rate of only 4.17% on diverse cross-domain samples in the popular In-the-Wild
dataset, paving the way for training generalist deepfake audio detectors.
AUDETER is available on GitHub.
\\ ( https://arxiv.org/abs/2509.04345 ,  2029kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04362 (*cross-listing*)
Date: Thu, 4 Sep 2025 16:22:29 GMT   (2053kb)

Title: Parking Availability Prediction via Fusing Multi-Source Data with A
  Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer
Authors: Yin Huang, Yongqi Dong, Youhua Tang, Li Li
Categories: cs.LG cs.AI stat.ML
Comments: 25 pages, 5 figures, under review for journal publication
\\
  The rapid growth of private car ownership has worsened the urban parking
predicament, underscoring the need for accurate and effective parking
availability prediction to support urban planning and management. To address
key limitations in modeling spatio-temporal dependencies and exploiting
multi-source data for parking availability prediction, this study proposes a
novel approach with SST-iTransformer. The methodology leverages K-means
clustering to establish parking cluster zones (PCZs), extracting and
integrating traffic demand characteristics from various transportation modes
(i.e., metro, bus, online ride-hailing, and taxi) associated with the targeted
parking lots. Upgraded on vanilla iTransformer, SST-iTransformer integrates
masking-reconstruction-based pretext tasks for self-supervised spatio-temporal
representation learning, and features an innovative dual-branch attention
mechanism: Series Attention captures long-term temporal dependencies via
patching operations, while Channel Attention models cross-variate interactions
through inverted dimensions. Extensive experiments using real-world data from
Chengdu, China, demonstrate that SST-iTransformer outperforms baseline deep
learning models (including Informer, Autoformer, Crossformer, and
iTransformer), achieving state-of-the-art performance with the lowest mean
squared error (MSE) and competitive mean absolute error (MAE). Comprehensive
ablation studies quantitatively reveal the relative importance of different
data sources: incorporating ride-hailing data provides the largest performance
gains, followed by taxi, whereas fixed-route transit features (bus/metro)
contribute marginally. Spatial correlation analysis further confirms that
excluding historical data from correlated parking lots within PCZs leads to
substantial performance degradation, underscoring the importance of modeling
spatial dependencies.
\\ ( https://arxiv.org/abs/2509.04362 ,  2053kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04398 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:10:01 GMT   (234kb)

Title: IPA: An Information-Preserving Input Projection Framework for Efficient
  Foundation Model Adaptation
Authors: Yuan Yin, Shashanka Venkataramanan, Tuan-Hung Vu, Andrei Bursuc,
  Matthieu Cord
Categories: cs.LG cs.AI
\\
  Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, reduce
adaptation cost by injecting low-rank updates into pretrained weights. However,
LoRA's down-projection is randomly initialized and data-agnostic, discarding
potentially useful information. Prior analyses show that this projection
changes little during training, while the up-projection carries most of the
adaptation, making the random input compression a performance bottleneck. We
propose IPA, a feature-aware projection framework that explicitly preserves
information in the reduced hidden space. In the linear case, we instantiate IPA
with algorithms approximating top principal components, enabling efficient
projector pretraining with negligible inference overhead. Across language and
vision benchmarks, IPA consistently improves over LoRA and DoRA, achieving on
average 1.5 points higher accuracy on commonsense reasoning and 2.3 points on
VTAB-1k, while matching full LoRA performance with roughly half the trainable
parameters when the projection is frozen.
\\ ( https://arxiv.org/abs/2509.04398 ,  234kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04404 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:16:26 GMT   (2059kb)

Title: No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in
  Resume Screening
Authors: Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, Aylin Caliskan
Categories: cs.CY cs.AI cs.CL cs.HC
Comments: Published in Proceedings of the 2025 AAAI/ACM Conference on AI,
  Ethics, and Society; code available at
  https://github.com/kyrawilson/No-Thoughts-Just-AI
ACM-class: K.4.2
\\
  In this study, we conduct a resume-screening experiment (N=528) where people
collaborate with simulated AI models exhibiting race-based preferences (bias)
to evaluate candidates for 16 high and low status occupations. Simulated AI
bias approximates factual and counterfactual estimates of racial bias in
real-world AI systems. We investigate people's preferences for White, Black,
Hispanic, and Asian candidates (represented through names and affinity groups
on quality-controlled resumes) across 1,526 scenarios and measure their
unconscious associations between race and status using implicit association
tests (IATs), which predict discriminatory hiring decisions but have not been
investigated in human-AI collaboration. When making decisions without AI or
with AI that exhibits no race-based preferences, people select all candidates
at equal rates. However, when interacting with AI favoring a particular group,
people also favor those candidates up to 90% of the time, indicating a
significant behavioral shift. The likelihood of selecting candidates whose
identities do not align with common race-status stereotypes can increase by 13%
if people complete an IAT before conducting resume screening. Finally, even if
people think AI recommendations are low quality or not important, their
decisions are still vulnerable to AI bias under certain circumstances. This
work has implications for people's autonomy in AI-HITL scenarios, AI and work,
design and evaluation of AI hiring systems, and strategies for mitigating bias
in collaborative decision-making tasks. In particular, organizational and
regulatory policy should acknowledge the complex nature of AI-HITL decision
making when implementing these systems, educating people who use them, and
determining which are subject to oversight.
\\ ( https://arxiv.org/abs/2509.04404 ,  2059kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04419 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:40:33 GMT   (440kb)

Title: Towards a Unified View of Large Language Model Post-Training
Authors: Xingtai Lv, Yuxin Zuo, Youbang Sun, Hongyi Liu, Yuntian Wei, Zhekai
  Chen, Lixuan He, Xuekai Zhu, Kaiyan Zhang, Bingning Wang, Ning Ding, Bowen
  Zhou
Categories: cs.LG cs.AI cs.CL
\\
  Two major sources of training data exist for post-training modern language
models: online (model-generated rollouts) data, and offline (human or
other-model demonstrations) data. These two types of data are typically used by
approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT),
respectively. In this paper, we show that these approaches are not in
contradiction, but are instances of a single optimization process. We derive a
Unified Policy Gradient Estimator, and present the calculations of a wide
spectrum of post-training approaches as the gradient of a common objective
under different data distribution assumptions and various bias-variance
tradeoffs. The gradient estimator is constructed with four interchangeable
parts: stabilization mask, reference policy denominator, advantage estimate,
and likelihood gradient. Motivated by our theoretical findings, we propose
Hybrid Post-Training (HPT), an algorithm that dynamically selects different
training signals. HPT is designed to yield both effective exploitation of
demonstration and stable exploration without sacrificing learned reasoning
patterns. We provide extensive experiments and ablation studies to verify the
effectiveness of our unified theoretical framework and HPT. Across six
mathematical reasoning benchmarks and two out-of-distribution suites, HPT
consistently surpasses strong baselines across models of varying scales and
families.
\\ ( https://arxiv.org/abs/2509.04419 ,  440kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04441 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:57:13 GMT   (3975kb)

Title: DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation
Authors: Hao-Shu Fang, Branden Romero, Yichen Xie, Arthur Hu, Bo-Ruei Huang,
  Juan Alvarez, Matthew Kim, Gabriel Margolis, Kavya Anbarasu, Masayoshi
  Tomizuka, Edward Adelson, Pulkit Agrawal
Categories: cs.RO cs.AI cs.CV cs.HC
Comments: project page: https://dex-op.github.io
\\
  We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (via proprioception) and mirrors
the human hand pose to the passive robot hand to maximize the transfer of
demonstrated skills to the robot. The force feedback and pose mirroring make
task demonstrations more natural for humans compared to teleoperation,
increasing both speed and accuracy. We evaluate DEXOP across a range of
dexterous, contact-rich tasks, demonstrating its ability to collect
high-quality demonstration data at scale. Policies learned with DEXOP data
significantly improve task performance per unit time of data collection
compared to teleoperation, making DEXOP a powerful tool for advancing robot
dexterity. Our project page is at https://dex-op.github.io.
\\ ( https://arxiv.org/abs/2509.04441 ,  3975kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04442 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:59:06 GMT   (282kb)

Title: Delta Activations: A Representation for Finetuned Large Language Models
Authors: Zhiqiu Xu, Amish Sethi, Mayur Naik, Ser-Nam Lim
Categories: cs.LG cs.AI cs.CL cs.IR
\\
  The success of powerful open source Large Language Models (LLMs) has enabled
the community to create a vast collection of post-trained models adapted to
specific tasks and domains. However, navigating and understanding these models
remains challenging due to inconsistent metadata and unstructured repositories.
We introduce Delta Activations, a method to represent finetuned models as
vector embeddings by measuring shifts in their internal activations relative to
a base model. This representation allows for effective clustering by domain and
task, revealing structure in the model landscape. Delta Activations also
demonstrate desirable properties: it is robust across finetuning settings and
exhibits an additive property when finetuning datasets are mixed. In addition,
we show that Delta Activations can embed tasks via few-shot finetuning, and
further explore its use for model selection and merging. We hope Delta
Activations can facilitate the practice of reusing publicly available models.
Code is available at https://github.com/OscarXZQ/delta_activations.
\\ ( https://arxiv.org/abs/2509.04442 ,  282kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04449 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:59:52 GMT   (6452kb)

Title: ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset
Authors: Adrian Catalin Lutu, Ioana Pintilie, Elena Burceanu, Andrei Manolache
Categories: cs.LG cs.AI
\\
  We present ChronoGraph, a graph-structured multivariate time series
forecasting dataset built from real-world production microservices. Each node
is a service that emits a multivariate stream of system-level performance
metrics, capturing CPU, memory, and network usage patterns, while directed
edges encode dependencies between services. The primary task is forecasting
future values of these signals at the service level. In addition, ChronoGraph
provides expert-annotated incident windows as anomaly labels, enabling
evaluation of anomaly detection methods and assessment of forecast robustness
during operational disruptions. Compared to existing benchmarks from industrial
control systems or traffic and air-quality domains, ChronoGraph uniquely
combines (i) multivariate time series, (ii) an explicit, machine-readable
dependency graph, and (iii) anomaly labels aligned with real incidents. We
report baseline results spanning forecasting models, pretrained time-series
foundation models, and standard anomaly detectors. ChronoGraph offers a
realistic benchmark for studying structure-aware forecasting and incident-aware
evaluation in microservice systems.
\\ ( https://arxiv.org/abs/2509.04449 ,  6452kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03787 (*cross-listing*)
Date: Thu, 4 Sep 2025 00:45:58 GMT   (185kb)

Title: Evaluating the Robustness of Retrieval-Augmented Generation to
  Adversarial Evidence in the Health Domain
Authors: Shakiba Amirshahi, Amin Bigdeli, Charles L. A. Clarke, Amira Ghenai
Categories: cs.IR cs.CL
\\
  Retrieval augmented generation (RAG) systems provide a method for factually
grounding the responses of a Large Language Model (LLM) by providing retrieved
evidence, or context, as support. Guided by this context, RAG systems can
reduce hallucinations and expand the ability of LLMs to accurately answer
questions outside the scope of their training data. Unfortunately, this design
introduces a critical vulnerability: LLMs may absorb and reproduce
misinformation present in retrieved evidence. This problem is magnified if
retrieved evidence contains adversarial material explicitly intended to
promulgate misinformation. This paper presents a systematic evaluation of RAG
robustness in the health domain and examines alignment between model outputs
and ground-truth answers. We focus on the health domain due to the potential
for harm caused by incorrect responses, as well as the availability of
evidence-based ground truth for many common health-related questions. We
conduct controlled experiments using common health questions, varying both the
type and composition of the retrieved documents (helpful, harmful, and
adversarial) as well as the framing of the question by the user (consistent,
neutral, and inconsistent). Our findings reveal that adversarial documents
substantially degrade alignment, but robustness can be preserved when helpful
evidence is also present in the retrieval pool. These findings offer actionable
insights for designing safer RAG systems in high-stakes domains by highlighting
the need for retrieval safeguards. To enable reproducibility and facilitate
future research, all experimental results are publicly available in our github
repository.
  https://github.com/shakibaam/RAG_ROBUSTNESS_EVAL
\\ ( https://arxiv.org/abs/2509.03787 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04072 (*cross-listing*)
Date: Thu, 4 Sep 2025 10:05:06 GMT   (1365kb)

Title: LibriQuote: A Speech Dataset of Fictional Character Utterances for
  Expressive Zero-Shot Speech Synthesis
Authors: Gaspard Michel and Elena V. Epure and Christophe Cerisara
Categories: eess.AS cs.CL cs.SD
\\
  Text-to-speech (TTS) systems have recently achieved more expressive and
natural speech synthesis by scaling to large speech datasets. However, the
proportion of expressive speech in such large-scale corpora is often unclear.
Besides, existing expressive speech corpora are typically smaller in scale and
primarily used for benchmarking TTS systems. In this paper, we introduce the
LibriQuote dataset, an English corpus derived from read audiobooks, designed
for both fine-tuning and benchmarking expressive zero-shot TTS system. The
training dataset includes 12.7K hours of read, non-expressive speech and 5.3K
hours of mostly expressive speech drawn from character quotations. Each
utterance in the expressive subset is supplemented with the context in which it
was written, along with pseudo-labels of speech verbs and adverbs used to
describe the quotation (\textit{e.g. ``he whispered softly''}). Additionally,
we provide a challenging 7.5 hour test set intended for benchmarking TTS
systems: given a neutral reference speech as input, we evaluate system's
ability to synthesize an expressive utterance while preserving reference
timbre. We validate qualitatively the test set by showing that it covers a wide
range of emotions compared to non-expressive speech, along with various
accents. Extensive subjective and objective evaluations show that fine-tuning a
baseline TTS system on LibriQuote significantly improves its synthesized speech
intelligibility, and that recent systems fail to synthesize speech as
expressive and natural as the ground-truth utterances. The dataset and
evaluation code are freely available. Audio samples can be found at
https://libriquote.github.io/.
\\ ( https://arxiv.org/abs/2509.04072 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04393 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:04:44 GMT   (532kb)

Title: Contextualized Token Discrimination for Speech Search Query Correction
Authors: Junyu Lu, Di Jiang, Mengze Hong, Victor Junqiu Wei, Qintian Guo,
  Zhiyang Su
Categories: cs.SD cs.CL
\\
  Query spelling correction is an important function of modern search engines
since it effectively helps users express their intentions clearly. With the
growing popularity of speech search driven by Automated Speech Recognition
(ASR) systems, this paper introduces a novel method named Contextualized Token
Discrimination (CTD) to conduct effective speech query correction. In CTD, we
first employ BERT to generate token-level contextualized representations and
then construct a composition layer to enhance semantic information. Finally, we
produce the correct query according to the aggregated token representation,
correcting the incorrect tokens by comparing the original token representations
and the contextualized representations. Extensive experiments demonstrate the
superior performance of our proposed method across all metrics, and we further
present a new benchmark dataset with erroneous ASR transcriptions to offer
comprehensive evaluations for audio query correction.
\\ ( https://arxiv.org/abs/2509.04393 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03623 (*cross-listing*)
Date: Wed, 3 Sep 2025 18:18:16 GMT   (3179kb)

Title: Revealing Fine Structure in Protoplanetary Disks with Physics
  Constrained Neural Fields
Authors: Aviad Levis, Nhan Luong, Richard Teague, Katherine. L. Bouman, Marcelo
  Barraza-Alfaro, Kevin Flaherty
Categories: astro-ph.EP cs.CV
\\
  Protoplanetary disks are the birthplaces of planets, and resolving their
three-dimensional structure is key to understanding disk evolution. The
unprecedented resolution of ALMA demands modeling approaches that capture
features beyond the reach of traditional methods. We introduce a computational
framework that integrates physics-constrained neural fields with differentiable
rendering and present RadJAX, a GPU-accelerated, fully differentiable line
radiative transfer solver achieving up to 10,000x speedups over conventional
ray tracers, enabling previously intractable, high-dimensional neural
reconstructions. Applied to ALMA CO observations of HD 163296, this framework
recovers the vertical morphology of the CO-rich layer, revealing a pronounced
narrowing and flattening of the emission surface beyond 400 au - a feature
missed by existing approaches. Our work establish a new paradigm for extracting
complex disk structure and advancing our understanding of protoplanetary
evolution.
\\ ( https://arxiv.org/abs/2509.03623 ,  3179kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03749 (*cross-listing*)
Date: Wed, 3 Sep 2025 22:24:55 GMT   (19751kb)

Title: Mapping on a Budget: Optimizing Spatial Data Collection for ML
Authors: Livia Betti, Farooq Sanni, Gnouyaro Sogoyou, Togbe Agbagla, Cullen
  Molitor, Tamma Carleton, Esther Rolf
Categories: cs.LG cs.CV
\\
  In applications across agriculture, ecology, and human development, machine
learning with satellite imagery (SatML) is limited by the sparsity of labeled
training data. While satellite data cover the globe, labeled training datasets
for SatML are often small, spatially clustered, and collected for other
purposes (e.g., administrative surveys or field measurements). Despite the
pervasiveness of this issue in practice, past SatML research has largely
focused on new model architectures and training algorithms to handle scarce
training data, rather than modeling data conditions directly. This leaves
scientists and policymakers who wish to use SatML for large-scale monitoring
uncertain about whether and how to collect additional data to maximize
performance. Here, we present the first problem formulation for the
optimization of spatial training data in the presence of heterogeneous data
collection costs and realistic budget constraints, as well as novel methods for
addressing this problem. In experiments simulating different problem settings
across three continents and four tasks, our strategies reveal substantial gains
from sample optimization. Further experiments delineate settings for which
optimized sampling is particularly effective. The problem formulation and
methods we introduce are designed to generalize across application domains for
SatML; we put special emphasis on a specific problem setting where our
coauthors can immediately use our findings to augment clustered agricultural
surveys for SatML monitoring in Togo.
\\ ( https://arxiv.org/abs/2509.03749 ,  19751kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03775 (*cross-listing*)
Date: Wed, 3 Sep 2025 23:40:17 GMT   (18386kb)

Title: ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast,
  Memory-Efficient Reconstruction
Authors: Sankeerth Durvasula, Sharanshangar Muhunthan, Zain Moustafa, Richard
  Chen, Ruofan Liang, Yushi Guan, Nilesh Ahuja, Nilesh Jain, Selvakumar
  Panneer, Nandita Vijaykumar
Categories: cs.GR cs.CV
\\
  3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.
\\ ( https://arxiv.org/abs/2509.03775 ,  18386kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03850 (*cross-listing*)
Date: Thu, 4 Sep 2025 03:24:35 GMT   (274kb)

Title: Data-Augmented Quantization-Aware Knowledge Distillation
Authors: Justin Kur, Kaiqi Zhao
Categories: cs.LG cs.CV
Comments: 10 pages, 2 figures
\\
  Quantization-aware training (QAT) and Knowledge Distillation (KD) are
combined to achieve competitive performance in creating low-bit deep learning
models. Existing KD and QAT works focus on improving the accuracy of quantized
models from the network output perspective by designing better KD loss
functions or optimizing QAT's forward and backward propagation. However,
limited attention has been given to understanding the impact of input
transformations, such as data augmentation (DA). The relationship between
quantization-aware KD and DA remains unexplored. In this paper, we address the
question: how to select a good DA in quantization-aware KD, especially for the
models with low precisions? We propose a novel metric which evaluates DAs
according to their capacity to maximize the Contextual Mutual Information--the
information not directly related to an image's label--while also ensuring the
predictions for each class are close to the ground truth labels on average. The
proposed method automatically ranks and selects DAs, requiring minimal training
overhead, and it is compatible with any KD or QAT algorithm. Extensive
evaluations demonstrate that selecting DA strategies using our metric
significantly improves state-of-the-art QAT and KD works across various model
architectures and datasets.
\\ ( https://arxiv.org/abs/2509.03850 ,  274kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04047 (*cross-listing*)
Date: Thu, 4 Sep 2025 09:28:20 GMT   (41804kb)

Title: TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface
  Scattering for Perlin Distributed Heterogeneous Media
Authors: Ashish Tiwari, Satyam Bhardwaj, Yash Bachwana, Parag Sarvoday Sahu,
  T.M.Feroz Ali, Bhargava Chintalapati, Shanmuganathan Raman
Categories: cs.GR cs.CV cs.LG
Comments: To appear in Pacific Graphics 2025 (CGF Journal Track), Project page:
  https://yashbachwana.github.io/TensoIS/
\\
  Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.
\\ ( https://arxiv.org/abs/2509.04047 ,  41804kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04058 (*cross-listing*)
Date: Thu, 4 Sep 2025 09:41:18 GMT   (9225kb)

Title: SMooGPT: Stylized Motion Generation using Large Language Models
Authors: Lei Zhong, Yi Yang, Changjian Li
Categories: cs.GR cs.CV
\\
  Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.
\\ ( https://arxiv.org/abs/2509.04058 ,  9225kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04107 (*cross-listing*)
Date: Thu, 4 Sep 2025 11:11:10 GMT   (6542kb)

Title: FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data
  Heterogeneity
Authors: Ozgu Goksu and Nicolas Pugeault
Categories: cs.LG cs.CV
Comments: The 3rd IEEE International Conference on Federated Learning
  Technologies and Applications (FLTA25)
\\
  Federated Learning (FL) provides decentralised model training, which
effectively tackles problems such as distributed data and privacy preservation.
However, the generalisation of global models frequently faces challenges from
data heterogeneity among clients. This challenge becomes even more pronounced
when datasets are limited in size and class imbalance. To address data
heterogeneity, we propose a novel method, \textit{FedQuad}, that explicitly
optimises smaller intra-class variance and larger inter-class variance across
clients, thereby decreasing the negative impact of model aggregation on the
global model over client representations. Our approach minimises the distance
between similar pairs while maximising the distance between negative pairs,
effectively disentangling client data in the shared feature space. We evaluate
our method on the CIFAR-10 and CIFAR-100 datasets under various data
distributions and with many clients, demonstrating superior performance
compared to existing approaches. Furthermore, we provide a detailed analysis of
metric learning-based strategies within both supervised and federated learning
paradigms, highlighting their efficacy in addressing representational learning
challenges in federated settings.
\\ ( https://arxiv.org/abs/2509.04107 ,  6542kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04145 (*cross-listing*)
Date: Thu, 4 Sep 2025 12:15:55 GMT   (6255kb)

Title: Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network
  Weight Space Diffusion
Authors: Dongliang Cao, Guoxing Sun, Marc Habermann, Florian Bernard
Categories: cs.GR cs.CV
\\
  Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.
\\ ( https://arxiv.org/abs/2509.04145 ,  6255kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04324 (*cross-listing*)
Date: Thu, 4 Sep 2025 15:42:36 GMT   (2027kb)

Title: OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent
  Detection
Authors: Chen Hu, Shan Luo, Letizia Gionfrida
Categories: cs.RO cs.CV
\\
  Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a vision-language foundation model with
an open-vocabulary mechanism, allowing zero-shot detection of previously unseen
objects without retraining. A multimodal decision-maker further fuses spatial
and linguistic cues to infer user intent, such as grasp or release, in
multi-object scenarios. We deploy the complete framework on a custom
egocentric-view wearable exoskeleton and conduct systematic evaluations on 15
objects across three grasp types. Experimental results with ten participants
demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%,
outperforming state-of-the-art baselines and achieving improved kinematic
alignment with natural hand motion.
\\ ( https://arxiv.org/abs/2509.04324 ,  2027kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04351 (*cross-listing*)
Date: Thu, 4 Sep 2025 16:12:14 GMT   (2930kb)

Title: Global-to-Local or Local-to-Global? Enhancing Image Retrieval with
  Efficient Local Search and Effective Global Re-ranking
Authors: Dror Aiger, Bingyi Cao, Kaifeng Chen, Andre Araujo
Categories: cs.IR cs.CV
\\
  The dominant paradigm in image retrieval systems today is to search large
databases using global image features, and re-rank those initial results with
local image feature matching techniques. This design, dubbed global-to-local,
stems from the computational cost of local matching approaches, which can only
be afforded for a small number of retrieved images. However, emerging efficient
local feature search approaches have opened up new possibilities, in particular
enabling detailed retrieval at large scale, to find partial matches which are
often missed by global feature search. In parallel, global feature-based
re-ranking has shown promising results with high computational efficiency. In
this work, we leverage these building blocks to introduce a local-to-global
retrieval paradigm, where efficient local feature search meets effective global
feature re-ranking. Critically, we propose a re-ranking method where global
features are computed on-the-fly, based on the local feature retrieval
similarities. Such re-ranking-only global features leverage multidimensional
scaling techniques to create embeddings which respect the local similarities
obtained during search, enabling a significant re-ranking boost.
Experimentally, we demonstrate solid retrieval performance, setting new
state-of-the-art results on the Revisited Oxford and Paris datasets.
\\ ( https://arxiv.org/abs/2509.04351 ,  2930kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04394 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:05:59 GMT   (8137kb)

Title: Transition Models: Rethinking the Generative Learning Objective
Authors: Zidong Wang, Yiyuan Zhang, Xiaoyu Yue, Xiangyu Yue, Yangguang Li,
  Wanli Ouyang, Lei Bai
Categories: cs.LG cs.CV
Comments: The code is released at https://github.com/WZDTHU/TiM
\\
  A fundamental dilemma in generative modeling persists: iterative diffusion
models achieve outstanding fidelity, but at a significant computational cost,
while efficient few-step alternatives are constrained by a hard quality
ceiling. This conflict between generation steps and output quality arises from
restrictive training objectives that focus exclusively on either infinitesimal
dynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by
introducing an exact, continuous-time dynamics equation that analytically
defines state transitions across any finite time interval. This leads to a
novel generative paradigm, Transition Models (TiM), which adapt to
arbitrary-step transitions, seamlessly traversing the generative trajectory
from single leaps to fine-grained refinement with more steps. Despite having
only 865M parameters, TiM achieves state-of-the-art performance, surpassing
leading models such as SD3.5 (8B parameters) and FLUX.1 (12B parameters) across
all evaluated step counts. Importantly, unlike previous few-step generators,
TiM demonstrates monotonic quality improvement as the sampling budget
increases. Additionally, when employing our native-resolution strategy, TiM
delivers exceptional fidelity at resolutions up to 4096x4096.
\\ ( https://arxiv.org/abs/2509.04394 ,  8137kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03660 (*cross-listing*)
Date: Wed, 3 Sep 2025 19:21:34 GMT   (9607kb)

Title: Semi-decentralized Federated Time Series Prediction with Client
  Availability Budgets
Authors: Yunkai Bao, Reza Safarzadeh, Xin Wang, Steve Drew
Categories: cs.LG cs.DC
\\
  Federated learning (FL) effectively promotes collaborative training among
distributed clients with privacy considerations in the Internet of Things (IoT)
scenarios. Despite of data heterogeneity, FL clients may also be constrained by
limited energy and availability budgets. Therefore, effective selection of
clients participating in training is of vital importance for the convergence of
the global model and the balance of client contributions. In this paper, we
discuss the performance impact of client availability with time-series data on
federated learning. We set up three different scenarios that affect the
availability of time-series data and propose FedDeCAB, a novel,
semi-decentralized client selection method applying probabilistic rankings of
available clients. When a client is disconnected from the server, FedDeCAB
allows obtaining partial model parameters from the nearest neighbor clients for
joint optimization, improving the performance of offline models and reducing
communication overhead. Experiments based on real-world large-scale taxi and
vessel trajectory datasets show that FedDeCAB is effective under highly
heterogeneous data distribution, limited communication budget, and dynamic
client offline or rejoining.
\\ ( https://arxiv.org/abs/2509.03660 ,  9607kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03945 (*cross-listing*)
Date: Thu, 4 Sep 2025 07:09:59 GMT   (979kb)

Title: Prob-GParareal: A Probabilistic Numerical Parallel-in-Time Solver for
  Differential Equations
Authors: Guglielmo Gattiglio, Lyudmila Grigoryeva, Massimiliano Tamborrino
Categories: stat.CO cs.DC cs.NA math.NA stat.ML
MSC-class: 65M55, 65M22, 65L05, 50G15, 65Y05
\\
  We introduce Prob-GParareal, a probabilistic extension of the GParareal
algorithm designed to provide uncertainty quantification for the
Parallel-in-Time (PinT) solution of (ordinary and partial) differential
equations (ODEs, PDEs). The method employs Gaussian processes (GPs) to model
the Parareal correction function, as GParareal does, further enabling the
propagation of numerical uncertainty across time and yielding probabilistic
forecasts of system's evolution. Furthermore, Prob-GParareal accommodates
probabilistic initial conditions and maintains compatibility with classical
numerical solvers, ensuring its straightforward integration into existing
Parareal frameworks. Here, we first conduct a theoretical analysis of the
computational complexity and derive error bounds of Prob-GParareal. Then, we
numerically demonstrate the accuracy and robustness of the proposed algorithm
on five benchmark ODE systems, including chaotic, stiff, and bifurcation
problems. To showcase the flexibility and potential scalability of the proposed
algorithm, we also consider Prob-nnGParareal, a variant obtained by replacing
the GPs in Parareal with the nearest-neighbors GPs, illustrating its increased
performance on an additional PDE example. This work bridges a critical gap in
the development of probabilistic counterparts to established PinT methods.
\\ ( https://arxiv.org/abs/2509.03945 ,  979kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04095 (*cross-listing*)
Date: Thu, 4 Sep 2025 10:53:27 GMT   (9923kb)

Title: Cloud-Assisted Remote Control for Aerial Robots: From Theory to
  Proof-of-Concept Implementation
Authors: Achilleas Santi Seisa, Viswa Narayanan Sankaranarayanan, Gerasimos
  Damigos, Sumeet Gajanan Satpute, George Nikolakopoulos
Categories: cs.RO cs.DC
Comments: 6 pages, 7 figures, CCGridW 2025
Journal-ref: 2025 IEEE 25th International Symposium on Cluster, Cloud and
  Internet Computing Workshops (CCGridW)
DOI: 10.1109/CCGridW65158.2025.00032
\\
  Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework consists of two main
components enabled by containerized technology: (a) a containerized cloud
cluster and (b) the containerized robot simulation environment. The system
incorporates two endpoints of a User Datagram Protocol (UDP) tunnel, enabling
bidirectional communication between the cloud cluster container and the robot
simulation environment, while simulating realistic network conditions. To
achieve this, we consider the use case of cloud-assisted remote control for
aerial robots, while utilizing Linux-based traffic control to introduce
artificial delay and jitter, replicating variable network conditions
encountered in practical cloud-robot deployments.
\\ ( https://arxiv.org/abs/2509.04095 ,  9923kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04277 (*cross-listing*)
Date: Thu, 4 Sep 2025 14:51:38 GMT   (1067kb)

Title: Massively-Parallel Implementation of Inextensible Elastic Rods Using
  Inter-block GPU Synchronization
Authors: Przemyslaw Korzeniowski, Niels Hald and Fernando Bello
Categories: cs.GR cs.DC
Comments: 12 pages, unpublished
MSC-class: 65D18
ACM-class: I.3.5
\\
  An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).
\\ ( https://arxiv.org/abs/2509.04277 ,  1067kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03638 (*cross-listing*)
Date: Wed, 3 Sep 2025 18:44:42 GMT   (7445kb)

Title: Cooperative Grasping for Collective Object Transport in Constrained
  Environments
Authors: David Alvear, George Turkiyyah, Shinkyu Park
Categories: cs.RO cs.MA
\\
  We propose a novel framework for decision-making in cooperative grasping for
two-robot object transport in constrained environments. The core of the
framework is a Conditional Embedding (CE) model consisting of two neural
networks that map grasp configuration information into an embedding space. The
resulting embedding vectors are then used to identify feasible grasp
configurations that allow two robots to collaboratively transport an object. To
ensure generalizability across diverse environments and object geometries, the
neural networks are trained on a dataset comprising a range of environment maps
and object shapes. We employ a supervised learning approach with negative
sampling to ensure that the learned embeddings effectively distinguish between
feasible and infeasible grasp configurations. Evaluation results across a wide
range of environments and objects in simulations demonstrate the model's
ability to reliably identify feasible grasp configurations. We further validate
the framework through experiments on a physical robotic platform, confirming
its practical applicability.
\\ ( https://arxiv.org/abs/2509.03638 ,  7445kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04198 (*cross-listing*)
Date: Thu, 4 Sep 2025 13:22:44 GMT   (610kb)

Title: Are LLM Agents the New RPA? A Comparative Study with RPA Across
  Enterprise Workflows
Authors: Petr Pr\r{u}cha, Michaela Matou\v{s}kov\'a, Jan Strnad
Categories: cs.CY cs.MA
\\
  The emergence of large language models (LLMs) has introduced a new paradigm
in automation: LLM agents or Agentic Automation with Computer Use (AACU).
Unlike traditional Robotic Process Automation (RPA), which relies on rule-based
workflows and scripting, AACU enables intelligent agents to perform tasks
through natural language instructions and autonomous interaction with user
interfaces. This study investigates whether AACU can serve as a viable
alternative to RPA in enterprise workflow automation. We conducted controlled
experiments across three standard RPA challenges data entry, monitoring, and
document extraction comparing RPA (via UiPath) and AACU (via Anthropic's
Computer Use Agent) in terms of speed, reliability, and development effort.
Results indicate that RPA outperforms AACU in execution speed and reliability,
particularly in repetitive, stable environments. However, AACU significantly
reduces development time and adapts more flexibly to dynamic interfaces. While
current AACU implementations are not yet production-ready, their promise in
rapid prototyping and lightweight automation is evident. Future research should
explore multi-agent orchestration, hybrid RPA-AACU architectures, and more
robust evaluation across industries and platforms.
\\ ( https://arxiv.org/abs/2509.04198 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04413 (*cross-listing*)
Date: Thu, 4 Sep 2025 17:34:59 GMT   (2563kb)

Title: SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety
  Certificates
Authors: Babak Esmaeili and Hamidreza Modares
Categories: eess.SY cs.LG cs.MA cs.RO cs.SY math.OC
Comments: Submitted to IEEE Transactions on Automation Science and Engineering
\\
  This paper proposes a fully data-driven motion-planning framework for
homogeneous linear multi-agent systems that operate in shared, obstacle-filled
workspaces without access to explicit system models. Each agent independently
learns its closed-loop behavior from experimental data by solving convex
semidefinite programs that generate locally invariant ellipsoids and
corresponding state-feedback gains. These ellipsoids, centered along grid-based
waypoints, certify the dynamic feasibility of short-range transitions and
define safe regions of operation. A sampling-based planner constructs a tree of
such waypoints, where transitions are allowed only when adjacent ellipsoids
overlap, ensuring invariant-to-invariant transitions and continuous safety. All
agents expand their trees simultaneously and are coordinated through a
space-time reservation table that guarantees inter-agent safety by preventing
simultaneous occupancy and head-on collisions. Each successful edge in the tree
is equipped with its own local controller, enabling execution without
re-solving optimization problems at runtime. The resulting trajectories are not
only dynamically feasible but also provably safe with respect to both
environmental constraints and inter-agent collisions. Simulation results
demonstrate the effectiveness of the approach in synthesizing synchronized,
safe trajectories for multiple agents under shared dynamics and constraints,
using only data and convex optimization tools.
\\ ( https://arxiv.org/abs/2509.04413 ,  2563kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2008.07324
replaced with revised version Wed, 3 Sep 2025 21:41:09 GMT   (4013kb)

Title: Intelligence Primer
Authors: Karl Fezer and Andrew Sloss
Categories: cs.AI cs.LG
Comments: 18 pages, 12 Figures
\\ ( https://arxiv.org/abs/2008.07324 ,  4013kb)
------------------------------------------------------------------------------
\\
arXiv:2311.17165
replaced with revised version Wed, 3 Sep 2025 21:45:18 GMT   (129kb)

Title: (Ir)rationality in AI: State of the Art, Research Challenges and Open
  Questions
Authors: Olivia Macmillan-Scott and Mirco Musolesi
Categories: cs.AI cs.CY cs.HC cs.LG cs.MA
Journal-ref: Artificial Intelligence Review 58, 352 (2025)
DOI: 10.1007/s10462-025-11341-4
\\ ( https://arxiv.org/abs/2311.17165 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2406.13923
replaced with revised version Thu, 4 Sep 2025 10:10:23 GMT   (3251kb)

Title: PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal
  Documents
Authors: Junjie Wang, Yuxiang Zhang, Minghao Liu, Yin Zhang, Yatai Ji, Weihao
  Xuan, Nie Lin, Kang Zhu, Zhiqiang Lin, Yiming Ren, Chunyang Jiang, Yiyao Yu,
  Zekun Wang, Tiezhen Wang, Wenhao Huang, Jie Fu, Qunshu Liu, Yujiu Yang, Ge
  Zhang, Ruibin Yuan, Bei Chen, Wenhu Chen
Categories: cs.AI cs.CL cs.CV cs.MM
Comments: Technical report v1.0
\\ ( https://arxiv.org/abs/2406.13923 ,  3251kb)
------------------------------------------------------------------------------
\\
arXiv:2410.08949
replaced with revised version Thu, 4 Sep 2025 02:10:45 GMT   (2991kb)

Title: Transferable Belief Model on Quantum Circuits
Authors: Qianli Zhou and Hao Luo and Lipeng Pan and Yong Deng and Eloi Bosse
Categories: cs.AI quant-ph
\\ ( https://arxiv.org/abs/2410.08949 ,  2991kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18970
replaced with revised version Thu, 4 Sep 2025 11:06:55 GMT   (3968kb)

Title: WASP: A Weight-Space Approach to Detecting Learned Spuriousness
Authors: Cristian Daniel P\u{a}duraru, Antonio B\u{a}rb\u{a}lau, Radu
  Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu
Categories: cs.AI cs.LG
Comments: under review
\\ ( https://arxiv.org/abs/2410.18970 ,  3968kb)
------------------------------------------------------------------------------
\\
arXiv:2412.05248
replaced with revised version Thu, 4 Sep 2025 11:42:04 GMT   (389kb)

Title: Enhancing FKG.in: automating Indian food composition analysis
Authors: Saransh Kumar Gupta, Lipika Dey, Partha Pratim Das, Geeta
  Trilok-Kumar, Ramesh Jain
Categories: cs.AI cs.CL cs.IR
Comments: 15 pages, 5 figures, 30 references, International Conference on
  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop
DOI: 10.1007/978-3-031-88217-3_6
\\ ( https://arxiv.org/abs/2412.05248 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17882
replaced with revised version Thu, 4 Sep 2025 01:28:51 GMT   (715kb)

Title: Science Across Languages: Assessing LLM Multilingual Translation of
  Scientific Papers
Authors: Hannah Calzi Kleidermacher, James Zou
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2502.17882 ,  715kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11671
replaced with revised version Wed, 3 Sep 2025 18:57:55 GMT   (509kb)

Title: Computational Basis of LLM's Decision Making in Social Simulation
Authors: Ji Ma
Categories: cs.AI cs.CY cs.LG econ.GN q-fin.EC
\\ ( https://arxiv.org/abs/2504.11671 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11701
replaced with revised version Thu, 4 Sep 2025 14:12:36 GMT   (774kb)

Title: DMN-Guided Prompting: A Framework for Controlling LLM Behavior
Authors: Shaghayegh Abedi and Amin Jalali
Categories: cs.AI
Comments: Large Language Models, Decision Model and Notation, Automated
  Feedback, Prompt Engineering
\\ ( https://arxiv.org/abs/2505.11701 ,  774kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03315
replaced with revised version Thu, 4 Sep 2025 09:04:10 GMT   (49kb)

Title: Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum
  as Fallback
Authors: Kai Sauerwald, Kenneth Skiba, Eduardo Ferm\'e and Thomas Meyer
Categories: cs.AI cs.LO
MSC-class: 03E99, 91B14
ACM-class: I.2.4
Journal-ref: Logics in Artificial Intelligence, JELIA 2025
DOI: 10.1007/978-3-032-04590-4_5
\\ ( https://arxiv.org/abs/2506.03315 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06052
replaced with revised version Thu, 4 Sep 2025 09:10:05 GMT   (1814kb)

Title: CP-Bench: Evaluating Large Language Models for Constraint Modelling
Authors: Kostis Michailidis, Dimos Tsouros, Tias Guns
Categories: cs.AI
Comments: ECAI 25
\\ ( https://arxiv.org/abs/2506.06052 ,  1814kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00401
replaced with revised version Thu, 4 Sep 2025 13:51:30 GMT   (566kb)

Title: Theory of Mind Using Active Inference: A Framework for Multi-Agent
  Cooperation
Authors: Riddhi J. Pitliya, Ozan \c{C}atal, Toon Van de Maele, Corrado Pezzato,
  Tim Verbelen
Categories: cs.AI cs.MA
\\ ( https://arxiv.org/abs/2508.00401 ,  566kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01700
replaced with revised version Thu, 4 Sep 2025 12:50:20 GMT   (2042kb)

Title: DeepVIS: Bridging Natural Language and Data Visualization Through
  Step-wise Reasoning
Authors: Zhihao Shuai, Boyan Li, Siyu Yan, Yuyu Luo, Weikai Yang
Categories: cs.AI
Comments: IEEE VIS 2025 full paper
\\ ( https://arxiv.org/abs/2508.01700 ,  2042kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16117
replaced with revised version Thu, 4 Sep 2025 11:54:35 GMT   (734kb)

Title: Extending FKG.in: Towards a Food Claim Traceability Network
Authors: Saransh Kumar Gupta, Rizwan Gulzar Mir, Lipika Dey, Partha Pratim Das,
  Anirban Sen, Ramesh Jain
Categories: cs.AI cs.CL cs.IR
Comments: 10 pages, 3 figures, 1 table, 45 references, ACM International
  Conference on Multimedia 2025 - Multi-modal Food Computing Workshop
DOI: 10.1145/3746264.3760496
\\ ( https://arxiv.org/abs/2508.16117 ,  734kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01909
replaced with revised version Thu, 4 Sep 2025 11:54:06 GMT   (5745kb)

Title: Oyster-I: Beyond Refusal -- Constructive Safety Alignment for
  Responsible Language Models
Authors: Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng,
  Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong,
  Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu,
  Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu,
  Yitong Yang, Jialing Tao, Hui Xue
Categories: cs.AI cs.CL cs.CY cs.HC cs.SC
Comments: Technical Report Code & Model weights available:
  https://github.com/Alibaba-AAIG/Oyster
\\ ( https://arxiv.org/abs/2509.01909 ,  5745kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01938
replaced with revised version Wed, 3 Sep 2025 20:43:51 GMT   (2945kb)

Title: EigenBench: A Comparative Behavioral Measure of Value Alignment
Authors: Jonathn Chang, Leonhard Piff, Suvadip Sana, Jasmine X. Li, Lionel
  Levine
Categories: cs.AI cs.CL cs.CY cs.LG
\\ ( https://arxiv.org/abs/2509.01938 ,  2945kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02761
replaced with revised version Thu, 4 Sep 2025 15:30:53 GMT   (925kb)

Title: Plan Verification for LLM-Based Embodied Task Completion Agents
Authors: Ananth Hariharan, Vardhan Dongre, Dilek Hakkani-T\"ur, Gokhan Tur
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.02761 ,  925kb)
------------------------------------------------------------------------------
\\
arXiv:2109.02325
replaced with revised version Thu, 4 Sep 2025 11:02:32 GMT   (0kb,I)

Title: MyProfessors: Mining Turkish Student Reviews
Authors: Ibrahim Faruk Ceylan and Necmettin Bera Calik
Categories: cs.CL
Comments: The paper is withdrawn due to the scraping errors in the dataset
  collection process and affected results
\\ ( https://arxiv.org/abs/2109.02325 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2305.06166
replaced with revised version Thu, 4 Sep 2025 08:56:39 GMT   (169kb)

Title: Mitigating Bias in Text Classification via Prompt-Based Text
  Transformation
Authors: Charmaine Barker and Dimitar Kazakov
Categories: cs.CL
Comments: This version corrects an error in the model specification
\\ ( https://arxiv.org/abs/2305.06166 ,  169kb)
------------------------------------------------------------------------------
\\
arXiv:2306.03774
replaced with revised version Thu, 4 Sep 2025 11:06:14 GMT   (6951kb)

Title: Exploring Linguistic Features for Turkish Text Readability
Authors: Ahmet Yavuz Uluslu and Gerold Schneider
Categories: cs.CL
\\ ( https://arxiv.org/abs/2306.03774 ,  6951kb)
------------------------------------------------------------------------------
\\
arXiv:2406.01359
replaced with revised version Thu, 4 Sep 2025 16:26:35 GMT   (13780kb)

Title: R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code
  Completion Abilities of Code Large Language Models
Authors: Ken Deng, Jiaheng Liu, He Zhu, Congnan Liu, Jingxin Li, Jiakai Wang,
  Peng Zhao, Chenchen Zhang, Yanan Wu, Xueqiao Yin, Yuanxing Zhang, Zizheng
  Zhan, Wenbo Su, Bangyu Xiang, Tiezheng Ge, Bo Zheng
Categories: cs.CL cs.SE
\\ ( https://arxiv.org/abs/2406.01359 ,  13780kb)
------------------------------------------------------------------------------
\\
arXiv:2411.01747
replaced with revised version Thu, 4 Sep 2025 16:22:32 GMT   (458kb)

Title: DynaSaur: Large Language Agents Beyond Predefined Actions
Authors: Dang Nguyen, Viet Dac Lai, Seunghyun Yoon, Ryan A. Rossi, Handong
  Zhao, Ruiyi Zhang, Puneet Mathur, Nedim Lipka, Yu Wang, Trung Bui, Franck
  Dernoncourt, Tianyi Zhou
Categories: cs.CL
Comments: Published as a conference paper at COLM 2025
\\ ( https://arxiv.org/abs/2411.01747 ,  458kb)
------------------------------------------------------------------------------
\\
arXiv:2411.12736
replaced with revised version Thu, 4 Sep 2025 17:56:24 GMT   (455kb)

Title: ACING: Actor-Critic for Instruction Learning in Black-Box LLMs
Authors: Salma Kharrat, Fares Fourati, Marco Canini
Categories: cs.CL cs.AI cs.LG cs.SY eess.SY math.OC
Comments: Accepted at EMNLP 2025
\\ ( https://arxiv.org/abs/2411.12736 ,  455kb)
------------------------------------------------------------------------------
\\
arXiv:2501.04316
replaced with revised version Thu, 4 Sep 2025 15:53:10 GMT   (5614kb)

Title: Small Changes, Large Consequences: Analyzing the Allocational Fairness
  of LLMs in Hiring Contexts
Authors: Preethi Seshadri, Hongyu Chen, Sameer Singh, Seraphina
  Goldfarb-Tarrant
Categories: cs.CL
\\ ( https://arxiv.org/abs/2501.04316 ,  5614kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11110
replaced with revised version Thu, 4 Sep 2025 14:01:21 GMT   (10948kb)

Title: Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large
  Language Models via a Multi-Paradigm Perspective
Authors: Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang,
  Xingxing Zhang, Ziyi Yang, Mahmoud Khademi, Hany Awadalla, Junjie Wang, Yujiu
  Yang, Furu Wei
Categories: cs.CL
Comments: Accepted to ACL 2025 (Main)
\\ ( https://arxiv.org/abs/2501.11110 ,  10948kb)
------------------------------------------------------------------------------
\\
arXiv:2501.13958
replaced with revised version Thu, 4 Sep 2025 14:24:19 GMT   (1094kb)

Title: A Survey of Graph Retrieval-Augmented Generation for Customized Large
  Language Models
Authors: Qinggang Zhang, Shengyuan Chen, Yuanchen Bei, Zheng Yuan, Huachi Zhou,
  Zijin Hong, Hao Chen, Yilin Xiao, Chuang Zhou, Yi Chang, Xiao Huang
Categories: cs.CL cs.AI cs.IR
\\ ( https://arxiv.org/abs/2501.13958 ,  1094kb)
------------------------------------------------------------------------------
\\
arXiv:2501.14701
replaced with revised version Thu, 4 Sep 2025 15:11:24 GMT   (659kb)

Title: An Unsupervised Natural Language Processing Pipeline for Assessing
  Referral Appropriateness
Authors: Vittorio Torri, Annamaria Bottelli, Michele Ercolanoni, Olivia Leoni,
  Francesca Ieva
Categories: cs.CL cs.LG
Comments: 49 pages, 10 figures
MSC-class: 68T50
ACM-class: I.2.7; J.1; J.3
\\ ( https://arxiv.org/abs/2501.14701 ,  659kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05982
replaced with revised version Wed, 3 Sep 2025 20:08:37 GMT   (1534kb)

Title: HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered
  Therapy Using LLM Agents
Authors: Mohammad Amin Abbasi, Farnaz Sadat Mirnezami, Ali Neshati, Hassan
  Naderi
Categories: cs.CL
\\ ( https://arxiv.org/abs/2502.05982 ,  1534kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11948
replaced with revised version Thu, 4 Sep 2025 01:22:12 GMT   (160kb)

Title: HalluEntity: Benchmarking and Understanding Entity-Level Hallucination
  Detection
Authors: Min-Hsuan Yeh, Max Kamachee, Seongheon Park, Yixuan Li
Categories: cs.CL
Comments: TMLR 2025
\\ ( https://arxiv.org/abs/2502.11948 ,  160kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12065
replaced with revised version Thu, 4 Sep 2025 12:43:14 GMT   (7893kb)

Title: Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical
  Definitions
Authors: Lan Zhang, Marco Valentino, Andre Freitas
Categories: cs.CL cs.FL
Comments: EMNLP 2025 Camera-Ready Version
\\ ( https://arxiv.org/abs/2502.12065 ,  7893kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12616
replaced with revised version Wed, 3 Sep 2025 18:04:05 GMT   (1708kb)

Title: Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions
Authors: Leonardo Ranaldi, Marco Valentino, Andr\`e Freitas
Categories: cs.CL
Report-no: 2025.acl.843
Journal-ref: 2025.acl-long.843
DOI: 10.18653/v1/2025.acl-long.843
\\ ( https://arxiv.org/abs/2502.12616 ,  1708kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14791
replaced with revised version Thu, 4 Sep 2025 14:58:09 GMT   (493kb)

Title: Rapid Word Learning Through Meta In-Context Learning
Authors: Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2502.14791 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18452
replaced with revised version Wed, 3 Sep 2025 19:00:37 GMT   (2652kb)

Title: FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in
  Object-Based Common Sense Reasoning for Disaster Response
Authors: Mollie Shichman, Claire Bonial, Austin Blodgett, Taylor Hudson,
  Francis Ferraro, Rachel Rudinger
Categories: cs.CL cs.AI
Comments: 8 pages, 3 figures, 5 tables
\\ ( https://arxiv.org/abs/2502.18452 ,  2652kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09454
replaced with revised version Thu, 4 Sep 2025 12:20:43 GMT   (256kb)

Title: Explicit Learning and the LLM in Machine Translation
Authors: Malik Marmonier, Rachel Bawden, Beno\^it Sagot
Categories: cs.CL
\\ ( https://arxiv.org/abs/2503.09454 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16561
replaced with revised version Thu, 4 Sep 2025 08:12:41 GMT   (228kb)

Title: FutureGen: A RAG-based Approach to Generate the Future Work of
  Scientific Article
Authors: Ibrahim Al Azher, Miftahul Jannat Mokarrama, Zhishuai Guo, Sagnik Ray
  Choudhury, Hamed Alhoori
Categories: cs.CL cs.LG
Comments: 12 pages, 6 figures, Accepted for publication at the Workshop on AI
  Principles in Science Communication (Ai4SC'25), held in conjunction with the
  IEEE eScience Conference 2025
\\ ( https://arxiv.org/abs/2503.16561 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:2503.21080
replaced with revised version Thu, 4 Sep 2025 15:06:27 GMT   (10777kb,D)

Title: EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming
  in Debt Recovery
Authors: Yunbo Long, Yuhan Liu, Liming Xu, Alexandra Brintrup
Categories: cs.CL
\\ ( https://arxiv.org/abs/2503.21080 ,  10777kb)
------------------------------------------------------------------------------
\\
arXiv:2504.12311
replaced with revised version Thu, 4 Sep 2025 10:49:13 GMT   (5733kb)

Title: Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer
Authors: Jianhua Liu, Liwen Cao, Yanru Wu, Zijie Zhao, Yang Li
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.12311 ,  5733kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14585
replaced with revised version Thu, 4 Sep 2025 11:31:24 GMT   (310kb)

Title: Context Reasoner: Incentivizing Reasoning Capability for Contextualized
  Privacy and Safety Compliance via Reinforcement Learning
Authors: Wenbin Hu, Haoran Li, Huihao Jing, Qi Hu, Ziqian Zeng, Sirui Han, Heli
  Xu, Tianshu Chu, Peizhao Hu, Yangqiu Song
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2505.14585 ,  310kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07900
replaced with revised version Thu, 4 Sep 2025 16:23:02 GMT   (1170kb)

Title: MiniCPM4: Ultra-Efficient LLMs on End Devices
Authors: MiniCPM Team: Chaojun Xiao, Yuxuan Li, Xu Han, Yuzhuo Bai, Jie Cai,
  Haotian Chen, Wentong Chen, Xin Cong, Ganqu Cui, Ning Ding, Shengda Fan,
  Yewei Fang, Zixuan Fu, Wenyu Guan, Yitong Guan, Junshao Guo, Yufeng Han,
  Bingxiang He, Yuxiang Huang, Baoxi Ji, Cunliang Kong, Qiuzuo Li, Siyuan Li,
  Wenhao Li, Xin Li, Yanghao Li, Yishan Li, Zhen Li, Dan Liu, Biyuan Lin,
  Yankai Lin, Xiang Long, Quanyu Lu, Yaxi Lu, Peiyan Luo, Hongya Lyu, Litu Ou,
  Yinxu Pan, Lushi Pu, Zekai Qu, Qundong Shi, Zijun Song, Jiayuan Su, Zhou Su,
  Ao Sun, Xianghui Sun, Peijun Tang, Fangzheng Wang, Feng Wang, Shuo Wang,
  Yudong Wang, Zheng Wang, Yesai Wu, Zhenyu Xiao, Jie Xie, Zihao Xie, Xiaoyue
  Xu, Yukun Yan, Jiarui Yuan, Jinqian Zhang, Kaihuo Zhang, Lei Zhang, Linyue
  Zhang, Xueren Zhang, Yudi Zhang, Hengyu Zhao, Weilin Zhao, Weilun Zhao, et
  al. (14 additional authors not shown)
Categories: cs.CL cs.AI
Comments: MiniCPM4 Technical Report
\\ ( https://arxiv.org/abs/2506.07900 ,  1170kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09556
replaced with revised version Thu, 4 Sep 2025 10:18:13 GMT   (95kb)

Title: MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for
  Speech Emotion Recognition in Naturalistic Conditions
Authors: Georgios Chatzichristodoulou, Despoina Kosmopoulou, Antonios Kritikos,
  Anastasia Poulopoulou, Efthymios Georgiou, Athanasios Katsamanis, Vassilis
  Katsouros, Alexandros Potamianos
Categories: cs.CL
Comments: Interspeech 2025
\\ ( https://arxiv.org/abs/2506.09556 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22141
replaced with revised version Wed, 3 Sep 2025 18:55:49 GMT   (955kb)

Title: DAPFAM: A Domain-Aware Family-level Dataset to benchmark cross domain
  patent retrieval
Authors: Iliass Ayaou (ICube), Denis Cavallucci (ICube), Hicham Chibane (ICube)
Categories: cs.CL cs.IR
\\ ( https://arxiv.org/abs/2506.22141 ,  955kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00454
replaced with revised version Thu, 4 Sep 2025 11:57:46 GMT   (1141kb)

Title: Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges
Authors: Yuqi Tang, Kehua Feng, Yunfeng Wang, Zhiwen Chen, Chengfei Lv, Gang
  Yu, Qiang Zhang, Keyan Ding
Categories: cs.CL
Comments: 15 pages, 2 pages, under review
\\ ( https://arxiv.org/abs/2508.00454 ,  1141kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06971
replaced with revised version Wed, 3 Sep 2025 19:00:02 GMT   (895kb)

Title: Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer
  Extraction
Authors: Mohamed Basem, Islam Oshallah, Ali Hamdi, Khaled Shaban, and Hozaifa
  Kassab
Categories: cs.CL cs.IR
Comments: 8 pages , 4 figures , Accepted in Aiccsa 2025 ,
  https://conferences.sigappfr.org/aiccsa2025/
\\ ( https://arxiv.org/abs/2508.06971 ,  895kb)
------------------------------------------------------------------------------
\\
arXiv:2508.14723
replaced with revised version Thu, 4 Sep 2025 15:58:17 GMT   (295kb)

Title: Transplant Then Regenerate: A New Paradigm for Text Data Augmentation
Authors: Guangzhan Wang, Hongyu Zhang, Beijun Shen, Xiaodong Gu
Categories: cs.CL cs.AI
Comments: Accepted by EMNLP 2025
\\ ( https://arxiv.org/abs/2508.14723 ,  295kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15478
replaced with revised version Thu, 4 Sep 2025 11:23:22 GMT   (3294kb)

Title: SLM-Bench: A Comprehensive Benchmark of Small Language Models on
  Environmental Impacts--Extended Version
Authors: Nghiem Thanh Pham, Tung Kieu, Duc-Manh Nguyen, Son Ha Xuan, Nghia
  Duong-Trung, Danh Le-Phuoc
Categories: cs.CL cs.CY cs.PF
Comments: 24 pages. An extended version of "SLM-Bench: A Comprehensive
  Benchmark of Small Language Models on Environmental Impacts" accepted at
  EMNLP 2025
\\ ( https://arxiv.org/abs/2508.15478 ,  3294kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19740
replaced with revised version Thu, 4 Sep 2025 09:08:29 GMT   (20159kb)

Title: Spotlight Attention: Towards Efficient LLM Generation via Non-linear
  Hashing-based KV Cache Retrieval
Authors: Wenhao Li and Yuxin Zhang and Gen Luo and Haiyuan Wan and Ziyang Gong
  and Fei Chao and Rongrong Ji
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.19740 ,  20159kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20038
replaced with revised version Thu, 4 Sep 2025 09:23:46 GMT   (8614kb)

Title: Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to
  Enhance LLM Safety Guardrail to Potential Attacks
Authors: Sheng Liu, Qiang Sheng, Danding Wang, Yang Li, Guang Yang, Juan Cao
Categories: cs.CL
Comments: EMNLP 2025 findings
\\ ( https://arxiv.org/abs/2508.20038 ,  8614kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20324
replaced with revised version Thu, 4 Sep 2025 15:36:07 GMT   (318kb)

Title: Can Compact Language Models Search Like Agents? Distillation-Guided
  Policy Optimization for Preserving Agentic RAG Capabilities
Authors: Rikuto Kotoge, Mai Nishimura, Jiaxin Ma
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.20324 ,  318kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20410
replaced with revised version Wed, 3 Sep 2025 23:48:21 GMT   (3805kb)

Title: UI-Bench: A Benchmark for Evaluating Design Capabilities of AI
  Text-to-App Tools
Authors: Sam Jung, Agustin Garcinuno, Spencer Mateega
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.20410 ,  3805kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01185
replaced with revised version Thu, 4 Sep 2025 17:22:16 GMT   (111kb)

Title: Modular Techniques for Synthetic Long-Context Data Generation in
  Language Model Training and Evaluation
Authors: Seganrasan Subramanian, Abhigya Verma
Categories: cs.CL cs.AI
Comments: 26 pages, 4 figures
\\ ( https://arxiv.org/abs/2509.01185 ,  111kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01221
replaced with revised version Thu, 4 Sep 2025 09:30:16 GMT   (827kb)

Title: DaMoC: Efficiently Selecting the Optimal Large Language Model for
  Fine-tuning Domain Tasks Based on Data and Model Compression
Authors: Wei Huang, Huang Wei, Yinggui Wang
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by EMNLP 2025
\\ ( https://arxiv.org/abs/2509.01221 ,  827kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02038
replaced with revised version Wed, 3 Sep 2025 22:50:00 GMT   (640kb)

Title: NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task
Authors: Bashar Talafha, Hawau Olamide Toyin, Peter Sullivan, AbdelRahim
  Elmadany, Abdurrahman Juma, Amirbek Djanibekov, Chiyu Zhang, Hamad Alshehhi,
  Hanan Aldarmaki, Mustafa Jarrar, Nizar Habash, Muhammad Abdul-Mageed
Categories: cs.CL cs.SD
\\ ( https://arxiv.org/abs/2509.02038 ,  640kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03020
replaced with revised version Thu, 4 Sep 2025 08:02:20 GMT   (373kb)

Title: Training LLMs to be Better Text Embedders through Bidirectional
  Reconstruction
Authors: Chang Su, Dengliang Shi, Siyuan Huang, Jintao Du, Changhua Meng, Yu
  Cheng, Weiqiang Wang, Zhouhan Lin
Categories: cs.CL cs.IR
Comments: accepted by EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2509.03020 ,  373kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03312
replaced with revised version Thu, 4 Sep 2025 17:49:20 GMT   (3445kb)

Title: AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?
Authors: Guibin Zhang, Junhao Wang, Junjie Chen, Wangchunshu Zhou, Kun Wang,
  Shuicheng Yan
Categories: cs.CL cs.MA
\\ ( https://arxiv.org/abs/2509.03312 ,  3445kb)
------------------------------------------------------------------------------
\\
arXiv:2309.16494
replaced with revised version Thu, 4 Sep 2025 09:03:13 GMT   (1234kb)

Title: Accurate and lightweight dehazing via multi-receptive-field non-local
  network and novel contrastive regularization
Authors: Zewei He, Zixuan Chen, Jinlei Li, Ziqian Lu, Xuecheng Sun, Hao Luo,
  Zhe-Ming Lu, Evangelos K. Markakis
Categories: cs.CV
Comments: submitted to the IEEE Journal for possible publication
\\ ( https://arxiv.org/abs/2309.16494 ,  1234kb)
------------------------------------------------------------------------------
\\
arXiv:2311.16507
replaced with revised version Thu, 4 Sep 2025 14:24:04 GMT   (10188kb)

Title: Straighter Flow Matching via a Diffusion-Based Coupling Prior
Authors: Siyu Xing, Jie Cao, Huaibo Huang, Haichao Shi, Xiao-Yu Zhang
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2311.16507 ,  10188kb)
------------------------------------------------------------------------------
\\
arXiv:2312.03993
replaced with revised version Thu, 4 Sep 2025 14:45:07 GMT   (7436kb)

Title: Style Transfer to Calvin and Hobbes comics using Stable Diffusion
Authors: Asvin Kumar Venkataramanan, Sloke Shrestha, Sundar Sripada
  Venugopalaswamy Sriraman
Categories: cs.CV cs.AI
Comments: Updated authorship
\\ ( https://arxiv.org/abs/2312.03993 ,  7436kb)
------------------------------------------------------------------------------
\\
arXiv:2405.06911
replaced with revised version Thu, 4 Sep 2025 12:21:13 GMT   (7000kb)

Title: Replication Study and Benchmarking of Real-Time Object Detection Models
Authors: Pierre-Luc Asselin, Vincent Coulombe, William Guimont-Martin, William
  Larriv\'ee-Hardy
Categories: cs.CV
Comments: Authors are presented in alphabetical order, each having equal
  contribution to the work
\\ ( https://arxiv.org/abs/2405.06911 ,  7000kb)
------------------------------------------------------------------------------
\\
arXiv:2405.11491
replaced with revised version Thu, 4 Sep 2025 04:49:14 GMT   (20520kb)

Title: BOSC: A Backdoor-based Framework for Open Set Synthetic Image
  Attribution
Authors: Jun Wang, Benedetta Tondi and Mauro Barni
Categories: cs.CV
DOI: 10.1109/TIFS.2025.3592531
\\ ( https://arxiv.org/abs/2405.11491 ,  20520kb)
------------------------------------------------------------------------------
\\
arXiv:2405.20188
replaced with revised version Thu, 4 Sep 2025 10:02:22 GMT   (42763kb)

Title: SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid
  Registration
Authors: Yuxin Yao and Bailin Deng and Junhui Hou and Juyong Zhang
Categories: cs.CV cs.GR
Comments: Accepted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence
DOI: 10.1109/TPAMI.2025.3598630
\\ ( https://arxiv.org/abs/2405.20188 ,  42763kb)
------------------------------------------------------------------------------
\\
arXiv:2408.05750
replaced with revised version Thu, 4 Sep 2025 16:38:49 GMT   (5176kb)

Title: FADE: A Dataset for Detecting Falling Objects around Buildings in Video
Authors: Zhigang Tu, Zitao Gao, Zhengbo Zhang, Chunluan Zhou, Junsong Yuan, Bo
  Du
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Information Forensics and Security
  (TIFS), 2025
\\ ( https://arxiv.org/abs/2408.05750 ,  5176kb)
------------------------------------------------------------------------------
\\
arXiv:2409.06002
replaced with revised version Thu, 4 Sep 2025 09:32:46 GMT   (11266kb)

Title: Enhanced Generative Data Augmentation for Semantic Segmentation via
  Stronger Guidance
Authors: Quang-Huy Che, Duc-Tri Le, Bich-Nga Pham, Duc-Khai Lam and Vinh-Tiep
  Nguyen
Categories: cs.CV
Comments: Published in ICPRAM 2025, ISBN 978-989-758-730-6, ISSN 2184-4313
Journal-ref: Proceedings of the 14th International Conference on Pattern
  Recognition Applications and Methods - ICPRAM (2025) 251-262
DOI: 10.5220/0013175900003905
\\ ( https://arxiv.org/abs/2409.06002 ,  11266kb)
------------------------------------------------------------------------------
\\
arXiv:2411.06119
replaced with revised version Thu, 4 Sep 2025 07:02:34 GMT   (9005kb)

Title: Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures
  for On-Device Image Generation
Authors: Sanchar Palit, Sathya Veera Reddy Dendi, Mallikarjuna Talluri, Raj
  Narayana Gadde
Categories: cs.CV cs.LG
Comments: presented at IJCNN 2025 poster track
\\ ( https://arxiv.org/abs/2411.06119 ,  9005kb)
------------------------------------------------------------------------------
\\
arXiv:2411.15537
replaced with revised version Thu, 4 Sep 2025 11:00:46 GMT   (6609kb)

Title: MUNBa: Machine Unlearning via Nash Bargaining
Authors: Jing Wu, Mehrtash Harandi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.15537 ,  6609kb)
------------------------------------------------------------------------------
\\
arXiv:2412.09465
replaced with revised version Wed, 3 Sep 2025 22:09:05 GMT   (12743kb)

Title: OFTSR: One-Step Flow for Image Super-Resolution with Tunable
  Fidelity-Realism Trade-offs
Authors: Yuanzhi Zhu, Ruiqing Wang, Shilin Lu, Junnan Li, Hanshu Yan, Kai Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.09465 ,  12743kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12722
replaced with revised version Thu, 4 Sep 2025 06:43:22 GMT   (3947kb)

Title: Defending LVLMs Against Vision Attacks through Partial-Perception
  Supervision
Authors: Qi Zhou, Tianlin Li, Qing Guo, Dongxia Wang, Yun Lin, Yang Liu, Jin
  Song Dong
Categories: cs.CV cs.AI cs.CR
Comments: Accepted to ICML 2025
\\ ( https://arxiv.org/abs/2412.12722 ,  3947kb)
------------------------------------------------------------------------------
\\
arXiv:2502.08352
replaced with revised version Thu, 4 Sep 2025 17:14:29 GMT   (27539kb)

Title: Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images
  with Depth and Normal Supervision
Authors: Tianle Liu, Shuangming Zhao, Wanshou Jiang, Bingxuan Guo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.08352 ,  27539kb)
------------------------------------------------------------------------------
\\
arXiv:2502.10118
replaced with revised version Thu, 4 Sep 2025 15:00:25 GMT   (5384kb)

Title: Image Embedding Sampling Method for Diverse Captioning
Authors: Sania Waheed, Na Min An
Categories: cs.CV cs.AI
Comments: 17 pages, 5 figures, 9 tables
\\ ( https://arxiv.org/abs/2502.10118 ,  5384kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14891
replaced with revised version Thu, 4 Sep 2025 02:53:35 GMT   (3594kb)

Title: CoDiff: Conditional Diffusion Model for Collaborative 3D Object
  Detection
Authors: Zhe Huang, Shuo Wang, Yongcai Wang, Lei Wang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2502.14891 ,  3594kb)
------------------------------------------------------------------------------
\\
arXiv:2502.20323
replaced with revised version Thu, 4 Sep 2025 05:17:20 GMT   (3696kb)

Title: ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model
Authors: Xuangeng Chu, Nabarun Goswami, Ziteng Cui, Hanqin Wang, Tatsuya Harada
Categories: cs.CV
Comments: SIGGRAPH Asia 2025, More video demonstrations, code, models and data
  can be found on our project website: http://xg-chu.site/project_artalk/
\\ ( https://arxiv.org/abs/2502.20323 ,  3696kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13756
replaced with revised version Wed, 3 Sep 2025 21:35:27 GMT   (6283kb)

Title: Fast rigid alignment of heterogeneous images in sliced Wasserstein
  distance
Authors: Yunpeng Shi, Amit Singer, Eric J. Verbeke
Categories: cs.CV cs.NA math.NA
\\ ( https://arxiv.org/abs/2503.13756 ,  6283kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20652
replaced with revised version Thu, 4 Sep 2025 13:19:09 GMT   (593kb)

Title: Imitating Radiological Scrolling: A Global-Local Attention Model for 3D
  Chest CT Volumes Multi-Label Anomaly Classification
Authors: Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel
Categories: cs.CV
Comments: 13 pages, 4 figures. Accepted for publication at MIDL 2025
\\ ( https://arxiv.org/abs/2503.20652 ,  593kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23746
replaced with revised version Thu, 4 Sep 2025 05:10:37 GMT   (5499kb)

Title: Short-video Propagation Influence Rating: A New Real-world Dataset and A
  New Large Graph Model
Authors: Dizhan Xue, Shengsheng Qian, Chuanrui Hu, Changsheng Xu
Categories: cs.CV cs.CL cs.LG cs.MM cs.SI
\\ ( https://arxiv.org/abs/2503.23746 ,  5499kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05774
replaced with revised version Thu, 4 Sep 2025 10:49:27 GMT   (21829kb)

Title: Transferable Mask Transformer: Cross-domain Semantic Segmentation with
  Region-adaptive Transferability Estimation
Authors: Jianhua Liu, Zhengyu Li, Yanru Wu, Jingge Wang, Yang Tan, Ruizhe Zhao,
  Guan Wang, Yang Li
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2504.05774 ,  21829kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13392
replaced with revised version Thu, 4 Sep 2025 03:45:36 GMT   (31748kb)

Title: POET: Supporting Prompting Creativity and Personalization with Automated
  Expansion of Text-to-Image Generation
Authors: Evans Xu Han, Alice Qian Zhang, Haiyi Zhu, Hong Shen, Paul Pu Liang,
  Jane Hsieh
Categories: cs.CV cs.HC
\\ ( https://arxiv.org/abs/2504.13392 ,  31748kb)
------------------------------------------------------------------------------
\\
arXiv:2505.02980
replaced with revised version Thu, 4 Sep 2025 15:06:07 GMT   (18993kb)

Title: Completing Spatial Transcriptomics Data for Gene Expression Prediction
  Benchmarking
Authors: Daniela Ruiz, Paula C\'ardenas, Leonardo Manrique, Daniela Vega,
  Gabriel M. Mejia, Pablo Arbel\'aez
Categories: cs.CV
Comments: arXiv admin note: substantial text overlap with arXiv:2407.13027
Journal-ref: Medical Image Analysis, Volume 106, 2025, 103754, ISSN 1361-8415
DOI: 10.1016/j.media.2025.103754
\\ ( https://arxiv.org/abs/2505.02980 ,  18993kb)
------------------------------------------------------------------------------
\\
arXiv:2505.03498
replaced with revised version Thu, 4 Sep 2025 17:50:32 GMT   (23521kb)

Title: Res-MoCoDiff: Residual-guided diffusion models for motion artifact
  correction in brain MRI
Authors: Mojtaba Safari, Shansong Wang, Qiang Li, Zach Eidex, Richard L.J. Qiu,
  Chih-Wei Chang, Hui Mao, and Xiaofeng Yang
Categories: cs.CV physics.med-ph
\\ ( https://arxiv.org/abs/2505.03498 ,  23521kb)
------------------------------------------------------------------------------
\\
arXiv:2505.03522
replaced with revised version Thu, 4 Sep 2025 04:08:12 GMT   (25780kb)

Title: Optimization of Module Transferability in Single Image Super-Resolution:
  Universality Assessment and Cycle Residual Blocks
Authors: Haotong Cheng, Zhiqi Zhang, Hao Li, Xinshang Zhang
Categories: cs.CV cs.AI
Comments: The paper has been accepted to IET Image Processing
\\ ( https://arxiv.org/abs/2505.03522 ,  25780kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07611
replaced with revised version Thu, 4 Sep 2025 09:28:05 GMT   (894kb)

Title: Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A
  Comprehensive Review of Methods, Datasets, and Future Directions
Authors: Ruonan Lin, Tao Tang, Yongtai Liu, Wenye Zhou, Xin Yang, Hao Zheng,
  Jianpu Lin and Yi Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.07611 ,  894kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10823
replaced with revised version Wed, 3 Sep 2025 20:41:40 GMT   (12084kb)

Title: From Embeddings to Accuracy: Comparing Foundation Models for
  Radiographic Classification
Authors: Xue Li, Jameson Merkow, Noel C. F. Codella, Alberto Santamaria-Pang,
  Naiteek Sangani, Alexander Ersoy, Christopher Burt, John W. Garrett, Richard
  J. Bruce, Joshua D. Warner, Tyler Bradshaw, Ivan Tarapov, Matthew P. Lungren,
  Alan B. McMillan
Categories: cs.CV eess.IV
Comments: 12 pages, 5 figures, 4 tables
\\ ( https://arxiv.org/abs/2505.10823 ,  12084kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20789
replaced with revised version Thu, 4 Sep 2025 07:37:08 GMT   (13481kb)

Title: Integrating Intermediate Layer Optimization and Projected Gradient
  Descent for Solving Inverse Problems with Diffusion Models
Authors: Yang Zheng, Wen Li, Zhaoqiang Liu
Categories: cs.CV cs.LG
Comments: ICML 2025
\\ ( https://arxiv.org/abs/2505.20789 ,  13481kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23525
replaced with revised version Thu, 4 Sep 2025 07:13:25 GMT   (9607kb)

Title: Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference
  Optimization and Temporal Motion Modulation
Authors: Jiahao Cui, Yan Chen, Mingwang Xu, Hanlin Shang, Yuxuan Chen, Yun
  Zhan, Zilong Dong, Yao Yao, Jingdong Wang, Siyu Zhu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.23525 ,  9607kb)
------------------------------------------------------------------------------
\\
arXiv:2506.05195
replaced with revised version Thu, 4 Sep 2025 00:40:57 GMT   (12431kb)

Title: Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven
  Angle-of-Arrival Estimation
Authors: Josue Marroquin, Nan Inzali, Miles Dillon Lantz, Campbell Freeman,
  Amod Ashtekar, \\Ajinkya Umesh Mulik, and Mohammed E Eltayeb
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.05195 ,  12431kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01587
replaced with revised version Thu, 28 Aug 2025 14:37:33 GMT   (1852kb)

Title: Towards Controllable Real Image Denoising with Camera Parameters
Authors: Youngjin Oh, Junhyeong Kwon, Keuntek Lee, Nam Ik Cho
Categories: cs.CV eess.IV
Comments: Published in 2025 IEEE International Conference on Image Processing
  (ICIP)
DOI: 10.1109/ICIP55913.2025.11084351
\\ ( https://arxiv.org/abs/2507.01587 ,  1852kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06949
replaced with revised version Thu, 4 Sep 2025 16:39:57 GMT   (43299kb)

Title: Ecological Legacies of Pre-Columbian Settlements Evident in Palm
  Clusters of Neotropical Mountain Forests
Authors: Sebastian Fajardo, Sina Mohammadi, Jonas Gregorio de Souza, C\'esar
  Ardila, Alan Tapscott Baltar, Shaddai Heidgen, Maria Isabel Mayorga
  Hern\'andez, Sylvia Mota de Oliveira, Fernando Montejo, Marco Moderato,
  Vinicius Peripato, Katy Puche, Carlos Reina, Juan Carlos Vargas, Frank W.
  Takes, Marco Madella
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.06949 ,  43299kb)
------------------------------------------------------------------------------
\\
arXiv:2507.12964
replaced with revised version Thu, 4 Sep 2025 16:55:10 GMT   (3261kb)

Title: Demographic-aware fine-grained classification of pediatric wrist
  fractures
Authors: Ammar Ahmed, Ali Shariq Imran, Zenun Kastrati, Sher Muhammad Daudpota
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2507.12964 ,  3261kb)
------------------------------------------------------------------------------
\\
arXiv:2507.14904
replaced with revised version Thu, 4 Sep 2025 13:42:44 GMT   (698kb)

Title: TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D
  Visual Grounding based on CLIP
Authors: Fan Li, Zanyi Wang, Zeyi Huang, Guang Dai, Jingdong Wang, Mengmeng
  Wang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2507.14904 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2507.15269
replaced with revised version Thu, 4 Sep 2025 09:36:19 GMT   (0kb,I)

Title: Conditional Video Generation for High-Efficiency Video Compression
Authors: Fangqiu Yi, Jingyu Xu, Jiawei Shao, Chi Zhang, Xuelong Li
Categories: cs.CV cs.AI
Comments: Critical methodology flaws invalidate key results
\\ ( https://arxiv.org/abs/2507.15269 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22627
replaced with revised version Thu, 4 Sep 2025 13:26:56 GMT   (10847kb)

Title: LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text
  Pairing
Authors: Federico Girella, Davide Talon, Ziyue Liu, Zanxi Ruan, Yiming Wang and
  Marco Cristani
Categories: cs.CV cs.AI
Comments: Accepted at ICCV25 (Oral). Project page:
  https://intelligolabs.github.io/lots/
\\ ( https://arxiv.org/abs/2507.22627 ,  10847kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23357
replaced with revised version Thu, 4 Sep 2025 07:47:30 GMT   (6034kb)

Title: Foundations and Models in Modern Computer Vision: Key Building Blocks in
  Landmark Architectures
Authors: Radu-Andrei Bourceanu, Neil De La Fuente, Jan Grimm, Andrei Jardan,
  Andriy Manucharyan, Cornelius Weiss, Daniel Cremers and Roman Pflugfelder
Categories: cs.CV
Report-no: IN45023-SS-2025
\\ ( https://arxiv.org/abs/2507.23357 ,  6034kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10868
replaced with revised version Wed, 3 Sep 2025 18:01:47 GMT   (24304kb)

Title: TexVerse: A Universe of 3D Objects with High-Resolution Textures
Authors: Yibo Zhang and Li Zhang and Rui Ma and Nan Cao
Categories: cs.CV
Comments: https://github.com/yiboz2001/TexVerse
\\ ( https://arxiv.org/abs/2508.10868 ,  24304kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13238
replaced with revised version Thu, 4 Sep 2025 08:05:29 GMT   (576kb)

Title: DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool
  Interleaved Vision-Language Model
Authors: Qian Chen, Xianyin Zhang, Lifan Guo, Feng Chen, Chi Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.13238 ,  576kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15387
replaced with revised version Thu, 4 Sep 2025 15:15:09 GMT   (2767kb)

Title: DIO: Refining Mutual Information and Causal Chain to Enhance Machine
  Abstract Reasoning Ability
Authors: Ruizhuo Song, Beiming Yuan
Categories: cs.CV
Comments: 15 pages, 9 figures, 8 tables
\\ ( https://arxiv.org/abs/2508.15387 ,  2767kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17832
replaced with revised version Thu, 4 Sep 2025 09:06:17 GMT   (5329kb)

Title: HLG: Comprehensive 3D Room Construction via Hierarchical Layout
  Generation
Authors: Xiping Wang, Yuxi Wang, Mengqi Zhou, Junsong Fan, and Zhaoxiang Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.17832 ,  5329kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18733
replaced with revised version Thu, 4 Sep 2025 14:22:42 GMT   (1634kb)

Title: Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from
  Vector Drawings
Authors: Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang
  Liu
Categories: cs.CV
Comments: Accepted to ACM MM 2025
\\ ( https://arxiv.org/abs/2508.18733 ,  1634kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19762
replaced with revised version Thu, 4 Sep 2025 08:58:39 GMT   (18kb)

Title: BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions
Authors: Ahmed Emam, Mohamed Elbassiouny, Julius Miller, Patrick Donworth,
  Sabine Seidel, Ribana Roscher
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.19762 ,  18kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00451
replaced with revised version Thu, 4 Sep 2025 08:19:24 GMT   (9094kb)

Title: Encoder-Only Image Registration
Authors: Xiang Chen, Renjiu Hu, Jinwei Zhang, Yuxi Zhang, Xinyao Yue, Min Liu,
  Yaonan Wang, Hang Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.00451 ,  9094kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01563
replaced with revised version Thu, 4 Sep 2025 03:24:09 GMT   (28726kb)

Title: Kwai Keye-VL 1.5 Technical Report
Authors: Biao Yang, Bin Wen, Boyang Ding, Changyi Liu, Chenglong Chu, Chengru
  Song, Chongling Rao, Chuan Yi, Da Li, Dunju Zang, Fan Yang, Guorui Zhou,
  Guowang Zhang, Han Shen, Hao Peng, Haojie Ding, Hao Wang, Haonan Fang,
  Hengrui Ju, Jiaming Huang, Jiangxia Cao, Jiankang Chen, Jingyun Hua, Kaibing
  Chen, Kaiyu Jiang, Kaiyu Tang, Kun Gai, Muhao Wei, Qiang Wang, Ruitao Wang,
  Sen Na, Shengnan Zhang, Siyang Mao, Sui Huang, Tianke Zhang, Tingting Gao,
  Wei Chen, Wei Yuan, Xiangyu Wu, Xiao Hu, Xingyu Lu, Yi-Fan Zhang, Yiping
  Yang, Yulong Chen, Zeyi Lu, Zhenhua Wu, Zhixin Ling, Zhuoran Yang, Ziming Li,
  Di Xu, Haixuan Gao, Hang Li, Jing Wang, Lejian Ren, Qigen Hu, Qianqian Wang,
  Shiyao Wang, Xinchen Luo, Yan Li, Yuhang Hu, Zixing Zhang
Categories: cs.CV
Comments: Github page: https://github.com/Kwai-Keye/Keye
\\ ( https://arxiv.org/abs/2509.01563 ,  28726kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02175
replaced with revised version Thu, 4 Sep 2025 16:38:44 GMT   (32572kb)

Title: Understanding Space Is Rocket Science -- Only Top Reasoning Models Can
  Solve Spatial Understanding Tasks
Authors: Nils Hoehing, Mayug Maniparambil, Ellen Rushe, Noel E. O'Connor,
  Anthony Ventresque
Categories: cs.CV cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.02175 ,  32572kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01228
replaced with revised version Wed, 3 Sep 2025 20:54:57 GMT   (235kb)

Title: ConServe: Fine-Grained GPU Harvesting for LLM Online and Offline
  Co-Serving
Authors: Yifan Qiao, Shu Anzai, Shan Yu, Haoran Ma, Shuo Yang, Yang Wang,
  Miryung Kim, Yongji Wu, Yang Zhou, Jiarong Xing, Joseph E. Gonzalez, Ion
  Stoica, Harry Xu
Categories: cs.DC cs.LG
\\ ( https://arxiv.org/abs/2410.01228 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12084
replaced with revised version Thu, 4 Sep 2025 15:21:11 GMT   (551kb)

Title: Dissecting the NVIDIA Hopper Architecture through Microbenchmarking and
  Multiple Level Analysis
Authors: Weile Luo, Ruibo Fan, Zeyu Li, Dayou Du, Hongyuan Liu, Qiang Wang,
  Xiaowen Chu
Categories: cs.DC cs.AR cs.PF
Comments: arXiv admin note: substantial text overlap with arXiv:2402.13499
\\ ( https://arxiv.org/abs/2501.12084 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02025
replaced with revised version Wed, 3 Sep 2025 20:30:47 GMT   (966kb)

Title: Evaluating the Efficacy of LLM-Based Reasoning for Multiobjective HPC
  Job Scheduling
Authors: Prachi Jadhav, Hongwei Jin, Ewa Deelman, Prasanna Balaprakash
Categories: cs.DC cs.AI
Comments: 10 pages, 6 figures, work under review
\\ ( https://arxiv.org/abs/2506.02025 ,  966kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04420
replaced with revised version Thu, 4 Sep 2025 17:52:44 GMT   (133kb)

Title: Skipper: Maximal Matching with a Single Pass over Edges
Authors: Mohsen Koohi Esfahani
Categories: cs.DC
\\ ( https://arxiv.org/abs/2507.04420 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03513
replaced with revised version Thu, 4 Sep 2025 03:06:29 GMT   (2499kb)

Title: Understanding the Landscape of Ampere GPU Memory Errors
Authors: Zhu Zhu, Yu Sun, Dhatri Parakal, Bo Fang, Steven Farrell, Gregory H.
  Bauer, Brett Bode, Ian T. Foster, Michael E. Papka, William Gropp, Zhao
  Zhang, Lishan Yang
Categories: cs.DC
\\ ( https://arxiv.org/abs/2508.03513 ,  2499kb)
------------------------------------------------------------------------------
\\
arXiv:2211.12143
replaced with revised version Thu, 4 Sep 2025 15:52:13 GMT   (2743kb)

Title: Autonomation, Not Automation: Activities and Needs of European
  Fact-checkers as a Basis for Designing Human-Centered AI Systems
Authors: Andrea Hrckova, Robert Moro, Ivan Srba, Jakub Simko, Maria Bielikova
Categories: cs.CY cs.AI cs.HC
Comments: 44 pages, 13 figures, 2 annexes. Accepted to ACM Journal on
  Responsible Computing
DOI: 10.1145/3764592
\\ ( https://arxiv.org/abs/2211.12143 ,  2743kb)
------------------------------------------------------------------------------
\\
arXiv:2403.03726
replaced with revised version Thu, 4 Sep 2025 11:13:05 GMT   (9849kb)

Title: Diffusion on language model encodings for protein sequence generation
Authors: Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov, Fedor
  Nikolaev, Nikita Ivanisenko, Olga Kardymon, Dmitry Vetrov
Categories: cs.LG cs.AI q-bio.BM
\\ ( https://arxiv.org/abs/2403.03726 ,  9849kb)
------------------------------------------------------------------------------
\\
arXiv:2405.08965
replaced with revised version Wed, 3 Sep 2025 21:19:19 GMT   (3661kb)

Title: MTP: A Meaning-Typed Language Abstraction for AI-Integrated Programming
Authors: Jayanaka L. Dantanarayana, Yiping Kang, Kugesan Sivasothynathan,
  Christopher Clarke, Baichuan Li, Savini Kashmira, Krisztian Flautner, Lingjia
  Tang, Jason Mars
Categories: cs.PL cs.AI
Comments: OOPSLA 2025
\\ ( https://arxiv.org/abs/2405.08965 ,  3661kb)
------------------------------------------------------------------------------
\\
arXiv:2405.17527
replaced with revised version Thu, 4 Sep 2025 14:38:34 GMT   (15759kb)

Title: Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE
  Solvers
Authors: Hang Zhou, Yuezhou Ma, Haixu Wu, Haowen Wang, Mingsheng Long
Categories: cs.LG cs.AI cs.NA math.NA
\\ ( https://arxiv.org/abs/2405.17527 ,  15759kb)
------------------------------------------------------------------------------
\\
arXiv:2407.15161
replaced with revised version Thu, 4 Sep 2025 14:07:56 GMT   (32235kb)

Title: FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via
  Flow Variational Inference
Authors: Qian Feng, Jianxiang Feng, Zhaopeng Chen, Rudolph Triebel, Alois Knoll
Categories: cs.RO cs.AI cs.LG
Comments: First two authors contributed equally, whose ordering decided via
  coin-tossing. Accepted for CoRL 2025
\\ ( https://arxiv.org/abs/2407.15161 ,  32235kb)
------------------------------------------------------------------------------
\\
arXiv:2407.15869
replaced with revised version Thu, 4 Sep 2025 01:16:59 GMT   (0kb,I)

Title: Long Input Sequence Network for Long Time Series Forecasting
Authors: Chao Ma, Yikai Hou, Xiang Li, Yinggang Sun, Haining Yu
Categories: cs.LG cs.AI
Comments: rewrite and authorship changing
\\ ( https://arxiv.org/abs/2407.15869 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2410.02807 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 14:13:49 GMT   (770kb)

Title: AutoPETIII: The Tracer Frontier. What Frontier?
Authors: Zacharia Mesbah, L\'eo Mottay, Romain Modzelewski, Pierre Decazes,
  S\'ebastien Hapdey, Su Ruan, S\'ebastien Thureau
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2410.02807 ,  770kb)
------------------------------------------------------------------------------
\\
arXiv:2410.12124
replaced with revised version Sun, 31 Aug 2025 00:47:29 GMT   (34392kb)

Title: Learning from 10 Demos: Generalisable and Sample-Efficient Policy
  Learning with Oriented Affordance Frames
Authors: Krishan Rana, Jad Abou-Chakra, Sourav Garg, Robert Lee, Ian Reid and
  Niko Suenderhauf
Categories: cs.RO cs.AI
Comments: Accepted at the Conference on Robot Learning (CoRL), 2025. Videos can
  be found on our project website: https://affordance-policy.github.io
\\ ( https://arxiv.org/abs/2410.12124 ,  34392kb)
------------------------------------------------------------------------------
\\
arXiv:2410.22381
replaced with revised version Thu, 4 Sep 2025 12:44:44 GMT   (3405kb)

Title: Robust training of implicit generative models for multivariate and
  heavy-tailed distributions with an invariant statistical loss
Authors: Jos\'e Manuel de Frutos, Manuel A. V\'azquez, Pablo Olmos, Joaqu\'in
  M\'iguez
Categories: cs.LG cs.AI stat.CO stat.ML
\\ ( https://arxiv.org/abs/2410.22381 ,  3405kb)
------------------------------------------------------------------------------
\\
arXiv:2411.00265
replaced with revised version Thu, 4 Sep 2025 12:15:53 GMT   (135kb)

Title: Quantifying Calibration Error in Neural Networks Through Evidence-Based
  Theory
Authors: Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Frank Kargl
Categories: cs.LG cs.AI math.LO
Comments: This is the preprint of the paper accepted to Fusion 2025 (28th
  International Conference on Information Fusion, Rio de Janeiro, Brazil, July
  7-10, 2025). The published version is available at
  https://doi.org/10.23919/FUSION65864.2025.11124121
DOI: 10.23919/FUSION65864.2025.11124121
\\ ( https://arxiv.org/abs/2411.00265 ,  135kb)
------------------------------------------------------------------------------
\\
arXiv:2411.03562
replaced with revised version Thu, 4 Sep 2025 14:07:26 GMT   (5999kb)

Title: Kolb-Based Experiential Learning for Generalist Agents with Human-Level
  Kaggle Data Science Performance
Authors: Antoine Grosnit, Alexandre Maraval, Refinath S N, Zichao Zhao, James
  Dora, Giuseppe Paolo, Albert Thomas, Jonas Gonzalez, Abhineet Kumar, Khyati
  Khandelwal, Abdelhakim Benechehab, Hamza Cherkaoui, Youssef Attia El-Hili,
  Kun Shao, Jianye Hao, Jun Yao, Bal\'azs K\'egl, Jun Wang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2411.03562 ,  5999kb)
------------------------------------------------------------------------------
\\
arXiv:2412.16572
replaced with revised version Thu, 4 Sep 2025 01:16:44 GMT   (0kb,I)

Title: Breaking the Context Bottleneck on Long Time Series Forecasting
Authors: Chao Ma, Yikai Hou, Xiang Li, Yinggang Sun, Haining Yu, Zhou Fang,
  Jiaxing Qu
Categories: cs.LG cs.AI
Comments: rewrite and authorship changing
\\ ( https://arxiv.org/abs/2412.16572 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05719
replaced with revised version Wed, 3 Sep 2025 22:24:27 GMT   (1232kb)

Title: Extended Histogram-based Outlier Score (EHBOS)
Authors: Tanvir Islam
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2502.05719 ,  1232kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06289 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 07:35:48 GMT   (1231kb)

Title: Is an Ultra Large Natural Image-Based Foundation Model Superior to a
  Retina-Specific Model for Detecting Ocular and Systemic Diseases?
Authors: Qingshan Hou, Yukun Zhou, Jocelyn Hui Lin Goh, Ke Zou, Samantha Min Er
  Yew, Sahana Srinivasan, Meng Wang, Thaddaeus Lo, Xiaofeng Lei, Siegfried K.
  Wagner, Mark A. Chia, Dawei Yang, Hongyang Jiang, An Ran Ran, Rui Santos,
  Gabor Mark Somfai, Juan Helen Zhou, Haoyu Chen, Qingyu Chen, Carol Y. Cheung,
  Pearse A. Keane, Yih Chung Tham
Categories: eess.IV cs.AI cs.CV
Comments: Accepted by Ophthalmology Science and is currently in press
\\ ( https://arxiv.org/abs/2502.06289 ,  1231kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09002
replaced with revised version Wed, 3 Sep 2025 21:48:29 GMT   (1023kb)

Title: KNighter: Transforming Static Analysis with LLM-Synthesized Checkers
Authors: Chenyuan Yang, Zijie Zhao, Zichen Xie, Haoyu Li, Lingming Zhang
Categories: cs.SE cs.AI cs.CR cs.OS
Comments: SOSP 2025
DOI: 10.1145/3731569.3764827
\\ ( https://arxiv.org/abs/2503.09002 ,  1023kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14048 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 08:38:38 GMT   (1212kb)

Title: Beyond holography: the entropic quantum gravity foundations of image
  processing
Authors: Ginestra Bianconi
Categories: cond-mat.dis-nn cond-mat.stat-mech cs.AI gr-qc quant-ph
Comments: (7 pages, 1 figure)
\\ ( https://arxiv.org/abs/2503.14048 ,  1212kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22524
replaced with revised version Thu, 4 Sep 2025 02:32:37 GMT   (644kb)

Title: Robust Offline Imitation Learning Through State-level Trajectory
  Stitching
Authors: Shuze Wang, Yunpeng Mei, Hongjie Cao, Yetian Yuan, Gang Wang, Jian
  Sun, Jie Chen
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2503.22524 ,  644kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02737
replaced with revised version Wed, 3 Sep 2025 18:55:07 GMT   (46473kb)

Title: RBT4DNN: Requirements-based Testing of Neural Networks
Authors: Nusrat Jahan Mozumder, Felipe Toledo, Swaroopa Dola and Matthew B.
  Dwyer
Categories: cs.SE cs.AI cs.LG
\\ ( https://arxiv.org/abs/2504.02737 ,  46473kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18102
replaced with revised version Thu, 4 Sep 2025 00:35:33 GMT   (458kb)

Title: How Can I Publish My LLM Benchmark Without Giving the True Answers Away?
Authors: Takashi Ishida, Thanawat Lodkaew, Ikko Yamane
Categories: cs.LG cs.AI cs.CL stat.ME
Comments: Extended version of the paper presented as an Oral at the ICML 2025
  Workshop on the Impact of Memorization on Trustworthy Foundation Models
\\ ( https://arxiv.org/abs/2505.18102 ,  458kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08570
replaced with revised version Thu, 4 Sep 2025 11:54:13 GMT   (325kb)

Title: Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling
  Paradigms for Text-to-Music Generation
Authors: Or Tal and Felix Kreuk and Yossi Adi
Categories: cs.SD cs.AI cs.LG eess.AS
\\ ( https://arxiv.org/abs/2506.08570 ,  325kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20790
replaced with revised version Thu, 4 Sep 2025 11:41:34 GMT   (5341kb)

Title: Stochastic Parameter Decomposition
Authors: Lucius Bushnaq, Dan Braun, Lee Sharkey
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.20790 ,  5341kb)
------------------------------------------------------------------------------
\\
arXiv:2507.09523
replaced with revised version Thu, 4 Sep 2025 06:03:10 GMT   (381kb)

Title: An Analysis of Action-Value Temporal-Difference Methods That Learn State
  Values
Authors: Brett Daley, Prabhat Nagarajan, Martha White, Marlos C. Machado
Categories: cs.LG cs.AI
Comments: Published in RLC/RLJ 2025. Camera-ready version
\\ ( https://arxiv.org/abs/2507.09523 ,  381kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02548
replaced with revised version Thu, 4 Sep 2025 15:06:45 GMT   (49kb)

Title: The KG-ER Conceptual Schema Language
Authors: Enrico Franconi and Beno\^it Groz and Jan Hidders and Nina Pardal and
  S{\l}awek Staworko and Jan Van den Bussche and Piotr Wieczorek
Categories: cs.DB cs.AI
MSC-class: 68P15
\\ ( https://arxiv.org/abs/2508.02548 ,  49kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08193
replaced with revised version Thu, 4 Sep 2025 14:42:06 GMT   (2967kb)

Title: Street-Level AI: Are Large Language Models Ready for Real-World
  Judgments?
Authors: Gaurab Pokharel, Shafkat Farabi, Patrick J. Fowler, Sanmay Das
Categories: cs.CY cs.AI
Comments: This work has been accepted for publication as a full paper at the
  AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)
\\ ( https://arxiv.org/abs/2508.08193 ,  2967kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08524
replaced with revised version Thu, 4 Sep 2025 13:56:50 GMT   (47671kb)

Title: StreetViewAI: Making Street View Accessible Using Context-Aware
  Multimodal AI
Authors: Jon E. Froehlich, Alexander Fiannaca, Nimer Jaber, Victor Tsaran,
  Shaun Kane
Categories: cs.HC cs.AI
Comments: Accepted to UIST'25 v2. Fixed a missing word in the PDF v3. Fixed a
  typo in an author's name
ACM-class: H.5; I.2
DOI: 10.1145/3746059.3747756
\\ ( https://arxiv.org/abs/2508.08524 ,  47671kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08715 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 07:56:00 GMT   (6769kb)

Title: MultiGen: Child-Friendly Multilingual Speech Generator with LLMs
Authors: Xiaoxue Gao, Huayun Zhang, Nancy F. Chen
Categories: eess.AS cs.AI cs.CL eess.SP
Comments: 5 pages
\\ ( https://arxiv.org/abs/2508.08715 ,  6769kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13755
replaced with revised version Thu, 4 Sep 2025 15:21:27 GMT   (1283kb)

Title: Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with
  Adaptive Exploration
Authors: Zhicheng Yang, Zhijiang Guo, Yinya Huang, Yongxin Wang, Dongchun Xie,
  Yiwei Wang, Xiaodan Liang, Jing Tang
Categories: cs.LG cs.AI
Comments: 16 pages, 14 figures
\\ ( https://arxiv.org/abs/2508.13755 ,  1283kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18464 (*cross-listing*)
replaced with revised version Wed, 3 Sep 2025 22:25:32 GMT   (241kb)

Title: Vectorized Attention with Learnable Encoding for Quantum Transformer
Authors: Ziqing Guo, Ziwen Pan, Alex Khan, Jan Balewski
Categories: quant-ph cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.18464 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20117
replaced with revised version Thu, 4 Sep 2025 06:26:17 GMT   (0kb,I)

Title: Is Artificial Intelligence Reshaping the Landscape of the International
  Academic Community of Geosciences?
Authors: Liang Li, Yuntian Li, Wenxin Zhao, Shan Ye, Yun Lu
Categories: cs.DL cs.AI cs.CY
Comments: miscommunication in the authorization process from the first author
\\ ( https://arxiv.org/abs/2508.20117 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20293
replaced with revised version Thu, 4 Sep 2025 05:03:16 GMT   (14kb)

Title: Beacon: Post-Training Quantization with Integrated Grid Selection
Authors: Shihao Zhang, Rayan Saab
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2508.20293 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00167
replaced with revised version Thu, 4 Sep 2025 15:59:28 GMT   (863kb)

Title: Pilot Study on Generative AI and Critical Thinking in Higher Education
  Classrooms
Authors: W. F. Lamberti, S. R. Lawrence, D. White, S. Kim, S. Abdullah
Categories: cs.CY cs.AI cs.HC stat.AP
\\ ( https://arxiv.org/abs/2509.00167 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00215
replaced with revised version Thu, 4 Sep 2025 12:46:04 GMT   (5236kb)

Title: First Order Model-Based RL through Decoupled Backpropagation
Authors: Joseph Amigo, Rooholla Khorrambakht, Elliot Chane-Sane, Nicolas
  Mansard, Ludovic Righetti
Categories: cs.RO cs.AI cs.LG
Comments: CoRL 2025. Project website: https://machines-in-motion.github.io/DMO/
\\ ( https://arxiv.org/abs/2509.00215 ,  5236kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00616
replaced with revised version Thu, 4 Sep 2025 01:01:04 GMT   (1112kb)

Title: TimeCopilot
Authors: Azul Garza, Rene\'e Rosillo
Categories: cs.LG cs.AI cs.HC
\\ ( https://arxiv.org/abs/2509.00616 ,  1112kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00813
replaced with revised version Thu, 4 Sep 2025 07:41:31 GMT   (3724kb)

Title: AImoclips: A Benchmark for Evaluating Emotion Conveyance in
  Text-to-Music Generation
Authors: Gyehun Go, Satbyul Han, Ahyeon Choi, Eunjin Choi, Juhan Nam and Jeong
  Mi Park
Categories: cs.SD cs.AI eess.AS
Comments: to be published in HCMIR25: 3rd Workshop on Human-Centric Music
  Information Research
\\ ( https://arxiv.org/abs/2509.00813 ,  3724kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01153
replaced with revised version Thu, 4 Sep 2025 01:07:56 GMT   (11662kb)

Title: EZhouNet:A framework based on graph neural network and anchor interval
  for the respiratory sound event detection
Authors: Yun Chu, Qiuhao Wang, Enze Zhou, Qian Liu and Gang Zheng
Categories: cs.SD cs.AI eess.AS
Journal-ref: Biomedical Signal Processing and Control 2026-02 | Journal article
DOI: 10.1016/j.bspc.2025.108491
\\ ( https://arxiv.org/abs/2509.01153 ,  11662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02349
replaced with revised version Thu, 4 Sep 2025 14:25:57 GMT   (4983kb)

Title: AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation
Authors: Lu Wang, Hao Chen, Siyu Wu, Zhiyue Wu, Hao Zhou, Chengfeng Zhang, Ting
  Wang and Haodi Zhang
Categories: cs.SD cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.02349 ,  4983kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02591 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 00:59:33 GMT   (32kb)

Title: Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical
  Mitosis Classification
Authors: Mieko Ochi, Bae Yuan
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2509.02591 ,  32kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03249
replaced with revised version Thu, 4 Sep 2025 08:55:32 GMT   (185kb)

Title: Structure Transfer: an Inference-Based Calculus for the Transformation
  of Representations
Authors: Daniel Raggi, Gem Stapleton, Mateja Jamnik, Aaron Stockdill, Grecia
  Garcia Garcia, Peter C-H. Cheng
Categories: cs.LG cs.AI cs.LO
MSC-class: 68T30, 68T27, 03B35
ACM-class: I.2.4; I.2.3; F.4.1; F.4.3
\\ ( https://arxiv.org/abs/2509.03249 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2407.01085
replaced with revised version Thu, 4 Sep 2025 02:14:46 GMT   (1019kb)

Title: Explaining Length Bias in LLM-Based Preference Evaluations
Authors: Zhengyu Hu, Linxin Song, Jieyu Zhang, Zheyuan Xiao, Tianfu Wang,
  Zhengyu Chen, Nicholas Jing Yuan, Jianxun Lian, Kaize Ding, Hui Xiong
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2407.01085 ,  1019kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05720
replaced with revised version Thu, 4 Sep 2025 12:08:46 GMT   (225kb)

Title: That is Unacceptable: the Moral Foundations of Canceling
Authors: Soda Marem Lo, Oscar Araque, Rajesh Sharma, Marco Antonio Stranisci
Categories: cs.CY cs.CL
\\ ( https://arxiv.org/abs/2503.05720 ,  225kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01115
replaced with revised version Wed, 3 Sep 2025 19:18:47 GMT   (285kb)

Title: Is Random Attention Sufficient for Sequence Modeling? Disentangling
  Trainable Components in the Transformer
Authors: Yihe Dong, Lorenzo Noci, Mikhail Khodak, Mufan Li
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2506.01115 ,  285kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02077
replaced with revised version Wed, 3 Sep 2025 18:14:56 GMT   (911kb)

Title: From Attack Descriptions to Vulnerabilities: A Sentence
  Transformer-Based Approach
Authors: Refat Othman, Diaeddin Rimawi, Bruno Rossi, Barbara Russo
Categories: cs.CR cs.CL cs.LG
Comments: Accepted in The Journal of Systems and Software (2025)
MSC-class: 68T50 Natural language processing
ACM-class: D.4.6; I.2.7
\\ ( https://arxiv.org/abs/2509.02077 ,  911kb)
------------------------------------------------------------------------------
\\
arXiv:2403.05702 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 09:22:57 GMT   (13480kb)

Title: Spatial-aware Transformer-GRU Framework for Enhanced Glaucoma Diagnosis
  from 3D OCT Imaging
Authors: Mona Ashtari-Majlan, David Masip
Categories: eess.IV cs.CV
DOI: 10.1109/JBHI.2025.3550394
\\ ( https://arxiv.org/abs/2403.05702 ,  13480kb)
------------------------------------------------------------------------------
\\
arXiv:2405.20321
replaced with revised version Thu, 4 Sep 2025 08:23:37 GMT   (10440kb)

Title: Vision-based Manipulation from Single Human Video with Open-World Object
  Graphs
Authors: Yifeng Zhu, Arisrei Lim, Peter Stone, Yuke Zhu
Categories: cs.RO cs.CV cs.LG
Comments: Extended version of paper adding results with RGB-only demonstration
  videos uploaded on 09/04/2025
\\ ( https://arxiv.org/abs/2405.20321 ,  10440kb)
------------------------------------------------------------------------------
\\
arXiv:2501.07681
replaced with revised version Wed, 3 Sep 2025 19:44:03 GMT   (1544kb)

Title: Dataset Distillation as Pushforward Optimal Quantization
Authors: Hong Ye Tan, Emma Slade
Categories: cs.LG cs.CV math.OC stat.ML
Comments: Modified abstract, additional experiments based on diffusion
  transformers
\\ ( https://arxiv.org/abs/2501.07681 ,  1544kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07107 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 06:28:55 GMT   (10080kb)

Title: A Framework for Supervised and Unsupervised Segmentation and
  Classification of Materials Microstructure Images
Authors: Kungang Zhang, Wei Chen, Wing K. Liu, L. Catherine Brinson, Daniel W.
  Apley
Categories: stat.AP cs.CV stat.ML
\\ ( https://arxiv.org/abs/2502.07107 ,  10080kb)
------------------------------------------------------------------------------
\\
arXiv:2504.09885
replaced with revised version Thu, 4 Sep 2025 08:25:53 GMT   (2998kb)

Title: Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated
  Piano Hand Motion Synthesis
Authors: Zihao Liu, Mingwen Ou, Zunnan Xu, Jiaqi Huang, Haonan Han, Ronghui Li,
  Xiu Li
Categories: cs.SD cs.CV eess.AS
Comments: 15 pages, 7 figures, Accepted to ACMMM 2025
\\ ( https://arxiv.org/abs/2504.09885 ,  2998kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11249 (*cross-listing*)
replaced with revised version Wed, 3 Sep 2025 20:25:50 GMT   (21228kb)

Title: Cryo-em images are intrinsically low dimensional
Authors: Luke Evans, Octavian-Vlad Murad, Lars Dingeldein, Pilar Cossio,
  Roberto Covino, Marina Meila
Categories: q-bio.QM cs.CV cs.LG q-bio.BM stat.ML
DOI: 10.1103/txrb-fw3z
\\ ( https://arxiv.org/abs/2504.11249 ,  21228kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12348
replaced with revised version Thu, 4 Sep 2025 01:53:54 GMT   (6829kb)

Title: Real-Time Per-Garment Virtual Try-On with Temporal Consistency for
  Loose-Fitting Garments
Authors: Zaiqiang Wu, I-Chao Shen, Takeo Igarashi
Categories: cs.GR cs.CV
DOI: 10.1111/cgf.70272
\\ ( https://arxiv.org/abs/2506.12348 ,  6829kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22832
replaced with revised version Thu, 4 Sep 2025 15:05:54 GMT   (6225kb)

Title: Pulling Back the Curtain on ReLU Networks
Authors: Maciej Satkiewicz
Categories: cs.LG cs.CV cs.NE
Comments: 12 pages, 3-page appendix, 4 figures, preprint; v3 changes: changed
  title, improved abstract, expanded introduction, added section on
  implications of the path stability
ACM-class: I.2.6; I.4.10
\\ ( https://arxiv.org/abs/2507.22832 ,  6225kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18826
replaced with revised version Thu, 4 Sep 2025 08:59:58 GMT   (990kb)

Title: SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation
Authors: Junyu Yan, Feng Chen, Yuyang Xue, Yuning Du, Konstantinos Vilouras,
  Sotirios A. Tsaftaris, Steven McDonagh
Categories: cs.LG cs.CV
Comments: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2025:015
Journal-ref: Machine.Learning.for.Biomedical.Imaging. 3 (2025)
DOI: 10.59275/j.melba.2025-de23
\\ ( https://arxiv.org/abs/2508.18826 ,  990kb)
------------------------------------------------------------------------------
\\
arXiv:2503.00170
replaced with revised version Thu, 4 Sep 2025 16:16:50 GMT   (229kb)

Title: Elastic Restaking Networks
Authors: Roi Bar-Zur and Ittay Eyal
Categories: cs.GT cs.DC
\\ ( https://arxiv.org/abs/2503.00170 ,  229kb)
------------------------------------------------------------------------------
\\
arXiv:2505.00458
replaced with revised version Thu, 4 Sep 2025 14:12:48 GMT   (1227kb)

Title: Memory-Centric Computing: Solving Computing's Memory Problem
Authors: Onur Mutlu, Ataberk Olgun, Ismail Emir Yuksel
Categories: cs.AR cs.DC
Comments: Extended version of an IMW 2025 Invited Paper
\\ ( https://arxiv.org/abs/2505.00458 ,  1227kb)
------------------------------------------------------------------------------
\\
arXiv:2506.05138
replaced with revised version Thu, 4 Sep 2025 15:08:01 GMT   (554kb)

Title: Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT
  Systems
Authors: Pavle Vasiljevic, Milica Matic, Miroslav Popovic
Categories: cs.LG cs.DC
Comments: 6 pages, 4 algorithms, 5 figures, 2 tables
Journal-ref: Published by IEEE Xplore
DOI: 10.1109/ZINC65316.2025.11103552
\\ ( https://arxiv.org/abs/2506.05138 ,  554kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
