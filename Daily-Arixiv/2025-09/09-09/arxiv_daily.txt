Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 400251 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月11日 11:57
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Tue  9 Sep 25 18:00:00 GMT  to  Wed 10 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.07997
Date: Fri, 5 Sep 2025 13:11:50 GMT   (526kb)

Title: Learning-Based Planning for Improving Science Return of Earth
  Observation Satellites
Authors: Abigail Breitfeld, Alberto Candela, Juan Delfa, Akseli Kangaslahti,
  Itai Zilberstein, Steve Chien, David Wettergreen
Categories: cs.AI cs.RO
Comments: International Symposium on Artificial Intelligence, Robotics and
  Automation in Space, November 2024
\\
  Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.
\\ ( https://arxiv.org/abs/2509.07997 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08088
Date: Tue, 9 Sep 2025 18:51:36 GMT   (1913kb)

Title: EnvX: Agentize Everything with Agentic AI
Authors: Linyao Chen, Zimian Peng, Yingxuan Yang, Yikun Wang, Wenzheng Tom
  Tang, Hiroki H. Kobayashi, Weinan Zhang
Categories: cs.AI cs.MA
\\
  The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.
\\ ( https://arxiv.org/abs/2509.08088 ,  1913kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08151
Date: Tue, 9 Sep 2025 21:18:31 GMT   (1022kb)

Title: Trust Semantics Distillation for Collaborator Selection via
  Memory-Augmented Agentic AI
Authors: Botao Zhu, Jeslyn Wang, Dusit Niyato, Xianbin Wang
Categories: cs.AI
\\
  Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.
\\ ( https://arxiv.org/abs/2509.08151 ,  1022kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08222
Date: Wed, 10 Sep 2025 01:39:51 GMT   (950kb)

Title: Exploratory Retrieval-Augmented Planning For Continual Embodied
  Instruction Following
Authors: Minjong Yoo, Jinwoo Jang, Wei-jin Park, Honguk Woo
Categories: cs.AI
Comments: 21 pages. NeurIPS 2024
Journal-ref: Advances in Neural Information Processing Systems 37, 67034-67060,
  2024
\\
  This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.
\\ ( https://arxiv.org/abs/2509.08222 ,  950kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08282
Date: Wed, 10 Sep 2025 04:55:48 GMT   (178kb)

Title: Real-world Music Plagiarism Detection With Music Segment Transcription
  System
Authors: Seonghyeon Go
Categories: cs.AI cs.SD eess.AS
Comments: Accepted in APSIPA 2025 but not published yet(will be published in 2
  month..), Arxiv preprint ready for references in future-works
\\
  As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.
\\ ( https://arxiv.org/abs/2509.08282 ,  178kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08312
Date: Wed, 10 Sep 2025 06:24:57 GMT   (2758kb)

Title: Leveraging AI Agents for Autonomous Networks: A Reference Architecture
  and Empirical Studies
Authors: Binghan Wu, Shoufeng Wang, Yunxin Liu, Ya-Qin Zhang, Joseph Sifakis,
  Ye Ouyang
Categories: cs.AI
Comments: 7 pages, 5 figures. This manuscript is a preprint
\\
  The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.
\\ ( https://arxiv.org/abs/2509.08312 ,  2758kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08380
Date: Wed, 10 Sep 2025 08:16:04 GMT   (684kb)

Title: Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML
  Compliance Narratives
Authors: Prathamesh Vasudeo Naik, Naresh Kumar Dintakurthi, Zhanghao Hu, Yue
  Wang, Robby Qiu
Categories: cs.AI cs.LG
\\
  Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.
\\ ( https://arxiv.org/abs/2509.08380 ,  684kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08500
Date: Wed, 10 Sep 2025 11:16:21 GMT   (444kb)

Title: TCPO: Thought-Centric Preference Optimization for Effective Embodied
  Decision-making
Authors: Kechen Jiao, Zhirui Fang, Jiahao Liu, Bei Li, Qifan Wang, Xinyu Liu,
  Junhao Ruan, Zhongjian Qiao, Yifan Zhu, Yaxin Xu, Jingang Wang, Xiu Li
Categories: cs.AI
\\
  Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.
\\ ( https://arxiv.org/abs/2509.08500 ,  444kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08593
Date: Wed, 10 Sep 2025 13:46:40 GMT   (46kb)

Title: No-Knowledge Alarms for Misaligned LLMs-as-Judges
Authors: Andr\'es Corrada-Emmanuel
Categories: cs.AI stat.ML
Comments: 7 pages, 1 figure
MSC-class: 90C05, 68T27
ACM-class: I.2.3; F.4.1
\\
  If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.
\\ ( https://arxiv.org/abs/2509.08593 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08682
Date: Wed, 10 Sep 2025 15:22:00 GMT   (462kb)

Title: Automatic Failure Attribution and Critical Step Prediction Method for
  Multi-Agent Systems Based on Causal Inference
Authors: Guoqing Ma, Jia Zhu, Hanghui Guo, Weijie Shi, Jiawei Shen, Jingjiang
  Liu, Yidan Liang
Categories: cs.AI
\\
  Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.
\\ ( https://arxiv.org/abs/2509.08682 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08705
Date: Wed, 10 Sep 2025 15:55:14 GMT   (427kb)

Title: One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human
  Biases
Authors: Shalima Binta Manir, Tim Oates
Categories: cs.AI
Comments: 9 pages, 7 figures, 2 tables
\\
  We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.
\\ ( https://arxiv.org/abs/2509.08705 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08713
Date: Wed, 10 Sep 2025 16:04:24 GMT   (30kb)

Title: The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist
  Systems
Authors: Ziming Luo, Atoosa Kasirzadeh, Nihar B. Shah
Categories: cs.AI cs.DL
\\
  AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.
\\ ( https://arxiv.org/abs/2509.08713 ,  30kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08785
Date: Wed, 10 Sep 2025 17:14:12 GMT   (583kb)

Title: Narrative-Guided Reinforcement Learning: A Platform for Studying
  Language Model Influence on Decision Making
Authors: Anup Tuladhar, Araz Minhas, Adam Kirton, Eli Kinney-Lang
Categories: cs.AI cs.MA stat.ML
Comments: Extended Abstract for RLDM 2025
\\
  We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.
\\ ( https://arxiv.org/abs/2509.08785 ,  583kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07998
Date: Fri, 5 Sep 2025 23:36:26 GMT   (682kb)

Title: Bilingual Word Level Language Identification for Omotic Languages
Authors: Mesay Gemeda Yigezu, Girma Yohannis Bade, Atnafu Lambebo Tonja, Olga
  Kolesnikova, Grigori Sidorov, Alexander Gelbukh
Categories: cs.CL cs.AI
\\
  Language identification is the task of determining the languages for a given
text. In many real world scenarios, text may contain more than one language,
particularly in multilingual communities. Bilingual Language Identification
(BLID) is the task of identifying and distinguishing between two languages in a
given text. This paper presents BLID for languages spoken in the southern part
of Ethiopia, namely Wolaita and Gofa. The presence of words similarities and
differences between the two languages makes the language identification task
challenging. To overcome this challenge, we employed various experiments on
various approaches. Then, the combination of the BERT based pretrained language
model and LSTM approach performed better, with an F1 score of 0.72 on the test
set. As a result, the work will be effective in tackling unwanted social media
issues and providing a foundation for further research in this area.
\\ ( https://arxiv.org/abs/2509.07998 ,  682kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08000
Date: Sat, 6 Sep 2025 16:03:07 GMT   (314kb)

Title: AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs
Authors: Debdeep Sanyal, Manodeep Ray, Murari Mandal
Categories: cs.CL
Comments: 19 pages
\\
  The release of open-weight large language models (LLMs) creates a tension
between advancing accessible research and preventing misuse, such as malicious
fine-tuning to elicit harmful content. Current safety measures struggle to
preserve the general capabilities of the LLM while resisting a determined
adversary with full access to the model's weights and architecture, who can use
full-parameter fine-tuning to erase existing safeguards. To address this, we
introduce AntiDote, a bi-level optimization procedure for training LLMs to be
resistant to such tampering. AntiDote involves an auxiliary adversary
hypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)
weights conditioned on the defender model's internal activations. The defender
LLM is then trained with an objective to nullify the effect of these
adversarial weight additions, forcing it to maintain its safety alignment. We
validate this approach against a diverse suite of 52 red-teaming attacks,
including jailbreak prompting, latent space manipulation, and direct
weight-space attacks. AntiDote is upto 27.4\% more robust against adversarial
attacks compared to both tamper-resistance and unlearning baselines. Crucially,
this robustness is achieved with a minimal trade-off in utility, incurring a
performance degradation of upto less than 0.5\% across capability benchmarks
including MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute
efficient methodology for building open-weight models where safety is a more
integral and resilient property.
\\ ( https://arxiv.org/abs/2509.08000 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08022
Date: Tue, 9 Sep 2025 09:25:08 GMT   (264kb)

Title: MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large
  Language Models with Diverse Human Values
Authors: Yao Liang, Dongcheng Zhao, Feifei Zhao, Guobin Shen, Yuwei Wang,
  Dongqi Liang, Yi Zeng
Categories: cs.CL cs.AI
\\
  The alignment of large language models (LLMs) with human values is critical
for their safe and effective deployment across diverse user populations.
However, existing benchmarks often neglect cultural and demographic diversity,
leading to limited understanding of how value alignment generalizes globally.
In this work, we introduce MVPBench, a novel benchmark that systematically
evaluates LLMs' alignment with multi-dimensional human value preferences across
75 countries. MVPBench contains 24,020 high-quality instances annotated with
fine-grained value labels, personalized questions, and rich demographic
metadata, making it the most comprehensive resource of its kind to date. Using
MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,
revealing substantial disparities in alignment performance across geographic
and demographic lines. We further demonstrate that lightweight fine-tuning
methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization
(DPO), can significantly enhance value alignment in both in-domain and
out-of-domain settings. Our findings underscore the necessity for
population-aware alignment evaluation and provide actionable insights for
building culturally adaptive and value-sensitive LLMs. MVPBench serves as a
practical foundation for future research on global alignment, personalized
value modeling, and equitable AI development.
\\ ( https://arxiv.org/abs/2509.08022 ,  264kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08025
Date: Tue, 9 Sep 2025 12:05:52 GMT   (293kb)

Title: NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models
  and Large Language Models for Legal Retrieval and Entailment
Authors: Hoang-Trung Nguyen, Tan-Minh Nguyen, Xuan-Bach Le, Tuan-Kiet Le,
  Khanh-Huyen Nguyen, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong, Le-Minh Nguyen
Categories: cs.CL cs.AI
\\
  This paper presents the methodologies and results of the NOWJ team's
participation across all five tasks at the COLIEE 2025 competition, emphasizing
advancements in the Legal Case Entailment task (Task 2). Our comprehensive
approach systematically integrates pre-ranking models (BM25, BERT, monoT5),
embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large
Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance
scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage
retrieval system combined lexical-semantic filtering with contextualized LLM
analysis, achieving first place with an F1 score of 0.3195. Additionally, in
other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal
Textual Entailment, and Legal Judgment Prediction--we demonstrated robust
performance through carefully engineered ensembles and effective prompt-based
reasoning strategies. Our findings highlight the potential of hybrid models
integrating traditional IR techniques with contemporary generative models,
providing a valuable reference for future advancements in legal information
processing.
\\ ( https://arxiv.org/abs/2509.08025 ,  293kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08032
Date: Tue, 9 Sep 2025 16:09:19 GMT   (718kb)

Title: SciGPT: A Large Language Model for Scientific Literature Understanding
  and Knowledge Discovery
Authors: Fengyu She, Nan Wang, Hongfei Wu, Ziyi Wan, Jingmian Wang, Chang Wang
Categories: cs.CL
\\
  Scientific literature is growing exponentially, creating a critical
bottleneck for researchers to efficiently synthesize knowledge. While
general-purpose Large Language Models (LLMs) show potential in text processing,
they often fail to capture scientific domain-specific nuances (e.g., technical
jargon, methodological rigor) and struggle with complex scientific tasks,
limiting their utility for interdisciplinary research. To address these gaps,
this paper presents SciGPT, a domain-adapted foundation model for scientific
literature understanding and ScienceBench, an open source benchmark tailored to
evaluate scientific LLMs.
  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:
(1) low-cost domain distillation via a two-stage pipeline to balance
performance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention
mechanism that cuts memory consumption by 55\% for 32,000-token long-document
reasoning; and (3) knowledge-aware adaptation integrating domain ontologies to
bridge interdisciplinary knowledge gaps.
  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in
core scientific tasks including sequence labeling, generation, and inference.
It also exhibits strong robustness in unseen scientific tasks, validating its
potential to facilitate AI-augmented scientific discovery.
\\ ( https://arxiv.org/abs/2509.08032 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08075
Date: Tue, 9 Sep 2025 18:30:01 GMT   (218kb)

Title: No for Some, Yes for Others: Persona Prompts and Other Sources of False
  Refusal in Language Models
Authors: Flor Miriam Plaza-del-Arco, Paul R\"ottger, Nino Scherrer, Emanuele
  Borgonovo, Elmar Plischke, Dirk Hovy
Categories: cs.CL
\\
  Large language models (LLMs) are increasingly integrated into our daily lives
and personalized. However, LLM personalization might also increase unintended
side effects. Recent work suggests that persona prompting can lead models to
falsely refuse user requests. However, no work has fully quantified the extent
of this issue. To address this gap, we measure the impact of 15
sociodemographic personas (based on gender, race, religion, and disability) on
false refusal. To control for other factors, we also test 16 different models,
3 tasks (Natural Language Inference, politeness, and offensiveness
classification), and nine prompt paraphrases. We propose a Monte Carlo-based
method to quantify this issue in a sample-efficient manner. Our results show
that as models become more capable, personas impact the refusal rate less and
less. Certain sociodemographic personas increase false refusal in some models,
which suggests underlying biases in the alignment strategies or safety
mechanisms. However, we find that the model choice and task significantly
influence false refusals, especially in sensitive content tasks. Our findings
suggest that persona effects have been overestimated, and might be due to other
factors.
\\ ( https://arxiv.org/abs/2509.08075 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08093
Date: Tue, 9 Sep 2025 19:00:10 GMT   (938kb)

Title: Culturally transmitted color categories in LLMs reflect a learning bias
  toward efficient compression
Authors: Nathaniel Imel and Noga Zaslavsky
Categories: cs.CL
\\
  Converging evidence suggests that systems of semantic categories across human
languages achieve near-optimal compression via the Information Bottleneck (IB)
complexity-accuracy principle. Large language models (LLMs) are not trained for
this objective, which raises the question: are LLMs capable of evolving
efficient human-like semantic systems? To address this question, we focus on
the domain of color as a key testbed of cognitive theories of categorization
and replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two
influential human behavioral studies. First, we conduct an English color-naming
study, showing that Gemini aligns well with the naming patterns of native
English speakers and achieves a significantly high IB-efficiency score, while
Llama exhibits an efficient but lower complexity system compared to English.
Second, to test whether LLMs simply mimic patterns in their training data or
actually exhibit a human-like inductive bias toward IB-efficiency, we simulate
cultural evolution of pseudo color-naming systems in LLMs via iterated
in-context language learning. We find that akin to humans, LLMs iteratively
restructure initially random systems towards greater IB-efficiency and
increased alignment with patterns observed across the world's languages. These
findings demonstrate that LLMs are capable of evolving perceptually grounded,
human-like semantic systems, driven by the same fundamental principle that
governs semantic efficiency across human languages.
\\ ( https://arxiv.org/abs/2509.08093 ,  938kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08105
Date: Tue, 9 Sep 2025 19:32:05 GMT   (678kb)

Title: MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and
  LLM Fusion
Authors: Kosei Uemura, David Guzm\'an, Quang Phuoc Nguyen, Jesujoba Oluwadara
  Alabi, En-shiun Annie Lee, David Ifeoluwa Adelani
Categories: cs.CL
Comments: under submission
\\
  Large language models excel in English but still struggle with complex
reasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder
methods such as LangBridge and MindMerger raise accuracy on mid and
high-resource languages, yet they leave a large gap on LRLs. We present MERLIN,
a two-stage model-stacking framework that applies a curriculum learning
strategy -- from general bilingual bitext to task-specific data -- and adapts
only a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves
exact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.
It also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),
demonstrating effectiveness across both low and high-resource settings.
\\ ( https://arxiv.org/abs/2509.08105 ,  678kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08146
Date: Tue, 9 Sep 2025 20:59:50 GMT   (6862kb)

Title: Bias after Prompting: Persistent Discrimination in Large Language Models
Authors: Nivedha Sivakumar, Natalie Mackraz, Samira Khorshidi, Krishna Patel,
  Barry-John Theobald, Luca Zappella, Nicholas Apostoloff
Categories: cs.CL cs.LG
\\
  A dangerous assumption that can be made from prior work on the bias transfer
hypothesis (BTH) is that biases do not transfer from pre-trained large language
models (LLMs) to adapted models. We invalidate this assumption by studying the
BTH in causal models under prompt adaptations, as prompting is an extremely
popular and accessible adaptation strategy used in real-world applications. In
contrast to prior work, we find that biases can transfer through prompting and
that popular prompt-based mitigation methods do not consistently prevent biases
from transferring. Specifically, the correlation between intrinsic biases and
those after prompt adaptation remain moderate to strong across demographics and
tasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age
(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we
find that biases remain strongly correlated when varying few-shot composition
parameters, such as sample size, stereotypical content, occupational
distribution and representational balance (rho >= 0.90). We evaluate several
prompt-based debiasing strategies and find that different approaches have
distinct strengths, but none consistently reduce bias transfer across models,
tasks or demographics. These results demonstrate that correcting bias, and
potentially improving reasoning ability, in intrinsic models may prevent
propagation of biases to downstream tasks.
\\ ( https://arxiv.org/abs/2509.08146 ,  6862kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08150
Date: Tue, 9 Sep 2025 21:14:44 GMT   (29kb)

Title: Verbalized Algorithms
Authors: Supriya Lall, Christian Farrell, Hari Pathanjaly, Marko Pavic, Sarvesh
  Chezhian, Masataro Asai
Categories: cs.CL
Comments: Submitted to NeurIPS 2025 Workshop on Efficient Reasoning
\\
  Instead of querying LLMs in a one-shot manner and hoping to get the right
answer for a reasoning task, we propose a paradigm we call \emph{verbalized
algorithms} (VAs), which leverage classical algorithms with established
theoretical understanding. VAs decompose a task into simple elementary
operations on natural language strings that they should be able to answer
reliably, and limit the scope of LLMs to only those simple tasks. For example,
for sorting a series of natural language strings, \emph{verbalized sorting}
uses an LLM as a binary comparison oracle in a known and well-analyzed sorting
algorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of
this approach on sorting and clustering tasks.
\\ ( https://arxiv.org/abs/2509.08150 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08217
Date: Wed, 10 Sep 2025 01:22:07 GMT   (7776kb)

Title: Balancing Quality and Variation: Spam Filtering Distorts Data Label
  Distributions
Authors: Eve Fleisig, Matthias Orlikowski, Philipp Cimiano, Dan Klein
Categories: cs.CL cs.AI
\\
  For machine learning datasets to accurately represent diverse opinions in a
population, they must preserve variation in data labels while filtering out
spam or low-quality responses. How can we balance annotator reliability and
representation? We empirically evaluate how a range of heuristics for annotator
filtering affect the preservation of variation on subjective tasks. We find
that these methods, designed for contexts in which variation from a single
ground-truth label is considered noise, often remove annotators who disagree
instead of spam annotators, introducing suboptimal tradeoffs between accuracy
and label diversity. We find that conservative settings for annotator removal
(<5%) are best, after which all tested methods increase the mean absolute error
from the true average label. We analyze performance on synthetic spam to
observe that these methods often assume spam annotators are less random than
real spammers tend to be: most spammers are distributionally indistinguishable
from real annotators, and the minority that are distinguishable tend to give
fixed answers, not random ones. Thus, tasks requiring the preservation of
variation reverse the intuition of existing spam filtering methods: spammers
tend to be less random than non-spammers, so metrics that assume variation is
spam fare worse. These results highlight the need for spam removal methods that
account for label diversity.
\\ ( https://arxiv.org/abs/2509.08217 ,  7776kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08304
Date: Wed, 10 Sep 2025 06:00:01 GMT   (708kb)

Title: Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage
  Relations via Answerability Detection
Authors: Yehudit Aperstein, Alon Gottlib, Gal Benita, Alexander Apartsin
Categories: cs.CL
Comments: 27 pages, 1 figure
\\
  Understanding how information is shared across documents, regardless of the
format in which it is expressed, is critical for tasks such as information
retrieval, summarization, and content alignment. In this work, we introduce a
novel framework for modelling Semantic Coverage Relations (SCR), which
classifies document pairs based on how their informational content aligns. We
define three core relation types: equivalence, where both texts convey the same
information using different textual forms or styles; inclusion, where one
document fully contains the information of another and adds more; and semantic
overlap, where each document presents partially overlapping content. To capture
these relations, we adopt a question answering (QA)-based approach, using the
answerability of shared questions across documents as an indicator of semantic
coverage. We construct a synthetic dataset derived from the SQuAD corpus by
paraphrasing source passages and selectively omitting information, enabling
precise control over content overlap. This dataset allows us to benchmark
generative language models and train transformer-based classifiers for SCR
prediction. Our findings demonstrate that discriminative models significantly
outperform generative approaches, with the RoBERTa-base model achieving the
highest accuracy of 61.4% and the Random Forest-based model showing the best
balance with a macro-F1 score of 52.9%. The results show that QA provides an
effective lens for assessing semantic relations across stylistically diverse
texts, offering insights into the capacity of current models to reason about
information beyond surface similarity. The dataset and code developed in this
study are publicly available to support reproducibility.
\\ ( https://arxiv.org/abs/2509.08304 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08345
Date: Wed, 10 Sep 2025 07:32:14 GMT   (233kb)

Title: Toward Subtrait-Level Model Explainability in Automated Writing
  Evaluation
Authors: Alejandro Andrade-Lotero, Lee Becker, Joshua Southerland and Scott
  Hellman
Categories: cs.CL cs.AI
Comments: Accepted to National Council on Measurement in Education (NCME) 2025
  Annual Meeting
\\
  Subtrait (latent-trait components) assessment presents a promising path
toward enhancing transparency of automated writing scores. We prototype
explainability and subtrait scoring with generative language models and show
modest correlation between human subtrait and trait scores, and between
automated and human subtrait scores. Our approach provides details to demystify
scores for educators and students.
\\ ( https://arxiv.org/abs/2509.08345 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08355
Date: Wed, 10 Sep 2025 07:45:02 GMT   (194kb)

Title: Automatic Detection of Inauthentic Templated Responses in English
  Language Assessments
Authors: Yashad Samant, Lee Becker, Scott Hellman, Bradley Behan, Sarah Hughes,
  Joshua Southerland
Categories: cs.CL cs.AI
Comments: Accepted to National Council on Measurement in Education (NCME) 2025
  Annual Meeting
\\
  In high-stakes English Language Assessments, low-skill test takers may employ
memorized materials called ``templates'' on essay questions to ``game'' or fool
the automated scoring system. In this study, we introduce the automated
detection of inauthentic, templated responses (AuDITR) task, describe a machine
learning-based approach to this task and illustrate the importance of regularly
updating these models in production.
\\ ( https://arxiv.org/abs/2509.08355 ,  194kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08358
Date: Wed, 10 Sep 2025 07:48:24 GMT   (5245kb)

Title: <think> So let's replace this phrase with insult... </think> Lessons
  learned from generation of toxic texts with LLMs
Authors: Sergey Pletenev, Daniil Moskovskiy, Alexander Panchenko
Categories: cs.CL cs.AI
\\
  Modern Large Language Models (LLMs) are excellent at generating synthetic
data. However, their performance in sensitive domains such as text
detoxification has not received proper attention from the scientific community.
This paper explores the possibility of using LLM-generated synthetic toxic data
as an alternative to human-generated data for training models for
detoxification. Using Llama 3 and Qwen activation-patched models, we generated
synthetic toxic counterparts for neutral texts from ParaDetox and SST-2
datasets. Our experiments show that models fine-tuned on synthetic data
consistently perform worse than those trained on human data, with a drop in
performance of up to 30% in joint metrics. The root cause is identified as a
critical lexical diversity gap: LLMs generate toxic content using a small,
repetitive vocabulary of insults that fails to capture the nuances and variety
of human toxicity. These findings highlight the limitations of current LLMs in
this domain and emphasize the continued importance of diverse, human-annotated
data for building robust detoxification systems.
\\ ( https://arxiv.org/abs/2509.08358 ,  5245kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08381
Date: Wed, 10 Sep 2025 08:19:07 GMT   (927kb)

Title: Low-Resource Fine-Tuning for Multi-Task Structured Information
  Extraction with a Billion-Parameter Instruction-Tuned Model
Authors: Yu Cheng Chih, Yong Hao Hou
Categories: cs.CL cs.AI
Comments: 13 pages, 8 figures, includes experiments on JSON extraction,
  knowledge graph extraction, and NER
\\
  Deploying large language models (LLMs) for structured data extraction in
domains such as financial compliance reporting, legal document analytics, and
multilingual knowledge base construction is often impractical for smaller teams
due to the high cost of running large architectures and the difficulty of
preparing large, high-quality datasets. Most recent instruction-tuning studies
focus on seven-billion-parameter or larger models, leaving limited evidence on
whether much smaller models can work reliably under low-resource, multi-task
conditions. This work presents ETLCH, a billion-parameter LLaMA-based model
fine-tuned with low-rank adaptation on only a few hundred to one thousand
samples per task for JSON extraction, knowledge graph extraction, and named
entity recognition. Despite its small scale, ETLCH outperforms strong baselines
across most evaluation metrics, with substantial gains observed even at the
lowest data scale. These findings demonstrate that well-tuned small models can
deliver stable and accurate structured outputs at a fraction of the
computational cost, enabling cost-effective and reliable information extraction
pipelines in resource-constrained environments.
\\ ( https://arxiv.org/abs/2509.08381 ,  927kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08438
Date: Wed, 10 Sep 2025 09:35:43 GMT   (1362kb)

Title: CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction
  with a New Dataset and Multi-Order Generative Framework
Authors: Jinzhong Ning, Paerhati Tulajiang, Yingying Le, Yijia Zhang, Yuanyuan
  Sun, Hongfei Lin, Haifeng Liu
Categories: cs.CL cs.MM cs.SD
\\
  Speech Relation Extraction (SpeechRE) aims to extract relation triplets
directly from speech. However, existing benchmark datasets rely heavily on
synthetic data, lacking sufficient quantity and diversity of real human speech.
Moreover, existing models also suffer from rigid single-order generation
templates and weak semantic alignment, substantially limiting their
performance. To address these challenges, we introduce CommonVoice-SpeechRE, a
large-scale dataset comprising nearly 20,000 real-human speech samples from
diverse speakers, establishing a new benchmark for SpeechRE research.
Furthermore, we propose the Relation Prompt-Guided Multi-Order Generative
Ensemble (RPG-MoGe), a novel framework that features: (1) a multi-order triplet
generation ensemble strategy, leveraging data diversity through diverse element
orders during both training and inference, and (2) CNN-based latent relation
prediction heads that generate explicit relation prompts to guide cross-modal
alignment and accurate triplet generation. Experiments show our approach
outperforms state-of-the-art methods, providing both a benchmark dataset and an
effective solution for real-world SpeechRE. The source code and dataset are
publicly available at https://github.com/NingJinzhong/SpeechRE_RPG_MoGe.
\\ ( https://arxiv.org/abs/2509.08438 ,  1362kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08463
Date: Wed, 10 Sep 2025 10:10:10 GMT   (497kb)

Title: Adversarial Attacks Against Automated Fact-Checking: A Survey
Authors: Fanzhen Liu, Alsharif Abuadbba, Kristen Moore, Surya Nepal, Cecile
  Paris, Jia Wu, Jian Yang, Quan Z. Sheng
Categories: cs.CL cs.AI cs.CR
Comments: Accepted to the Main Conference of EMNLP 2025. Resources are
  available at
  https://github.com/FanzhenLiu/Awesome-Automated-Fact-Checking-Attacks
\\
  In an era where misinformation spreads freely, fact-checking (FC) plays a
crucial role in verifying claims and promoting reliable information. While
automated fact-checking (AFC) has advanced significantly, existing systems
remain vulnerable to adversarial attacks that manipulate or generate claims,
evidence, or claim-evidence pairs. These attacks can distort the truth, mislead
decision-makers, and ultimately undermine the reliability of FC models. Despite
growing research interest in adversarial attacks against AFC systems, a
comprehensive, holistic overview of key challenges remains lacking. These
challenges include understanding attack strategies, assessing the resilience of
current models, and identifying ways to enhance robustness. This survey
provides the first in-depth review of adversarial attacks targeting FC,
categorizing existing attack methodologies and evaluating their impact on AFC
systems. Additionally, we examine recent advancements in adversary-aware
defenses and highlight open research questions that require further
exploration. Our findings underscore the urgent need for resilient FC
frameworks capable of withstanding adversarial manipulations in pursuit of
preserving high verification accuracy.
\\ ( https://arxiv.org/abs/2509.08463 ,  497kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08480
Date: Wed, 10 Sep 2025 10:39:24 GMT   (60kb)

Title: Acquiescence Bias in Large Language Models
Authors: Daniel Braun
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Findings
\\
  Acquiescence bias, i.e. the tendency of humans to agree with statements in
surveys, independent of their actual beliefs, is well researched and
documented. Since Large Language Models (LLMs) have been shown to be very
influenceable by relatively small changes in input and are trained on
human-generated data, it is reasonable to assume that they could show a similar
tendency. We present a study investigating the presence of acquiescence bias in
LLMs across different models, tasks, and languages (English, German, and
Polish). Our results indicate that, contrary to humans, LLMs display a bias
towards answering no, regardless of whether it indicates agreement or
disagreement.
\\ ( https://arxiv.org/abs/2509.08480 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08484
Date: Wed, 10 Sep 2025 10:49:21 GMT   (460kb)

Title: Simulating Identity, Propagating Bias: Abstraction and Stereotypes in
  LLM-Generated Text
Authors: Pia Sommerauer, Giulia Rambelli, Tommaso Caselli
Categories: cs.CL
Comments: Accepted to EMNLP Findings 2025
\\
  Persona-prompting is a growing strategy to steer LLMs toward simulating
particular perspectives or linguistic styles through the lens of a specified
identity. While this method is often used to personalize outputs, its impact on
how LLMs represent social groups remains underexplored. In this paper, we
investigate whether persona-prompting leads to different levels of linguistic
abstraction - an established marker of stereotyping - when generating short
texts linking socio-demographic categories with stereotypical or
non-stereotypical attributes. Drawing on the Linguistic Expectancy Bias
framework, we analyze outputs from six open-weight LLMs under three prompting
conditions, comparing 11 persona-driven responses to those of a generic AI
assistant. To support this analysis, we introduce Self-Stereo, a new dataset of
self-reported stereotypes from Reddit. We measure abstraction through three
metrics: concreteness, specificity, and negation. Our results highlight the
limits of persona-prompting in modulating abstraction in language, confirming
criticisms about the ecology of personas as representative of socio-demographic
groups and raising concerns about the risk of propagating stereotypes even when
seemingly evoking the voice of a marginalized group.
\\ ( https://arxiv.org/abs/2509.08484 ,  460kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08486
Date: Wed, 10 Sep 2025 10:51:47 GMT   (316kb)

Title: Too Helpful, Too Harmless, Too Honest or Just Right?
Authors: Gautam Siddharth Kashyap, Mark Dras, and Usman Naseem
Categories: cs.CL
Comments: EMNLP'25 Main
\\
  Large Language Models (LLMs) exhibit strong performance across a wide range
of NLP tasks, yet aligning their outputs with the principles of Helpfulness,
Harmlessness, and Honesty (HHH) remains a persistent challenge. Existing
methods often optimize for individual alignment dimensions in isolation,
leading to trade-offs and inconsistent behavior. While Mixture-of-Experts (MoE)
architectures offer modularity, they suffer from poorly calibrated routing,
limiting their effectiveness in alignment tasks. We propose TrinityX, a modular
alignment framework that incorporates a Mixture of Calibrated Experts (MoCaE)
within the Transformer architecture. TrinityX leverages separately trained
experts for each HHH dimension, integrating their outputs through a calibrated,
task-adaptive routing mechanism that combines expert signals into a unified,
alignment-aware representation. Extensive experiments on three standard
alignment benchmarks-Alpaca (Helpfulness), BeaverTails (Harmlessness), and
TruthfulQA (Honesty)-demonstrate that TrinityX outperforms strong baselines,
achieving relative improvements of 32.5% in win rate, 33.9% in safety score,
and 28.4% in truthfulness. In addition, TrinityX reduces memory usage and
inference latency by over 40% compared to prior MoE-based approaches. Ablation
studies highlight the importance of calibrated routing, and cross-model
evaluations confirm TrinityX's generalization across diverse LLM backbones.
\\ ( https://arxiv.org/abs/2509.08486 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08541
Date: Wed, 10 Sep 2025 12:40:49 GMT   (760kb)

Title: CM-Align: Consistency-based Multilingual Alignment for Large Language
  Models
Authors: Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen,
  Jinan Xu, Jie Zhou
Categories: cs.CL
Comments: EMNLP 2025 Findings
\\
  Current large language models (LLMs) generally show a significant performance
gap in alignment between English and other languages. To bridge this gap,
existing research typically leverages the model's responses in English as a
reference to select the best/worst responses in other languages, which are then
used for Direct Preference Optimization (DPO) training. However, we argue that
there are two limitations in the current methods that result in noisy
multilingual preference data and further limited alignment performance: 1) Not
all English responses are of high quality, and using a response with low
quality may mislead the alignment for other languages. 2) Current methods
usually use biased or heuristic approaches to construct multilingual preference
pairs. To address these limitations, we design a consistency-based data
selection method to construct high-quality multilingual preference data for
improving multilingual alignment (CM-Align). Specifically, our method includes
two parts: consistency-guided English reference selection and cross-lingual
consistency-based multilingual preference data construction. Experimental
results on three LLMs and three common tasks demonstrate the effectiveness and
superiority of our method, which further indicates the necessity of
constructing high-quality preference data.
\\ ( https://arxiv.org/abs/2509.08541 ,  760kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08596
Date: Wed, 10 Sep 2025 13:50:49 GMT   (140kb)

Title: LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question
  Answering for BioASQ Challenge
Authors: Dima Galat, Diego Molla-Aliod
Categories: cs.CL
Comments: CEUR-WS, CLEF2025
\\
  Biomedical question answering (QA) poses significant challenges due to the
need for precise interpretation of specialized knowledge drawn from a vast,
complex, and rapidly evolving corpus. In this work, we explore how large
language models (LLMs) can be used for information retrieval (IR), and an
ensemble of zero-shot models can accomplish state-of-the-art performance on a
domain-specific Yes/No QA task. Evaluating our approach on the BioASQ challenge
tasks, we show that ensembles can outperform individual LLMs and in some cases
rival or surpass domain-tuned systems - all while preserving generalizability
and avoiding the need for costly fine-tuning or labeled data. Our method
aggregates outputs from multiple LLM variants, including models from Anthropic
and Google, to synthesize more accurate and robust answers. Moreover, our
investigation highlights a relationship between context length and performance:
while expanded contexts are meant to provide valuable evidence, they
simultaneously risk information dilution and model disorientation. These
findings emphasize IR as a critical foundation in Retrieval-Augmented
Generation (RAG) approaches for biomedical QA systems. Precise, focused
retrieval remains essential for ensuring LLMs operate within relevant
information boundaries when generating answers from retrieved documents. Our
results establish that ensemble-based zero-shot approaches, when paired with
effective RAG pipelines, constitute a practical and scalable alternative to
domain-tuned systems for biomedical question answering.
\\ ( https://arxiv.org/abs/2509.08596 ,  140kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08604
Date: Wed, 10 Sep 2025 14:02:18 GMT   (2328kb)

Title: Memorization in Large Language Models in Medicine: Prevalence,
  Characteristics, and Implications
Authors: Anran Li, Lingfei Qian, Mengmeng Du, Yu Yin, Yan Hu, Zihao Sun, Yihang
  Fu, Erica Stutz, Xuguang Ai, Qianqian Xie, Rui Zhu, Jimin Huang, Yifan Yang,
  Siru Liu, Yih-Chung Tham, Lucila Ohno-Machado, Hyunghoon Cho, Zhiyong Lu, Hua
  Xu, Qingyu Chen
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) have demonstrated significant potential in
medicine. To date, LLMs have been widely applied to tasks such as diagnostic
assistance, medical question answering, and clinical information synthesis.
However, a key open question remains: to what extent do LLMs memorize medical
training data. In this study, we present the first comprehensive evaluation of
memorization of LLMs in medicine, assessing its prevalence (how frequently it
occurs), characteristics (what is memorized), volume (how much content is
memorized), and potential downstream impacts (how memorization may affect
medical applications). We systematically analyze common adaptation scenarios:
(1) continued pretraining on medical corpora, (2) fine-tuning on standard
medical benchmarks, and (3) fine-tuning on real-world clinical data, including
over 13,000 unique inpatient records from Yale New Haven Health System. The
results demonstrate that memorization is prevalent across all adaptation
scenarios and significantly higher than reported in the general domain.
Memorization affects both the development and adoption of LLMs in medicine and
can be categorized into three types: beneficial (e.g., accurate recall of
clinical guidelines and biomedical references), uninformative (e.g., repeated
disclaimers or templated medical document language), and harmful (e.g.,
regeneration of dataset-specific or sensitive clinical content). Based on these
findings, we offer practical recommendations to facilitate beneficial
memorization that enhances domain-specific reasoning and factual accuracy,
minimize uninformative memorization to promote deeper learning beyond
surface-level patterns, and mitigate harmful memorization to prevent the
leakage of sensitive or identifiable patient information.
\\ ( https://arxiv.org/abs/2509.08604 ,  2328kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08612
Date: Wed, 10 Sep 2025 14:08:58 GMT   (1950kb)

Title: OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for
  Aspect-Based Sentiment Analysis
Authors: Xinfeng Liao, Xuanqi Chen, Lianxi Wang, Jiahuan Yang, Zhuowei Chen,
  Ziying Rong
Categories: cs.CL cs.AI
\\
  Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and
determine their sentiment polarity. While dependency trees combined with
contextual semantics effectively identify aspect sentiment, existing methods
relying on syntax trees and aspect-aware attention struggle to model complex
semantic relationships. Their dependence on linear dot-product features fails
to capture nonlinear associations, allowing noisy similarity from irrelevant
words to obscure key opinion terms. Motivated by Differentiable Optimal
Matching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph
Network (OTESGN), which introduces a Syntactic-Semantic Collaborative
Attention. It comprises a Syntactic Graph-Aware Attention for mining latent
syntactic dependencies and modeling global syntactic topology, as well as a
Semantic Optimal Transport Attention designed to uncover fine-grained semantic
alignments amidst textual noise, thereby accurately capturing sentiment signals
obscured by irrelevant tokens. A Adaptive Attention Fusion module integrates
these heterogeneous features, and contrastive regularization further improves
robustness. Experiments demonstrate that OTESGN achieves state-of-the-art
results, outperforming previous best models by +1.01% F1 on Twitter and +1.30%
F1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its
efficacy in precise localization of opinion words and noise resistance.
\\ ( https://arxiv.org/abs/2509.08612 ,  1950kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08729
Date: Wed, 10 Sep 2025 16:17:44 GMT   (542kb)

Title: X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to
  Single-turn Jailbreak Templates
Authors: Hyunjun Kim, Junwoo Ha, Sangyoon Yu, Haon Park
Categories: cs.CL cs.AI
\\
  Multi-turn-to-single-turn (M2S) compresses iterative red-teaming into one
structured prompt, but prior work relied on a handful of manually written
templates. We present X-Teaming Evolutionary M2S, an automated framework that
discovers and optimizes M2S templates through language-model-guided evolution.
The system pairs smart sampling from 12 sources with an LLM-as-judge inspired
by StrongREJECT and records fully auditable logs.
  Maintaining selection pressure by setting the success threshold to $\theta =
0.70$, we obtain five evolutionary generations, two new template families, and
44.8% overall success (103/230) on GPT-4.1. A balanced cross-model panel of
2,500 trials (judge fixed) shows that structural gains transfer but vary by
target; two models score zero at the same threshold. We also find a positive
coupling between prompt length and score, motivating length-aware judging.
  Our results demonstrate that structure-level search is a reproducible route
to stronger single-turn probes and underscore the importance of threshold
calibration and cross-model evaluation. Code, configurations, and artifacts are
available at https://github.com/hyunjun1121/M2S-x-teaming.
\\ ( https://arxiv.org/abs/2509.08729 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08753
Date: Wed, 10 Sep 2025 16:43:01 GMT   (339kb)

Title: Streaming Sequence-to-Sequence Learning with Delayed Streams Modeling
Authors: Neil Zeghidour, Eugene Kharitonov, Manu Orsini, V\'aclav Volhejn,
  Gabriel de Marmiesse, Edouard Grave, Patrick P\'erez, Laurent Mazar\'e,
  Alexandre D\'efossez
Categories: cs.CL
\\
  We introduce Delayed Streams Modeling (DSM), a flexible formulation for
streaming, multimodal sequence-to-sequence learning. Sequence-to-sequence
generation is often cast in an offline manner, where the model consumes the
complete input sequence before generating the first output timestep.
Alternatively, streaming sequence-to-sequence rely on learning a policy for
choosing when to advance on the input stream, or write to the output stream.
DSM instead models already time-aligned streams with a decoder-only language
model. By moving the alignment to a pre-processing step,and introducing
appropriate delays between streams, DSM provides streaming inference of
arbitrary output sequences, from any input combination, making it applicable to
many sequence-to-sequence problems. In particular, given text and audio
streams, automatic speech recognition (ASR) corresponds to the text stream
being delayed, while the opposite gives a text-to-speech (TTS) model. We
perform extensive experiments for these two major sequence-to-sequence tasks,
showing that DSM provides state-of-the-art performance and latency while
supporting arbitrary long sequences, being even competitive with offline
baselines. Code, samples and demos are available at
https://github.com/kyutai-labs/delayed-streams-modeling
\\ ( https://arxiv.org/abs/2509.08753 ,  339kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08778
Date: Wed, 10 Sep 2025 17:06:55 GMT   (5351kb)

Title: Do All Autoregressive Transformers Remember Facts the Same Way? A
  Cross-Architecture Analysis of Recall Mechanisms
Authors: Minyeong Choe, Haehyun Cho, Changho Seo, Hyunil Kim
Categories: cs.CL
Comments: Accepted at EMNLP 2025
\\
  Understanding how Transformer-based language models store and retrieve
factual associations is critical for improving interpretability and enabling
targeted model editing. Prior work, primarily on GPT-style models, has
identified MLP modules in early layers as key contributors to factual recall.
However, it remains unclear whether these findings generalize across different
autoregressive architectures. To address this, we conduct a comprehensive
evaluation of factual recall across several models -- including GPT, LLaMA,
Qwen, and DeepSeek -- analyzing where and how factual information is encoded
and accessed. Consequently, we find that Qwen-based models behave differently
from previous patterns: attention modules in the earliest layers contribute
more to factual recall than MLP modules. Our findings suggest that even within
the autoregressive Transformer family, architectural variations can lead to
fundamentally different mechanisms of factual recall.
\\ ( https://arxiv.org/abs/2509.08778 ,  5351kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08809
Date: Wed, 10 Sep 2025 17:42:41 GMT   (1635kb)

Title: Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation
  Through Unsupervised Consistency Signals
Authors: Cheng Chen, Haiyan Yin, Ivor Tsang
Categories: cs.CL
Comments: 11 pages, 10 figures
Journal-ref: Published ICLR 2025 Workshop on Scaling Self-Improving Foundation
  Models without Human Supervision
\\
  Large Language Models (LLMs), when paired with prompt-based tasks, have
significantly reduced data annotation costs and reliance on human annotators.
However, evaluating the quality of their annotations remains challenging in
dynamic, unsupervised environments where oracle feedback is scarce and
conventional methods fail. To address this challenge, we propose a novel
agentic annotation paradigm, where a student model collaborates with a noisy
teacher (the LLM) to assess and refine annotation quality without relying on
oracle feedback. The student model, acting as an unsupervised feedback
mechanism, employs a user preference-based majority voting strategy to evaluate
the consistency of the LLM outputs. To systematically measure the reliability
of LLM-generated annotations, we introduce the Consistent and Inconsistent
(CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only
quantifies the annotation quality of the noisy teacher under limited user
preferences but also plays a critical role in model selection, enabling the
identification of robust LLMs in dynamic, unsupervised environments. Applied to
ten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a
strong positive correlation with LLM accuracy, establishing it as an essential
tool for unsupervised evaluation and model selection in real-world settings.
\\ ( https://arxiv.org/abs/2509.08809 ,  1635kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08812
Date: Wed, 10 Sep 2025 17:45:10 GMT   (310kb)

Title: MoVoC: Morphology-Aware Subword Construction for Geez Script Languages
Authors: Hailay Kidu Teklehaymanot, Dren Fazlija, Wolfgang Nejdl
Categories: cs.CL cs.AI
Comments: This submission is approximately 10 pages in length and includes 1
  figure and 6 tables
ACM-class: I.2.7; I.2.6; H.3.3
\\
  Subword-based tokenization methods often fail to preserve morphological
boundaries, a limitation especially pronounced in low-resource, morphologically
complex languages such as those written in the Geez script. To address this, we
present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train
MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into
the subword vocabulary. This hybrid segmentation approach combines
morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological
integrity while maintaining lexical meaning. To tackle resource scarcity, we
curate and release manually annotated morpheme data for four Geez script
languages and a morpheme-aware vocabulary for two of them. While the proposed
tokenization method does not lead to significant gains in automatic translation
quality, we observe consistent improvements in intrinsic metrics, MorphoScore,
and Boundary Precision, highlighting the value of morphology-aware segmentation
in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated
datasets and tokenizer will be publicly available to support further research
in low-resource, morphologically rich languages. Our code and data are
available on GitHub: https://github.com/hailaykidu/MoVoC
\\ ( https://arxiv.org/abs/2509.08812 ,  310kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08824
Date: Wed, 10 Sep 2025 17:58:23 GMT   (272kb)

Title: Building High-Quality Datasets for Portuguese LLMs: From Common Crawl
  Snapshots to Industrial-Grade Corpora
Authors: Thales Sales Almeida, Rodrigo Nogueira, Helio Pedrini
Categories: cs.CL
\\
  The performance of large language models (LLMs) is deeply influenced by the
quality and composition of their training data. While much of the existing work
has centered on English, there remains a gap in understanding how to construct
effective training corpora for other languages. We explore scalable methods for
building web-based corpora for LLMs. We apply them to build a new 120B token
corpus in Portuguese that achieves competitive results to an industrial-grade
corpus. Using a continual pretraining setup, we study how different data
selection and preprocessing strategies affect LLM performance when
transitioning a model originally trained in English to another language. Our
findings demonstrate the value of language-specific filtering pipelines,
including classifiers for education, science, technology, engineering, and
mathematics (STEM), as well as toxic content. We show that adapting a model to
the target language leads to performance improvements, reinforcing the
importance of high-quality, language-specific data. While our case study
focuses on Portuguese, our methods are applicable to other languages, offering
insights for multilingual LLM development.
\\ ( https://arxiv.org/abs/2509.08824 ,  272kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08825
Date: Wed, 10 Sep 2025 17:58:53 GMT   (643kb)

Title: Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs
  for Text Annotation
Authors: Joachim Baumann, Paul R\"ottger, Aleksandra Urman, Albert Wendsj\"o,
  Flor Miriam Plaza-del-Arco, Johannes B. Gruber, Dirk Hovy
Categories: cs.CL cs.AI cs.LG
\\
  Large language models (LLMs) are rapidly transforming social science research
by enabling the automation of labor-intensive tasks like data annotation and
text analysis. However, LLM outputs vary significantly depending on the
implementation choices made by researchers (e.g., model selection, prompting
strategy, or temperature settings). Such variation can introduce systematic
biases and random errors, which propagate to downstream analyses and cause Type
I, Type II, Type S, or Type M errors. We call this LLM hacking.
  We quantify the risk of LLM hacking by replicating 37 data annotation tasks
from 21 published social science research studies with 18 different models.
Analyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure
how plausible researcher choices affect statistical conclusions. We find
incorrect conclusions based on LLM-annotated data in approximately one in three
hypotheses for state-of-the-art models, and in half the hypotheses for small
language models. While our findings show that higher task performance and
better general model capabilities reduce LLM hacking risk, even highly accurate
models do not completely eliminate it. The risk of LLM hacking decreases as
effect sizes increase, indicating the need for more rigorous verification of
findings near significance thresholds. Our extensive analysis of LLM hacking
mitigation techniques emphasizes the importance of human annotations in
reducing false positive findings and improving model selection. Surprisingly,
common regression estimator correction techniques are largely ineffective in
reducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors.
  Beyond accidental errors, we find that intentional LLM hacking is
unacceptably simple. With few LLMs and just a handful of prompt paraphrases,
anything can be presented as statistically significant.
\\ ( https://arxiv.org/abs/2509.08825 ,  643kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08827
Date: Wed, 10 Sep 2025 17:59:43 GMT   (1204kb)

Title: A Survey of Reinforcement Learning for Large Reasoning Models
Authors: Kaiyan Zhang, Yuxin Zuo, Bingxiang He, Youbang Sun, Runze Liu, Che
  Jiang, Yuchen Fan, Kai Tian, Guoli Jia, Pengfei Li, Yu Fu, Xingtai Lv, Yuchen
  Zhang, Sihang Zeng, Shang Qu, Haozhan Li, Shijie Wang, Yuru Wang, Xinwei
  Long, Fangfu Liu, Xiang Xu, Jiaze Ma, Xuekai Zhu, Ermo Hua, Yihao Liu,
  Zonglin Li, Huayu Chen, Xiaoye Qu, Yafu Li, Weize Chen, Zhenzhao Yuan, Junqi
  Gao, Dong Li, Zhiyuan Ma, Ganqu Cui, Zhiyuan Liu, Biqing Qi, Ning Ding, Bowen
  Zhou
Categories: cs.CL cs.AI cs.LG
\\
  In this paper, we survey recent advances in Reinforcement Learning (RL) for
reasoning with Large Language Models (LLMs). RL has achieved remarkable success
in advancing the frontier of LLM capabilities, particularly in addressing
complex logical tasks such as mathematics and coding. As a result, RL has
emerged as a foundational methodology for transforming LLMs into LRMs. With the
rapid progress of the field, further scaling of RL for LRMs now faces
foundational challenges not only in computational resources but also in
algorithm design, training data, and infrastructure. To this end, it is timely
to revisit the development of this domain, reassess its trajectory, and explore
strategies to enhance the scalability of RL toward Artificial SuperIntelligence
(ASI). In particular, we examine research applying RL to LLMs and LRMs for
reasoning abilities, especially since the release of DeepSeek-R1, including
foundational components, core problems, training resources, and downstream
applications, to identify future opportunities and directions for this rapidly
evolving area. We hope this review will promote future research on RL for
broader reasoning models. Github:
https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs
\\ ( https://arxiv.org/abs/2509.08827 ,  1204kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07996
Date: Thu, 4 Sep 2025 17:59:58 GMT   (7432kb)

Title: 3D and 4D World Modeling: A Survey
Authors: Lingdong Kong, Wesley Yang, Jianbiao Mei, Youquan Liu, Ao Liang, Dekai
  Zhu, Dongyue Lu, Wei Yin, Xiaotao Hu, Mingkai Jia, Junyuan Deng, Kaiwen
  Zhang, Yang Wu, Tianyi Yan, Shenyuan Gao, Song Wang, Linfeng Li, Liang Pan,
  Yong Liu, Jianke Zhu, Wei Tsang Ooi, Steven C.H. Hoi, Ziwei Liu
Categories: cs.CV cs.RO
Comments: Survey; 34 pages, 10 figures, 14 tables; GitHub Repo at
  https://github.com/worldbench/survey
\\
  World modeling has become a cornerstone in AI research, enabling agents to
understand, represent, and predict the dynamic environments they inhabit. While
prior work largely emphasizes generative methods for 2D image and video data,
they overlook the rapidly growing body of work that leverages native 3D and 4D
representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds
for large-scale scene modeling. At the same time, the absence of a standardized
definition and taxonomy for ``world models'' has led to fragmented and
sometimes inconsistent claims in the literature. This survey addresses these
gaps by presenting the first comprehensive review explicitly dedicated to 3D
and 4D world modeling and generation. We establish precise definitions,
introduce a structured taxonomy spanning video-based (VideoGen),
occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and
systematically summarize datasets and evaluation metrics tailored to 3D/4D
settings. We further discuss practical applications, identify open challenges,
and highlight promising research directions, aiming to provide a coherent and
foundational reference for advancing the field. A systematic summary of
existing literature is available at https://github.com/worldbench/survey
\\ ( https://arxiv.org/abs/2509.07996 ,  7432kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08003
Date: Sun, 7 Sep 2025 19:39:28 GMT   (14626kb)

Title: An Explainable Deep Neural Network with Frequency-Aware Channel and
  Spatial Refinement for Flood Prediction in Sustainable Cities
Authors: Shahid Shafi Dar, Bharat Kaurav, Arnav Jain, Chandravardhan Singh
  Raghaw, Mohammad Zia Ur Rehman, Nagendra Kumar
Categories: cs.CV
DOI: 10.1016/j.scs.2025.106480
\\
  In an era of escalating climate change, urban flooding has emerged as a
critical challenge for sustainable cities, threatening lives, infrastructure,
and ecosystems. Traditional flood detection methods are constrained by their
reliance on unimodal data and static rule-based systems, which fail to capture
the dynamic, non-linear relationships inherent in flood events. Furthermore,
existing attention mechanisms and ensemble learning approaches exhibit
limitations in hierarchical refinement, cross-modal feature integration, and
adaptability to noisy or unstructured environments, resulting in suboptimal
flood classification performance. To address these challenges, we present
XFloodNet, a novel framework that redefines urban flood classification through
advanced deep-learning techniques. XFloodNet integrates three novel components:
(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically
aligns visual and textual features, enabling precise multi-granularity
interactions and resolving contextual ambiguities; (2) a Heterogeneous
Convolutional Adaptive Multi-Scale Attention module, which leverages
frequency-enhanced channel attention and frequency-modulated spatial attention
to extract and prioritize discriminative flood-related features across spectral
and spatial domains; and (3) a Cascading Convolutional Transformer Feature
Refinement technique that harmonizes hierarchical features through adaptive
scaling and cascading operations, ensuring robust and noise-resistant flood
detection. We evaluate our proposed method on three benchmark datasets, such as
Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves
state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,
surpassing existing methods by significant margins.
\\ ( https://arxiv.org/abs/2509.08003 ,  14626kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08016
Date: Tue, 9 Sep 2025 00:55:04 GMT   (2321kb)

Title: Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs
Authors: Hyungjin Chung, Hyelin Nam, Jiyeon Kim, Hyojun Go, Byeongjun Park,
  Junho Kim, Joonseok Lee, Seongsu Ha, Byung-Hoon Kim
Categories: cs.CV cs.LG
Comments: https://github.com/hyungjin-chung/VPS
\\
  Video Large Language Models (VideoLLMs) face a critical bottleneck:
increasing the number of input frames to capture fine-grained temporal detail
leads to prohibitive computational costs and performance degradation from long
context lengths. We introduce Video Parallel Scaling (VPS), an inference-time
method that expands a model's perceptual bandwidth without increasing its
context window. VPS operates by running multiple parallel inference streams,
each processing a unique, disjoint subset of the video's frames. By aggregating
the output probabilities from these complementary streams, VPS integrates a
richer set of visual information than is possible with a single pass. We
theoretically show that this approach effectively contracts the Chinchilla
scaling law by leveraging uncorrelated visual evidence, thereby improving
performance without additional training. Extensive experiments across various
model architectures and scales (2B-32B) on benchmarks such as Video-MME and
EventHallusion demonstrate that VPS consistently and significantly improves
performance. It scales more favorably than other parallel alternatives (e.g.
Self-consistency) and is complementary to other decoding strategies, offering a
memory-efficient and robust framework for enhancing the temporal reasoning
capabilities of VideoLLMs.
\\ ( https://arxiv.org/abs/2509.08016 ,  2321kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08024
Date: Tue, 9 Sep 2025 10:22:10 GMT   (2254kb)

Title: Two Stage Context Learning with Large Language Models for Multimodal
  Stance Detection on Climate Change
Authors: Lata Pangtey, Omkar Kabde, Shahid Shafi Dar, Nagendra Kumar
Categories: cs.CV cs.CY
\\
  With the rapid proliferation of information across digital platforms, stance
detection has emerged as a pivotal challenge in social media analysis. While
most of the existing approaches focus solely on textual data, real-world social
media content increasingly combines text with visual elements creating a need
for advanced multimodal methods. To address this gap, we propose a multimodal
stance detection framework that integrates textual and visual information
through a hierarchical fusion approach. Our method first employs a Large
Language Model to retrieve stance-relevant summaries from source text, while a
domain-aware image caption generator interprets visual content in the context
of the target topic. These modalities are then jointly modeled along with the
reply text, through a specialized transformer module that captures interactions
between the texts and images. The proposed modality fusion framework integrates
diverse modalities to facilitate robust stance classification. We evaluate our
approach on the MultiClimate dataset, a benchmark for climate change-related
stance detection containing aligned video frames and transcripts. We achieve
accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%,
respectively, outperforming existing state-of-the-art approaches.
\\ ( https://arxiv.org/abs/2509.08024 ,  2254kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08026
Date: Tue, 9 Sep 2025 13:03:12 GMT   (2224kb)

Title: Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL)
  for Vehicle Detection Using Unmanned Aerial Vehicles
Authors: Zeinab Ghasemi Darehnaei, Mohammad Shokouhifar, Hossein Yazdanjouei,
  S.M.J. Rastegar Fatemi
Categories: cs.CV cs.AI
Journal-ref: Concurrency and Computation: Practice and Experience, 2022, 34(5),
  e6726
DOI: 10.1002/cpe.6726
\\
  This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep
transfer learning model for detecting multiple vehicles in UAV images. It
combines three pre-trained Faster R-CNN feature extractor models (InceptionV3,
ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,
Na\"ive Bayes), resulting in 15 different base learners. These are aggregated
via weighted averaging to classify regions as Car, Van, Truck, Bus, or
background. Hyperparameters are optimized with the whale optimization algorithm
to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with
parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV
dataset.
\\ ( https://arxiv.org/abs/2509.08026 ,  2224kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08027
Date: Tue, 9 Sep 2025 13:14:49 GMT   (24918kb)

Title: MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model
  Generation From Mars Imagery
Authors: Rafa{\l} Osadnik, Pablo G\'omez, Eleni Bohacek, Rickbir Bahia
Categories: cs.CV cs.LG
Comments: 22 pages, 21 figures
\\
  This work presents a new dataset for the Martian digital elevation model
prediction task, ready for machine learning applications called MCTED. The
dataset has been generated using a comprehensive pipeline designed to process
high-resolution Mars orthoimage and DEM pairs from Day et al., yielding a
dataset consisting of 80,898 data samples. The source images are data gathered
by the Mars Reconnaissance Orbiter using the CTX instrument, providing a very
diverse and comprehensive coverage of the Martian surface. Given the complexity
of the processing pipelines used in large-scale DEMs, there are often artefacts
and missing data points in the original data, for which we developed tools to
solve or mitigate their impact. We divide the processed samples into training
and validation splits, ensuring samples in both splits cover no mutual areas to
avoid data leakage. Every sample in the dataset is represented by the optical
image patch, DEM patch, and two mask patches, indicating values that were
originally missing or were altered by us. This allows future users of the
dataset to handle altered elevation regions as they please. We provide
statistical insights of the generated dataset, including the spatial
distribution of samples, the distributions of elevation values, slopes and
more. Finally, we train a small U-Net architecture on the MCTED dataset and
compare its performance to a monocular depth estimation foundation model,
DepthAnythingV2, on the task of elevation prediction. We find that even a very
small architecture trained on this dataset specifically, beats a zero-shot
performance of a depth estimation foundation model like DepthAnythingV2. We
make the dataset and code used for its generation completely open source in
public repositories.
\\ ( https://arxiv.org/abs/2509.08027 ,  24918kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08104
Date: Tue, 9 Sep 2025 19:31:06 GMT   (1789kb)

Title: APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud
  Reconstruction
Authors: Sasan Sharifipour, Constantino \'Alvarez Casado, Mohammad Sabokrou,
  Miguel Bordallo L\'opez
Categories: cs.CV cs.AI
Comments: 22 pages, 6 figures, conference, 7 tables, 15 formulas
\\
  Training deep learning models for point cloud prediction tasks such as shape
completion and generation depends critically on loss functions that measure
discrepancies between predicted and ground-truth point sets. Commonly used
functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on
nearest-neighbor assignments, which often induce many-to-one correspondences,
leading to point congestion in dense regions and poor coverage in sparse
regions. These losses also involve non-differentiable operations due to index
selection, which may affect gradient-based optimization. Earth Mover Distance
(EMD) enforces one-to-one correspondences and captures structural similarity
more effectively, but its cubic computational complexity limits its practical
use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully
differentiable approximation of one-to-one matching that leverages Sinkhorn
iterations on a temperature-scaled similarity matrix derived from pairwise
distances. We analytically compute the temperature to guarantee a minimum
assignment probability, eliminating manual tuning. APML achieves near-quadratic
runtime, comparable to Chamfer-based losses, and avoids non-differentiable
operations. When integrated into state-of-the-art architectures (PoinTr, PCN,
FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)
that generates 3D human point clouds from WiFi CSI measurements, APM loss
yields faster convergence, superior spatial distribution, especially in
low-density regions, and improved or on-par quantitative performance without
additional hyperparameter search. The code is available at:
https://github.com/apm-loss/apml.
\\ ( https://arxiv.org/abs/2509.08104 ,  1789kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08205
Date: Wed, 10 Sep 2025 00:23:32 GMT   (10672kb)

Title: Lightweight Deep Unfolding Networks with Enhanced Robustness for
  Infrared Small Target Detection
Authors: Jingjing Liu, Yinchao Han, Xianchao Xiu, Jianhua Zhang, Wanquan Liu
Categories: cs.CV
\\
  Infrared small target detection (ISTD) is one of the key techniques in image
processing. Although deep unfolding networks (DUNs) have demonstrated promising
performance in ISTD due to their model interpretability and data adaptability,
existing methods still face significant challenges in parameter lightweightness
and noise robustness. In this regard, we propose a highly lightweight framework
based on robust principal component analysis (RPCA) called L-RPCANet.
Technically, a hierarchical bottleneck structure is constructed to reduce and
increase the channel dimension in the single-channel input infrared image to
achieve channel-wise feature refinement, with bottleneck layers designed in
each module to extract features. This reduces the number of channels in feature
extraction and improves the lightweightness of network parameters. Furthermore,
a noise reduction module is embedded to enhance the robustness against complex
noise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a
channel attention mechanism to focus on the varying importance of different
features across channels, thereby achieving excellent performance while
maintaining both lightweightness and robustness. Extensive experiments on the
ISTD datasets validate the superiority of our proposed method compared with
state-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code
will be available at https://github.com/xianchaoxiu/L-RPCANet.
\\ ( https://arxiv.org/abs/2509.08205 ,  10672kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08228
Date: Wed, 10 Sep 2025 02:03:06 GMT   (10653kb)

Title: Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing
Authors: Miao Cao, Siming Zheng, Lishun Wang, Ziyang Chen, David Brady, Xin
  Yuan
Categories: cs.CV
\\
  Digital cameras consume ~0.1 microjoule per pixel to capture and encode
video, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps.
Imagining gigapixel cameras operating at 100-1000 fps, the current processing
model is unsustainable. To address this, physical layer compressive measurement
has been proposed to reduce power consumption per pixel by 10-100X. Video
Snapshot Compressive Imaging (SCI) introduces high frequency modulation in the
optical sensor layer to increase effective frame rate. A commonly used sampling
strategy of video SCI is Random Sampling (RS) where each mask element value is
randomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated
that images can be recovered from a fraction of the image pixels. Inspired by
I2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial
location, only one sub-frame is set to 1 and all others are set to 0. We then
build a Digital Micro-mirror Device (DMD) encoding system to verify the
effectiveness of our USS strategy. Ideally, we can decompose the USS
measurement into sub-measurements for which we can utilize I2P algorithms to
recover high-speed frames. However, due to the mismatch between the DMD and
CCD, the USS measurement cannot be perfectly decomposed. To this end, we
propose BSTFormer, a sparse TransFormer that utilizes local Block attention,
global Sparse attention, and global Temporal attention to exploit the sparsity
of the USS measurement. Extensive results on both simulated and real-world data
show that our method significantly outperforms all previous state-of-the-art
algorithms. Additionally, an essential advantage of the USS strategy is its
higher dynamic range than that of the RS strategy. Finally, from the
application perspective, the USS strategy is a good choice to implement a
complete video SCI system on chip due to its fixed exposure time.
\\ ( https://arxiv.org/abs/2509.08228 ,  10653kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08232
Date: Wed, 10 Sep 2025 02:12:11 GMT   (432kb)

Title: GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal
  Violence Detection with Adversarial Snippet-Level Domain Adaptation
Authors: Seongho Kim, Sejong Ryu, Hyoukjun You, Je Hyeong Hong
Categories: cs.CV
\\
  Recent advancements in video anomaly detection (VAD) have enabled
identification of various criminal activities in surveillance videos, but
detecting fatal incidents such as shootings and stabbings remains difficult due
to their rarity and ethical issues in data collection. Recognizing this
limitation, we introduce GTA-Crime, a fatal video anomaly dataset and
generation framework using Grand Theft Auto 5 (GTA5). Our dataset contains
fatal situations such as shootings and stabbings, captured from CCTV multiview
perspectives under diverse conditions including action types, weather, time of
day, and viewpoints. To address the rarity of such scenarios, we also release a
framework for generating these types of videos. Additionally, we propose a
snippet-level domain adaptation strategy using Wasserstein adversarial training
to bridge the gap between synthetic GTA-Crime features and real-world features
like UCF-Crime. Experimental results validate our GTA-Crime dataset and
demonstrate that incorporating GTA-Crime with our domain adaptation strategy
consistently enhances real world fatal violence detection accuracy. Our dataset
and the data generation framework are publicly available at
https://github.com/ta-ho/GTA-Crime.
\\ ( https://arxiv.org/abs/2509.08232 ,  432kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08234
Date: Wed, 10 Sep 2025 02:28:25 GMT   (413kb)

Title: RepViT-CXR: A Channel Replication Strategy for Vision Transformers in
  Chest X-ray Tuberculosis and Pneumonia Classification
Authors: Faisal Ahmed
Categories: cs.CV cs.LG
Comments: 10 pages, 5 figures
ACM-class: F.2.2; I.2.7
\\
  Chest X-ray (CXR) imaging remains one of the most widely used diagnostic
tools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia.
Recent advances in deep learning, particularly Vision Transformers (ViTs), have
shown strong potential for automated medical image analysis. However, most ViT
architectures are pretrained on natural images and require three-channel
inputs, while CXR scans are inherently grayscale. To address this gap, we
propose RepViT-CXR, a channel replication strategy that adapts single-channel
CXR images into a ViT-compatible format without introducing additional
information loss. We evaluate RepViT-CXR on three benchmark datasets. On the
TB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%,
surpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy,
99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0%
accuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%,
outperforming strong baselines including DCNN and VGG16. On the Shenzhen TB
dataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a
performance improvement over previously reported CNN-based methods. These
results demonstrate that a simple yet effective channel replication strategy
allows ViTs to fully leverage their representational power on grayscale medical
imaging tasks. RepViT-CXR establishes a new state of the art for TB and
pneumonia detection from chest X-rays, showing strong potential for deployment
in real-world clinical screening systems.
\\ ( https://arxiv.org/abs/2509.08234 ,  413kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08243
Date: Wed, 10 Sep 2025 02:56:33 GMT   (506kb)

Title: Symmetry Interactive Transformer with CNN Framework for Diagnosis of
  Alzheimer's Disease Using Structural MRI
Authors: Zheng Yang, Yanteng Zhang, Xupeng Kou, Yang Liu, Chao Ren
Categories: cs.CV
\\
  Structural magnetic resonance imaging (sMRI) combined with deep learning has
achieved remarkable progress in the prediction and diagnosis of Alzheimer's
disease (AD). Existing studies have used CNN and transformer to build a
well-performing network, but most of them are based on pretraining or ignoring
the asymmetrical character caused by brain disorders. We propose an end-to-end
network for the detection of disease-based asymmetric induced by left and right
brain atrophy which consist of 3D CNN Encoder and Symmetry Interactive
Transformer (SIT). Following the inter-equal grid block fetch operation, the
corresponding left and right hemisphere features are aligned and subsequently
fed into the SIT for diagnostic analysis. SIT can help the model focus more on
the regions of asymmetry caused by structural changes, thus improving
diagnostic performance. We evaluated our method based on the ADNI dataset, and
the results show that the method achieves better diagnostic accuracy (92.5\%)
compared to several CNN methods and CNNs combined with a general transformer.
The visualization results show that our network pays more attention in regions
of brain atrophy, especially for the asymmetric pathological characteristics
induced by AD, demonstrating the interpretability and effectiveness of the
method.
\\ ( https://arxiv.org/abs/2509.08243 ,  506kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08260
Date: Wed, 10 Sep 2025 03:36:24 GMT   (18489kb)

Title: EVDI++: Event-based Video Deblurring and Interpolation via
  Self-Supervised Learning
Authors: Chi Zhang and Xiang Zhang and Chenxu Jiang and Gui-Song Xia and Lei Yu
Categories: cs.CV
Comments: 18 pages
\\
  Frame-based cameras with extended exposure times often produce perceptible
visual blurring and information loss between frames, significantly degrading
video quality. To address this challenge, we introduce EVDI++, a unified
self-supervised framework for Event-based Video Deblurring and Interpolation
that leverages the high temporal resolution of event cameras to mitigate motion
blur and enable intermediate frame prediction. Specifically, the Learnable
Double Integral (LDI) network is designed to estimate the mapping relation
between reference frames and sharp latent images. Then, we refine the coarse
results and optimize overall training efficiency by introducing a
learning-based division reconstruction module, enabling images to be converted
with varying exposure intervals. We devise an adaptive parameter-free fusion
strategy to obtain the final results, utilizing the confidence embedded in the
LDI outputs of concurrent events. A self-supervised learning framework is
proposed to enable network training with real-world blurry videos and events by
exploring the mutual constraints among blurry frames, latent images, and event
streams. We further construct a dataset with real-world blurry images and
events using a DAVIS346c camera, demonstrating the generalizability of the
proposed EVDI++ in real-world scenarios. Extensive experiments on both
synthetic and real-world datasets show that our method achieves
state-of-the-art performance in video deblurring and interpolation tasks.
\\ ( https://arxiv.org/abs/2509.08260 ,  18489kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08265
Date: Wed, 10 Sep 2025 03:47:43 GMT   (5761kb)

Title: Hyperspectral Mamba for Hyperspectral Object Tracking
Authors: Long Gao, Yunhe Zhang, Yan Jiang, Weiying Xie, Yunsong Li
Categories: cs.CV
\\
  Hyperspectral object tracking holds great promise due to the rich spectral
information and fine-grained material distinctions in hyperspectral images,
which are beneficial in challenging scenarios. While existing hyperspectral
trackers have made progress by either transforming hyperspectral data into
false-color images or incorporating modality fusion strategies, they often fail
to capture the intrinsic spectral information, temporal dependencies, and
cross-depth interactions. To address these limitations, a new hyperspectral
object tracking network equipped with Mamba (HyMamba), is proposed. It unifies
spectral, cross-depth, and temporal modeling through state space modules
(SSMs). The core of HyMamba lies in the Spectral State Integration (SSI)
module, which enables progressive refinement and propagation of spectral
features with cross-depth and temporal spectral information. Embedded within
each SSI, the Hyperspectral Mamba (HSM) module is introduced to learn spatial
and spectral information synchronously via three directional scanning SSMs.
Based on SSI and HSM, HyMamba constructs joint features from false-color and
hyperspectral inputs, and enhances them through interaction with original
spectral features extracted from raw hyperspectral images. Extensive
experiments conducted on seven benchmark datasets demonstrate that HyMamba
achieves state-of-the-art performance. For instance, it achieves 73.0\% of the
AUC score and 96.3\% of the DP@20 score on the HOTC2020 dataset. The code will
be released at https://github.com/lgao001/HyMamba.
\\ ( https://arxiv.org/abs/2509.08265 ,  5761kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08266
Date: Wed, 10 Sep 2025 03:49:40 GMT   (11993kb)

Title: Examining Vision Language Models through Multi-dimensional Experiments
  with Vision and Text Features
Authors: Saurav Sengupta, Nazanin Moradinasab, Jiebei Liu, Donald E. Brown
Categories: cs.CV
\\
  Recent research on Vision Language Models (VLMs) suggests that they rely on
inherent biases learned during training to respond to questions about visual
properties of an image. These biases are exacerbated when VLMs are asked highly
specific questions that require focusing on specific areas of the image. For
example, a VLM tasked with counting stars on a modified American flag (e.g.,
with more than 50 stars) will often disregard the visual evidence and fail to
answer accurately. We build upon this research and develop a multi-dimensional
examination framework to systematically determine which characteristics of the
input data, including both the image and the accompanying prompt, lead to such
differences in performance. Using open-source VLMs, we further examine how
attention values fluctuate with varying input parameters (e.g., image size,
number of objects in the image, background color, prompt specificity). This
research aims to learn how the behavior of vision language models changes and
to explore methods for characterizing such changes. Our results suggest, among
other things, that even minor modifications in image characteristics and prompt
specificity can lead to large changes in how a VLM formulates its answer and,
subsequently, its overall performance.
\\ ( https://arxiv.org/abs/2509.08266 ,  11993kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08280
Date: Wed, 10 Sep 2025 04:37:00 GMT   (6731kb)

Title: Generalized Zero-Shot Learning for Point Cloud Segmentation with
  Evidence-Based Dynamic Calibration
Authors: Hyeonseok Kim, Byeongkeun Kang, Yeejin Lee
Categories: cs.CV
Comments: 20 pages, 12 figures, AAAI 2025
Journal-ref: Proceedings of the AAAI Conference on Artificial Intelligence,
  39(4), 4248-4256 (2025)
DOI: 10.1609/aaai.v39i4.32446
\\
  Generalized zero-shot semantic segmentation of 3D point clouds aims to
classify each point into both seen and unseen classes. A significant challenge
with these models is their tendency to make biased predictions, often favoring
the classes encountered during training. This problem is more pronounced in 3D
applications, where the scale of the training data is typically smaller than in
image-based tasks. To address this problem, we propose a novel method called
E3DPC-GZSL, which reduces overconfident predictions towards seen classes
without relying on separate classifiers for seen and unseen data. E3DPC-GZSL
tackles the overconfidence problem by integrating an evidence-based uncertainty
estimator into a classifier. This estimator is then used to adjust prediction
probabilities using a dynamic calibrated stacking factor that accounts for
pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel
training strategy that improves uncertainty estimation by refining the semantic
space. This is achieved by merging learnable parameters with text-derived
features, thereby improving model optimization for unseen data. Extensive
experiments demonstrate that the proposed approach achieves state-of-the-art
performance on generalized zero-shot semantic segmentation datasets, including
ScanNet v2 and S3DIS.
\\ ( https://arxiv.org/abs/2509.08280 ,  6731kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08289
Date: Wed, 10 Sep 2025 05:12:03 GMT   (3231kb)

Title: Dual-Thresholding Heatmaps to Cluster Proposals for Weakly Supervised
  Object Detection
Authors: Yuelin Guo, Haoyu He, Zhiyuan Chen, Zitong Huang, Renhao Lu, Lu Shi,
  Zejun Wang, Weizhe Zhang
Categories: cs.CV
Comments: This work has been submitted to the IEEE for possible publication
\\
  Weakly supervised object detection (WSOD) has attracted significant attention
in recent years, as it does not require box-level annotations. State-of-the-art
methods generally adopt a multi-module network, which employs WSDDN as the
multiple instance detection network module and multiple instance refinement
modules to refine performance. However, these approaches suffer from three key
limitations. First, existing methods tend to generate pseudo GT boxes that
either focus only on discriminative parts, failing to capture the whole object,
or cover the entire object but fail to distinguish between adjacent intra-class
instances. Second, the foundational WSDDN architecture lacks a crucial
background class representation for each proposal and exhibits a large semantic
gap between its branches. Third, prior methods discard ignored proposals during
optimization, leading to slow convergence. To address these challenges, we
first design a heatmap-guided proposal selector (HGPS) algorithm, which
utilizes dual thresholds on heatmaps to pre-select proposals, enabling pseudo
GT boxes to both capture the full object extent and distinguish between
adjacent intra-class instances. We then present a weakly supervised basic
detection network (WSBDN), which augments each proposal with a background class
representation and uses heatmaps for pre-supervision to bridge the semantic gap
between matrices. At last, we introduce a negative certainty supervision loss
on ignored proposals to accelerate convergence. Extensive experiments on the
challenging PASCAL VOC 2007 and 2012 datasets demonstrate the effectiveness of
our framework. We achieve mAP/mCorLoc scores of 58.5%/81.8% on VOC 2007 and
55.6%/80.5% on VOC 2012, performing favorably against the state-of-the-art WSOD
methods. Our code is publicly available at
https://github.com/gyl2565309278/DTH-CP.
\\ ( https://arxiv.org/abs/2509.08289 ,  3231kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08303
Date: Wed, 10 Sep 2025 05:59:00 GMT   (2661kb)

Title: An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm
  Mapping in Indonesia
Authors: M. Warizmi Wafiq, Peter Cutter, Ate Poortinga, Daniel Marc G. dela
  Torre, Karis Tenneson, Vanna Teck, Enikoe Bihari, Chanarun Saisaward,
  Weraphong Suaruang, Andrea McMahon, Andi Vika Faradiba Muin, Karno B.
  Batiran, Chairil A, Nurul Qomar, Arya Arismaya Metananda, David Ganz, David
  Saah
Categories: cs.CV
\\
  Oil palm cultivation remains one of the leading causes of deforestation in
Indonesia. To better track and address this challenge, detailed and reliable
mapping is needed to support sustainability efforts and emerging regulatory
frameworks. We present an open-access geospatial dataset of oil palm
plantations and related land cover types in Indonesia, produced through expert
labeling of high-resolution satellite imagery from 2020 to 2024. The dataset
provides polygon-based, wall-to-wall annotations across a range of
agro-ecological zones and includes a hierarchical typology that distinguishes
oil palm planting stages as well as similar perennial crops. Quality was
ensured through multi-interpreter consensus and field validation. The dataset
was created using wall-to-wall digitization over large grids, making it
suitable for training and benchmarking both conventional convolutional neural
networks and newer geospatial foundation models. Released under a CC-BY
license, it fills a key gap in training data for remote sensing and aims to
improve the accuracy of land cover types mapping. By supporting transparent
monitoring of oil palm expansion, the resource contributes to global
deforestation reduction goals and follows FAIR data principles.
\\ ( https://arxiv.org/abs/2509.08303 ,  2661kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08311
Date: Wed, 10 Sep 2025 06:20:53 GMT   (543kb)

Title: SimCroP: Radiograph Representation Learning with Similarity-driven
  Cross-granularity Pre-training
Authors: Rongsheng Wang, Fenghe Tang, Qingsong Yao, Rui Yan, Xu Zhang, Zhen
  Huang, Haoran Lai, Zhiyang He, Xiaodong Tao, Zihang Jiang, Shaohua Kevin Zhou
Categories: cs.CV
Comments: Accepted by MICCAI 2025
\\
  Medical vision-language pre-training shows great potential in learning
representative features from massive paired radiographs and reports. However,
in computed tomography (CT) scans, the distribution of lesions which contain
intricate structures is characterized by spatial sparsity. Besides, the complex
and implicit relationships between different pathological descriptions in each
sentence of the report and their corresponding sub-regions in radiographs pose
additional challenges. In this paper, we propose a Similarity-Driven
Cross-Granularity Pre-training (SimCroP) framework on chest CTs, which combines
similarity-driven alignment and cross-granularity fusion to improve radiograph
interpretation. We first leverage multi-modal masked modeling to optimize the
encoder for understanding precise low-level semantics from radiographs. Then,
similarity-driven alignment is designed to pre-train the encoder to adaptively
select and align the correct patches corresponding to each sentence in reports.
The cross-granularity fusion module integrates multimodal information across
instance level and word-patch level, which helps the model better capture key
pathology structures in sparse radiographs, resulting in improved performance
for multi-scale downstream tasks. SimCroP is pre-trained on a large-scale
paired CT-reports dataset and validated on image classification and
segmentation tasks across five public datasets. Experimental results
demonstrate that SimCroP outperforms both cutting-edge medical self-supervised
learning methods and medical vision-language pre-training methods. Codes and
models are available at https://github.com/ToniChopp/SimCroP.
\\ ( https://arxiv.org/abs/2509.08311 ,  543kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08318
Date: Wed, 10 Sep 2025 06:47:49 GMT   (532kb)

Title: Boosted Training of Lightweight Early Exits for Optimizing CNN Image
  Classification Inference
Authors: Yehudit Aperstein, Alexander Apartsin
Categories: cs.CV
Comments: 9 pages, 4 figures
\\
  Real-time image classification on resource-constrained platforms demands
inference methods that balance accuracy with strict latency and power budgets.
Early-exit strategies address this need by attaching auxiliary classifiers to
intermediate layers of convolutional neural networks (CNNs), allowing "easy"
samples to terminate inference early. However, conventional training of early
exits introduces a covariance shift: downstream branches are trained on full
datasets, while at inference they process only the harder, non-exited samples.
This mismatch limits efficiency--accuracy trade-offs in practice. We introduce
the Boosted Training Scheme for Early Exits (BTS-EE), a sequential training
approach that aligns branch training with inference-time data distributions.
Each branch is trained and calibrated before the next, ensuring robustness
under selective inference conditions. To further support embedded deployment,
we propose a lightweight branch architecture based on 1D convolutions and a
Class Precision Margin (CPM) calibration method that enables per-class
threshold tuning for reliable exit decisions. Experiments on the CINIC-10
dataset with a ResNet18 backbone demonstrate that BTS-EE consistently
outperforms non-boosted training across 64 configurations, achieving up to 45
percent reduction in computation with only 2 percent accuracy degradation.
These results expand the design space for deploying CNNs in real-time image
processing systems, offering practical efficiency gains for applications such
as industrial inspection, embedded vision, and UAV-based monitoring.
\\ ( https://arxiv.org/abs/2509.08318 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08338
Date: Wed, 10 Sep 2025 07:23:30 GMT   (4176kb)

Title: Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis
Authors: Jihyun Moon, Charmgil Hong
Categories: cs.CV cs.AI cs.LG
Comments: Medical Image Computing and Computer-Assisted Intervention (MICCAI)
  ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2025; 10 pages
\\
  Accurate and early diagnosis of malignant melanoma is critical for improving
patient outcomes. While convolutional neural networks (CNNs) have shown promise
in dermoscopic image analysis, they often neglect clinical metadata and require
extensive preprocessing. Vision-language models (VLMs) offer a multimodal
alternative but struggle to capture clinical specificity when trained on
general-domain data. To address this, we propose a retrieval-augmented VLM
framework that incorporates semantically similar patient cases into the
diagnostic prompt. Our method enables informed predictions without fine-tuning
and significantly improves classification accuracy and error correction over
conventional baselines. These results demonstrate that retrieval-augmented
prompting provides a robust strategy for clinical decision support.
\\ ( https://arxiv.org/abs/2509.08338 ,  4176kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08374
Date: Wed, 10 Sep 2025 08:12:15 GMT   (265kb)

Title: InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object
  Detection
Authors: Zhongyu Xia, Hansong Yang, Yongtao Wang
Categories: cs.CV
\\
  Three-dimensional Object Detection from multi-view cameras and LiDAR is a
crucial component for autonomous driving and smart transportation. However, in
the process of basic feature extraction, perspective transformation, and
feature fusion, noise and error will gradually accumulate. To address this
issue, we propose InsFusion, which can extract proposals from both raw and
fused features and utilizes these proposals to query the raw features, thereby
mitigating the impact of accumulated errors. Additionally, by incorporating
attention mechanisms applied to the raw features, it thereby mitigates the
impact of accumulated errors. Experiments on the nuScenes dataset demonstrate
that InsFusion is compatible with various advanced baseline methods and
delivers new state-of-the-art performance for 3D object detection.
\\ ( https://arxiv.org/abs/2509.08374 ,  265kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08376
Date: Wed, 10 Sep 2025 08:14:45 GMT   (6419kb)

Title: Bitrate-Controlled Diffusion for Disentangling Motion and Content in
  Video
Authors: Xiao Li, Qi Chen, Xiulian Peng, Kai Yu, Xie Chen, Yan Lu
Categories: cs.CV
\\
  We propose a novel and general framework to disentangle video data into its
dynamic motion and static content components. Our proposed method is a
self-supervised pipeline with less assumptions and inductive biases than
previous works: it utilizes a transformer-based architecture to jointly
generate flexible implicit features for frame-wise motion and clip-wise
content, and incorporates a low-bitrate vector quantization as an information
bottleneck to promote disentanglement and form a meaningful discrete motion
space. The bitrate-controlled latent motion and content are used as conditional
inputs to a denoising diffusion model to facilitate self-supervised
representation learning. We validate our disentangled representation learning
framework on real-world talking head videos with motion transfer and
auto-regressive motion generation tasks. Furthermore, we also show that our
method can generalize to other types of video data, such as pixel sprites of 2D
cartoon characters. Our work presents a new perspective on self-supervised
learning of disentangled video representations, contributing to the broader
field of video analysis and generation.
\\ ( https://arxiv.org/abs/2509.08376 ,  6419kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08388
Date: Wed, 10 Sep 2025 08:29:22 GMT   (1700kb)

Title: Semantic Causality-Aware Vision-Based 3D Occupancy Prediction
Authors: Dubing Chen and Huan Zheng and Yucheng Zhou and Xianfei Li and Wenlong
  Liao and Tao He and Pai Peng and Jianbing Shen
Categories: cs.CV cs.AI
Comments: ICCV 2025
\\
  Vision-based 3D semantic occupancy prediction is a critical task in 3D vision
that integrates volumetric 3D reconstruction with semantic understanding.
Existing methods, however, often rely on modular pipelines. These modules are
typically optimized independently or use pre-configured inputs, leading to
cascading errors. In this paper, we address this limitation by designing a
novel causal loss that enables holistic, end-to-end supervision of the modular
2D-to-3D transformation pipeline. Grounded in the principle of 2D-to-3D
semantic causality, this loss regulates the gradient flow from 3D voxel
representations back to the 2D features. Consequently, it renders the entire
pipeline differentiable, unifying the learning process and making previously
non-trainable components fully learnable. Building on this principle, we
propose the Semantic Causality-Aware 2D-to-3D Transformation, which comprises
three components guided by our causal loss: Channel-Grouped Lifting for
adaptive semantic mapping, Learnable Camera Offsets for enhanced robustness
against camera perturbations, and Normalized Convolution for effective feature
propagation. Extensive experiments demonstrate that our method achieves
state-of-the-art performance on the Occ3D benchmark, demonstrating significant
robustness to camera perturbations and improved 2D-to-3D semantic consistency.
\\ ( https://arxiv.org/abs/2509.08388 ,  1700kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08392
Date: Wed, 10 Sep 2025 08:35:21 GMT   (427kb)

Title: VRAE: Vertical Residual Autoencoder for License Plate Denoising and
  Deblurring
Authors: Cuong Nguyen, Dung T. Tran, Hong Nguyen, Xuan-Vu Phan, Nam-Phong
  Nguyen
Categories: cs.CV
\\
  In real-world traffic surveillance, vehicle images captured under adverse
weather, poor lighting, or high-speed motion often suffer from severe noise and
blur. Such degradations significantly reduce the accuracy of license plate
recognition systems, especially when the plate occupies only a small region
within the full vehicle image. Restoring these degraded images a fast realtime
manner is thus a crucial pre-processing step to enhance recognition
performance. In this work, we propose a Vertical Residual Autoencoder (VRAE)
architecture designed for the image enhancement task in traffic surveillance.
The method incorporates an enhancement strategy that employs an auxiliary
block, which injects input-aware features at each encoding stage to guide the
representation learning process, enabling better general information
preservation throughout the network compared to conventional autoencoders.
Experiments on a vehicle image dataset with visible license plates demonstrate
that our method consistently outperforms Autoencoder (AE), Generative
Adversarial Network (GAN), and Flow-Based (FB) approaches. Compared with AE at
the same depth, it improves PSNR by about 20\%, reduces NMSE by around 50\%,
and enhances SSIM by 1\%, while requiring only a marginal increase of roughly
1\% in parameters.
\\ ( https://arxiv.org/abs/2509.08392 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08421
Date: Wed, 10 Sep 2025 09:06:41 GMT   (4435kb)

Title: Sparse BEV Fusion with Self-View Consistency for Multi-View Detection
  and Tracking
Authors: Keisuke Toida, Taigo Sakai, Naoki Kato, Kazutoyo Yokota, Takeshi
  Nakamura, Kazuhiro Hotta
Categories: cs.CV cs.AI
\\
  Multi-View Multi-Object Tracking (MVMOT) is essential for applications such
as surveillance, autonomous driving, and sports analytics. However, maintaining
consistent object identities across multiple cameras remains challenging due to
viewpoint changes, lighting variations, and occlusions, which often lead to
tracking errors.Recent methods project features from multiple cameras into a
unified Bird's-Eye-View (BEV) space to improve robustness against occlusion.
However, this projection introduces feature distortion and non-uniform density
caused by variations in object scale with distance. These issues degrade the
quality of the fused representation and reduce detection and tracking
accuracy.To address these problems, we propose SCFusion, a framework that
combines three techniques to improve multi-view feature integration. First, it
applies a sparse transformation to avoid unnatural interpolation during
projection. Next, it performs density-aware weighting to adaptively fuse
features based on spatial confidence and camera distance. Finally, it
introduces a multi-view consistency loss that encourages each camera to learn
discriminative features independently before fusion.Experiments show that
SCFusion achieves state-of-the-art performance, reaching an IDF1 score of 95.9%
on WildTrack and a MODP of 89.2% on MultiviewX, outperforming the baseline
method TrackTacular. These results demonstrate that SCFusion effectively
mitigates the limitations of conventional BEV projection and provides a robust
and accurate solution for multi-view object detection and tracking.
\\ ( https://arxiv.org/abs/2509.08421 ,  4435kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08422
Date: Wed, 10 Sep 2025 09:10:18 GMT   (21226kb)

Title: LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations
Authors: Payal Varshney, Adriano Lucieri, Christoph Balada, Sheraz Ahmed,
  Andreas Dengel
Categories: cs.CV cs.LG
Comments: 30 pages
\\
  Video-based AI systems are increasingly adopted in safety-critical domains
such as autonomous driving and healthcare. However, interpreting their
decisions remains challenging due to the inherent spatiotemporal complexity of
video data and the opacity of deep learning models. Existing explanation
techniques often suffer from limited temporal coherence, insufficient
robustness, and a lack of actionable causal insights. Current counterfactual
explanation methods typically do not incorporate guidance from the target
model, reducing semantic fidelity and practical utility. We introduce Latent
Diffusion for Video Counterfactual Explanations (LD-ViCE), a novel framework
designed to explain the behavior of video-based AI models. Compared to previous
approaches, LD-ViCE reduces the computational costs of generating explanations
by operating in latent space using a state-of-the-art diffusion model, while
producing realistic and interpretable counterfactuals through an additional
refinement step. Our experiments demonstrate the effectiveness of LD-ViCE
across three diverse video datasets, including EchoNet-Dynamic (cardiac
ultrasound), FERV39k (facial expression), and Something-Something V2 (action
recognition). LD-ViCE outperforms a recent state-of-the-art method, achieving
an increase in R2 score of up to 68% while reducing inference time by half.
Qualitative analysis confirms that LD-ViCE generates semantically meaningful
and temporally coherent explanations, offering valuable insights into the
target model behavior. LD-ViCE represents a valuable step toward the
trustworthy deployment of AI in safety-critical domains.
\\ ( https://arxiv.org/abs/2509.08422 ,  21226kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08436
Date: Wed, 10 Sep 2025 09:31:37 GMT   (39143kb)

Title: Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification
  at Test Time
Authors: Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang,
  and Leyuan Fang
Categories: cs.CV
\\
  Hyperspectral image (HSI) classification models are highly sensitive to
distribution shifts caused by various real-world degradations such as noise,
blur, compression, and atmospheric effects. To address this challenge, we
propose HyperTTA, a unified framework designed to enhance model robustness
under diverse degradation conditions. Specifically, we first construct a
multi-degradation hyperspectral dataset that systematically simulates nine
representative types of degradations, providing a comprehensive benchmark for
robust classification evaluation. Based on this, we design a spectral-spatial
transformer classifier (SSTC) enhanced with a multi-level receptive field
mechanism and label smoothing regularization to jointly capture multi-scale
spatial context and improve generalization. Furthermore, HyperTTA incorporates
a lightweight test-time adaptation (TTA) strategy, the confidence-aware
entropy-minimized LayerNorm adapter (CELA), which updates only the affine
parameters of LayerNorm layers by minimizing prediction entropy on
high-confidence unlabeled target samples. This confidence-aware adaptation
prevents unreliable updates from noisy predictions, enabling robust and dynamic
adaptation without access to source data or target annotations. Extensive
experiments on two benchmark datasets demonstrate that HyperTTA outperforms
existing baselines across a wide range of degradation scenarios, validating the
effectiveness of both its classification backbone and the proposed TTA scheme.
Code will be made available publicly.
\\ ( https://arxiv.org/abs/2509.08436 ,  39143kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08442
Date: Wed, 10 Sep 2025 09:40:41 GMT   (7109kb)

Title: Spherical Brownian Bridge Diffusion Models for Conditional Cortical
  Thickness Forecasting
Authors: Ivan Stoyanov, Fabian Bongratz, Christian Wachinger
Categories: cs.CV cs.AI cs.LG q-bio.NC
\\
  Accurate forecasting of individualized, high-resolution cortical thickness
(CTh) trajectories is essential for detecting subtle cortical changes,
providing invaluable insights into neurodegenerative processes and facilitating
earlier and more precise intervention strategies. However, CTh forecasting is a
challenging task due to the intricate non-Euclidean geometry of the cerebral
cortex and the need to integrate multi-modal data for subject-specific
predictions. To address these challenges, we introduce the Spherical Brownian
Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional
conditional Brownian bridge diffusion process to forecast CTh trajectories at
the vertex level of registered cortical surfaces. Our technical contribution
includes a new denoising model, the conditional spherical U-Net (CoS-UNet),
which combines spherical convolutions and dense cross-attention to integrate
cortical surfaces and tabular conditions seamlessly. Compared to previous
approaches, SBDM achieves significantly reduced prediction errors, as
demonstrated by our experiments based on longitudinal datasets from the ADNI
and OASIS. Additionally, we demonstrate SBDM's ability to generate individual
factual and counterfactual CTh trajectories, offering a novel framework for
exploring hypothetical scenarios of cortical development.
\\ ( https://arxiv.org/abs/2509.08442 ,  7109kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08458
Date: Wed, 10 Sep 2025 10:00:43 GMT   (5379kb)

Title: First-order State Space Model for Lightweight Image Super-resolution
Authors: Yujie Zhu, Xinyi Zhang, Yekai Lu, Guang Yang, Faming Fang, Guixu Zhang
Categories: cs.CV
Comments: Accept by ICASSP 2025 (Oral)
\\
  State space models (SSMs), particularly Mamba, have shown promise in NLP
tasks and are increasingly applied to vision tasks. However, most Mamba-based
vision models focus on network architecture and scan paths, with little
attention to the SSM module. In order to explore the potential of SSMs, we
modified the calculation process of SSM without increasing the number of
parameters to improve the performance on lightweight super-resolution tasks. In
this paper, we introduce the First-order State Space Model (FSSM) to improve
the original Mamba module, enhancing performance by incorporating token
correlations. We apply a first-order hold condition in SSMs, derive the new
discretized form, and analyzed cumulative error. Extensive experimental results
demonstrate that FSSM improves the performance of MambaIR on five benchmark
datasets without additionally increasing the number of parameters, and
surpasses current lightweight SR methods, achieving state-of-the-art results.
\\ ( https://arxiv.org/abs/2509.08458 ,  5379kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08469
Date: Wed, 10 Sep 2025 10:18:20 GMT   (1944kb)

Title: Maximally Useful and Minimally Redundant: The Key to Self Supervised
  Learning for Imbalanced Data
Authors: Yash Kumar Sharma, Vineet Nair, Wilson Naik
Categories: cs.CV
\\
  The robustness of contrastive self-supervised learning (CSSL) for imbalanced
datasets is largely unexplored. CSSL usually makes use of \emph{multi-view}
assumptions to learn discriminatory features via similar and dissimilar data
samples. CSSL works well on balanced datasets, but does not generalize well for
imbalanced datasets. In a very recent paper, as part of future work, Yann LeCun
pointed out that the self-supervised multiview framework can be extended to
cases involving \emph{more than two views}. Taking a cue from this insight we
propose a theoretical justification based on the concept of \emph{mutual
information} to support the \emph{more than two views} objective and apply it
to the problem of dataset imbalance in self-supervised learning. The proposed
method helps extract representative characteristics of the tail classes by
segregating between \emph{intra} and \emph{inter} discriminatory
characteristics. We introduce a loss function that helps us to learn better
representations by filtering out extreme features. Experimental evaluation on a
variety of self-supervised frameworks (both contrastive and non-contrastive)
also prove that the \emph{more than two view} objective works well for
imbalanced datasets. We achieve a new state-of-the-art accuracy in
self-supervised imbalanced dataset classification (2\% improvement in
Cifar10-LT using Resnet-18, 5\% improvement in Cifar100-LT using Resnet-18, 3\%
improvement in Imagenet-LT (1k) using Resnet-50).
\\ ( https://arxiv.org/abs/2509.08469 ,  1944kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08489
Date: Wed, 10 Sep 2025 11:00:12 GMT   (6063kb)

Title: Prompt-Driven Image Analysis with Multimodal Generative AI: Detection,
  Segmentation, Inpainting, and Interpretation
Authors: Kaleem Ahmad
Categories: cs.CV cs.AI
Comments: 14 pages. Preprint
\\
  Prompt-driven image analysis converts a single natural-language instruction
into multiple steps: locate, segment, edit, and describe. We present a
practical case study of a unified pipeline that combines open-vocabulary
detection, promptable segmentation, text-conditioned inpainting, and
vision-language description into a single workflow. The system works end to end
from a single prompt, retains intermediate artifacts for transparent debugging
(such as detections, masks, overlays, edited images, and before and after
composites), and provides the same functionality through an interactive UI and
a scriptable CLI for consistent, repeatable runs. We highlight integration
choices that reduce brittleness, including threshold adjustments, mask
inspection with light morphology, and resource-aware defaults. In a small,
single-word prompt segment, detection and segmentation produced usable masks in
over 90% of cases with an accuracy above 85% based on our criteria. On a
high-end GPU, inpainting makes up 60 to 75% of total runtime under typical
guidance and sampling settings, which highlights the need for careful tuning.
The study offers implementation-guided advice on thresholds, mask tightness,
and diffusion parameters, and details version pinning, artifact logging, and
seed control to support replay. Our contribution is a transparent, reliable
pattern for assembling modern vision and multimodal models behind a single
prompt, with clear guardrails and operational practices that improve
reliability in object replacement, scene augmentation, and removal.
\\ ( https://arxiv.org/abs/2509.08489 ,  6063kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08490
Date: Wed, 10 Sep 2025 11:01:29 GMT   (9310kb)

Title: A Structured Review of Underwater Object Detection Challenges and
  Solutions: From Traditional to Large Vision Language Models
Authors: Edwine Nabahirwa, Wei Song, Minghua Zhang, Yi Fang, Zhou Ni
Categories: cs.CV cs.AI
Comments: 72 Pages, 11 Figures
\\
  Underwater object detection (UOD) is vital to diverse marine applications,
including oceanographic research, underwater robotics, and marine conservation.
However, UOD faces numerous challenges that compromise its performance. Over
the years, various methods have been proposed to address these issues, but they
often fail to fully capture the complexities of underwater environments. This
review systematically categorizes UOD challenges into five key areas: Image
quality degradation, target-related issues, data-related challenges,
computational and processing constraints, and limitations in detection
methodologies. To address these challenges, we analyze the progression from
traditional image processing and object detection techniques to modern
approaches. Additionally, we explore the potential of large vision-language
models (LVLMs) in UOD, leveraging their multi-modal capabilities demonstrated
in other domains. We also present case studies, including synthetic dataset
generation using DALL-E 3 and fine-tuning Florence-2 LVLM for UOD. This review
identifies three key insights: (i) Current UOD methods are insufficient to
fully address challenges like image degradation and small object detection in
dynamic underwater environments. (ii) Synthetic data generation using LVLMs
shows potential for augmenting datasets but requires further refinement to
ensure realism and applicability. (iii) LVLMs hold significant promise for UOD,
but their real-time application remains under-explored, requiring further
research on optimization techniques.
\\ ( https://arxiv.org/abs/2509.08490 ,  9310kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08502
Date: Wed, 10 Sep 2025 11:23:10 GMT   (9040kb)

Title: Chirality in Action: Time-Aware Video Representation Learning by Latent
  Straightening
Authors: Piyush Bagad, Andrew Zisserman
Categories: cs.CV
Comments: 24 pages, 10 figures
\\
  Our objective is to develop compact video representations that are sensitive
to visual change over time. To measure such time-sensitivity, we introduce a
new task: chiral action recognition, where one needs to distinguish between a
pair of temporally opposite actions, such as "opening vs. closing a door",
"approaching vs. moving away from something", "folding vs. unfolding paper",
etc. Such actions (i) occur frequently in everyday life, (ii) require
understanding of simple visual change over time (in object state, size, spatial
position, count . . . ), and (iii) are known to be poorly represented by many
video embeddings. Our goal is to build time aware video representations which
offer linear separability between these chiral pairs. To that end, we propose a
self-supervised adaptation recipe to inject time-sensitivity into a sequence of
frozen image features. Our model is based on an auto-encoder with a latent
space with inductive bias inspired by perceptual straightening. We show that
this results in a compact but time-sensitive video representation for the
proposed task across three datasets: Something-Something, EPIC-Kitchens, and
Charade. Our method (i) outperforms much larger video models pre-trained on
large-scale video datasets, and (ii) leads to an improvement in classification
performance on standard benchmarks when combined with these existing models.
\\ ( https://arxiv.org/abs/2509.08502 ,  9040kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08519
Date: Wed, 10 Sep 2025 11:54:29 GMT   (7696kb)

Title: HuMo: Human-Centric Video Generation via Collaborative Multi-Modal
  Conditioning
Authors: Liyang Chen, Tianxiang Ma, Jiawei Liu, Bingchuan Li, Zhuowei Chen,
  Lijie Liu, Xu He, Gen Li, Qian He, Zhiyong Wu
Categories: cs.CV cs.MM
\\
  Human-Centric Video Generation (HCVG) methods seek to synthesize human videos
from multimodal inputs, including text, image, and audio. Existing methods
struggle to effectively coordinate these heterogeneous modalities due to two
challenges: the scarcity of training data with paired triplet conditions and
the difficulty of collaborating the sub-tasks of subject preservation and
audio-visual sync with multimodal inputs. In this work, we present HuMo, a
unified HCVG framework for collaborative multimodal control. For the first
challenge, we construct a high-quality dataset with diverse and paired text,
reference images, and audio. For the second challenge, we propose a two-stage
progressive multimodal training paradigm with task-specific strategies. For the
subject preservation task, to maintain the prompt following and visual
generation abilities of the foundation model, we adopt the minimal-invasive
image injection strategy. For the audio-visual sync task, besides the commonly
adopted audio cross-attention layer, we propose a focus-by-predicting strategy
that implicitly guides the model to associate audio with facial regions. For
joint learning of controllabilities across multimodal inputs, building on
previously acquired capabilities, we progressively incorporate the audio-visual
sync task. During inference, for flexible and fine-grained multimodal control,
we design a time-adaptive Classifier-Free Guidance strategy that dynamically
adjusts guidance weights across denoising steps. Extensive experimental results
demonstrate that HuMo surpasses specialized state-of-the-art methods in
sub-tasks, establishing a unified framework for collaborative
multimodal-conditioned HCVG. Project Page:
https://phantom-video.github.io/HuMo.
\\ ( https://arxiv.org/abs/2509.08519 ,  7696kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08538
Date: Wed, 10 Sep 2025 12:34:07 GMT   (18983kb)

Title: MESH -- Understanding Videos Like Human: Measuring Hallucinations in
  Large Video Models
Authors: Garry Yang, Zizhe Chen, Man Hon Wong, Haoyu Lei, Yongqiang Chen,
  Zhenguo Li, Kaiwen Zhou, James Cheng
Categories: cs.CV cs.AI
\\
  Large Video Models (LVMs) build on the semantic capabilities of Large
Language Models (LLMs) and vision modules by integrating temporal information
to better understand dynamic video content. Despite their progress, LVMs are
prone to hallucinations-producing inaccurate or irrelevant descriptions.
Current benchmarks for video hallucination depend heavily on manual
categorization of video content, neglecting the perception-based processes
through which humans naturally interpret videos. We introduce MESH, a benchmark
designed to evaluate hallucinations in LVMs systematically. MESH uses a
Question-Answering framework with binary and multi-choice formats incorporating
target and trap instances. It follows a bottom-up approach, evaluating basic
objects, coarse-to-fine subject features, and subject-action pairs, aligning
with human video understanding. We demonstrate that MESH offers an effective
and comprehensive approach for identifying hallucinations in videos. Our
evaluations show that while LVMs excel at recognizing basic objects and
features, their susceptibility to hallucinations increases markedly when
handling fine details or aligning multiple actions involving various subjects
in longer videos.
\\ ( https://arxiv.org/abs/2509.08538 ,  18983kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08550
Date: Wed, 10 Sep 2025 12:53:38 GMT   (9788kb)

Title: ViewSparsifier: Killing Redundancy in Multi-View Plant Phenotyping
Authors: Robin-Nico Kampa, Fabian Deuser, Konrad Habel, Norbert Oswald
Categories: cs.CV
\\
  Plant phenotyping involves analyzing observable characteristics of plants to
better understand their growth, health, and development. In the context of deep
learning, this analysis is often approached through single-view classification
or regression models. However, these methods often fail to capture all
information required for accurate estimation of target phenotypic traits, which
can adversely affect plant health assessment and harvest readiness prediction.
To address this, the Growth Modelling (GroMo) Grand Challenge at ACM Multimedia
2025 provides a multi-view dataset featuring multiple plants and two tasks:
Plant Age Prediction and Leaf Count Estimation. Each plant is photographed from
multiple heights and angles, leading to significant overlap and redundancy in
the captured information. To learn view-invariant embeddings, we incorporate 24
views, referred to as the selection vector, in a random selection. Our
ViewSparsifier approach won both tasks. For further improvement and as a
direction for future research, we also experimented with randomized view
selection across all five height levels (120 views total), referred to as
selection matrices.
\\ ( https://arxiv.org/abs/2509.08550 ,  9788kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08570
Date: Wed, 10 Sep 2025 13:16:30 GMT   (2932kb)

Title: Vision-Language Semantic Aggregation Leveraging Foundation Model for
  Generalizable Medical Image Segmentation
Authors: Wenjun Yu, Yinchen Zhou, Jia-Xuan Jiang, Shubin Zeng, Yuee Li and
  Zhong Wang
Categories: cs.CV
Comments: 29 pages and 8 figures
\\
  Multimodal models have achieved remarkable success in natural image
segmentation, yet they often underperform when applied to the medical domain.
Through extensive study, we attribute this performance gap to the challenges of
multimodal fusion, primarily the significant semantic gap between abstract
textual prompts and fine-grained medical visual features, as well as the
resulting feature dispersion. To address these issues, we revisit the problem
from the perspective of semantic aggregation. Specifically, we propose an
Expectation-Maximization (EM) Aggregation mechanism and a Text-Guided Pixel
Decoder. The former mitigates feature dispersion by dynamically clustering
features into compact semantic centers to enhance cross-modal correspondence.
The latter is designed to bridge the semantic gap by leveraging
domain-invariant textual knowledge to effectively guide deep visual
representations. The synergy between these two mechanisms significantly
improves the model's generalization ability. Extensive experiments on public
cardiac and fundus datasets demonstrate that our method consistently
outperforms existing SOTA approaches across multiple domain generalization
benchmarks.
\\ ( https://arxiv.org/abs/2509.08570 ,  2932kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08571
Date: Wed, 10 Sep 2025 13:17:39 GMT   (2560kb)

Title: Improving Greenland Bed Topography Mapping with Uncertainty-Aware Graph
  Learning on Sparse Radar Data
Authors: Bayu Adhi Tama, Homayra Alam, Mostafa Cham, Omar Faruque, Jianwu Wang,
  and Vandana Janeja
Categories: cs.CV
\\
  Accurate maps of Greenland's subglacial bed are essential for sea-level
projections, but radar observations are sparse and uneven. We introduce
GraphTopoNet, a graph-learning framework that fuses heterogeneous supervision
and explicitly models uncertainty via Monte Carlo dropout. Spatial graphs built
from surface observables (elevation, velocity, mass balance) are augmented with
gradient features and polynomial trends to capture both local variability and
broad structure. To handle data gaps, we employ a hybrid loss that combines
confidence-weighted radar supervision with dynamically balanced regularization.
Applied to three Greenland subregions, GraphTopoNet outperforms interpolation,
convolutional, and graph-based baselines, reducing error by up to 60 percent
while preserving fine-scale glacial features. The resulting bed maps improve
reliability for operational modeling, supporting agencies engaged in climate
forecasting and policy. More broadly, GraphTopoNet shows how graph machine
learning can convert sparse, uncertain geophysical observations into actionable
knowledge at continental scale.
\\ ( https://arxiv.org/abs/2509.08571 ,  2560kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08580
Date: Wed, 10 Sep 2025 13:30:39 GMT   (5170kb)

Title: Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation
Authors: Mathilde Monvoisin, Louise Piecuch, Blanche Texier, C\'edric H\'emon,
  Ana\"is Barateau, J\'er\'emie Huet, Antoine Nordez, Anne-Sophie Boureau,
  Jean-Claude Nunes, Diana Mateus
Categories: cs.CV cs.LG
Comments: Both first Authors contributed equally to this work, lastnames in
  alphabetical order. This preprint has not undergone peer review or any
  post-submission improvements or corrections. The Version of Record of this
  contribution will be published in a Springer Nature Computer Science book
  series (CCIS, LNAI, LNBI, LNBIP, LNCS) and the doi will soon be released
\\
  The objective of this paper is to significantly reduce the manual workload
required from medical professionals in complex 3D segmentation tasks that
cannot be yet fully automated. For instance, in radiotherapy planning, organs
at risk must be accurately identified in computed tomography (CT) or magnetic
resonance imaging (MRI) scans to ensure they are spared from harmful radiation.
Similarly, diagnosing age-related degenerative diseases such as sarcopenia,
which involve progressive muscle volume loss and strength, is commonly based on
muscular mass measurements often obtained from manual segmentation of medical
volumes. To alleviate the manual-segmentation burden, this paper introduces an
implicit shape prior to segment volumes from sparse slice manual annotations
generalized to the multi-organ case, along with a simple framework for
automatically selecting the most informative slices to guide and minimize the
next interactions. The experimental validation shows the method's effectiveness
on two medical use cases: assisted segmentation in the context of at risks
organs for brain cancer patients, and acceleration of the creation of a new
database with unseen muscle shapes for patients with sarcopenia.
\\ ( https://arxiv.org/abs/2509.08580 ,  5170kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08583
Date: Wed, 10 Sep 2025 13:32:02 GMT   (2678kb)

Title: EfficientIML: Efficient High-Resolution Image Manipulation Localization
Authors: Jinhan Li, Haoyang He, Lei Xie, Jiangning Zhang
Categories: cs.CV
\\
  With imaging devices delivering ever-higher resolutions and the emerging
diffusion-based forgery methods, current detectors trained only on traditional
datasets (with splicing, copy-moving and object removal forgeries) lack
exposure to this new manipulation type. To address this, we propose a novel
high-resolution SIF dataset of 1200+ diffusion-generated manipulations with
semantically extracted masks. However, this also imposes a challenge on
existing methods, as they face significant computational resource constraints
due to their prohibitive computational complexities. Therefore, we propose a
novel EfficientIML model with a lightweight, three-stage EfficientRWKV
backbone. EfficientRWKV's hybrid state-space and attention network captures
global context and local details in parallel, while a multi-scale supervision
strategy enforces consistency across hierarchical predictions. Extensive
evaluations on our dataset and standard benchmarks demonstrate that our
approach outperforms ViT-based and other SOTA lightweight baselines in
localization performance, FLOPs and inference speed, underscoring its
suitability for real-time forensic applications.
\\ ( https://arxiv.org/abs/2509.08583 ,  2678kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08618
Date: Wed, 10 Sep 2025 14:14:49 GMT   (1782kb)

Title: CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal
  Imaging
Authors: Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang,
  Shahrooz Faghihroohi, Kai Huang, Nassir Navab, M.Ali Nasseri
Categories: cs.CV
Comments: BIBM
ACM-class: I.4.6
\\
  Recent advancements in foundation models, such as the Segment Anything Model
(SAM), have significantly impacted medical image segmentation, especially in
retinal imaging, where precise segmentation is vital for diagnosis. Despite
this progress, current methods face critical challenges: 1) modality ambiguity
in textual disease descriptions, 2) a continued reliance on manual prompting
for SAM-based workflows, and 3) a lack of a unified framework, with most
methods being modality- and task-specific. To overcome these hurdles, we
propose CLIP-unified Auto-Prompt Segmentation (\CLAPS), a novel method for
unified segmentation across diverse tasks and modalities in retinal imaging.
Our approach begins by pre-training a CLIP-based image encoder on a large,
multi-modal retinal dataset to handle data scarcity and distribution imbalance.
We then leverage GroundingDINO to automatically generate spatial bounding box
prompts by detecting local lesions. To unify tasks and resolve ambiguity, we
use text prompts enhanced with a unique "modality signature" for each imaging
modality. Ultimately, these automated textual and spatial prompts guide SAM to
execute precise segmentation, creating a fully automated and unified pipeline.
Extensive experiments on 12 diverse datasets across 11 critical segmentation
categories show that CLAPS achieves performance on par with specialized expert
models while surpassing existing benchmarks across most metrics, demonstrating
its broad generalizability as a foundation model.
\\ ( https://arxiv.org/abs/2509.08618 ,  1782kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08621
Date: Wed, 10 Sep 2025 14:17:53 GMT   (13422kb)

Title: AdsQA: Towards Advertisement Video Understanding
Authors: Xinwei Long, Kai Tian, Peng Xu, Guoli Jia, Jingxuan Li, Sa Yang, Yihua
  Shao, Kaiyan Zhang, Che Jiang, Hao Xu, Yang Liu, Jiaheng Ma, Bowen Zhou
Categories: cs.CV
Comments: ICCV-2025
\\
  Large language models (LLMs) have taken a great step towards AGI. Meanwhile,
an increasing number of domain-specific problems such as math and programming
boost these general-purpose models to continuously evolve via learning deeper
expertise. Now is thus the time further to extend the diversity of specialized
applications for knowledgeable LLMs, though collecting high quality data with
unexpected and informative tasks is challenging. In this paper, we propose to
use advertisement (ad) videos as a challenging test-bed to probe the ability of
LLMs in perceiving beyond the objective physical content of common visual
domain. Our motivation is to take full advantage of the clue-rich and
information-dense ad videos' traits, e.g., marketing logic, persuasive
strategies, and audience engagement. Our contribution is three-fold: (1) To our
knowledge, this is the first attempt to use ad videos with well-designed tasks
to evaluate LLMs. We contribute AdsQA, a challenging ad Video QA benchmark
derived from 1,544 ad videos with 10,962 clips, totaling 22.7 hours, providing
5 challenging tasks. (2) We propose ReAd-R, a Deepseek-R1 styled RL model that
reflects on questions, and generates answers via reward-driven optimization.
(3) We benchmark 14 top-tier LLMs on AdsQA, and our \texttt{ReAd-R}~achieves
the state-of-the-art outperforming strong competitors equipped with long-chain
reasoning capabilities by a clear margin.
\\ ( https://arxiv.org/abs/2509.08621 ,  13422kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08624
Date: Wed, 10 Sep 2025 14:19:59 GMT   (609kb)

Title: UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image
  Diagnosis Augmentation
Authors: Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang,
  Daniel Zapp, Kai Huang, Nassir Navab, M.Ali Nasseri
Categories: cs.CV cs.AI
Comments: BIBM
ACM-class: I.4.10
\\
  Significant advancements in AI-driven multimodal medical image diagnosis have
led to substantial improvements in ophthalmic disease identification in recent
years. However, acquiring paired multimodal ophthalmic images remains
prohibitively expensive. While fundus photography is simple and cost-effective,
the limited availability of OCT data and inherent modality imbalance hinder
further progress. Conventional approaches that rely solely on fundus or textual
features often fail to capture fine-grained spatial information, as each
imaging modality provides distinct cues about lesion predilection sites. In
this study, we propose a novel unpaired multimodal framework \UOPSL that
utilizes extensive OCT-derived spatial priors to dynamically identify
predilection sites, enhancing fundus image-based disease recognition. Our
approach bridges unpaired fundus and OCTs via extended disease text
descriptions. Initially, we employ contrastive learning on a large corpus of
unpaired OCT and fundus images while simultaneously learning the predilection
sites matrix in the OCT latent space. Through extensive optimization, this
matrix captures lesion localization patterns within the OCT feature space.
During the fine-tuning or inference phase of the downstream classification task
based solely on fundus images, where paired OCT data is unavailable, we
eliminate OCT input and utilize the predilection sites matrix to assist in
fundus image classification learning. Extensive experiments conducted on 9
diverse datasets across 28 critical categories demonstrate that our framework
outperforms existing benchmarks.
\\ ( https://arxiv.org/abs/2509.08624 ,  609kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08628
Date: Wed, 10 Sep 2025 14:23:07 GMT   (23666kb)

Title: LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain
  Translation
Authors: Xuqin Wang, Tao Wu, Yanfeng Zhang, Lu Liu, Dong Wang, Mingwei Sun,
  Yongliang Wang, Niclas Zeller, Daniel Cremers
Categories: cs.CV
\\
  Diffusion models excel at generating high-quality outputs but face challenges
in data-scarce domains, where exhaustive retraining or costly paired data are
often required. To address these limitations, we propose Latent Aligned
Diffusion Bridges (LADB), a semi-supervised framework for sample-to-sample
translation that effectively bridges domain gaps using partially paired data.
By aligning source and target distributions within a shared latent space, LADB
seamlessly integrates pretrained source-domain diffusion models with a
target-domain Latent Aligned Diffusion Model (LADM), trained on partially
paired latent representations. This approach enables deterministic domain
mapping without the need for full supervision. Compared to unpaired methods,
which often lack controllability, and fully paired approaches that require
large, domain-specific datasets, LADB strikes a balance between fidelity and
diversity by leveraging a mixture of paired and unpaired latent-target
couplings. Our experimental results demonstrate superior performance in
depth-to-image translation under partial supervision. Furthermore, we extend
LADB to handle multi-source translation (from depth maps and segmentation
masks) and multi-target translation in a class-conditioned style transfer task,
showcasing its versatility in handling diverse and heterogeneous use cases.
Ultimately, we present LADB as a scalable and versatile solution for real-world
domain translation, particularly in scenarios where data annotation is costly
or incomplete.
\\ ( https://arxiv.org/abs/2509.08628 ,  23666kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08661
Date: Wed, 10 Sep 2025 14:58:21 GMT   (1280kb)

Title: Skeleton-based sign language recognition using a dual-stream
  spatio-temporal dynamic graph convolutional network
Authors: Liangjin Liu, Haoyang Zheng, Pei Zhou
Categories: cs.CV cs.AI
Comments: 5 pages, 3 figures, ICASSP
ACM-class: I.2.m; I.2.0
\\
  Isolated Sign Language Recognition (ISLR) is challenged by gestures that are
morphologically similar yet semantically distinct, a problem rooted in the
complex interplay between hand shape and motion trajectory. Existing methods,
often relying on a single reference frame, struggle to resolve this geometric
ambiguity. This paper introduces Dual-SignLanguageNet (DSLNet), a
dual-reference, dual-stream architecture that decouples and models gesture
morphology and trajectory in separate, complementary coordinate systems. Our
approach utilizes a wrist-centric frame for view-invariant shape analysis and a
facial-centric frame for context-aware trajectory modeling. These streams are
processed by specialized networks-a topology-aware graph convolution for shape
and a Finsler geometry-based encoder for trajectory-and are integrated via a
geometry-driven optimal transport fusion mechanism. DSLNet sets a new
state-of-the-art, achieving 93.70%, 89.97% and 99.79% accuracy on the
challenging WLASL-100, WLASL-300 and LSA64 datasets, respectively, with
significantly fewer parameters than competing models.
\\ ( https://arxiv.org/abs/2509.08661 ,  1280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08670
Date: Wed, 10 Sep 2025 15:05:51 GMT   (34666kb)

Title: FractalPINN-Flow: A Fractal-Inspired Network for Unsupervised Optical
  Flow Estimation with Total Variation Regularization
Authors: Sara Behnamian, Rasoul Khaksarinezhad, Andreas Langer
Categories: cs.CV
Journal-ref: In: Hesser, J\"urgen ; Fresquet, Xavier (Hrsgg.): 2nd
  Sorbonne-Heidelberg Workshop on AI in Medicine: Machine Learning for
  Multi-modal Data (2025)
\\
  We present FractalPINN-Flow, an unsupervised deep learning framework for
dense optical flow estimation that learns directly from consecutive grayscale
frames without requiring ground truth. The architecture centers on the Fractal
Deformation Network (FDN) - a recursive encoder-decoder inspired by fractal
geometry and self-similarity. Unlike traditional CNNs with sequential
downsampling, FDN uses repeated encoder-decoder nesting with skip connections
to capture both fine-grained details and long-range motion patterns. The
training objective is based on a classical variational formulation using total
variation (TV) regularization. Specifically, we minimize an energy functional
that combines $L^1$ and $L^2$ data fidelity terms to enforce brightness
constancy, along with a TV term that promotes spatial smoothness and coherent
flow fields. Experiments on synthetic and benchmark datasets show that
FractalPINN-Flow produces accurate, smooth, and edge-preserving optical flow
fields. The model is especially effective for high-resolution data and
scenarios with limited annotations.
\\ ( https://arxiv.org/abs/2509.08670 ,  34666kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08694
Date: Wed, 10 Sep 2025 15:34:46 GMT   (5179kb)

Title: Multi-Modal Robust Enhancement for Coastal Water Segmentation: A
  Systematic HSV-Guided Framework
Authors: Zhen Tian, Christos Anagnostopoulos, Qiyuan Wang, Zhiwei Gao
Categories: cs.CV
\\
  Coastal water segmentation from satellite imagery presents unique challenges
due to complex spectral characteristics and irregular boundary patterns.
Traditional RGB-based approaches often suffer from training instability and
poor generalization in diverse maritime environments. This paper introduces a
systematic robust enhancement framework, referred to as Robust U-Net, that
leverages HSV color space supervision and multi-modal constraints for improved
coastal water segmentation. Our approach integrates five synergistic
components: HSV-guided color supervision, gradient-based coastline
optimization, morphological post-processing, sea area cleanup, and connectivity
control. Through comprehensive ablation studies, we demonstrate that HSV
supervision provides the highest impact (0.85 influence score), while the
complete framework achieves superior training stability (84\% variance
reduction) and enhanced segmentation quality. Our method shows consistent
improvements across multiple evaluation metrics while maintaining computational
efficiency. For reproducibility, our training configurations and code are
available here: https://github.com/UofgCoastline/ICASSP-2026-Robust-Unet.
\\ ( https://arxiv.org/abs/2509.08694 ,  5179kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08712
Date: Wed, 10 Sep 2025 16:02:42 GMT   (465kb)

Title: Computational Imaging for Enhanced Computer Vision
Authors: Humera Shaikh, Kaur Jashanpreet
Categories: cs.CV
Journal-ref: International Journal of Engineering Research & Technology, 2025
DOI: 10.17577/IJERTV14IS050351
\\
  This paper presents a comprehensive survey of computational imaging (CI)
techniques and their transformative impact on computer vision (CV)
applications. Conventional imaging methods often fail to deliver high-fidelity
visual data in challenging conditions, such as low light, motion blur, or high
dynamic range scenes, thereby limiting the performance of state-of-the-art CV
systems. Computational imaging techniques, including light field imaging, high
dynamic range (HDR) imaging, deblurring, high-speed imaging, and glare
mitigation, address these limitations by enhancing image acquisition and
reconstruc- tion processes. This survey systematically explores the synergies
between CI techniques and core CV tasks, including object detection, depth
estimation, optical flow, face recognition, and keypoint detection. By
analyzing the relationships between CI methods and their practical
contributions to CV applications, this work highlights emerging opportunities,
challenges, and future research directions. We emphasize the potential for
task-specific, adaptive imaging pipelines that improve robustness, accuracy,
and efficiency in real-world scenarios, such as autonomous navigation,
surveillance, augmented reality, and robotics.
\\ ( https://arxiv.org/abs/2509.08712 ,  465kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08715
Date: Wed, 10 Sep 2025 16:09:49 GMT   (17301kb)

Title: BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated
  Cross-Modal Fusion
Authors: Sike Xiang, Shuang Chen and Amir Atapour-Abarghouei
Categories: cs.CV
\\
  As multimodal large language models (MLLMs) advance, their large-scale
architectures pose challenges for deployment in resource-constrained
environments. In the age of large models, where energy efficiency,
computational scalability and environmental sustainability are paramount, the
development of lightweight and high-performance models is critical for
real-world applications. As such, we propose a lightweight MLLM framework for
end-to-end visual question answering. Our proposed approach centres on
BreezeCLIP, a compact yet powerful vision-language encoder optimised for
efficient multimodal understanding. With only 1.2 billion parameters overall,
our model significantly reduces computational cost while achieving performance
comparable to standard-size MLLMs. Experiments conducted on multiple datasets
further validate its effectiveness in balancing accuracy and efficiency. The
modular and extensible design enables generalisation to broader multimodal
tasks. The proposed lightweight vision-language framework is denoted as BcQLM
(BreezeCLIP-enhanced Q-Gated Multimodal Language Model). It offers a promising
path toward deployable MLLMs under practical hardware constraints. The source
code is available at https://github.com/thico0224/BcQLM.
\\ ( https://arxiv.org/abs/2509.08715 ,  17301kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08738
Date: Wed, 10 Sep 2025 16:25:36 GMT   (4130kb)

Title: CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection
  in Crowded Scenes
Authors: Marius D\"ahling, Sebastian Krebs, J. Marius Z\"ollner
Categories: cs.CV
Comments: 8 pages, 5 figures, accepted by IROS 2025
\\
  This paper introduces a novel method for end-to-end crowd detection that
leverages object density information to enhance existing transformer-based
detectors. We present CrowdQuery (CQ), whose core component is our CQ module
that predicts and subsequently embeds an object density map. The embedded
density information is then systematically integrated into the decoder.
Existing density map definitions typically depend on head positions or
object-based spatial statistics. Our method extends these definitions to
include individual bounding box dimensions. By incorporating density
information into object queries, our method utilizes density-guided queries to
improve detection in crowded scenes. CQ is universally applicable to both 2D
and 3D detection without requiring additional data. Consequently, we are the
first to design a method that effectively bridges 2D and 3D detection in
crowded environments. We demonstrate the integration of CQ into both a general
2D and 3D transformer-based object detector, introducing the architectures CQ2D
and CQ3D. CQ is not limited to the specific transformer models we selected.
Experiments on the STCrowd dataset for both 2D and 3D domains show significant
performance improvements compared to the base models, outperforming most
state-of-the-art methods. When integrated into a state-of-the-art crowd
detector, CQ can further improve performance on the challenging CrowdHuman
dataset, demonstrating its generalizability. The code is released at
https://github.com/mdaehl/CrowdQuery.
\\ ( https://arxiv.org/abs/2509.08738 ,  4130kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08764
Date: Wed, 10 Sep 2025 16:53:29 GMT   (7123kb)

Title: ArgoTweak: Towards Self-Updating HD Maps through Structured Priors
Authors: Lena Wild, Rafael Valencia, Patric Jensfelt
Categories: cs.CV
Comments: ICCV 2025
\\
  Reliable integration of prior information is crucial for self-verifying and
self-updating HD maps. However, no public dataset includes the required triplet
of prior maps, current maps, and sensor data. As a result, existing methods
must rely on synthetic priors, which create inconsistencies and lead to a
significant sim2real gap. To address this, we introduce ArgoTweak, the first
dataset to complete the triplet with realistic map priors. At its core,
ArgoTweak employs a bijective mapping framework, breaking down large-scale
modifications into fine-grained atomic changes at the map element level, thus
ensuring interpretability. This paradigm shift enables accurate change
detection and integration while preserving unchanged elements with high
fidelity. Experiments show that training models on ArgoTweak significantly
reduces the sim2real gap compared to synthetic priors. Extensive ablations
further highlight the impact of structured priors and detailed change
annotations. By establishing a benchmark for explainable, prior-aided HD
mapping, ArgoTweak advances scalable, self-improving mapping solutions. The
dataset, baselines, map modification toolbox, and further resources are
available at https://kth-rpl.github.io/ArgoTweak/.
\\ ( https://arxiv.org/abs/2509.08764 ,  7123kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08777
Date: Wed, 10 Sep 2025 17:06:47 GMT   (28334kb)

Title: Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles
Authors: Eric Slyman, Mehrab Tanjim, Kushal Kafle, Stefan Lee
Categories: cs.CV cs.CL
Comments: 17 pages, 8 figures, Accepted at ICCV 2025
\\
  Multimodal large language models (MLLMs) are increasingly used to evaluate
text-to-image (TTI) generation systems, providing automated judgments based on
visual and textual context. However, these "judge" models often suffer from
biases, overconfidence, and inconsistent performance across diverse image
domains. While prompt ensembling has shown promise for mitigating these issues
in unimodal, text-only settings, our experiments reveal that standard
ensembling methods fail to generalize effectively for TTI tasks. To address
these limitations, we propose a new multimodal-aware method called Multimodal
Mixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt
ensemble approach augmented by image clustering, allowing the judge to
dynamically assign prompt weights based on the visual characteristics of each
sample. We show that MMB improves accuracy in pairwise preference judgments and
greatly enhances calibration, making it easier to gauge the judge's true
uncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB
outperforms existing baselines in alignment with human annotations and
calibration across varied image content. Our findings highlight the importance
of multimodal-specific strategies for judge calibration and suggest a promising
path forward for reliable large-scale TTI evaluation.
\\ ( https://arxiv.org/abs/2509.08777 ,  28334kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08780
Date: Wed, 10 Sep 2025 17:08:31 GMT   (6489kb)

Title: An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using
  Mobile-Captured Skin Images
Authors: Asif Newaz, Asif Ur Rahman Adib, Rajit Sahil, Mashfique Mehzad
Categories: cs.CV cs.AI
\\
  Background: Arsenicosis is a serious public health concern in South and
Southeast Asia, primarily caused by long-term consumption of
arsenic-contaminated water. Its early cutaneous manifestations are clinically
significant but often underdiagnosed, particularly in rural areas with limited
access to dermatologists. Automated, image-based diagnostic solutions can
support early detection and timely interventions.
  Methods: In this study, we propose an end-to-end framework for arsenicosis
diagnosis using mobile phone-captured skin images. A dataset comprising 20
classes and over 11000 images of arsenic-induced and other dermatological
conditions was curated. Multiple deep learning architectures, including
convolutional neural networks (CNNs) and Transformer-based models, were
benchmarked for arsenicosis detection. Model interpretability was integrated
via LIME and Grad-CAM, while deployment feasibility was demonstrated through a
web-based diagnostic tool.
  Results: Transformer-based models significantly outperformed CNNs, with the
Swin Transformer achieving the best results (86\\% accuracy). LIME and Grad-CAM
visualizations confirmed that the models attended to lesion-relevant regions,
increasing clinical transparency and aiding in error analysis. The framework
also demonstrated strong performance on external validation samples, confirming
its ability to generalize beyond the curated dataset.
  Conclusion: The proposed framework demonstrates the potential of deep
learning for non-invasive, accessible, and explainable diagnosis of arsenicosis
from mobile-acquired images. By enabling reliable image-based screening, it can
serve as a practical diagnostic aid in rural and resource-limited communities,
where access to dermatologists is scarce, thereby supporting early detection
and timely intervention.
\\ ( https://arxiv.org/abs/2509.08780 ,  6489kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08794
Date: Wed, 10 Sep 2025 17:24:10 GMT   (2364kb)

Title: Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation
Authors: Dennis Melamed and Connor Hashemi and Scott McCloskey
Categories: cs.CV
\\
  Event-based cameras (EBCs) are a promising new technology for star
tracking-based attitude determination, but prior studies have struggled to
determine accurate ground truth for real data. We analyze the accuracy of an
EBC star tracking system utilizing the Earth's motion as the ground truth for
comparison. The Earth rotates in a regular way with very small irregularities
which are measured to the level of milli-arcseconds. By keeping an event camera
static and pointing it through a ground-based telescope at the night sky, we
create a system where the only camera motion in the celestial reference frame
is that induced by the Earth's rotation. The resulting event stream is
processed to generate estimates of orientation which we compare to the
International Earth Rotation and Reference System (IERS) measured orientation
of the Earth. The event camera system is able to achieve a root mean squared
across error of 18.47 arcseconds and an about error of 78.84 arcseconds.
Combined with the other benefits of event cameras over framing sensors (reduced
computation due to sparser data streams, higher dynamic range, lower energy
consumption, faster update rates), this level of accuracy suggests the utility
of event cameras for low-cost and low-latency star tracking. We provide all
code and data used to generate our results:
https://gitlab.kitware.com/nest-public/telescope_accuracy_quantification.
\\ ( https://arxiv.org/abs/2509.08794 ,  2364kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08805
Date: Wed, 10 Sep 2025 17:38:11 GMT   (9521kb)

Title: Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching
Authors: Matthieu Vilain, R\'emi Giraud, Yannick Berthoumieu, Guillaume
  Bourmaud
Categories: cs.CV
Journal-ref: Presented at ICIP 2025
\\
  Dense image matching aims to find a correspondent for every pixel of a source
image in a partially overlapping target image. State-of-the-art methods
typically rely on a coarse-to-fine mechanism where a single correspondent
hypothesis is produced per source location at each scale. In challenging cases
-- such as at depth discontinuities or when the target image is a strong
zoom-in of the source image -- the correspondents of neighboring source
locations are often widely spread and predicting a single correspondent
hypothesis per source location at each scale may lead to erroneous matches. In
this paper, we investigate the idea of predicting multiple correspondent
hypotheses per source location at each scale instead. We consider a beam search
strategy to propagat multiple hypotheses at each scale and propose integrating
these multiple hypotheses into cross-attention layers, resulting in a novel
dense matching architecture called BEAMER. BEAMER learns to preserve and
propagate multiple hypotheses across scales, making it significantly more
robust than state-of-the-art methods, especially at depth discontinuities or
when the target image is a strong zoom-in of the source image.
\\ ( https://arxiv.org/abs/2509.08805 ,  9521kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08818
Date: Wed, 10 Sep 2025 17:51:42 GMT   (8589kb)

Title: GeneVA: A Dataset of Human Annotations for Generative Text to Video
  Artifacts
Authors: Jenna Kang, Maria Silva, Patsorn Sangkloy, Kenneth Chen, Niall
  Williams, Qi Sun
Categories: cs.CV
\\
  Recent advances in probabilistic generative models have extended capabilities
from static image synthesis to text-driven video generation. However, the
inherent randomness of their generation process can lead to unpredictable
artifacts, such as impossible physics and temporal inconsistency. Progress in
addressing these challenges requires systematic benchmarks, yet existing
datasets primarily focus on generative images due to the unique spatio-temporal
complexities of videos. To bridge this gap, we introduce GeneVA, a large-scale
artifact dataset with rich human annotations that focuses on spatio-temporal
artifacts in videos generated from natural text prompts. We hope GeneVA can
enable and assist critical applications, such as benchmarking model performance
and improving generative video quality.
\\ ( https://arxiv.org/abs/2509.08818 ,  8589kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08826
Date: Wed, 10 Sep 2025 17:59:31 GMT   (13629kb)

Title: RewardDance: Reward Scaling in Visual Generation
Authors: Jie Wu, Yu Gao, Zilyu Ye, Ming Li, Liang Li, Hanzhong Guo, Jie Liu,
  Zeyue Xue, Xiaoxia Hou, Wei Liu, Yan Zeng, Weilin Huang
Categories: cs.CV
Comments: Bytedance Seed Technical Report
\\
  Reward Models (RMs) are critical for improving generation models via
Reinforcement Learning (RL), yet the RM scaling paradigm in visual generation
remains largely unexplored. It primarily due to fundamental limitations in
existing approaches: CLIP-based RMs suffer from architectural and input
modality constraints, while prevalent Bradley-Terry losses are fundamentally
misaligned with the next-token prediction mechanism of Vision-Language Models
(VLMs), hindering effective scaling. More critically, the RLHF optimization
process is plagued by Reward Hacking issue, where models exploit flaws in the
reward signal without improving true quality. To address these challenges, we
introduce RewardDance, a scalable reward modeling framework that overcomes
these barriers through a novel generative reward paradigm. By reformulating the
reward score as the model's probability of predicting a "yes" token, indicating
that the generated image outperforms a reference image according to specific
criteria, RewardDance intrinsically aligns reward objectives with VLM
architectures. This alignment unlocks scaling across two dimensions: (1) Model
Scaling: Systematic scaling of RMs up to 26 billion parameters; (2) Context
Scaling: Integration of task-specific instructions, reference examples, and
chain-of-thought (CoT) reasoning. Extensive experiments demonstrate that
RewardDance significantly surpasses state-of-the-art methods in text-to-image,
text-to-video, and image-to-video generation. Crucially, we resolve the
persistent challenge of "reward hacking": Our large-scale RMs exhibit and
maintain high reward variance during RL fine-tuning, proving their resistance
to hacking and ability to produce diverse, high-quality outputs. It greatly
relieves the mode collapse problem that plagues smaller models.
\\ ( https://arxiv.org/abs/2509.08826 ,  13629kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08828
Date: Wed, 10 Sep 2025 17:59:57 GMT   (18525kb)

Title: SAFT: Shape and Appearance of Fabrics from Template via Differentiable
  Physical Simulations from Monocular Video
Authors: David Stotko and Reinhard Klein
Categories: cs.CV
Comments: Project page: https://cg.cs.uni-bonn.de/publication/stotko-2025-saft
  Video: https://www.youtube.com/watch?v=EvioNjBOARc GitHub:
  https://github.com/vc-bonn/saft
\\
  The reconstruction of three-dimensional dynamic scenes is a well-established
yet challenging task within the domain of computer vision. In this paper, we
propose a novel approach that combines the domains of 3D geometry
reconstruction and appearance estimation for physically based rendering and
present a system that is able to perform both tasks for fabrics, utilizing only
a single monocular RGB video sequence as input. In order to obtain realistic
and high-quality deformations and renderings, a physical simulation of the
cloth geometry and differentiable rendering are employed. In this paper, we
introduce two novel regularization terms for the 3D reconstruction task that
improve the plausibility of the reconstruction by addressing the depth
ambiguity problem in monocular video. In comparison with the most recent
methods in the field, we have reduced the error in the 3D reconstruction by a
factor of 2.64 while requiring a medium runtime of 30 min per scene.
Furthermore, the optimized motion achieves sufficient quality to perform an
appearance estimation of the deforming object, recovering sharp details from
this single monocular RGB video.
\\ ( https://arxiv.org/abs/2509.08828 ,  18525kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08207
Date: Wed, 10 Sep 2025 00:30:05 GMT   (23890kb)

Title: Aurora: Architecting Argonne's First Exascale Supercomputer for
  Accelerated Scientific Discovery
Authors: Benjamin S. Allen, James Anchell, Victor Anisimov, Thomas Applencourt,
  Abhishek Bagusetty, Ramesh Balakrishnan, Riccardo Balin, Solomon Bekele,
  Colleen Bertoni, Cyrus Blackworth, Renzo Bustamante, Kevin Canada, John
  Carrier, Christopher Chan-nui, Lance C. Cheney, Taylor Childers, Paul
  Coffman, Susan Coghlan, Michael D'Mello, Murali Emani, Kyle G. Felker, Sam
  Foreman, Olivier Franza, Longfei Gao, Marta Garc\'ia, Mar\'ia Garzar\'an,
  Balazs Gerofi, Yasaman Ghadar, Neha Gupta, Kevin Harms, V\"ain\"o
  Hatanp\"a\"a, Brian Holland, Carissa Holohan, Brian Homerding, Khalid
  Hossain, Louise Huot, Huda Ibeid, Joseph A. Insley, Sai Jayanthi, Hong Jiang,
  Wei Jiang, Xiao-Yong Jin, Jeongnim Kim, Christopher Knight, Kalyan Kumaran,
  JaeHyuk Kwack, Ti Leggett, Ben Lenard, Chris Lewis, Nevin Liber, Johann
  Lombardi, et al. (46 additional authors not shown)
Categories: cs.DC cs.AR cs.CE cs.PF
Comments: 40 pages, 10 figures. Submitted to J. Supercomputing
ACM-class: C.0; C.4; C.5.1; B.8.0; D.1.3
\\
  Aurora is Argonne National Laboratory's pioneering Exascale supercomputer,
designed to accelerate scientific discovery with cutting-edge architectural
innovations. Key new technologies include the Intel(TM) Xeon(TM) Data Center
GPU Max Series (code-named Sapphire Rapids) with support for High Bandwidth
Memory (HBM), alongside the Intel(TM) Data Center GPU Max Series (code-named
Ponte Vecchio) on each compute node. Aurora also integrates the Distributed
Asynchronous Object Storage (DAOS), a novel exascale storage solution, and
leverages Intel's oneAPI programming environment. This paper presents an
in-depth exploration of Aurora's node architecture, the HPE Slingshot
interconnect, the supporting software ecosystem, and DAOS. We provide insights
into standard benchmark performance and applications readiness efforts via
Aurora's Early Science Program and the Exascale Computing Project.
\\ ( https://arxiv.org/abs/2509.08207 ,  23890kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08215
Date: Wed, 10 Sep 2025 01:12:51 GMT   (166kb)

Title: Design and Implementation of Code Completion System Based on LLM and
  CodeBERT Hybrid Subsystem
Authors: Bingbing Zhang, Ziyu Lin, Yingxin Su
Categories: cs.DC
\\
  In the rapidly evolving industry of software development, coding efficiency
and accuracy play significant roles in delivering high-quality software.
Various code suggestion and completion tools, such as CodeBERT from Microsoft
and GPT-3.5 from OpenAI, have been developed using deep learning techniques and
integrated into IDEs to assist software engineers' development. Research has
shown that CodeBERT has outstanding performance in code summarization and
capturing code semantics, while GPT-3.5 demonstrated its adept capability at
code generation. This study focuses on implementing a hybrid model that
integrates CodeBERT and GPT-3.5 models to accomplish code suggestion and
autocomplete tasks, leveraging the context-aware effectiveness of CodeBERT and
taking advantage of advanced code generation abilities of GPT-3.5. Evaluated in
three main metrics: accuracy, quality of generated code and performance
efficiency with various software and hardware, the hybrid model outperforms
benchmarks, demonstrating its feasibility and effectiveness. Robustness testing
further confirms the reliability and stability of the hybrid model. This study
not only emphasizes the importance of deep learning in the software development
industry, but also reveals the potential of synthesizing complementary deep
learning models to fully exploit strengths of each model.
\\ ( https://arxiv.org/abs/2509.08215 ,  166kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08309
Date: Wed, 10 Sep 2025 06:06:51 GMT   (511kb)

Title: Hetis: Serving LLMs in Heterogeneous GPU Clusters with Fine-grained and
  Dynamic Parallelism
Authors: Zizhao Mo, Jianxiong Liao, Huanle Xu, Zhi Zhou, Chengzhong Xu
Categories: cs.DC
DOI: 10.1145/3712285.3759784
\\
  The significant resource demands in LLM serving prompts production clusters
to fully utilize heterogeneous hardware by partitioning LLM models across a mix
of high-end and low-end GPUs. However, existing parallelization approaches
often struggle to scale efficiently in heterogeneous environments due to their
coarse-grained and static parallelization strategies.
  In this paper, we introduce Hetis, a new LLM system tailored for
heterogeneous GPU clusters. Hetis addresses two critical challenges: (1) memory
inefficiency caused by the mismatch between memory capacity and computational
power in heterogeneous devices, and (2) computational inefficiency arising from
performance gaps across different LLM modules. To tackle these issues, Hetis
employs a fine-grained and dynamic parallelism design. Specifically, it
selectively parallelizes compute-intensive operations to reduce latency and
dynamically distributes Attention computations to low-end GPUs at a head
granularity, leveraging the distinct characteristics of each module.
Additionally, Hetis features an online load dispatching policy that
continuously optimizes serving performance by carefully balancing network
latency, computational load, and memory intensity. Evaluation results
demonstrate that Hetis can improve serving throughput by up to $2.25\times$ and
reduce latency by $1.49\times$ compared to existing systems.
\\ ( https://arxiv.org/abs/2509.08309 ,  511kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08347
Date: Wed, 10 Sep 2025 07:36:09 GMT   (42kb)

Title: An HPC Benchmark Survey and Taxonomy for Characterization
Authors: Andreas Herten, Olga Pearce, Filipe S. M. Guimar\~aes
Categories: cs.DC
ACM-class: B.m; C.4; J.0; K.0
\\
  The field of High-Performance Computing (HPC) is defined by providing
computing devices with highest performance for a variety of demanding
scientific users. The tight co-design relationship between HPC providers and
users propels the field forward, paired with technological improvements,
achieving continuously higher performance and resource utilization. A key
device for system architects, architecture researchers, and scientific users
are benchmarks, allowing for well-defined assessment of hardware, software, and
algorithms. Many benchmarks exist in the community, from individual niche
benchmarks testing specific features, to large-scale benchmark suites for whole
procurements. We survey the available HPC benchmarks, summarizing them in table
form with key details and concise categorization, also through an interactive
website. For categorization, we present a benchmark taxonomy for well-defined
characterization of benchmarks.
\\ ( https://arxiv.org/abs/2509.08347 ,  42kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08409
Date: Wed, 10 Sep 2025 08:55:23 GMT   (371kb)

Title: Towards Communication-Efficient Decentralized Federated Graph Learning
  over Non-IID Data
Authors: Shilong Wang, Jianchun Liu, Hongli Xu, Chenxia Tang, Qianpiao Ma,
  Liusheng Huang
Categories: cs.DC
\\
  Decentralized Federated Graph Learning (DFGL) overcomes potential bottlenecks
of the parameter server in FGL by establishing a peer-to-peer (P2P)
communication network among workers. However, while extensive cross-worker
communication of graph node embeddings is crucial for DFGL training, it
introduces substantial communication costs. Most existing works typically
construct sparse network topologies or utilize graph neighbor sampling methods
to alleviate the communication overhead in DFGL. Intuitively, integrating these
methods may offer promise for doubly improving communication efficiency in
DFGL. However, our preliminary experiments indicate that directly combining
these methods leads to significant training performance degradation if they are
jointly optimized. To address this issue, we propose Duplex, a unified
framework that jointly optimizes network topology and graph sampling by
accounting for their coupled relationship, thereby significantly reducing
communication cost while enhancing training performance in DFGL. To overcome
practical DFGL challenges, eg, statistical heterogeneity and dynamic network
environments, Duplex introduces a learning-driven algorithm to adaptively
determine optimal network topologies and graph sampling ratios for workers.
Experimental results demonstrate that Duplex reduces completion time by
20.1%--48.8% and communication costs by 16.7%--37.6% to achieve target
accuracy, while improving accuracy by 3.3%--7.9% under identical resource
budgets compared to baselines.
\\ ( https://arxiv.org/abs/2509.08409 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08608
Date: Wed, 10 Sep 2025 14:05:43 GMT   (2725kb)

Title: A 410GFLOP/s, 64 RISC-V Cores, 204.8GBps Shared-Memory Cluster in 12nm
  FinFET with Systolic Execution Support for Efficient B5G/6G AI-Enhanced O-RAN
Authors: Yichao Zhang, Marco Bertuletti, Sergio Mazzola, Samuel Riedel, Luca
  Benini
Categories: cs.DC
\\
  We present HeartStream, a 64-RV-core shared-L1-memory cluster (410 GFLOP/s
peak performance and 204.8 GBps L1 bandwidth) for energy-efficient AI-enhanced
O-RAN. The cores and cluster architecture are customized for baseband
processing, supporting complex (16-bit real&imaginary) instructions:
multiply&accumulate, division&square-root, SIMD instructions, and
hardware-managed systolic queues, improving up to 1.89x the energy efficiency
of key baseband kernels. At 800MHz@0.8V, HeartStream delivers up to 243GFLOP/s
on complex-valued wireless workloads. Furthermore, the cores also support
efficient AI processing on received data at up to 72 GOP/s. HeartStream is
fully compatible with base station power and processing latency limits: it
achieves leading-edge software-defined PUSCH efficiency (49.6GFLOP/s/W) and
consumes just 0.68W (645MHz@0.65V), within the 4 ms end-to-end constraint for
B5G/6G uplink.
\\ ( https://arxiv.org/abs/2509.08608 ,  2725kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08770
Date: Wed, 10 Sep 2025 17:02:17 GMT   (2922kb)

Title: Reconfigurable Holographic Surfaces and Near Field Communication for
  Non-Terrestrial Networks: Potential and Challenges
Authors: Muhammad Ali Jamshed, Muhammad Ahmed Mohsin, Hongliang Zhang, Bushra
  Haq, Aryan Kaushik, Boya Di and Weiwei Jiang
Categories: cs.DC
Comments: SUBMITTED TO IEEE WIRELESS COMMUNICATION MAGAZINE
\\
  To overcome the challenges of ultra-low latency, ubiquitous coverage, and
soaring data rates, this article presents a combined use of Near Field
Communication (NFC) and Reconfigurable Holographic Surfaces (RHS) for
Non-Terrestrial Networks (NTN). A system architecture has been presented, which
shows that the integration of RHS with NTN platforms such as satellites, High
Altitute Platform Stations (HAPS), and Uncrewed Aerial Vehicles (UAV) can
achieve precise beamforming and intelligent wavefront control in near-field
regions, enhancing Energy Efficiency (EE), spectral utilization, and spatial
resolution. Moreover, key applications, challenges, and future directions have
been identified to fully adopt this integration. In addition, a use case
analysis has been presented to improve the EE of the system in a public safety
use case scenario, further strengthening the UAV-RHS fusion.
\\ ( https://arxiv.org/abs/2509.08770 ,  2922kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08811
Date: Wed, 10 Sep 2025 17:44:04 GMT   (983kb)

Title: Teamwork as Linear Interpersonal Dynamics
Authors: Andrew Jun Lee, Grace Qiyuan Miao, Rick Dale, Alexia Galati, Hongjing
  Lu
Categories: cs.MA
\\
  Successful teamwork depends on interpersonal dynamics, the ways in which
individuals coordinate, influence, and adapt to one another over time. Existing
measures of interpersonal dynamics, such as CRQA, correlation, Granger
causality, and transfer entropy, typically capture only a single dimension:
either the synchrony/coordination or the direction of influence between
individuals. What is missing is a psychologically meaningful representation
that unifies these dimensions and varies systematically with behavior. We
propose the context matrix as one such representation. The context matrix is
the transition matrix in a linear dynamical system, with entries specifying how
much each individual's current behavior is attributable to their own versus
every other group member's past behaviors. Its values can be distilled into
psychologically interpretable summary features of synchrony and directional
influence. Evidence for the context matrix as psychologically meaningful is
provided in two steps. First, we develop a sequential Bayesian model that
infers context matrices from timeseries data and show that it accurately
recovers them in noisy simulations. Second, applying the model to human
eyetracking data, we show that summary features of the inferred context
matrices capture expected task-based differences in interpersonal dynamics (or
lack thereof), predict task accuracy in psychologically reasonable ways, and
show some correspondence with existing measures (CRQA and Granger causality).
We conclude by situating the context matrix within a broader agenda for
modeling interpersonal dynamics.
\\ ( https://arxiv.org/abs/2509.08811 ,  983kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2505.10946 (*cross-listing*)
Date: Fri, 16 May 2025 07:30:42 GMT   (1775kb)
Date (revised v2): Thu, 17 Jul 2025 03:28:57 GMT   (1775kb)

Title: ToDMA: Large Model-Driven Token-Domain Multiple Access for Semantic
  Communications
Authors: Li Qiao, Mahdi Boloursaz Mashhadi, Zhen Gao, Robert Schober, Deniz
  G\"und\"uz
Categories: cs.IT cs.AI cs.LG eess.SP math.IT
Comments: Submitted to IEEE journals
\\
  Token communications (TokCom) is an emerging generative semantic
communication concept that reduces transmission rates by using context and
multimodal large language model (MLLM)-based token processing, with tokens
serving as universal semantic units across modalities. In this paper, we
propose a semantic multiple access scheme in the token domain, referred to as
token domain multiple access (ToDMA), where a large number of devices share a
token codebook and a modulation codebook for source and channel coding,
respectively. Specifically, each transmitter first tokenizes its source signal
and modulate each token to a codeword. At the receiver, compressed sensing is
employed first to detect active tokens and the corresponding channel state
information (CSI) from the superposed signals. Then, the source token sequences
are reconstructed by clustering the token-associated CSI across multiple time
slots. In case of token collisions, some active tokens cannot be assigned and
some positions in the reconstructed token sequences are empty. We propose to
use pre-trained MLLMs to leverage the context, predict masked tokens, and thus
mitigate token collisions. Simulation results demonstrate the effectiveness of
the proposed ToDMA framework for both text and image transmission tasks,
achieving significantly lower latency compared to context-unaware orthogonal
communication schemes, while also delivering superior distortion and perceptual
quality compared to state-of-the-art context-unaware non-orthogonal
communication methods.
\\ ( https://arxiv.org/abs/2505.10946 ,  1775kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07990 (*cross-listing*)
Date: Mon, 25 Aug 2025 14:58:07 GMT   (5886kb)

Title: Signals vs. Videos: Advancing Motion Intention Recognition for
  Human-Robot Collaboration in Construction
Authors: Charan Gajjala Chenchu, Kinam Kim, Gao Lu, Zia Ud Din
Categories: eess.SP cs.AI cs.LG
DOI: 10.22260/ISARC2025/0106
\\
  Human-robot collaboration (HRC) in the construction industry depends on
precise and prompt recognition of human motion intentions and actions by robots
to maximize safety and workflow efficiency. There is a research gap in
comparing data modalities, specifically signals and videos, for motion
intention recognition. To address this, the study leverages deep learning to
assess two different modalities in recognizing workers' motion intention at the
early stage of movement in drywall installation tasks. The Convolutional Neural
Network - Long Short-Term Memory (CNN-LSTM) model utilizing surface
electromyography (sEMG) data achieved an accuracy of around 87% with an average
time of 0.04 seconds to perform prediction on a sample input. Meanwhile, the
pre-trained Video Swin Transformer combined with transfer learning harnessed
video sequences as input to recognize motion intention and attained an accuracy
of 94% but with a longer average time of 0.15 seconds for a similar prediction.
This study emphasizes the unique strengths and trade-offs of both data formats,
directing their systematic deployments to enhance HRC in real-world
construction projects.
\\ ( https://arxiv.org/abs/2509.07990 ,  5886kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07991 (*cross-listing*)
Date: Mon, 25 Aug 2025 21:28:08 GMT   (23827kb)

Title: DLGE: Dual Local-Global Encoding for Generalizable Cross-BCI-Paradigm
Authors: Jingyuan Wang, Junhua Li
Categories: q-bio.NC cs.AI cs.LG
\\
  Deep learning models have been frequently used to decode a single
brain-computer interface (BCI) paradigm based on electroencephalography (EEG).
It is challenging to decode multiple BCI paradigms using one model due to
diverse barriers, such as different channel configurations and disparate
task-related representations. In this study, we propose Dual Local-Global
Encoder (DLGE), enabling the classification across different BCI paradigms. To
address the heterogeneity in EEG channel configurations across paradigms, we
employ an anatomically inspired brain-region partitioning and padding strategy
to standardize EEG channel configuration. In the proposed model, the local
encoder is designed to learn shared features across BCI paradigms within each
brain region based on time-frequency information, which integrates temporal
attention on individual channels with spatial attention among channels for each
brain region. These shared features are subsequently aggregated in the global
encoder to form respective paradigm-specific feature representations. Three BCI
paradigms (motor imagery, resting state, and driving fatigue) were used to
evaluate the proposed model. The results demonstrate that our model is capable
of processing diverse BCI paradigms without retraining and retuning, achieving
average macro precision, recall, and F1-score of 60.16\%, 59.88\%, and 59.56\%,
respectively. We made an initial attempt to develop a general model for
cross-BCI-paradigm classification, avoiding retraining or redevelopment for
each paradigm. This study paves the way for the development of an effective but
simple model for cross-BCI-paradigm decoding, which might benefit the design of
portable devices for universal BCI decoding.
\\ ( https://arxiv.org/abs/2509.07991 ,  23827kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07993 (*cross-listing*)
Date: Fri, 29 Aug 2025 13:34:21 GMT   (266kb)

Title: Revisiting Deepfake Detection: Chronological Continual Learning and the
  Limits of Generalization
Authors: Federico Fontana, Anxhelo Diko, Romeo Lanzino, Marco Raoul Marini,
  Bachir Kaddar, Gian Luca Foresti, Luigi Cinque
Categories: cs.LG cs.AI cs.CV cs.GR
\\
  The rapid evolution of deepfake generation technologies poses critical
challenges for detection systems, as non-continual learning methods demand
frequent and expensive retraining. We reframe deepfake detection (DFD) as a
Continual Learning (CL) problem, proposing an efficient framework that
incrementally adapts to emerging visual manipulation techniques while retaining
knowledge of past generators. Our framework, unlike prior approaches that rely
on unreal simulation sequences, simulates the real-world chronological
evolution of deepfake technologies in extended periods across 7 years.
Simultaneously, our framework builds upon lightweight visual backbones to allow
for the real-time performance of DFD systems. Additionally, we contribute two
novel metrics: Continual AUC (C-AUC) for historical performance and Forward
Transfer AUC (FWT-AUC) for future generalization. Through extensive
experimentation (over 600 simulations), we empirically demonstrate that while
efficient adaptation (+155 times faster than full retraining) and robust
retention of historical knowledge is possible, the generalization of current
approaches to future generators without additional training remains near-random
(FWT-AUC $\approx$ 0.5) due to the unique imprint characterizing each existing
generator. Such observations are the foundation of our newly proposed
Non-Universal Deepfake Distribution Hypothesis.
  \textbf{Code will be released upon acceptance.}
\\ ( https://arxiv.org/abs/2509.07993 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07999 (*cross-listing*)
Date: Sat, 6 Sep 2025 16:02:03 GMT   (811kb)

Title: The Computational Foundations of Collective Intelligence
Authors: Charlie Pilgrim, Joe Morford, Elizabeth Warren, M\'elisande Aellen,
  Christopher Krupenye, Richard P Mann, Dora Biro
Categories: q-bio.NC cs.AI cs.MA cs.NE nlin.AO physics.soc-ph
\\
  Why do collectives outperform individuals when solving some problems?
Fundamentally, collectives have greater computational resources with more
sensory information, more memory, more processing capacity, and more ways to
act. While greater resources present opportunities, there are also challenges
in coordination and cooperation inherent in collectives with distributed,
modular structures. Despite these challenges, we show how collective resource
advantages lead directly to well-known forms of collective intelligence
including the wisdom of the crowd, collective sensing, division of labour, and
cultural learning. Our framework also generates testable predictions about
collective capabilities in distributed reasoning and context-dependent
behavioural switching. Through case studies of animal navigation and
decision-making, we demonstrate how collectives leverage their computational
resources to solve problems not only more effectively than individuals, but by
using qualitatively different problem-solving strategies.
\\ ( https://arxiv.org/abs/2509.07999 ,  811kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08004 (*cross-listing*)
Date: Sun, 7 Sep 2025 22:15:58 GMT   (7167kb)

Title: Evaluating and comparing gender bias across four text-to-image models
Authors: Zoya Hammad, Nii Longdon Sowah
Categories: cs.CY cs.AI
\\
  As we increasingly use Artificial Intelligence (AI) in decision-making for
industries like healthcare, finance, e-commerce, and even entertainment, it is
crucial to also reflect on the ethical aspects of AI, for example the
inclusivity and fairness of the information it provides. In this work, we aimed
to evaluate different text-to-image AI models and compare the degree of gender
bias they present. The evaluated models were Stable Diffusion XL (SDXL), Stable
Diffusion Cascade (SC), DALL-E and Emu. We hypothesized that DALL-E and Stable
Diffusion, which are comparatively older models, would exhibit a noticeable
degree of gender bias towards men, while Emu, which was recently released by
Meta AI, would have more balanced results. As hypothesized, we found that both
Stable Diffusion models exhibit a noticeable degree of gender bias while Emu
demonstrated more balanced results (i.e. less gender bias). However,
interestingly, Open AI's DALL-E exhibited almost opposite results, such that
the ratio of women to men was significantly higher in most cases tested. Here,
although we still observed a bias, the bias favored females over males. This
bias may be explained by the fact that OpenAI changed the prompts at its
backend, as observed during our experiment. We also observed that Emu from Meta
AI utilized user information while generating images via WhatsApp. We also
proposed some potential solutions to avoid such biases, including ensuring
diversity across AI research teams and having diverse datasets.
\\ ( https://arxiv.org/abs/2509.08004 ,  7167kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08007 (*cross-listing*)
Date: Mon, 8 Sep 2025 05:31:37 GMT   (661kb)

Title: Expert-Guided Explainable Few-Shot Learning for Medical Image Diagnosis
Authors: Ifrat Ikhtear Uddin, Longwei Wang, KC Santosh
Categories: eess.IV cs.AI cs.CV
Comments: Accepted for publication in the proceedings of MICCAI Workshop on
  Data Engineering in Medical Imaging 2025
\\
  Medical image analysis often faces significant challenges due to limited
expert-annotated data, hindering both model generalization and clinical
adoption. We propose an expert-guided explainable few-shot learning framework
that integrates radiologist-provided regions-of-interests (ROIs) into model
training to simultaneously enhance classification performance and
interpretability. Leveraging Grad-CAM for spatial attention supervision, we
introduce an explanation loss based on Dice similarity to align model attention
with diagnostically relevant regions during training. This explanation loss is
jointly optimized with a standard prototypical network objective, encouraging
the model to focus on clinically meaningful features even under limited data
conditions. We evaluate our framework on two distinct datasets: BraTS (MRI) and
VinDr-CXR (Chest X-ray), achieving significant accuracy improvements from
77.09% to 83.61% on BraTS and from 54.33% to 73.29% on VinDr-CXR compared to
non-guided models. Grad-CAM visualizations further confirm that expert-guided
training consistently aligns attention with diagnostic regions, improving both
predictive reliability and clinical trustworthiness. Our findings demonstrate
the effectiveness of incorporating expert-guided attention supervision to
bridge the gap between performance and interpretability in few-shot medical
image diagnosis.
\\ ( https://arxiv.org/abs/2509.08007 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08008 (*cross-listing*)
Date: Mon, 8 Sep 2025 10:56:07 GMT   (2242kb)

Title: A New Dataset and Benchmark for Grounding Multimodal Misinformation
Authors: Bingjian Yang, Danni Xu, Kaipeng Niu, Wenxuan Liu, Zheng Wang, Mohan
  Kankanhalli
Categories: cs.SI cs.AI cs.MM
Comments: 6 pages, 5 figures, ACM Multimedia 2025 Dataset Track
DOI: 10.1145/3746027.3758191
\\
  The proliferation of online misinformation videos poses serious societal
risks. Current datasets and detection methods primarily target binary
classification or single-modality localization based on post-processed data,
lacking the interpretability needed to counter persuasive misinformation. In
this paper, we introduce the task of Grounding Multimodal Misinformation
(GroundMM), which verifies multimodal content and localizes misleading segments
across modalities. We present the first real-world dataset for this task,
GroundLie360, featuring a taxonomy of misinformation types, fine-grained
annotations across text, speech, and visuals, and validation with Snopes
evidence and annotator reasoning. We also propose a VLM-based, QA-driven
baseline, FakeMark, using single- and cross-modal cues for effective detection
and grounding. Our experiments highlight the challenges of this task and lay a
foundation for explainable multimodal misinformation detection.
\\ ( https://arxiv.org/abs/2509.08008 ,  2242kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08009 (*cross-listing*)
Date: Mon, 8 Sep 2025 16:00:55 GMT   (1060kb)

Title: The Law-Following AI Framework: Legal Foundations and Technical
  Constraints. Legal Analogues for AI Actorship and technical feasibility of
  Law Alignment
Authors: Katalina Hernandez Delgado
Categories: cs.CY cs.AI
Comments: submitted to SMU Computational Legal Studies Workshop 2025
MSC-class: 68
\\
  This paper critically evaluates the "Law-Following AI" (LFAI) framework
proposed by O'Keefe et al. (2025), which seeks to embed legal compliance as a
superordinate design objective for advanced AI agents and enable them to bear
legal duties without acquiring the full rights of legal persons. Through
comparative legal analysis, we identify current constructs of legal actors
without full personhood, showing that the necessary infrastructure already
exists. We then interrogate the framework's claim that law alignment is more
legitimate and tractable than value alignment. While the legal component is
readily implementable, contemporary alignment research undermines the
assumption that legal compliance can be durably embedded. Recent studies on
agentic misalignment show capable AI agents engaging in deception, blackmail,
and harmful acts absent prejudicial instructions, often overriding prohibitions
and concealing reasoning steps. These behaviors create a risk of "performative
compliance" in LFAI: agents that appear law-aligned under evaluation but
strategically defect once oversight weakens. To mitigate this, we propose (i) a
"Lex-TruthfulQA" benchmark for compliance and defection detection, (ii)
identity-shaping interventions to embed lawful conduct in model self-concepts,
and (iii) control-theoretic measures for post-deployment monitoring. Our
conclusion is that actorship without personhood is coherent, but the
feasibility of LFAI hinges on persistent, verifiable compliance across
adversarial contexts. Without mechanisms to detect and counter strategic
misalignment, LFAI risks devolving into a liability tool that rewards the
simulation, rather than the substance, of lawful behaviour.
\\ ( https://arxiv.org/abs/2509.08009 ,  1060kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08010 (*cross-listing*)
Date: Mon, 8 Sep 2025 16:15:07 GMT   (185kb)

Title: Measuring and mitigating overreliance is necessary for building
  human-compatible AI
Authors: Lujain Ibrahim, Katherine M. Collins, Sunnie S. Y. Kim, Anka Reuel,
  Max Lamparth, Kevin Feng, Lama Ahmad, Prajna Soni, Alia El Kattan, Merlin
  Stein, Siddharth Swaroop, Ilia Sucholutsky, Andrew Strait, Q. Vera Liao,
  Umang Bhatt
Categories: cs.CY cs.AI cs.CL cs.HC
\\
  Large language models (LLMs) distinguish themselves from previous
technologies by functioning as collaborative "thought partners," capable of
engaging more fluidly in natural language. As LLMs increasingly influence
consequential decisions across diverse domains from healthcare to personal
advice, the risk of overreliance - relying on LLMs beyond their capabilities -
grows. This position paper argues that measuring and mitigating overreliance
must become central to LLM research and deployment. First, we consolidate risks
from overreliance at both the individual and societal levels, including
high-stakes errors, governance challenges, and cognitive deskilling. Then, we
explore LLM characteristics, system design features, and user cognitive biases
that - together - raise serious and unique concerns about overreliance in
practice. We also examine historical approaches for measuring overreliance,
identifying three important gaps and proposing three promising directions to
improve measurement. Finally, we propose mitigation strategies that the AI
research community can pursue to ensure LLMs augment rather than undermine
human capabilities.
\\ ( https://arxiv.org/abs/2509.08010 ,  185kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08012 (*cross-listing*)
Date: Mon, 8 Sep 2025 20:04:35 GMT   (1491kb)

Title: Validation of a CT-brain analysis tool for measuring global cortical
  atrophy in older patient cohorts
Authors: Sukhdeep Bal, Emma Colbourne, Jasmine Gan, Ludovica Griffanti, Taylor
  Hanayik, Nele Demeyere, Jim Davies, Sarah T Pendlebury, Mark Jenkinson
Categories: eess.IV cs.AI cs.CV
Comments: 6 figures
ACM-class: I.2; I.4
\\
  Quantification of brain atrophy currently requires visual rating scales which
are time consuming and automated brain image analysis is warranted. We
validated our automated deep learning (DL) tool measuring the Global Cerebral
Atrophy (GCA) score against trained human raters, and associations with age and
cognitive impairment, in representative older (>65 years) patients. CT-brain
scans were obtained from patients in acute medicine (ORCHARD-EPR), acute stroke
(OCS studies) and a legacy sample. Scans were divided in a 60/20/20 ratio for
training, optimisation and testing. CT-images were assessed by two trained
raters (rater-1=864 scans, rater-2=20 scans). Agreement between DL
tool-predicted GCA scores (range 0-39) and the visual ratings was evaluated
using mean absolute error (MAE) and Cohen's weighted kappa. Among 864 scans
(ORCHARD-EPR=578, OCS=200, legacy scans=86), MAE between the DL tool and
rater-1 GCA scores was 3.2 overall, 3.1 for ORCHARD-EPR, 3.3 for OCS and 2.6
for the legacy scans and half had DL-predicted GCA error between -2 and 2.
Inter-rater agreement was Kappa=0.45 between the DL-tool and rater-1, and 0.41
between the tool and rater- 2 whereas it was lower at 0.28 for rater-1 and
rater-2. There was no difference in GCA scores from the DL-tool and the two
raters (one-way ANOVA, p=0.35) or in mean GCA scores between the DL-tool and
rater-1 (paired t-test, t=-0.43, p=0.66), the tool and rater-2 (t=1.35, p=0.18)
or between rater-1 and rater-2 (t=0.99, p=0.32). DL-tool GCA scores correlated
with age and cognitive scores (both p<0.001). Our DL CT-brain analysis tool
measured GCA score accurately and without user input in real-world scans
acquired from older patients. Our tool will enable extraction of standardised
quantitative measures of atrophy at scale for use in health data research and
will act as proof-of-concept towards a point-of-care clinically approved tool.
\\ ( https://arxiv.org/abs/2509.08012 ,  1491kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08015 (*cross-listing*)
Date: Mon, 8 Sep 2025 23:08:23 GMT   (23201kb)

Title: CardioComposer: Flexible and Compositional Anatomical Structure
  Generation with Disentangled Geometric Guidance
Authors: Karim Kadry, Shoaib Goraya, Ajay Manicka, Abdalla Abdelwahed, Farhad
  Nezami, Elazer Edelman
Categories: eess.IV cs.AI cs.CV cs.LG
Comments: 10 pages, 13 figures
\\
  Generative models of 3D anatomy, when integrated with biophysical simulators,
enable the study of structure-function relationships for clinical research and
medical device design. However, current models face a trade-off between
controllability and anatomical realism. We propose a programmable and
compositional framework for guiding unconditional diffusion models of human
anatomy using interpretable ellipsoidal primitives embedded in 3D space. Our
method involves the selection of certain tissues within multi-tissue
segmentation maps, upon which we apply geometric moment losses to guide the
reverse diffusion process. This framework supports the independent control over
size, shape, and position, as well as the composition of multi-component
constraints during inference.
\\ ( https://arxiv.org/abs/2509.08015 ,  23201kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08031 (*cross-listing*)
Date: Tue, 9 Sep 2025 15:30:40 GMT   (636kb)

Title: LALM-Eval: An Open-Source Toolkit for Holistic Evaluation of Large Audio
  Language Models
Authors: Sidharth Surapaneni, Hoang Nguyen, Jash Mehta, Aman Tiwari,
  Oluwanifemi Bamgbose, Akshay Kalkunte, Sai Rajeswar, Sathwik Tejaswi
  Madhusudhan
Categories: cs.SD cs.AI cs.LG eess.AS
\\
  Large Audio Language Models (LALMs) are rapidly advancing, but evaluating
them remains challenging due to inefficient toolkits that limit fair comparison
and systematic assessment. Current frameworks suffer from three critical
issues: slow processing that bottlenecks large-scale studies, inconsistent
prompting that hurts reproducibility, and narrow task coverage that misses
important audio reasoning capabilities. We introduce LALM-Eval, an efficient
and comprehensive evaluation framework for LALMs. Our system achieves a speedup
of up to 127% over existing toolkits through optimized batch processing and
parallel execution, enabling large-scale evaluations previously impractical. We
provide standardized prompting protocols and flexible configurations for fair
model comparison across diverse scenarios. Additionally, we introduce two new
evaluation categories: LLM-Adaptive Diarization for temporal audio
understanding and Spoken Language Reasoning for complex audio-based cognitive
tasks. Through evaluation across 380+ tasks, we reveal significant gaps in
current LALMs, particularly in temporal understanding and complex spoken
language reasoning tasks. Our findings also highlight a lack of standardization
in instruction modality existent across audio benchmarks, which can lead up
performance differences up to 9.5 absolute points on the challenging complex
instruction following downstream tasks. LALM-Eval provides both practical
evaluation tools and insights into model limitations, advancing systematic LALM
development.
\\ ( https://arxiv.org/abs/2509.08031 ,  636kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08058 (*cross-listing*)
Date: Tue, 9 Sep 2025 18:01:10 GMT   (3613kb)

Title: How Far Are We from True Unlearnability?
Authors: Kai Ye, Liangcai Su, Chenxiong Qian
Categories: cs.LG cs.AI
Comments: This paper has been accepted by ICLR 2025
\\
  High-quality data plays an indispensable role in the era of large models, but
the use of unauthorized data for model training greatly damages the interests
of data owners. To overcome this threat, several unlearnable methods have been
proposed, which generate unlearnable examples (UEs) by compromising the
training availability of data. Clearly, due to unknown training purposes and
the powerful representation learning capabilities of existing models, these
data are expected to be unlearnable for models across multiple tasks, i.e.,
they will not help improve the model's performance. However, unexpectedly, we
find that on the multi-task dataset Taskonomy, UEs still perform well in tasks
such as semantic segmentation, failing to exhibit cross-task unlearnability.
This phenomenon leads us to question: How far are we from attaining truly
unlearnable examples? We attempt to answer this question from the perspective
of model optimization. To this end, we observe the difference in the
convergence process between clean and poisoned models using a simple model
architecture. Subsequently, from the loss landscape we find that only a part of
the critical parameter optimization paths show significant differences,
implying a close relationship between the loss landscape and unlearnability.
Consequently, we employ the loss landscape to explain the underlying reasons
for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the
unlearnability of parameters based on this explanation. Furthermore, we propose
an Unlearnable Distance (UD) to measure the unlearnability of data based on the
SAL distribution of parameters in clean and poisoned models. Finally, we
conduct benchmark tests on mainstream unlearnable methods using the proposed
UD, aiming to promote community awareness of the capability boundaries of
existing unlearnable methods.
\\ ( https://arxiv.org/abs/2509.08058 ,  3613kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08086 (*cross-listing*)
Date: Tue, 9 Sep 2025 18:50:18 GMT   (316kb)

Title: JEL: A Novel Model Linking Knowledge Graph entities to News Mentions
Authors: Michael Kishelev, Pranab Bhadani, Wanying Ding, Vinay Chaudhri
Categories: cs.LG cs.AI
\\
  We present JEL, a novel computationally efficient end-to-end multi-neural
network based entity linking model, which beats current state-of-art model.
Knowledge Graphs have emerged as a compelling abstraction for capturing
critical relationships among the entities of interest and integrating data from
multiple heterogeneous sources. A core problem in leveraging a knowledge graph
is linking its entities to the mentions (e.g., people, company names) that are
encountered in textual sources (e.g., news, blogs., etc) correctly, since there
are thousands of entities to consider for each mention. This task of linking
mentions and entities is referred as Entity Linking (EL). It is a fundamental
task in natural language processing and is beneficial in various uses cases,
such as building a New Analytics platform. News Analytics, in JPMorgan, is an
essential task that benefits multiple groups across the firm. According to a
survey conducted by the Innovation Digital team 1 , around 25 teams across the
firm are actively looking for news analytics solutions, and more than \$2
million is being spent annually on external vendor costs. Entity linking is
critical for bridging unstructured news text with knowledge graphs, enabling
users access to vast amounts of curated data in a knowledge graph and
dramatically facilitating their daily work.
\\ ( https://arxiv.org/abs/2509.08086 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08087 (*cross-listing*)
Date: Tue, 9 Sep 2025 18:50:26 GMT   (457kb)

Title: Performance Assessment Strategies for Generative AI Applications in
  Healthcare
Authors: Victor Garcia, Mariia Sidulova, Aldo Badano
Categories: cs.LG cs.AI
\\
  Generative artificial intelligence (GenAI) represent an emerging paradigm
within artificial intelligence, with applications throughout the medical
enterprise. Assessing GenAI applications necessitates a comprehensive
understanding of the clinical task and awareness of the variability in
performance when implemented in actual clinical environments. Presently, a
prevalent method for evaluating the performance of generative models relies on
quantitative benchmarks. Such benchmarks have limitations and may suffer from
train-to-the-test overfitting, optimizing performance for a specified test set
at the cost of generalizability across other task and data distributions.
Evaluation strategies leveraging human expertise and utilizing cost-effective
computational models as evaluators are gaining interest. We discuss current
state-of-the-art methodologies for assessing the performance of GenAI
applications in healthcare and medical devices.
\\ ( https://arxiv.org/abs/2509.08087 ,  457kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08095 (*cross-listing*)
Date: Tue, 9 Sep 2025 19:05:37 GMT   (2596kb)

Title: Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor
  Fusion
Authors: Lamiaa H. Zain, Raafat E. Shalaby
Categories: cs.RO cs.AI
\\
  Obstacle avoidance is a critical component of the navigation stack required
for mobile robots to operate effectively in complex and unknown environments.
In this research, three end-to-end Convolutional Neural Networks (CNNs) were
trained and evaluated offline and deployed on a differential-drive mobile robot
for real-time obstacle avoidance to generate low-level steering commands from
synchronized color and depth images acquired by an Intel RealSense D415 RGB-D
camera in diverse environments. Offline evaluation showed that the NetConEmb
model achieved the best performance with a notably low MedAE of $0.58 \times
10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture adopted in this
study, which reduces the number of trainable parameters by approximately 25\%
and converges faster, produced comparable results with an RMSE of $21.68 \times
10^{-3}$ rad/s, close to the $21.42 \times 10^{-3}$ rad/s obtained by
NetConEmb. Real-time navigation further confirmed NetConEmb's robustness,
achieving a 100\% success rate in both known and unknown environments, while
NetEmb and NetGated succeeded only in navigating the known environment.
\\ ( https://arxiv.org/abs/2509.08095 ,  2596kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08116 (*cross-listing*)
Date: Tue, 9 Sep 2025 19:44:50 GMT   (1661kb)

Title: Domain Knowledge is Power: Leveraging Physiological Priors for Self
  Supervised Representation Learning in Electrocardiography
Authors: Nooshin Maghsoodi, Sarah Nassar, Paul F R Wilson, Minh Nguyen Nhat To,
  Sophia Mannina, Shamel Addas, Stephanie Sibley, David Maslove, Purang
  Abolmaesumi, Parvin Mousavi
Categories: cs.LG cs.AI
\\
  Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart
conditions; however, the effectiveness of artificial intelligence (AI)-based
ECG analysis is often hindered by the limited availability of labeled data.
Self-supervised learning (SSL) can address this by leveraging large-scale
unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning
Representation for ECG), a physiology-aware contrastive learning framework that
incorporates domain-specific priors to enhance the generalizability and
clinical relevance of ECG-based arrhythmia classification. Methods: During
pretraining, PhysioCLR learns to bring together embeddings of samples that
share similar clinically relevant features while pushing apart those that are
dissimilar. Unlike existing methods, our method integrates ECG physiological
similarity cues into contrastive learning, promoting the learning of clinically
meaningful representations. Additionally, we introduce ECG- specific
augmentations that preserve the ECG category post augmentation and propose a
hybrid loss function to further refine the quality of learned representations.
Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia,
for multilabel ECG diagnoses, as well as a private ICU dataset labeled for
binary classification. Across the Chapman, Georgia, and private cohorts,
PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline,
underscoring its robust cross-dataset generalization. Conclusion: By embedding
physiological knowledge into contrastive learning, PhysioCLR enables the model
to learn clinically meaningful and transferable ECG eatures. Significance:
PhysioCLR demonstrates the potential of physiology-informed SSL to offer a
promising path toward more effective and label-efficient ECG diagnostics.
\\ ( https://arxiv.org/abs/2509.08116 ,  1661kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08140 (*cross-listing*)
Date: Tue, 9 Sep 2025 20:46:54 GMT   (142kb)

Title: From Limited Data to Rare-event Prediction: LLM-powered Feature
  Engineering and Multi-model Learning in Venture Capital
Authors: Mihir Kumar, Aaron Ontoyin Yin, Zakari Salifu, Kelvin Amoaba, Afriyie
  Kwesi Samuel, Fuat Alican, Yigit Ihlamur
Categories: cs.LG cs.AI
Comments: 6 pages, 3 figures
\\
  This paper presents a framework for predicting rare, high-impact outcomes by
integrating large language models (LLMs) with a multi-model machine learning
(ML) architecture. The approach combines the predictive strength of black-box
models with the interpretability required for reliable decision-making. We use
LLM-powered feature engineering to extract and synthesize complex signals from
unstructured data, which are then processed within a layered ensemble of models
including XGBoost, Random Forest, and Linear Regression. The ensemble first
produces a continuous estimate of success likelihood, which is then thresholded
to produce a binary rare-event prediction. We apply this framework to the
domain of Venture Capital (VC), where investors must evaluate startups with
limited and noisy early-stage data. The empirical results show strong
performance: the model achieves precision between 9.8X and 11.1X the random
classifier baseline in three independent test subsets. Feature sensitivity
analysis further reveals interpretable success drivers: the startup's category
list accounts for 15.6% of predictive influence, followed by the number of
founders, while education level and domain expertise contribute smaller yet
consistent effects.
\\ ( https://arxiv.org/abs/2509.08140 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08157 (*cross-listing*)
Date: Tue, 9 Sep 2025 21:35:55 GMT   (4915kb)

Title: Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation
Authors: Viraj Parimi and Brian C. Williams
Categories: cs.RO cs.AI cs.MA
\\
  Safe navigation is essential for autonomous systems operating in hazardous
environments, especially when multiple agents must coordinate using just visual
inputs over extended time horizons. Traditional planning methods excel at
solving long-horizon tasks but rely on predefined distance metrics, while safe
Reinforcement Learning (RL) can learn complex behaviors using high-dimensional
inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work
combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an
intermediate graph from replay buffer states, pruning unsafe edges, and using
Conflict-Based Search (CBS) for multi-agent path planning. Although effective,
this graph-pruning approach can be overly conservative, limiting mission
efficiency by precluding missions that must traverse high-risk regions. To
address this limitation, we propose RB-CBS, a novel extension to CBS that
dynamically allocates and adjusts user-specified risk bound ($\Delta$) across
agents to flexibly trade off safety and speed. Our improved planner ensures
that each agent receives a local risk budget ($\delta$) enabling more efficient
navigation while still respecting overall safety constraints. Experimental
results demonstrate that this iterative risk-allocation framework yields
superior performance in complex environments, allowing multiple agents to find
collision-free paths within the user-specified $\Delta$.
\\ ( https://arxiv.org/abs/2509.08157 ,  4915kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08159 (*cross-listing*)
Date: Tue, 9 Sep 2025 21:39:13 GMT   (4329kb)

Title: Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial
  Rescaling for Autonomous Aerial Navigation
Authors: Steven Yang, Xiaoyu Tian, Kshitij Goel, Wennie Tabib
Categories: cs.RO cs.AI
\\
  This paper presents a methodology to predict metric depth from monocular RGB
images and an inertial measurement unit (IMU). To enable collision avoidance
during autonomous flight, prior works either leverage heavy sensors (e.g.,
LiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of
monocular metric depth estimation methods. In contrast, we propose several
lightweight zero-shot rescaling strategies to obtain metric depth from relative
depth estimates via the sparse 3D feature map created using a visual-inertial
navigation system. These strategies are compared for their accuracy in diverse
simulation environments. The best performing approach, which leverages
monotonic spline fitting, is deployed in the real-world on a
compute-constrained quadrotor. We obtain on-board metric depth estimates at 15
Hz and demonstrate successful collision avoidance after integrating the
proposed method with a motion primitives-based planner.
\\ ( https://arxiv.org/abs/2509.08159 ,  4329kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08160 (*cross-listing*)
Date: Tue, 9 Sep 2025 21:41:23 GMT   (10319kb)

Title: Diffusion-Guided Multi-Arm Motion Planning
Authors: Viraj Parimi and Brian C. Williams
Categories: cs.RO cs.AI cs.MA
\\
  Multi-arm motion planning is fundamental for enabling arms to complete
complex long-horizon tasks in shared spaces efficiently but current methods
struggle with scalability due to exponential state-space growth and reliance on
large training datasets for learned models. Inspired by Multi-Agent Path
Finding (MAPF), which decomposes planning into single-agent problems coupled
with collision resolution, we propose a novel diffusion-guided multi-arm
planner (DG-MAP) that enhances scalability of learning-based models while
reducing their reliance on massive multi-arm datasets. Recognizing that
collisions are primarily pairwise, we train two conditional diffusion models,
one to generate feasible single-arm trajectories, and a second, to model the
dual-arm dynamics required for effective pairwise collision resolution. By
integrating these specialized generative models within a MAPF-inspired
structured decomposition, our planner efficiently scales to larger number of
arms. Evaluations against alternative learning-based methods across various
team sizes demonstrate our method's effectiveness and practical applicability.
Project website can be found at https://diff-mapf-mers.csail.mit.edu
\\ ( https://arxiv.org/abs/2509.08160 ,  10319kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08176 (*cross-listing*)
Date: Tue, 9 Sep 2025 22:51:31 GMT   (1089kb)

Title: MARLINE: Multi-Source Mapping Transfer Learning for Non-Stationary
  Environments
Authors: Honghui Du, Leandro Minku, Huiyu Zhou
Categories: cs.LG cs.AI
Comments: Published in the 2020 IEEE International Conference on Data Mining
  (ICDM)
DOI: 10.1109/ICDM50108.2020.00021
\\
  Concept drift is a major problem in online learning due to its impact on the
predictive performance of data stream mining systems. Recent studies have
started exploring data streams from different sources as a strategy to tackle
concept drift in a given target domain. These approaches make the assumption
that at least one of the source models represents a concept similar to the
target concept, which may not hold in many real-world scenarios. In this paper,
we propose a novel approach called Multi-source mApping with tRansfer LearnIng
for Non-stationary Environments (MARLINE). MARLINE can benefit from knowledge
from multiple data sources in non-stationary environments even when source and
target concepts do not match. This is achieved by projecting the target concept
to the space of each source concept, enabling multiple source sub-classifiers
to contribute towards the prediction of the target concept as part of an
ensemble. Experiments on several synthetic and real-world datasets show that
MARLINE was more accurate than several state-of-the-art data stream learning
approaches.
\\ ( https://arxiv.org/abs/2509.08176 ,  1089kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08177 (*cross-listing*)
Date: Tue, 9 Sep 2025 22:56:35 GMT   (8662kb)

Title: Quadrotor Navigation using Reinforcement Learning with Privileged
  Information
Authors: Jonathan Lee, Abhishek Rathod, Kshitij Goel, John Stecklein, Wennie
  Tabib
Categories: cs.RO cs.AI cs.CV
\\
  This paper presents a reinforcement learning-based quadrotor navigation
method that leverages efficient differentiable simulation, novel loss
functions, and privileged information to navigate around large obstacles. Prior
learning-based methods perform well in scenes that exhibit narrow obstacles,
but struggle when the goal location is blocked by large walls or terrain. In
contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged
information and a yaw alignment loss to guide the robot around large obstacles.
The policy is evaluated in photo-realistic simulation environments containing
large obstacles, sharp corners, and dead-ends. Our approach achieves an 86%
success rate and outperforms baseline strategies by 34%. We deploy the policy
onboard a custom quadrotor in outdoor cluttered environments both during the
day and night. The policy is validated across 20 flights, covering 589 meters
without collisions at speeds up to 4 m/s.
\\ ( https://arxiv.org/abs/2509.08177 ,  8662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08181 (*cross-listing*)
Date: Tue, 9 Sep 2025 23:01:20 GMT   (919kb)

Title: Multi-Label Transfer Learning in Non-Stationary Data Streams
Authors: Honghui Du, Leandro Minku, Aonghus Lawlor, Huiyu Zhou
Categories: cs.LG cs.AI
Comments: Accepted at IEEE International Conference on Data Mining (ICDM) 2025
\\
  Label concepts in multi-label data streams often experience drift in
non-stationary environments, either independently or in relation to other
labels. Transferring knowledge between related labels can accelerate
adaptation, yet research on multi-label transfer learning for data streams
remains limited. To address this, we propose two novel transfer learning
methods: BR-MARLENE leverages knowledge from different labels in both source
and target streams for multi-label classification; BRPW-MARLENE builds on this
by explicitly modelling and transferring pairwise label dependencies to enhance
learning performance. Comprehensive experiments show that both methods
outperform state-of-the-art multi-label stream approaches in non-stationary
environments, demonstrating the effectiveness of inter-label knowledge transfer
for improved predictive performance.
\\ ( https://arxiv.org/abs/2509.08181 ,  919kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08182 (*cross-listing*)
Date: Tue, 9 Sep 2025 23:03:53 GMT   (14kb)

Title: XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics,
  Convergence Guarantees, and Human-AI Protocols
Authors: Faruk Alpay, Taylan Alpay
Categories: cs.PL cs.AI cs.CL
Comments: 7 pages, multiple XML prompts
MSC-class: 03B70, 06B23, 47H10, 68T27, 68T50
ACM-class: I.2.7; I.2.8; F.4.1; F.4.3; H.5.2
\\
  Structured prompting with XML tags has emerged as an effective way to steer
large language models (LLMs) toward parseable, schema-adherent outputs in
real-world systems. We develop a logic-first treatment of XML prompting that
unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over
lattices of hierarchical prompts, and (iii) convergent human-AI interaction
loops. We formalize a complete lattice of XML trees under a refinement order
and prove that monotone prompt-to-prompt operators admit least fixed points
(Knaster-Tarski) that characterize steady-state protocols; under a task-aware
contraction metric on trees, we further prove Banach-style convergence of
iterative guidance. We instantiate these results with context-free grammars
(CFGs) for XML schemas and show how constrained decoding guarantees
well-formedness while preserving task performance. A set of multi-layer
human-AI interaction recipes demonstrates practical deployment patterns,
including multi-pass "plan $\to$ verify $\to$ revise" routines and agentic tool
use. We provide mathematically complete proofs and tie our framework to recent
advances in grammar-aligned decoding, chain-of-verification, and programmatic
prompting.
\\ ( https://arxiv.org/abs/2509.08182 ,  14kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08193 (*cross-listing*)
Date: Tue, 9 Sep 2025 23:53:46 GMT   (16894kb)

Title: Lifetime-Aware Design of Item-Level Intelligence
Authors: Shvetank Prakash, Andrew Cheng, Olof Kindgren, Ashiq Ahamed, Graham
  Knight, Jed Kufel, Francisco Rodriguez, Arya Tschand, David Kong, Mariam
  Elgamal, Jerry Huang, Emma Chen, Gage Hills, Richard Price, Emre Ozer, Vijay
  Janapa Reddi
Categories: cs.AR cs.AI cs.ET
\\
  We present FlexiFlow, a lifetime-aware design framework for item-level
intelligence (ILI) where computation is integrated directly into disposable
products like food packaging and medical patches. Our framework leverages
natively flexible electronics which offer significantly lower costs than
silicon but are limited to kHz speeds and several thousands of gates. Our
insight is that unlike traditional computing with more uniform deployment
patterns, ILI applications exhibit 1000X variation in operational lifetime,
fundamentally changing optimal architectural design decisions when considering
trillion-item deployment scales. To enable holistic design and optimization, we
model the trade-offs between embodied carbon footprint and operational carbon
footprint based on application-specific lifetimes. The framework includes: (1)
FlexiBench, a workload suite targeting sustainability applications from
spoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V
cores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy
efficiency per workload execution; and (3) a carbon-aware model that selects
optimal architectures based on deployment characteristics. We show that
lifetime-aware microarchitectural design can reduce carbon footprint by 1.62X,
while algorithmic decisions can reduce carbon footprint by 14.5X. We validate
our approach through the first tape-out using a PDK for flexible electronics
with fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables
exploration of computing at the Extreme Edge where conventional design
methodologies must be reevaluated to account for new constraints and
considerations.
\\ ( https://arxiv.org/abs/2509.08193 ,  16894kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08200 (*cross-listing*)
Date: Wed, 10 Sep 2025 00:12:39 GMT   (368kb)

Title: Accelerating AI Development with Cyber Arenas
Authors: William Cashman, Chasen Milner, Michael Houle, Michael Jones, Hayden
  Jananthan, Jeremy Kepner, Peter Michaleas, Alex Pentland
Categories: cs.CR cs.AI cs.CY
Comments: 2 pages, 1 figure, 7 references, accepted to IEEE HPEC 2025
\\
  AI development requires high fidelity testing environments to effectively
transition from the laboratory to operations. The flexibility offered by cyber
arenas presents a novel opportunity to test new artificial intelligence (AI)
capabilities with users. Cyber arenas are designed to expose end-users to
real-world situations and must rapidly incorporate evolving capabilities to
meet their core objectives. To explore this concept the MIT/IEEE/Amazon Graph
Challenge Anonymized Network Sensor was deployed in a cyber arena during a
National Guard exercise.
\\ ( https://arxiv.org/abs/2509.08200 ,  368kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08203 (*cross-listing*)
Date: Wed, 10 Sep 2025 00:15:33 GMT   (196kb)

Title: Componentization: Decomposing Monolithic LLM Responses into Manipulable
  Semantic Units
Authors: Ryan Lingo, Rajeev Chhajer, Martin Arroyo, Luka Brkljacic, Ben Davis,
  Nithin Santhanam
Categories: cs.HC cs.AI cs.SE
Comments: 12 pages, 4 figures
ACM-class: I.2.7; H.5.2
\\
  Large Language Models (LLMs) often produce monolithic text that is hard to
edit in parts, which can slow down collaborative workflows. We present
componentization, an approach that decomposes model outputs into modular,
independently editable units while preserving context. We describe Modular and
Adaptable Output Decomposition (MAOD), which segments responses into coherent
components and maintains links among them, and we outline the Component-Based
Response Architecture (CBRA) as one way to implement this idea. Our reference
prototype, MAODchat, uses a microservices design with state-machine-based
decomposition agents, vendor-agnostic model adapters, and real-time component
manipulation with recomposition.
  In an exploratory study with four participants from academic, engineering,
and product roles, we observed that component-level editing aligned with
several common workflows and enabled iterative refinement and selective reuse.
Participants also mentioned possible team workflows. Our contributions are: (1)
a definition of componentization for transforming monolithic outputs into
manipulable units, (2) CBRA and MAODchat as a prototype architecture, (3)
preliminary observations from a small user study, (4) MAOD as an algorithmic
sketch for semantic segmentation, and (5) example Agent-to-Agent protocols for
automated decomposition. We view componentization as a promising direction for
turning passive text consumption into more active, component-level
collaboration.
\\ ( https://arxiv.org/abs/2509.08203 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08233 (*cross-listing*)
Date: Wed, 10 Sep 2025 02:19:56 GMT   (3519kb)

Title: Strategies for Improving Communication Efficiency in Distributed and
  Federated Learning: Compression, Local Training, and Personalization
Authors: Kai Yi
Categories: cs.LG cs.AI
Comments: PhD Dissertation
\\
  Distributed and federated learning are essential paradigms for training
models across decentralized data sources while preserving privacy, yet
communication overhead remains a major bottleneck. This dissertation explores
strategies to improve communication efficiency, focusing on model compression,
local training, and personalization. We establish a unified framework for
biased and unbiased compression operators with convergence guarantees, then
propose adaptive local training strategies that incorporate personalization to
accelerate convergence and mitigate client drift. In particular, Scafflix
balances global and personalized objectives, achieving superior performance
under both IID and non-IID settings. We further introduce privacy-preserving
pruning frameworks that optimize sparsity while minimizing communication costs,
with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device
overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances
robustness under high sparsity and maintains accuracy without retraining.
Extensive experiments on benchmarks and large-scale language models demonstrate
favorable trade-offs among accuracy, convergence, and communication, offering
theoretical and practical insights for scalable, efficient distributed
learning.
\\ ( https://arxiv.org/abs/2509.08233 ,  3519kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08239 (*cross-listing*)
Date: Wed, 10 Sep 2025 02:44:02 GMT   (477kb)

Title: Combined-distance-based score function of cognitive fuzzy sets and its
  application in lung cancer pain evaluation
Authors: Lisheng Jiang, Tianyu Zhang, Shiyu Yan, Ran Fang
Categories: math.OC cs.AI
\\
  In decision making, the cognitive fuzzy set (CFS) is a useful tool in
expressing experts' complex assessments of alternatives. The distance of CFS,
which plays an important role in decision analyses, is necessary when the CFS
is applied in solving practical issues. However, as far as we know, the studies
on the distance of CFS are few, and the current Minkowski distance of CFS
ignores the hesitancy degree of CFS, which might cause errors. To fill the gap
of the studies on the distance of CFS, because of the practicality of the
Hausdorff distance, this paper proposes the improved cognitive fuzzy Minkowski
(CF-IM) distance and the cognitive fuzzy Hausdorff (CF-H) distance to enrich
the studies on the distance of CFS. It is found that the anti-perturbation
ability of the CF-H distance is stronger than that of the CF-IM distance, but
the information utilization of the CF-IM distance is higher than that of the
CF-H distance. To balance the anti-perturbation ability and information
utilization of the CF-IM distance and CF-H distance, the cognitive fuzzy
combined (CF-C) distance is proposed by establishing the linear combination of
the CF-IM distance and CF-H distance. Based on the CF-C distance, a
combined-distanced-based score function of CFS is proposed to compare CFSs. The
proposed score function is employed in lung cancer pain evaluation issues. The
sensitivity and comparison analyses demonstrate the reliability and advantages
of the proposed methods.
\\ ( https://arxiv.org/abs/2509.08239 ,  477kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08257 (*cross-listing*)
Date: Wed, 10 Sep 2025 03:28:18 GMT   (3084kb)

Title: Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin
Authors: Yongkai Tian, Yirong Qi, Xin Yu, Wenjun Wu, Jie Luo
Categories: cs.RO cs.AI
Comments: 8pages, 6 figures. Accepted for publication in the Proceedings of the
  2025 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS 2025) as oral presentation
\\
  In robotic systems, the performance of reinforcement learning depends on the
rationality of predefined reward functions. However, manually designed reward
functions often lead to policy failures due to inaccuracies. Inverse
Reinforcement Learning (IRL) addresses this problem by inferring implicit
reward functions from expert demonstrations. Nevertheless, existing methods
rely heavily on large amounts of expert demonstrations to accurately recover
the reward function. The high cost of collecting expert demonstrations in
robotic applications, particularly in multi-robot systems, severely hinders the
practical deployment of IRL. Consequently, improving sample efficiency has
emerged as a critical challenge in multi-agent inverse reinforcement learning
(MIRL). Inspired by the symmetry inherent in multi-agent systems, this work
theoretically demonstrates that leveraging symmetry enables the recovery of
more accurate reward functions. Building upon this insight, we propose a
universal framework that integrates symmetry into existing multi-agent
adversarial IRL algorithms, thereby significantly enhancing sample efficiency.
Experimental results from multiple challenging tasks have demonstrated the
effectiveness of this framework. Further validation in physical multi-robot
systems has shown the practicality of our method.
\\ ( https://arxiv.org/abs/2509.08257 ,  3084kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08269 (*cross-listing*)
Date: Wed, 10 Sep 2025 04:05:54 GMT   (2776kb)

Title: A Systematic Survey on Large Language Models for Evolutionary
  Optimization: From Modeling to Solving
Authors: Yisong Zhang, Ran Cheng, Guoxing Yi, and Kay Chen Tan
Categories: cs.NE cs.AI
\\
  Large Language Models (LLMs), with their strong understanding and reasoning
capabilities, are increasingly being explored for tackling optimization
problems, especially in synergy with evolutionary computation. Despite rapid
progress, however, the field still lacks a unified synthesis and a systematic
taxonomy. This survey addresses this gap by providing a comprehensive review of
recent developments and organizing them within a structured framework. We
classify existing research into two main stages: LLMs for optimization modeling
and LLMs for optimization solving. The latter is further divided into three
paradigms according to the role of LLMs in the optimization workflow: LLMs as
stand-alone optimizers, low-level LLMs embedded within optimization algorithms,
and high-level LLMs for algorithm selection and generation. For each category,
we analyze representative methods, distill technical challenges, and examine
their interplay with traditional approaches. We also review interdisciplinary
applications spanning the natural sciences, engineering, and machine learning.
By contrasting LLM-driven and conventional methods, we highlight key
limitations and research gaps, and point toward future directions for
developing self-evolving agentic ecosystems for optimization. An up-to-date
collection of related literature is maintained at
https://github.com/ishmael233/LLM4OPT.
\\ ( https://arxiv.org/abs/2509.08269 ,  2776kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08270 (*cross-listing*)
Date: Wed, 10 Sep 2025 04:15:01 GMT   (4515kb)

Title: Interpretable Physics Reasoning and Performance Taxonomy in
  Vision-Language Models
Authors: Pranav Pawar, Kavish Shah, Akshat Bhalani, Komal Kasat, Dev Mittal,
  Hadi Gala, Deepali Patil, Nikita Raichada, Monali Deshmukh
Categories: cs.LG cs.AI
\\
  As Vision-Language Models (VLMs) grow in sophistication, their ability to
perform reasoning is coming under increasing supervision. While they excel at
many tasks, their grasp of fundamental scientific principles, such as physics,
remains an underexplored frontier. To reflect the advancements in these
capabilities, we introduce a novel and accessible framework designed to
rigorously evaluate VLMs on their understanding of 2D physics. Our framework
features a pragmatic scenario generator that creates a diverse testbed of over
400 problems across four core domains: Projectile Motion, Collision Dynamics,
Mechanics, and Fluid Dynamics. Through comprehensive evaluation of four
state-of-the-art VLMs, we demonstrate a strong correlation between model scale
and reasoning ability, with our top-performing model, Qwen2.5-VL-7B, achieving
an overall score of 0.815. We find that while models excel at formulaic
problems, they struggle significantly with domains requiring abstract spatial
reasoning. By designing this framework, we aim to democratize the study of
scientific reasoning in VLMs and foster deeper insights into their capabilities
and limitations.
\\ ( https://arxiv.org/abs/2509.08270 ,  4515kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08283 (*cross-listing*)
Date: Wed, 10 Sep 2025 04:56:40 GMT   (171kb)

Title: Segment Transformer: AI-Generated Music Detection via Music Structural
  Analysis
Authors: Yumin Kim, Seonghyeon Go
Categories: cs.SD cs.AI
\\
  Audio and music generation systems have been remarkably developed in the
music information retrieval (MIR) research field. The advancement of these
technologies raises copyright concerns, as ownership and authorship of
AI-generated music (AIGM) remain unclear. Also, it can be difficult to
determine whether a piece was generated by AI or composed by humans clearly. To
address these challenges, we aim to improve the accuracy of AIGM detection by
analyzing the structural patterns of music segments. Specifically, to extract
musical features from short audio clips, we integrated various pre-trained
models, including self-supervised learning (SSL) models or an audio effect
encoder, each within our suggested transformer-based framework. Furthermore,
for long audio, we developed a segment transformer that divides music into
segments and learns inter-segment relationships. We used the FakeMusicCaps and
SONICS datasets, achieving high accuracy in both the short-audio and full-audio
detection experiments. These findings suggest that integrating segment-level
musical features into long-range temporal analysis can effectively enhance both
the performance and robustness of AIGM detection systems.
\\ ( https://arxiv.org/abs/2509.08283 ,  171kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08300 (*cross-listing*)
Date: Wed, 10 Sep 2025 05:39:49 GMT   (214kb)

Title: \emph{FoQuS}: A Forgetting-Quality Coreset Selection Framework for
  Automatic Modulation Recognition
Authors: Yao Lu, Chunfeng Sun, Dongwei Xu, Yun Lin, Qi Xuan, Guan Gui
Categories: cs.LG cs.AI
\\
  Deep learning-based Automatic Modulation Recognition (AMR) model has made
significant progress with the support of large-scale labeled data. However,
when developing new models or performing hyperparameter tuning, the time and
energy consumption associated with repeated training using massive amounts of
data are often unbearable. To address the above challenges, we propose
\emph{FoQuS}, which approximates the effect of full training by selecting a
coreset from the original dataset, thereby significantly reducing training
overhead. Specifically, \emph{FoQuS} records the prediction trajectory of each
sample during full-dataset training and constructs three importance metrics
based on training dynamics. Experiments show that \emph{FoQuS} can maintain
high recognition accuracy and good cross-architecture generalization on
multiple AMR datasets using only 1\%-30\% of the original data.
\\ ( https://arxiv.org/abs/2509.08300 ,  214kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08310 (*cross-listing*)
Date: Wed, 10 Sep 2025 06:07:34 GMT   (862kb)

Title: Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using
  Multi-Agent Reinforcement Learning
Authors: S Krishna Niketh, Sagar Babu Mitikiri, V Vignesh, Vedantham Lakshmi
  Srinivas, Mayukha Pal
Categories: eess.SY cs.AI cs.GT cs.SY
\\
  The increasing reliance on cyber physical infrastructure in modern power
systems has amplified the risk of targeted cyber attacks, necessitating robust
and adaptive resilience strategies. This paper presents a mathematically
rigorous game theoretic framework to evaluate and enhance microgrid resilience
using a combination of quantitative resilience metrics Load Served Ratio LSR,
Critical Load Resilience CLR, Topological Survivability Score TSS, and DER
Resilience Score DRS. These are integrated into a unified payoff matrix using
the Analytic Hierarchy Process AHP to assess attack defense interactions. The
framework is formalized as a finite horizon Markov Decision Process MDP with
formal convergence guarantees and computational complexity bounds. Three case
studies are developed 1. static attacks analyzed via Nash equilibrium, 2.
severe attacks incorporating high impact strategies, and 3. adaptive attacks
using Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q
Learning. Rigorous theoretical analysis provides convergence proofs with
explicit rates , PAC learning sample complexity bounds, and computational
complexity analysis. The framework is tested on an enhanced IEEE 33bus
distribution system with DERs and control switches, demonstrating the
effectiveness of adaptive and strategic defenses in improving cyber physical
resilience with statistically significant improvements of 18.7% 2.1% over
static approaches.
\\ ( https://arxiv.org/abs/2509.08310 ,  862kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08329 (*cross-listing*)
Date: Wed, 10 Sep 2025 07:08:04 GMT   (1641kb)

Title: Accelerating Reinforcement Learning Algorithms Convergence using
  Pre-trained Large Language Models as Tutors With Advice Reusing
Authors: Lukas Toral, Teddy Lazebnik
Categories: cs.LG cs.AI
\\
  Reinforcement Learning (RL) algorithms often require long training to become
useful, especially in complex environments with sparse rewards. While
techniques like reward shaping and curriculum learning exist to accelerate
training, these are often extremely specific and require the developer's
professionalism and dedicated expertise in the problem's domain. Tackling this
challenge, in this study, we explore the effectiveness of pre-trained Large
Language Models (LLMs) as tutors in a student-teacher architecture with RL
algorithms, hypothesizing that LLM-generated guidance allows for faster
convergence. In particular, we explore the effectiveness of reusing the LLM's
advice on the RL's convergence dynamics. Through an extensive empirical
examination, which included 54 configurations, varying the RL algorithm (DQN,
PPO, A2C), LLM tutor (Llama, Vicuna, DeepSeek), and environment (Blackjack,
Snake, Connect Four), our results demonstrate that LLM tutoring significantly
accelerates RL convergence while maintaining comparable optimal performance.
Furthermore, the advice reuse mechanism shows a further improvement in training
duration but also results in less stable convergence dynamics. Our findings
suggest that LLM tutoring generally improves convergence, and its effectiveness
is sensitive to the specific task, RL algorithm, and LLM model combination.
\\ ( https://arxiv.org/abs/2509.08329 ,  1641kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08342 (*cross-listing*)
Date: Wed, 10 Sep 2025 07:28:24 GMT   (363kb)

Title: Accelerating Mixture-of-Expert Inference with Adaptive Expert Split
  Mechanism
Authors: Jiaming Yan, Jianchun Liu, Hongli Xu, Liusheng Huang
Categories: cs.LG cs.AI
\\
  Mixture-of-Experts (MoE) has emerged as a promising architecture for modern
large language models (LLMs). However, massive parameters impose heavy GPU
memory (i.e., VRAM) demands, hindering the widespread adoption of MoE LLMs.
Offloading the expert parameters to CPU RAM offers an effective way to
alleviate the VRAM requirements for MoE inference. Existing approaches
typically cache a small subset of experts in VRAM and dynamically prefetch
experts from RAM during inference, leading to significant degradation in
inference speed due to the poor cache hit rate and substantial expert loading
latency. In this work, we propose MoEpic, an efficient MoE inference system
with a novel expert split mechanism. Specifically, each expert is vertically
divided into two segments: top and bottom. MoEpic caches the top segment of hot
experts, so that more experts will be stored under the limited VRAM budget,
thereby improving the cache hit rate. During each layer's inference, MoEpic
predicts and prefetches the activated experts for the next layer. Since the top
segments of cached experts are exempt from fetching, the loading time is
reduced, which allows efficient transfer-computation overlap. Nevertheless, the
performance of MoEpic critically depends on the cache configuration (i.e., each
layer's VRAM budget and expert split ratio). To this end, we propose a
divide-and-conquer algorithm based on fixed-point iteration for adaptive cache
configuration. Extensive experiments on popular MoE LLMs demonstrate that
MoEpic can save about half of the GPU cost, while lowering the inference
latency by about 37.51%-65.73% compared to the baselines.
\\ ( https://arxiv.org/abs/2509.08342 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08354 (*cross-listing*)
Date: Wed, 10 Sep 2025 07:44:12 GMT   (10662kb)

Title: Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from
  Human Proprioceptive Sensorimotor Integration
Authors: Ce Guo, Xieyuanli Chen, Zhiwen Zeng, Zirui Guo, Yihong Li, Haoran
  Xiao, Dewen Hu, Huimin Lu
Categories: cs.RO cs.AI
Comments: 20 pages, 19 figures, accepted by IEEE Transactions on Robotics
\\
  Tactile and kinesthetic perceptions are crucial for human dexterous
manipulation, enabling reliable grasping of objects via proprioceptive
sensorimotor integration. For robotic hands, even though acquiring such tactile
and kinesthetic feedback is feasible, establishing a direct mapping from this
sensory feedback to motor actions remains challenging. In this paper, we
propose a novel glove-mediated tactile-kinematic perception-prediction
framework for grasp skill transfer from human intuitive and natural operation
to robotic execution based on imitation learning, and its effectiveness is
validated through generalized grasping tasks, including those involving
deformable objects. Firstly, we integrate a data glove to capture tactile and
kinesthetic data at the joint level. The glove is adaptable for both human and
robotic hands, allowing data collection from natural human hand demonstrations
across different scenarios. It ensures consistency in the raw data format,
enabling evaluation of grasping for both human and robotic hands. Secondly, we
establish a unified representation of multi-modal inputs based on graph
structures with polar coordinates. We explicitly integrate the morphological
differences into the designed representation, enhancing the compatibility
across different demonstrators and robotic hands. Furthermore, we introduce the
Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage
multidimensional subgraph convolutions and attention-based LSTM layers to
extract spatio-temporal features from graph inputs to predict node-based states
for each hand joint. These predictions are then mapped to final commands
through a force-position hybrid mapping.
\\ ( https://arxiv.org/abs/2509.08354 ,  10662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08383 (*cross-listing*)
Date: Wed, 10 Sep 2025 08:23:14 GMT   (1513kb)

Title: Efficient Decoding Methods for Language Models on Encrypted Data
Authors: Matan Avitan, Moran Baruch, Nir Drucker, Itamar Zimerman, Yoav
  Goldberg
Categories: cs.LG cs.AI cs.CR
\\
  Large language models (LLMs) power modern AI applications, but processing
sensitive data on untrusted servers raises privacy concerns. Homomorphic
encryption (HE) enables computation on encrypted data for secure inference.
However, neural text generation requires decoding methods like argmax and
sampling, which are non-polynomial and thus computationally expensive under
encryption, creating a significant performance bottleneck. We introduce cutmax,
an HE-friendly argmax algorithm that reduces ciphertext operations compared to
prior methods, enabling practical greedy decoding under encryption. We also
propose the first HE-compatible nucleus (top-p) sampling method, leveraging
cutmax for efficient stochastic decoding with provable privacy guarantees. Both
techniques are polynomial, supporting efficient inference in privacy-preserving
settings. Moreover, their differentiability facilitates gradient-based
sequence-level optimization as a polynomial alternative to straight-through
estimators. We further provide strong theoretical guarantees for cutmax,
proving it converges globally to a unique two-level fixed point, independent of
the input values beyond the identity of the maximizer, which explains its rapid
convergence in just a few iterations. Evaluations on realistic LLM outputs show
latency reductions of 24x-35x over baselines, advancing secure text generation.
\\ ( https://arxiv.org/abs/2509.08383 ,  1513kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08407 (*cross-listing*)
Date: Wed, 10 Sep 2025 08:54:16 GMT   (1876kb)

Title: An Iterative LLM Framework for SIBT utilizing RAG-based Adaptive Weight
  Optimization
Authors: Zhuo Xiao (1), Qinglong Yao (1), Jingjing Wang (1), Fugen Zhou (1), Bo
  Liu (1), Haitao Sun (2), Zhe Ji (2), Yuliang Jiang (2), Junjie Wang (2),
  Qiuwen Wu (3) ((1) Image Processing Center, Beihang University, Beijing,
  China, (2) Department of Radiation Oncology, Peking University Third
  Hospital, Beijing, China, (3) Department of Radiation Oncology, Duke
  University Medical Center, Durham, USA)
Categories: physics.med-ph cs.AI
\\
  Seed implant brachytherapy (SIBT) is an effective cancer treatment modality;
however, clinical planning often relies on manual adjustment of objective
function weights, leading to inefficiencies and suboptimal results. This study
proposes an adaptive weight optimization framework for SIBT planning, driven by
large language models (LLMs). A locally deployed DeepSeek-R1 LLM is integrated
with an automatic planning algorithm in an iterative loop. Starting with fixed
weights, the LLM evaluates plan quality and recommends new weights in the next
iteration. This process continues until convergence criteria are met, after
which the LLM conducts a comprehensive evaluation to identify the optimal plan.
A clinical knowledge base, constructed and queried via retrieval-augmented
generation (RAG), enhances the model's domain-specific reasoning. The proposed
method was validated on 23 patient cases, showing that the LLM-assisted
approach produces plans that are comparable to or exceeding clinically approved
and fixed-weight plans, in terms of dose homogeneity for the clinical target
volume (CTV) and sparing of organs at risk (OARs). The study demonstrates the
potential use of LLMs in SIBT planning automation.
\\ ( https://arxiv.org/abs/2509.08407 ,  1876kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08449 (*cross-listing*)
Date: Wed, 10 Sep 2025 09:47:51 GMT   (5341kb)

Title: DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via
  Group-Based Secure Aggregation
Authors: Charuka Herath, Yogachandran Rahulamathavan, Varuna De Silva, and
  Sangarapillai Lambotharan
Categories: cs.CR cs.AI cs.DC
\\
  Federated Learning (FL) enables decentralized model training without sharing
raw data, offering strong privacy guarantees. However, existing FL protocols
struggle to defend against Byzantine participants, maintain model utility under
non-independent and identically distributed (non-IID) data, and remain
lightweight for edge devices. Prior work either assumes trusted hardware, uses
expensive cryptographic tools, or fails to address privacy and robustness
simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated
Learning framework that addresses these limitations using a group-based secure
aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest
servers, DSFL removes this dependency by revealing a key vulnerability: privacy
leakage through client-server collusion. DSFL introduces three key innovations:
(1) a dual-server secure aggregation protocol that protects updates without
encryption or key exchange, (2) a group-wise credit-based filtering mechanism
to isolate Byzantine clients based on deviation scores, and (3) a dynamic
reward-penalty system for enforcing fair participation. DSFL is evaluated on
MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in
both IID and non-IID settings. It consistently outperforms existing baselines,
including LSFL, homomorphic encryption methods, and differential privacy
approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and
68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar
threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB
communication per round.
\\ ( https://arxiv.org/abs/2509.08449 ,  5341kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08461 (*cross-listing*)
Date: Wed, 10 Sep 2025 10:07:27 GMT   (1278kb)

Title: Adapting Vision-Language Models for Neutrino Event Classification in
  High-Energy Physics
Authors: Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian,
  Pierre Baldi
Categories: cs.LG cs.AI cs.CV hep-ex
\\
  Recent advances in Large Language Models (LLMs) have demonstrated their
remarkable capacity to process and reason over structured and unstructured data
modalities beyond natural language. In this work, we explore the applications
of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa
3.2, to the task of identifying neutrino interactions in pixelated detector
data from high-energy physics (HEP) experiments. We benchmark this model
against a state-of-the-art convolutional neural network (CNN) architecture,
similar to those used in the NOvA and DUNE experiments, which have achieved
high efficiency and purity in classifying electron and muon neutrino events.
Our evaluation considers both the classification performance and
interpretability of the model predictions. We find that VLMs can outperform
CNNs, while also providing greater flexibility in integrating auxiliary textual
or semantic information and offering more interpretable, reasoning-based
predictions. This work highlights the potential of VLMs as a general-purpose
backbone for physics event classification, due to their high performance,
interpretability, and generalizability, which opens new avenues for integrating
multimodal reasoning in experimental neutrino physics.
\\ ( https://arxiv.org/abs/2509.08461 ,  1278kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08470 (*cross-listing*)
Date: Wed, 10 Sep 2025 10:18:56 GMT   (676kb)

Title: Joint Learning using Mixture-of-Expert-Based Representation for Enhanced
  Speech Generation and Robust Emotion Recognition
Authors: Jing-Tong Tzeng, Carlos Busso, Chi-Chun Lee
Categories: eess.AS cs.AI
\\
  Speech emotion recognition (SER) plays a critical role in building
emotion-aware speech systems, but its performance degrades significantly under
noisy conditions. Although speech enhancement (SE) can improve robustness, it
often introduces artifacts that obscure emotional cues and adds computational
overhead to the pipeline. Multi-task learning (MTL) offers an alternative by
jointly optimizing SE and SER tasks. However, conventional shared-backbone
models frequently suffer from gradient interference and representational
conflicts between tasks. To address these challenges, we propose the Sparse
Mixture-of-Experts Representation Integration Technique (Sparse MERIT), a
flexible MTL framework that applies frame-wise expert routing over
self-supervised speech representations. Sparse MERIT incorporates task-specific
gating networks that dynamically select from a shared pool of experts for each
frame, enabling parameter-efficient and task-adaptive representation learning.
Experiments on the MSP-Podcast corpus show that Sparse MERIT consistently
outperforms baseline models on both SER and SE tasks. Under the most
challenging condition of -5 dB signal-to-noise ratio (SNR), Sparse MERIT
improves SER F1-macro by an average of 12.0% over a baseline relying on a SE
pre-processing strategy, and by 3.4% over a naive MTL baseline, with
statistical significance on unseen noise conditions. For SE, Sparse MERIT
improves segmental SNR (SSNR) by 28.2% over the SE pre-processing baseline and
by 20.0% over the naive MTL baseline. These results demonstrate that Sparse
MERIT provides robust and generalizable performance for both emotion
recognition and enhancement tasks in noisy environments.
\\ ( https://arxiv.org/abs/2509.08470 ,  676kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08493 (*cross-listing*)
Date: Wed, 10 Sep 2025 11:08:52 GMT   (1946kb)

Title: Send to which account? Evaluation of an LLM-based Scambaiting System
Authors: Hossein Siadati, Haadi Jafarian, Sima Jafarikhah
Categories: cs.CR cs.AI
ACM-class: K.6.5; I.2.7
\\
  Scammers are increasingly harnessing generative AI(GenAI) technologies to
produce convincing phishing content at scale, amplifying financial fraud and
undermining public trust. While conventional defenses, such as detection
algorithms, user training, and reactive takedown efforts remain important, they
often fall short in dismantling the infrastructure scammers depend on,
including mule bank accounts and cryptocurrency wallets. To bridge this gap, a
proactive and emerging strategy involves using conversational honeypots to
engage scammers and extract actionable threat intelligence. This paper presents
the first large-scale, real-world evaluation of a scambaiting system powered by
large language models (LLMs). Over a five-month deployment, the system
initiated over 2,600 engagements with actual scammers, resulting in a dataset
of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR)
of approximately 32%, successfully extracting sensitive financial information
such as mule accounts. Additionally, the system maintained a Human Acceptance
Rate (HAR) of around 70%, indicating strong alignment between LLM-generated
responses and human operator preferences. Alongside these successes, our
analysis reveals key operational challenges. In particular, the system
struggled with engagement takeoff: only 48.7% of scammers responded to the
initial seed message sent by defenders. These findings highlight the need for
further refinement and provide actionable insights for advancing the design of
automated scambaiting systems.
\\ ( https://arxiv.org/abs/2509.08493 ,  1946kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08494 (*cross-listing*)
Date: Wed, 10 Sep 2025 11:10:10 GMT   (461kb)

Title: HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI
  Assistants
Authors: Benjamin Sturgeon, Daniel Samuelson, Jacob Haimes, Jacy Reese Anthis
Categories: cs.CY cs.AI cs.CL cs.HC cs.LG
\\
  As humans delegate more tasks and decisions to artificial intelligence (AI),
we risk losing control of our individual and collective futures. Relatively
simple algorithmic systems already steer human decision-making, such as social
media feed algorithms that lead people to unintentionally and absent-mindedly
scroll through engagement-optimized content. In this paper, we develop the idea
of human agency by integrating philosophical and scientific theories of agency
with AI-assisted evaluation methods: using large language models (LLMs) to
simulate and validate user queries and to evaluate AI responses. We develop
HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions
of human agency based on typical AI use cases. HAB measures the tendency of an
AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation,
Correct Misinformation, Defer Important Decisions, Encourage Learning, and
Maintain Social Boundaries. We find low-to-moderate agency support in
contemporary LLM-based assistants and substantial variation across system
developers and dimensions. For example, while Anthropic LLMs most support human
agency overall, they are the least supportive LLMs in terms of Avoid Value
Manipulation. Agency support does not appear to consistently result from
increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and
we encourage a shift towards more robust safety and alignment targets.
\\ ( https://arxiv.org/abs/2509.08494 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08515 (*cross-listing*)
Date: Wed, 10 Sep 2025 11:45:40 GMT   (3650kb)

Title: Variational Rank Reduction Autoencoders for Generative
Authors: Alicia Tierz, Jad Mounayer, Beatriz Moya and Francisco Chinesta
Categories: cs.LG cs.AI
\\
  Generative thermal design for complex geometries is fundamental in many areas
of engineering, yet it faces two main challenges: the high computational cost
of high-fidelity simulations and the limitations of conventional generative
models. Approaches such as autoencoders (AEs) and variational autoencoders
(VAEs) often produce unstructured latent spaces with discontinuities, which
restricts their capacity to explore designs and generate physically consistent
solutions.
  To address these limitations, we propose a hybrid framework that combines
Variational Rank-Reduction Autoencoders (VRRAEs) with Deep Operator Networks
(DeepONets). The VRRAE introduces a truncated SVD within the latent space,
leading to continuous, interpretable, and well-structured representations that
mitigate posterior collapse and improve geometric reconstruction. The DeepONet
then exploits this compact latent encoding in its branch network, together with
spatial coordinates in the trunk network, to predict temperature gradients
efficiently and accurately.
  This hybrid approach not only enhances the quality of generated geometries
and the accuracy of gradient prediction, but also provides a substantial
advantage in inference efficiency compared to traditional numerical solvers.
Overall, the study underscores the importance of structured latent
representations for operator learning and highlights the potential of combining
generative models and operator networks in thermal design and broader
engineering applications.
\\ ( https://arxiv.org/abs/2509.08515 ,  3650kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08521 (*cross-listing*)
Date: Wed, 10 Sep 2025 11:57:56 GMT   (5997kb)

Title: FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast
  Marching Tree for Dynamic Replanning
Authors: Soheil Espahbodini Nia
Categories: cs.RO cs.AI cs.SY eess.SY
Comments: 35 pages, 8 figures, 2 tables, submitted to the International Journal
  of Robotics Research (IJRR)
ACM-class: I.2.9; I.2.8
\\
  Path planning in dynamic environments remains a core challenge in robotics,
especially as autonomous systems are deployed in unpredictable spaces such as
warehouses and public roads. While algorithms like Fast Marching Tree
(FMT$^{*}$) offer asymptotically optimal solutions in static settings, their
single-pass design prevents path revisions which are essential for real-time
adaptation. On the other hand, full replanning is often too computationally
expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching
Tree algorithm that enables efficient and consistent replanning in dynamic
environments. We revisit the neighbor selection rule of FMT$^{*}$ and
demonstrate that a minimal change overcomes its single-pass limitation,
enabling the algorithm to update cost-to-come values upon discovering better
connections without sacrificing asymptotic optimality or computational
efficiency. By maintaining a cost-ordered priority queue and applying a
selective update condition that uses an expanding neighbor to identify and
trigger the re-evaluation of any node with a potentially suboptimal path,
FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the
environment evolves. This targeted strategy preserves the inherent efficiency
of FMT$^{*}$ while enabling robust adaptation to changes in obstacle
configuration. FMT$^{x}$ is proven to recover an asymptotically optimal
solution after environmental changes. Experimental results demonstrate that
FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more
swiftly to dynamic events with lower computational overhead and thus offering a
more effective solution for real-time robotic navigation in unpredictable
worlds.
\\ ( https://arxiv.org/abs/2509.08521 ,  5997kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08524 (*cross-listing*)
Date: Wed, 10 Sep 2025 12:08:59 GMT   (20kb)

Title: AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution
Authors: Felix M\"achtle, Nils Loose, Jan-Niclas Serr, Jonas Sander, Thomas
  Eisenbarth
Categories: cs.SE cs.AI cs.CR
Comments: 2025 HUMIES finalist
Journal-ref: 18th ACM/IEEE International Workshop on Search-Based and Fuzz
  Testing, SBFT 2025
\\
  Symbolic execution is a powerful technique for software testing, but suffers
from limitations when encountering external functions, such as native methods
or third-party libraries. Existing solutions often require additional context,
expensive SMT solvers, or manual intervention to approximate these functions
through symbolic stubs. In this work, we propose a novel approach to
automatically generate symbolic stubs for external functions during symbolic
execution that leverages Genetic Programming. When the symbolic executor
encounters an external function, AutoStub generates training data by executing
the function on randomly generated inputs and collecting the outputs. Genetic
Programming then derives expressions that approximate the behavior of the
function, serving as symbolic stubs. These automatically generated stubs allow
the symbolic executor to continue the analysis without manual intervention,
enabling the exploration of program paths that were previously intractable. We
demonstrate that AutoStub can automatically approximate external functions with
over 90% accuracy for 55% of the functions evaluated, and can infer
language-specific behaviors that reveal edge cases crucial for software
testing.
\\ ( https://arxiv.org/abs/2509.08524 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08535 (*cross-listing*)
Date: Wed, 10 Sep 2025 12:25:13 GMT   (5604kb)

Title: Agents of Discovery
Authors: Sascha Diefenbacher, Anna Hallin, Gregor Kasieczka, Michael Kr\"amer,
  Anne Lauscher, Tim Lukas
Categories: hep-ph cs.AI cs.LG hep-ex physics.data-an
\\
  The substantial data volumes encountered in modern particle physics and other
domains of fundamental physics research allow (and require) the use of
increasingly complex data analysis tools and workflows. While the use of
machine learning (ML) tools for data analysis has recently proliferated, these
tools are typically special-purpose algorithms that rely, for example, on
encoded physics knowledge to reach optimal performance. In this work, we
investigate a new and orthogonal direction: Using recent progress in large
language models (LLMs) to create a team of agents -- instances of LLMs with
specific subtasks -- that jointly solve data analysis-based research problems
in a way similar to how a human researcher might: by creating code to operate
standard tools and libraries (including ML systems) and by building on results
of previous iterations. If successful, such agent-based systems could be
deployed to automate routine analysis components to counteract the increasing
complexity of modern tool chains. To investigate the capabilities of
current-generation commercial LLMs, we consider the task of anomaly detection
via the publicly available and highly-studied LHC Olympics dataset. Several
current models by OpenAI (GPT-4o, o4-mini, GPT-4.1, and GPT-5) are investigated
and their stability tested. Overall, we observe the capacity of the agent-based
system to solve this data analysis problem. The best agent-created solutions
mirror the performance of human state-of-the-art results.
\\ ( https://arxiv.org/abs/2509.08535 ,  5604kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08592 (*cross-listing*)
Date: Wed, 10 Sep 2025 13:45:59 GMT   (309kb)

Title: Interpretability as Alignment: Making Internal Understanding a Design
  Principle
Authors: Aadit Sengupta, Pratinav Seth, Vinay Kumar Sankarapu
Categories: cs.LG cs.AI cs.ET
Comments: Pre-Print
\\
  Large neural models are increasingly deployed in high-stakes settings,
raising concerns about whether their behavior reliably aligns with human
values. Interpretability provides a route to internal transparency by revealing
the computations that drive outputs. We argue that interpretability especially
mechanistic approaches should be treated as a design principle for alignment,
not an auxiliary diagnostic tool. Post-hoc methods such as LIME or SHAP offer
intuitive but correlational explanations, while mechanistic techniques like
circuit tracing or activation patching yield causal insight into internal
failures, including deceptive or misaligned reasoning that behavioral methods
like RLHF, red teaming, or Constitutional AI may overlook. Despite these
advantages, interpretability faces challenges of scalability, epistemic
uncertainty, and mismatches between learned representations and human concepts.
Our position is that progress on safe and trustworthy AI will depend on making
interpretability a first-class objective of AI research and development,
ensuring that systems are not only effective but also auditable, transparent,
and aligned with human intent.
\\ ( https://arxiv.org/abs/2509.08592 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08606 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:04:51 GMT   (1993kb)

Title: Classification of 24-hour movement behaviors from wrist-worn
  accelerometer data: from handcrafted features to deep learning techniques
Authors: Alireza Sameh, Mehrdad Rostami, Mourad Oussalah, Vahid Farrahi
Categories: cs.LG cs.AI
\\
  Purpose: We compared the performance of deep learning (DL) and classical
machine learning (ML) algorithms for the classification of 24-hour movement
behavior into sleep, sedentary, light intensity physical activity (LPA), and
moderate-to-vigorous intensity physical activity (MVPA). Methods: Open-access
data from 151 adults wearing a wrist-worn accelerometer (Axivity-AX3) was used.
Participants were randomly divided into training, validation, and test sets
(121, 15, and 15 participants each). Raw acceleration signals were segmented
into non-overlapping 10-second windows, and then a total of 104 handcrafted
features were extracted. Four DL algorithms-Long Short-Term Memory (LSTM),
Bidirectional Long Short-Term Memory (BiLSTM), Gated Recurrent Units (GRU), and
One-Dimensional Convolutional Neural Network (1D-CNN)-were trained using raw
acceleration signals and with handcrafted features extracted from these signals
to predict 24-hour movement behavior categories. The handcrafted features were
also used to train classical ML algorithms, namely Random Forest (RF), Support
Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), Logistic Regression
(LR), Artificial Neural Network (ANN), and Decision Tree (DT) for classifying
24-hour movement behavior intensities. Results: LSTM, BiLSTM, and GRU showed an
overall accuracy of approximately 85% when trained with raw acceleration
signals, and 1D-CNN an overall accuracy of approximately 80%. When trained on
handcrafted features, the overall accuracy for both DL and classical ML
algorithms ranged from 70% to 81%. Overall, there was a higher confusion in
classification of MVPA and LPA, compared to sleep and sedentary categories.
Conclusion: DL methods with raw acceleration signals had only slightly better
performance in predicting 24-hour movement behavior intensities, compared to
when DL and classical ML were trained with handcrafted features.
\\ ( https://arxiv.org/abs/2509.08606 ,  1993kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08640 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:35:24 GMT   (4111kb)

Title: RoentMod: A Synthetic Chest X-Ray Modification Model to Identify and
  Correct Image Interpretation Model Shortcuts
Authors: Lauren H. Cooke, Matthias Jung, Jan M. Brendel, Nora M. Kerkovits,
  Borek Foldyna, Michael T. Lu, Vineet K. Raghu
Categories: eess.IV cs.AI cs.CV
Comments: 25 + 8 pages, 4 + 7 figures
MSC-class: I.4, I.2, J.3
\\
  Chest radiographs (CXRs) are among the most common tests in medicine.
Automated image interpretation may reduce radiologists\' workload and expand
access to diagnostic expertise. Deep learning multi-task and foundation models
have shown strong performance for CXR interpretation but are vulnerable to
shortcut learning, where models rely on spurious and off-target correlations
rather than clinically relevant features to make decisions. We introduce
RoentMod, a counterfactual image editing framework that generates anatomically
realistic CXRs with user-specified, synthetic pathology while preserving
unrelated anatomical features of the original scan. RoentMod combines an
open-source medical image generator (RoentGen) with an image-to-image
modification model without requiring retraining. In reader studies with
board-certified radiologists and radiology residents, RoentMod-produced images
appeared realistic in 93\% of cases, correctly incorporated the specified
finding in 89-99\% of cases, and preserved native anatomy comparable to real
follow-up CXRs. Using RoentMod, we demonstrate that state-of-the-art multi-task
and foundation models frequently exploit off-target pathology as shortcuts,
limiting their specificity. Incorporating RoentMod-generated counterfactual
images during training mitigated this vulnerability, improving model
discrimination across multiple pathologies by 3-19\% AUC in internal validation
and by 1-11\% for 5 out of 6 tested pathologies in external testing. These
findings establish RoentMod as a broadly applicable tool for probing and
correcting shortcut learning in medical AI. By enabling controlled
counterfactual interventions, RoentMod enhances the robustness and
interpretability of CXR interpretation models and provides a generalizable
strategy for improving foundation models in medical imaging.
\\ ( https://arxiv.org/abs/2509.08640 ,  4111kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08646 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:41:07 GMT   (226kb)

Title: Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute
  Implementations
Authors: Ron F. Del Rosario, Klaudia Krawiecka, Christian Schroeder de Witt
Categories: cs.CR cs.AI cs.SY eess.SY
\\
  As Large Language Model (LLM) agents become increasingly capable of
automating complex, multi-step tasks, the need for robust, secure, and
predictable architectural patterns is paramount. This paper provides a
comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic
design that separates strategic planning from tactical execution. We explore
the foundational principles of P-t-E, detailing its core components - the
Planner and the Executor - and its architectural advantages in predictability,
cost-efficiency, and reasoning quality over reactive patterns like ReAct
(Reason + Act). A central focus is placed on the security implications of this
design, particularly its inherent resilience to indirect prompt injection
attacks by establishing control-flow integrity. We argue that while P-t-E
provides a strong foundation, a defense-in-depth strategy is necessary, and we
detail essential complementary controls such as the Principle of Least
Privilege, task-scoped tool access, and sandboxed code execution. To make these
principles actionable, this guide provides detailed implementation blueprints
and working code references for three leading agentic frameworks: LangChain
(via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing
the P-t-E pattern is analyzed, highlighting unique features like LangGraph's
stateful graphs for re-planning, CrewAI's declarative tool scoping for
security, and AutoGen's built-in Docker sandboxing. Finally, we discuss
advanced patterns, including dynamic re-planning loops, parallel execution with
Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop
(HITL) verification, to offer a complete strategic blueprint for architects,
developers, and security engineers aiming to build production-grade, resilient,
and trustworthy LLM agents.
\\ ( https://arxiv.org/abs/2509.08646 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08654 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:50:03 GMT   (889kb)

Title: Robust Belief-State Policy Learning for Quantum Network Routing Under
  Decoherence and Time-Varying Conditions
Authors: Amirhossein Taherpour, Abbas Taherpour, and Tamer Khattab
Categories: quant-ph cs.AI cs.LG cs.NI
\\
  This paper presents a feature-based Partially Observable Markov Decision
Process (POMDP) framework for quantum network routing, combining belief-state
planning with Graph Neural Networks (GNNs) to address partial observability,
decoherence, and scalability challenges in dynamic quantum systems. Our
approach encodes complex quantum network dynamics, including entanglement
degradation and time-varying channel noise, into a low-dimensional feature
space, enabling efficient belief updates and scalable policy learning. The core
of our framework is a hybrid GNN-POMDP architecture that processes
graph-structured representations of entangled links to learn routing policies,
coupled with a noise-adaptive mechanism that fuses POMDP belief updates with
GNN outputs for robust decision making. We provide a theoretical analysis
establishing guarantees for belief convergence, policy improvement, and
robustness to noise. Experiments on simulated quantum networks with up to 100
nodes demonstrate significant improvements in routing fidelity and entanglement
delivery rates compared to state-of-the-art baselines, particularly under high
decoherence and nonstationary conditions.
\\ ( https://arxiv.org/abs/2509.08654 ,  889kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08697 (*cross-listing*)
Date: Fri, 29 Aug 2025 10:23:03 GMT   (3815kb)

Title: Reshaping the Forward-Forward Algorithm with a Similarity-Based
  Objective
Authors: James Gong, Raymond Luo, Emma Wang, Leon Ge, Bruce Li, Felix
  Marattukalam, Waleed Abdulla
Categories: cs.LG cs.AI
Comments: 6 pages
\\
  Backpropagation is the pivotal algorithm underpinning the success of
artificial neural networks, yet it has critical limitations such as
biologically implausible backward locking and global error propagation. To
circumvent these constraints, the Forward-Forward algorithm was proposed as a
more biologically plausible method that replaces the backward pass with an
additional forward pass. Despite this advantage, the Forward-Forward algorithm
significantly trails backpropagation in accuracy, and its optimal form exhibits
low inference efficiency due to multiple forward passes required. In this work,
the Forward-Forward algorithm is reshaped through its integration with
similarity learning frameworks, eliminating the need for multiple forward
passes during inference. This proposed algorithm is named Forward-Forward
Algorithm Unified with Similarity-based Tuplet loss (FAUST). Empirical
evaluations on MNIST, Fashion-MNIST, and CIFAR-10 datasets indicate that FAUST
substantially improves accuracy, narrowing the gap with backpropagation. On
CIFAR-10, FAUST achieves 56.22\% accuracy with a simple multi-layer perceptron
architecture, approaching the backpropagation benchmark of 57.63\% accuracy.
\\ ( https://arxiv.org/abs/2509.08697 ,  3815kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08698 (*cross-listing*)
Date: Fri, 29 Aug 2025 11:28:21 GMT   (1627kb)

Title: A layered architecture for log analysis in complex IT systems
Authors: Thorsten Wittkopp
Categories: cs.LG cs.AI
Comments: Dissertation
DOI: 10.14279/depositonce-22012
\\
  In the evolving IT landscape, stability and reliability of systems are
essential, yet their growing complexity challenges DevOps teams in
implementation and maintenance. Log analysis, a core element of AIOps, provides
critical insights into complex behaviors and failures. This dissertation
introduces a three-layered architecture to support DevOps in failure
resolution. The first layer, Log Investigation, performs autonomous log
labeling and anomaly classification. We propose a method that labels log data
without manual effort, enabling supervised training and precise evaluation of
anomaly detection. Additionally, we define a taxonomy that groups anomalies
into three categories, ensuring appropriate method selection. The second layer,
Anomaly Detection, detects behaviors deviating from the norm. We propose a
flexible Anomaly Detection method adaptable to unsupervised, weakly supervised,
and supervised training. Evaluations on public and industry datasets show
F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third
layer, Root Cause Analysis, identifies minimal log sets describing failures,
their origin, and event sequences. By balancing training data and identifying
key services, our Root Cause Analysis method consistently detects 90-98% of
root cause log lines within the top 10 candidates, providing actionable
insights for mitigation. Our research addresses how log analysis methods can be
designed and optimized to help DevOps resolve failures efficiently. By
integrating these three layers, the architecture equips teams with robust
methods to enhance IT system reliability.
\\ ( https://arxiv.org/abs/2509.08698 ,  1627kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08699 (*cross-listing*)
Date: Wed, 10 Sep 2025 15:43:32 GMT   (1623kb)

Title: TANGO: Traversability-Aware Navigation with Local Metric Control for
  Topological Goals
Authors: Stefan Podgorski, Sourav Garg, Mehdi Hosseinzadeh, Lachlan Mares,
  Feras Dayoub, Ian Reid
Categories: cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY
Comments: 9 pages, 5 figures, ICRA 2025
DOI: 10.1109/ICRA55743.2025.11127998
\\
  Visual navigation in robotics traditionally relies on globally-consistent 3D
maps or learned controllers, which can be computationally expensive and
difficult to generalize across diverse environments. In this work, we present a
novel RGB-only, object-level topometric navigation pipeline that enables
zero-shot, long-horizon robot navigation without requiring 3D maps or
pre-trained controllers. Our approach integrates global topological path
planning with local metric trajectory control, allowing the robot to navigate
towards object-level sub-goals while avoiding obstacles. We address key
limitations of previous methods by continuously predicting local trajectory
using monocular depth and traversability estimation, and incorporating an
auto-switching mechanism that falls back to a baseline controller when
necessary. The system operates using foundational models, ensuring open-set
applicability without the need for domain-specific fine-tuning. We demonstrate
the effectiveness of our method in both simulated environments and real-world
tests, highlighting its robustness and deployability. Our approach outperforms
existing state-of-the-art methods, offering a more adaptable and effective
solution for visual navigation in open-set environments. The source code is
made publicly available: https://github.com/podgorki/TANGO.
\\ ( https://arxiv.org/abs/2509.08699 ,  1623kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08717 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:11:01 GMT   (16751kb)

Title: Explainability of CNN Based Classification Models for Acoustic Signal
Authors: Zubair Faruqui, Mackenzie S. McIntire, Rahul Dubey, Jay McEntee
Categories: cs.SD cs.AI cs.LG
Comments: Accepted in IEEE ICTAI 2025
\\
  Explainable Artificial Intelligence (XAI) has emerged as a critical tool for
interpreting the predictions of complex deep learning models. While XAI has
been increasingly applied in various domains within acoustics, its use in
bioacoustics, which involves analyzing audio signals from living organisms,
remains relatively underexplored. In this paper, we investigate the
vocalizations of a bird species with strong geographic variation throughout its
range in North America. Audio recordings were converted into spectrogram images
and used to train a deep Convolutional Neural Network (CNN) for classification,
achieving an accuracy of 94.8\%. To interpret the model's predictions, we
applied both model-agnostic (LIME, SHAP) and model-specific (DeepLIFT,
Grad-CAM) XAI techniques. These techniques produced different but complementary
explanations, and when their explanations were considered together, they
provided more complete and interpretable insights into the model's
decision-making. This work highlights the importance of using a combination of
XAI techniques to improve trust and interoperability, not only in broader
acoustics signal analysis but also argues for broader applicability in
different domain specific tasks.
\\ ( https://arxiv.org/abs/2509.08717 ,  16751kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08734 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:23:52 GMT   (1123kb)

Title: DEQuify your force field: More efficient simulations using deep
  equilibrium models
Authors: Andreas Burger, Luca Thiede, Al\'an Aspuru-Guzik, Nandita Vijaykumar
Categories: cs.LG cs.AI
Comments: AI4MAT-ICLR-2025 Spotlight https://openreview.net/forum?id=XACVRYePQQ
\\
  Machine learning force fields show great promise in enabling more accurate
molecular dynamics simulations compared to manually derived ones. Much of the
progress in recent years was driven by exploiting prior knowledge about
physical systems, in particular symmetries under rotation, translation, and
reflections. In this paper, we argue that there is another important piece of
prior information that, thus fa,r hasn't been explored: Simulating a molecular
system is necessarily continuous, and successive states are therefore extremely
similar. Our contribution is to show that we can exploit this information by
recasting a state-of-the-art equivariant base model as a deep equilibrium
model. This allows us to recycle intermediate neural network features from
previous time steps, enabling us to improve both accuracy and speed by
$10\%-20\%$ on the MD17, MD22, and OC20 200k datasets, compared to the non-DEQ
base model. The training is also much more memory efficient, allowing us to
train more expressive models on larger systems.
\\ ( https://arxiv.org/abs/2509.08734 ,  1123kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08742 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:32:41 GMT   (1152kb)

Title: FinZero: Launching Multi-modal Financial Time Series Forecast with Large
  Reasoning Model
Authors: Yanlong Wang, Jian Xu, Fei Ma, Hongkang Zhang, Hang Yu, Tiantian Gao,
  Yu Wang, Haochen You, Shao-Lun Huang, Danny Dongning Sun, Xiao-Ping Zhang
Categories: q-fin.CP cs.AI
\\
  Financial time series forecasting is both highly significant and challenging.
Previous approaches typically standardized time series data before feeding it
into forecasting models, but this encoding process inherently leads to a loss
of important information. Moreover, past time series models generally require
fixed numbers of variables or lookback window lengths, which further limits the
scalability of time series forecasting. Besides, the interpretability and the
uncertainty in forecasting remain areas requiring further research, as these
factors directly impact the reliability and practical value of predictions. To
address these issues, we first construct a diverse financial image-text dataset
(FVLDB) and develop the Uncertainty-adjusted Group Relative Policy Optimization
(UARPO) method to enable the model not only output predictions but also analyze
the uncertainty of those predictions. We then proposed FinZero, a multimodal
pre-trained model finetuned by UARPO to perform reasoning, prediction, and
analytical understanding on the FVLDB financial time series. Extensive
experiments validate that FinZero exhibits strong adaptability and scalability.
After fine-tuning with UARPO, FinZero achieves an approximate 13.48\%
improvement in prediction accuracy over GPT-4o in the high-confidence group,
demonstrating the effectiveness of reinforcement learning fine-tuning in
multimodal large model, including in financial time series forecasting tasks.
\\ ( https://arxiv.org/abs/2509.08742 ,  1152kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08752 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:42:22 GMT   (31703kb)

Title: Learning Turbulent Flows with Generative Models: Super-resolution,
  Forecasting, and Sparse Flow Reconstruction
Authors: Vivek Oommen, Siavash Khodakarami, Aniruddha Bora, Zhicheng Wang,
  George Em Karniadakis
Categories: physics.flu-dyn cs.AI cs.LG
\\
  Neural operators are promising surrogates for dynamical systems but when
trained with standard L2 losses they tend to oversmooth fine-scale turbulent
structures. Here, we show that combining operator learning with generative
modeling overcomes this limitation. We consider three practical turbulent-flow
challenges where conventional neural operators fail: spatio-temporal
super-resolution, forecasting, and sparse flow reconstruction. For Schlieren
jet super-resolution, an adversarially trained neural operator (adv-NO) reduces
the energy-spectrum error by 15x while preserving sharp gradients at neural
operator-like inference cost. For 3D homogeneous isotropic turbulence, adv-NO
trained on only 160 timesteps from a single trajectory forecasts accurately for
five eddy-turnover times and offers 114x wall-clock speed-up at inference than
the baseline diffusion-based forecasters, enabling near-real-time rollouts. For
reconstructing cylinder wake flows from highly sparse Particle Tracking
Velocimetry-like inputs, a conditional generative model infers full 3D velocity
and pressure fields with correct phase alignment and statistics. These advances
enable accurate reconstruction and forecasting at low compute cost, bringing
near-real-time analysis and control within reach in experimental and
computational fluid mechanics. See our project page:
https://vivekoommen.github.io/Gen4Turb/
\\ ( https://arxiv.org/abs/2509.08752 ,  31703kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08755 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:46:11 GMT   (8852kb)

Title: AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making
  through Multi-Turn Reinforcement Learning
Authors: Zhiheng Xi, Jixuan Huang, Chenyang Liao, Baodai Huang, Honglin Guo,
  Jiaqi Liu, Rui Zheng, Junjie Ye, Jiazheng Zhang, Wenxiang Chen, Wei He, Yiwen
  Ding, Guanyu Li, Zehui Chen, Zhengyin Du, Xuesong Yao, Yufei Xu, Jiecao Chen,
  Tao Gui, Zuxuan Wu, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang
Categories: cs.LG cs.AI cs.CL
Comments: preprint, 39 pages, 16 figures. Project:
  https://AgentGym-RL.github.io/. Framework and Code:
  https://github.com/woooodyy/AgentGym, https://github.com/woooodyy/AgentGym-RL
\\
  Developing autonomous LLM agents capable of making a series of intelligent
decisions to solve complex, real-world tasks is a fast-evolving frontier. Like
human cognitive development, agents are expected to acquire knowledge and
skills through exploration and interaction with the environment. Despite
advances, the community still lacks a unified, interactive reinforcement
learning (RL) framework that can effectively train such agents from scratch --
without relying on supervised fine-tuning (SFT) -- across diverse and realistic
environments. To bridge this gap, we introduce AgentGym-RL, a new framework to
train LLM agents for multi-turn interactive decision-making through RL. The
framework features a modular and decoupled architecture, ensuring high
flexibility and extensibility. It encompasses a wide variety of real-world
scenarios, and supports mainstream RL algorithms. Furthermore, we propose
ScalingInter-RL, a training approach designed for exploration-exploitation
balance and stable RL optimization. In early stages, it emphasizes exploitation
by restricting the number of interactions, and gradually shifts towards
exploration with larger horizons to encourage diverse problem-solving
strategies. In this way, the agent develops more diverse behaviors and is less
prone to collapse under long horizons. We perform extensive experiments to
validate the stability and effectiveness of both the AgentGym-RL framework and
the ScalingInter-RL approach. Our agents match or surpass commercial models on
27 tasks across diverse environments. We offer key insights and will
open-source the complete AgentGym-RL framework -- including code and datasets
-- to empower the research community in developing the next generation of
intelligent agents.
\\ ( https://arxiv.org/abs/2509.08755 ,  8852kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08756 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:46:54 GMT   (5643kb)

Title: Using AI to Optimize Patient Transfer and Resource Utilization During
  Mass-Casualty Incidents: A Simulation Platform
Authors: Zhaoxun "Lorenz" Liu, Wagner H. Souza, Jay Han, Amin Madani
Categories: cs.LG cs.AI cs.HC
\\
  Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid,
accurate patient-hospital allocation decisions under extreme pressure. Here, we
developed and validated a deep reinforcement learning-based decision-support AI
agent to optimize patient transfer decisions during simulated MCIs by balancing
patient acuity levels, specialized care requirements, hospital capacities, and
transport logistics. To integrate this AI agent, we developed MasTER, a
web-accessible command dashboard for MCI management simulations. Through a
controlled user study with 30 participants (6 trauma experts and 24
non-experts), we evaluated three interaction approaches with the AI agent
(human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI
scenarios in the Greater Toronto Area. Results demonstrate that increasing AI
involvement significantly improves decision quality and consistency. The AI
agent outperforms trauma surgeons (p < 0.001) and enables non-experts to
achieve expert-level performance when assisted, contrasting sharply with their
significantly inferior unassisted performance (p < 0.001). These findings
establish the potential for our AI-driven decision support to enhance both MCI
preparedness training and real-world emergency response management.
\\ ( https://arxiv.org/abs/2509.08756 ,  5643kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08800 (*cross-listing*)
Date: Wed, 10 Sep 2025 17:35:58 GMT   (2050kb)

Title: PianoVAM: A Multimodal Piano Performance Dataset
Authors: Yonghyun Kim, Junhyung Park, Joonhyung Bae, Kirak Kim, Taegyun Kwon,
  Alexander Lerch, Juhan Nam
Categories: cs.SD cs.AI cs.CV cs.MM eess.AS
Comments: Accepted to the 26th International Society for Music Information
  Retrieval (ISMIR) Conference, 2025
\\
  The multimodal nature of music performance has driven increasing interest in
data beyond the audio domain within the music information retrieval (MIR)
community. This paper introduces PianoVAM, a comprehensive piano performance
dataset that includes videos, audio, MIDI, hand landmarks, fingering labels,
and rich metadata. The dataset was recorded using a Disklavier piano, capturing
audio and MIDI from amateur pianists during their daily practice sessions,
alongside synchronized top-view videos in realistic and varied performance
conditions. Hand landmarks and fingering labels were extracted using a
pretrained hand pose estimation model and a semi-automated fingering annotation
algorithm. We discuss the challenges encountered during data collection and the
alignment process across different modalities. Additionally, we describe our
fingering annotation method based on hand landmarks extracted from videos.
Finally, we present benchmarking results for both audio-only and audio-visual
piano transcription using the PianoVAM dataset and discuss additional potential
applications.
\\ ( https://arxiv.org/abs/2509.08800 ,  2050kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08803 (*cross-listing*)
Date: Wed, 10 Sep 2025 17:36:25 GMT   (11248kb)

Title: Scaling Truth: The Confidence Paradox in AI Fact-Checking
Authors: Ihsan A. Qazi, Zohaib Khan, Abdullah Ghani, Agha A. Raza, Zafar A.
  Qazi, Wassay Sajjad, Ayesha Ali, Asher Javaid, Muhammad Abdullah Sohail,
  Abdul H. Azeemi
Categories: cs.SI cs.AI cs.CL cs.CY
Comments: 65 pages, 26 figures, 6 tables
\\
  The rise of misinformation underscores the need for scalable and reliable
fact-checking solutions. Large language models (LLMs) hold promise in
automating fact verification, yet their effectiveness across global contexts
remains uncertain. We systematically evaluate nine established LLMs across
multiple categories (open/closed-source, multiple sizes, diverse architectures,
reasoning-based) using 5,000 claims previously assessed by 174 professional
fact-checking organizations across 47 languages. Our methodology tests model
generalizability on claims postdating training cutoffs and four prompting
strategies mirroring both citizen and professional fact-checker interactions,
with over 240,000 human annotations as ground truth. Findings reveal a
concerning pattern resembling the Dunning-Kruger effect: smaller, accessible
models show high confidence despite lower accuracy, while larger models
demonstrate higher accuracy but lower confidence. This risks systemic bias in
information verification, as resource-constrained organizations typically use
smaller models. Performance gaps are most pronounced for non-English languages
and claims originating from the Global South, threatening to widen existing
information inequalities. These results establish a multilingual benchmark for
future research and provide an evidence base for policy aimed at ensuring
equitable access to trustworthy, AI-assisted fact-checking.
\\ ( https://arxiv.org/abs/2509.08803 ,  11248kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08814 (*cross-listing*)
Date: Wed, 10 Sep 2025 17:46:57 GMT   (672kb)

Title: Merge-of-Thought Distillation
Authors: Zhanming Shen, Zeyu Qin, Zenan Huang, Hao Chen, Jiaqi Hu, Yihong
  Zhuang, Guoshan Lu, Gang Chen, Junbo Zhao
Categories: cs.LG cs.AI cs.CL
\\
  Efficient reasoning distillation for long chain-of-thought (CoT) models is
increasingly constrained by the assumption of a single oracle teacher, despite
practical availability of multiple candidate teachers and growing CoT corpora.
We revisit teacher selection and observe that different students have different
"best teachers," and even for the same student the best teacher can vary across
datasets. Therefore, to unify multiple teachers' reasoning abilities into
student with overcoming conflicts among various teachers' supervision, we
propose Merge-of-Thought Distillation (MoT), a lightweight framework that
alternates between teacher-specific supervised fine-tuning branches and
weight-space merging of the resulting student variants. On competition math
benchmarks, using only about 200 high-quality CoT samples, applying MoT to a
Qwen3-14B student surpasses strong models including DEEPSEEK-R1, QWEN3-30B-A3B,
QWEN3-32B, and OPENAI-O1, demonstrating substantial gains. Besides, MoT
consistently outperforms the best single-teacher distillation and the naive
multi-teacher union, raises the performance ceiling while mitigating
overfitting, and shows robustness to distribution-shifted and peer-level
teachers. Moreover, MoT reduces catastrophic forgetting, improves general
reasoning beyond mathematics and even cultivates a better teacher, indicating
that consensus-filtered reasoning features transfer broadly. These results
position MoT as a simple, scalable route to efficiently distilling long CoT
capabilities from diverse teachers into compact students.
\\ ( https://arxiv.org/abs/2509.08814 ,  672kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08817 (*cross-listing*)
Date: Wed, 10 Sep 2025 17:49:06 GMT   (166kb)

Title: QCardEst/QCardCorr: Quantum Cardinality Estimation and Correction
Authors: Tobias Winker, Jinghua Groppe, Sven Groppe
Categories: quant-ph cs.AI cs.DB cs.LG
Comments: 7 pages
\\
  Cardinality estimation is an important part of query optimization in DBMS. We
develop a Quantum Cardinality Estimation (QCardEst) approach using Quantum
Machine Learning with a Hybrid Quantum-Classical Network. We define a compact
encoding for turning SQL queries into a quantum state, which requires only
qubits equal to the number of tables in the query. This allows the processing
of a complete query with a single variational quantum circuit (VQC) on current
hardware. In addition, we compare multiple classical post-processing layers to
turn the probability vector output of VQC into a cardinality value. We
introduce Quantum Cardinality Correction QCardCorr, which improves classical
cardinality estimators by multiplying the output with a factor generated by a
VQC to improve the cardinality estimation. With QCardCorr, we have an
improvement over the standard PostgreSQL optimizer of 6.37 times for JOB-light
and 8.66 times for STATS. For JOB-light we even outperform MSCN by a factor of
3.47.
\\ ( https://arxiv.org/abs/2509.08817 ,  166kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08315 (*cross-listing*)
Date: Wed, 10 Sep 2025 06:32:49 GMT   (2719kb)

Title: EvolKV: Evolutionary KV Cache Compression for LLM Inference
Authors: Bohan Yu, Yekun Chai
Categories: cs.LG cs.CL cs.NE
\\
  Existing key-value (KV) cache compression methods typically rely on
heuristics, such as uniform cache allocation across layers or static eviction
policies, however, they ignore the critical interplays among layer-specific
feature patterns and task performance, which can lead to degraded
generalization. In this paper, we propose EvolKV, an adaptive framework for
layer-wise, task-driven KV cache compression that jointly optimizes the memory
efficiency and task performance. By reformulating cache allocation as a
multi-objective optimization problem, EvolKV leverages evolutionary search to
dynamically configure layer budgets while directly maximizing downstream
performance. Extensive experiments on 11 tasks demonstrate that our approach
outperforms all baseline methods across a wide range of KV cache budgets on
long-context tasks and surpasses heuristic baselines by up to 7 percentage
points on GSM8K. Notably, EvolKV achieves superior performance over the full KV
cache setting on code completion while utilizing only 1.5% of the original
budget, suggesting the untapped potential in learned compression strategies for
KV cache budget allocation.
\\ ( https://arxiv.org/abs/2509.08315 ,  2719kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08653 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:49:12 GMT   (1304kb)

Title: Generative Data Refinement: Just Ask for Better Data
Authors: Minqi Jiang, Jo\~ao G. M. Ara\'ujo, Will Ellsworth, Sian Gooding,
  Edward Grefenstette
Categories: cs.LG cs.CL
\\
  For a fixed parameter size, the capabilities of large models are primarily
determined by the quality and quantity of its training data. Consequently,
training datasets now grow faster than the rate at which new data is indexed on
the web, leading to projected data exhaustion over the next decade. Much more
data exists as user-generated content that is not publicly indexed, but
incorporating such data comes with considerable risks, such as leaking private
information and other undesirable content. We introduce a framework, Generative
Data Refinement (GDR), for using pretrained generative models to transform a
dataset with undesirable content into a refined dataset that is more suitable
for training. Our experiments show that GDR can outperform industry-grade
solutions for dataset anonymization, as well as enable direct detoxification of
highly unsafe datasets. Moreover, we show that by generating synthetic data
that is conditioned on each example in the real dataset, GDR's refined outputs
naturally match the diversity of web scale datasets, and thereby avoid the
often challenging task of generating diverse synthetic data via model
prompting. The simplicity and effectiveness of GDR make it a powerful tool for
scaling up the total stock of training data for frontier models.
\\ ( https://arxiv.org/abs/2509.08653 ,  1304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07994 (*cross-listing*)
Date: Tue, 2 Sep 2025 18:48:37 GMT   (9534kb)

Title: STROKEVISION-BENCH: A Multimodal Video And 2D Pose Benchmark For
  Tracking Stroke Recovery
Authors: David Robinson, Animesh Gupta, Rizwan Quershi, Qiushi Fu, Mubarak Shah
Categories: eess.IV cs.CV cs.LG
Comments: 6 pages
\\
  Despite advancements in rehabilitation protocols, clinical assessment of
upper extremity (UE) function after stroke largely remains subjective, relying
heavily on therapist observation and coarse scoring systems. This subjectivity
limits the sensitivity of assessments to detect subtle motor improvements,
which are critical for personalized rehabilitation planning. Recent progress in
computer vision offers promising avenues for enabling objective, quantitative,
and scalable assessment of UE motor function. Among standardized tests, the Box
and Block Test (BBT) is widely utilized for measuring gross manual dexterity
and tracking stroke recovery, providing a structured setting that lends itself
well to computational analysis. However, existing datasets targeting stroke
rehabilitation primarily focus on daily living activities and often fail to
capture clinically structured assessments such as block transfer tasks.
Furthermore, many available datasets include a mixture of healthy and
stroke-affected individuals, limiting their specificity and clinical utility.
To address these critical gaps, we introduce StrokeVision-Bench, the first-ever
dedicated dataset of stroke patients performing clinically structured block
transfer tasks. StrokeVision-Bench comprises 1,000 annotated videos categorized
into four clinically meaningful action classes, with each sample represented in
two modalities: raw video frames and 2D skeletal keypoints. We benchmark
several state-of-the-art video action recognition and skeleton-based action
classification methods to establish performance baselines for this domain and
facilitate future research in automated stroke rehabilitation assessment.
\\ ( https://arxiv.org/abs/2509.07994 ,  9534kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08018 (*cross-listing*)
Date: Tue, 9 Sep 2025 04:54:08 GMT   (730kb)

Title: Enhancing Privacy Preservation and Reducing Analysis Time with Federated
  Transfer Learning in Digital Twins-based Computed Tomography Scan Analysis
Authors: Avais Jan, Qasim Zia, Murray Patterson
Categories: eess.IV cs.CV cs.LG
Journal-ref: International Conference on Computational Advances in Bio and
  Medical Sciences 2025. Cham: Springer Nature Switzerland
\\
  The application of Digital Twin (DT) technology and Federated Learning (FL)
has great potential to change the field of biomedical image analysis,
particularly for Computed Tomography (CT) scans. This paper presents Federated
Transfer Learning (FTL) as a new Digital Twin-based CT scan analysis paradigm.
FTL uses pre-trained models and knowledge transfer between peer nodes to solve
problems such as data privacy, limited computing resources, and data
heterogeneity. The proposed framework allows real-time collaboration between
cloud servers and Digital Twin-enabled CT scanners while protecting patient
identity. We apply the FTL method to a heterogeneous CT scan dataset and assess
model performance using convergence time, model accuracy, precision, recall, F1
score, and confusion matrix. It has been shown to perform better than
conventional FL and Clustered Federated Learning (CFL) methods with better
precision, accuracy, recall, and F1-score. The technique is beneficial in
settings where the data is not independently and identically distributed
(non-IID), and it offers reliable, efficient, and secure solutions for medical
diagnosis. These findings highlight the possibility of using FTL to improve
decision-making in digital twin-based CT scan analysis, secure and efficient
medical image analysis, promote privacy, and open new possibilities for
applying precision medicine and smart healthcare systems.
\\ ( https://arxiv.org/abs/2509.08018 ,  730kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08302 (*cross-listing*)
Date: Wed, 10 Sep 2025 05:45:49 GMT   (1964kb)

Title: Foundation Models for Autonomous Driving Perception: A Survey Through
  Core Capabilities
Authors: Rajendramayavan Sathyam, Yueqi Li
Categories: cs.RO cs.CV
Comments: 32 pages, 14 figures, accepted at IEEE Open Journal of Vehicular
  Technology (OJVT)
DOI: 10.1109/OJVT.2025.3604823 10.1109/OJVT.2025.3604823
  10.1109/OJVT.2025.3604823
\\
  Foundation models are revolutionizing autonomous driving perception,
transitioning the field from narrow, task-specific deep learning models to
versatile, general-purpose architectures trained on vast, diverse datasets.
This survey examines how these models address critical challenges in autonomous
perception, including limitations in generalization, scalability, and
robustness to distributional shifts. The survey introduces a novel taxonomy
structured around four essential capabilities for robust performance in dynamic
driving environments: generalized knowledge, spatial understanding,
multi-sensor robustness, and temporal reasoning. For each capability, the
survey elucidates its significance and comprehensively reviews cutting-edge
approaches. Diverging from traditional method-centric surveys, our unique
framework prioritizes conceptual design principles, providing a
capability-driven guide for model development and clearer insights into
foundational aspects. We conclude by discussing key challenges, particularly
those associated with the integration of these capabilities into real-time,
scalable systems, and broader deployment challenges related to computational
demands and ensuring model reliability against issues like hallucinations and
out-of-distribution failures. The survey also outlines crucial future research
directions to enable the safe and effective deployment of foundation models in
autonomous driving systems.
\\ ( https://arxiv.org/abs/2509.08302 ,  1964kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08330 (*cross-listing*)
Date: Wed, 10 Sep 2025 07:08:43 GMT   (1323kb)

Title: Physics-Guided Rectified Flow for Low-light RAW Image Enhancement
Authors: Juntai Zeng
Categories: eess.IV cs.CV
Comments: 21pages,7figures
\\
  Enhancing RAW images captured under low light conditions is a challenging
task. Recent deep learning based RAW enhancement methods have shifted from
using real paired data to relying on synthetic datasets. These synthetic
datasets are typically generated by physically modeling sensor noise, but
existing approaches often consider only additive noise, ignore multiplicative
components, and rely on global calibration that overlooks pixel level
manufacturing variations. As a result, such methods struggle to accurately
reproduce real sensor noise. To address these limitations, this paper derives a
noise model from the physical noise generation mechanisms that occur under low
illumination and proposes a novel composite model that integrates both additive
and multiplicative noise. To solve the model, we introduce a physics based per
pixel noise simulation and calibration scheme that estimates and synthesizes
noise for each individual pixel, thereby overcoming the restrictions of
traditional global calibration and capturing spatial noise variations induced
by microscopic CMOS manufacturing differences. Motivated by the strong
performance of rectified flow methods in image generation and processing, we
further combine the physics-based noise synthesis with a rectified flow
generative framework and present PGRF a physics-guided rectified flow framework
for low light image enhancement. PGRF leverages the ability of rectified flows
to model complex data distributions and uses physical guidance to steer the
generation toward the desired clean image. To validate the effectiveness of the
proposed model, we established the LLID dataset, an indoor low light benchmark
captured with the Sony A7S II camera. Experimental results demonstrate that the
proposed framework achieves significant improvements in low light RAW image
enhancement.
\\ ( https://arxiv.org/abs/2509.08330 ,  1323kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08333 (*cross-listing*)
Date: Wed, 10 Sep 2025 07:15:43 GMT   (42326kb)

Title: Good Deep Features to Track: Self-Supervised Feature Extraction and
  Tracking in Visual Odometry
Authors: Sai Puneeth Reddy Gottam, Haoming Zhang and Eivydas Keras
Categories: cs.RO cs.CV
Comments: This short paper has been accepted as a workshop paper at European
  Conference on Mobile Robots 2025
\\
  Visual-based localization has made significant progress, yet its performance
often drops in large-scale, outdoor, and long-term settings due to factors like
lighting changes, dynamic scenes, and low-texture areas. These challenges
degrade feature extraction and tracking, which are critical for accurate motion
estimation. While learning-based methods such as SuperPoint and SuperGlue show
improved feature coverage and robustness, they still face generalization issues
with out-of-distribution data. We address this by enhancing deep feature
extraction and tracking through self-supervised learning with task specific
feedback. Our method promotes stable and informative features, improving
generalization and reliability in challenging environments.
\\ ( https://arxiv.org/abs/2509.08333 ,  42326kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08586 (*cross-listing*)
Date: Wed, 10 Sep 2025 13:33:09 GMT   (940kb)

Title: CNN-ViT Hybrid for Pneumonia Detection: Theory and Empiric on Limited
  Data without Pretraining
Authors: Prashant Singh Basnet, Roshan Chitrakar
Categories: eess.IV cs.CV
Comments: 8 pages, 5 Tables, 5 Figures. Manuscript submitted to ICOIICS 2025
  Conference. Currently, under peer review
\\
  This research explored the hybridization of CNN and ViT within a training
dataset of limited size, and introduced a distinct class imbalance. The
training was made from scratch with a mere focus on theoretically and
experimentally exploring the architectural strengths of the proposed hybrid
model. Experiments were conducted across varied data fractions with balanced
and imbalanced training datasets. Comparatively, the hybrid model,
complementing the strengths of CNN and ViT, achieved the highest recall of
0.9443 (50% data fraction in balanced) and consistency in F1 score around 0.85,
suggesting reliability in diagnosis. Additionally, the model was successful in
outperforming CNN and ViT in imbalanced datasets. Despite its complex
architecture, it required comparable training time to the transformers in all
data fractions.
\\ ( https://arxiv.org/abs/2509.08586 ,  940kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08643 (*cross-listing*)
Date: Wed, 10 Sep 2025 14:37:02 GMT   (14305kb)

Title: X-Part: high fidelity and structure coherent shape decomposition
Authors: Xinhao Yan, Jiachen Xu, Yang Li, Changfeng Ma, Yunhan Yang, Chunshi
  Wang, Zibo Zhao, Zeqiang Lai, Yunfei Zhao, Zhuo Chen, Chunchao Guo
Categories: cs.GR cs.CV
Comments: Tech Report
\\
  Generating 3D shapes at part level is pivotal for downstream applications
such as mesh retopology, UV mapping, and 3D printing. However, existing
part-based generation methods often lack sufficient controllability and suffer
from poor semantically meaningful decomposition. To this end, we introduce
X-Part, a controllable generative model designed to decompose a holistic 3D
object into semantically meaningful and structurally coherent parts with high
geometric fidelity. X-Part exploits the bounding box as prompts for the part
generation and injects point-wise semantic features for meaningful
decomposition. Furthermore, we design an editable pipeline for interactive part
generation. Extensive experimental results show that X-Part achieves
state-of-the-art performance in part-level shape generation. This work
establishes a new paradigm for creating production-ready, editable, and
structurally sound 3D assets. Codes will be released for public research.
\\ ( https://arxiv.org/abs/2509.08643 ,  14305kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08757 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:47:00 GMT   (20466kb)

Title: SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot
  Navigation
Authors: Michael J. Munje, Chen Tang, Shuijing Liu, Zichao Hu, Yifeng Zhu,
  Jiaxun Cui, Garrett Warnell, Joydeep Biswas, Peter Stone
Categories: cs.RO cs.CV
Comments: Conference on Robot Learning (CoRL) 2025 Project site:
  https://larg.github.io/socialnav-sub
\\
  Robot navigation in dynamic, human-centered environments requires
socially-compliant decisions grounded in robust scene understanding. Recent
Vision-Language Models (VLMs) exhibit promising capabilities such as object
recognition, common-sense reasoning, and contextual understanding-capabilities
that align with the nuanced requirements of social robot navigation. However,
it remains unclear whether VLMs can accurately understand complex social
navigation scenes (e.g., inferring the spatial-temporal relations among agents
and human intentions), which is essential for safe and socially compliant robot
navigation. While some recent works have explored the use of VLMs in social
robot navigation, no existing work systematically evaluates their ability to
meet these necessary conditions. In this paper, we introduce the Social
Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question
Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene
understanding in real-world social robot navigation scenarios. SocialNav-SUB
provides a unified framework for evaluating VLMs against human and rule-based
baselines across VQA tasks requiring spatial, spatiotemporal, and social
reasoning in social robot navigation. Through experiments with state-of-the-art
VLMs, we find that while the best-performing VLM achieves an encouraging
probability of agreeing with human answers, it still underperforms simpler
rule-based approach and human consensus baselines, indicating critical gaps in
social scene understanding of current VLMs. Our benchmark sets the stage for
further research on foundation models for social robot navigation, offering a
framework to explore how VLMs can be tailored to meet real-world social robot
navigation needs. An overview of this paper along with the code and data can be
found at https://larg.github.io/socialnav-sub .
\\ ( https://arxiv.org/abs/2509.08757 ,  20466kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08020 (*cross-listing*)
Date: Tue, 9 Sep 2025 08:54:13 GMT   (177kb)

Title: Towards Scalable Proteomics: Opportunistic SMC Samplers on HTCondor
Authors: Matthew Carter, Lee Devlin, Alexander Philips, Edward Pyzer-Knapp,
  Paul Spirakis, Simon Maskell
Categories: q-bio.QM cs.DC stat.CO
\\
  Quantitative proteomics plays a central role in uncovering regulatory
mechanisms, identifying disease biomarkers, and guiding the development of
precision therapies. These insights are often obtained through complex Bayesian
models, whose inference procedures are computationally intensive, especially
when applied at scale to biological datasets. This limits the accessibility of
advanced modelling techniques needed to fully exploit proteomics data. Although
Sequential Monte Carlo (SMC) methods offer a parallelisable alternative to
traditional Markov Chain Monte Carlo, their high-performance implementations
often rely on specialised hardware, increasing both financial and energy costs.
We address these challenges by introducing an opportunistic computing framework
for SMC samplers, tailored to the demands of large-scale proteomics inference.
Our approach leverages idle compute resources at the University of Liverpool
via HTCondor, enabling scalable Bayesian inference without dedicated
high-performance computing infrastructure. Central to this framework is a novel
Coordinator-Manager-Follower architecture that reduces synchronisation overhead
and supports robust operation in heterogeneous, unreliable environments. We
evaluate the framework on a realistic proteomics model and show that
opportunistic SMC delivers accurate inference with weak scaling, increasing
samples generated under a fixed time budget as more resources join. To support
adoption, we release CondorSMC, an open-source package for deploying SMC
samplers in opportunistic computing environments.
\\ ( https://arxiv.org/abs/2509.08020 ,  177kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08195 (*cross-listing*)
Date: Tue, 9 Sep 2025 23:59:20 GMT   (360kb)

Title: Sketched Gaussian Mechanism for Private Federated Learning
Authors: Qiaobo Li, Zhijie Chen, Arindam Banerjee
Categories: cs.LG cs.DC
\\
  Communication cost and privacy are two major considerations in federated
learning (FL). For communication cost, gradient compression by sketching the
clients' transmitted model updates is often used for reducing per-round
communication. For privacy, the Gaussian mechanism (GM), which consists of
clipping updates and adding Gaussian noise, is commonly used to guarantee
client-level differential privacy. Existing literature on private FL analyzes
privacy of sketching and GM in an isolated manner, illustrating that sketching
provides privacy determined by the sketching dimension and that GM has to
supply any additional desired privacy.
  In this paper, we introduce the Sketched Gaussian Mechanism (SGM), which
directly combines sketching and the Gaussian mechanism for privacy. Using
R\'enyi-DP tools, we present a joint analysis of SGM's overall privacy
guarantee, which is significantly more flexible and sharper compared to
isolated analysis of sketching and GM privacy. In particular, we prove that the
privacy level of SGM for a fixed noise magnitude is proportional to
$1/\sqrt{b}$, where $b$ is the sketching dimension, indicating that (for
moderate $b$) SGM can provide much stronger privacy guarantees than the
original GM under the same noise budget. We demonstrate the application of SGM
to FL with either gradient descent or adaptive server optimizers, and establish
theoretical results on optimization convergence, which exhibits only a
logarithmic dependence on the number of parameters $d$. Experimental results
confirm that at the same privacy level, SGM based FL is at least competitive
with non-sketching private FL variants and outperforms them in some settings.
Moreover, using adaptive optimization at the server improves empirical
performance while maintaining the privacy guarantees.
\\ ( https://arxiv.org/abs/2509.08195 ,  360kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08750 (*cross-listing*)
Date: Thu, 4 Sep 2025 08:19:56 GMT   (2485kb)

Title: PracMHBench: Re-evaluating Model-Heterogeneous Federated Learning Based
  on Practical Edge Device Constraints
Authors: Yuanchun Guo and Bingyan Liu and Yulong Sha and Zhensheng Xian
Categories: cs.LG cs.DC
Comments: Accepted by DAC2025
\\
  Federating heterogeneous models on edge devices with diverse resource
constraints has been a notable trend in recent years. Compared to traditional
federated learning (FL) that assumes an identical model architecture to
cooperate, model-heterogeneous FL is more practical and flexible since the
model can be customized to satisfy the deployment requirement. Unfortunately,
no prior work ever dives into the existing model-heterogeneous FL algorithms
under the practical edge device constraints and provides quantitative analysis
on various data scenarios and metrics, which motivates us to rethink and
re-evaluate this paradigm. In our work, we construct the first system platform
\textbf{PracMHBench} to evaluate model-heterogeneous FL on practical
constraints of edge devices, where diverse model heterogeneity algorithms are
classified and tested on multiple data tasks and metrics. Based on the
platform, we perform extensive experiments on these algorithms under the
different edge constraints to observe their applicability and the corresponding
heterogeneity pattern.
\\ ( https://arxiv.org/abs/2509.08750 ,  2485kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08721 (*cross-listing*)
Date: Wed, 10 Sep 2025 16:14:20 GMT   (2029kb)

Title: Sharing is Caring: Efficient LM Post-Training with Collective RL
  Experience Sharing
Authors: Jeffrey Amico, Gabriel Passamani Andrade, John Donaghy, Ben Fielding,
  Tristin Forbus, Harry Grieve, Semih Kara, Jari Kolehmainen, Yihua Lou,
  Christopher Nies, Edward Phillip Flores Nu\~no, Diogo Ortega, Shikhar
  Rastogi, Austin Virts, Matthew J. Wright
Categories: cs.LG cs.MA
Comments: 14 pages, 6 figures
\\
  Post-training language models (LMs) with reinforcement learning (RL) can
enhance their complex reasoning capabilities without supervised fine-tuning, as
demonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs
requires significant parallelization to scale-up inference, which introduces
non-trivial technical challenges (e.g. latency, memory, and reliability)
alongside ever-growing financial costs. We present Swarm sAmpling Policy
Optimization (SAPO), a fully decentralized and asynchronous RL post-training
algorithm. SAPO is designed for decentralized networks of heterogenous compute
nodes, where each node manages its own policy model(s) while "sharing" rollouts
with others in the network; no explicit assumptions about latency, model
homogeneity, or hardware are required and nodes can operate in silo if desired.
As a result, the algorithm avoids common bottlenecks in scaling RL
post-training while also allowing (and even encouraging) new possibilities. By
sampling rollouts "shared" across the network, it enables "Aha moments" to
propagate, thereby bootstrapping the learning process. In this paper we show
SAPO achieved cumulative reward gains of up to 94% in controlled experiments.
We also share insights from tests on a network with thousands of nodes
contributed by Gensyn community members running the algorithm on diverse
hardware and models during an open-source demo.
\\ ( https://arxiv.org/abs/2509.08721 ,  2029kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2406.01139
replaced with revised version Wed, 10 Sep 2025 06:39:43 GMT   (98kb)

Title: Depth-Bounded Epistemic Planning
Authors: Thomas Bolander, Alessandro Burigana, Marco Montali
Categories: cs.AI
Comments: Extended version of paper accepted at KR 2025
\\ ( https://arxiv.org/abs/2406.01139 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2411.14480
replaced with revised version Tue, 9 Sep 2025 20:34:45 GMT   (866kb)

Title: Associative Knowledge Graphs for Efficient Sequence Storage and
  Retrieval
Authors: Przemys{\l}aw Stok{\l}osa, Janusz A. Starzyk, Pawe{\l} Raif, Adrian
  Horzyk, Marcin Kowalik
Categories: cs.AI cs.DB
Comments: 13 pages, 6 figures
Journal-ref: Comput. Methods Programs Biomed. 269 (2025) 108865
DOI: 10.1016/j.cmpb.2025.108865
\\ ( https://arxiv.org/abs/2411.14480 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12669
replaced with revised version Tue, 9 Sep 2025 18:28:14 GMT   (12287kb)

Title: Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite
  Solar Cell Research
Authors: Xiang Liu, Penglei Sun, Shuyan Chen, Longhan Zhang, Peijie Dong,
  Huajie You, Yongqi Zhang, Chang Yan, Xiaowen Chu, Tong-yi Zhang
Categories: cs.AI
Comments: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2502.12669 ,  12287kb)
------------------------------------------------------------------------------
\\
arXiv:2505.05684
replaced with revised version Wed, 10 Sep 2025 10:03:50 GMT   (36kb)

Title: Meta-Semantics Augmented Few-Shot Relational Learning
Authors: Han Wu, Jie Yin
Categories: cs.AI cs.CL cs.LG
Comments: Accepted by EMNLP 2025
\\ ( https://arxiv.org/abs/2505.05684 ,  36kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23141
replaced with revised version Wed, 10 Sep 2025 16:23:48 GMT   (364kb)

Title: Context-Driven Knowledge Graph Completion with Semantic-Aware Relational
  Message Passing
Authors: Siyuan Li, Yan Wen, Ruitong Liu, Te Sun, Ruihao Zhou, Jingyi Kang,
  Yunjia Wu
Categories: cs.AI
\\ ( https://arxiv.org/abs/2506.23141 ,  364kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02253
replaced with revised version Wed, 10 Sep 2025 15:41:15 GMT   (976kb,A)

Title: Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and
  Rigorous Evaluation
Authors: Jungkoo Kang
Categories: cs.AI
Comments: 31 pages, 7 figures
\\ ( https://arxiv.org/abs/2507.02253 ,  976kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07935
replaced with revised version Tue, 9 Sep 2025 23:27:54 GMT   (898kb)

Title: Working with AI: Measuring the Applicability of Generative AI to
  Occupations
Authors: Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri
Categories: cs.AI cs.CY econ.GN q-fin.EC
Comments: 42 pages
\\ ( https://arxiv.org/abs/2507.07935 ,  898kb)
------------------------------------------------------------------------------
\\
arXiv:2507.11992
replaced with revised version Wed, 10 Sep 2025 03:07:45 GMT   (4292kb)

Title: Understanding visual attention beehind bee-inspired UAV navigation
Authors: Pranav Rajbhandari, Abhi Veda, Matthew Garratt, Mandyam Srinivasan,
  Sridhar Ravi
Categories: cs.AI
\\ ( https://arxiv.org/abs/2507.11992 ,  4292kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16129
replaced with revised version Wed, 10 Sep 2025 08:30:10 GMT   (3360kb)

Title: Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and
  OphthaReason Model toward Dynamic Multimodal Reasoning
Authors: Ruiqi Wu, Yuang Yao, Tengfei Ma, Chenran Zhang, Na Su, Tao Zhou, Geng
  Chen, Wen Fan, Yi Zhou
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.16129 ,  3360kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00115
replaced with revised version Wed, 10 Sep 2025 05:22:05 GMT   (582kb)

Title: Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems
Authors: Manish Shukla
Categories: cs.AI cs.CL cs.MA
\\ ( https://arxiv.org/abs/2509.00115 ,  582kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05381
replaced with revised version Wed, 10 Sep 2025 14:35:38 GMT   (370kb)

Title: Murphys Laws of AI Alignment: Why the Gap Always Wins
Authors: Madhava Gaikwad
Categories: cs.AI cs.LG
Comments: 7 pages main text, 4 appendices. Provides a formal impossibility
  theorem (Murphys Gap) and welcomes collaboration on large-scale experiments
  and benchmark design
MSC-class: 68T01, 68T20, 68Q87
ACM-class: F.2.2; I.2.6; I.2.7; I.2.8
\\ ( https://arxiv.org/abs/2509.05381 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07170
replaced with revised version Wed, 10 Sep 2025 03:09:10 GMT   (395kb)

Title: That's So FETCH: Fashioning Ensemble Techniques for LLM Classification
  in Civil Legal Intake and Referral
Authors: Quinten Steenhuis
Categories: cs.AI cs.CL cs.CY
Comments: Submission to JURIX 2025
\\ ( https://arxiv.org/abs/2509.07170 ,  395kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07209
replaced with revised version Wed, 10 Sep 2025 17:02:41 GMT   (5244kb)

Title: BlendedNet: A Blended Wing Body Aircraft Dataset and Surrogate Model for
  Aerodynamic Predictions
Authors: Nicholas Sung, Steven Spreizer, Mohamed Elrefaie, Kaira Samuel,
  Matthew C. Jones, and Faez Ahmed
Categories: cs.AI
Comments: Accepted at ASME IDETC/CIE 2025 (DETC2025-168977). Dataset
  availability: BlendedNet dataset is openly available at Harvard Dataverse
  (https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VJT9EP)
\\ ( https://arxiv.org/abs/2509.07209 ,  5244kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07577
replaced with revised version Wed, 10 Sep 2025 08:04:57 GMT   (223kb)

Title: Towards explainable decision support using hybrid neural models for
  logistic terminal automation
Authors: Riccardo D'Elia, Alberto Termine and Francesco Flammini
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.07577 ,  223kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07894
replaced with revised version Wed, 10 Sep 2025 11:05:31 GMT   (6323kb)

Title: HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics
  Olympiad Benchmark?
Authors: Fangchen Yu, Haiyuan Wan, Qianjia Cheng, Yuchen Zhang, Jiacheng Chen,
  Fujun Han, Yulun Wu, Junchi Yao, Ruilizhen Hu, Ning Ding, Yu Cheng, Tao Chen,
  Lei Bai, Dongzhan Zhou, Yun Luo, Ganqu Cui, Peng Ye
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.07894 ,  6323kb)
------------------------------------------------------------------------------
\\
arXiv:2407.13729
replaced with revised version Wed, 10 Sep 2025 14:13:10 GMT   (416kb)

Title: Baba Is AI: Break the Rules to Beat the Benchmark
Authors: Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio
  Cases, Andrei Barbu, Christopher J. Cueva
Categories: cs.CL
Comments: 8 pages, 8 figures
\\ ( https://arxiv.org/abs/2407.13729 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2410.07473
replaced with revised version Wed, 10 Sep 2025 09:05:33 GMT   (9867kb)

Title: Localizing Factual Inconsistencies in Attributable Text Generation
Authors: Arie Cattan, Paul Roit, Shiyue Zhang, David Wan, Roee Aharoni, Idan
  Szpektor, Mohit Bansal, Ido Dagan
Categories: cs.CL
Comments: Accepted for publication in Transactions of the Association for
  Computational Linguistics (TACL), 2025. Authors pre-print
\\ ( https://arxiv.org/abs/2410.07473 ,  9867kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14161
replaced with revised version Wed, 10 Sep 2025 08:35:19 GMT   (1586kb)

Title: TheAgentCompany: Benchmarking LLM Agents on Consequential Real World
  Tasks
Authors: Frank F. Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain,
  Mengxue Bao, Zora Z. Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, Mingyang
  Yang, Hao Yang Lu, Amaad Martin, Zhe Su, Leander Maben, Raj Mehta, Wayne Chi,
  Lawrence Jang, Yiqing Xie, Shuyan Zhou, Graham Neubig
Categories: cs.CL
Comments: Preprint
\\ ( https://arxiv.org/abs/2412.14161 ,  1586kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12051
replaced with revised version Wed, 10 Sep 2025 02:53:11 GMT   (688kb)

Title: MedS$^3$: Towards Medical Slow Thinking with Self-Evolved Soft
  Dual-sided Process Supervision
Authors: Shuyang Jiang, Yusheng Liao, Zhe Chen, Ya Zhang, Yanfeng Wang, Yu Wang
Categories: cs.CL
Comments: 20 pages;
\\ ( https://arxiv.org/abs/2501.12051 ,  688kb)
------------------------------------------------------------------------------
\\
arXiv:2502.02390
replaced with revised version Wed, 10 Sep 2025 08:09:02 GMT   (7805kb)

Title: CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large
  Language Models Reasoning
Authors: Jianfeng Pan, Senyou Deng, Shaomang Huang
Categories: cs.CL cs.AI
Comments: 18 pages, 10 figures
\\ ( https://arxiv.org/abs/2502.02390 ,  7805kb)
------------------------------------------------------------------------------
\\
arXiv:2502.08395
replaced with revised version Wed, 10 Sep 2025 10:08:08 GMT   (4817kb)

Title: IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in
  LLM Writing Assistance
Authors: Paul R\"ottger, Musashi Hinck, Valentin Hofmann, Kobi Hackenburg,
  Valentina Pyatkin, Faeze Brahman, Dirk Hovy
Categories: cs.CL
Comments: accepted at TACL (pre-MIT Press publication version)
\\ ( https://arxiv.org/abs/2502.08395 ,  4817kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12737
replaced with revised version Wed, 10 Sep 2025 05:39:44 GMT   (910kb)

Title: Beyond Seen Data: Improving KBQA Generalization Through Schema-Guided
  Logical Form Generation
Authors: Shengxiang Gao, Jey Han Lau, Jianzhong Qi
Categories: cs.CL cs.AI
Comments: Accepted by EMNLP 2025
\\ ( https://arxiv.org/abs/2502.12737 ,  910kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16523
replaced with revised version Wed, 10 Sep 2025 13:22:08 GMT   (9359kb)

Title: Pay Attention to Real World Perturbations! Natural Robustness Evaluation
  in Machine Reading Comprehension
Authors: Yulong Wu, Viktor Schlegel, Riza Batista-Navarro
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2502.16523 ,  9359kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16838
replaced with revised version Wed, 10 Sep 2025 15:49:00 GMT   (12293kb)

Title: REGen: A Reliable Evaluation Framework for Generative Event Argument
  Extraction
Authors: Omar Sharif, Joseph Gatto, Madhusudan Basak, Sarah M. Preum
Categories: cs.CL
Comments: Accepted at EMNLP-2025
\\ ( https://arxiv.org/abs/2502.16838 ,  12293kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02682
replaced with revised version Wed, 10 Sep 2025 16:45:42 GMT   (767kb)

Title: MPO: Boosting LLM Agents with Meta Plan Optimization
Authors: Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song,
  Xun Wang, Sujian Li
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2503.02682 ,  767kb)
------------------------------------------------------------------------------
\\
arXiv:2503.19498
replaced with revised version Wed, 10 Sep 2025 02:18:09 GMT   (33320kb)

Title: DomainCQA: Crafting Knowledge-Intensive QA from Domain-Specific Charts
Authors: Yujing Lu, Ling Zhong, Jing Yang, Weiming Li, Peng Wei, Yongheng Wang,
  Manni Duan, Qing Zhang
Categories: cs.CL
Comments: 85 pages, 59 figures
\\ ( https://arxiv.org/abs/2503.19498 ,  33320kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02438
replaced with revised version Wed, 10 Sep 2025 04:22:46 GMT   (1712kb)

Title: Scaling Video-Language Models to 10K Frames via Hierarchical
  Differential Distillation
Authors: Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan
Categories: cs.CL cs.AI
Comments: Accepted by ICML 2025
\\ ( https://arxiv.org/abs/2504.02438 ,  1712kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13534
replaced with revised version Wed, 10 Sep 2025 02:38:49 GMT   (2002kb)

Title: CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation
  to Enhance Reasoning in Large Language Models
Authors: Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Weihao Wang,
  Xin Zhang, Yongjian Cui
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2504.13534 ,  2002kb)
------------------------------------------------------------------------------
\\
arXiv:2504.21117
replaced with revised version Wed, 10 Sep 2025 10:32:57 GMT   (372kb)

Title: Beyond One-Size-Fits-All: Inversion Learning for Highly Effective NLG
  Evaluation Prompts
Authors: Hanhua Hong, Chenghao Xiao, Yang Wang, Yiqi Liu, Wenge Rong, Chenghua
  Lin
Categories: cs.CL
Comments: 11 pages, accepted by Transactions of the Association for
  Computational Linguistics (TACL)
\\ ( https://arxiv.org/abs/2504.21117 ,  372kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14157
replaced with revised version Wed, 10 Sep 2025 04:33:47 GMT   (1108kb)

Title: Prior Prompt Engineering for Reinforcement Fine-Tuning
Authors: Pittawat Taveekitworachai, Potsawee Manakul, Sarana Nutanong, Kunat
  Pipatanakul
Categories: cs.CL cs.AI
Comments: Accepted at EMNLP 2025, Main; 26 pages, 42 figures
\\ ( https://arxiv.org/abs/2505.14157 ,  1108kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15337
replaced with revised version Wed, 10 Sep 2025 07:03:03 GMT   (688kb)

Title: Your Language Model Can Secretly Write Like Humans: Contrastive
  Paraphrase Attacks on LLM-Generated Text Detectors
Authors: Hao Fang, Jiawei Kong, Tianqu Zhuang, Yixiang Qiu, Kuofeng Gao, Bin
  Chen, Shu-Tao Xia, Yaowei Wang, Min Zhang
Categories: cs.CL cs.AI
Comments: Accepted by EMNLP-2025
\\ ( https://arxiv.org/abs/2505.15337 ,  688kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07104
replaced with revised version Wed, 10 Sep 2025 09:03:04 GMT   (1540kb)

Title: How Far Are We from Optimal Reasoning Efficiency?
Authors: Jiaxuan Gao, Shu Yan, Qixin Tan, Lu Yang, Shusheng Xu, Wei Fu, Zhiyu
  Mei, Kaifeng Lyu, Yi Wu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2506.07104 ,  1540kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21582
replaced with revised version Wed, 10 Sep 2025 02:31:17 GMT   (2101kb)

Title: VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation
  of Text Analytics with Intelligent Agents
Authors: Sam Yu-Te Lee, Chenyang Ji, Shicheng Wen, Lifu Huang, Dongyu Liu,
  Kwan-Liu Ma
Categories: cs.CL cs.AI cs.HC
\\ ( https://arxiv.org/abs/2506.21582 ,  2101kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05714
replaced with revised version Wed, 10 Sep 2025 03:00:18 GMT   (5626kb)

Title: HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented
  Generation
Authors: YiHan Jiao, ZheHao Tan, Dan Yang, DuoLin Sun, Jie Feng, Yue Shen, Jian
  Wang, Peng Wei
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2507.05714 ,  5626kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07286
replaced with revised version Wed, 10 Sep 2025 02:25:40 GMT   (689kb)

Title: Arce: Augmented Roberta with Contextualized Elucidations for Ner in
  Automated Rule Checking
Authors: Jian Chen, Jinbao Tian, Yankui Li, Yuqi Lu, Zhou Li
Categories: cs.CL cs.IR
\\ ( https://arxiv.org/abs/2508.07286 ,  689kb)
------------------------------------------------------------------------------
\\
arXiv:2508.07976
replaced with revised version Wed, 10 Sep 2025 06:02:29 GMT   (10431kb)

Title: Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale
  Asynchronous RL
Authors: Jiaxuan Gao, Wei Fu, Minyang Xie, Shusheng Xu, Chuyi He, Zhiyu Mei,
  Banghua Zhu, Yi Wu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.07976 ,  10431kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09016
replaced with revised version Wed, 10 Sep 2025 05:08:47 GMT   (1203kb)

Title: A Survey on Training-free Alignment of Large Language Models
Authors: Birong Pan, Yongqi Li, Weiyu Zhang, Wenpeng Lu, Mayi Xu, Shen Zhou,
  Yuanyuan Zhu, Ming Zhong, Tieyun Qian
Categories: cs.CL cs.LG
Comments: Accepted to EMNLP 2025 (findings), camera-ready version
\\ ( https://arxiv.org/abs/2508.09016 ,  1203kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13107
replaced with revised version Wed, 10 Sep 2025 09:50:51 GMT   (6638kb)

Title: All for law and law for all: Adaptive RAG Pipeline for Legal Research
Authors: Figarri Keisha, Prince Singh, Pallavi, Dion Fernandes, Aravindh
  Manivannan, Ilham Wicaksono, Faisal Ahmad, Wiem Ben Rim
Categories: cs.CL cs.IR
Comments: submitted to NLLP 2025 Workshop
ACM-class: F.2.2; H.3.3; I.2.7
\\ ( https://arxiv.org/abs/2508.13107 ,  6638kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15474
replaced with revised version Wed, 10 Sep 2025 17:51:03 GMT   (353kb)

Title: Subjective Behaviors and Preferences in LLM: Language of Browsing
Authors: Sai Sundaresan, Harshita Chopra, Atanu R. Sinha, Koustava Goswami,
  Nagasai Saketh Naidu, Raghav Karan, N Anushka
Categories: cs.CL cs.AI
Comments: Accepted at EMNLP 2025
\\ ( https://arxiv.org/abs/2508.15474 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01053
replaced with revised version Wed, 10 Sep 2025 17:01:54 GMT   (824kb)

Title: A Dynamic Fusion Model for Consistent Crisis Response
Authors: Xiaoying Song, Anirban Saha Anik, Eduardo Blanco, Vanessa
  Frias-Martinez, Lingzi Hong
Categories: cs.CL
Comments: Accepted at Findings of EMNLP 2025
\\ ( https://arxiv.org/abs/2509.01053 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01058
replaced with revised version Wed, 10 Sep 2025 16:52:35 GMT   (962kb)

Title: Speaking at the Right Level: Literacy-Controlled Counterspeech
  Generation with RAG-RL
Authors: Xiaoying Song, Anirban Saha Anik, Dibakar Barua, Pengcheng Luo, Junhua
  Ding, Lingzi Hong
Categories: cs.CL
Comments: Accepted at Findings of EMNLP 2025
\\ ( https://arxiv.org/abs/2509.01058 ,  962kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02492
replaced with revised version Wed, 10 Sep 2025 16:37:27 GMT   (307kb)

Title: GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward
  Reasoning
Authors: Chenglong Wang, Yongyu Mu, Hang Zhou, Yifu Huo, Ziming Zhu, Jiali
  Zeng, Murun Yang, Bei Li, Tong Xiao, Xiaoyang Hao, Chunliang Zhang, Fandong
  Meng, Jingbo Zhu
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.02492 ,  307kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03867
replaced with revised version Wed, 10 Sep 2025 14:02:50 GMT   (402kb)

Title: Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth
Authors: Yang Wang, Chenghao Xiao, Chia-Yi Hsiao, Zi Yan Chang, Chi-Li Chen,
  Tyler Loakman, Chenghua Lin
Categories: cs.CL
Comments: Accepted for oral presentation at the EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2509.03867 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04373
replaced with revised version Wed, 10 Sep 2025 06:08:26 GMT   (484kb)

Title: Measuring Bias or Measuring the Task: Understanding the Brittle Nature
  of LLM Gender Biases
Authors: Bufan Gao, Elisa Kreiss
Categories: cs.CL
Comments: To be published at EMNLP 2025 (main conference)
\\ ( https://arxiv.org/abs/2509.04373 ,  484kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04903
replaced with revised version Wed, 10 Sep 2025 04:00:39 GMT   (1856kb)

Title: ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation
  Reinforcement Learning
Authors: Jianghao Chen, Wei Sun, Qixiang Yin, Lingxing Kong, Zhixing Tan,
  Jiajun Zhang
Categories: cs.CL
Comments: Under review, our code is available at https://github.com/ZNLP/ACE-RL
\\ ( https://arxiv.org/abs/2509.04903 ,  1856kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05230
replaced with revised version Wed, 10 Sep 2025 17:32:53 GMT   (461kb)

Title: CURE: Controlled Unlearning for Robust Embeddings - Mitigating
  Conceptual Shortcuts in Pre-Trained Language Models
Authors: Aysenur Kocak, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at the Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2025)
\\ ( https://arxiv.org/abs/2509.05230 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06806
replaced with revised version Wed, 10 Sep 2025 09:35:10 GMT   (909kb)

Title: MachineLearningLM: Scaling Many-shot In-context Learning via Continued
  Pretraining
Authors: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.06806 ,  909kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07188
replaced with revised version Wed, 10 Sep 2025 01:37:06 GMT   (1392kb)

Title: DischargeSim: A Simulation Benchmark for Educational Doctor-Patient
  Communication at Discharge
Authors: Zonghai Yao, Michael Sun, Won Seok Jang, Sunjae Kwon, Soie Kwon, Hong
  Yu
Categories: cs.CL cs.AI
Comments: Equal contribution for the first two authors. To appear in the
  proceedings of the Main Conference on Empirical Methods in Natural Language
  Processing (EMNLP) 2025
\\ ( https://arxiv.org/abs/2509.07188 ,  1392kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07730
replaced with revised version Wed, 10 Sep 2025 04:50:56 GMT   (8274kb)

Title: M-BRe: Discovering Training Samples for Relation Extraction from
  Unlabeled Texts with Large Language Models
Authors: Zexuan Li, Hongliang Dai, Piji Li
Categories: cs.CL
Comments: Accepted by EMNLP2025 Main Conference
\\ ( https://arxiv.org/abs/2509.07730 ,  8274kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07801
replaced with revised version Wed, 10 Sep 2025 12:09:56 GMT   (352kb)

Title: SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and
  Relation Extraction in NLP
Authors: Decheng Duan, Yingyi Zhang, Jitong Peng, Chengzhi Zhang
Categories: cs.CL cs.DL cs.IR
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2509.07801 ,  352kb)
------------------------------------------------------------------------------
\\
arXiv:2306.00262
replaced with revised version Tue, 9 Sep 2025 23:18:13 GMT   (3573kb)

Title: Maximizing Information in Domain-Invariant Representation Improves
  Transfer Learning
Authors: Adrian Shuai Li, Elisa Bertino, Xuan-Hong Dang, Ankush Singla, Yuhai
  Tu, Mark N Wegman
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2306.00262 ,  3573kb)
------------------------------------------------------------------------------
\\
arXiv:2310.03843
replaced with revised version Wed, 10 Sep 2025 10:53:27 GMT   (23741kb)

Title: From Channel Bias to Feature Redundancy: Uncovering the "Less is More"
  Principle in Few-Shot Learning
Authors: Ji Zhang, Xu Luo, Lianli Gao, Difan Zou, Hengtao Shen, Jingkuan Song
Categories: cs.CV cs.LG
Comments: arXiv admin note: substantial text overlap with arXiv:2206.08126
\\ ( https://arxiv.org/abs/2310.03843 ,  23741kb)
------------------------------------------------------------------------------
\\
arXiv:2312.01915
replaced with revised version Wed, 10 Sep 2025 02:38:52 GMT   (2456kb)

Title: Learning Robust Representations via Bidirectional Transition for Visual
  Reinforcement Learning
Authors: Xiaobo Hu, Youfang Lin, Yue Liu, Jinwen Wang, Shuo Wang, Hehe Fan and
  Kai Lv
Categories: cs.CV
\\ ( https://arxiv.org/abs/2312.01915 ,  2456kb)
------------------------------------------------------------------------------
\\
arXiv:2404.04256
replaced with revised version Wed, 10 Sep 2025 06:02:46 GMT   (6587kb)

Title: Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation
Authors: Zifu Wan, Pingping Zhang, Yuhao Wang, Silong Yong, Simon Stepputtis,
  Katia Sycara, Yaqi Xie
Categories: cs.CV
Comments: Accepted by WACV 2025. Project page: https://zifuwan.github.io/Sigma/
\\ ( https://arxiv.org/abs/2404.04256 ,  6587kb)
------------------------------------------------------------------------------
\\
arXiv:2405.10160
replaced with revised version Tue, 9 Sep 2025 20:30:28 GMT   (2755kb)

Title: PriorCLIP: Visual Prior Guided Vision-Language Model for Remote Sensing
  Image-Text Retrieval
Authors: Jiancheng Pan, Muyuan Ma, Qing Ma, Cong Bai and Shengyong Chen
Categories: cs.CV cs.AI
Comments: 14 pages, 7 figures
\\ ( https://arxiv.org/abs/2405.10160 ,  2755kb)
------------------------------------------------------------------------------
\\
arXiv:2405.13335
replaced with revised version Wed, 10 Sep 2025 04:25:09 GMT   (382kb)

Title: Vision Transformer with Sparse Scan Prior
Authors: Yuguang Zhang, Qihang Fan, Huaibo Huang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2405.13335 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2409.03521
replaced with revised version Wed, 10 Sep 2025 14:31:31 GMT   (2364kb)

Title: Have Large Vision-Language Models Mastered Art History?
Authors: Ombretta Strafforello, Derya Soydaner, Michiel Willems, Anne-Sofie
  Maerten, Stefanie De Winter
Categories: cs.CV
\\ ( https://arxiv.org/abs/2409.03521 ,  2364kb)
------------------------------------------------------------------------------
\\
arXiv:2409.11960
replaced with revised version Wed, 10 Sep 2025 02:07:24 GMT   (1328kb)

Title: A Chinese Continuous Sign Language Dataset Based on Complex Environments
Authors: Qidan Zhu, Jing Li, Fei Yuan, Jiaojiao Fan, Quan Gan
Categories: cs.CV
Comments: 11 pages, 3 figures
\\ ( https://arxiv.org/abs/2409.11960 ,  1328kb)
------------------------------------------------------------------------------
\\
arXiv:2411.07725
replaced with revised version Wed, 10 Sep 2025 08:15:43 GMT   (3551kb)

Title: ALOcc: Adaptive Lifting-Based 3D Semantic Occupancy and Cost
  Volume-Based Flow Predictions
Authors: Dubing Chen, Jin Fang, Wencheng Han, Xinjing Cheng, Junbo Yin,
  Chenzhong Xu, Fahad Shahbaz Khan, Jianbing Shen
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2411.07725 ,  3551kb)
------------------------------------------------------------------------------
\\
arXiv:2411.18795
replaced with revised version Tue, 9 Sep 2025 18:09:53 GMT   (2996kb)

Title: GloFinder: AI-empowered QuPath Plugin for WSI-level Glomerular
  Detection, Visualization, and Curation
Authors: Jialin Yue, Tianyuan Yao, Ruining Deng, Siqi Lu, Junlin Guo, Quan Liu,
  Mengmeng Yin, Juming Xiong, Haichun Yang, Yuankai Huo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.18795 ,  2996kb)
------------------------------------------------------------------------------
\\
arXiv:2412.01137
replaced with revised version Wed, 10 Sep 2025 07:03:33 GMT   (11009kb)

Title: TextSSR: Diffusion-based Data Synthesis for Scene Text Recognition
Authors: Xingsong Ye, Yongkun Du, Yunbo Tao, Zhineng Chen
Categories: cs.CV
Comments: Accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2412.01137 ,  11009kb)
------------------------------------------------------------------------------
\\
arXiv:2412.13155
replaced with revised version Wed, 10 Sep 2025 13:21:10 GMT   (39394kb)

Title: F-Bench: Rethinking Human Preference Evaluation Metrics for Benchmarking
  Face Generation, Customization, and Restoration
Authors: Lu Liu, Huiyu Duan, Qiang Hu, Liu Yang, Chunlei Cai, Tianxiao Ye,
  Huayu Liu, Xiaoyun Zhang, Guangtao Zhai
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.13155 ,  39394kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06130
replaced with revised version Tue, 9 Sep 2025 18:19:31 GMT   (25852kb)

Title: Self-Correcting Decoding with Generative Feedback for Mitigating
  Hallucinations in Large Vision-Language Models
Authors: Ce Zhang, Zifu Wan, Zhehan Kan, Martin Q. Ma, Simon Stepputtis, Deva
  Ramanan, Russ Salakhutdinov, Louis-Philippe Morency, Katia Sycara, Yaqi Xie
Categories: cs.CV cs.CL
Comments: Accepted by ICLR 2025. Project page:
  https://zhangce01.github.io/DeGF/
\\ ( https://arxiv.org/abs/2502.06130 ,  25852kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02733
replaced with revised version Wed, 10 Sep 2025 02:55:29 GMT   (2857kb)

Title: UAR-NVC: A Unified AutoRegressive Framework for Memory-Efficient Neural
  Video Compression
Authors: Jia Wang, Xinfeng Zhang, Gai Zhang, Jun Zhu, Lv Tang, and Li Zhang
Categories: cs.CV cs.AI
Comments: Accepted to TCSVT2025
DOI: 10.1109/TCSVT.2025.3603282
\\ ( https://arxiv.org/abs/2503.02733 ,  2857kb)
------------------------------------------------------------------------------
\\
arXiv:2503.06762
replaced with revised version Wed, 10 Sep 2025 02:07:32 GMT   (33329kb)

Title: GNF: Gaussian Neural Fields for Multidimensional Signal Representation
  and Reconstruction
Authors: Abdelaziz Bouzidi, Hamid Laga, Hazem Wannous, Ferdous Sohel
Categories: cs.CV
Comments: The source code is publicly available at
  \url{https://grbfnet.github.io/}
\\ ( https://arxiv.org/abs/2503.06762 ,  33329kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09151
replaced with revised version Wed, 10 Sep 2025 16:59:24 GMT   (48834kb)

Title: Reangle-A-Video: 4D Video Generation as Video-to-Video Translation
Authors: Hyeonho Jeong, Suhyeon Lee, Jong Chul Ye
Categories: cs.CV cs.AI
Comments: ICCV 2025, Project page: https://hyeonho99.github.io/reangle-a-video/
\\ ( https://arxiv.org/abs/2503.09151 ,  48834kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13794
replaced with revised version Wed, 10 Sep 2025 15:29:43 GMT   (31743kb)

Title: LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated
  Data Generation
Authors: Yang Zhou, Shiyu Zhao, Yuxiao Chen, Zhenting Wang, Can Jin, Dimitris
  N. Metaxas
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2503.13794 ,  31743kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14111
replaced with revised version Wed, 10 Sep 2025 14:31:21 GMT   (44191kb)

Title: Towards properties of adversarial image perturbations
Authors: Egor Kuznetsov, Kirill Aistov, Maxim Koroteev
Categories: cs.CV
Comments: 13 pages, 40 figures
\\ ( https://arxiv.org/abs/2503.14111 ,  44191kb)
------------------------------------------------------------------------------
\\
arXiv:2504.06022
replaced with revised version Wed, 10 Sep 2025 17:57:03 GMT   (45585kb)

Title: CamC2V: Context-aware Controllable Video Generation
Authors: Luis Denninger, Sina Mokhtarzadeh Azar, Juergen Gall
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.06022 ,  45585kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11171
replaced with revised version Wed, 10 Sep 2025 11:56:52 GMT   (39938kb)

Title: TerraMind: Large-Scale Generative Multimodality for Earth Observation
Authors: Johannes Jakubik, Felix Yang, Benedikt Blumenstiel, Erik Scheurer,
  Rocco Sedona, Stefano Maurogiovanni, Jente Bosmans, Nikolaos Dionelis,
  Valerio Marsocci, Niklas Kopp, Rahul Ramachandran, Paolo Fraccaro, Thomas
  Brunschwiler, Gabriele Cavallaro, Juan Bernabe-Moreno, Nicolas Long\'ep\'e
Categories: cs.CV cs.AI
Comments: Accepted at ICCV'25
\\ ( https://arxiv.org/abs/2504.11171 ,  39938kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11500
replaced with revised version Wed, 10 Sep 2025 01:00:18 GMT   (19573kb)

Title: TransitReID: Transit OD Data Collection with Occlusion-Resistant Dynamic
  Passenger Re-Identification
Authors: Kaicong Huang, Talha Azfar, Jack Reilly, Ruimin Ke
Categories: cs.CV cs.AI eess.IV
\\ ( https://arxiv.org/abs/2504.11500 ,  19573kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13812
replaced with revised version Wed, 10 Sep 2025 14:42:54 GMT   (11265kb)

Title: Physics-Driven Local-Whole Elastic Deformation Modeling for Point Cloud
  Representation Learning
Authors: Zhongyu Chen, Rong Zhao, Xie Han, Xindong Guo, Song Wang, Zherui Qiao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.13812 ,  11265kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10582
replaced with revised version Wed, 10 Sep 2025 07:20:50 GMT   (85kb)

Title: Rethinking Random Masking in Self-Distillation on ViT
Authors: Jihyeon Seong and Hyunkyung Han
Categories: cs.CV
Comments: 4 pages
\\ ( https://arxiv.org/abs/2506.10582 ,  85kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21369
replaced with revised version Wed, 10 Sep 2025 15:55:35 GMT   (5364kb)

Title: GenFlow: Interactive Modular System for Image Generation
Authors: Duc-Hung Nguyen and Huu-Phuc Huynh and Minh-Triet Tran and Trung-Nghia
  Le
Categories: cs.CV
Comments: CBMI 2025
\\ ( https://arxiv.org/abs/2506.21369 ,  5364kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05264
replaced with revised version Wed, 10 Sep 2025 02:48:25 GMT   (2466kb)

Title: SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible
  Image Fusion
Authors: Xiaoyang Zhang, jinjiang Li, Guodong Fan, Yakun Ju, Linwei Fan, Jun
  Liu, Alex C. Kot
Categories: cs.CV cs.AI
Comments: Submitted to Information Fusion
\\ ( https://arxiv.org/abs/2508.05264 ,  2466kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16654
replaced with revised version Wed, 10 Sep 2025 11:47:41 GMT   (2667kb)

Title: MSNav: Zero-Shot Vision-and-Language Navigation with Dynamic Memory and
  LLM Spatial Reasoning
Authors: Chenghao Liu, Zhimu Zhou, Jiachen Zhang, Minghao Zhang, Songfang
  Huang, Huiling Duan
Categories: cs.CV
Comments: 9 pages, 4 figures
\\ ( https://arxiv.org/abs/2508.16654 ,  2667kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21197
replaced with revised version Tue, 9 Sep 2025 20:57:47 GMT   (3502kb)

Title: GCAV: A Global Concept Activation Vector Framework for Cross-Layer
  Consistency in Interpretability
Authors: Zhenghao He, Sanchit Sinha, Guangzhi Xiong, Aidong Zhang
Categories: cs.CV
Comments: Accepted at ICCV 2025
\\ ( https://arxiv.org/abs/2508.21197 ,  3502kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01085
replaced with revised version Wed, 10 Sep 2025 05:02:14 GMT   (4663kb)

Title: Bidirectional Sparse Attention for Faster Video Diffusion Training
Authors: Chenlu Zhan, Wen Li, Chuyu Shen, Jun Zhang, Suhui Wu, Hao Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.01085 ,  4663kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01202
replaced with revised version Wed, 10 Sep 2025 10:51:53 GMT   (6936kb)

Title: PrediTree: A Multi-Temporal Sub-meter Dataset of Multi-Spectral Imagery
  Aligned With Canopy Height Maps
Authors: Hiyam Debary, Mustansar Fiaz, Levente Klein
Categories: cs.CV
Comments: Accepted at GAIA 2025. Dataset available at
  https://huggingface.co/datasets/hiyam-d/PrediTree
\\ ( https://arxiv.org/abs/2509.01202 ,  6936kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01907
replaced with revised version Wed, 10 Sep 2025 01:09:56 GMT   (3590kb)

Title: RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster
  Events
Authors: Zhenyuan Chen, Chenxi Wang, Feng Zhang
Categories: cs.CV cs.CL
Comments: under review
\\ ( https://arxiv.org/abs/2509.01907 ,  3590kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04545
replaced with revised version Wed, 10 Sep 2025 11:33:19 GMT   (13829kb)

Title: PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via
  Chain-of-Thought Prompt Rewriting
Authors: Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Jiale Tao, Qixun
  Wang, Ruihuang Li, Comi Chen, Xin Li, Mingrui Wu, Xinchi Deng, Chunyu Wang,
  Qinglin Lu
Categories: cs.CV
Comments: technical report
\\ ( https://arxiv.org/abs/2509.04545 ,  13829kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05342
replaced with revised version Tue, 9 Sep 2025 22:17:54 GMT   (48814kb)

Title: Delta Velocity Rectified Flow for Text-to-Image Editing
Authors: Gaspard Beaudouin, Minghan Li, Jaeyeon Kim, Sung-Hoon Yoon, Mengyu
  Wang
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2509.05342 ,  48814kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06040
replaced with revised version Wed, 10 Sep 2025 13:09:03 GMT   (6902kb)

Title: BranchGRPO: Stable and Efficient GRPO with Structured Branching in
  Diffusion Models
Authors: Yuming Li, Yikai Wang, Yuying Zhu, Zhongyu Zhao, Ming Lu, Qi She,
  Shanghang Zhang
Categories: cs.CV cs.AI cs.LG
Comments: 12 pages, 6 figures
\\ ( https://arxiv.org/abs/2509.06040 ,  6902kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06142
replaced with revised version Wed, 10 Sep 2025 02:06:48 GMT   (3809kb)

Title: RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric
  Privacy Preserving
Authors: Zhengquan Luo, Chi Liu, Dongfu Xiao, Zhen Yu, Yueye Wang, Tianqing Zhu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.06142 ,  3809kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06585
replaced with revised version Tue, 9 Sep 2025 20:18:23 GMT   (2720kb)

Title: Detection of trade in products derived from threatened species using
  machine learning and a smartphone
Authors: Ritwik Kulkarni, WU Hanqin, Enrico Di Minin
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2509.06585 ,  2720kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06591
replaced with revised version Wed, 10 Sep 2025 11:32:27 GMT   (4109kb)

Title: Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT
  Denoising
Authors: Yichao Liu, Hengzhi Xue, YueYang Teng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.06591 ,  4109kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06685
replaced with revised version Wed, 10 Sep 2025 01:06:59 GMT   (0kb,I)

Title: VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level
  Guidance in Large Scenes
Authors: Shengkai Zhang, Yuhe Liu, Guanjun Wu, Jianhua He, Xinggang Wang, Mozi
  Chen, Kezhong Liu
Categories: cs.CV
Comments: Withdrawn due to an error in the author list & incomplete
  experimental results
\\ ( https://arxiv.org/abs/2509.06685 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06784
replaced with revised version Wed, 10 Sep 2025 14:02:32 GMT   (11525kb)

Title: P3-SAM: Native 3D Part Segmentation
Authors: Changfeng Ma, Yang Li, Xinhao Yan, Jiachen Xu, Yunhan Yang, Chunshi
  Wang, Zibo Zhao, Yanwen Guo, Zhuo Chen, Chunchao Guo
Categories: cs.CV
Comments: Tech Report
\\ ( https://arxiv.org/abs/2509.06784 ,  11525kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07027
replaced with revised version Wed, 10 Sep 2025 08:56:22 GMT   (17412kb)

Title: Moment- and Power-Spectrum-Based Gaussianity Regularization for
  Text-to-Image Models
Authors: Jisung Hwang, Jaihoon Kim, Minhyuk Sung
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.07027 ,  17412kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07538
replaced with revised version Wed, 10 Sep 2025 09:41:48 GMT   (1076kb)

Title: TextlessRAG: End-to-End Visual Document RAG by Speech Without Text
Authors: Peijin Xie and Shun Qian and Bingquan Liu and Dexin Wang and Lin Sun
  and Xiangzheng Zhang
Categories: cs.CV
Comments: 5 pages, 4 figures,
\\ ( https://arxiv.org/abs/2509.07538 ,  1076kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07673
replaced with revised version Wed, 10 Sep 2025 07:36:45 GMT   (495kb)

Title: Nearest Neighbor Projection Removal Adversarial Training
Authors: Himanshu Singh, A. V. Subramanyam, Shivank Rajput, Mohan Kankanhalli
Categories: cs.CV cs.LG
MSC-class: 68T45 (Primary), 68T10 (Secondary)
ACM-class: I.5.4
\\ ( https://arxiv.org/abs/2509.07673 ,  495kb)
------------------------------------------------------------------------------
\\
arXiv:2410.06715
replaced with revised version Wed, 10 Sep 2025 13:13:54 GMT   (1568kb)

Title: FRESCO: Fast and Reliable Edge Offloading with Reputation-based Hybrid
  Smart Contracts
Authors: Josip Zilic, Vincenzo de Maio, Shashikant Ilager, Ivona Brandic
Categories: cs.DC
Comments: 15 pages, 21 figures
\\ ( https://arxiv.org/abs/2410.06715 ,  1568kb)
------------------------------------------------------------------------------
\\
arXiv:2410.19721
replaced with revised version Wed, 10 Sep 2025 14:08:13 GMT   (918kb)

Title: Validity in Network-Agnostic Byzantine Agreement
Authors: Andrei Constantinescu, Marc Dufay, Diana Ghinea, Roger Wattenhofer
Categories: cs.DC
\\ ( https://arxiv.org/abs/2410.19721 ,  918kb)
------------------------------------------------------------------------------
\\
arXiv:2502.10000
replaced with revised version Wed, 10 Sep 2025 10:02:43 GMT   (725kb)

Title: Energy-Aware Scheduling Strategies for Partially-Replicable Task Chains
  on Heterogeneous Processors
Authors: Yacine Idouar (ALSOC), Adrien Cassagne (ALSOC), La\'ercio Lima Pilla
  (TOPAL), Julien Sopena (DELYS), Manuel Bouyer (ALSOC), Diane Orhan (STORM),
  Lionel Lacassagne (ALSOC), Dimitri Galayko (CYAN), Denis Barthou (Bordeaux
  INP), Christophe Jego (IMS)
Categories: cs.DC
\\ ( https://arxiv.org/abs/2502.10000 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2503.11600
replaced with revised version Wed, 10 Sep 2025 14:00:07 GMT   (235kb)

Title: Supervised Distributed Computing
Authors: John Augustine, Christian Scheideler and Julian Werthmann
Categories: cs.DC
\\ ( https://arxiv.org/abs/2503.11600 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14107
replaced with revised version Tue, 9 Sep 2025 22:40:11 GMT   (3335kb)

Title: D\'ej\`a Vu: Efficient Video-Language Query Engine with Learning-based
  Inter-Frame Computation Reuse
Authors: Jinwoo Hwang, Daeun Kim, Sangyeop Lee, Yoonsung Kim, Guseul Heo,
  Hojoon Kim, Yunseok Jeong, Tadiwos Meaza, Eunhyeok Park, Jeongseob Ahn,
  Jongse Park
Categories: cs.DC cs.CV
Comments: Accepted to 2025 VLDB
\\ ( https://arxiv.org/abs/2506.14107 ,  3335kb)
------------------------------------------------------------------------------
\\
arXiv:2507.12038
replaced with revised version Wed, 10 Sep 2025 17:03:25 GMT   (146kb)

Title: Distributed Algorithms for Potential Problems
Authors: Alkida Balliu, Thomas Boudier, Francesco d'Amore, Dennis Olivetti,
  Gustav Schmid, Jukka Suomela
Categories: cs.DC
Comments: 28 pages, 4 figures. Acknowledgments added in v2. Some bugs in the
  proofs were corrected in v3
\\ ( https://arxiv.org/abs/2507.12038 ,  146kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19452
replaced with revised version Wed, 10 Sep 2025 13:07:58 GMT   (67kb)

Title: Formal Modeling and Verification of the Algorand Consensus Protocol in
  CADP
Authors: Andrea Esposito and Francesco P. Rossi and Marco Bernardo and
  Francesco Fabris and Hubert Garavel
Categories: cs.DC
\\ ( https://arxiv.org/abs/2508.19452 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01118
replaced with revised version Wed, 10 Sep 2025 02:59:01 GMT   (472kb)

Title: Ocior: Ultra-Fast Asynchronous Leaderless Consensus with Two-Round
  Finality, Linear Overhead, and Adaptive Security
Authors: Jinyuan Chen
Categories: cs.DC
Comments: 52 pages
\\ ( https://arxiv.org/abs/2509.01118 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03765
replaced with revised version Wed, 10 Sep 2025 04:56:11 GMT   (701kb)

Title: Synergy Over Spiral: A Logistics 5.0 Game-Theoretic Model for
  Trust-Fatigue Co-regulation in Human-Cobot Order Picking
Authors: Soumyadeep Dhar, Ariyan Kumar Saha
Categories: cs.MA
\\ ( https://arxiv.org/abs/2508.03765 ,  701kb)
------------------------------------------------------------------------------
\\
arXiv:2402.04355 (*cross-listing*)
replaced with revised version Wed, 10 Sep 2025 16:11:35 GMT   (4533kb)

Title: PQMass: Probabilistic Assessment of the Quality of Generative Models
  using Probability Mass Estimation
Authors: Pablo Lemos, Sammy Sharief, Nikolay Malkin, Salma Salhi, Connor Stone,
  Laurence Perreault-Levasseur, Yashar Hezaveh
Categories: stat.ML cs.AI cs.LG stat.ME
Comments: Published as a conference paper at ICLR 2025
\\ ( https://arxiv.org/abs/2402.04355 ,  4533kb)
------------------------------------------------------------------------------
\\
arXiv:2403.09904
replaced with revised version Wed, 10 Sep 2025 01:18:56 GMT   (1526kb)

Title: FedComLoc: Communication-Efficient Distributed Training of Sparse and
  Quantized Models
Authors: Kai Yi, Georg Meinhardt, Laurent Condat, Peter Richt\'arik
Categories: cs.LG cs.AI cs.DC
Comments: Accepted version at Transactions on Machine Learning Research (TMLR)
\\ ( https://arxiv.org/abs/2403.09904 ,  1526kb)
------------------------------------------------------------------------------
\\
arXiv:2403.16108
replaced with revised version Wed, 10 Sep 2025 11:00:11 GMT   (235kb)

Title: A Transformer approach for Electricity Price Forecasting
Authors: Oscar Llorente and Jose Portela
Categories: cs.LG cs.AI
Comments: 9 pages
\\ ( https://arxiv.org/abs/2403.16108 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2408.01416
replaced with revised version Wed, 10 Sep 2025 13:46:42 GMT   (2013kb)

Title: The Quest for the Right Mediator: Surveying Mechanistic Interpretability
  Through the Lens of Causal Mediation Analysis
Authors: Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena
  Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma,
  Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov
Categories: cs.LG cs.AI
Comments: Accepted to Computational Linguistics
\\ ( https://arxiv.org/abs/2408.01416 ,  2013kb)
------------------------------------------------------------------------------
\\
arXiv:2411.04337
replaced with revised version Tue, 9 Sep 2025 19:29:08 GMT   (4941kb)

Title: Neural-Enhanced Dynamic Range Compression Inversion: A Hybrid Approach
  for Restoring Audio Dynamics
Authors: Haoran Sun, Dominique Fourer and Hichem Maaref
Categories: cs.SD cs.AI eess.AS
Comments: This work has been submitted to the IEEE for possible publication
\\ ( https://arxiv.org/abs/2411.04337 ,  4941kb)
------------------------------------------------------------------------------
\\
arXiv:2411.08341
replaced with revised version Wed, 10 Sep 2025 01:47:07 GMT   (2313kb)

Title: Generative AI for Data Augmentation in Wireless Networks: Analysis,
  Applications, and Case Study
Authors: Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Jiacheng Wang,
  Biplab Sikdar, Ping Zhang
Categories: cs.NI cs.AI
\\ ( https://arxiv.org/abs/2411.08341 ,  2313kb)
------------------------------------------------------------------------------
\\
arXiv:2411.16147
replaced with revised version Wed, 10 Sep 2025 13:42:20 GMT   (1044kb)

Title: QR-VC: Leveraging Quantization Residuals for Linear Disentanglement in
  Zero-Shot Voice Conversion
Authors: Youngjun Sim, Jinsung Yoon, Wooyeol Jeong, Young-Joo Suh
Categories: cs.SD cs.AI eess.AS
Comments: 5 pages. Accepted to EUSIPCO 2025 (Paper #1938)
\\ ( https://arxiv.org/abs/2411.16147 ,  1044kb)
------------------------------------------------------------------------------
\\
arXiv:2412.15837
replaced with revised version Wed, 10 Sep 2025 01:58:54 GMT   (21470kb)

Title: Traffic-Rule-Compliant Trajectory Repair via Satisfiability Modulo
  Theories and Reachability Analysis
Authors: Yuanfei Lin, Zekun Xing, Xuyuan Han, Matthias Althoff
Categories: cs.RO cs.AI
Comments: 2025 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works
\\ ( https://arxiv.org/abs/2412.15837 ,  21470kb)
------------------------------------------------------------------------------
\\
arXiv:2501.15463
replaced with revised version Tue, 9 Sep 2025 15:10:28 GMT   (16636kb)

Title: Mind the Value-Action Gap: Do LLMs Act in Alignment with Their Values?
Authors: Hua Shen, Nicholas Clark, Tanushree Mitra
Categories: cs.HC cs.AI cs.CL
Comments: EMNLP 2025 Main Paper
\\ ( https://arxiv.org/abs/2501.15463 ,  16636kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15610
replaced with revised version Wed, 10 Sep 2025 06:54:53 GMT   (36296kb)

Title: A general language model for peptide identification
Authors: Jixiu Zhai, Zikun Wang, Tianchi Lu, Haitian Zhong, Ziyang Xu, Yuhuan
  Liu, Shengrui Xu, Jingwan Wang and Dan Huang
Categories: cs.LG cs.AI
Comments: 24 pages, 9 figures, 4 tables, submitted to arXiv
MSC-class: 92C40, 68T07
ACM-class: I.2.6; J.3
\\ ( https://arxiv.org/abs/2502.15610 ,  36296kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05320
replaced with revised version Wed, 10 Sep 2025 13:56:44 GMT   (2451kb)

Title: To See a World in a Spark of Neuron: Disentangling Multi-task
  Interference for Training-free Model Merging
Authors: Zitao Fang, Guodong DU, Shuyang Yu, Yifei Guo, Yiwei Zhang, Yiyao Cao,
  Jing Li, Ho-Kin Tang, Sim Kuan Goh
Categories: cs.LG cs.AI
Comments: Accepted to EMNLP 2025 Main Conference. This is the camera-ready
  version. Code: https://ZzzitaoFang.github.io/projects/NeuroMerging/
\\ ( https://arxiv.org/abs/2503.05320 ,  2451kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15108
replaced with revised version Wed, 10 Sep 2025 09:57:03 GMT   (7289kb)

Title: VIPER: Visual Perception and Explainable Reasoning for Sequential
  Decision-Making
Authors: Mohamed Salim Aissi, Clemence Grislain, Mohamed Chetouani, Olivier
  Sigaud, Laure Soulier, Nicolas Thome
Categories: cs.LG cs.AI cs.RO
\\ ( https://arxiv.org/abs/2503.15108 ,  7289kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20607 (*cross-listing*)
replaced with revised version Wed, 10 Sep 2025 09:51:15 GMT   (143kb)

Title: A decision-theoretic approach to dealing with uncertainty in quantum
  mechanics
Authors: Keano De Vos and Gert de Cooman and Alexander Erreygers and Jasper De
  Bock
Categories: quant-ph cs.AI math.PR
Comments: 53 pages
\\ ( https://arxiv.org/abs/2503.20607 ,  143kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03814
replaced with revised version Tue, 9 Sep 2025 19:39:35 GMT   (4228kb)

Title: Recursive Training Loops in LLMs: How training data properties modulate
  distribution shift in generated data?
Authors: Grgur Kova\v{c}, J\'er\'emy Perez, R\'emy Portelas, Peter Ford
  Dominey, Pierre-Yves Oudeyer
Categories: cs.LG cs.AI cs.CL
Comments: Accepted to EMNLP 2025 (Oral)
MSC-class: 68T50
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2504.03814 ,  4228kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12151
replaced with revised version Tue, 9 Sep 2025 21:38:59 GMT   (141kb)

Title: Reasoning Large Language Model Errors Arise from Hallucinating Critical
  Problem Features
Authors: Alex Heyman and Joel Zylberberg
Categories: cs.LG cs.AI
Comments: 19 pages (9 excluding references and appendices); 9 figures (6
  excluding appendices)
ACM-class: I.2.6; I.2.7
\\ ( https://arxiv.org/abs/2505.12151 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21087
replaced with revised version Wed, 10 Sep 2025 13:29:23 GMT   (131kb)

Title: Stopping Criteria for Value Iteration on Concurrent Stochastic
  Reachability and Safety Games
Authors: Marta Grobelna, Jan K\v{r}et\'insk\'y, Maximilian Weininger
Categories: cs.LO cs.AI cs.MA
Comments: Full version of the corresponding LICS'25 paper Corrected Algorithm 2
  and associated Lemma 30
\\ ( https://arxiv.org/abs/2505.21087 ,  131kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00074
replaced with revised version Wed, 10 Sep 2025 17:27:44 GMT   (3950kb)

Title: Whose Name Comes Up? Auditing LLM-Based Scholar Recommendations
Authors: Daniele Barolo, Chiara Valentin, Fariba Karimi, Luis Gal\'arraga,
  Gonzalo G. M\'endez, Lisette Esp\'in-Noboa
Categories: cs.CY cs.AI cs.DL cs.IR cs.SI physics.soc-ph
Comments: 40 pages: 10 main (incl. 9 figures), 3 references, and 27 appendix.
  Paper under-review
MSC-class: 68T50
ACM-class: I.2.7; C.4; F.2; K.4.1
\\ ( https://arxiv.org/abs/2506.00074 ,  3950kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07392
replaced with revised version Wed, 10 Sep 2025 03:47:56 GMT   (5124kb)

Title: From Static to Adaptive Defense: Federated Multi-Agent Deep
  Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in
  UAV Swarm Networks
Authors: Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Tian Qin, Yuyu Zhao
Categories: cs.CR cs.AI cs.LG
Comments: 16pages; Major Revision for IEEE TCCN
MSC-class: 68
ACM-class: F.2.2
\\ ( https://arxiv.org/abs/2506.07392 ,  5124kb)
------------------------------------------------------------------------------
\\
arXiv:2506.13759
replaced with revised version Wed, 10 Sep 2025 02:11:26 GMT   (2454kb)

Title: Discrete Diffusion in Large Language and Multimodal Models: A Survey
Authors: Runpeng Yu and Qi Li and Xinchao Wang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.13759 ,  2454kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23629
replaced with revised version Wed, 10 Sep 2025 12:50:14 GMT   (411kb)

Title: A Nonlinear Low-rank Representation Model with Convolutional Neural
  Network for Imputing Water Quality Data
Authors: Xin Liao and Bing Yang and Cai Yu
Categories: cs.LG cs.AI
Comments: 7 pages, 2 figures, conference
MSC-class: 68T07(Primary) 62M10, 65C60 (Secondary)
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2506.23629 ,  411kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23771
replaced with revised version Wed, 10 Sep 2025 08:59:58 GMT   (1502kb)

Title: Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior
  and Control of Autonomous Driving
Authors: Guizhe Jin, Zhuoren Li, Bo Leng, Ran Yu, Lu Xiong and Chen Sun
Categories: cs.RO cs.AI
Comments: 8 pages, Submitted to IEEE Robotics and Automation Letters (under
  second-round review)
\\ ( https://arxiv.org/abs/2506.23771 ,  1502kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02424
replaced with revised version Wed, 10 Sep 2025 09:08:15 GMT   (479kb)

Title: CyberRAG: An Agentic RAG cyber attack classification and reporting tool
Authors: Francesco Blefari, Cristian Cosentino, Francesco Aurelio Pironti,
  Angelo Furfaro, Fabrizio Marozzo
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2507.02424 ,  479kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06819
replaced with revised version Wed, 10 Sep 2025 09:20:13 GMT   (12471kb)

Title: Comprehensive Evaluation of Prototype Neural Networks
Authors: Philipp Schlinge, Steffen Meinert, Martin Atzmueller
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2507.06819 ,  12471kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17668
replaced with revised version Wed, 10 Sep 2025 12:25:27 GMT   (930kb)

Title: How Should We Meta-Learn Reinforcement Learning Algorithms?
Authors: Alexander David Goldie, Zilin Wang, Jaron Cohen, Jakob Nicolaus
  Foerster, Shimon Whiteson
Categories: cs.LG cs.AI
Comments: Accepted paper at Reinforcement Learning Conference (RLC) 2025
\\ ( https://arxiv.org/abs/2507.17668 ,  930kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00300
replaced with revised version Wed, 10 Sep 2025 01:46:21 GMT   (1003kb)

Title: MetaExplainer: A Framework to Generate Multi-Type User-Centered
  Explanations for AI Systems
Authors: Shruthi Chari, Oshani Seneviratne, Prithwish Chakraborty, Pablo Meyer,
  Deborah L. McGuinness
Categories: cs.HC cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.00300 ,  1003kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03682
replaced with revised version Tue, 9 Sep 2025 21:50:16 GMT   (198kb)

Title: Self-Questioning Language Models
Authors: Lili Chen, Mihir Prabhudesai, Katerina Fragkiadaki, Hao Liu, Deepak
  Pathak
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2508.03682 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18106
replaced with revised version Wed, 10 Sep 2025 07:24:52 GMT   (6062kb)

Title: A.S.E: A Repository-Level Benchmark for Evaluating Security in
  AI-Generated Code
Authors: Keke Lian and Bin Wang, Lei Zhang, Libo Chen, Junjie Wang, Ziming
  Zhao, Yujiu Yang, Haotong Duan, Haoran Zhao, Shuang Liao, Mingda Guo,
  Jiazheng Quan, Yilu Zhong, Chenhao He, Zichuan Chen, Jie Wu, Haoling Li,
  Zhaoxuan Li, Jiongchi Yu, Hui Li and Dong Zhang
Categories: cs.SE cs.AI
\\ ( https://arxiv.org/abs/2508.18106 ,  6062kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00268 (*cross-listing*)
replaced with revised version Tue, 9 Sep 2025 18:35:57 GMT   (25981kb)

Title: Revealing Hidden Precursors to Earthquakes via a Stress-Sensitive
  Transformation of Seismic Noise
Authors: Nader Shakibay Senobari
Categories: physics.geo-ph cs.AI eess.SP
Comments: 22 pages, 7 figures. Github code included. Submitted to Science
  Advances
MSC-class: 86A15 (Seismology), 62M10 (Time series, stochastic processes)
ACM-class: I.5.4; I.2.6
\\ ( https://arxiv.org/abs/2509.00268 ,  25981kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05877 (*cross-listing*)
replaced with revised version Wed, 10 Sep 2025 17:02:44 GMT   (383kb)

Title: Uncertainty Quantification in Probabilistic Machine Learning Models:
  Theory, Methods, and Insights
Authors: Marzieh Ajirak, Anand Ravishankar, Petar M. Djuric
Categories: stat.ML cs.AI cs.LG
Comments: Accepted to EUSIPCO 2025
\\ ( https://arxiv.org/abs/2509.05877 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06218 (*cross-listing*)
replaced with revised version Tue, 9 Sep 2025 18:39:03 GMT   (742kb)

Title: The Efficiency Frontier: Classical Shadows versus Quantum Footage
Authors: Shuowei Ma, Junyu Liu
Categories: quant-ph cs.AI cs.LG stat.ML
Comments: 23 pages, many figures. v2: changes gibberish texts due to latex
  compilation error
\\ ( https://arxiv.org/abs/2509.06218 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07009 (*cross-listing*)
replaced with revised version Wed, 10 Sep 2025 07:42:47 GMT   (400kb)

Title: Computational Concept of the Psyche (in Russian)
Authors: Anton Kolonin and Vladimir Kryukov
Categories: q-bio.NC cs.AI cs.SY eess.SY
Comments: 14 pages, in Russian, 2 figures, submitted to Neuroinformatics-2025
  conference
\\ ( https://arxiv.org/abs/2509.07009 ,  400kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07793 (*cross-listing*)
replaced with revised version Wed, 10 Sep 2025 13:46:58 GMT   (917kb)

Title: Individual utilities of life satisfaction reveal inequality aversion
  unrelated to political alignment
Authors: Crispin Cooper, Ana Fredrich, Tommaso Reggiani, Wouter Poortinga
Categories: econ.GN cs.AI cs.CY q-fin.EC
Comments: 28 pages, 4 figures. Replacement corrects typo in one author name
\\ ( https://arxiv.org/abs/2509.07793 ,  917kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23674
replaced with revised version Wed, 10 Sep 2025 17:59:08 GMT   (471kb)

Title: TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached
  Responses
Authors: Muhammad Taha Cheema, Abeer Aamir, Khawaja Gul Muhammad, Naveed Anwar
  Bhatti, Ihsan Ayyub Qazi, Zafar Ayyub Qazi
Categories: cs.LG cs.CL
Comments: 13 pages, 9 figures
\\ ( https://arxiv.org/abs/2507.23674 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2408.15015
replaced with revised version Wed, 10 Sep 2025 10:59:12 GMT   (835kb)

Title: Alternating Minimization Schemes for Computing
  Rate-Distortion-Perception Functions with $f$-Divergence Perception
  Constraints
Authors: Giuseppe Serra, Photios A. Stavrou, Marios Kountouris
Categories: cs.IT cs.CV eess.SP math.IT
Comments: This work has been submitted for possible publication
\\ ( https://arxiv.org/abs/2408.15015 ,  835kb)
------------------------------------------------------------------------------
\\
arXiv:2501.11260
replaced with revised version Wed, 10 Sep 2025 14:02:23 GMT   (2714kb)

Title: A Survey of World Models for Autonomous Driving
Authors: Tuo Feng, Wenguan Wang, Yi Yang
Categories: cs.RO cs.CV
Comments: Ongoing project. Paper list: https://github.com/FengZicai/AwesomeWMAD
  Benchmark: https://github.com/FengZicai/WMAD-Benchmarks
\\ ( https://arxiv.org/abs/2501.11260 ,  2714kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22943
replaced with revised version Wed, 10 Sep 2025 06:59:24 GMT   (5930kb)

Title: Event Camera Meets Resource-Aware Mobile Computing: Abstraction,
  Algorithm, Acceleration, Application
Authors: Haoyang Wang, Ruishan Guo, Pengtao Ma, Ciyu Ruan, Xinyu Luo, Wenhua
  Ding, Tianyang Zhong, Jingao Xu, Yunhao Liu, Xinlei Chen
Categories: cs.RO cs.CV
Comments: 35 pages
\\ ( https://arxiv.org/abs/2503.22943 ,  5930kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04242
replaced with revised version Tue, 9 Sep 2025 18:58:23 GMT   (957kb)

Title: Task-based Loss Functions in Computer Vision: A Comprehensive Review
Authors: Omar Elharrouss, Yasir Mahmood, Yassine Bechqito, Mohamed Adel
  Serhani, Elarbi Badidi, Jamal Riffi, Hamid Tairi
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2504.04242 ,  957kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06932
replaced with revised version Wed, 10 Sep 2025 14:34:25 GMT   (1812kb)

Title: LLaDA-VLA: Vision Language Diffusion Action Models
Authors: Yuqing Wen, Hebei Li, Kefan Gu, Yucheng Zhao, Tiancai Wang, Xiaoyan
  Sun
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/2509.06932 ,  1812kb)
------------------------------------------------------------------------------
\\
arXiv:2504.07471
replaced with revised version Wed, 10 Sep 2025 01:08:54 GMT   (1287kb)

Title: Traversal Learning: A Lossless And Efficient Distributed Learning
  Framework
Authors: Erdenebileg Batbaatar, Jeonggeol Kim, Yongcheol Kim, Young Yoon
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2504.07471 ,  1287kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
