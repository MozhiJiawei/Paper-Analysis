Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 8004a1 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月15日 11:41
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Thu 11 Sep 25 18:00:00 GMT  to  Fri 12 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.09738
Date: Wed, 10 Sep 2025 18:02:23 GMT   (658kb)

Title: Human-AI Collaboration Increases Efficiency in Regulatory Writing
Authors: Umut Eser, Yael Gozin, L. Jay Stallons, Ari Caroline, Martin Preusse,
  Brandon Rice, Scott Wright, Andrew Robertson
Categories: cs.AI q-bio.QM
ACM-class: I.2.7
\\
  Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.
\\ ( https://arxiv.org/abs/2509.09738 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09775
Date: Thu, 11 Sep 2025 18:12:46 GMT   (611kb)

Title: Executable Ontologies: Synthesizing Event Semantics with Dataflow
  Architecture
Authors: Aleksandr Boldachev
Categories: cs.AI cs.CL cs.FL cs.SE
Comments: 22 pages, 6 figures
\\
  This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.
\\ ( https://arxiv.org/abs/2509.09775 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09790
Date: Thu, 11 Sep 2025 18:51:26 GMT   (2398kb)

Title: How well can LLMs provide planning feedback in grounded environments?
Authors: Yuxuan Li, Victor Zhong
Categories: cs.AI
\\
  Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.
\\ ( https://arxiv.org/abs/2509.09790 ,  2398kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09794
Date: Thu, 11 Sep 2025 18:53:21 GMT   (24242kb)

Title: A Modular and Multimodal Generative AI Framework for Urban Building
  Energy Data: Generating Synthetic Homes
Authors: Jackson Eshbaugh, Chetan Tiwari, Jorge Silveyra
Categories: cs.AI cs.LG
Comments: 44 pages; 2 appendices; 9 figures; 1 table. Code available at
  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes
\\
  Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.
\\ ( https://arxiv.org/abs/2509.09794 ,  24242kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09810
Date: Thu, 11 Sep 2025 19:28:56 GMT   (78kb)

Title: Towards a Common Framework for Autoformalization
Authors: Agnieszka Mensfelt and David Tena Cucala and Santiago Franco and
  Angeliki Koutsoukou-Argyraki and Vince Trencsenyi and Kostas Stathis
Categories: cs.AI
\\
  Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.
\\ ( https://arxiv.org/abs/2509.09810 ,  78kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09848
Date: Thu, 11 Sep 2025 20:58:51 GMT   (1924kb)

Title: Towards an AI-based knowledge assistant for goat farmers based on
  Retrieval-Augmented Generation
Authors: Nana Han, Dong Liu, Tomas Norton
Categories: cs.AI
\\
  Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.
\\ ( https://arxiv.org/abs/2509.09848 ,  1924kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09867
Date: Thu, 11 Sep 2025 21:42:33 GMT   (150kb)

Title: LLMs as Agentic Cooperative Players in Multiplayer UNO
Authors: Yago Romano Matinez, Jesse Roberts
Categories: cs.AI cs.CL
\\
  LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.
\\ ( https://arxiv.org/abs/2509.09867 ,  150kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09915
Date: Fri, 12 Sep 2025 01:14:34 GMT   (613kb)

Title: The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards
  Autonomous Science
Authors: Woong Shin, Renan Souza, Daniel Rosendo, Fr\'ed\'eric Suter, Feiyi
  Wang, Prasanna Balaprakash, Rafael Ferreira da Silva
Categories: cs.AI cs.DC
\\
  Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.
\\ ( https://arxiv.org/abs/2509.09915 ,  613kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09919
Date: Fri, 12 Sep 2025 01:51:01 GMT   (1895kb)

Title: A Markovian Framing of WaveFunctionCollapse for Procedurally Generating
  Aesthetically Complex Environments
Authors: Franklin Yiu, Mohan Lu, Nina Li, Kevin Joseph, Tianxu Zhang, Julian
  Togelius, Timothy Merino, Sam Earle
Categories: cs.AI
\\
  Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.
\\ ( https://arxiv.org/abs/2509.09919 ,  1895kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09982
Date: Fri, 12 Sep 2025 05:52:47 GMT   (236kb)

Title: Evaluation of Black-Box XAI Approaches for Predictors of Values of
  Boolean Formulae
Authors: Stav Armoni-Friedmann, Hana Chockler and David A. Kelly
Categories: cs.AI
Comments: Accepted to ECAI-EXCD Workshop, 8 pages, 2 figures, 5 tables
ACM-class: I.2.4
\\
  Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae
\\ ( https://arxiv.org/abs/2509.09982 ,  236kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10018
Date: Fri, 12 Sep 2025 07:22:49 GMT   (835kb)

Title: GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation
  Enhanced by Domain Rules and Disproof Method
Authors: Hailong Yang, Renhuo Zhao, Guanjin Wang and Zhaohong Deng
Categories: cs.AI
\\
  With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.
\\ ( https://arxiv.org/abs/2509.10018 ,  835kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10054
Date: Fri, 12 Sep 2025 08:40:58 GMT   (620kb)

Title: XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN
  Rules and Multipolar Task Processing Graph
Authors: Hailong Yang, Mingxian Gu, Jianqi Wang, Guanjin Wang and Zhaohong Deng
Categories: cs.AI
\\
  The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.
\\ ( https://arxiv.org/abs/2509.10054 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10104
Date: Fri, 12 Sep 2025 09:52:45 GMT   (313kb)

Title: AI Harmonics: a human-centric and harms severity-adaptive AI risk
  assessment framework
Authors: Sofia Vei, Paolo Giudici, Pavlos Sermpezis, Athena Vakali and Adelaide
  Emma Bernardelli
Categories: cs.AI stat.ME
\\
  The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.
\\ ( https://arxiv.org/abs/2509.10104 ,  313kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10147
Date: Fri, 12 Sep 2025 11:20:11 GMT   (142kb)

Title: Virtual Agent Economies
Authors: Nenad Tomasev, Matija Franklin, Joel Z. Leibo, Julian Jacobs, William
  A. Cunningham, Iason Gabriel, Simon Osindero
Categories: cs.AI
\\
  The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.
\\ ( https://arxiv.org/abs/2509.10147 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10162
Date: Fri, 12 Sep 2025 11:41:23 GMT   (1243kb)

Title: Online Robust Planning under Model Uncertainty: A Sample-Based Approach
Authors: Tamir Shazman, Idan Lev-Yehudi, Ron Benchetit, Vadim Indelman
Categories: cs.AI
\\
  Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.
\\ ( https://arxiv.org/abs/2509.10162 ,  1243kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10210
Date: Fri, 12 Sep 2025 12:56:47 GMT   (292kb)

Title: Towards Fully Automated Molecular Simulations: Multi-Agent Framework for
  Simulation Setup and Force Field Extraction
Authors: Marko Petkovi\'c, Vlado Menkovski, Sof\'ia Calero
Categories: cs.AI cs.MA
\\
  Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.
\\ ( https://arxiv.org/abs/2509.10210 ,  292kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10222
Date: Fri, 12 Sep 2025 13:14:47 GMT   (7128kb)

Title: Compartmentalised Agentic Reasoning for Clinical NLI
Authors: Ma\"el Jullien, Lei Xu, Marco Valentino, Andr\'e Freitas
Categories: cs.AI
\\
  A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.
\\ ( https://arxiv.org/abs/2509.10222 ,  7128kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10249
Date: Fri, 12 Sep 2025 13:46:43 GMT   (404kb)

Title: Investigating Language Model Capabilities to Represent and Process
  Formal Knowledge: A Preliminary Study to Assist Ontology Engineering
Authors: Hanna Abi Akl
Categories: cs.AI
Comments: accepted for the International Joint Conference on Rules and
  Reasoning (RuleML+RR) 2025
\\
  Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.
\\ ( https://arxiv.org/abs/2509.10249 ,  404kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10297
Date: Fri, 12 Sep 2025 14:37:57 GMT   (2074kb)

Title: The Morality of Probability: How Implicit Moral Biases in LLMs May Shape
  the Future of Human-AI Symbiosis
Authors: Eoin O'Doherty, Nicole Weinrauch, Andrew Talone, Uri Klempner,
  Xiaoyuan Yi, Xing Xie, Yi Zeng
Categories: cs.AI
Comments: Work in progress
\\
  Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.
\\ ( https://arxiv.org/abs/2509.10297 ,  2074kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10326
Date: Fri, 12 Sep 2025 15:05:52 GMT   (40kb)

Title: State Algebra for Propositional Logic
Authors: Dmitry Lesnik and Tobias Sch\"afer
Categories: cs.AI cs.LO
Comments: 47 pages
MSC-class: 03G27 (Primary) 68W30, 68T27 (Secondary)
\\
  This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.
\\ ( https://arxiv.org/abs/2509.10326 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10401
Date: Fri, 12 Sep 2025 16:51:15 GMT   (428kb)

Title: Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure
  Attribution in Multi-Agent Systems
Authors: Alva West, Yixuan Weng, Minjun Zhu, Zhen Lin, Yue Zhang
Categories: cs.AI cs.CL
\\
  Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.
\\ ( https://arxiv.org/abs/2509.10401 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10423
Date: Fri, 12 Sep 2025 17:24:20 GMT   (1395kb)

Title: Mutual Information Tracks Policy Coherence in Reinforcement Learning
Authors: Cameron Reid and Wael Hafez and Amirhossein Nazeri
Categories: cs.AI cs.LG cs.RO
Comments: 10 pages, 4 figures, 1 table
\\
  Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.
\\ ( https://arxiv.org/abs/2509.10423 ,  1395kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09699
Date: Thu, 4 Sep 2025 12:01:38 GMT   (2863kb)

Title: Structured Information Matters: Explainable ICD Coding with
  Patient-Level Knowledge Graphs
Authors: Mingyang Li, Viktor Schlegel, Tingting Mu, Warren Del-Pinto, Goran
  Nenadic
Categories: cs.CL cs.AI
\\
  Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.
\\ ( https://arxiv.org/abs/2509.09699 ,  2863kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09700
Date: Thu, 4 Sep 2025 14:37:34 GMT   (451kb)

Title: Cross-Layer Attention Probing for Fine-Grained Hallucination Detection
Authors: Malavika Suresh, Rahaf Aljundi, Ikechukwu Nkisi-Orji, Nirmalie
  Wiratunga
Categories: cs.CL cs.AI
Comments: To be published at the TRUST-AI workshop, ECAI 2025
\\
  With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.
\\ ( https://arxiv.org/abs/2509.09700 ,  451kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09701
Date: Thu, 4 Sep 2025 17:21:36 GMT   (397kb)

Title: Optimal Multi-Task Learning at Regularization Horizon for Speech
  Translation Task
Authors: JungHo Jung and Junhyun Lee
Categories: cs.CL
\\
  End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.
\\ ( https://arxiv.org/abs/2509.09701 ,  397kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09702
Date: Fri, 5 Sep 2025 04:44:29 GMT   (530kb)

Title: Creativity Benchmark: A benchmark for marketing creativity for LLM
  models
Authors: Ninad Bhat, Kieran Browne, Pip Bingemann
Categories: cs.CL cs.AI cs.HC
Comments: 30 Pages, 14 figures
\\
  We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.
\\ ( https://arxiv.org/abs/2509.09702 ,  530kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09703
Date: Fri, 5 Sep 2025 05:59:50 GMT   (3261kb)

Title: CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language
  Models via Cross-Turn Contextual Correlation Backdoor
Authors: Zhenhua Xu, Xixiang Zhao, Xubin Yue, Shengwei Tian, Changting Lin,
  Meng Han
Categories: cs.CL cs.AI
Comments: Accepted by EMNLP2025 MainConference
\\
  The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.
\\ ( https://arxiv.org/abs/2509.09703 ,  3261kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09704
Date: Fri, 5 Sep 2025 16:21:23 GMT   (3223kb)

Title: Temporal Preferences in Language Models for Long-Horizon Assistance
Authors: Ali Mazyaki, Mohammad Naghizadeh, Samaneh Ranjkhah Zonouzaghi, Hossein
  Setareh
Categories: cs.CL cs.AI cs.CY
\\
  We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.
\\ ( https://arxiv.org/abs/2509.09704 ,  3223kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09705
Date: Fri, 5 Sep 2025 17:31:14 GMT   (4127kb)

Title: The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in
  Repetition Trials of Standard Multiple-Choice Benchmarks
Authors: Claudio Pinhanez and Paulo Cavalin and Cassia Sanctos and Marcelo
  Grave and Yago Primerano
Categories: cs.CL cs.AI
\\
  This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.
\\ ( https://arxiv.org/abs/2509.09705 ,  4127kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09708
Date: Sun, 7 Sep 2025 02:29:07 GMT   (3033kb)

Title: Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal
Authors: Nirmalendu Prakash, Yeo Wei Jie, Amir Abdullah, Ranjan Satapathy, Erik
  Cambria, Roy Ka Wei Lee
Categories: cs.CL cs.AI
\\
  Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.
\\ ( https://arxiv.org/abs/2509.09708 ,  3033kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09709
Date: Sun, 7 Sep 2025 10:24:28 GMT   (4174kb)

Title: Assisting Research Proposal Writing with Large Language Models:
  Evaluation and Refinement
Authors: Jing Ren, Weiqi Wang
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.
\\ ( https://arxiv.org/abs/2509.09709 ,  4174kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09710
Date: Sun, 7 Sep 2025 17:03:08 GMT   (1705kb)

Title: Generating Individual Travel Diaries Using Large Language Models
  Informed by Census and Land-Use Data
Authors: Sepehr Golrokh Amin, Devin Rhoads, Fatemeh Fakhrmoosavi, Nicholas E.
  Lownes, and John N. Ivan
Categories: cs.CL cs.AI cs.LG
\\
  This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.
\\ ( https://arxiv.org/abs/2509.09710 ,  1705kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09711
Date: Sun, 7 Sep 2025 20:57:24 GMT   (12395kb)

Title: Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry
Authors: Aya E. Fouda, Abdelrahamn A. Hassan, Radwa J. Hanafy and Mohammed E.
  Fouda
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.
\\ ( https://arxiv.org/abs/2509.09711 ,  12395kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09712
Date: Mon, 8 Sep 2025 02:30:12 GMT   (1103kb)

Title: The Thinking Therapist: Training Large Language Models to Deliver
  Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio
  Policy Optimization
Authors: Talha Tahir
Categories: cs.CL cs.AI
\\
  Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.
\\ ( https://arxiv.org/abs/2509.09712 ,  1103kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09713
Date: Mon, 8 Sep 2025 06:22:38 GMT   (389kb)

Title: HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented
  Generation for Multi-hop Question Answering
Authors: Duolin Sun, Dan Yang, Yue Shen, Yihan Jiao, Zhehao Tan, Jie Feng,
  Lianzhen Zhong, Jian Wang, Peng Wei, Jinjie Gu
Categories: cs.CL cs.AI
\\
  The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.
\\ ( https://arxiv.org/abs/2509.09713 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09714
Date: Mon, 8 Sep 2025 11:00:18 GMT   (95kb)

Title: How Small Transformation Expose the Weakness of Semantic Similarity
  Measures
Authors: Serge Lionel Nikiema, Alb\'erick Euraste Djire, Abdoul Aziz
  Bonkoungou, Micheline B\'en\'edicte Moumoula, Jordan Samhi, Abdoul Kader
  Kabore, Jacques Klein and Tegawend\'e F. Bissyande
Categories: cs.CL cs.AI
\\
  This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.
\\ ( https://arxiv.org/abs/2509.09714 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09715
Date: Tue, 9 Sep 2025 05:50:08 GMT   (625kb)

Title: Investigating Symbolic Triggers of Hallucination in Gemma Models Across
  HaluEval and TruthfulQA
Authors: Naveen Lamba, Sanju Tiwari and Manas Gaur
Categories: cs.CL cs.AI
\\
  Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.
\\ ( https://arxiv.org/abs/2509.09715 ,  625kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09723
Date: Wed, 10 Sep 2025 04:21:02 GMT   (2336kb)

Title: ALIGNS: Unlocking nomological networks in psychological measurement
  through a large language model
Authors: Kai R. Larsen, Sen Yan, Roland M\"uller, Lan Sang, Mikko R\"onkk\"o,
  Ravi Starzl, Donald Edmondson
Categories: cs.CL cs.AI cs.LG stat.ME
ACM-class: I.2.6; J.4; I.5.1; H.3.3; H.2.8
\\
  Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.
\\ ( https://arxiv.org/abs/2509.09723 ,  2336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09724
Date: Wed, 10 Sep 2025 05:47:25 GMT   (1136kb)

Title: DiTTO-LLM: Framework for Discovering Topic-based Technology
  Opportunities via Large Language Model
Authors: Wonyoung Kim and Sujeong Seo and Juhyun Lee
Categories: cs.CL cs.AI cs.LG
Comments: 5 figures
MSC-class: 68T09
\\
  Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.
\\ ( https://arxiv.org/abs/2509.09724 ,  1136kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09725
Date: Wed, 10 Sep 2025 09:14:25 GMT   (188kb)

Title: BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025
Authors: Chunyu Li, Xindi Zheng, Siqi Liu
Categories: cs.CL
\\
  Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.
\\ ( https://arxiv.org/abs/2509.09725 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09726
Date: Wed, 10 Sep 2025 09:22:12 GMT   (3430kb)

Title: Natural Language Translation of Formal Proofs through Informalization of
  Proof Steps and Recursive Summarization along Proof Structure
Authors: Seiji Hattori, Takuya Matsuzaki, Makoto Fujiwara
Categories: cs.CL
Comments: Submitted to INLG 2025 (accepted)
\\
  This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.
\\ ( https://arxiv.org/abs/2509.09726 ,  3430kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09727
Date: Wed, 10 Sep 2025 09:40:18 GMT   (1167kb)

Title: A Role-Aware Multi-Agent Framework for Financial Education Question
  Answering with LLMs
Authors: Andy Zhu, Yingjun Du
Categories: cs.CL cs.CE
Comments: 8 pages, 6 figures, Underreview
\\
  Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.
\\ ( https://arxiv.org/abs/2509.09727 ,  1167kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09728
Date: Wed, 10 Sep 2025 10:05:32 GMT   (226kb)

Title: A meta-analysis on the performance of machine-learning based language
  models for sentiment analysis
Authors: Elena Rohde, Jonas Klingwort, Christian Borgs
Categories: cs.CL cs.LG stat.AP
\\
  This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.
\\ ( https://arxiv.org/abs/2509.09728 ,  226kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09729
Date: Wed, 10 Sep 2025 11:14:54 GMT   (2304kb)

Title: MultimodalHugs: Enabling Sign Language Processing in Hugging Face
Authors: Gerard Sant, Zifan Jiang, Carlos Escolano, Amit Moryossef, Mathias
  M\"uller, Rico Sennrich, Sarah Ebling
Categories: cs.CL cs.AI cs.MM
\\
  In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.
\\ ( https://arxiv.org/abs/2509.09729 ,  2304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09731
Date: Wed, 10 Sep 2025 13:02:29 GMT   (38960kb)

Title: Benchmarking Vision-Language Models on Chinese Ancient Documents: From
  OCR to Knowledge Reasoning
Authors: Haiyang Yu, Yuchuan Wu, Fan Shi, Lei Liao, Jinghui Lu, Xiaodong Ge,
  Han Wang, Minghan Zhuo, Xuecheng Wu, Xiang Fei, Hao Feng, Guozhi Tang, An-Lan
  Wang, Hanshen Zhu, Yangfan He, Quanhuan Liang, Liyuan Meng, Chao Feng, Can
  Huang, Jingqun Tang, Bin Li
Categories: cs.CL
\\
  Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.
\\ ( https://arxiv.org/abs/2509.09731 ,  38960kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09734
Date: Wed, 10 Sep 2025 14:08:40 GMT   (1575kb)

Title: MCP-AgentBench: Evaluating Real-World Language Agent Performance with
  MCP-Mediated Tools
Authors: Zikang Guo, Benfeng Xu, Chiwei Zhu, Wentao Hong, Xiaorui Wang,
  Zhendong Mao
Categories: cs.CL cs.AI cs.LG
\\
  The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.
\\ ( https://arxiv.org/abs/2509.09734 ,  1575kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09735
Date: Wed, 10 Sep 2025 14:25:09 GMT   (1546kb)

Title: Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in
  Decision-Making and Summarisation
Authors: Willem Huijzer and Jieying Chen
Categories: cs.CL
Comments: 7 pages
\\
  The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.
\\ ( https://arxiv.org/abs/2509.09735 ,  1546kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09801
Date: Thu, 11 Sep 2025 19:06:46 GMT   (22kb)

Title: HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and
  Accuracy of Language Model Reasoning
Authors: Brennen Hill
Categories: cs.CL cs.AI cs.LG
MSC-class: 68T07, 68T50, 68T05
ACM-class: I.2.7; I.2.6; C.4
\\
  The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.
\\ ( https://arxiv.org/abs/2509.09801 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09804
Date: Thu, 11 Sep 2025 19:14:57 GMT   (1038kb)

Title: Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to
  Multimodality in Turn Organization
Authors: Helen de Andrade Abreu, Tiago Timponi Torrent, Ely Edison da Silva
  Matos
Categories: cs.CL
Comments: Paper submitted to Language Sciences Journal
\\
  This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.
\\ ( https://arxiv.org/abs/2509.09804 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09852
Date: Thu, 11 Sep 2025 21:01:54 GMT   (322kb)

Title: Topic-Guided Reinforcement Learning with LLMs for Enhancing
  Multi-Document Summarization
Authors: Chuyuan Li, Austin Xu, Shafiq Joty, Giuseppe Carenini
Categories: cs.CL
\\
  A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.
\\ ( https://arxiv.org/abs/2509.09852 ,  322kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09871
Date: Thu, 11 Sep 2025 21:43:59 GMT   (48kb)

Title: Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic
  Survey Responses for the Chilean Case
Authors: Basti\'an Gonz\'alez-Bustamante, Nando Verelst, Carla Cisternas
Categories: cs.CL cs.AI
Comments: Working paper: 18 pages, 4 tables, 2 figures
MSC-class: 68T50 (Primary) 91F10 (Secondary)
\\
  Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.
\\ ( https://arxiv.org/abs/2509.09871 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09969
Date: Fri, 12 Sep 2025 05:08:11 GMT   (3917kb)

Title: Large Language Models Meet Legal Artificial Intelligence: A Survey
Authors: Zhitian Hou, Zihan Ye, Nanli Zeng, Tianyong Hao, Kun Zeng
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.
\\ ( https://arxiv.org/abs/2509.09969 ,  3917kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09990
Date: Fri, 12 Sep 2025 06:18:44 GMT   (6921kb)

Title: CMHG: A Dataset and Benchmark for Headline Generation of Minority
  Languages in China
Authors: Guixian Xu, Zeli Su, Ziyin Zhang, Jianing Liu, XU Han, Ting Zhang and
  Yushuang Dong
Categories: cs.CL
\\
  Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.
\\ ( https://arxiv.org/abs/2509.09990 ,  6921kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10004
Date: Fri, 12 Sep 2025 06:58:17 GMT   (3252kb)

Title: Unsupervised Hallucination Detection by Inspecting Reasoning Processes
Authors: Ponhvoan Srey, Xiaobao Wu, Anh Tuan Luu
Categories: cs.CL cs.AI
Comments: To appear in EMNLP 2025
\\
  Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.
\\ ( https://arxiv.org/abs/2509.10004 ,  3252kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10010
Date: Fri, 12 Sep 2025 07:10:55 GMT   (139kb)

Title: Multi-Intent Recognition in Dialogue Understanding: A Comparison Between
  Smaller Open-Source LLMs
Authors: Adnan Ahmad, Philine Kowol, Stefan Hillmann, Sebastian M\"oller
Categories: cs.CL cs.HC
\\
  In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.
\\ ( https://arxiv.org/abs/2509.10010 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10035
Date: Fri, 12 Sep 2025 08:02:38 GMT   (2585kb)

Title: Linguistic trajectories of bipolar disorder on social media
Authors: Laurin Plank and Armin Zlomuzica
Categories: cs.CL
Comments: Pre-print
\\
  Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.
\\ ( https://arxiv.org/abs/2509.10035 ,  2585kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10040
Date: Fri, 12 Sep 2025 08:08:45 GMT   (509kb)

Title: !MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for
  Readability Assessment
Authors: Mohamed Basem, Mohamed Younes, Seif Ahmed, Abdelrahman Moustafa
Categories: cs.CL
Comments: 10 Pages , 8 figures , ArabicNLP 2025 , Co-located with EMNLP 2025
\\
  We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.
\\ ( https://arxiv.org/abs/2509.10040 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10078
Date: Fri, 12 Sep 2025 09:14:42 GMT   (519kb)

Title: Established Psychometric vs. Ecologically Valid Questionnaires:
  Rethinking Psychological Assessments in Large Language Models
Authors: Dongmin Choi, Woojung Song, Jongwook Han, Eun-Ju Lee, Yohan Jo
Categories: cs.CL cs.AI
Comments: 17 pages, 4 figures
\\
  Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.
\\ ( https://arxiv.org/abs/2509.10078 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10087
Date: Fri, 12 Sep 2025 09:28:29 GMT   (1065kb)

Title: Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery
Authors: Mustapha Adamu, Qi Zhang, Huitong Pan, Longin Jan Latecki, Eduard C.
  Dragut
Categories: cs.CL
Comments: ACM SIGIR 2025 Workshop MANILA
\\
  The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.
\\ ( https://arxiv.org/abs/2509.10087 ,  1065kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10095
Date: Fri, 12 Sep 2025 09:37:26 GMT   (168kb)

Title: Arabic Large Language Models for Medical Text Generation
Authors: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Ammar Mohammed
Categories: cs.CL
Comments: Published in 2025 4th International Conference on Computer
  Technologies (ICCTech)
\\
  Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.
\\ ( https://arxiv.org/abs/2509.10095 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10108
Date: Fri, 12 Sep 2025 09:58:11 GMT   (289kb)

Title: Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing
  Generative AI with Synthetic Patient Records
Authors: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Khaled Shaban
Categories: cs.CL
Comments: Accepted in AICCSA 2025
\\
  The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.
\\ ( https://arxiv.org/abs/2509.10108 ,  289kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10116
Date: Fri, 12 Sep 2025 10:18:38 GMT   (110kb)

Title: Prominence-aware automatic speech recognition for conversational speech
Authors: Julian Linke and Barbara Schuppler
Categories: cs.CL eess.AS
\\
  This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.
\\ ( https://arxiv.org/abs/2509.10116 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10127
Date: Fri, 12 Sep 2025 10:43:47 GMT   (1711kb)

Title: Population-Aligned Persona Generation for LLM-based Social Simulation
Authors: Zhengyu Hu, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu Wang, Jianxun
  Lian, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie
Categories: cs.CL cs.AI cs.LG
\\
  Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.
\\ ( https://arxiv.org/abs/2509.10127 ,  1711kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10129
Date: Fri, 12 Sep 2025 10:44:24 GMT   (1880kb)

Title: Towards Reliable and Interpretable Document Question Answering via VLMs
Authors: Alessio Chen, Simone Giovannini, Andrea Gemelli, Fabio Coppini, Simone
  Marinai
Categories: cs.CL cs.IR
\\
  Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.
\\ ( https://arxiv.org/abs/2509.10129 ,  1880kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10179
Date: Fri, 12 Sep 2025 12:12:20 GMT   (780kb)

Title: Benchmark of stylistic variation in LLM-generated texts
Authors: Ji\v{r}\'i Mili\v{c}ka, Anna Marklov\'a, V\'aclav Cvr\v{c}ek
Categories: cs.CL cs.AI
\\
  This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.
\\ ( https://arxiv.org/abs/2509.10179 ,  780kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10184
Date: Fri, 12 Sep 2025 12:25:02 GMT   (311kb)

Title: Incongruent Positivity: When Miscalibrated Positivity Undermines Online
  Supportive Conversations
Authors: Leen Almajed, Abeer ALdayel
Categories: cs.CL
Comments: This paper is under review
\\
  In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.
\\ ( https://arxiv.org/abs/2509.10184 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10199
Date: Fri, 12 Sep 2025 12:47:28 GMT   (1952kb)

Title: Beyond Token Limits: Assessing Language Model Performance on Long Text
  Classification
Authors: Mikl\'os Seb\H{o}k, Viktor Kov\'acs, Martin B\'an\'oczy, Daniel
  M{\o}ller Eriksen, Nathalie Neptune, Philippe Roussille
Categories: cs.CL
ACM-class: I.7; I.2; J.4
\\
  The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.
\\ ( https://arxiv.org/abs/2509.10199 ,  1952kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10208
Date: Fri, 12 Sep 2025 12:56:14 GMT   (2178kb)

Title: SI-FACT: Mitigating Knowledge Conflict via Self-Improving
  Faithfulness-Aware Contrastive Tuning
Authors: Shengqiang Fu
Categories: cs.CL cs.AI
\\
  Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.
\\ ( https://arxiv.org/abs/2509.10208 ,  2178kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10377
Date: Fri, 12 Sep 2025 16:09:39 GMT   (2491kb)

Title: Dropping Experts, Recombining Neurons: Retraining-Free Pruning for
  Sparse Mixture-of-Experts LLMs
Authors: Yixiao Zhou, Ziyu Zhao, Dongzhou Cheng, zhiliang wu, Jie Gui, Yi Yang,
  Fei Wu, Yu Cheng, Hehe Fan
Categories: cs.CL
Comments: Accepted to EMNLP2025
\\
  Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.
\\ ( https://arxiv.org/abs/2509.10377 ,  2491kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10414
Date: Fri, 12 Sep 2025 17:12:04 GMT   (11260kb)

Title: Is In-Context Learning Learning?
Authors: Adrian de Wynter
Categories: cs.CL cs.AI cs.LG
Comments: Director's cut
\\
  In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.
\\ ( https://arxiv.org/abs/2509.10414 ,  11260kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10417
Date: Fri, 12 Sep 2025 17:13:47 GMT   (20kb)

Title: Long Context Automated Essay Scoring with Language Models
Authors: Christopher Ormerod and Gitit Kehat
Categories: cs.CL
Comments: 8 pages, 2 figures, 2 tables
\\
  Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.
\\ ( https://arxiv.org/abs/2509.10417 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10436
Date: Fri, 12 Sep 2025 17:44:22 GMT   (7882kb)

Title: RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question
  Solutions in Cloud and Edge Deployment
Authors: Shadikur Rahman, Aroosa Hameed, Gautam Srivastava, Syed Muhammad
  Danish
Categories: cs.CL
Comments: 12 pages, 5 figures, submitted to IEEE Transactions on Services
  Computing
\\
  To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.
\\ ( https://arxiv.org/abs/2509.10436 ,  7882kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10446
Date: Fri, 12 Sep 2025 17:52:35 GMT   (987kb)

Title: DeepDive: Advancing Deep Search Agents with Knowledge Graphs and
  Multi-Turn RL
Authors: Rui Lu, Zhenyu Hou, Zihan Wang, Hanchen Zhang, Xiao Liu, Yujiang Li,
  Shi Feng, Jie Tang, Yuxiao Dong
Categories: cs.CL
\\
  Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.
\\ ( https://arxiv.org/abs/2509.10446 ,  987kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10452
Date: Fri, 12 Sep 2025 17:59:09 GMT   (366kb)

Title: WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained
  Speech Recognition Transformers
Authors: Akshat Pandey, Karun Kumar, Raphael Tang
Categories: cs.CL cs.LG
Comments: 5 pages, 2 figures
\\
  Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.
\\ ( https://arxiv.org/abs/2509.10452 ,  366kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09720
Date: Tue, 9 Sep 2025 22:26:01 GMT   (3390kb)

Title: Australian Supermarket Object Set (ASOS): A Benchmark Dataset of
  Physical Objects and 3D Models for Robotics and Computer Vision
Authors: Akansel Cosgun, Lachlan Chumbley, Benjamin J. Meyer
Categories: cs.CV cs.RO eess.IV
\\
  This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.
\\ ( https://arxiv.org/abs/2509.09720 ,  3390kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09721
Date: Wed, 10 Sep 2025 01:58:07 GMT   (1039kb)

Title: A Multimodal RAG Framework for Housing Damage Assessment: Collaborative
  Optimization of Image Encoding and Policy Vector Retrieval
Authors: Jiayi Miao, Dingxin Lu, Zhuqi Wang
Categories: cs.CV cs.AI cs.LG
\\
  After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.
\\ ( https://arxiv.org/abs/2509.09721 ,  1039kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09722
Date: Wed, 10 Sep 2025 03:18:24 GMT   (2430kb)

Title: Improving MLLM Historical Record Extraction with Test-Time Image
Authors: Taylor Archibald and Tony Martinez
Categories: cs.CV cs.CL cs.LG
\\
  We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.
\\ ( https://arxiv.org/abs/2509.09722 ,  2430kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09730
Date: Wed, 10 Sep 2025 12:07:34 GMT   (9524kb)

Title: MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic
  Surveillance
Authors: Kaikai Zhao, Zhaoxiang Liu, Peng Wang, Xin Wang, Zhicheng Ma, Yajun
  Xu, Wenjing Zhang, Yibing Nan, Kai Wang, Shiguo Lian
Categories: cs.CV cs.AI
Comments: accepted by Image and Vision Computing
\\
  General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.
\\ ( https://arxiv.org/abs/2509.09730 ,  9524kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09732
Date: Wed, 10 Sep 2025 13:08:03 GMT   (136kb)

Title: Decomposing Visual Classification: Assessing Tree-Based Reasoning in
  VLMs
Authors: Sary Elmansoury, Islam Mesabah, Gerrit Gro{\ss}mann, Peter Neigel, Raj
  Bhalwankar, Daniel Kondermann, Sebastian J. Vollmer
Categories: cs.CV
\\
  Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.
\\ ( https://arxiv.org/abs/2509.09732 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09737
Date: Wed, 10 Sep 2025 18:01:04 GMT   (4112kb)

Title: World Modeling with Probabilistic Structure Integration
Authors: Klemen Kotar, Wanhee Lee, Rahul Venkatesh, Honglin Chen, Daniel Bear,
  Jared Watrous, Simon Kim, Khai Loong Aw, Lilian Naing Chen, Stefan Stojanov,
  Kevin Feigelis, Imran Thobani, Alex Durango, Khaled Jedoui, Atlas Kazemian,
  and Dan Yamins
Categories: cs.CV cs.AI cs.LG
\\
  We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.
\\ ( https://arxiv.org/abs/2509.09737 ,  4112kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09742
Date: Thu, 11 Sep 2025 04:34:42 GMT   (1516kb)

Title: Images in Motion?: A First Look into Video Leakage in Collaborative Deep
  Learning
Authors: Md Fazle Rasul, Alanood Alqobaisi, Bruhadeshwar Bezawada, and
  Indrakshi Ray
Categories: cs.CV
\\
  Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.
\\ ( https://arxiv.org/abs/2509.09742 ,  1516kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09750
Date: Thu, 11 Sep 2025 13:40:43 GMT   (2133kb)

Title: A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO
  Networks for Object Detection in Densely Packed Retail Images
Authors: Hossein Yazdanjouei, Arash Mansouri, Mohammad Shokouhifar
Categories: cs.CV cs.AI
\\
  This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.
\\ ( https://arxiv.org/abs/2509.09750 ,  2133kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09785
Date: Thu, 11 Sep 2025 18:33:40 GMT   (526kb)

Title: Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds
  Classification via Token Purging
Authors: Moslem Yazdanpanah, Ali Bahri, Mehrdad Noori, Sahar Dastani, Gustavo
  Adolfo Vargas Hakim, David Osowiechi, Ismail Ben Ayed, and Christian
  Desrosiers
Categories: cs.CV
\\
  Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}
\\ ( https://arxiv.org/abs/2509.09785 ,  526kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09792
Date: Thu, 11 Sep 2025 18:52:16 GMT   (42817kb)

Title: Fine-Grained Cross-View Localization via Local Feature Matching and
  Monocular Depth Priors
Authors: Zimin Xia, Chenghao Xu, Alexandre Alahi
Categories: cs.CV
\\
  We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.
\\ ( https://arxiv.org/abs/2509.09792 ,  42817kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09808
Date: Thu, 11 Sep 2025 19:27:57 GMT   (1182kb)

Title: Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye
  Reflex Test
Authors: Judith Massmann, Alexander Lichtenstein, Francisco M. L\'opez
Categories: cs.CV cs.LG
Comments: Accepted at IEEE ICDL 2025. 6 pages, 7 figures, 2 tables
\\
  Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.
\\ ( https://arxiv.org/abs/2509.09808 ,  1182kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09828
Date: Thu, 11 Sep 2025 20:03:00 GMT   (29918kb)

Title: DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception
Authors: Tim Broedermannn, Christos Sakaridis, Luigi Piccinelli, Wim Abbeloos,
  and Luc Van Gool
Categories: cs.CV cs.LG cs.RO
Comments: Code and models will be available at
  https://github.com/timbroed/DGFusion
\\
  Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion
\\ ( https://arxiv.org/abs/2509.09828 ,  29918kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09841
Date: Thu, 11 Sep 2025 20:44:13 GMT   (3488kb)

Title: Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning
  Framework
Authors: Chengyu Yang, Rishik Reddy Yesgari, Chengjun Liu
Categories: cs.CV
\\
  Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.
\\ ( https://arxiv.org/abs/2509.09841 ,  3488kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09844
Date: Thu, 11 Sep 2025 20:54:26 GMT   (693kb)

Title: Privacy-Preserving Automated Rosacea Detection Based on Medically
  Inspired Region of Interest Selection
Authors: Chengyu Yang, Rishik Reddy Yesgari, Chengjun Liu
Categories: cs.CV
\\
  Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.
\\ ( https://arxiv.org/abs/2509.09844 ,  693kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09849
Date: Thu, 11 Sep 2025 20:58:52 GMT   (1766kb)

Title: Investigating the Impact of Various Loss Functions and Learnable Wiener
  Filter for Laparoscopic Image Desmoking
Authors: Chengyu Yang, Chengjun Liu
Categories: cs.CV
\\
  To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.
\\ ( https://arxiv.org/abs/2509.09849 ,  1766kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09859
Date: Thu, 11 Sep 2025 21:18:32 GMT   (2043kb)

Title: WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector
Authors: Razvan Stefanescu and Ethan Oh and Ruben Vazquez and Chris Mesterharm
  and Constantin Serban and Ritu Chadha
Categories: cs.CV cs.LG
Comments: 11 pages, 11 figures
MSC-class: 68W99
\\
  We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.
\\ ( https://arxiv.org/abs/2509.09859 ,  2043kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09869
Date: Thu, 11 Sep 2025 21:43:45 GMT   (3403kb)

Title: Surrogate Supervision for Robust and Generalizable Deformable Image
  Registration
Authors: Yihao Liu, Junyu Chen, Lianrui Zuo, Shuwen Wei, Brian D. Boyd, Carmen
  Andreescu, Olusola Ajilore, Warren D. Taylor, Aaron Carass, Bennett A.
  Landman
Categories: cs.CV cs.AI
\\
  Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.
\\ ( https://arxiv.org/abs/2509.09869 ,  3403kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09911
Date: Fri, 12 Sep 2025 00:54:07 GMT   (13931kb)

Title: An Autoencoder and Vision Transformer-based Interpretability Analysis of
  the Differences in Automated Staging of Second and Third Molars
Authors: Barkin Buyukcakir, Jannick De Tobel, Patrick Thevissen, Dirk
  Vandermeulen, Peter Claes
Categories: cs.CV cs.AI
Comments: 21 pages, 11 figures, Scientific Reports
MSC-class: 68T07 (Primary)
\\
  The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.
\\ ( https://arxiv.org/abs/2509.09911 ,  13931kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09935
Date: Fri, 12 Sep 2025 02:53:03 GMT   (1704kb)

Title: SCoDA: Self-supervised Continual Domain Adaptation
Authors: Chirayu Agrawal and Snehasis Mukherjee
Categories: cs.CV
Comments: Submitted to ICVGIP 2025
\\
  Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.
\\ ( https://arxiv.org/abs/2509.09935 ,  1704kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09943
Date: Fri, 12 Sep 2025 03:19:35 GMT   (7011kb)

Title: Segment Anything for Cell Tracking
Authors: Zhu Chen, Mert Edg\"u, Er Jin, Johannes Stegmaier
Categories: cs.CV
\\
  Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.
\\ ( https://arxiv.org/abs/2509.09943 ,  7011kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09946
Date: Fri, 12 Sep 2025 03:28:35 GMT   (1551kb)

Title: Online 3D Multi-Camera Perception through Robust 2D Tracking and
  Depth-based Late Aggregation
Authors: Vu-Minh Le, Thao-Anh Tran, Duc Huy Do, Xuan Canh Do, Huong Ninh, Hai
  Tran
Categories: cs.CV
Comments: Accepted at ICCVW 2025
\\
  Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.
\\ ( https://arxiv.org/abs/2509.09946 ,  1551kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09958
Date: Fri, 12 Sep 2025 04:32:52 GMT   (721kb)

Title: Zero-Shot Referring Expression Comprehension via Visual-Language
  True/False Verification
Authors: Jeffrey Liu and Rongbin Hu
Categories: cs.CV cs.AI
\\
  Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.
\\ ( https://arxiv.org/abs/2509.09958 ,  721kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09961
Date: Fri, 12 Sep 2025 04:38:32 GMT   (734kb)

Title: Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and
  Pest Segmentation
Authors: Tianqi Wei, Xin Yu, Zhi Chen, Scott Chapman, Zi Huang
Categories: cs.CV
\\
  Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.
\\ ( https://arxiv.org/abs/2509.09961 ,  734kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09962
Date: Fri, 12 Sep 2025 04:39:38 GMT   (8336kb)

Title: An HMM-based framework for identity-aware long-term multi-object
  tracking from sparse and uncertain identification: use case on long-term
  tracking in livestock
Authors: Anne Marthe Sophie Ngo Bibinbe, Chiron Bang, Patrick Gagnon, Jamie
  Ahloy-Dallaire, Eric R. Paquet
Categories: cs.CV
Comments: 13 pages, 7 figures, 1 table, accepted at CVPR animal workshop 2024,
  submitted to IJCV
\\
  The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking
\\ ( https://arxiv.org/abs/2509.09962 ,  8336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09971
Date: Fri, 12 Sep 2025 05:16:54 GMT   (2308kb)

Title: Event Camera Guided Visual Media Restoration & 3D Reconstruction: A
  Survey
Authors: Aupendu Kar, Vishnu Raj, Guan-Ming Su
Categories: cs.CV
\\
  Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.
\\ ( https://arxiv.org/abs/2509.09971 ,  2308kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09977
Date: Fri, 12 Sep 2025 05:37:17 GMT   (5734kb)

Title: ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking
Authors: Siying Liu, Zikai Wang, Hanle Zheng, Yifan Hu, Xilin Wang, Qingkai
  Yang, Jibin Wu, Hao Guo, Lei Deng
Categories: cs.CV
Comments: 15 pages, 8 figures
\\
  RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.
\\ ( https://arxiv.org/abs/2509.09977 ,  5734kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09988
Date: Fri, 12 Sep 2025 06:09:09 GMT   (9150kb)

Title: FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for
  72-Hour Solar Flare Prediction
Authors: Yusuke Takagi, Shunya Nagashima, and Komei Sugiura
Categories: cs.CV astro-ph.SR
Comments: Accepted for presentation at ICONIP2025
\\
  Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.
\\ ( https://arxiv.org/abs/2509.09988 ,  9150kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10005
Date: Fri, 12 Sep 2025 07:02:45 GMT   (3614kb)

Title: TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal
  Feature Extraction and Cross-Modal Feature Fusion
Authors: Xiaodong Guo, Tong Liu, Yike Li, Zi'ang Lin, Zhihong Deng
Categories: cs.CV
\\
  RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.
\\ ( https://arxiv.org/abs/2509.10005 ,  3614kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10006
Date: Fri, 12 Sep 2025 07:04:25 GMT   (1733kb)

Title: Few-Part-Shot Font Generation
Authors: Masaki Akiba, Shumpei Takezaki, Daichi Haraguchi, and Seiichi Uchida
Categories: cs.CV
Comments: ICDAR 2025 Workshop on Machine Learning
\\
  This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.
\\ ( https://arxiv.org/abs/2509.10006 ,  1733kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10021
Date: Fri, 12 Sep 2025 07:30:24 GMT   (9192kb)

Title: Efficient and Accurate Downfacing Visual Inertial Odometry
Authors: Jonas K\"uhne, Christian Vogt, Michele Magno, Luca Benini
Categories: cs.CV cs.RO eess.IV
Comments: This article has been accepted for publication in the IEEE Internet
  of Things Journal (IoT-J)
DOI: 10.1109/JIOT.2025.3609011
\\
  Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.
\\ ( https://arxiv.org/abs/2509.10021 ,  9192kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10024
Date: Fri, 12 Sep 2025 07:42:27 GMT   (26991kb)

Title: Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction
  From Single Images
Authors: Danling Cao
Categories: cs.CV
Comments: This work was completed during the author's MPhil studies at the
  University of Manchester
\\
  Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.
\\ ( https://arxiv.org/abs/2509.10024 ,  26991kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10026
Date: Fri, 12 Sep 2025 07:45:44 GMT   (10032kb)

Title: LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization
  for Real-World Multilingual VQA
Authors: Jing Huang, Zhiya Tan, Shutao Gong, Fanwei Zeng, Jianshu Li
Categories: cs.CV
Comments: 12 Pages, 12 Figures, 2 Tables
\\
  As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}
\\ ( https://arxiv.org/abs/2509.10026 ,  10032kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10058
Date: Fri, 12 Sep 2025 08:44:22 GMT   (54697kb)

Title: Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings
  for Improved Diffusion Generation
Authors: Sung-Lin Tsai, Bo-Lun Huang, Yu Ting Shen, Cheng Yu Yeo, Chiang Tseng,
  Bo-Kai Ruan, Wen-Sheng Lien, Hong-Han Shuai
Categories: cs.CV
Comments: Accepted to ACM Multimedia 2025 (MM '25)
DOI: 10.1145/3746027.3755385
\\
  Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.
\\ ( https://arxiv.org/abs/2509.10058 ,  54697kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10059
Date: Fri, 12 Sep 2025 08:46:49 GMT   (8188kb)

Title: Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery:
  Benchmarking, Analysis, and Exploration
Authors: Yue Zhou, Litong Feng, Mengcheng Lan, Xue Yang, Qingyun Li, Yiping Ke,
  Xue Jiang, Wayne Zhang
Categories: cs.CV cs.AI
Comments: 17 pages, 16 figures
\\
  Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math
\\ ( https://arxiv.org/abs/2509.10059 ,  8188kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10080
Date: Fri, 12 Sep 2025 09:17:54 GMT   (4837kb)

Title: BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View
  with Deformable Attention and Sparse Goal Proposals
Authors: Minsang Kong, Myeongjun Kim, Sang Gu Kang, Sang Hun Lee
Categories: cs.CV
Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems
  (under review)
ACM-class: I.2.9; I.4.8
\\
  In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.
\\ ( https://arxiv.org/abs/2509.10080 ,  4837kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10093
Date: Fri, 12 Sep 2025 09:36:23 GMT   (10349kb)

Title: Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human
  Parsing
Authors: Laura Bragagnolo, Matteo Terreran, Leonardo Barcellona and Stefano
  Ghidoni
Categories: cs.CV
Comments: ICIAP 2025
\\
  Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.
\\ ( https://arxiv.org/abs/2509.10093 ,  10349kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10105
Date: Fri, 12 Sep 2025 09:55:56 GMT   (99kb)

Title: VARCO-VISION-2.0 Technical Report
Authors: Young-rok Cha, Jeongho Ju, SunYoung Park, Jong-Hyeon Lee, Younghyun
  Yu, Youngjune Kim
Categories: cs.CV cs.CL
Comments: 19 pages, 1 figure, 14 tables. Technical report for VARCO-VISION-2.0,
  a Korean-English bilingual VLM in 14B and 1.7B variants. Key features:
  multi-image understanding, OCR with text localization, improved Korean
  capabilities
\\
  We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.
\\ ( https://arxiv.org/abs/2509.10105 ,  99kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10114
Date: Fri, 12 Sep 2025 10:13:38 GMT   (1352kb)

Title: A Lightweight Ensemble-Based Face Image Quality Assessment Method with
  Correlation-Aware Loss
Authors: MohammadAli Hamidi, Hadi Amirpour, Luigi Atzori, Christian Timmerer
Categories: cs.CV
\\
  Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.
\\ ( https://arxiv.org/abs/2509.10114 ,  1352kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10122
Date: Fri, 12 Sep 2025 10:32:04 GMT   (10006kb)

Title: Realism Control One-step Diffusion for Real-World Image Super-Resolution
Authors: Zongliang Wu, Siming Zheng, Peng-Tao Jiang, and Xin Yuan
Categories: cs.CV cs.AI
\\
  Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.
\\ ( https://arxiv.org/abs/2509.10122 ,  10006kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10134
Date: Fri, 12 Sep 2025 10:51:46 GMT   (4725kb)

Title: Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature
  Disalignment
Authors: Rini Smita Thakur, Rajeev Ranjan Dwivedi, Vinod K Kurmi
Categories: cs.CV
Comments: Accepted in BMVC 2025
\\
  Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.
\\ ( https://arxiv.org/abs/2509.10134 ,  4725kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10140
Date: Fri, 12 Sep 2025 11:08:21 GMT   (20453kb)

Title: Scalable Training for Vector-Quantized Networks with 100% Codebook
  Utilization
Authors: Yifan Chang, Jie Qin, Limeng Qiao, Xiaofeng Wang, Zheng Zhu, Lin Ma,
  Xingang Wang
Categories: cs.CV
\\
  Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.
\\ ( https://arxiv.org/abs/2509.10140 ,  20453kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10156
Date: Fri, 12 Sep 2025 11:32:51 GMT   (2071kb)

Title: LayerLock: Non-collapsing Representation Learning with Progressive
  Freezing
Authors: Goker Erdogan, Nikhil Parthasarathy, Catalin Ionescu, Drew Hudson,
  Alexander Lerchner, Andrew Zisserman, Mehdi Sajjadi, Joao Carreira
Categories: cs.CV
Comments: ICCV 2025
\\
  We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.
\\ ( https://arxiv.org/abs/2509.10156 ,  2071kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10241
Date: Fri, 12 Sep 2025 13:37:18 GMT   (13157kb)

Title: On the Geometric Accuracy of Implicit and Primitive-based
  Representations Derived from View Rendering Constraints
Authors: Elias De Smijter, Renaud Detry and Christophe De Vleeschouwer
Categories: cs.CV
Comments: 9 pages, 3 figures, to be presented at ASTRA25,
\\
  We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.
\\ ( https://arxiv.org/abs/2509.10241 ,  13157kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10250
Date: Fri, 12 Sep 2025 13:46:54 GMT   (3123kb)

Title: GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented
  Training for AI-Generated Image Detection
Authors: Haozhen Yan, Yan Hong, Suning Lang, Jiahui Zhan, Yikun Ji, Yujie Gao,
  Jun Lan, Huijia Zhu, Weiqiang Wang, Jianfu Zhang
Categories: cs.CV
Comments: 11 pages, 5 figures
\\
  With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.
\\ ( https://arxiv.org/abs/2509.10250 ,  3123kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10257
Date: Fri, 12 Sep 2025 13:59:23 GMT   (6638kb)

Title: Robustness and Diagnostic Performance of Super-Resolution Fetal Brain
  MRI
Authors: Ema Masterl, Tina Vipotnik Vesnaver, \v{Z}iga \v{S}piclin
Categories: cs.CV
Comments: Accepted at the PIPPI Workshop of MICCAI 2025
\\
  Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.
\\ ( https://arxiv.org/abs/2509.10257 ,  6638kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10259
Date: Fri, 12 Sep 2025 14:02:52 GMT   (3501kb)

Title: Mask Consistency Regularization in Object Removal
Authors: Hua Yuan, Jin Yuan, Yicheng Jiang, Yao Zhang, Xin Geng, Yong Rui
Categories: cs.CV
\\
  Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.
\\ ( https://arxiv.org/abs/2509.10259 ,  3501kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10260
Date: Fri, 12 Sep 2025 14:03:00 GMT   (2492kb)

Title: MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained
  Artifacts Assessment in Text-to-Image Generation
Authors: Jia Wang, Jie Hu, Xiaoqi Ma, Hanghang Ma, Yanbing Zeng, Xiaoming Wei
Categories: cs.CV
\\
  Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.
\\ ( https://arxiv.org/abs/2509.10260 ,  2492kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10266
Date: Fri, 12 Sep 2025 14:08:06 GMT   (775kb)

Title: SignClip: Leveraging Mouthing Cues for Sign Language Translation by
  Multimodal Contrastive Fusion
Authors: Wenfang Wu, Tingting Yuan, Yupeng Li, Daling Wang, Xiaoming Fu
Categories: cs.CV cs.AI
\\
  Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.
\\ ( https://arxiv.org/abs/2509.10266 ,  775kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10278
Date: Fri, 12 Sep 2025 14:20:29 GMT   (1707kb)

Title: Detecting Text Manipulation in Images using Vision Language Models
Authors: Vidit Vidit, Pavel Korshunov, Amir Mohammadi, Christophe Ecabert,
  Ketan Kotwal, S\'ebastien Marcel
Categories: cs.CV
Comments: Accepted in Synthetic Realities and Biometric Security Workshop
  BMVC-2025. For paper page see https://www.idiap.ch/paper/textvlmdet/
\\
  Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.
\\ ( https://arxiv.org/abs/2509.10278 ,  1707kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10282
Date: Fri, 12 Sep 2025 14:21:54 GMT   (12155kb)

Title: MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly
  Detection
Authors: Gang Li, Tianjiao Chen, Mingle Zhou, Min Li, Delong Han and Jin Wan
Categories: cs.CV cs.LG
Comments: Page 14, 5 pictures
\\
  Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.
\\ ( https://arxiv.org/abs/2509.10282 ,  12155kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10298
Date: Fri, 12 Sep 2025 14:38:18 GMT   (13kb)

Title: Adversarial robustness through Lipschitz-Guided Stochastic Depth in
  Neural Networks
Authors: Laith Nayal, Mahmoud Mousatat, Bader Rasheed
Categories: cs.CV
Comments: 8 pages, 2 tables
\\
  Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.
\\ ( https://arxiv.org/abs/2509.10298 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10310
Date: Fri, 12 Sep 2025 14:52:42 GMT   (2246kb)

Title: A Stochastic Birth-and-Death Approach for Street Furniture Geolocation
  in Urban Environments
Authors: Evan Murphy, Marco Viola, Vladimir A. Krylov
Categories: cs.CV
Comments: Accepted for publication in the Proceedings of the 27th Irish Machine
  Vision and Image Processing Conference (IMVIP 2025)
\\
  In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.
\\ ( https://arxiv.org/abs/2509.10310 ,  2246kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10312
Date: Fri, 12 Sep 2025 14:53:45 GMT   (9646kb)

Title: Compute Only 16 Tokens in One Timestep: Accelerating Diffusion
  Transformers with Cluster-Driven Feature Caching
Authors: Zhixin Zheng, Xinyu Wang, Chang Zou, Shaobo Wang, Linfeng Zhang
Categories: cs.CV
Comments: 11 pages, 11 figures; Accepted by ACM MM2025; Mainly focus on feature
  caching for diffusion transformers acceleration
\\
  Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.
\\ ( https://arxiv.org/abs/2509.10312 ,  9646kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10334
Date: Fri, 12 Sep 2025 15:14:19 GMT   (3903kb)

Title: I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic
  Segmentation
Authors: Jordan Sassoon, Michal Szczepanski and Martyna Poreba
Categories: cs.CV cs.AI cs.LG
\\
  Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.
\\ ( https://arxiv.org/abs/2509.10334 ,  3903kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10341
Date: Fri, 12 Sep 2025 15:24:41 GMT   (2245kb)

Title: GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT
Authors: Botond Fazekas, Thomas Pinetz, Guilherme Aresta, Taha Emre, Hrvoje
  Bogunovic
Categories: cs.CV
\\
  Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.
\\ ( https://arxiv.org/abs/2509.10341 ,  2245kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10344
Date: Fri, 12 Sep 2025 15:33:18 GMT   (1096kb)

Title: GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography
Authors: Yuexi Du, Lihui Chen, Nicha C. Dvornek
Categories: cs.CV cs.AI cs.LG
Comments: Accepted by MICCAI 2025
\\
  Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.
\\ ( https://arxiv.org/abs/2509.10344 ,  1096kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10345
Date: Fri, 12 Sep 2025 15:33:49 GMT   (557kb)

Title: Towards Understanding Visual Grounding in Visual Language Models
Authors: Georgios Pantazopoulos, Eda B. \"Ozyi\u{g}it
Categories: cs.CV cs.AI
\\
  Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.
\\ ( https://arxiv.org/abs/2509.10345 ,  557kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10359
Date: Fri, 12 Sep 2025 15:47:50 GMT   (22623kb)

Title: Immunizing Images from Text to Image Editing via Adversarial
  Cross-Attention
Authors: Matteo Trippodo, Federico Becattini, Lorenzo Seidenari
Categories: cs.CV
Comments: Accepted as Regular Paper at ACM Multimedia 2025
\\
  Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.
\\ ( https://arxiv.org/abs/2509.10359 ,  22623kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10366
Date: Fri, 12 Sep 2025 15:59:55 GMT   (3284kb)

Title: Efficient Learned Image Compression Through Knowledge Distillation
Authors: Fabien Allemand, Attilio Fiandrotti, Sumanta Chaudhuri, Alaa Eddine
  Mazouz
Categories: cs.CV
Comments: 19 pages, 21 figures
\\
  Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .
\\ ( https://arxiv.org/abs/2509.10366 ,  3284kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10388
Date: Fri, 12 Sep 2025 16:29:02 GMT   (22295kb)

Title: Ordinality of Visible-Thermal Image Intensities for Intrinsic Image
  Decomposition
Authors: Zeqing Leo Yuan, Mani Ramanagopal, Aswin C. Sankaranarayanan,
  Srinivasa G. Narasimhan
Categories: cs.CV
\\
  Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.
\\ ( https://arxiv.org/abs/2509.10388 ,  22295kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10407
Date: Fri, 12 Sep 2025 16:58:20 GMT   (9018kb)

Title: Compressed Video Quality Enhancement: Classifying and Benchmarking over
  Standards
Authors: Xiem HoangVan and Dang BuiDinh and Sang NguyenQuang and Wen-Hsiao Peng
Categories: cs.CV
\\
  Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.
\\ ( https://arxiv.org/abs/2509.10407 ,  9018kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10408
Date: Fri, 12 Sep 2025 16:58:51 GMT   (5244kb)

Title: Multimodal SAM-adapter for Semantic Segmentation
Authors: Iacopo Curti, Pierluigi Zama Ramirez, Alioscia Petrelli, Luigi Di
  Stefano
Categories: cs.CV cs.AI
\\
  Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.
\\ ( https://arxiv.org/abs/2509.10408 ,  5244kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10441
Date: Fri, 12 Sep 2025 17:48:57 GMT   (24320kb)

Title: InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis
Authors: Tao Han, Wanghan Xu, Junchao Gong, Xiaoyu Yue, Song Guo, Luping Zhou,
  Lei Bai
Categories: cs.CV
Comments: Accepted by ICCV 2025
\\
  Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.
\\ ( https://arxiv.org/abs/2509.10441 ,  24320kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10453
Date: Fri, 12 Sep 2025 17:59:32 GMT   (750kb)

Title: SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and
  Adaptability Across Alzheimer's Prediction Tasks and Datasets
Authors: Emily Kaczmarek, Justin Szeto, Brennan Nichyporuk, Tal Arbel
Categories: cs.CV cs.LG
\\
  Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.
\\ ( https://arxiv.org/abs/2509.10453 ,  750kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09795
Date: Thu, 11 Sep 2025 18:56:53 GMT   (165kb)

Title: Setchain Algorithms for Blockchain Scalability
Authors: Arivarasan Karmegam, Gabina Luz Bianchi, Margarita Capretto, Mart\'in
  Ceresa, Antonio Fern\'andez Anta, C\'esar S\'anchez
Categories: cs.DC cs.DB cs.DS cs.PF
\\
  Setchain has been proposed to increase blockchain scalability by relaxing the
strict total order requirement among transactions. Setchain organizes elements
into a sequence of sets, referred to as epochs, so that elements within each
epoch are unordered. In this paper, we propose and evaluate three distinct
Setchain algorithms, that leverage an underlying block-based ledger. Vanilla is
a basic implementation that serves as a reference point. Compresschain
aggregates elements into batches, and compresses these batches before appending
them as epochs in the ledger. Hashchain converts batches into fixed-length
hashes which are appended as epochs in the ledger. This requires Hashchain to
use a distributed service to obtain the batch contents from its hash. To allow
light clients to safely interact with only one server, the proposed algorithms
maintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the
hash of the epoch, cryptographically signed by a server. A client can verify
the correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum
number of Byzantine servers assumed). All three Setchain algorithms are
implemented on top of the CometBFT blockchain application platform. We
conducted performance evaluations across various configurations, using clusters
of four, seven, and ten servers. Our results show that the Setchain algorithms
reach orders of magnitude higher throughput than the underlying blockchain, and
achieve finality with latency below 4 seconds.
\\ ( https://arxiv.org/abs/2509.09795 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09868
Date: Thu, 11 Sep 2025 21:43:13 GMT   (348kb)

Title: Ordered Consensus with Equal Opportunity
Authors: Yunhao Zhang, Haobin Ni, Soumya Basu, Shir Cohen, Maofan Yin, Lorenzo
  Alvisi, Robbert van Renesse, Qi Chen, Lidong Zhou
Categories: cs.DC cs.CR cs.MA
\\
  The specification of state machine replication (SMR) has no requirement on
the final total order of commands. In blockchains based on SMR, however, order
matters, since different orders could provide their clients with different
financial rewards. Ordered consensus augments the specification of SMR to
include specific guarantees on such order, with a focus on limiting the
influence of Byzantine nodes. Real-world ordering manipulations, however, can
and do happen even without Byzantine replicas, typically because of factors,
such as faster networks or closer proximity to the blockchain infrastructure,
that give some clients an unfair advantage. To address this challenge, this
paper proceeds to extend ordered consensus by requiring it to also support
equal opportunity, a concrete notion of fairness, widely adopted in social
sciences. Informally, equal opportunity requires that two candidates who,
according to a set of criteria deemed to be relevant, are equally qualified for
a position (in our case, a specific slot in the SMR total order), should have
an equal chance of landing it. We show how randomness can be leveraged to keep
bias in check, and, to this end, introduce the secret random oracle (SRO), a
system component that generates randomness in a fault-tolerant manner. We
describe two SRO designs based, respectively, on trusted hardware and threshold
verifiable random functions, and instantiate them in Bercow, a new ordered
consensus protocol that, by approximating equal opportunity up to within a
configurable factor, can effectively mitigate well-known ordering attacks in
SMR-based blockchains.
\\ ( https://arxiv.org/abs/2509.09868 ,  348kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10371
Date: Fri, 12 Sep 2025 16:05:07 GMT   (905kb)

Title: Characterizing the Efficiency of Distributed Training: A Power,
  Performance, and Thermal Perspective
Authors: Seokjin Go, Joongun Park, Spandan More, Hanjiang Wu, Irene Wang, Aaron
  Jezghani, Tushar Krishna, Divya Mahajan
Categories: cs.DC cs.LG
\\
  The rapid scaling of Large Language Models (LLMs) has pushed training
workloads far beyond the limits of single-node analysis, demanding a deeper
understanding of how these models behave across large-scale, multi-GPU systems.
In this paper, we present a comprehensive characterization of LLM training
across diverse real-world workloads and hardware platforms, including NVIDIA
H100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various
parallelism strategies -- tensor, pipeline, data, and expert -- and evaluate
their effects on hardware utilization, power consumption, and thermal behavior.
We further evaluate the effectiveness of optimizations such as activation
recomputation and compute-communication overlap. Our findings show that
performance is not determined solely by scaling hardware capacity. Scale-up
systems with fewer, higher-memory GPUs can outperform scale-out systems in
communication-bound regimes, but only under carefully tuned configurations; in
other cases, scale-out deployments achieve superior throughput. We also show
that certain parallelism combinations, such as tensor with pipeline, lead to
bandwidth underutilization due to inefficient data chunking, while increasing
microbatch sizes beyond a certain point induces bursty execution and peak power
excursions that worsen thermal throttling. These insights reveal how training
performance is shaped by complex interactions between hardware, system
topology, and model execution. We conclude by offering recommendations for
system and hardware design to improve the scalability and reliability of future
LLM systems and workloads. The source code of this project is available at
https://github.com/sitar-lab/CharLLM-PPT.
\\ ( https://arxiv.org/abs/2509.10371 ,  905kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09906
Date: Fri, 12 Sep 2025 00:25:20 GMT   (16739kb)

Title: Tackling One Health Risks: How Large Language Models are leveraged for
  Risk Negotiation and Consensus-building
Authors: Alexandra Fetsch, Iurii Savvateev, Racem Ben Romdhane, Martin
  Wiedmann, Artemiy Dimov, Maciej Durkalec, Josef Teichmann, Jakob Zinsstag,
  Konstantinos Koutsoumanis, Andreja Rajkovic, Jason Mann, Mauro Tonolla,
  Monika Ehling-Schulz, Matthias Filter, Sophia Johler
Categories: cs.MA cs.AI
\\
  Key global challenges of our times are characterized by complex
interdependencies and can only be effectively addressed through an integrated,
participatory effort. Conventional risk analysis frameworks often reduce
complexity to ensure manageability, creating silos that hinder comprehensive
solutions. A fundamental shift towards holistic strategies is essential to
enable effective negotiations between different sectors and to balance the
competing interests of stakeholders. However, achieving this balance is often
hindered by limited time, vast amounts of information, and the complexity of
integrating diverse perspectives. This study presents an AI-assisted
negotiation framework that incorporates large language models (LLMs) and
AI-based autonomous agents into a negotiation-centered risk analysis workflow.
The framework enables stakeholders to simulate negotiations, systematically
model dynamics, anticipate compromises, and evaluate solution impacts. By
leveraging LLMs' semantic analysis capabilities we could mitigate information
overload and augment decision-making process under time constraints.
Proof-of-concept implementations were conducted in two real-world scenarios:
(i) prudent use of a biopesticide, and (ii) targeted wild animal population
control. Our work demonstrates the potential of AI-assisted negotiation to
address the current lack of tools for cross-sectoral engagement. Importantly,
the solution's open source, web based design, suits for application by a
broader audience with limited resources and enables users to tailor and develop
it for their own needs.
\\ ( https://arxiv.org/abs/2509.09906 ,  16739kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10284
Date: Fri, 12 Sep 2025 14:23:02 GMT   (2825kb)

Title: A Holistic Architecture for Monitoring and Optimization of Robust
  Multi-Agent Path Finding Plan Execution
Authors: David Zahr\'adka (1 and 2), Denisa Mu\v{z}\'ikov\'a (1), David Woller
  (2), Miroslav Kulich (2), Ji\v{r}\'i \v{S}vancara (3), Roman Bart\'ak (3)
  ((1) Faculty of Electrical Engineering, Czech Technical University in Prague,
  (2) Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical
  University in Prague, (3) Faculty of Mathematics and Physics, Charles
  University)
Categories: cs.MA cs.RO
Comments: 23 pages, 10 figures
\\
  The goal of Multi-Agent Path Finding (MAPF) is to find a set of paths for a
fleet of agents moving in a shared environment such that the agents reach their
goals without colliding with each other. In practice, some of the robots
executing the plan may get delayed, which can introduce collision risk.
Although robust execution methods are used to ensure safety even in the
presence of delays, the delays may still have a significant impact on the
duration of the execution. At some point, the accumulated delays may become
significant enough that instead of continuing with the execution of the
original plan, even if it was optimal, there may now exist an alternate plan
which will lead to a shorter execution. However, the problem is how to decide
when to search for the alternate plan, since it is a costly procedure. In this
paper, we propose a holistic architecture for robust execution of MAPF plans,
its monitoring and optimization. We exploit a robust execution method called
Action Dependency Graph to maintain an estimate of the expected execution
duration during the plan's execution. This estimate is used to predict the
potential that finding an alternate plan would lead to shorter execution. We
empirically evaluate the architecture in experiments in a real-time simulator
which we designed to mimic our real-life demonstrator of an autonomous
warehouse robotic fleet.
\\ ( https://arxiv.org/abs/2509.10284 ,  2825kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2509.08919 (*cross-listing*)
Date: Wed, 10 Sep 2025 18:29:18 GMT   (15409kb)

Title: Generative Engine Optimization: How to Dominate AI Search
Authors: Mahe Chen, Xiaoxuan Wang, Kaiwen Chen, Nick Koudas
Categories: cs.IR cs.AI cs.CL cs.LG cs.SI
\\
  The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.
\\ ( https://arxiv.org/abs/2509.08919 ,  15409kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09177 (*cross-listing*)
Date: Thu, 11 Sep 2025 06:27:10 GMT   (1094kb)

Title: Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level
  RL
Authors: Hanyi Mao, Quanjia Xiao, Lei Pang, Haixiao Liu
Categories: cs.LG cs.AI cs.CL
\\
  We propose FSPO (Fair Sequence Policy Optimization), a sequence-level
reinforcement learning method for LLMs that enforces length-fair clipping
directly in the importance-sampling (IS) weight space. We revisit
sequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping
is transplanted to sequences: a fixed clip range systematically reweights short
vs. long responses, distorting the effective objective. Theoretically, we
formalize length fairness via a Length Reweighting Error (LRE) and prove that
small LRE yields a directional cosine guarantee between the clipped and true
updates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the
sequence log-IS ratio with a band that applies a KL-corrected drift term and
scales as $\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,
stabilizes training, and outperforms all baselines across multiple evaluation
datasets.
\\ ( https://arxiv.org/abs/2509.09177 ,  1094kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09470 (*cross-listing*)
Date: Thu, 11 Sep 2025 13:52:52 GMT   (3643kb)

Title: AEGIS: An Agent for Extraction and Geographic Identification in
  Scholarly Proceedings
Authors: Om Vishesh, Harshad Khadilkar, Deepak Akkil
Categories: cs.LG cs.AI
Comments: 5 pages, 2 figures
\\
  Keeping pace with the rapid growth of academia literature presents a
significant challenge for researchers, funding bodies, and academic societies.
To address the time-consuming manual effort required for scholarly discovery,
we present a novel, fully automated system that transitions from data discovery
to direct action. Our pipeline demonstrates how a specialized AI agent,
'Agent-E', can be tasked with identifying papers from specific geographic
regions within conference proceedings and then executing a Robotic Process
Automation (RPA) to complete a predefined action, such as submitting a
nomination form. We validated our system on 586 papers from five different
conferences, where it successfully identified every target paper with a recall
of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the
potential of task-oriented AI agents to not only filter information but also to
actively participate in and accelerate the workflows of the academic community.
\\ ( https://arxiv.org/abs/2509.09470 ,  3643kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09681 (*cross-listing*)
Date: Tue, 12 Aug 2025 08:27:53 GMT   (1003kb)

Title: DB3 Team's Solution For Meta KDD Cup' 25
Authors: Yikuan Xia, Jiazun Chen, Yirui Zhan, Suifeng Zhao, Weipeng Jiang,
  Chaorui Zhang, Wei Han, Bo Bai, Jun Gao
Categories: cs.IR cs.AI cs.CL cs.LG
\\
  This paper presents the db3 team's winning solution for the Meta CRAG-MM
Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,
multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive
framework that integrates tailored retrieval pipelines for different tasks with
a unified LLM-tuning approach for hallucination control. Our solution features
(1) domain-specific retrieval pipelines handling image-indexed knowledge
graphs, web sources, and multi-turn conversations; and (2) advanced refusal
training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd
place in Task 2, and 1st place in Task 3, securing the grand prize for
excellence in ego-centric queries through superior handling of first-person
perspective challenges.
\\ ( https://arxiv.org/abs/2509.09681 ,  1003kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09683 (*cross-listing*)
Date: Fri, 15 Aug 2025 10:01:53 GMT   (3213kb)

Title: Forecasting Clicks in Digital Advertising: Multimodal Inputs and
  Interpretable Outputs
Authors: Briti Gangopadhyay, Zhao Wang, Shingo Takamatsu
Categories: cs.IR cs.AI
\\
  Forecasting click volume is a key task in digital advertising, influencing
both revenue and campaign strategy. Traditional time series models rely solely
on numerical data, often overlooking rich contextual information embedded in
textual elements, such as keyword updates. We present a multimodal forecasting
framework that combines click data with textual logs from real-world ad
campaigns and generates human-interpretable explanations alongside numeric
predictions. Reinforcement learning is used to improve comprehension of textual
information and enhance fusion of modalities. Experiments on a large-scale
industry dataset show that our method outperforms baselines in both accuracy
and reasoning quality.
\\ ( https://arxiv.org/abs/2509.09683 ,  3213kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09684 (*cross-listing*)
Date: Mon, 18 Aug 2025 01:25:41 GMT   (591kb)

Title: Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for
  Query Translation
Authors: Bruno Yui Yamate, Thais Rodrigues Neubauer, Marcelo Fantinato,
  Sarajane Marques Peres
Categories: cs.IR cs.AI cs.CL cs.DB
Comments: 33 pages
\\
  This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)
benchmark dataset designed for the text-to-SQL task in the process mining
domain. Text-to-SQL conversion facilitates natural language querying of
databases, increasing accessibility for users without SQL expertise and
productivity for those that are experts. The text-2-SQL-4-PM dataset is
customized to address the unique challenges of process mining, including
specialized vocabularies and single-table relational structures derived from
event logs. The dataset comprises 1,655 natural language utterances, including
human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods
include manual curation by experts, professional translations, and a detailed
annotation process to enable nuanced analyses of task complexity. Additionally,
a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility
of the dataset for text-to-SQL applications. The results show that
text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering
broader applicability for semantic parsing and other natural language
processing tasks.
\\ ( https://arxiv.org/abs/2509.09684 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09685 (*cross-listing*)
Date: Mon, 18 Aug 2025 05:06:58 GMT   (351kb)

Title: TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal
  Conversational Music Recommendation
Authors: Keunwoo Choi, Seungheon Doh, Juhan Nam
Categories: cs.IR cs.AI cs.MM cs.SD eess.AS
\\
  We present TalkPlayData 2, a synthetic dataset for multimodal conversational
music recommendation generated by an agentic data pipeline. In TalkPlayData 2
pipeline, multiple large language model (LLM) agents are created under various
roles with specialized prompts and access to different parts of information,
and the chat data is acquired by logging the conversation between the Listener
LLM and the Recsys LLM. To cover various conversation scenarios, for each
conversation, the Listener LLM is conditioned on a finetuned conversation goal.
Finally, all the LLMs are multimodal with audio and images, allowing a
simulation of multimodal recommendation and conversation. In the LLM-as-a-judge
and subjective evaluation experiments, TalkPlayData 2 achieved the proposed
goal in various aspects related to training a generative recommendation model
for music. TalkPlayData 2 and its generation code are open-sourced at
https://talkpl.ai/talkplaydata2.html.
\\ ( https://arxiv.org/abs/2509.09685 ,  351kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09686 (*cross-listing*)
Date: Mon, 18 Aug 2025 08:29:22 GMT   (4065kb)

Title: GeoGPT.RAG Technical Report
Authors: Fei Huang, Fan Wu, Zeqing Zhang, Qihao Wang, Long Zhang, Grant Michael
  Boquet and Hongyang Chen
Categories: cs.IR cs.AI
Comments: 19 pages, 10 figures, 10 tables
ACM-class: I.2; I.7; H.4; H.5
\\
  GeoGPT is an open large language model system built to advance research in
the geosciences. To enhance its domain-specific capabilities, we integrated
Retrieval Augmented Generation(RAG), which augments model outputs with relevant
information retrieved from an external knowledge source. GeoGPT uses RAG to
draw from the GeoGPT Library, a specialized corpus curated for geoscientific
content, enabling it to generate accurate, context-specific answers. Users can
also create personalized knowledge bases by uploading their own publication
lists, allowing GeoGPT to retrieve and respond using user-provided materials.
To further improve retrieval quality and domain alignment, we fine-tuned both
the embedding model and a ranking model that scores retrieved passages by
relevance to the query. These enhancements optimize RAG for geoscience
applications and significantly improve the system's ability to deliver precise
and trustworthy outputs. GeoGPT reflects a strong commitment to open science
through its emphasis on collaboration, transparency, and community driven
development. As part of this commitment, we have open-sourced two core RAG
components-GeoEmbedding and GeoReranker-to support geoscientists, researchers,
and professionals worldwide with powerful, accessible AI tools.
\\ ( https://arxiv.org/abs/2509.09686 ,  4065kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09688 (*cross-listing*)
Date: Mon, 18 Aug 2025 15:16:29 GMT   (168kb)

Title: AI-Powered Assistant for Long-Term Access to RHIC Knowledge
Authors: Mohammad Atif, Vincent Garonne, Eric Lancon, Jerome Lauret, Alexandr
  Prozorov, Michal Vranovsky
Categories: cs.IR cs.AI cs.CL
\\
  As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National
Laboratory concludes 25 years of operation, preserving not only its vast data
holdings ($\sim$1 ExaByte) but also the embedded scientific knowledge becomes a
critical priority. The RHIC Data and Analysis Preservation Plan (DAPP)
introduces an AI-powered assistant system that provides natural language access
to documentation, workflows, and software, with the aim of supporting
reproducibility, education, and future discovery. Built upon Large Language
Models using Retrieval-Augmented Generation and the Model Context Protocol,
this assistant indexes structured and unstructured content from RHIC
experiments and enables domain-adapted interaction. We report on the
deployment, computational performance, ongoing multi-experiment integration,
and architectural features designed for a sustainable and explainable long-term
AI access. Our experience illustrates how modern AI/ML tools can transform the
usability and discoverability of scientific legacy data.
\\ ( https://arxiv.org/abs/2509.09688 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09689 (*cross-listing*)
Date: Mon, 18 Aug 2025 22:14:57 GMT   (168kb)

Title: Personas within Parameters: Fine-Tuning Small Language Models with
  Low-Rank Adapters to Mimic User Behaviors
Authors: Himanshu Thakur, Eshani Agrawal, Smruthi Mukund
Categories: cs.IR cs.AI cs.CL cs.LG
\\
  A long-standing challenge in developing accurate recommendation models is
simulating user behavior, mainly due to the complex and stochastic nature of
user interactions. Towards this, one promising line of work has been the use of
Large Language Models (LLMs) for simulating user behavior. However, aligning
these general-purpose large pre-trained models with user preferences
necessitates: (i) effectively and continously parsing large-scale tabular
user-item interaction data, (ii) overcoming pre-training-induced inductive
biases to accurately learn user specific knowledge, and (iii) achieving the
former two at scale for millions of users. While most previous works have
focused on complex methods to prompt an LLM or fine-tune it on tabular
interaction datasets, our approach shifts the focus to extracting robust
textual user representations using a frozen LLM and simulating cost-effective,
resource-efficient user agents powered by fine-tuned Small Language Models
(SLMs). Further, we showcase a method for training multiple low-rank adapters
for groups of users or \textit{persona}, striking an optimal balance between
scalability and performance of user behavior agents. Our experiments provide
compelling empirical evidence of the efficacy of our methods, demonstrating
that user agents developed using our approach have the potential to bridge the
gap between offline metrics and real-world performance of recommender systems.
\\ ( https://arxiv.org/abs/2509.09689 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09691 (*cross-listing*)
Date: Thu, 21 Aug 2025 10:13:24 GMT   (195kb)

Title: Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware
  Alternative to Vector Embedding Stores
Authors: Aleksandr Listopad
Categories: cs.IR cs.AI cs.DB
Comments: 9 pages, 6 figures
MSC-class: 68T05 (Primary), 42C10, 94A12 (Secondary)
ACM-class: I.2.6; H.2.4; H.3.3
\\
  Conventional vector-based memory systems rely on cosine or inner product
similarity within real-valued embedding spaces. While computationally
efficient, such approaches are inherently phase-insensitive and limited in
their ability to capture resonance phenomena crucial for meaning
representation. We propose Wave-Based Semantic Memory, a novel framework that
models knowledge as wave patterns $\psi(x) = A(x) e^{i\phi(x)}$ and retrieves
it through resonance-based interference. This approach preserves both amplitude
and phase information, enabling more expressive and robust semantic similarity.
We demonstrate that resonance-based retrieval achieves higher discriminative
power in cases where vector methods fail, including phase shifts, negations,
and compositional queries. Our implementation, ResonanceDB, shows scalability
to millions of patterns with millisecond latency, positioning wave-based memory
as a viable alternative to vector stores for AGI-oriented reasoning and
knowledge representation.
\\ ( https://arxiv.org/abs/2509.09691 ,  195kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09706 (*cross-listing*)
Date: Fri, 5 Sep 2025 21:43:06 GMT   (234kb)

Title: Differential Robustness in Transformer Language Models: Empirical
  Evaluation Under Adversarial Text Attacks
Authors: Taniya Gidatkar, Oluwaseun Ajao, Matthew Shardlow
Categories: cs.CR cs.AI cs.CL
Comments: 8 pages, 4 tables, to appear in proceedings of Recent Advances in
  Natural Language Processing (RANLP 2025) and ACL Anthology
ACM-class: I.2; H.3.3
\\
  This study evaluates the resilience of large language models (LLMs) against
adversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.
Using systematically designed adversarial tests through TextFooler and
BERTAttack, we found significant variations in model robustness. RoBERTa-Base
and FlanT5 demonstrated remarkable resilience, maintaining accuracy even when
subjected to sophisticated attacks, with attack success rates of 0%. In
contrast. BERT-Base showed considerable vulnerability, with TextFooler
achieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.
Our research reveals that while certain LLMs have developed effective defensive
mechanisms, these safeguards often require substantial computational resources.
This study contributes to the understanding of LLM security by identifying
existing strengths and weaknesses in current safeguarding approaches and
proposes practical recommendations for developing more efficient and effective
defensive strategies.
\\ ( https://arxiv.org/abs/2509.09706 ,  234kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09707 (*cross-listing*)
Date: Fri, 5 Sep 2025 21:46:41 GMT   (2223kb)

Title: LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased
  Random Key Genetic Algorithm
Authors: Camilo Chac\'on Sartori, Mart\'in Isla Pino, Pedro Pinacho-Davidson,
  Christian Blum
Categories: cs.NE cs.AI cs.CL
Comments: Submitted to a journal for review
\\
  Integrating Large Language Models (LLMs) within metaheuristics opens a novel
path for solving complex combinatorial optimization problems. While most
existing approaches leverage LLMs for code generation to create or refine
specific heuristics, they often overlook the structural properties of
individual problem instances. In this work, we introduce a novel framework that
integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the
NP-hard Longest Run Subsequence problem. Our approach extends the
instance-driven heuristic bias paradigm by introducing a human-LLM
collaborative process to co-design and implement a set of computationally
efficient metrics. The LLM analyzes these instance-specific metrics to generate
a tailored heuristic bias, which steers the BRKGA toward promising areas of the
search space. We conduct a comprehensive experimental evaluation, including
rigorous statistical tests, convergence and behavioral analyses, and targeted
ablation studies, comparing our method against a standard BRKGA baseline across
1,050 generated instances of varying complexity. Results show that our
top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically
significant improvements over the baseline, particularly on the most complex
instances. Our findings confirm that leveraging an LLM to produce an a priori,
instance-driven heuristic bias is a valuable approach for enhancing
metaheuristics in complex optimization domains.
\\ ( https://arxiv.org/abs/2509.09707 ,  2223kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09716 (*cross-listing*)
Date: Tue, 9 Sep 2025 14:28:58 GMT   (324kb)

Title: VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions
Authors: Jun Zhan, Mingyang Han, Yuxuan Xie, Chen Wang, Dong Zhang, Kexin
  Huang, Haoxiang Shi, DongXiao Wang, Tengtao Song, Qinyuan Cheng, Shimin Li,
  Jun Song, Xipeng Qiu, Bo Zheng
Categories: cs.SD cs.AI cs.CL eess.AS
\\
  Spoken language models (SLMs) have emerged as a unified paradigm for speech
understanding and generation, enabling natural human machine interaction.
However, while most progress has focused on semantic accuracy and instruction
following, the ability of SLMs to adapt their speaking style based on spoken
instructions has received limited attention. We introduce Voice Style
Adaptation (VSA), a new task that examines whether SLMs can modify their
speaking style, such as timbre, prosody, or persona following natural language
spoken commands. To study this task, we present VStyle, a bilingual (Chinese &
English) benchmark covering four categories of speech generation: acoustic
attributes, natural language instruction, role play, and implicit empathy. We
also introduce the Large Audio Language Model as a Judge (LALM as a Judge)
framework, which progressively evaluates outputs along textual faithfulness,
style adherence, and naturalness, ensuring reproducible and objective
assessment. Experiments on commercial systems and open source SLMs demonstrate
that current models face clear limitations in controllable style adaptation,
highlighting both the novelty and challenge of this task. By releasing VStyle
and its evaluation toolkit, we aim to provide the community with a foundation
for advancing human centered spoken interaction. The dataset and code are
publicly available at
\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.
\\ ( https://arxiv.org/abs/2509.09716 ,  324kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09740 (*cross-listing*)
Date: Wed, 10 Sep 2025 22:25:33 GMT   (3982kb)

Title: HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster
  Resolution Selection Using Perturb-seq Datasets
Authors: Ying Yuan, Xing-Yue Monica Ge, Aaron Archer Waterman, Tommaso
  Biancalani, David Richmond, Yogesh Pandit, Avtar Singh, Russell Littman, Jin
  Liu, Jan-Christian Huetter, Vladimir Ermakov
Categories: q-bio.QM cs.AI cs.CL cs.LG
\\
  Large-scale single-cell and Perturb-seq investigations routinely involve
clustering cells and subsequently annotating each cluster with Gene-Ontology
(GO) terms to elucidate the underlying biological programs. However, both
stages, resolution selection and functional annotation, are inherently
subjective, relying on heuristics and expert curation. We present
HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming
cluster annotation into a quantitatively optimizable task. Initially, an LLM
functioning as a gene-set analyst analyzes the content of each gene program or
perturbation module and generates a ranked list of GO-based hypotheses,
accompanied by calibrated confidence scores. Subsequently, we embed every
predicted description with a sentence-embedding model, compute pair-wise cosine
similarities, and let the agent referee panel score (i) the internal
consistency of the predictions, high average similarity within the same
cluster, termed intra-cluster agreement (ii) their external distinctiveness,
low similarity between clusters, termed inter-cluster separation. These two
quantities are combined to produce an agent-derived resolution score, which is
maximized when clusters exhibit simultaneous coherence and mutual exclusivity.
When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary
test, our Resolution Score selects clustering granularities that exhibit
alignment with known pathway compared to classical metrics such silhouette
score, modularity score for gene functional enrichment summary. These findings
establish LLM agents as objective adjudicators of cluster resolution and
functional annotation, thereby paving the way for fully automated,
context-aware interpretation pipelines in single-cell multi-omics studies.
\\ ( https://arxiv.org/abs/2509.09740 ,  3982kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09744 (*cross-listing*)
Date: Thu, 11 Sep 2025 07:24:39 GMT   (3297kb)

Title: Structure Matters: Brain Graph Augmentation via Learnable Edge Masking
  for Data-efficient Psychiatric Diagnosis
Authors: Mujie Liu, Chenze Wang, Liping Chen, Nguyen Linh Dan Le, Niharika
  Tewari, Ting Dang, Jiangang Ma, and Feng Xia
Categories: cs.LG cs.AI
\\
  The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.
\\ ( https://arxiv.org/abs/2509.09744 ,  3297kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09747 (*cross-listing*)
Date: Thu, 11 Sep 2025 10:54:07 GMT   (102kb)

Title: D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for
  Unimodal Inference
Authors: Leen Daher and Zhaobo Wang and Malcolm Mielle
Categories: cs.LG cs.AI cs.RO
\\
  Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.
\\ ( https://arxiv.org/abs/2509.09747 ,  102kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09751 (*cross-listing*)
Date: Thu, 11 Sep 2025 14:20:45 GMT   (3703kb)

Title: Meta-Learning Reinforcement Learning for Crypto-Return Prediction
Authors: Junqiao Wang, Zhaoyang Guan, Guanyu Liu, Tianze Xia, Xianzhi Li, Shuo
  Yin, Xinyuan Song, Chuhan Cheng, Tianyu Shi, Alex Lee
Categories: cs.LG cs.AI
\\
  Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.
\\ ( https://arxiv.org/abs/2509.09751 ,  3703kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09754 (*cross-listing*)
Date: Thu, 11 Sep 2025 16:48:24 GMT   (1624kb)

Title: LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation
Authors: Yiqun Shen, Song Yuan, Zhengze Zhang, Xiaoliang Wang, Daxin Jiang,
  Nguyen Cam-Tu
Categories: cs.LG cs.AI
\\
  KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.
\\ ( https://arxiv.org/abs/2509.09754 ,  1624kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09787 (*cross-listing*)
Date: Thu, 11 Sep 2025 18:44:09 GMT   (466kb)

Title: ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full
  Version)
Authors: Nojan Sheybani, Alessandro Pegoraro, Jonathan Knauer, Phillip Rieger,
  Elissa Mollakuqe, Farinaz Koushanfar, Ahmad-Reza Sadeghi
Categories: cs.CR cs.AI
Comments: Full version of CCS 2025 paper
\\
  Split Learning (SL) is a distributed learning approach that enables
resource-constrained clients to collaboratively train deep neural networks
(DNNs) by offloading most layers to a central server while keeping in- and
output layers on the client-side. This setup enables SL to leverage server
computation capacities without sharing data, making it highly effective in
resource-constrained environments dealing with sensitive data. However, the
distributed nature enables malicious clients to manipulate the training
process. By sending poisoned intermediate gradients, they can inject backdoors
into the shared DNN. Existing defenses are limited by often focusing on
server-side protection and introducing additional overhead for the server. A
significant challenge for client-side defenses is enforcing malicious clients
to correctly execute the defense algorithm.
  We present ZORRO, a private, verifiable, and robust SL defense scheme.
Through our novel design and application of interactive zero-knowledge proofs
(ZKPs), clients prove their correct execution of a client-located defense
algorithm, resulting in proofs of computational integrity attesting to the
benign nature of locally trained DNN portions. Leveraging the frequency
representation of model partitions enables ZORRO to conduct an in-depth
inspection of the locally trained models in an untrusted environment, ensuring
that each client forwards a benign checkpoint to its succeeding client. In our
extensive evaluation, covering different model architectures as well as various
attack strategies and data scenarios, we show ZORRO's effectiveness, as it
reduces the attack success rate to less than 6\% while causing even for models
storing \numprint{1000000} parameters on the client-side an overhead of less
than 10 seconds.
\\ ( https://arxiv.org/abs/2509.09787 ,  466kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09823 (*cross-listing*)
Date: Thu, 11 Sep 2025 19:49:30 GMT   (2436kb)

Title: SoilSound: Smartphone-based Soil Moisture Estimation
Authors: Yixuan Gao, Tanvir Ahmed, Shuang He, Zhongqi Cheng, Rajalakshmi
  Nandakumar
Categories: cs.SD cs.AI cs.ET cs.HC eess.SP
Comments: 12 pages, 8 figures
\\
  Soil moisture monitoring is essential for agriculture and environmental
management, yet existing methods require either invasive probes disturbing the
soil or specialized equipment, limiting access to the public. We present
SoilSound, an ubiquitous accessible smartphone-based acoustic sensing system
that can measure soil moisture without disturbing the soil. We leverage the
built-in speaker and microphone to perform a vertical scan mechanism to
accurately measure moisture without any calibration. Unlike existing work that
use transmissive properties, we propose an alternate model for acoustic
reflections in soil based on the surface roughness effect to enable moisture
sensing without disturbing the soil. The system works by sending acoustic
chirps towards the soil and recording the reflections during a vertical scan,
which are then processed and fed to a convolutional neural network for
on-device soil moisture estimation with negligible computational, memory, or
power overhead. We evaluated the system by training with curated soils in boxes
in the lab and testing in the outdoor fields and show that SoilSound achieves a
mean absolute error (MAE) of 2.39% across 10 different locations. Overall, the
evaluation shows that SoilSound can accurately track soil moisture levels
ranging from 15.9% to 34.0% across multiple soil types, environments, and
users; without requiring any calibration or disturbing the soil, enabling
widespread moisture monitoring for home gardeners, urban farmers, citizen
scientists, and agricultural communities in resource-limited settings.
\\ ( https://arxiv.org/abs/2509.09823 ,  2436kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09836 (*cross-listing*)
Date: Thu, 11 Sep 2025 20:31:18 GMT   (7927kb)

Title: CoDiCodec: Unifying Continuous and Discrete Compressed Representations
  of Audio
Authors: Marco Pasini, Stefan Lattner, George Fazekas
Categories: cs.SD cs.AI cs.LG eess.AS
Comments: Accepted to ISMIR 2025
\\
  Efficiently representing audio signals in a compressed latent space is
critical for latent generative modelling. However, existing autoencoders often
force a choice between continuous embeddings and discrete tokens. Furthermore,
achieving high compression ratios while maintaining audio fidelity remains a
challenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes
these limitations by both efficiently encoding global features via summary
embeddings, and by producing both compressed continuous embeddings at ~ 11 Hz
and discrete tokens at a rate of 2.38 kbps from the same trained model,
offering unprecedented flexibility for different downstream generative tasks.
This is achieved through Finite Scalar Quantization (FSQ) and a novel
FSQ-dropout technique, and does not require additional loss terms beyond the
single consistency loss used for end-to-end training. CoDiCodec supports both
autoregressive decoding and a novel parallel decoding strategy, with the latter
achieving superior audio quality and faster decoding. CoDiCodec outperforms
existing continuous and discrete autoencoders at similar bitrates in terms of
reconstruction audio quality. Our work enables a unified approach to audio
compression, bridging the gap between continuous and discrete generative
modelling paradigms.
\\ ( https://arxiv.org/abs/2509.09836 ,  7927kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09838 (*cross-listing*)
Date: Thu, 11 Sep 2025 20:34:08 GMT   (21336kb)

Title: Revisiting Actor-Critic Methods in Discrete Action Off-Policy
  Reinforcement Learning
Authors: Reza Asad, Reza Babanezhad, Sharan Vaswani
Categories: cs.LG cs.AI
\\
  Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.
\\ ( https://arxiv.org/abs/2509.09838 ,  21336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09843 (*cross-listing*)
Date: Thu, 11 Sep 2025 20:50:00 GMT   (890kb)

Title: HGEN: Heterogeneous Graph Ensemble Networks
Authors: Jiajun Shen, Yufei Jin, Yi He and Xingquan Zhu
Categories: cs.LG cs.AI
Comments: The paper is in proceedings of the 34th IJCAI Conference, 2025
\\
  This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.
\\ ( https://arxiv.org/abs/2509.09843 ,  890kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09853 (*cross-listing*)
Date: Thu, 11 Sep 2025 21:04:10 GMT   (99kb)

Title: SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under
  Resource Constraints
Authors: Zhiyu Fan, Kirill Vasilevski, Dayi Lin, Boyuan Chen, Yihao Chen,
  Zhiqing Zhong, Jie M. Zhang, Pinjia He, Ahmed E. Hassan
Categories: cs.SE cs.AI
\\
  The advancement of large language models (LLMs) and code agents has
demonstrated significant potential to assist software engineering (SWE) tasks,
such as autonomous issue resolution and feature addition. Existing AI for
software engineering leaderboards (e.g., SWE-bench) focus solely on solution
accuracy, ignoring the crucial factor of effectiveness in a
resource-constrained world. This is a universal problem that also exists beyond
software engineering tasks: any AI system should be more than correct - it must
also be cost-effective. To address this gap, we introduce SWE-Effi, a set of
new metrics to re-evaluate AI systems in terms of holistic effectiveness
scores. We define effectiveness as the balance between the accuracy of outcome
(e.g., issue resolve rate) and the resources consumed (e.g., token and time).
In this paper, we specifically focus on the software engineering scenario by
re-ranking popular AI systems for issue resolution on a subset of the SWE-bench
benchmark using our new multi-dimensional metrics. We found that AI system's
effectiveness depends not just on the scaffold itself, but on how well it
integrates with the base model, which is key to achieving strong performance in
a resource-efficient manner. We also identified systematic challenges such as
the "token snowball" effect and, more significantly, a pattern of "expensive
failures". In these cases, agents consume excessive resources while stuck on
unsolvable tasks - an issue that not only limits practical deployment but also
drives up the cost of failed rollouts during RL training. Lastly, we observed a
clear trade-off between effectiveness under the token budget and effectiveness
under the time budget, which plays a crucial role in managing project budgets
and enabling scalable reinforcement learning, where fast responses are
essential.
\\ ( https://arxiv.org/abs/2509.09853 ,  99kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09864 (*cross-listing*)
Date: Thu, 11 Sep 2025 21:35:19 GMT   (1085kb)

Title: Latency and Token-Aware Test-Time Compute
Authors: Jenny Y. Huang, Mehul Damani, Yousef El-Kurdi, Ramon Astudillo, Wei
  Sun
Categories: cs.LG cs.AI cs.CL
\\
  Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.
\\ ( https://arxiv.org/abs/2509.09864 ,  1085kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09870 (*cross-listing*)
Date: Thu, 11 Sep 2025 21:43:49 GMT   (11250kb)

Title: Vibe Check: Understanding the Effects of LLM-Based Conversational
  Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks
Authors: Hasibur Rahman, Smit Desai
Categories: cs.HC cs.AI cs.CL
\\
  Large language models (LLMs) enable conversational agents (CAs) to express
distinctive personalities, raising new questions about how such designs shape
user perceptions. This study investigates how personality expression levels and
user-agent personality alignment influence perceptions in goal-oriented tasks.
In a between-subjects experiment (N=150), participants completed travel
planning with CAs exhibiting low, medium, or high expression across the Big
Five traits, controlled via our novel Trait Modulation Keys framework. Results
revealed an inverted-U relationship: medium expression produced the most
positive evaluations across Intelligence, Enjoyment, Anthropomorphism,
Intention to Adopt, Trust, and Likeability, significantly outperforming both
extremes. Personality alignment further enhanced outcomes, with Extraversion
and Emotional Stability emerging as the most influential traits. Cluster
analysis identified three distinct compatibility profiles, with "Well-Aligned"
users reporting substantially positive perceptions. These findings demonstrate
that personality expression and strategic trait alignment constitute optimal
design targets for CA personality, offering design implications as LLM-based
CAs become increasingly prevalent.
\\ ( https://arxiv.org/abs/2509.09870 ,  11250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09873 (*cross-listing*)
Date: Thu, 11 Sep 2025 21:46:20 GMT   (1043kb)

Title: From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI
  Ecosystem
Authors: James Jewitt, Hao Li, Bram Adams, Gopi Krishnan Rajbahadur, Ahmed E.
  Hassan
Categories: cs.SE cs.AI
Comments: 9 pages, 4 figures, 5 tables, pre-print
\\
  Hidden license conflicts in the open-source AI ecosystem pose serious legal
and ethical risks, exposing organizations to potential litigation and users to
undisclosed risk. However, the field lacks a data-driven understanding of how
frequently these conflicts occur, where they originate, and which communities
are most affected. We present the first end-to-end audit of licenses for
datasets and models on Hugging Face, as well as their downstream integration
into open-source software applications, covering 364 thousand datasets, 1.6
million models, and 140 thousand GitHub projects. Our empirical analysis
reveals systemic non-compliance in which 35.5% of model-to-application
transitions eliminate restrictive license clauses by relicensing under
permissive terms. In addition, we prototype an extensible rule engine that
encodes almost 200 SPDX and model-specific clauses for detecting license
conflicts, which can solve 86.4% of license conflicts in software applications.
To support future research, we release our dataset and the prototype engine.
Our study highlights license compliance as a critical governance challenge in
open-source AI and provides both the data and tools necessary to enable
automated, AI-aware compliance at scale.
\\ ( https://arxiv.org/abs/2509.09873 ,  1043kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09880 (*cross-listing*)
Date: Thu, 11 Sep 2025 22:22:32 GMT   (3927kb)

Title: Automated Tuning for Diffusion Inverse Problem Solvers without
  Generative Prior Retraining
Authors: Ya\c{s}ar Utku Al\c{c}alar, Junno Yun, Mehmet Ak\c{c}akaya
Categories: eess.IV cs.AI cs.CV cs.LG physics.med-ph
Comments: IEEE International Workshop on Computational Advances in Multi-Sensor
  Adaptive Processing (CAMSAP), 2025
\\
  Diffusion/score-based models have recently emerged as powerful generative
priors for solving inverse problems, including accelerated MRI reconstruction.
While their flexibility allows decoupling the measurement model from the
learned prior, their performance heavily depends on carefully tuned data
fidelity weights, especially under fast sampling schedules with few denoising
steps. Existing approaches often rely on heuristics or fixed weights, which
fail to generalize across varying measurement conditions and irregular timestep
schedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling
(ZADS), a test-time optimization method that adaptively tunes fidelity weights
across arbitrary noise schedules without requiring retraining of the diffusion
prior. ZADS treats the denoising process as a fixed unrolled sampler and
optimizes fidelity weights in a self-supervised manner using only undersampled
measurements. Experiments on the fastMRI knee dataset demonstrate that ZADS
consistently outperforms both traditional compressed sensing and recent
diffusion-based methods, showcasing its ability to deliver high-fidelity
reconstructions across varying noise schedules and acquisition settings.
\\ ( https://arxiv.org/abs/2509.09880 ,  3927kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09893 (*cross-listing*)
Date: Thu, 11 Sep 2025 23:10:56 GMT   (1800kb)

Title: Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe
  Self-augmentation with Demonstrator-annotated Precision
Authors: Hanbit Oh, Masaki Murooka, Tomohiro Motoda, Ryoichi Nakajo, and
  Yukiyasu Domae
Categories: cs.RO cs.AI
Comments: Under review
\\
  Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .
\\ ( https://arxiv.org/abs/2509.09893 ,  1800kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09918 (*cross-listing*)
Date: Fri, 12 Sep 2025 01:43:26 GMT   (516kb)

Title: WALL: A Web Application for Automated Quality Assurance using Large
  Language Models
Authors: Seyed Moein Abtahi, Akramul Azim
Categories: cs.SE cs.AI
\\
  As software projects become increasingly complex, the volume and variety of
issues in code files have grown substantially. Addressing this challenge
requires efficient issue detection, resolution, and evaluation tools. This
paper presents WALL, a web application that integrates SonarQube and large
language models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these
tasks. WALL comprises three modules: an issue extraction tool, code issues
reviser, and code comparison tool. Together, they enable a seamless pipeline
for detecting software issues, generating automated code revisions, and
evaluating the accuracy of revisions. Our experiments, conducted on 563 files
with over 7,599 issues, demonstrate WALL's effectiveness in reducing human
effort while maintaining high-quality revisions. Results show that employing a
hybrid approach of cost-effective and advanced LLMs can significantly lower
costs and improve revision rates. Future work aims to enhance WALL's
capabilities by integrating open-source LLMs and eliminating human
intervention, paving the way for fully automated code quality management.
\\ ( https://arxiv.org/abs/2509.09918 ,  516kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09942 (*cross-listing*)
Date: Fri, 12 Sep 2025 03:14:50 GMT   (743kb)

Title: SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation
  with Security-Aware Group Relative Policy Optimization
Authors: Lei Yu, Jingyuan Zhang, Xin Wang, Jiajia Ma, Li Yang, Fengjun Zhang
Categories: cs.CR cs.AI cs.SE
\\
  Smart contracts automate the management of high-value assets, where
vulnerabilities can lead to catastrophic financial losses. This challenge is
amplified in Large Language Models (LLMs) by two interconnected failures: they
operate as unauditable "black boxes" lacking a transparent reasoning process,
and consequently, generate code riddled with critical security vulnerabilities.
To address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a
novel framework for secure and explainable smart contract generation. It begins
with Continual Pre-training (CPT) to specialize the model. We then apply Long
Chain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated
reasoning-and-code samples to train the model to emulate human security
analysis. Finally, to directly mitigate vulnerabilities, we employ
Security-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement
learning phase that refines the generation policy by optimizing a weighted
reward signal for compilation success, security compliance, and format
correctness. Evaluated against 17 baselines on a benchmark of 756 real-world
functions, SmartCoder-R1 establishes a new state of the art, achieving top
performance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a
SafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This
FullRate marks a 45.79% relative improvement over the strongest baseline,
DeepSeek-R1. Crucially, its generated reasoning also excels in human
evaluations, achieving high-quality ratings for Functionality (82.7%), Security
(85.3%), and Clarity (90.7%).
\\ ( https://arxiv.org/abs/2509.09942 ,  743kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09955 (*cross-listing*)
Date: Fri, 12 Sep 2025 04:11:59 GMT   (7427kb)

Title: Adaptive Token Merging for Efficient Transformer Semantic Communication
  at the Edge
Authors: Omar Erak, Omar Alhussein, Hatem Abou-Zeid, Mehdi Bennis, Sami
  Muhaidat
Categories: cs.LG cs.AI cs.CV eess.IV
Comments: Submitted to IEEE Journals
\\
  Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.
\\ ( https://arxiv.org/abs/2509.09955 ,  7427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09960 (*cross-listing*)
Date: Fri, 12 Sep 2025 04:34:46 GMT   (4420kb)

Title: Limited Reference, Reliable Generation: A Two-Component Framework for
  Tabular Data Generation in Low-Data Regimes
Authors: Mingxuan Jiang, Yongxin Wang, Ziyue Dai, Yicun Liu, Hongyi Nie, Sen
  Liu, and Hongfeng Chai
Categories: cs.LG cs.AI
\\
  Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.
\\ ( https://arxiv.org/abs/2509.09960 ,  4420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09970 (*cross-listing*)
Date: Fri, 12 Sep 2025 05:15:35 GMT   (22kb)

Title: Securing LLM-Generated Embedded Firmware through AI Agent-Driven
  Validation and Patching
Authors: Seyed Moein Abtahi, Akramul Azim
Categories: cs.CR cs.AI
\\
  Large Language Models (LLMs) show promise in generating firmware for embedded
systems, but often introduce security flaws and fail to meet real-time
performance constraints. This paper proposes a three-phase methodology that
combines LLM-based firmware generation with automated security validation and
iterative refinement in a virtualized environment. Using structured prompts,
models like GPT-4 generate firmware for networking and control tasks, deployed
on FreeRTOS via QEMU. These implementations are tested using fuzzing, static
analysis, and runtime monitoring to detect vulnerabilities such as buffer
overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats
(CWE-400). Specialized AI agents for Threat Detection, Performance
Optimization, and Compliance Verification collaborate to improve detection and
remediation. Identified issues are categorized using CWE, then used to prompt
targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\%
Vulnerability Remediation Rate (37.3\% improvement), 95.8\% Threat Model
Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms
worst-case execution time and 195{\mu}s jitter. This process enhances firmware
security and performance while contributing an open-source dataset for future
research.
\\ ( https://arxiv.org/abs/2509.09970 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09972 (*cross-listing*)
Date: Fri, 12 Sep 2025 05:16:56 GMT   (839kb)

Title: Drone-Based Multispectral Imaging and Deep Learning for Timely Detection
  of Branched Broomrape in Tomato Farms
Authors: Mohammadreza Narimani, Alireza Pourreza, Ali Moghimi, Mohsen Mesgaran,
  Parastoo Farajpoor, and Hamid Jafarbiglu
Categories: eess.IV cs.AI cs.CV cs.LG
Comments: Author-accepted version (no publisher header/footer). 10 pages +
  presentation. Published in Proceedings of SPIE Defense + Commercial Sensing
  2024, Vol. 13053, Paper 1305304. Event: National Harbor, Maryland, USA.
  Official version: https://doi.org/10.1117/12.3021219
Journal-ref: Proc. SPIE 13053, Autonomous Air and Ground Sensing Systems for
  Agricultural Optimization and Phenotyping IX, 1305304 (7 June 2024)
DOI: 10.1117/12.3021219.
\\
  This study addresses the escalating threat of branched broomrape (Phelipanche
ramosa) to California's tomato industry, which supplies over 90 percent of U.S.
processing tomatoes. The parasite's largely underground life cycle makes early
detection difficult, while conventional chemical controls are costly,
environmentally harmful, and often ineffective. To address this, we combined
drone-based multispectral imagery with Long Short-Term Memory (LSTM) deep
learning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)
to handle class imbalance. Research was conducted on a known broomrape-infested
tomato farm in Woodland, Yolo County, CA, across five key growth stages
determined by growing degree days (GDD). Multispectral images were processed to
isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with
79.09 percent overall accuracy and 70.36 percent recall without integrating
later stages. Incorporating sequential growth stages with LSTM improved
detection substantially. The best-performing scenario, which integrated all
growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy
and 95.37 percent recall. These results demonstrate the strong potential of
temporal multispectral analysis and LSTM networks for early broomrape
detection. While further real-world data collection is needed for practical
deployment, this study shows that UAV-based multispectral sensing coupled with
deep learning could provide a powerful precision agriculture tool to reduce
losses and improve sustainability in tomato production.
\\ ( https://arxiv.org/abs/2509.09972 ,  839kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10011 (*cross-listing*)
Date: Fri, 12 Sep 2025 07:11:05 GMT   (347kb)

Title: Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer
  and a Projected Loss
Authors: Antoine Orioua, Philipp Krah, Julian Koellermeier
Categories: cs.LG cs.AI cs.NA math.NA
Comments: Preprint with 12 pages and 12 figures
\\
  This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.
\\ ( https://arxiv.org/abs/2509.10011 ,  347kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10025 (*cross-listing*)
Date: Fri, 12 Sep 2025 07:45:10 GMT   (4374kb)

Title: Exploring Expert Specialization through Unsupervised Training in Sparse
  Mixture of Experts
Authors: Strahinja Nikolic, Ilker Oguz, Demetri Psaltis
Categories: cs.LG cs.AI
Comments: 14 pages, 7 figures
\\
  Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.
\\ ( https://arxiv.org/abs/2509.10025 ,  4374kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10057 (*cross-listing*)
Date: Fri, 12 Sep 2025 08:41:39 GMT   (1286kb)

Title: Reinforcement learning for spin torque oscillator tasks
Authors: Jakub Mojsiejuk, S{\l}awomir Zi\k{e}tek, Witold Skowro\'nski
Categories: physics.app-ph cs.AI cs.LG
Comments: 3 figures, 6 pages
\\
  We address the problem of automatic synchronisation of the spintronic
oscillator (STO) by means of reinforcement learning (RL). A numerical solution
of the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to
simulate the STO and we train the two types of RL agents to synchronise with a
target frequency within a fixed number of steps. We explore modifications to
this base task and show an improvement in both convergence and energy
efficiency of the synchronisation that can be easily achieved in the simulated
environment.
\\ ( https://arxiv.org/abs/2509.10057 ,  1286kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10063 (*cross-listing*)
Date: Fri, 12 Sep 2025 08:51:28 GMT   (3330kb)

Title: TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim
  Digital Twin Sensor Model
Authors: Xiyan Huang and Zhe Xu and Chenxi Xiao
Categories: cs.RO cs.AI
Comments: 7 pages, 9 figures, 1 table, to be published in IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS 2025)
ACM-class: I.2.9
\\
  Robot skill acquisition processes driven by reinforcement learning often rely
on simulations to efficiently generate large-scale interaction data. However,
the absence of simulation models for tactile sensors has hindered the use of
tactile sensing in such skill learning processes, limiting the development of
effective policies driven by tactile perception. To bridge this gap, we present
TwinTac, a system that combines the design of a physical tactile sensor with
its digital twin model. Our hardware sensor is designed for high sensitivity
and a wide measurement range, enabling high quality sensing data essential for
object interaction tasks. Building upon the hardware sensor, we develop the
digital twin model using a real-to-sim approach. This involves collecting
synchronized cross-domain data, including finite element method results and the
physical sensor's outputs, and then training neural networks to map simulated
data to real sensor responses. Through experimental evaluation, we
characterized the sensitivity of the physical sensor and demonstrated the
consistency of the digital twin in replicating the physical sensor's output.
Furthermore, by conducting an object classification task, we showed that
simulation data generated by our digital twin sensor can effectively augment
real-world data, leading to improved accuracy. These results highlight
TwinTac's potential to bridge the gap in cross-domain learning tasks.
\\ ( https://arxiv.org/abs/2509.10063 ,  3330kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10077 (*cross-listing*)
Date: Fri, 12 Sep 2025 09:13:47 GMT   (8874kb)

Title: Predictive Spike Timing Enables Distributed Shortest Path Computation in
  Spiking Neural Networks
Authors: Simen Storesund, Kristian Valset Aars, Robin Dietrich, Nicolai Waniek
Categories: cs.NE cs.AI cs.DS cs.LG
\\
  Efficient planning and sequence selection are central to intelligence, yet
current approaches remain largely incompatible with biological computation.
Classical graph algorithms like Dijkstra's or A* require global state and
biologically implausible operations such as backtracing, while reinforcement
learning methods rely on slow gradient-based policy updates that appear
inconsistent with rapid behavioral adaptation observed in natural systems.
  We propose a biologically plausible algorithm for shortest-path computation
that operates through local spike-based message-passing with realistic
processing delays. The algorithm exploits spike-timing coincidences to identify
nodes on optimal paths: Neurons that receive inhibitory-excitatory message
pairs earlier than predicted reduce their response delays, creating a temporal
compression that propagates backwards from target to source. Through analytical
proof and simulations on random spatial networks, we demonstrate that the
algorithm converges and discovers all shortest paths using purely timing-based
mechanisms. By showing how short-term timing dynamics alone can compute
shortest paths, this work provides new insights into how biological networks
might solve complex computational problems through purely local computation and
relative spike-time prediction. These findings open new directions for
understanding distributed computation in biological and artificial systems,
with possible implications for computational neuroscience, AI, reinforcement
learning, and neuromorphic systems.
\\ ( https://arxiv.org/abs/2509.10077 ,  8874kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10099 (*cross-listing*)
Date: Fri, 12 Sep 2025 09:49:46 GMT   (1582kb)

Title: Generating Energy-Efficient Code via Large-Language Models -- Where are
  we now?
Authors: Radu Apsan, Vincenzo Stoico, Michel Albonico, Rudra Dhar, Karthik
  Vaidhyanathan, Ivano Malavolta
Categories: cs.SE cs.AI
\\
  Context. The rise of Large Language Models (LLMs) has led to their widespread
adoption in development pipelines. Goal. We empirically assess the energy
efficiency of Python code generated by LLMs against human-written code and code
developed by a Green software expert. Method. We test 363 solutions to 9 coding
problems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting
techniques, and comparing them to human-developed solutions. Energy consumption
is measured on three different hardware platforms: a server, a PC, and a
Raspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%
more energy-efficient on the server and 3% on the Raspberry Pi, while LLMs
outperform human developers by 25% on the PC. Prompting does not consistently
lead to energy savings, where the most energy-efficient prompts vary by
hardware platform. The code developed by a Green software expert is
consistently more energy-efficient by at least 17% to 30% against all LLMs on
all hardware platforms. Conclusions. Even though LLMs exhibit relatively good
code generation capabilities, no LLM-generated code was more energy-efficient
than that of an experienced Green software developer, suggesting that as of
today there is still a great need of human expertise for developing
energy-efficient Python code.
\\ ( https://arxiv.org/abs/2509.10099 ,  1582kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10128 (*cross-listing*)
Date: Fri, 12 Sep 2025 10:43:58 GMT   (4570kb)

Title: Efficient Learning-Based Control of a Legged Robot in Lunar Gravity
Authors: Philip Arm, Oliver Fischer, Joseph Church, Adrian Fuhrer, Hendrik
  Kolvenbach, Marco Hutter
Categories: cs.RO cs.AI
\\
  Legged robots are promising candidates for exploring challenging areas on
low-gravity bodies such as the Moon, Mars, or asteroids, thanks to their
advanced mobility on unstructured terrain. However, as planetary robots' power
and thermal budgets are highly restricted, these robots need energy-efficient
control approaches that easily transfer to multiple gravity environments. In
this work, we introduce a reinforcement learning-based control approach for
legged robots with gravity-scaled power-optimized reward functions. We use our
approach to develop and validate a locomotion controller and a base pose
controller in gravity environments from lunar gravity (1.62 m/s2) to a
hypothetical super-Earth (19.62 m/s2). Our approach successfully scales across
these gravity levels for locomotion and base pose control with the
gravity-scaled reward functions. The power-optimized locomotion controller
reached a power consumption for locomotion of 23.4 W in Earth gravity on a
15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.
Additionally, we designed a constant-force spring offload system that allowed
us to conduct real-world experiments on legged locomotion in lunar gravity. In
lunar gravity, the power-optimized control policy reached 12.2 W, 36 % less
than a baseline controller which is not optimized for power efficiency. Our
method provides a scalable approach to developing power-efficient locomotion
controllers for legged robots across multiple gravity levels.
\\ ( https://arxiv.org/abs/2509.10128 ,  4570kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10151 (*cross-listing*)
Date: Fri, 12 Sep 2025 11:27:17 GMT   (1420kb)

Title: BenchECG and xECG: a benchmark and baseline for ECG foundation models
Authors: Riccardo Lunelli, Angus Nicolson, Samuel Martin Pr\"oll, Sebastian
  Johannes Reinstadler, Axel Bauer, Clemens Dlaska
Categories: cs.LG cs.AI
Comments: 32 pages, 4 figures, 22 tables
ACM-class: I.2.1
\\
  Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.
\\ ( https://arxiv.org/abs/2509.10151 ,  1420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10220 (*cross-listing*)
Date: Fri, 12 Sep 2025 13:12:09 GMT   (464kb)

Title: Openness in AI and downstream governance: A global value chain approach
Authors: Christopher Foster
Categories: cs.CY cs.AI
ACM-class: K.4.1; K.4.3
\\
  The rise of AI has been rapid, becoming a leading sector for investment and
promising disruptive impacts across the economy. Within the critical analysis
of the economic impacts, AI has been aligned to the critical literature on data
power and platform capitalism - further concentrating power and value capture
amongst a small number of "big tech" leaders.
  The equally rapid rise of openness in AI (here taken to be claims made by AI
firms about openness, "open source" and free provision) signals an interesting
development. It highlights an emerging ecosystem of open AI models, datasets
and toolchains, involving massive capital investment. It poses questions as to
whether open resources can support technological transfer and the ability for
catch-up, even in the face of AI industry power.
  This work seeks to add conceptual clarity to these debates by conceptualising
openness in AI as a unique type of interfirm relation and therefore amenable to
value chain analysis. This approach then allows consideration of the capitalist
dynamics of "outsourcing" of foundational firms in value chains, and
consequently the types of governance and control that might emerge downstream
as AI is adopted. This work, therefore, extends previous mapping of AI value
chains to build a framework which links foundational AI with downstream value
chains.
  Overall, this work extends our understanding of AI as a productive sector.
While the work remains critical of the power of leading AI firms, openness in
AI may lead to potential spillovers stemming from the intense competition for
global technological leadership in AI.
\\ ( https://arxiv.org/abs/2509.10220 ,  464kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10289 (*cross-listing*)
Date: Fri, 12 Sep 2025 14:29:14 GMT   (162kb)

Title: We Need a New Ethics for a World of AI Agents
Authors: Iason Gabriel, Geoff Keeling, Arianna Manzini, James Evans
Categories: cs.CY cs.AI
Comments: 6 pages, no figures
ACM-class: I.2.0; K.4.1
Journal-ref: Nature, 644 (8075), 2025, 38-40
DOI: 10.1038/d41586-025-02454-5
\\
  The deployment of capable AI agents raises fresh questions about safety,
human-machine relationships and social coordination. We argue for greater
engagement by scientists, scholars, engineers and policymakers with the
implications of a world increasingly populated by AI agents. We explore key
challenges that must be addressed to ensure that interactions between humans
and agents, and among agents themselves, remain broadly beneficial.
\\ ( https://arxiv.org/abs/2509.10289 ,  162kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10303 (*cross-listing*)
Date: Fri, 12 Sep 2025 14:45:39 GMT   (1333kb)

Title: Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns
  Effective Scheduling through Random Data
Authors: Jesse van Remmerden, Zaharah Bukhsh, Yingqian Zhang
Categories: cs.LG cs.AI
\\
  The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.
\\ ( https://arxiv.org/abs/2509.10303 ,  1333kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10369 (*cross-listing*)
Date: Fri, 12 Sep 2025 16:01:18 GMT   (907kb)

Title: Data distribution impacts the performance and generalisability of
  contrastive learning-based foundation models of electrocardiograms
Authors: Gul Rukh Khattak, Konstantinos Patlatzoglou, Joseph Barker, Libor
  Pastika, Boroumand Zeidaabadi, Ahmed El-Medany, Hesham Aggour, Yixiu Liang,
  Antonio H. Ribeiro, Jeffrey Annis, Antonio Luiz Pinho Ribeiro, Junbo Ge,
  Daniel B. Kramer, Jonathan W. Waks, Evan Brittain, Nicholas Peters, Fu Siong
  Ng, Arunashis Sau
Categories: cs.LG cs.AI eess.SP q-bio.TO
Comments: Currently under review at npj Digital Medicine
\\
  Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.
\\ ( https://arxiv.org/abs/2509.10369 ,  907kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10391 (*cross-listing*)
Date: Fri, 12 Sep 2025 16:31:20 GMT   (562kb)

Title: Improving Audio Event Recognition with Consistency Regularization
Authors: Shanmuka Sadhu and Weiran Wang
Categories: cs.SD cs.AI
Comments: Under Review
\\
  Consistency regularization (CR), which enforces agreement between model
predictions on augmented views, has found recent benefits in automatic speech
recognition [1]. In this paper, we propose the use of consistency
regularization for audio event recognition, and demonstrate its effectiveness
on AudioSet. With extensive ablation studies for both small ($\sim$20k) and
large ($\sim$1.8M) supervised training sets, we show that CR brings consistent
improvement over supervised baselines which already heavily utilize data
augmentation, and CR using stronger augmentation and multiple augmentations
leads to additional gain for the small training set. Furthermore, we extend the
use of CR into the semi-supervised setup with 20K labeled samples and 1.8M
unlabeled samples, and obtain performance improvement over our best model
trained on the small set.
\\ ( https://arxiv.org/abs/2509.10391 ,  562kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10392 (*cross-listing*)
Date: Fri, 12 Sep 2025 16:34:07 GMT   (75kb)

Title: Diversified recommendations of cultural activities with personalized
  determinantal point processes
Authors: Carole Ibrahim, Hiba Bederina, Daniel Cuesta, Laurent Montier, Cyrille
  Delabre, Jill-J\^enn Vie
Categories: cs.IR cs.AI
Comments: 7 pages, accepted at RecSys workshop RecSoGood 2025
Journal-ref: RecSoGood 2025 - Second International Workshop on Recommender
  Systems for Sustainability and Social Good
\\
  While optimizing recommendation systems for user engagement is a
well-established practice, effectively diversifying recommendations without
negatively impacting core business metrics remains a significant industry
challenge. In line with our initiative to broaden our audience's cultural
practices, this study investigates using personalized Determinantal Point
Processes (DPPs) to sample diverse and relevant recommendations. We rely on a
well-known quality-diversity decomposition of the similarity kernel to give
more weight to user preferences. In this paper, we present our implementations
of the personalized DPP sampling, evaluate the trade-offs between relevance and
diversity through both offline and online metrics, and give insights for
practitioners on their use in a production environment. For the sake of
reproducibility, we release the full code for our platform and experiments on
GitHub.
\\ ( https://arxiv.org/abs/2509.10392 ,  75kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10432 (*cross-listing*)
Date: Fri, 12 Sep 2025 17:38:46 GMT   (753kb)

Title: Standards in the Preparation of Biomedical Research Metadata: A
  Bridge2AI Perspective
Authors: Harry Caufield, Satrajit Ghosh, Sek Wong Kong, Jillian Parker, Nathan
  Sheffield, Bhavesh Patel, Andrew Williams, Timothy Clark, Monica C.
  Munoz-Torres
Categories: q-bio.OT cs.AI
\\
  AI-readiness describes the degree to which data may be optimally and
ethically used for subsequent AI and Machine Learning (AI/ML) methods, where
those methods may involve some combination of model training, data
classification, and ethical, explainable prediction. The Bridge2AI consortium
has defined the particular criteria a biomedical dataset may possess to render
it AI-ready: in brief, a dataset's readiness is related to its FAIRness,
provenance, degree of characterization, explainability, sustainability, and
computability, in addition to its accompaniment with documentation about
ethical data practices.
  To ensure AI-readiness and to clarify data structure and relationships within
Bridge2AI's Grand Challenges (GCs), particular types of metadata are necessary.
The GCs within the Bridge2AI initiative include four data-generating projects
focusing on generating AI/ML-ready datasets to tackle complex biomedical and
behavioral research problems. These projects develop standardized, multimodal
data, tools, and training resources to support AI integration, while addressing
ethical data practices. Examples include using voice as a biomarker, building
interpretable genomic tools, modeling disease trajectories with diverse
multimodal data, and mapping cellular and molecular health indicators across
the human body.
  This report assesses the state of metadata creation and standardization in
the Bridge2AI GCs, provides guidelines where required, and identifies gaps and
areas for improvement across the program. New projects, including those outside
the Bridge2AI consortium, would benefit from what we have learned about
creating metadata as part of efforts to promote AI readiness.
\\ ( https://arxiv.org/abs/2509.10432 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09987 (*cross-listing*)
Date: Fri, 12 Sep 2025 06:03:24 GMT   (531kb)

Title: Whisper Has an Internal Word Aligner
Authors: Sung-Lin Yeh, Yen Meng, Hao Tang
Categories: eess.AS cs.CL
Comments: ASRU 2025
\\
  There is an increasing interest in obtaining accurate word-level timestamps
from strong automatic speech recognizers, in particular Whisper. Existing
approaches either require additional training or are simply not competitive.
The evaluation in prior work is also relatively loose, typically using a
tolerance of more than 200 ms. In this work, we discover attention heads in
Whisper that capture accurate word alignments and are distinctively different
from those that do not. Moreover, we find that using characters produces finer
and more accurate alignments than using wordpieces. Based on these findings, we
propose an unsupervised approach to extracting word alignments by filtering
attention heads while teacher forcing Whisper with characters. Our approach not
only does not require training but also produces word alignments that are more
accurate than prior work under a stricter tolerance between 20 ms and 100 ms.
\\ ( https://arxiv.org/abs/2509.09987 ,  531kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10031 (*cross-listing*)
Date: Fri, 12 Sep 2025 07:52:51 GMT   (199kb)

Title: Unified Learnable 2D Convolutional Feature Extraction for ASR
Authors: Peter Vieting, Benedikt Hilmes, Ralf Schl\"uter, Hermann Ney
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: Accepted at ITG Conference on Speech Communication 2025
\\
  Neural front-ends represent a promising approach to feature extraction for
automatic speech recognition (ASR) systems as they enable to learn specifically
tailored features for different tasks. Yet, many of the existing techniques
remain heavily influenced by classical methods. While this inductive bias may
ease the system design, our work aims to develop a more generic front-end for
feature extraction. Furthermore, we seek to unify the front-end architecture
contrasting with existing approaches that apply a composition of several layer
topologies originating from different sources. The experiments systematically
show how to reduce the influence of existing techniques to achieve a generic
front-end. The resulting 2D convolutional front-end is parameter-efficient and
suitable for a scenario with limited computational resources unlike large
models pre-trained on unlabeled audio. The results demonstrate that this
generic unified approach is not only feasible but also matches the performance
of existing supervised learnable feature extractors.
\\ ( https://arxiv.org/abs/2509.10031 ,  199kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10143 (*cross-listing*)
Date: Fri, 12 Sep 2025 11:10:38 GMT   (182kb)

Title: Error Analysis in a Modular Meeting Transcription System
Authors: Peter Vieting, Simon Berger, Thilo von Neumann, Christoph Boeddeker,
  Ralf Schl\"uter, Reinhold Haeb-Umbach
Categories: eess.AS cs.CL cs.LG cs.SD
Comments: Accepted at ITG Conference on Speech Communication 2025
\\
  Meeting transcription is a field of high relevance and remarkable progress in
recent years. Still, challenges remain that limit its performance. In this
work, we extend a previously proposed framework for analyzing leakage in speech
separation with proper sensitivity to temporal locality. We show that there is
significant leakage to the cross channel in areas where only the primary
speaker is active. At the same time, the results demonstrate that this does not
affect the final performance much as these leaked parts are largely ignored by
the voice activity detection (VAD). Furthermore, different segmentations are
compared showing that advanced diarization approaches are able to reduce the
gap to oracle segmentation by a third compared to a simple energy-based VAD. We
additionally reveal what factors contribute to the remaining difference. The
results represent state-of-the-art performance on LibriCSS among systems that
train the recognition module on LibriSpeech data only.
\\ ( https://arxiv.org/abs/2509.10143 ,  182kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09926 (*cross-listing*)
Date: Fri, 12 Sep 2025 02:28:32 GMT   (6725kb)

Title: LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised
  Learning in Open-World Scenarios
Authors: Jiahao Chen, Zhiyuan Huang, Yurou Liu, Bing Su
Categories: cs.LG cs.CV
\\
  Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.
\\ ( https://arxiv.org/abs/2509.09926 ,  6725kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09952 (*cross-listing*)
Date: Fri, 12 Sep 2025 04:03:07 GMT   (15085kb)

Title: Chord: Chain of Rendering Decomposition for PBR Material Estimation from
  Generated Texture Images
Authors: Zhi Ying, Boxiang Rong, Jingyu Wang, Maoyuan Xu
Categories: cs.GR cs.CV
Comments: Accepted to SIGGRAPH Asia 2025. Project page:
  https://ubisoft-laforge.github.io/world/chord
\\
  Material creation and reconstruction are crucial for appearance modeling but
traditionally require significant time and expertise from artists. While recent
methods leverage visual foundation models to synthesize PBR materials from
user-provided inputs, they often fall short in quality, flexibility, and user
control. We propose a novel two-stage generate-and-estimate framework for PBR
material generation. In the generation stage, a fine-tuned diffusion model
synthesizes shaded, tileable texture images aligned with user input. In the
estimation stage, we introduce a chained decomposition scheme that sequentially
predicts SVBRDF channels by passing previously extracted representation as
input into a single-step image-conditional diffusion model. Our method is
efficient, high quality, and enables flexible user control. We evaluate our
approach against existing material generation and estimation methods,
demonstrating superior performance. Our material estimation method shows strong
robustness on both generated textures and in-the-wild photographs. Furthermore,
we highlight the flexibility of our framework across diverse applications,
including text-to-material, image-to-material, structure-guided generation, and
material editing.
\\ ( https://arxiv.org/abs/2509.09952 ,  15085kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10096 (*cross-listing*)
Date: Fri, 12 Sep 2025 09:38:17 GMT   (7543kb)

Title: HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in
  Physical Assistance Scenario
Authors: Saeed Saadatnejad, Reyhaneh Hosseininejad, Jose Barreiros, Katherine
  M. Tsui, Alexandre Alahi
Categories: cs.RO cs.CV
Comments: Accepted to RA-L 2025
Journal-ref: IEEE Robotics and Automation Letters, vol. 10, no. 9, pp.
  8746-8753, Sept. 2025
DOI: 10.1109/LRA.2025.3586011
\\
  The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home
\\ ( https://arxiv.org/abs/2509.10096 ,  7543kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10098 (*cross-listing*)
Date: Fri, 12 Sep 2025 09:40:42 GMT   (1480kb)

Title: Polarization Denoising and Demosaicking: Dataset and Baseline Method
Authors: Muhamad Daniel Ariff Bin Abdul Rahman, Yusuke Monno, Masayuki Tanaka,
  Masatoshi Okutomi
Categories: eess.IV cs.CV
Comments: Published in ICIP2025; Project page:
  http://www.ok.sc.e.titech.ac.jp/res/PolarDem/PDD.html
\\
  A division-of-focal-plane (DoFP) polarimeter enables us to acquire images
with multiple polarization orientations in one shot and thus it is valuable for
many applications using polarimetric information. The image processing pipeline
for a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.
While polarization demosaicking for a noise-free case has increasingly been
studied, the research for the joint task of polarization denoising and
demosaicking is scarce due to the lack of a suitable evaluation dataset and a
solid baseline method. In this paper, we propose a novel dataset and method for
polarization denoising and demosaicking. Our dataset contains 40 real-world
scenes and three noise-level conditions, consisting of pairs of noisy mosaic
inputs and noise-free full images. Our method takes a
denoising-then-demosaicking approach based on well-accepted signal processing
components to offer a reproducible method. Experimental results demonstrate
that our method exhibits higher image reconstruction performance than other
alternative methods, offering a solid baseline.
\\ ( https://arxiv.org/abs/2509.10098 ,  1480kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10348 (*cross-listing*)
Date: Fri, 12 Sep 2025 15:36:26 GMT   (680kb)

Title: Multi-pathology Chest X-ray Classification with Rejection Mechanisms
Authors: Yehudit Aperstein, Amit Tzahar, Alon Gottlib, Tal Verber, Ravit Shagan
  Damti, Alexander Apartsin
Categories: eess.IV cs.CV cs.LG
Comments: 12 pages, 4 figures
\\
  Overconfidence in deep learning models poses a significant risk in
high-stakes medical imaging tasks, particularly in multi-label classification
of chest X-rays, where multiple co-occurring pathologies must be detected
simultaneously. This study introduces an uncertainty-aware framework for chest
X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective
prediction mechanisms: entropy-based rejection and confidence interval-based
rejection. Both methods enable the model to abstain from uncertain predictions,
improving reliability by deferring ambiguous cases to clinical experts. A
quantile-based calibration procedure is employed to tune rejection thresholds
using either global or class-specific strategies. Experiments conducted on
three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)
demonstrate that selective rejection improves the trade-off between diagnostic
accuracy and coverage, with entropy-based rejection yielding the highest
average AUC across all pathologies. These results support the integration of
selective prediction into AI-assisted diagnostic workflows, providing a
practical step toward safer, uncertainty-aware deployment of deep learning in
clinical settings.
\\ ( https://arxiv.org/abs/2509.10348 ,  680kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10454 (*cross-listing*)
Date: Fri, 12 Sep 2025 17:59:58 GMT   (3183kb)

Title: GC-VLN: Instruction as Graph Constraints for Training-free
  Vision-and-Language Navigation
Authors: Hang Yin, Haoyu Wei, Xiuwei Xu, Wenxuan Guo, Jie Zhou, Jiwen Lu
Categories: cs.RO cs.CV
Comments: Accepted to CoRL 2025. Project page: [this https
  URL](https://bagh2178.github.io/GC-VLN/)
\\
  In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.
\\ ( https://arxiv.org/abs/2509.10454 ,  3183kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09898 (*cross-listing*)
Date: Thu, 11 Sep 2025 23:19:25 GMT   (843kb)

Title: DBOS Network Sensing: A Web Services Approach to Collaborative Awareness
Authors: Sophia Lockton, Jeremy Kepner, Michael Stonebraker, Hayden Jananthan,
  LaToya Anderson, William Arcand, David Bestor, William Bergeron, Alex Bonn,
  Daniel Burrill, Chansup Byun, Timothy Davis, Vijay Gadepally, Michael Houle,
  Matthew Hubbell, Michael Jones, Piotr Luszczek, Peter Michaleas, Lauren
  Milechin, Chasen Milner, Guillermo Morales, Julie Mullen, Michel Pelletier,
  Alex Poliakov, Andrew Prout, Albert Reuther, Antonio Rosa, Charles Yee, Alex
  Pentland
Categories: cs.NI cs.CR cs.DB cs.DC cs.OS
Comments: 8 pages, 10 figures, 37 references, accepted to IEEE HPEC 2025
\\
  DBOS (DataBase Operating System) is a novel capability that integrates web
services, operating system functions, and database features to significantly
reduce web-deployment effort while increasing resilience. Integration of high
performance network sensing enables DBOS web services to collaboratively create
a shared awareness of their network environments to enhance their collective
resilience and security. Network sensing is added to DBOS using GraphBLAS
hypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)
OneSparse PostgreSQL. These capabilities are demonstrated using the workflow
and analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph
Challenge. The system was parallelized using pPython and benchmarked using 64
compute nodes on the MIT SuperCloud. The web request rate sustained by a single
DBOS instance was ${>}10^5$, well above the required maximum, indicating that
network sensing can be added to DBOS with negligible overhead. For
collaborative awareness, many DBOS instances were connected to a single DBOS
aggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations
scaled linearly up to 64 and 32 nodes respectively. These results suggest that
DBOS collaborative network awareness can be achieved with a negligible increase
in computing resources.
\\ ( https://arxiv.org/abs/2509.09898 ,  843kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10161 (*cross-listing*)
Date: Fri, 12 Sep 2025 11:41:06 GMT   (9845kb)

Title: FedBiF: Communication-Efficient Federated Learning via Bits Freezing
Authors: Shiwei Li, Qunwei Li, Haozhao Wang, Ruixuan Li, Jianbin Lin, Wenliang
  Zhong
Categories: cs.LG cs.DC
Comments: Accepted by TPDS
\\
  Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.
\\ ( https://arxiv.org/abs/2509.10161 ,  9845kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10426 (*cross-listing*)
Date: Fri, 12 Sep 2025 17:29:02 GMT   (2013kb)

Title: DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with
  Disentangled Context-Aware Pre-Training
Authors: Jianxin Shi, Zengqi Peng, Xiaolong Chen, Tianyu Wo, Jun Ma
Categories: cs.RO cs.MA
\\
  Trajectory prediction is a critical component of autonomous driving,
essential for ensuring both safety and efficiency on the road. However,
traditional approaches often struggle with the scarcity of labeled data and
exhibit suboptimal performance in multi-agent prediction scenarios. To address
these challenges, we introduce a disentangled context-aware pre-training
framework for multi-agent motion prediction, named DECAMP. Unlike existing
methods that entangle representation learning with pretext tasks, our framework
decouples behavior pattern learning from latent feature reconstruction,
prioritizing interpretable dynamics and thereby enhancing scene representation
for downstream prediction. Additionally, our framework incorporates
context-aware representation learning alongside collaborative spatial-motion
pretext tasks, which enables joint optimization of structural and intentional
reasoning while capturing the underlying dynamic intentions. Our experiments on
the Argoverse 2 benchmark showcase the superior performance of our method, and
the results attained underscore its effectiveness in multi-agent motion
forecasting. To the best of our knowledge, this is the first context
autoencoder framework for multi-agent motion forecasting in autonomous driving.
The code and models will be made publicly available.
\\ ( https://arxiv.org/abs/2509.10426 ,  2013kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2407.01875
replaced with revised version Fri, 12 Sep 2025 02:04:17 GMT   (3500kb)

Title: Spatio-Temporal Graphical Counterfactuals: An Overview
Authors: Mingyu Kang and Duxin Chen and Ziyuan Pu and Jianxi Gao and Wenwu Yu
Categories: cs.AI
Comments: in press
Journal-ref: SCIENCE CHINA Information Sciences, 2025
\\ ( https://arxiv.org/abs/2407.01875 ,  3500kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20600
replaced with revised version Fri, 12 Sep 2025 13:52:45 GMT   (2788kb)

Title: Multi-Turn Human-LLM Interaction Through the Lens of a Two-Way
  Intelligibility Protocol
Authors: Harshvardhan Mestha, Karan Bania, Shreyas V, Sidong Liu, Ashwin
  Srinivasan
Categories: cs.AI cs.HC cs.LG cs.MA
\\ ( https://arxiv.org/abs/2410.20600 ,  2788kb)
------------------------------------------------------------------------------
\\
arXiv:2502.00858
replaced with revised version Fri, 12 Sep 2025 15:09:06 GMT   (10992kb)

Title: Learning to Plan with Personalized Preferences
Authors: Manjie Xu, Xinyi Yang, Wei Liang, Chi Zhang, Yixin Zhu
Categories: cs.AI cs.HC
\\ ( https://arxiv.org/abs/2502.00858 ,  10992kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07531
replaced with revised version Fri, 12 Sep 2025 12:03:22 GMT   (1374kb)

Title: QuantX: A Framework for Hardware-Aware Quantization of Generative AI
  Workloads
Authors: Muhammad Ahmad, Khurram Mazher, Saqib Akram, Ahmad Tameem and Saad Bin
  Nasir
Categories: cs.AI eess.SP
\\ ( https://arxiv.org/abs/2505.07531 ,  1374kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19005
replaced with revised version Fri, 12 Sep 2025 05:22:00 GMT   (1467kb)

Title: Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A
  Framework and Benchmark
Authors: Yuxuan Cai, Yipeng Hao, Jie Zhou, Hang Yan, Zhikai Lei, Rui Zhen,
  Zhenhua Han, Yutao Yang, Junsong Li, Qianjun Pan, Tianyu Huai, Qin Chen, Xin
  Li, Kai Chen, Bo Zhang, Xipeng Qiu, and Liang He
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2508.19005 ,  1467kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01909
replaced with revised version Fri, 12 Sep 2025 04:23:22 GMT   (5747kb)

Title: Oyster-I: Beyond Refusal -- Constructive Safety Alignment for
  Responsible Language Models
Authors: Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng,
  Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong,
  Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu,
  Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu,
  Yitong Yang, Jialing Tao, Hui Xue
Categories: cs.AI cs.CL cs.CY cs.HC cs.SC
Comments: Technical Report Code & Model weights available:
  https://github.com/Alibaba-AAIG/Oyster
\\ ( https://arxiv.org/abs/2509.01909 ,  5747kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08972
replaced with revised version Fri, 12 Sep 2025 01:02:19 GMT   (2788kb)

Title: ForTIFAI: Fending Off Recursive Training Induced Failure for AI Models
Authors: Soheil Zibakhsh Shabgahi, Pedram Aghazadeh, Azalia Mirhoseini, and
  Farinaz Koushanfar
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.08972 ,  2788kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09448
replaced with revised version Fri, 12 Sep 2025 14:00:08 GMT   (3085kb)

Title: TORSO: Template-Oriented Reasoning Towards General Tasks
Authors: Minhyuk Kim, Seungyoon Lee, Heuiseok Lim
Categories: cs.AI
Comments: Accepted to EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2509.09448 ,  3085kb)
------------------------------------------------------------------------------
\\
arXiv:2405.13798
replaced with revised version Fri, 12 Sep 2025 17:03:33 GMT   (1360kb)

Title: Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property
  for Perplexity in Generative Language Models
Authors: Tyler Bell, Avinash Mudireddy, Ivan Johnson-Eversoll, Soura Dasgupta
  and Raghu Mudumbai
Categories: cs.CL cs.AI cs.IT math.IT
\\ ( https://arxiv.org/abs/2405.13798 ,  1360kb)
------------------------------------------------------------------------------
\\
arXiv:2406.18173
replaced with revised version Fri, 12 Sep 2025 15:39:00 GMT   (0kb,I)

Title: UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs
Authors: Wenhao Li and Mingbao Lin and Yunshan Zhong and Shuicheng Yan and
  Rongrong Ji
Categories: cs.CL
Comments: This article was not accepted, and its quality is not very good.
  Therefore, we have decided to withdraw the submission and will not resubmit
  it elsewhere
\\ ( https://arxiv.org/abs/2406.18173 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2409.14664
replaced with revised version Fri, 12 Sep 2025 17:21:39 GMT   (175kb)

Title: Direct Judgement Preference Optimization
Authors: Peifeng Wang, Austin Xu, Yilun Zhou, Caiming Xiong, Shafiq Joty
Categories: cs.CL
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2409.14664 ,  175kb)
------------------------------------------------------------------------------
\\
arXiv:2410.16708
replaced with revised version Fri, 12 Sep 2025 01:53:59 GMT   (8874kb)

Title: Atomic Fact Decomposition Helps Attributed Question Answering
Authors: Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Xiaoli Li, Ru Li, Jeff Z.Pan
Categories: cs.CL
\\ ( https://arxiv.org/abs/2410.16708 ,  8874kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18889
replaced with revised version Fri, 12 Sep 2025 17:18:27 GMT   (3070kb)

Title: Are LLMs Better than Reported? Detecting Label Errors and Mitigating
  Their Effect on Model Performance
Authors: Omer Nahum, Nitay Calderon, Orgad Keller, Idan Szpektor, Roi Reichart
Categories: cs.CL
\\ ( https://arxiv.org/abs/2410.18889 ,  3070kb)
------------------------------------------------------------------------------
\\
arXiv:2412.00559
replaced with revised version Fri, 12 Sep 2025 06:49:21 GMT   (9470kb)

Title: Polish-English medical knowledge transfer: A new benchmark and results
Authors: {\L}ukasz Grzybowski, Jakub Pokrywka, Micha{\l} Ciesi\'o{\l}ka, Jeremi
  I. Kaczmarek, Marek Kubis
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2412.00559 ,  9470kb)
------------------------------------------------------------------------------
\\
arXiv:2412.01340
replaced with revised version Fri, 12 Sep 2025 12:10:06 GMT   (2389kb)

Title: A 2-step Framework for Automated Literary Translation Evaluation: Its
  Promises and Pitfalls
Authors: Sheikh Shafayat, Dongkeun Yoon, Woori Jang, Jiwoo Choi, Alice Oh,
  Seohyon Jung
Categories: cs.CL
\\ ( https://arxiv.org/abs/2412.01340 ,  2389kb)
------------------------------------------------------------------------------
\\
arXiv:2412.10924
replaced with revised version Thu, 11 Sep 2025 21:57:39 GMT   (31961kb)

Title: Tokens, the oft-overlooked appetizer: Large language models, the
  distributional hypothesis, and meaning
Authors: Julia Witte Zimmerman, Denis Hudon, Kathryn Cramer, Alejandro J. Ruiz,
  Calla Beauregard, Ashley Fehr, Mikaela Irene Fudolig, Bradford Demarest,
  Yoshi Meke Bird, Milo Z. Trujillo, Christopher M. Danforth, Peter Sheridan
  Dodds
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2412.10924 ,  31961kb)
------------------------------------------------------------------------------
\\
arXiv:2502.10990
replaced with revised version Fri, 12 Sep 2025 02:40:43 GMT   (375kb)

Title: FinMTEB: Finance Massive Text Embedding Benchmark
Authors: Yixuan Tang, Yi Yang
Categories: cs.CL cs.IR
Comments: EMNLP 2025, https://github.com/yixuantt/FinMTEB
\\ ( https://arxiv.org/abs/2502.10990 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11829
replaced with revised version Fri, 12 Sep 2025 04:48:46 GMT   (685kb)

Title: D\'ej\`a Vu: Multilingual LLM Evaluation through the Lens of Machine
  Translation Evaluation
Authors: Julia Kreutzer, Eleftheria Briakou, Sweta Agrawal, Marzieh Fadaee,
  Kocmi Tom
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2504.11829 ,  685kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13204
replaced with revised version Fri, 12 Sep 2025 09:08:05 GMT   (1242kb)

Title: Alignment-Augmented Speculative Decoding with Alignment Sampling and
  Conditional Verification
Authors: Jikai Wang, Zhenxu Tian, Juntao Li, Qingrong Xia, Xinyu Duan, Zhefeng
  Wang, Baoxing Huai, Min Zhang
Categories: cs.CL
Comments: Accepted at EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2505.13204 ,  1242kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14160
replaced with revised version Thu, 11 Sep 2025 20:26:08 GMT   (2414kb)

Title: Breaking Language Barriers or Reinforcing Bias? A Study of Gender and
  Racial Disparities in Multilingual Contrastive Vision Language Models
Authors: Zahraa Al Sahili, Ioannis Patras, Matthew Purver
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2505.14160 ,  2414kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17222
replaced with revised version Fri, 12 Sep 2025 06:41:58 GMT   (1077kb)

Title: Humans Hallucinate Too: Language Models Identify and Correct Subjective
  Annotation Errors With Label-in-a-Haystack Prompts
Authors: Georgios Chochlakis, Peter Wu, Arjun Bedi, Marcus Ma, Kristina Lerman,
  Shrikanth Narayanan
Categories: cs.CL
Comments: Accepted to the Main Proceedings of EMNLP, 2025. 20 pages, 16
  figures, 10 tables
\\ ( https://arxiv.org/abs/2505.17222 ,  1077kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18383
replaced with revised version Thu, 11 Sep 2025 22:14:33 GMT   (3613kb)

Title: NileChat: Towards Linguistically Diverse and Culturally Aware LLMs for
  Local Communities
Authors: Abdellah El Mekki, Houdaifa Atou, Omer Nacar, Shady Shehata, Muhammad
  Abdul-Mageed
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.18383 ,  3613kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19634
replaced with revised version Fri, 12 Sep 2025 01:41:20 GMT   (551kb)

Title: Faster and Better LLMs via Latency-Aware Test-Time Scaling
Authors: Zili Wang, Tianyu Zhang, Haoli Bai, Lu Hou, Xianzhi Yu, Wulong Liu,
  Shiming Xiang, Lei Zhu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.19634 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07899
replaced with revised version Thu, 11 Sep 2025 20:56:58 GMT   (881kb)

Title: MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed
  Retention for LLMs
Authors: Ke Wang, Yiming Qin, Nikolaos Dimitriadis, Alessandro Favero, Pascal
  Frossard
Categories: cs.CL cs.LG
Comments: The first two authors contributed equally to this work
\\ ( https://arxiv.org/abs/2506.07899 ,  881kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13335
replaced with revised version Fri, 12 Sep 2025 14:23:05 GMT   (3618kb)

Title: Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour
  Understanding from Traditional Puns to Topical Jokes
Authors: Tyler Loakman, William Thorne and Chenghua Lin
Categories: cs.CL
Comments: Accepted to Findings of EMNLP 2025
\\ ( https://arxiv.org/abs/2507.13335 ,  3618kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20241
replaced with revised version Fri, 12 Sep 2025 09:08:02 GMT   (2872kb)

Title: Reframe Your Life Story: Interactive Narrative Therapist and Innovative
  Moment Assessment with Large Language Models
Authors: Yi Feng, Jiaqi Wang, Wenxuan Zhang, Zhuang Chen, Yutong Shen, Xiyao
  Xiao, Minlie Huang, Liping Jing, Jian Yu
Categories: cs.CL
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2507.20241 ,  2872kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08791
replaced with revised version Fri, 12 Sep 2025 02:57:21 GMT   (1213kb)

Title: Feedback-Driven Tool-Use Improvements in Large Language Models via
  Automated Build Environments
Authors: Junjie Ye, Changhao Jiang, Zhengyin Du, Yufei Xu, Xuesong Yao, Zhiheng
  Xi, Xiaoran Fan, Qi Zhang, Tao Gui, Xuanjing Huang, Jiecao Chen
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.08791 ,  1213kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09337
replaced with revised version Thu, 11 Sep 2025 21:41:16 GMT   (1972kb)

Title: Decoding Neural Emotion Patterns through Large Language Model Embeddings
Authors: Gideon Vos, Maryam Ebrahimpour, Liza van Eijk, Zoltan Sarnyai, Mostafa
  Rahimi Azghadi
Categories: cs.CL
Comments: 26 pages, 9 figures
\\ ( https://arxiv.org/abs/2508.09337 ,  1972kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01328
replaced with revised version Fri, 12 Sep 2025 07:26:28 GMT   (233kb)

Title: Can Large Language Models Master Complex Card Games?
Authors: Wei Wang, Felix Henry, Junzhe Chen, Dan Zhang, Shiyu Huang, Evgeny
  Kharlamov, Jie Tang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.01328 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06806
replaced with revised version Fri, 12 Sep 2025 13:11:51 GMT   (910kb)

Title: MachineLearningLM: Scaling Many-shot In-context Learning via Continued
  Pretraining
Authors: Haoyu Dong, Pengkun Zhang, Mingzhe Lu, Yanzhen Shen, Guolin Ke
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.06806 ,  910kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07980
replaced with revised version Fri, 12 Sep 2025 17:15:56 GMT   (1612kb)

Title: Parallel-R1: Towards Parallel Thinking via Reinforcement Learning
Authors: Tong Zheng, Hongming Zhang, Wenhao Yu, Xiaoyang Wang, Runpeng Dai, Rui
  Liu, Huiwen Bao, Chengsong Huang, Heng Huang, Dong Yu
Categories: cs.CL
Comments: Project website: https://zhengkid.github.io/Parallel_R1.github.io/
\\ ( https://arxiv.org/abs/2509.07980 ,  1612kb)
------------------------------------------------------------------------------
\\
arXiv:2208.06175
replaced with revised version Fri, 12 Sep 2025 10:28:58 GMT   (2271kb)

Title: The Weighting Game: Evaluating Quality of Explainability Methods
Authors: Lassi Raatikainen and Esa Rahtu
Categories: cs.CV
Comments: Published in: Image Analysis (SCIA 2025), Lecture Notes in Computer
  Science (LNCS), vol. 15726, pp. 325-338 (2025). This is the
  submitted-manuscript (pre-review) version. v2: added required preprint notice
  and updated metadata. Version of Record: see DOI 10.1007/978-3-031-95918-9_23
Journal-ref: Lecture Notes in Computer Science (LNCS), 15726:325-338 (2025).
  Image Analysis (SCIA 2025)
DOI: 10.1007/978-3-031-95918-9_23
\\ ( https://arxiv.org/abs/2208.06175 ,  2271kb)
------------------------------------------------------------------------------
\\
arXiv:2301.02560
replaced with revised version Thu, 11 Sep 2025 19:49:28 GMT   (41204kb)

Title: GeoDE: a Geographically Diverse Evaluation Dataset for Object
  Recognition
Authors: Vikram V. Ramaswamy, Sing Yu Lin, Dora Zhao, Aaron B. Adcock, Laurens
  van der Maaten, Deepti Ghadiyaram, Olga Russakovsky
Categories: cs.CV
Comments: Published at NeurIPS D&B, 2023
\\ ( https://arxiv.org/abs/2301.02560 ,  41204kb)
------------------------------------------------------------------------------
\\
arXiv:2304.11631
replaced with revised version Fri, 12 Sep 2025 03:36:02 GMT   (459kb)

Title: TSGCNeXt: Dynamic-Static Multi-Graph Convolution for Efficient
  Skeleton-Based Action Recognition with Long-term Learning Potential
Authors: Dongjingdin Liu, Pengpeng Chen, Miao Yao, Yijing Lu, Zijie Cai, Yuxin
  Tian
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2304.11631 ,  459kb)
------------------------------------------------------------------------------
\\
arXiv:2410.14334
replaced with revised version Fri, 12 Sep 2025 10:32:29 GMT   (2402kb)

Title: Evaluating the Evaluators: Towards Human-aligned Metrics for Missing
  Markers Reconstruction
Authors: Taras Kucherenko, Derek Peristy, Judith B\"utepage
Categories: cs.CV cs.HC cs.LG
Comments: Accepted at the ACM International Conference on Multimedia 2025 (ACM
  MM'25)
\\ ( https://arxiv.org/abs/2410.14334 ,  2402kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20158
replaced with revised version Thu, 11 Sep 2025 23:09:05 GMT   (3076kb)

Title: Your Image is Secretly the Last Frame of a Pseudo Video
Authors: Wenlong Chen, Wenlin Chen, Lapo Rastrelli, Yingzhen Li
Categories: cs.CV cs.LG
Comments: Presented at the ICLR 2025 Workshop on Deep Generative Model in
  Machine Learning: Theory, Principle and Efficacy (DeLTa). 1-frame results for
  CIFAR10 in Table 2 corrected. Code released
\\ ( https://arxiv.org/abs/2410.20158 ,  3076kb)
------------------------------------------------------------------------------
\\
arXiv:2410.21471
replaced with revised version Thu, 11 Sep 2025 18:29:35 GMT   (1075kb)

Title: AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models
Authors: Yaopei Zeng, Yuanpu Cao, Bochuan Cao, Yurui Chang, Jinghui Chen, Lu
  Lin
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2410.21471 ,  1075kb)
------------------------------------------------------------------------------
\\
arXiv:2412.05074
replaced with revised version Fri, 12 Sep 2025 06:42:21 GMT   (5308kb)

Title: LoFi: Vision-Aided Label Generator for Wi-Fi Localization and Tracking
Authors: Zijian Zhao, Tingwei Chen, Fanyi Meng, Zhijie Cai, Hang Li, Xiaoyang
  Li, Guangxu Zhu
Categories: cs.CV eess.SP
\\ ( https://arxiv.org/abs/2412.05074 ,  5308kb)
------------------------------------------------------------------------------
\\
arXiv:2412.19087
replaced with revised version Fri, 12 Sep 2025 05:49:30 GMT   (18094kb)

Title: MoPD: Mixture-of-Prompts Distillation for Vision-Language Models
Authors: Yang Chen, Shuai Fu, Yu Zhang
Categories: cs.CV cs.CL cs.LG
\\ ( https://arxiv.org/abs/2412.19087 ,  18094kb)
------------------------------------------------------------------------------
\\
arXiv:2502.13818
replaced with revised version Fri, 12 Sep 2025 12:15:34 GMT   (17793kb)

Title: Building Age Estimation: A New Multi-Modal Benchmark Dataset and
  Community Challenge
Authors: Nikolaos Dionelis, Alessandra Feliciotti, Mattia Marconcini, Devis
  Peressutti, Nika Oman Kadunc, JaeWan Park, Hagai Raja Sinulingga, Steve
  Andreas Immanuel, Ba Tran, Caroline Arnold, Nicolas Long\'ep\'e
Categories: cs.CV cs.LG
Comments: 16 pages, 20 figures, 1 table, Submitted
\\ ( https://arxiv.org/abs/2502.13818 ,  17793kb)
------------------------------------------------------------------------------
\\
arXiv:2503.03556
replaced with revised version Fri, 12 Sep 2025 10:34:34 GMT   (43944kb)

Title: Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented
  Manipulation
Authors: Xiaomeng Zhu, Yuyang Li, Leiyao Cui, Pengfei Li, Huan-ang Gao, Yixin
  Zhu, Hao Zhao
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2503.03556 ,  43944kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07890
replaced with revised version Fri, 12 Sep 2025 08:50:31 GMT   (5322kb)

Title: Can Generative Geospatial Diffusion Models Excel as Discriminative
  Geospatial Foundation Models?
Authors: Yuru Jia, Valerio Marsocci, Ziyang Gong, Xue Yang, Maarten Vergauwen,
  Andrea Nascetti
Categories: cs.CV
Comments: ICCV 2025, camera ready
\\ ( https://arxiv.org/abs/2503.07890 ,  5322kb)
------------------------------------------------------------------------------
\\
arXiv:2503.08336
replaced with revised version Fri, 12 Sep 2025 15:05:09 GMT   (5463kb)

Title: Talk2PC: Enhancing 3D Visual Grounding through LiDAR and Radar Point
  Clouds Fusion for Autonomous Driving
Authors: Runwei Guan, Jianan Liu, Ningwei Ouyang, Shaofeng Liang, Daizong Liu,
  Xiaolou Sun, Lianqing Zheng, Ming Xu, Yutao Yue, Guoqiang Mao, Hui Xiong
Categories: cs.CV
Comments: 13 pages, 12 figures
\\ ( https://arxiv.org/abs/2503.08336 ,  5463kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16365
replaced with revised version Fri, 12 Sep 2025 17:56:19 GMT   (4894kb)

Title: JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play
  Visual Games with Keyboards and Mouse
Authors: Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang
Categories: cs.CV cs.AI
Comments: Accepted by ACL 2025
\\ ( https://arxiv.org/abs/2503.16365 ,  4894kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20724
replaced with revised version Fri, 12 Sep 2025 13:44:47 GMT   (27355kb)

Title: Dynamic Motion Blending for Versatile Motion Editing
Authors: Nan Jiang, Hongjie Li, Ziye Yuan, Zimo He, Yixin Chen, Tengyu Liu,
  Yixin Zhu, Siyuan Huang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.20724 ,  27355kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04191
replaced with revised version Fri, 12 Sep 2025 09:55:20 GMT   (21466kb)

Title: GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill
Authors: Jieming Cui, Tengyu Liu, Ziyu Meng, Jiale Yu, Ran Song, Wei Zhang,
  Yixin Zhu, Siyuan Huang
Categories: cs.CV cs.RO
\\ ( https://arxiv.org/abs/2504.04191 ,  21466kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04323
replaced with revised version Fri, 12 Sep 2025 09:13:18 GMT   (363kb)

Title: MedM-VL: What Makes a Good Medical LVLM?
Authors: Yiming Shi, Shaoshuai Yang, Xun Zhu, Haoyu Wang, Xiangling Fu, Miao
  Li, Ji Wu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.04323 ,  363kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11705
replaced with revised version Thu, 11 Sep 2025 21:18:08 GMT   (13408kb)

Title: Just Say the Word: Annotation-Free Fine-Grained Object Counting
Authors: Adriano D'Alessandro, Ali Mahdavi-Amiri and Ghassan Hamarneh
Categories: cs.CV
Comments: data - https://dalessandro.dev/datasets/lookalikes/
\\ ( https://arxiv.org/abs/2504.11705 ,  13408kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16763
replaced with revised version Fri, 12 Sep 2025 05:22:32 GMT   (6663kb)

Title: Self-Rewarding Large Vision-Language Models for Optimizing Prompts in
  Text-to-Image Generation
Authors: Hongji Yang, Yucheng Zhou, Wencheng Han and Jianbing Shen
Categories: cs.CV
Comments: Accepted by ACL2025 Findings
\\ ( https://arxiv.org/abs/2505.16763 ,  6663kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04996
replaced with revised version Fri, 12 Sep 2025 09:36:22 GMT   (174kb)

Title: PATS: Proficiency-Aware Temporal Sampling for Multi-View Sports Skill
  Assessment
Authors: Edoardo Bianchi, Antonio Liotta
Categories: cs.CV
Comments: Accepted at the 2025 4th IEEE International Workshop on Sport
  Technology and Research
\\ ( https://arxiv.org/abs/2506.04996 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14765
replaced with revised version Fri, 12 Sep 2025 12:41:40 GMT   (6000kb)

Title: Earth Observation Foundation Model PhilEO: Pretraining on the MajorTOM
  and FastTOM Datasets
Authors: Nikolaos Dionelis, Jente Bosmans, Riccardo Musto, Giancarlo Paoletti,
  Simone Sarti, Giacomo Cascarano, Casper Fibaek, Luke Camilleri, Bertrand Le
  Saux, Nicolas Long\'ep\'e
Categories: cs.CV
Comments: 15 pages, 22 figures, 2 tables, 64 references
\\ ( https://arxiv.org/abs/2506.14765 ,  6000kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21152
replaced with revised version Fri, 12 Sep 2025 11:26:35 GMT   (3206kb)

Title: Geometry and Perception Guided Gaussians for Multiview-consistent 3D
  Generation from a Single Image
Authors: Pufan Li, Bi'an Du and Wei Hu
Categories: cs.CV
Comments: 10 pages, 5 figures
MSC-class: 68
ACM-class: I.4.0
\\ ( https://arxiv.org/abs/2506.21152 ,  3206kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01607
replaced with revised version Fri, 12 Sep 2025 11:19:56 GMT   (2894kb)

Title: Survivability of Backdoor Attacks on Unconstrained Face Recognition
  Systems
Authors: Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi,
  Eric Bourbao
Categories: cs.CV cs.AI cs.CR cs.LG
\\ ( https://arxiv.org/abs/2507.01607 ,  2894kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05084
replaced with revised version Fri, 12 Sep 2025 15:09:41 GMT   (8605kb)

Title: AdaFusion: Prompt-Guided Inference with Adaptive Fusion of Pathology
  Foundation Models
Authors: Yuxiang Xiao, Yang Hu, Bin Li, Tianyang Zhang, Zexi Li, Huazhu Fu,
  Jens Rittscher, Kaixiang Yang
Categories: cs.CV
Comments: 6 Tables, 11 Figures
\\ ( https://arxiv.org/abs/2508.05084 ,  8605kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08765
replaced with revised version Fri, 12 Sep 2025 17:29:48 GMT   (3431kb)

Title: Bridging the Gap: A Framework for Real-World Video Deepfake Detection
  via Social Network Compression Emulation
Authors: Andrea Montibeller, Dasara Shullani, Daniele Baracchi, Alessandro
  Piva, and Giulia Boato
Categories: cs.CV cs.AI
DOI: 10.1145/3746265.3759670
\\ ( https://arxiv.org/abs/2508.08765 ,  3431kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16016
replaced with revised version Fri, 12 Sep 2025 09:50:49 GMT   (7530kb)

Title: DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance
  Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue
  Missions
Authors: Aykut Sirma, Angelos Plastropoulos, Gilbert Tang and Argyrios Zolotas
Categories: cs.CV
Comments: Technical Paper of Scientific data paper: UAV imagery dataset from
  2023 Turkiye earthquakes, annotated for instance segmentation to support SAR
  robotics. Initial version of the Dataset is released:
  https://figshare.com/s/66d3116a0de5b7d827fb and
  https://universe.roboflow.com/cranfield-university-dwusz/phd-project-instance-segmentation
\\ ( https://arxiv.org/abs/2508.16016 ,  7530kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21135
replaced with revised version Fri, 12 Sep 2025 02:23:49 GMT   (7396kb)

Title: HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object
  Detection
Authors: Harris Song, Tuan-Anh Vu, Sanjith Menon, Sriram Narasimhan, M. Khalid
  Jawed
Categories: cs.CV cs.AI
Comments: fix typos
\\ ( https://arxiv.org/abs/2508.21135 ,  7396kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03108
replaced with revised version Fri, 12 Sep 2025 10:53:43 GMT   (10511kb)

Title: Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods
Authors: Shota Iwamatsu, Koichi Ito, Takafumi Aoki
Categories: cs.CV
Comments: 2025 Asia Pacific Signal and Information Processing Association
  Annual Summit and Conference (APSIPA ASC)
\\ ( https://arxiv.org/abs/2509.03108 ,  10511kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03498
replaced with revised version Fri, 12 Sep 2025 07:12:41 GMT   (28178kb)

Title: OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and
  Generation
Authors: Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang
  Weng, Jingang Wang, Xunliang Cai, Wenrui Dai, Hongkai Xiong
Categories: cs.CV
Comments: technical report, project url:https://onecat-ai.github.io/
\\ ( https://arxiv.org/abs/2509.03498 ,  28178kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03897
replaced with revised version Fri, 12 Sep 2025 05:44:35 GMT   (397kb)

Title: SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation
Authors: Xiaofu Chen, Israfel Salazar, Yova Kementchedjhieva
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2509.03897 ,  397kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03951
replaced with revised version Thu, 11 Sep 2025 19:44:24 GMT   (1448kb)

Title: ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD
  Detection
Authors: Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.03951 ,  1448kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06591
replaced with revised version Fri, 12 Sep 2025 13:48:25 GMT   (4855kb)

Title: Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT
  Denoising
Authors: Yichao Liu, Hengzhi Xue, YueYang Teng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.06591 ,  4855kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08926
replaced with revised version Fri, 12 Sep 2025 10:57:10 GMT   (1172kb)

Title: Similarity-based Outlier Detection for Noisy Object Re-Identification
  Using Beta Mixtures
Authors: Waqar Ahmad, Evan Murphy, Vladimir A. Krylov
Categories: cs.CV cs.AI cs.LG math.ST stat.ML stat.TH
\\ ( https://arxiv.org/abs/2509.08926 ,  1172kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08934
replaced with revised version Fri, 12 Sep 2025 02:17:13 GMT   (2001kb)

Title: SFD-Mamba2Net: Structure-Guided Frequency-Enhanced Dual-Stream Mamba2
  Network for Coronary Artery Segmentation
Authors: Nan Mu, Ruiqi Song, Zhihui Xu, Jingfeng Jiang, Chen Zhao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.08934 ,  2001kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09501
replaced with revised version Fri, 12 Sep 2025 05:32:10 GMT   (5491kb)

Title: Region-Wise Correspondence Prediction between Manga Line Art Images
Authors: Yingxuan Li, Jiafeng Mao, Qianru Qiu, Yusuke Matsui
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.09501 ,  5491kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05591
replaced with revised version Fri, 12 Sep 2025 16:07:51 GMT   (470kb)

Title: Round-Optimal Approximate Agreement on Trees
Authors: Marc Fuchs, Diana Ghinea, Zahra Parsaeian
Categories: cs.DC
\\ ( https://arxiv.org/abs/2502.05591 ,  470kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19216
replaced with revised version Fri, 12 Sep 2025 10:14:23 GMT   (824kb)

Title: Constitutional Consensus
Authors: Idit Keidar, Andrew Lewis-Pye, and Ehud Shapiro
Categories: cs.DC cs.CR cs.DS cs.NI
\\ ( https://arxiv.org/abs/2505.19216 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21727
replaced with revised version Fri, 12 Sep 2025 16:51:00 GMT   (681kb)

Title: FedCostAware: Enabling Cost-Aware Federated Learning on the Cloud
Authors: Aditya Sinha, Zilinghan Li, Tingkai Liu, Volodymyr Kindratenko, Kibaek
  Kim, Ravi Madduri
Categories: cs.DC
\\ ( https://arxiv.org/abs/2505.21727 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2210.13533
replaced with revised version Fri, 12 Sep 2025 04:46:47 GMT   (8960kb)

Title: Sufficient Invariant Learning for Distribution Shift
Authors: Taero Kim, Subeen Park, Sungjun Lim, Yonghan Jung, Krikamol Muandet,
  Kyungwoo Song
Categories: cs.LG cs.AI stat.ML
Comments: Accepted by CVPR 2025. Corresponding author: Kyungwoo Song
\\ ( https://arxiv.org/abs/2210.13533 ,  8960kb)
------------------------------------------------------------------------------
\\
arXiv:2307.08327
replaced with revised version Fri, 12 Sep 2025 07:14:11 GMT   (335kb)

Title: Analyzing the Impact of Adversarial Examples on Explainable Machine
  Learning
Authors: Prathyusha Devabhakthini, Sasmita Parida, Raj Mani Shukla, Suvendu
  Chandan Nayak, Tapadhir Das
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2307.08327 ,  335kb)
------------------------------------------------------------------------------
\\
arXiv:2405.01158
replaced with revised version Fri, 12 Sep 2025 05:14:00 GMT   (3455kb)

Title: Interpretable Data-driven Anomaly Detection in Industrial Processes with
  ExIFFI
Authors: Davide Frizzo, Francesco Borsatti, Alessio Arcudi, Antonio De Moliner,
  Roberto Oboe, Gian Antonio Susto
Categories: cs.LG cs.AI
Comments: This is an extension of the previous version of the paper, submitted
  to IEEE Transaction for Industry Application. The extension consists in:
  improved text, new citations, new benchmark dataset `CoffeeData` and new
  figures
\\ ( https://arxiv.org/abs/2405.01158 ,  3455kb)
------------------------------------------------------------------------------
\\
arXiv:2406.16929 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 07:09:41 GMT   (948kb)

Title: Modelling the 5G Energy Consumption using Real-world Data: Energy
  Fingerprint is All You Need
Authors: Tingwei Chen, Yantao Wang, Hanzhi Chen, Zijian Zhao, Xinhao Li, Nicola
  Piovesan, Guangxu Zhu, Qingjiang Shi
Categories: eess.SP cs.AI
\\ ( https://arxiv.org/abs/2406.16929 ,  948kb)
------------------------------------------------------------------------------
\\
arXiv:2406.17949
replaced with revised version Fri, 12 Sep 2025 08:22:27 GMT   (921kb)

Title: The Overcooked Generalisation Challenge: Evaluating Cooperation with
  Novel Partners in Unknown Environments Using Unsupervised Environment Design
Authors: Constantin Ruhdorfer and Matteo Bortoletto and Anna Penzkofer and
  Andreas Bulling
Categories: cs.LG cs.AI cs.MA
Comments: TMLR, 31 pages
\\ ( https://arxiv.org/abs/2406.17949 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2408.08242
replaced with revised version Fri, 12 Sep 2025 16:03:33 GMT   (19001kb)

Title: A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning
  Decision System for Interactive Driving in Roundabouts
Authors: Zhihao Lin, Zhen Tian, Jianglin Lan, Qi Zhang, Ziyang Ye, Hanyang
  Zhuang, and Xianxian Zhao
Categories: cs.RO cs.AI cs.LG cs.SY eess.SY
Comments: 14 pages, 11 figures, published in IEEE Transactions on Intelligent
  Transportation Systems
DOI: 10.1109/TITS.2025.3578279
\\ ( https://arxiv.org/abs/2408.08242 ,  19001kb)
------------------------------------------------------------------------------
\\
arXiv:2410.03855
replaced with revised version Fri, 12 Sep 2025 15:31:36 GMT   (8302kb)

Title: A Survey on Group Fairness in Federated Learning: Challenges, Taxonomy
  of Solutions and Directions for Future Research
Authors: Teresa Salazar, Helder Ara\'ujo, Alberto Cano, Pedro Henriques Abreu
Categories: cs.LG cs.AI cs.CY
MSC-class: 68T01
ACM-class: I.2.6; I.5.1; K.4.1
\\ ( https://arxiv.org/abs/2410.03855 ,  8302kb)
------------------------------------------------------------------------------
\\
arXiv:2411.09852
replaced with revised version Thu, 11 Sep 2025 18:51:53 GMT   (1084kb)

Title: InterFormer: Effective Heterogeneous Interaction Learning for
  Click-Through Rate Prediction
Authors: Zhichen Zeng, Xiaolong Liu, Mengyue Hang, Xiaoyi Liu, Qinghai Zhou,
  Chaofei Yang, Yiqun Liu, Yichen Ruan, Laming Chen, Yuxin Chen, Yujia Hao,
  Jiaqi Xu, Jade Nie, Xi Liu, Buyun Zhang, Wei Wen, Siyang Yuan, Hang Yin, Xin
  Zhang, Kai Wang, Wen-Yen Chen, Yiping Han, Huayu Li, Chunzhi Yang, Bo Long,
  Philip S. Yu, Hanghang Tong, Jiyan Yang
Categories: cs.IR cs.AI cs.LG
Comments: 11 pages, 6 figures
\\ ( https://arxiv.org/abs/2411.09852 ,  1084kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12039
replaced with revised version Thu, 11 Sep 2025 18:10:07 GMT   (3204kb)

Title: Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability
  Detection
Authors: Ira Ceka, Feitong Qiao, Anik Dey, Aastha Valecha, Gail Kaiser,
  Baishakhi Ray
Categories: cs.CR cs.AI cs.CL cs.SE
\\ ( https://arxiv.org/abs/2412.12039 ,  3204kb)
------------------------------------------------------------------------------
\\
arXiv:2412.17910
replaced with revised version Fri, 12 Sep 2025 03:23:17 GMT   (3564kb)

Title: A Novel Approach to Balance Convenience and Nutrition in Meals With
  Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its
  Implementation in BEACON
Authors: Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Nitin Gupta,
  Zach Abdulrahman, Andrew Davison, Biplav Srivastava
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2412.17910 ,  3564kb)
------------------------------------------------------------------------------
\\
arXiv:2501.06089
replaced with revised version Fri, 12 Sep 2025 03:22:52 GMT   (14303kb)

Title: Towards Developing Socially Compliant Automated Vehicles: Advances,
  Expert Insights, and A Conceptual Framework
Authors: Yongqi Dong, Bart van Arem, and Haneen Farah
Categories: cs.RO cs.AI cs.LG cs.MA cs.SY eess.SY
Comments: 23 pages, 13 figures, accepted by the Journal of Communications in
  Transportation Research
Journal-ref: Communications in Transportation Research 2025
DOI: 10.1016/j.commtr.2025.100207
\\ ( https://arxiv.org/abs/2501.06089 ,  14303kb)
------------------------------------------------------------------------------
\\
arXiv:2502.08987
replaced with revised version Fri, 12 Sep 2025 13:15:39 GMT   (39822kb)

Title: Neural Force Field: Few-shot Learning of Generalized Physical Reasoning
Authors: Shiqian Li, Ruihong Shen, Yaoyu Tao, Chi Zhang, Yixin Zhu
Categories: cs.LG cs.AI
Comments: 31 pages
\\ ( https://arxiv.org/abs/2502.08987 ,  39822kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16446
replaced with revised version Thu, 11 Sep 2025 19:05:03 GMT   (3643kb)

Title: Auxiliary Discrminator Sequence Generative Adversarial Networks
  (ADSeqGAN) for Few Sample Molecule Generation
Authors: Haocheng Tang, Jing Long, Beihong Ji and Junmei Wang
Categories: cs.LG cs.AI q-bio.BM
Comments: Accepted by Journal of Chemical Information and Modeling, ASAP
\\ ( https://arxiv.org/abs/2502.16446 ,  3643kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04267
replaced with revised version Fri, 12 Sep 2025 14:57:13 GMT   (825kb)

Title: Prompt Programming: A Platform for Dialogue-based Computational Problem
  Solving with Generative AI Models
Authors: Victor-Alexandru P\u{a}durean, Paul Denny, Alkis Gotovos, Adish Singla
Categories: cs.CY cs.AI
Comments: ITiCSE'25 paper
\\ ( https://arxiv.org/abs/2503.04267 ,  825kb)
------------------------------------------------------------------------------
\\
arXiv:2504.15546
replaced with revised version Fri, 12 Sep 2025 11:24:08 GMT   (2921kb)

Title: A Framework for Testing and Adapting REST APIs as LLM Tools
Authors: Jayachandu Bandlamudi, Ritwik Chaudhuri, Neelamadhav Gantayat, Sambit
  Ghosh, Kushal Mukherjee, Prerna Agarwal, Renuka Sindhgatta, Sameep Mehta
Categories: cs.SE cs.AI
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2504.15546 ,  2921kb)
------------------------------------------------------------------------------
\\
arXiv:2505.02846
replaced with revised version Fri, 12 Sep 2025 16:39:39 GMT   (82kb)

Title: The Precautionary Principle and the Innovation Principle: Incompatible
  Guides for AI Innovation Governance?
Authors: Kim Kaivanto
Categories: cs.CY cs.AI econ.GN q-fin.EC
Comments: 47 pages
\\ ( https://arxiv.org/abs/2505.02846 ,  82kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07879
replaced with revised version Fri, 12 Sep 2025 11:47:31 GMT   (9994kb)

Title: OMGM: Orchestrate Multiple Granularities and Modalities for Efficient
  Multimodal Retrieval
Authors: Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian
Categories: cs.IR cs.AI cs.CV
Comments: Accepted to ACL 2025 Main Conference
\\ ( https://arxiv.org/abs/2505.07879 ,  9994kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24298
replaced with revised version Fri, 12 Sep 2025 07:59:18 GMT   (370kb)

Title: AReaL: A Large-Scale Asynchronous Reinforcement Learning System for
  Language Reasoning
Authors: Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He,
  Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.24298 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14391
replaced with revised version Thu, 11 Sep 2025 21:09:24 GMT   (84kb)

Title: HiLight: A Hierarchical Reinforcement Learning Framework with Global
  Adversarial Guidance for Large-Scale Traffic Signal Control
Authors: Yaqiao Zhu, Hongkai Wen, Geyong Min, Man Luo
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.14391 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2507.00419 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 05:54:23 GMT   (24962kb)

Title: Geological Everything Model 3D: A Promptable Foundation Model for
  Unified and Zero-Shot Subsurface Understanding
Authors: Yimin Dou, Xinming Wu, Nathan L Bangs, Harpreet Singh Sethi, Jintao
  Li, Hang Gao, Zhixiang Guo
Categories: physics.geo-ph cs.AI
\\ ( https://arxiv.org/abs/2507.00419 ,  24962kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07373
replaced with revised version Fri, 12 Sep 2025 01:02:28 GMT   (1732kb)

Title: Atherosclerosis through Hierarchical Explainable Neural Network Analysis
Authors: Irsyad Adam, Steven Swee, Erika Yilin, Ethan Ji, William Speier, Dean
  Wang, Alex Bui, Wei Wang, Karol Watson, Peipei Ping
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2507.07373 ,  1732kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02773
replaced with revised version Fri, 12 Sep 2025 15:26:02 GMT   (1312kb)

Title: Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges
Authors: Yiming Shen, Jiashuo Zhang, Zhenzhe Shao, Wenxuan Luo, Yanlin Wang,
  Ting Chen, Zibin Zheng and Jiachi Chen
Categories: cs.CY cs.AI econ.GN q-fin.EC
\\ ( https://arxiv.org/abs/2508.02773 ,  1312kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03703
replaced with revised version Fri, 12 Sep 2025 02:59:56 GMT   (1673kb)

Title: Privacy Risks of LLM-Empowered Recommender Systems: An Inversion Attack
  Perspective
Authors: Yubo Wang and Min Tang and Nuo Shen and Shujie Cui and Weiqing Wang
Categories: cs.IR cs.AI
Comments: Accepted at ACM RecSys 2025 (10 pages, 4 figures)
\\ ( https://arxiv.org/abs/2508.03703 ,  1673kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03747
replaced with revised version Fri, 12 Sep 2025 14:48:48 GMT   (2724kb)

Title: Data-Driven Discovery of Mobility Periodicity for Understanding Urban
  Systems
Authors: Xinyu Chen, Qi Wang, Yunhan Zheng, Nina Cao, HanQin Cai, Jinhua Zhao
Categories: cs.SI cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.03747 ,  2724kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05672
replaced with revised version Fri, 12 Sep 2025 17:32:41 GMT   (136kb)

Title: LMAR: Language Model Augmented Retriever for Domain-specific Knowledge
  Indexing
Authors: Yao Zhao, Yantian Ding, Zhiyue Zhang, Dapeng Yao, and Yanxun Xu
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2508.05672 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08672
replaced with revised version Fri, 12 Sep 2025 13:49:51 GMT   (3168kb)

Title: Imposing AI: Deceptive design patterns against sustainability
Authors: Ana\"elle Beignon, Thomas Thibault, Nolwenn Maudet
Categories: cs.HC cs.AI
Journal-ref: Proceedings of 11th Workshop on Computing Within Limits, June
  26-27, 2025, Online
DOI: 10.48550/arXiv.2508.08672
\\ ( https://arxiv.org/abs/2508.08672 ,  3168kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13355
replaced with revised version Thu, 11 Sep 2025 20:38:41 GMT   (2569kb)

Title: Counterfactual Probabilistic Diffusion with Expert Models
Authors: Wenhao Mu, Zhi Cao, Mehmed Uludag, Alexander Rodr\'iguez
Categories: cs.LG cs.AI stat.ME
\\ ( https://arxiv.org/abs/2508.13355 ,  2569kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13654
replaced with revised version Fri, 12 Sep 2025 07:04:59 GMT   (56kb)

Title: Input-Time Scaling
Authors: Rapheal Huang (Yuming), Weilong Guo
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2508.13654 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02196 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 17:15:04 GMT   (23793kb)

Title: Beyond Ensembles: Simulating All-Atom Protein Dynamics in a Learned
  Latent Space
Authors: Aditya Sengar, Ali Hariri, Pierre Vandergheynst, Patrick Barth
Categories: q-bio.BM cs.AI
\\ ( https://arxiv.org/abs/2509.02196 ,  23793kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02622 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 09:26:25 GMT   (815kb,D)

Title: IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic
  Scenes using Deep Filtering
Authors: Cl\'ementine Berger (S2A, IDS), Paraskevas Stamatiadis (S2A, IDS),
  Roland Badeau (S2A, IDS), Slim Essid (S2A, IDS)
Categories: eess.AS cs.AI cs.SD eess.SP
Journal-ref: IEEE Workshop on Applications of Signal Processing to Audio and
  Acoustics (WASPAA 2025), IEEE, Oct 2025, Tahoe City, CA, United States
\\ ( https://arxiv.org/abs/2509.02622 ,  815kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02853
replaced with revised version Fri, 12 Sep 2025 02:23:53 GMT   (676kb)

Title: The Architecture of AI Transformation: Four Strategic Patterns and an
  Emerging Frontier
Authors: Diana A. Wolfe, Alice Choe, Fergus Kidd
Categories: cs.CY cs.AI
Comments: 59 pages, 2 tables, 4 figures
\\ ( https://arxiv.org/abs/2509.02853 ,  676kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02896
replaced with revised version Fri, 12 Sep 2025 16:30:38 GMT   (2661kb)

Title: Cut Costs, Not Accuracy: LLM-Powered Data Processing with Guarantees
Authors: Sepanta Zeighami, Shreya Shankar, Aditya Parameswaran
Categories: cs.DB cs.AI
Comments: To appear in SIGMOD'26
\\ ( https://arxiv.org/abs/2509.02896 ,  2661kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05367
replaced with revised version Fri, 12 Sep 2025 11:05:08 GMT   (2206kb)

Title: Between a Rock and a Hard Place: Exploiting Ethical Reasoning to
  Jailbreak LLMs
Authors: Shei Pern Chua, Zhen Leng Thai, Teh Kai Jun, Xiao Li, Xiaolin Hu
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2509.05367 ,  2206kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06426 (*cross-listing*)
replaced with revised version Thu, 11 Sep 2025 21:45:17 GMT   (11199kb)

Title: Musculoskeletal simulation of limb movement biomechanics in Drosophila
  melanogaster
Authors: Pembe Gizem \"Ozdil, Chuanfang Ning, Jasper S. Phelps, Sibo Wang-Chen,
  Guy Elisha, Alexander Blanke, Auke Ijspeert, Pavan Ramdya
Categories: q-bio.NC cs.AI cs.LG cs.RO
Comments: 23 pages, 11 figures
\\ ( https://arxiv.org/abs/2509.06426 ,  11199kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09009
replaced with revised version Fri, 12 Sep 2025 05:22:38 GMT   (6276kb)

Title: Open-sci-ref-0.01: open and reproducible reference baselines for
  language model and dataset comparison
Authors: Marianna Nezhurina and J\"org Franke and Taishi Nakamura and Timur
  Carstensen and Niccol\`o Ajroldi and Ville Komulainen and David Salinas and
  Jenia Jitsev
Categories: cs.LG cs.AI cs.CL
Comments: Model weights and intermediate checkpoints are available at
  https://huggingface.co/collections/open-sci/open-sci-ref-001-685905e598be658fbcebff4f;
  code for reproducing training, evaluation and raw experiments data at
  https://github.com/LAION-AI/open-sci-ref-0.01
\\ ( https://arxiv.org/abs/2509.09009 ,  6276kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09332
replaced with revised version Fri, 12 Sep 2025 08:01:55 GMT   (20797kb)

Title: OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and
  Embodiment-aware Reasoning
Authors: Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yuzheng
  Zhuang, Bowen Yang, He Zhu, Lingfeng Zhang, Pengwei Xie, David Gamaliel Arcos
  Bravo, Yingxue Zhang, Jianye Hao, Xingyue Quan
Categories: cs.RO cs.AI cs.CL cs.CV
\\ ( https://arxiv.org/abs/2509.09332 ,  20797kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04996
replaced with revised version Fri, 12 Sep 2025 03:15:11 GMT   (622kb)

Title: Agentic Vehicles for Human-Centered Mobility Systems
Authors: Jiangbo Yu
Categories: cs.CY cs.CE cs.CL cs.HC cs.RO
\\ ( https://arxiv.org/abs/2507.04996 ,  622kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09631
replaced with revised version Fri, 12 Sep 2025 01:59:18 GMT   (780kb)

Title: DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for
  Low-Latency Zero-Shot Text-To-Speech
Authors: Ngoc-Son Nguyen, Hieu-Nghia Huynh-Nguyen, Thanh V. T. Tran, Truong-Son
  Hy, Van Nguyen
Categories: cs.SD cs.CL cs.CV
\\ ( https://arxiv.org/abs/2509.09631 ,  780kb)
------------------------------------------------------------------------------
\\
arXiv:2110.14484 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 06:17:06 GMT   (6060kb)

Title: PL-Net: Progressive Learning Network for Medical Image Segmentation
Authors: Kunpeng Mao, Ruoyu Li, Junlong Cheng, Danmei Huang, Zhiping Song, and
  ZeKui Liu
Categories: eess.IV cs.CV cs.LG
\\ ( https://arxiv.org/abs/2110.14484 ,  6060kb)
------------------------------------------------------------------------------
\\
arXiv:2402.02734 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 05:11:48 GMT   (923kb)

Title: Integrative Variational Autoencoders for Generative Modeling of an Image
  Outcome with Multiple Input Images
Authors: Bowen Lei, Yeseul Jeon, Rajarshi Guhaniyogi, Aaron Scheffler, Bani
  Mallick, Alzheimer's Disease Neuroimaging Initiatives
Categories: eess.IV cs.CV cs.NE stat.AP stat.ML
\\ ( https://arxiv.org/abs/2402.02734 ,  923kb)
------------------------------------------------------------------------------
\\
arXiv:2408.01284
replaced with revised version Fri, 12 Sep 2025 02:08:16 GMT   (1447kb)

Title: Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot
  Learning: A General Framework
Authors: Liuyuan Wen
Categories: cs.MM cs.CV cs.SD eess.AS eess.IV
Comments: Accepted to BMVC 2024
\\ ( https://arxiv.org/abs/2408.01284 ,  1447kb)
------------------------------------------------------------------------------
\\
arXiv:2411.02992
replaced with revised version Fri, 12 Sep 2025 10:13:54 GMT   (3714kb)

Title: Efficient and Effective Adaptation of Multimodal Foundation Models in
  Sequential Recommendation
Authors: Junchen Fu, Xuri Ge, Xin Xin, Alexandros Karatzoglou, Ioannis
  Arapakis, Kaiwen Zheng, Yongxin Ni, Joemon M. Jose
Categories: cs.IR cs.CV
Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering
  (TKDE)
DOI: 10.1109/TKDE.2025.3608071
\\ ( https://arxiv.org/abs/2411.02992 ,  3714kb)
------------------------------------------------------------------------------
\\
arXiv:2502.09507
replaced with revised version Fri, 12 Sep 2025 08:50:44 GMT   (10358kb)

Title: When and How Does CLIP Enable Domain and Compositional Generalization?
Authors: Elias Kempf, Simon Schrodi, Max Argus, Thomas Brox
Categories: cs.LG cs.CV
Comments: ICML 2025 (Spotlight)
\\ ( https://arxiv.org/abs/2502.09507 ,  10358kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00702 (*cross-listing*)
replaced with revised version Fri, 12 Sep 2025 13:15:43 GMT   (6095kb)

Title: Orientation Scores should be a Piece of Cake
Authors: Finn M. Sherry and Chase van de Geijn and Erik J. Bekkers and Remco
  Duits
Categories: math.DG cs.CV
Comments: Accepted in the 7th International Conference on Geometric Science of
  Information
\\ ( https://arxiv.org/abs/2504.00702 ,  6095kb)
------------------------------------------------------------------------------
\\
arXiv:2504.12908
replaced with revised version Fri, 12 Sep 2025 09:53:33 GMT   (4111kb)

Title: Taccel: Scaling Up Vision-based Tactile Robotics via High-performance
  GPU Simulation
Authors: Yuyang Li, Wenxin Du, Chang Yu, Puhao Li, Zihang Zhao, Tengyu Liu,
  Chenfanfu Jiang, Yixin Zhu, Siyuan Huang
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/2504.12908 ,  4111kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04881 (*cross-listing*)
replaced with revised version Thu, 11 Sep 2025 18:02:31 GMT   (6331kb)

Title: Uncovering Neuroimaging Biomarkers of Brain Tumor Surgery with AI-Driven
  Methods
Authors: Carmen Jimenez-Mesa, Yizhou Wan, Guilio Sansone, Francisco J.
  Martinez-Murcia, Javier Ramirez, Pietro Lio, Juan M. Gorriz, Stephen J.
  Price, John Suckling, Michail Mamalakis
Categories: eess.IV cs.CV
Comments: 18 pages, 6 figures
\\ ( https://arxiv.org/abs/2507.04881 ,  6331kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02521
replaced with revised version Thu, 11 Sep 2025 23:41:01 GMT   (274kb)

Title: Towards Reliable Audio Deepfake Attribution and Model Recognition: A
  Multi-Level Autoencoder-Based Framework
Authors: Andrea Di Pierno (1), Luca Guarnera (2), Dario Allegra (2), Sebastiano
  Battiato (2) ((1) IMT School of Advanced Studies, (2) University of Catania)
Categories: cs.SD cs.CV eess.AS
\\ ( https://arxiv.org/abs/2508.02521 ,  274kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11007
replaced with revised version Fri, 12 Sep 2025 04:41:28 GMT   (3720kb)

Title: Local-Cloud Inference Offloading for LLMs in Multi-Modal, Multi-Task,
  Multi-Dialogue Settings
Authors: Liangqi Yuan and Dong-Jun Han and Shiqiang Wang and Christopher G.
  Brinton
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2502.11007 ,  3720kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09638
replaced with revised version Fri, 12 Sep 2025 11:07:04 GMT   (915kb)

Title: Distributed Rhombus Formation of Sliding Squares
Authors: Irina Kostitsyna, David Liedtke, Christian Scheideler
Categories: cs.CG cs.DC
ACM-class: F.2.2
\\ ( https://arxiv.org/abs/2508.09638 ,  915kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
