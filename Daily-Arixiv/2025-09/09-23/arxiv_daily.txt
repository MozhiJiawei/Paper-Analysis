Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 8004a1 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月25日 11:56
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Tue 23 Sep 25 18:00:00 GMT  to  Wed 24 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.19456
Date: Tue, 23 Sep 2025 18:12:45 GMT   (34kb)

Title: The Indispensable Role of User Simulation in the Pursuit of AGI
Authors: Krisztian Balog, ChengXiang Zhai
Categories: cs.AI
Comments: Accepted for publication in Communications of the ACM
DOI: 10.1145/3768170
\\
  Progress toward Artificial General Intelligence (AGI) faces significant
bottlenecks, particularly in rigorously evaluating complex interactive systems
and acquiring the vast interaction data needed for training adaptive agents.
This paper posits that user simulation -- creating computational agents that
mimic human interaction with AI systems -- is not merely a useful tool, but is
a critical catalyst required to overcome these bottlenecks and accelerate AGI
development. We argue that realistic simulators provide the necessary
environments for scalable evaluation, data generation for interactive learning,
and fostering the adaptive capabilities central to AGI. Therefore, research
into user simulation technology and intelligent task agents are deeply
synergistic and must advance hand-in-hand. This article elaborates on the
critical role of user simulation for AGI, explores the interdisciplinary nature
of building realistic simulators, identifies key challenges including those
posed by large language models, and proposes a future research agenda.
\\ ( https://arxiv.org/abs/2509.19456 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19464
Date: Tue, 23 Sep 2025 18:17:21 GMT   (1276kb)

Title: Evaluation-Aware Reinforcement Learning
Authors: Shripad Vilasrao Deshmukh, Will Schwarzer, Scott Niekum
Categories: cs.AI cs.LG
Comments: 9 pages, under submission
\\
  Policy evaluation is often a prerequisite for deploying safety- and
performance-critical systems. Existing evaluation approaches frequently suffer
from high variance due to limited data and long-horizon tasks, or high bias due
to unequal support or inaccurate environmental models. We posit that these
challenges arise, in part, from the standard reinforcement learning (RL)
paradigm of policy learning without explicit consideration of evaluation. As an
alternative, we propose evaluation-aware reinforcement learning (EvA-RL), in
which a policy is trained to maximize expected return while simultaneously
minimizing expected evaluation error under a given value prediction scheme --
in other words, being "easy" to evaluate. We formalize a framework for EvA-RL
and design an instantiation that enables accurate policy evaluation,
conditioned on a small number of rollouts in an assessment environment that can
be different than the deployment environment. However, our theoretical analysis
and empirical results show that there is often a tradeoff between evaluation
accuracy and policy performance when using a fixed value-prediction scheme
within EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an
assessment-conditioned state-value predictor alongside the policy. Empirical
results across diverse discrete and continuous action domains demonstrate that
EvA-RL can substantially reduce evaluation error while maintaining competitive
returns. This work lays the foundation for a broad new class of RL methods that
treat reliable evaluation as a first-class principle during training.
\\ ( https://arxiv.org/abs/2509.19464 ,  1276kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19489
Date: Tue, 23 Sep 2025 18:51:56 GMT   (4kb)

Title: Estimating the Self-Consistency of LLMs
Authors: Robert Nowak
Categories: cs.AI
Comments: 5 pages
\\
  Systems often repeat the same prompt to large language models (LLMs) and
aggregate responses to improve reliability. This short note analyzes an
estimator of the self-consistency of LLMs and the tradeoffs it induces under a
fixed compute budget $B=mn$, where $m$ is the number of prompts sampled from
the task distribution and $n$ is the number of repeated LLM calls per prompt;
the resulting analysis favors a rough split $m,n\propto\sqrt{B}$.
\\ ( https://arxiv.org/abs/2509.19489 ,  4kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19517
Date: Tue, 23 Sep 2025 19:36:56 GMT   (1190kb)

Title: Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop
  Reasoning
Authors: Sai Teja Reddy Adapala
Categories: cs.AI cs.CL cs.LG
ACM-class: I.2.7; I.2.6
\\
  The scaling of Large Language Models (LLMs) has exposed a critical gap
between their performance on static benchmarks and their fragility in dynamic,
information-rich environments. While models excel at isolated tasks, the
computational limits that govern their reasoning under cognitive load remain
poorly understood. In this work, we introduce a formal theory of computational
cognitive load, positing that extraneous, task-irrelevant information (Context
Saturation) and interference from task-switching (Attentional Residue) are key
mechanisms that degrade performance. We designed the Interleaved Cognitive
Evaluation (ICE), a deconfounded benchmark to systematically manipulate these
load factors on challenging multi-hop reasoning tasks. A comprehensive study (N
= 10 replications per item across 200 questions) revealed significant
performance variations across five instruction-tuned models. Smaller
open-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)
exhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all
conditions, including clean controls, on this high-intrinsic-load task. In
contrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%
accuracy in control conditions, with a statistically significant degradation
under context saturation ($\beta = -0.003$ per % load, $p < 0.001$). These
findings provide preliminary evidence that cognitive load is a key contributor
to reasoning failures, supporting theories of hallucination-as-guessing under
uncertainty. We conclude that dynamic, cognitive-aware stress testing, as
exemplified by the ICE benchmark, is essential for evaluating the true
resilience and safety of advanced AI systems.
\\ ( https://arxiv.org/abs/2509.19517 ,  1190kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19524
Date: Tue, 23 Sep 2025 19:42:14 GMT   (786kb)

Title: Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for
  Robotic Manipulation
Authors: Ramy ElMallah, Krish Chhajer, Chi-Guhn Lee
Categories: cs.AI cs.RO
Comments: Accepted to the CoRL 2025 Eval&Deploy Workshop
\\
  Robot learning papers typically report a single binary success rate (SR),
which obscures where a policy succeeds or fails along a multi-step manipulation
task. We argue that subgoal-level reporting should become routine: for each
trajectory, a vector of per-subgoal SRs that makes partial competence visible
(e.g., grasp vs. pour). We propose a blueprint for StepEval, a cost-aware
plug-in evaluation framework that utilizes vision-language models (VLMs) as
automated judges of subgoal outcomes from recorded images or videos. Rather
than proposing new benchmarks or APIs, our contribution is to outline design
principles for a scalable, community-driven open-source project. In StepEval,
the primary artifact for policy evaluation is the per-subgoal SR vector;
however, other quantities (e.g., latency or cost estimates) are also considered
for framework-optimization diagnostics to help the community tune evaluation
efficiency and accuracy when ground-truth subgoal success labels are available.
We discuss how such a framework can remain model-agnostic, support single- or
multi-view inputs, and be lightweight enough to adopt across labs. The intended
contribution is a shared direction: a minimal, extensible seed that invites
open-source contributions, so that scoring the steps, not just the final goal,
becomes a standard and reproducible practice.
\\ ( https://arxiv.org/abs/2509.19524 ,  786kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19566
Date: Tue, 23 Sep 2025 20:44:31 GMT   (3732kb)

Title: Nano Bio-Agents (NBA): Small Language Model Agents for Genomics
Authors: George Hong, Daniel Trejo Banos
Categories: cs.AI q-bio.GN
\\
  We investigate the application of Small Language Models (<10 billion
parameters) for genomics question answering via agentic framework to address
hallucination issues and computational cost challenges. The Nano Bio-Agent
(NBA) framework we implemented incorporates task decomposition, tool
orchestration, and API access into well-established systems such as NCBI and
AlphaGenome. Results show that SLMs combined with such agentic framework can
achieve comparable and in many cases superior performance versus existing
approaches utilising larger models, with our best model-agent combination
achieving 98% accuracy on the GeneTuring benchmark. Notably, small 3-10B
parameter models consistently achieve 85-97% accuracy while requiring much
lower computational resources than conventional approaches. This demonstrates
promising potential for efficiency gains, cost savings, and democratization of
ML-powered genomics tools while retaining highly robust and accurate
performance.
\\ ( https://arxiv.org/abs/2509.19566 ,  3732kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19590
Date: Tue, 23 Sep 2025 21:29:04 GMT   (678kb)

Title: What Does Your Benchmark Really Measure? A Framework for Robust
  Inference of AI Capabilities
Authors: Nathanael Jo, Ashia Wilson
Categories: cs.AI cs.CY cs.LG
\\
  Evaluations of generative models on benchmark data are now ubiquitous, and
their outcomes critically shape public and scientific expectations of AI's
capabilities. Yet growing skepticism surrounds their reliability. How can we
know that a reported accuracy genuinely reflects a model's true performance?
Evaluations are often presented as simple measurements, but in reality they are
inferences: to treat benchmark scores as evidence of capability is already to
assume a theory of what capability is and how it manifests in a test. We make
this step explicit by proposing a principled framework for evaluation as
inference: begin from a theory of capability, and then derive methods for
estimating it. This perspective, familiar in fields such as psychometrics, has
not yet become commonplace in AI evaluation. As a proof of concept, we address
a central challenge that undermines reliability: sensitivity to perturbations.
After formulating a model of ability, we introduce methods that infer ability
while accounting for uncertainty from sensitivity and finite samples, including
an adaptive algorithm that significantly reduces sample complexity. Together,
these contributions lay the groundwork for more reliable and trustworthy
estimates of AI capabilities as measured through benchmarks.
\\ ( https://arxiv.org/abs/2509.19590 ,  678kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19623
Date: Tue, 23 Sep 2025 22:30:52 GMT   (629kb)

Title: SteinerSQL: Graph-Guided Mathematical Reasoning for Text-to-SQL
  Generation
Authors: Xutao Mao and Tao Liu and Hongying Zan
Categories: cs.AI
Comments: Accept in Non-archival EMNLP 2025 MathNLP
\\
  Large Language Models (LLMs) struggle with complex Text-to-SQL queries that
demand both sophisticated mathematical reasoning and intricate schema
navigation. Existing methods often tackle these challenges in isolation,
creating a fractured reasoning process that compromises logical and structural
correctness. To resolve this, we introduce SteinerSQL, a framework that unifies
these dual challenges into a single, graph-centric optimization problem.
SteinerSQL operates in three stages: mathematical decomposition to identify
required tables (terminals), optimal reasoning scaffold construction via a
Steiner tree problem, and multi-level validation to ensure correctness. On the
challenging LogicCat and Spider2.0-Lite benchmarks, SteinerSQL establishes a
new state-of-the-art with 36.10% and 40.04% execution accuracy, respectively,
using Gemini-2.5-Pro. Beyond accuracy, SteinerSQL presents a new, unified
paradigm for Text-to-SQL, paving the way for more robust and principled
solutions to complex reasoning tasks.
\\ ( https://arxiv.org/abs/2509.19623 ,  629kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19681
Date: Wed, 24 Sep 2025 01:36:00 GMT   (581kb)

Title: Calibrated Reasoning: An Explanatory Verifier for Dynamic and Efficient
  Problem-Solving
Authors: Anisha Garg, Engin Tekin, Yash More, David Bick, Nishit Neema, Ganesh
  Venkatesh
Categories: cs.AI
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
  2025) Workshop: Efficient Reasoning
\\
  Advanced test-time computing strategies are essential for scaling reasoning
models, but their effectiveness is capped by the models' poor self-evaluation.
We propose a pairwise Explanatory Verifier, trained via reinforcement learning
(GRPO), that produces calibrated confidence scores and associated natural
language reasoning for generated solutions. Our verifier improves the accuracy
and efficiency of test-time strategies like best-of-n and self-reflection.
Crucially, it excels at identifying challenging failure modes, such as when
both candidate solutions are identically incorrect, succeeding where standard
methods like majority voting fail.
\\ ( https://arxiv.org/abs/2509.19681 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19736
Date: Wed, 24 Sep 2025 03:33:20 GMT   (3118kb)

Title: UserRL: Training Interactive User-Centric Agent via Reinforcement
  Learning
Authors: Cheng Qian, Zuxin Liu, Akshara Prabhakar, Jielin Qiu, Zhiwei Liu,
  Haolin Chen, Shirley Kokane, Heng Ji, Weiran Yao, Shelby Heinecke, Silvio
  Savarese, Caiming Xiong, Huan Wang
Categories: cs.AI cs.CL cs.LG
Comments: 28 Pages, 15 Figures, 6 Tables; Built upon latest UserBench release:
  arXiv:2507.22034
\\
  Reinforcement learning (RL) has shown promise in training agentic models that
move beyond static benchmarks to engage in dynamic, multi-turn interactions.
Yet, the ultimate value of such agents lies in their ability to assist users, a
setting where diversity and dynamics of user interaction pose challenges. In
this work, we propose UserRL, a unified framework for training and evaluating
user-centric abilities through standardized gym environments paired with
simulated users. We systematically vary turn-level reward assignment and
trajectory-level score calculation to analyze how different formulations affect
learning under the GRPO algorithm. Our experiments across Qwen3 models reveal
three key findings: (i) SFT cold start is critical for unlocking initial
interaction ability and enabling sustained RL improvements; (ii) deliberate
trajectory scoring yields more efficient and effective multi-turn interactions;
and (iii) while stronger simulated users (e.g., GPT-4o) facilitates training,
open-source simulators (e.g., Qwen3-32B) remain a cost-effective and
transferable option. Together, these results highlight that careful design of
reward shaping and user simulation choice is as crucial as model scale, and
establish UserRL as a practical pathway for developing robust user-centric
agentic models. All codes and data are public for future research.
\\ ( https://arxiv.org/abs/2509.19736 ,  3118kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19762
Date: Wed, 24 Sep 2025 05:09:43 GMT   (152kb)

Title: The Conductor and the Engine: A Path Towards Co-Designed Reasoning
Authors: Yuanxin Wang, Pawel Filipczuk, Anisha Garg, Amaan Dhada, Mohammad
  Hassanpour, David Bick, Ganesh Venkatesh
Categories: cs.AI
\\
  Modern LLM reasoning relies on extensive test-time computation, driven by
internal model training and external agentic orchestration. However, this
synergy is often inefficient, as model verbosity and poor instruction following
lead to wasted compute. We analyze this capability-cost trade-off and introduce
an optimized reasoning workflow (\cepo) that empowers smaller open-source
models to outperform models multiple times their size. We will open-source this
workflow to enable further research. Our work demonstrates a clear path toward
co-designing orchestration frameworks with the underlying model capabilities to
unlock powerful reasoning in small-to-medium sized models.
\\ ( https://arxiv.org/abs/2509.19762 ,  152kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19783
Date: Wed, 24 Sep 2025 06:10:23 GMT   (12kb)

Title: Agentic Metacognition: Designing a "Self-Aware" Low-Code Agent for
  Failure Prediction and Human Handoff
Authors: Jiexi Xu
Categories: cs.AI cs.HC cs.SE
Comments: 7 pages, 2 tables
\\
  The inherent non-deterministic nature of autonomous agents, particularly
within low-code/no-code (LCNC) environments, presents significant reliability
challenges. Agents can become trapped in unforeseen loops, generate inaccurate
outputs, or encounter unrecoverable failures, leading to user frustration and a
breakdown of trust. This report proposes a novel architectural pattern to
address these issues: the integration of a secondary, "metacognitive" layer
that actively monitors the primary LCNC agent. Inspired by human introspection,
this layer is designed to predict impending task failures based on a defined
set of triggers, such as excessive latency or repetitive actions. Upon
predicting a failure, the metacognitive agent proactively initiates a human
handoff, providing the user with a clear summary of the agent's "thought
process" and a detailed explanation of why it could not proceed. An empirical
analysis of a prototype system demonstrates that this approach significantly
increases the overall task success rate. However, this performance gain comes
with a notable increase in computational overhead. The findings reframe human
handoffs not as an admission of defeat but as a core design feature that
enhances system resilience, improves user experience, and builds trust by
providing transparency into the agent's internal state. The report discusses
the practical and ethical implications of this approach and identifies key
directions for future research.
\\ ( https://arxiv.org/abs/2509.19783 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19800
Date: Wed, 24 Sep 2025 06:36:11 GMT   (2636kb)

Title: Analysis of approximate linear programming solution to Markov decision
  problem with log barrier function
Authors: Donghwan Lee, Hyukjun Yang, Bum Geun Park
Categories: cs.AI
\\
  There are two primary approaches to solving Markov decision problems (MDPs):
dynamic programming based on the Bellman equation and linear programming (LP).
Dynamic programming methods are the most widely used and form the foundation of
both classical and modern reinforcement learning (RL). By contrast, LP-based
methods have been less commonly employed, although they have recently gained
attention in contexts such as offline RL. The relative underuse of the LP-based
methods stems from the fact that it leads to an inequality-constrained
optimization problem, which is generally more challenging to solve effectively
compared with Bellman-equation-based methods. The purpose of this paper is to
establish a theoretical foundation for solving LP-based MDPs in a more
effective and practical manner. Our key idea is to leverage the log-barrier
function, widely used in inequality-constrained optimization, to transform the
LP formulation of the MDP into an unconstrained optimization problem. This
reformulation enables approximate solutions to be obtained easily via gradient
descent. While the method may appear simple, to the best of our knowledge, a
thorough theoretical interpretation of this approach has not yet been
developed. This paper aims to bridge this gap.
\\ ( https://arxiv.org/abs/2509.19800 ,  2636kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19839
Date: Wed, 24 Sep 2025 07:31:54 GMT   (112kb)

Title: LatentGuard: Controllable Latent Steering for Robust Refusal of Attacks
  and Reliable Response Generation
Authors: Huizhen Shu, Xuying Li, Zhuo Li
Categories: cs.AI
Comments: 9-page NeurIPS 2025 preprint including 3 figures and 1 table, with
  additional appendix material. Prepared using the NeurIPS 2025 preprint
  template and compiled with pdfLaTeX. All references are included via the
  provided .bbl file. Figures are in PDF format. No external supplementary
  files. All necessary style files and images are included
\\
  Achieving robust safety alignment in large language models (LLMs) while
preserving their utility remains a fundamental challenge. Existing approaches
often struggle to balance comprehensive safety with fine-grained
controllability at the representation level. We introduce LATENTGUARD, a novel
three-stage framework that combines behavioral alignment with supervised latent
space control for interpretable and precise safety steering. Our approach
begins by fine-tuning an LLM on rationalized datasets containing both
reasoning-enhanced refusal responses to adversarial prompts and
reasoning-enhanced normal responses to benign queries, establishing robust
behavioral priors across both safety-critical and utility-preserving scenarios.
We then train a structured variational autoencoder (VAE) on intermediate MLP
activations, supervised by multi-label annotations including attack types,
attack methods, and benign indicators. This supervision enables the VAE to
learn disentangled latent representations that capture distinct adversarial
characteristics while maintaining semantic interpretability. Through targeted
manipulation of learned latent dimensions, LATENTGUARD achieves selective
refusal behavior, effectively blocking harmful requests while preserving
helpfulness for legitimate use cases. Experiments on Qwen3-8B demonstrate
significant improvements in both safety controllability and response
interpretability without compromising utility. Cross-architecture validation on
Mistral-7B confirms the generalizability of our latent steering approach,
showing consistent effectiveness across different model families. Our results
suggest that structured representation-level intervention offers a promising
pathway toward building safer yet practical LLM systems.
\\ ( https://arxiv.org/abs/2509.19839 ,  112kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19925
Date: Wed, 24 Sep 2025 09:29:17 GMT   (3033kb)

Title: CON-QA: Privacy-Preserving QA using cloud LLMs in Contract Domain
Authors: Ajeet Kumar Singh, Rajsabi Surya, Anurag Tripathi, Santanu Choudhury,
  Sudhir Bisane
Categories: cs.AI
\\
  As enterprises increasingly integrate cloud-based large language models
(LLMs) such as ChatGPT and Gemini into their legal document workflows,
protecting sensitive contractual information - including Personally
Identifiable Information (PII) and commercially sensitive clauses - has emerged
as a critical challenge. In this work, we propose CON-QA, a hybrid
privacy-preserving framework designed specifically for secure question
answering over enterprise contracts, effectively combining local and
cloud-hosted LLMs. The CON-QA framework operates through three stages: (i)
semantic query decomposition and query-aware document chunk retrieval using a
locally deployed LLM analysis, (ii) anonymization of detected sensitive
entities via a structured one-to-many mapping scheme, ensuring semantic
coherence while preventing cross-session entity inference attacks, and (iii)
anonymized response generation by a cloud-based LLM, with accurate
reconstruction of the original answer locally using a session-consistent
many-to-one reverse mapping. To rigorously evaluate CON-QA, we introduce
CUAD-QA, a corpus of 85k question-answer pairs generated over 510 real-world
CUAD contract documents, encompassing simple, complex, and summarization-style
queries. Empirical evaluations, complemented by detailed human assessments,
confirm that CON-QA effectively maintains both privacy and utility, preserves
answer quality, maintains fidelity to legal clause semantics, and significantly
mitigates privacy risks, demonstrating its practical suitability for secure,
enterprise-level contract documents.
\\ ( https://arxiv.org/abs/2509.19925 ,  3033kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20021
Date: Wed, 24 Sep 2025 11:37:48 GMT   (4147kb)

Title: Embodied AI: From LLMs to World Models
Authors: Tongtong Feng, Xin Wang, Yu-Gang Jiang, Wenwu Zhu
Categories: cs.AI cs.CL cs.RO
Comments: Accepted by IEEE CASM
\\
  Embodied Artificial Intelligence (AI) is an intelligent system paradigm for
achieving Artificial General Intelligence (AGI), serving as the cornerstone for
various applications and driving the evolution from cyberspace to physical
systems. Recent breakthroughs in Large Language Models (LLMs) and World Models
(WMs) have drawn significant attention for embodied AI. On the one hand, LLMs
empower embodied AI via semantic reasoning and task decomposition, bringing
high-level natural language instructions and low-level natural language actions
into embodied cognition. On the other hand, WMs empower embodied AI by building
internal representations and future predictions of the external world,
facilitating physical law-compliant embodied interactions. As such, this paper
comprehensively explores the literature in embodied AI from basics to advances,
covering both LLM driven and WM driven works. In particular, we first present
the history, key technologies, key components, and hardware systems of embodied
AI, as well as discuss its development via looking from unimodal to multimodal
angle. We then scrutinize the two burgeoning fields of embodied AI, i.e.,
embodied AI with LLMs/multimodal LLMs (MLLMs) and embodied AI with WMs,
meticulously delineating their indispensable roles in end-to-end embodied
cognition and physical laws-driven embodied interactions. Building upon the
above advances, we further share our insights on the necessity of the joint
MLLM-WM driven embodied AI architecture, shedding light on its profound
significance in enabling complex tasks within physical worlds. In addition, we
examine representative applications of embodied AI, demonstrating its wide
applicability in real-world scenarios. Last but not least, we point out future
research directions of embodied AI that deserve further investigation.
\\ ( https://arxiv.org/abs/2509.20021 ,  4147kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20067
Date: Wed, 24 Sep 2025 12:37:11 GMT   (7538kb)

Title: MACD: Multi-Agent Clinical Diagnosis with Self-Learned Knowledge for LLM
Authors: Wenliang Li, Rui Yan, Xu Zhang, Li Chen, Hongji Zhu, Jing Zhao, Junjun
  Li, Mengru Li, Wei Cao, Zihang Jiang, Wei Wei, Kun Zhang, Shaohua Kevin Zhou
Categories: cs.AI
\\
  Large language models (LLMs) have demonstrated notable potential in medical
applications, yet they face substantial challenges in handling complex
real-world clinical diagnoses using conventional prompting methods. Current
prompt engineering and multi-agent approaches typically optimize isolated
inferences, neglecting the accumulation of reusable clinical experience. To
address this, this study proposes a novel Multi-Agent Clinical Diagnosis (MACD)
framework, which allows LLMs to self-learn clinical knowledge via a multi-agent
pipeline that summarizes, refines, and applies diagnostic insights. It mirrors
how physicians develop expertise through experience, enabling more focused and
accurate diagnosis on key disease-specific cues. We further extend it to a
MACD-human collaborative workflow, where multiple LLM-based diagnostician
agents engage in iterative consultations, supported by an evaluator agent and
human oversight for cases where agreement is not reached. Evaluated on 4,390
real-world patient cases across seven diseases using diverse open-source LLMs
(Llama-3.1 8B/70B, DeepSeek-R1-Distill-Llama 70B), MACD significantly improves
primary diagnostic accuracy, outperforming established clinical guidelines with
gains up to 22.3% (MACD). On the subset of the data, it achieves performance on
par with or exceeding that of human physicians (up to 16% improvement over
physicians-only diagnosis). Additionally, on the MACD-human workflow, it
achieves an 18.6% improvement compared to physicians-only diagnosis. Moreover,
self-learned knowledge exhibits strong cross-model stability, transferability,
and model-specific personalization, while the system can generate traceable
rationales, enhancing explainability. Consequently, this work presents a
scalable self-learning paradigm for LLM-assisted diagnosis, bridging the gap
between the intrinsic knowledge of LLMs and real-world clinical practice.
\\ ( https://arxiv.org/abs/2509.20067 ,  7538kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20095
Date: Wed, 24 Sep 2025 13:16:35 GMT   (1260kb)

Title: From Pheromones to Policies: Reinforcement Learning for Engineered
  Biological Swarms
Authors: Aymeric Vellinger, Nemanja Antonic and Elio Tuci
Categories: cs.AI
Comments: Contribution to the 9th International Symposium on Swarm Behavior and
  Bio-Inspired Robotics 2025
\\
  Swarm intelligence emerges from decentralised interactions among simple
agents, enabling collective problem-solving. This study establishes a
theoretical equivalence between pheromone-mediated aggregation in \celeg\ and
reinforcement learning (RL), demonstrating how stigmergic signals function as
distributed reward mechanisms. We model engineered nematode swarms performing
foraging tasks, showing that pheromone dynamics mathematically mirror
cross-learning updates, a fundamental RL algorithm. Experimental validation
with data from literature confirms that our model accurately replicates
empirical \celeg\ foraging patterns under static conditions. In dynamic
environments, persistent pheromone trails create positive feedback loops that
hinder adaptation by locking swarms into obsolete choices. Through
computational experiments in multi-armed bandit scenarios, we reveal that
introducing a minority of exploratory agents insensitive to pheromones restores
collective plasticity, enabling rapid task switching. This behavioural
heterogeneity balances exploration-exploitation trade-offs, implementing
swarm-level extinction of outdated strategies. Our results demonstrate that
stigmergic systems inherently encode distributed RL processes, where
environmental signals act as external memory for collective credit assignment.
By bridging synthetic biology with swarm robotics, this work advances
programmable living systems capable of resilient decision-making in volatile
environments.
\\ ( https://arxiv.org/abs/2509.20095 ,  1260kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20102
Date: Wed, 24 Sep 2025 13:27:35 GMT   (2621kb)

Title: Steerable Adversarial Scenario Generation through Test-Time Preference
  Alignment
Authors: Tong Nie, Yuewen Mei, Yihong Tang, Junlin He, Jie Sun, Haotian Shi,
  Wei Ma, Jian Sun
Categories: cs.AI
\\
  Adversarial scenario generation is a cost-effective approach for safety
assessment of autonomous driving systems. However, existing methods are often
constrained to a single, fixed trade-off between competing objectives such as
adversariality and realism. This yields behavior-specific models that cannot be
steered at inference time, lacking the efficiency and flexibility to generate
tailored scenarios for diverse training and testing requirements. In view of
this, we reframe the task of adversarial scenario generation as a
multi-objective preference alignment problem and introduce a new framework
named \textbf{S}teerable \textbf{A}dversarial scenario \textbf{GE}nerator
(SAGE). SAGE enables fine-grained test-time control over the trade-off between
adversariality and realism without any retraining. We first propose
hierarchical group-based preference optimization, a data-efficient offline
alignment method that learns to balance competing objectives by decoupling hard
feasibility constraints from soft preferences. Instead of training a fixed
model, SAGE fine-tunes two experts on opposing preferences and constructs a
continuous spectrum of policies at inference time by linearly interpolating
their weights. We provide theoretical justification for this framework through
the lens of linear mode connectivity. Extensive experiments demonstrate that
SAGE not only generates scenarios with a superior balance of adversariality and
realism but also enables more effective closed-loop training of driving
policies. Project page: https://tongnie.github.io/SAGE/.
\\ ( https://arxiv.org/abs/2509.20102 ,  2621kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20105
Date: Wed, 24 Sep 2025 13:29:53 GMT   (696kb)

Title: PEPS: Quantum-Inspired Reinforcement Learning for Coherent Reasoning
  Traces in LLMs
Authors: Venkat Margapuri, Garik Kazanjian, Naren Kosaraju
Categories: cs.AI
\\
  Large Language Models (LLMs) often struggle with maintaining coherent
multi-step reasoning traces, particularly in tasks that require a structured
logical flow. This work introduces a quantum-inspired approach to address the
challenge by incorporating a fidelity-based reward derived from Projected
Entangled Pair States (PEPS) into Proximal Policy Optimization. Unlike prior
approaches that use direct supervision or contrastive objectives, the proposed
method guides learning through structural consistency, offering a novel
approach to enforce global coherence in generated reasoning traces. The
proposed framework is evaluated using multiple coherence-determining metrics on
diverse datasets such as GSM8K, StrategyQA, and EntailmentBank spanning
arithmetic, intuitive, and entailment-based reasoning. Results show that the
proposed quantum-inspired approach offers significant improvements over
supervised, contrastive, and pretrained baseline approaches, highlighting the
effectiveness of quantum-inspired fidelity as a foundation to improve reasoning
trace coherence in LLMs.
\\ ( https://arxiv.org/abs/2509.20105 ,  696kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20138
Date: Wed, 24 Sep 2025 14:02:33 GMT   (98kb)

Title: Formal Verification of Minimax Algorithms
Authors: Wieger Wesselink, Kees Huizing, Huub van de Wetering
Categories: cs.AI
Comments: 12 pages
MSC-class: 68Q60, 68T20
\\
  Using the Dafny verification system, we formally verify a range of minimax
search algorithms, including variations with alpha-beta pruning and
transposition tables. For depth-limited search with transposition tables, we
introduce a witness-based correctness criterion and apply it to two
representative algorithms. All verification artifacts, including proofs and
Python implementations, are publicly available.
\\ ( https://arxiv.org/abs/2509.20138 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20175
Date: Wed, 24 Sep 2025 14:38:06 GMT   (1647kb)

Title: Federation of Agents: A Semantics-Aware Communication Fabric for
  Large-Scale Agentic AI
Authors: Lorenzo Giusti, Ole Anton Werner, Riccardo Taiello, Matilde Carvalho
  Costa, Emre Tosun, Andrea Protani, Marc Molina, Rodrigo Lopes de Almeida,
  Paolo Cacace, Diogo Reis Santos, Luigi Serio
Categories: cs.AI cs.CL
Comments: 18 pages, 4 figures
\\
  We present Federation of Agents (FoA), a distributed orchestration framework
that transforms static multi-agent coordination into dynamic, capability-driven
collaboration. FoA introduces Versioned Capability Vectors (VCVs):
machine-readable profiles that make agent capabilities searchable through
semantic embeddings, enabling agents to advertise their capabilities, cost, and
limitations. Our aarchitecturecombines three key innovations: (1) semantic
routing that matches tasks to agents over sharded HNSW indices while enforcing
operational constraints through cost-biased optimization, (2) dynamic task
decomposition where compatible agents collaboratively break down complex tasks
into DAGs of subtasks through consensus-based merging, and (3) smart clustering
that groups agents working on similar subtasks into collaborative channels for
k-round refinement before synthesis. Built on top of MQTT,s publish-subscribe
semantics for scalable message passing, FoA achieves sub-linear complexity
through hierarchical capability matching and efficient index maintenance.
Evaluation on HealthBench shows 13x improvements over single-model baselines,
with clustering-enhanced laboration particularly effective for complex
reasoning tasks requiring multiple perspectives. The system scales horizontally
while maintaining consistent performance, demonstrating that semantic
orchestration with structured collaboration can unlock the collective
intelligence of heterogeneous federations of AI agents.
\\ ( https://arxiv.org/abs/2509.20175 ,  1647kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20218
Date: Wed, 24 Sep 2025 15:15:05 GMT   (9980kb)

Title: Design Insights and Comparative Evaluation of a Hardware-Based
  Cooperative Perception Architecture for Lane Change Prediction
Authors: Mohamed Manzour, Catherine M. Elias, Omar M. Shehata, Rub\'en
  Izquierdo and Miguel \'Angel Sotelo
Categories: cs.AI cs.AR cs.CV cs.LG
\\
  Research on lane change prediction has gained attention in the last few
years. Most existing works in this area have been conducted in simulation
environments or with pre-recorded datasets, these works often rely on
simplified assumptions about sensing, communication, and traffic behavior that
do not always hold in practice. Real-world deployments of lane-change
prediction systems are relatively rare, and when they are reported, the
practical challenges, limitations, and lessons learned are often
under-documented. This study explores cooperative lane-change prediction
through a real hardware deployment in mixed traffic and shares the insights
that emerged during implementation and testing. We highlight the practical
challenges we faced, including bottlenecks, reliability issues, and operational
constraints that shaped the behavior of the system. By documenting these
experiences, the study provides guidance for others working on similar
pipelines.
\\ ( https://arxiv.org/abs/2509.20218 ,  9980kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20270
Date: Wed, 24 Sep 2025 16:04:11 GMT   (277kb)

Title: Scan-do Attitude: Towards Autonomous CT Protocol Management using a
  Large Language Model Agent
Authors: Xingjian Kang, Linda Vorberg, Andreas Maier, Alexander Katzmann,
  Oliver Taubmann
Categories: cs.AI cs.CL
\\
  Managing scan protocols in Computed Tomography (CT), which includes adjusting
acquisition parameters or configuring reconstructions, as well as selecting
postprocessing tools in a patient-specific manner, is time-consuming and
requires clinical as well as technical expertise. At the same time, we observe
an increasing shortage of skilled workforce in radiology. To address this
issue, a Large Language Model (LLM)-based agent framework is proposed to assist
with the interpretation and execution of protocol configuration requests given
in natural language or a structured, device-independent format, aiming to
improve the workflow efficiency and reduce technologists' workload. The agent
combines in-context-learning, instruction-following, and structured toolcalling
abilities to identify relevant protocol elements and apply accurate
modifications. In a systematic evaluation, experimental results indicate that
the agent can effectively retrieve protocol components, generate device
compatible protocol definition files, and faithfully implement user requests.
Despite demonstrating feasibility in principle, the approach faces limitations
regarding syntactic and semantic validity due to lack of a unified device API,
and challenges with ambiguous or complex requests. In summary, the findings
show a clear path towards LLM-based agents for supporting scan protocol
management in CT imaging.
\\ ( https://arxiv.org/abs/2509.20270 ,  277kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19314
Date: Tue, 9 Sep 2025 16:44:28 GMT   (45kb)

Title: Automated Item Neutralization for Non-Cognitive Scales: A Large Language
  Model Approach to Reducing Social-Desirability Bias
Authors: Sirui Wu, Daijin Yang
Categories: cs.CL cs.AI cs.CY
Comments: Accepted for publication in NCME-AIME 2025
\\
  This study evaluates item neutralization assisted by the large language model
(LLM) to reduce social desirability bias in personality assessment. GPT-o3 was
used to rewrite the International Personality Item Pool Big Five Measure
(IPIP-BFM-50), and 203 participants completed either the original or
neutralized form along with the Marlowe-Crowne Social Desirability Scale. The
results showed preserved reliability and a five-factor structure, with gains in
Conscientiousness and declines in Agreeableness and Openness. The correlations
with social desirability decreased for several items, but inconsistently.
Configural invariance held, though metric and scalar invariance failed.
Findings support AI neutralization as a potential but imperfect bias-reduction
method.
\\ ( https://arxiv.org/abs/2509.19314 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19319
Date: Fri, 12 Sep 2025 06:52:55 GMT   (522kb)

Title: FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR
  Question Answering
Authors: Gyubok Lee, Elea Bach, Eric Yang, Tom Pollard, Alistair Johnson,
  Edward Choi, Yugang jia, Jong Ha Lee
Categories: cs.CL cs.AI
Comments: Under review
\\
  The recent shift toward the Health Level Seven Fast Healthcare
Interoperability Resources (HL7 FHIR) standard opens a new frontier for
clinical AI, demanding LLM agents to navigate complex, resource-based data
models instead of conventional structured health data. However, existing
benchmarks have lagged behind this transition, lacking the realism needed to
evaluate recent LLMs on interoperable clinical data. To bridge this gap, we
introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical
questions in the HL7 FHIR standard. Using this benchmark, we systematically
evaluate agentic frameworks, comparing different data retrieval strategies
(direct FHIR API calls vs. specialized tools), interaction patterns
(single-turn vs. multi-turn), and reasoning strategies (natural language vs.
code generation). Our experiments highlight the practical challenges of
retrieving data from intricate FHIR resources and the difficulty of reasoning
over them, both of which critically affect question answering performance. We
publicly release the FHIR-AgentBench dataset and evaluation suite
(https://github.com/glee4810/FHIR-AgentBench) to promote reproducible research
and the development of robust, reliable LLM agents for clinical applications.
\\ ( https://arxiv.org/abs/2509.19319 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19322
Date: Fri, 12 Sep 2025 20:34:58 GMT   (34kb)

Title: Readme_AI: Dynamic Context Construction for Large Language Models
Authors: Millie Vyas, Timothy Blattner, Alden Dima
Categories: cs.CL cs.AI
\\
  Despite being trained on significant amounts of data, Large Language Models
(LLMs) can provide inaccurate or unreliable information in the context of a
user's specific query. Given query-specific context significantly improves the
usefulness of its responses. In this paper, we present a specification that can
be used to dynamically build context for data sources. The data source owner
creates the file containing metadata for LLMs to use when reasoning about
dataset-related queries. To demonstrate our proposed specification, we created
a prototype Readme_AI Model Context Protocol (MCP) server that retrieves the
metadata from the data source and uses it to dynamically build context. Some
features that make this specification dynamic are the extensible types that
represent crawling web-pages, fetching data from data repositories, downloading
and parsing publications, and general text. The context is formatted and
grouped using user-specified tags that provide clear contextual information for
the LLM to reason about the content. We demonstrate the capabilities of this
early prototype by asking the LLM about the NIST-developed Hedgehog library,
for which common LLMs often provides inaccurate and irrelevant responses
containing hallucinations. With Readme_AI, the LLM receives enough context that
it is now able to reason about the library and its use, and even generate code
interpolated from examples that were included in the Readme_AI file provided by
Hedgehog's developer. Our primary contribution is a extensible protocol for
dynamically grounding LLMs in specialized, owner-provided data, enhancing
responses from LLMs and reducing hallucinations. The source code for the
Readme_AI tool is posted here: https://github.com/usnistgov/readme_ai .
\\ ( https://arxiv.org/abs/2509.19322 ,  34kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19323
Date: Fri, 12 Sep 2025 22:26:15 GMT   (30kb)

Title: Magnitude Matters: a Superior Class of Similarity Metrics for Holistic
  Semantic Understanding
Authors: V.S. Raghu Parupudi
Categories: cs.CL cs.AI
Comments: submitted to AAAI 2026
\\
  Vector comparison in high dimensions is a fundamental task in NLP, yet it is
dominated by two baselines: the raw dot product, which is unbounded and
sensitive to vector norms, and the cosine similarity, which discards magnitude
information entirely. This paper challenges both standards by proposing and
rigorously evaluating a new class of parameter-free, magnitude-aware similarity
metrics. I introduce two such functions, Overlap Similarity (OS) and Hyperbolic
Tangent Similarity (HTS), designed to integrate vector magnitude and alignment
in a more principled manner. To ensure that my findings are robust and
generalizable, I conducted a comprehensive evaluation using four
state-of-the-art sentence embedding models (all-MiniLM-L6-v2,
all-mpnet-base-v2, paraphrase-mpnet-base-v2, and BAAI/bge-large-en-v1.5) across
a diverse suite of eight standard NLP benchmarks, including STS-B, SICK, Quora,
and PAWS. Using the Wilcoxon signed-rank test for statistical significance, my
results are definitive: on the tasks requiring holistic semantic understanding
(paraphrase and inference), both OS and HTS provide a statistically significant
improvement in Mean Squared Error over both the raw dot product and cosine
similarity, regardless of the underlying embedding model.Crucially, my findings
delineate the specific domain of advantage for these metrics: for tasks
requiring holistic semantic understanding like paraphrase and inference, my
magnitude-aware metrics offer a statistically superior alternative. This
significant improvement was not observed on benchmarks designed to test highly
nuanced compositional semantics (SICK, STS-B), identifying the challenge of
representing compositional text as a distinct and important direction for
future work.
\\ ( https://arxiv.org/abs/2509.19323 ,  30kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19325
Date: Sat, 13 Sep 2025 18:55:52 GMT   (270kb)

Title: How Much of Your Data Can Suck? Thresholds for Domain Performance and
  Emergent Misalignment in LLMs
Authors: Jian Ouyang, Arman T, Ge Jin
Categories: cs.CL
\\
  This paper investigates the impact of incorrect data on the performance and
safety of large language models (LLMs), specifically gpt-4o, during supervised
fine-tuning (SFT). Although LLMs become increasingly vital across broad domains
like finance, coding, law, and health, fine-tuning on incorrect data can lead
to "emergent misalignment," producing harmful or deceptive outputs unrelated to
the intended task. We evaluate gpt-4o models fine-tuned with varying ratios
(10\% to 90\% correct) of both obviously and subtly incorrect data across four
domains: coding, finance, health, and legal. Our findings show that even modest
amounts of incorrect data (10-25\%) dramatically degrade domain performance and
not moral alignment. A clear threshold of at least 50\% correct data is needed
for models to consistently recover strong performance, though they rarely match
the robustness and safety of the base model, which exhibits near-perfect
alignment and zero dangerous completions out-of-the-box. This research
emphasizes that the cost of incorrect data is heavy, highlighting the critical
need for extremely high-quality data curation or, alternatively, leveraging
robust base models without unnecessary fine-tuning for high-stakes
applications.
\\ ( https://arxiv.org/abs/2509.19325 ,  270kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19326
Date: Sat, 13 Sep 2025 19:15:22 GMT   (3486kb)

Title: Unveiling the Merits and Defects of LLMs in Automatic Review Generation
  for Scientific Papers
Authors: Ruochi Li, Haoxuan Zhang, Edward Gehringer, Ting Xiao, Junhua Ding,
  Haihua Chen
Categories: cs.CL cs.AI
Comments: Accepted as short paper at 25th IEEE International Conference on Data
  Mining
\\
  The surge in scientific submissions has placed increasing strain on the
traditional peer-review process, prompting the exploration of large language
models (LLMs) for automated review generation. While LLMs demonstrate
competence in producing structured and coherent feedback, their capacity for
critical reasoning, contextual grounding, and quality sensitivity remains
limited. To systematically evaluate these aspects, we propose a comprehensive
evaluation framework that integrates semantic similarity analysis and
structured knowledge graph metrics to assess LLM-generated reviews against
human-written counterparts. We construct a large-scale benchmark of 1,683
papers and 6,495 expert reviews from ICLR and NeurIPS in multiple years, and
generate reviews using five LLMs. Our findings show that LLMs perform well in
descriptive and affirmational content, capturing the main contributions and
methodologies of the original work, with GPT-4o highlighted as an illustrative
example, generating 15.74% more entities than human reviewers in the strengths
section of good papers in ICLR 2025. However, they consistently underperform in
identifying weaknesses, raising substantive questions, and adjusting feedback
based on paper quality. GPT-4o produces 59.42% fewer entities than real
reviewers in the weaknesses and increases node count by only 5.7% from good to
weak papers, compared to 50% in human reviews. Similar trends are observed
across all conferences, years, and models, providing empirical foundations for
understanding the merits and defects of LLM-generated reviews and informing the
development of future LLM-assisted reviewing tools. Data, code, and more
detailed results are publicly available at
https://github.com/RichardLRC/Peer-Review.
\\ ( https://arxiv.org/abs/2509.19326 ,  3486kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19327
Date: Sat, 13 Sep 2025 21:21:05 GMT   (1300kb)

Title: A systematic review of trial-matching pipelines using large language
  models
Authors: Braxton A. Morrison (1), Madhumita Sushil (1), Jacob S. Young (1) ((1)
  University of California, San Francisco)
Categories: cs.CL cs.AI
Comments: 28 pages, 3 figures
\\
  Matching patients to clinical trial options is critical for identifying novel
treatments, especially in oncology. However, manual matching is labor-intensive
and error-prone, leading to recruitment delays. Pipelines incorporating large
language models (LLMs) offer a promising solution. We conducted a systematic
review of studies published between 2020 and 2025 from three academic databases
and one preprint server, identifying LLM-based approaches to clinical trial
matching. Of 126 unique articles, 31 met inclusion criteria. Reviewed studies
focused on matching patient-to-criterion only (n=4), patient-to-trial only
(n=10), trial-to-patient only (n=2), binary eligibility classification only
(n=1) or combined tasks (n=14). Sixteen used synthetic data; fourteen used real
patient data; one used both. Variability in datasets and evaluation metrics
limited cross-study comparability. In studies with direct comparisons, the
GPT-4 model consistently outperformed other models, even finely-tuned ones, in
matching and eligibility extraction, albeit at higher cost. Promising
strategies included zero-shot prompting with proprietary LLMs like the GPT-4o
model, advanced retrieval methods, and fine-tuning smaller, open-source models
for data privacy when incorporation of large models into hospital
infrastructure is infeasible. Key challenges include accessing sufficiently
large real-world data sets, and deployment-associated challenges such as
reducing cost, mitigating risk of hallucinations, data leakage, and bias. This
review synthesizes progress in applying LLMs to clinical trial matching,
highlighting promising directions and key limitations. Standardized metrics,
more realistic test sets, and attention to cost-efficiency and fairness will be
critical for broader deployment.
\\ ( https://arxiv.org/abs/2509.19327 ,  1300kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19329
Date: Sun, 14 Sep 2025 02:24:41 GMT   (871kb)

Title: How Model Size, Temperature, and Prompt Style Affect LLM-Human
  Assessment Score Alignment
Authors: Julie Jung, Max Lu, Sina Chole Benker, and Dogus Darici
Categories: cs.CL stat.ME
Comments: 9 pages, 4 figures, accepted at NCME AIME 2025
\\
  We examined how model size, temperature, and prompt style affect Large
Language Models' (LLMs) alignment within itself, between models, and with human
in assessing clinical reasoning skills. Model size emerged as a key factor in
LLM-human score alignment. Study highlights the importance of checking
alignments across multiple levels.
\\ ( https://arxiv.org/abs/2509.19329 ,  871kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19332
Date: Sun, 14 Sep 2025 18:28:21 GMT   (1214kb)

Title: Quantifying Compositionality of Classic and State-of-the-Art Embeddings
Authors: Zhijin Guo (1 and 2), Chenhao Xue (1), Zhaozhen Xu (2), Hongbo Bo (2),
  Yuxuan Ye (2), Janet B. Pierrehumbert (1), Martha Lewis (3) ((1) University
  of Oxford, (2) University of Bristol, (3) University of Amsterdam)
Categories: cs.CL cs.AI
Comments: Findings of the Association for Computational Linguistics: EMNLP 2025
\\
  For language models to generalize correctly to novel expressions, it is
critical that they exploit access compositional meanings when this is
justified. Even if we don't know what a "pelp" is, we can use our knowledge of
numbers to understand that "ten pelps" makes more pelps than "two pelps".
Static word embeddings such as Word2vec made strong, indeed excessive, claims
about compositionality. The SOTA generative, transformer models and graph
models, however, go too far in the other direction by providing no real limits
on shifts in meaning due to context. To quantify the additive compositionality,
we formalize a two-step, generalized evaluation that (i) measures the linearity
between known entity attributes and their embeddings via canonical correlation
analysis, and (ii) evaluates additive generalization by reconstructing
embeddings for unseen attribute combinations and checking reconstruction
metrics such as L2 loss, cosine similarity, and retrieval accuracy. These
metrics also capture failure cases where linear composition breaks down.
Sentences, knowledge graphs, and word embeddings are evaluated and tracked the
compositionality across all layers and training stages. Stronger compositional
signals are observed in later training stages across data modalities, and in
deeper layers of the transformer-based model before a decline at the top layer.
Code is available at
https://github.com/Zhijin-Guo1/quantifying-compositionality.
\\ ( https://arxiv.org/abs/2509.19332 ,  1214kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19333
Date: Mon, 15 Sep 2025 01:57:49 GMT   (93kb)

Title: Pluralistic Off-policy Evaluation and Alignment
Authors: Chengkai Huang, Junda Wu, Zhouhang Xie, Yu Xia, Rui Wang, Tong Yu,
  Subrata Mitra, Julian McAuley, Lina Yao
Categories: cs.CL cs.AI
\\
  Personalized preference alignment for LLMs with diverse human preferences
requires evaluation and alignment methods that capture pluralism. Most existing
preference alignment datasets are logged under policies that differ
substantially from the evaluated LLMs, and existing off-policy estimators focus
solely on overall utility while ignoring preference pluralism. Extending
Off-Policy Evaluation (OPE) to pluralistic preference alignment, therefore,
remains an open question. Thus, we propose the Pluralistic Off-Policy
Evaluation (POPE), the first framework for offline pluralistic preference
evaluation and alignment in LLMs. POPE includes a unified reward function that
combines (1) a collaborative utility component derived from human preference
signals (e.g., upvotes or relevance scores) and (2) a diversity component
inspired by entropy-based coverage measures, together reflecting pluralistic
alignment. Furthermore, to estimate this reward from logged interactions, we
derive decomposable inverse propensity scoring (IPS) estimators that separately
evaluate relevance and diversity. Theoretically, we prove that our decomposed
IPS estimators establish a lower bound on their variance. With the off-policy
evaluated value function, we can directly enable off-policy optimization to
further enhance pluralistic alignment. Empirical results demonstrate that POPE
efficiently enhances pluralistic response generation and maintains the models'
general capabilities on downstream tasks
\\ ( https://arxiv.org/abs/2509.19333 ,  93kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19336
Date: Mon, 15 Sep 2025 10:11:25 GMT   (948kb)

Title: Cognitive-Level Adaptive Generation via Capability-Aware Retrieval and
  Style Adaptation
Authors: Qingsong Wang, Tao Wu, Wang Lin, Yueying Feng, Gongsheng Yuan, Chang
  Yao, Jingyuan Chen
Categories: cs.CL cs.AI
Comments: Accepted to Findings of EMNLP 2026
\\
  Large Language Models (LLMs) have demonstrated strong performance in
open-ended generation tasks. However, they often struggle to adapt content to
users with differing cognitive capacities, leading to a phenomenon we term
cognitive misalignment. This issue arises in two forms: knowledge-level
misalignment, where content is too complex or too simplistic relative to user
understanding, and presentation-style misalignment, where the structure or tone
hinders effective comprehension. To address these challenges, we propose the
Cognitive-Level Alignment Framework (CLAF), a general-purpose generation
framework that aligns both knowledge complexity and presentation style with
user cognition. CLAF integrates a capability-aware retrieval module based on a
hierarchical knowledge graph and a style optimization module guided by Bloom's
taxonomy and preference learning. Additionally, a knowledge-controllable
generation component ensures consistency and relevance throughout the output.
To support training and evaluation, we construct SCALE, a cognitively annotated
dataset containing responses at multiple comprehension levels per query.
Empirical results show that CLAF enhances the adaptability and informativeness
of LLM outputs across a range of user profiles, offering a robust solution to
cognitive-level alignment in real-world applications.
\\ ( https://arxiv.org/abs/2509.19336 ,  948kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19343
Date: Tue, 16 Sep 2025 12:59:55 GMT   (708kb)

Title: Part-of-speech tagging for Nagamese Language using CRF
Authors: Alovi N Shohe, Chonglio Khiamungam, Teisovi Angami
Categories: cs.CL cs.AI
Comments: 8 pages
\\
  This paper investigates part-of-speech tagging, an important task in Natural
Language Processing (NLP) for the Nagamese language. The Nagamese language,
a.k.a. Naga Pidgin, is an Assamese-lexified Creole language developed primarily
as a means of communication in trade between the Nagas and people from Assam in
northeast India. A substantial amount of work in part-of-speech-tagging has
been done for resource-rich languages like English, Hindi, etc. However, no
work has been done in the Nagamese language. To the best of our knowledge, this
is the first attempt at part-of-speech tagging for the Nagamese Language. The
aim of this work is to identify the part-of-speech for a given sentence in the
Nagamese language. An annotated corpus of 16,112 tokens is created and applied
machine learning technique known as Conditional Random Fields (CRF). Using CRF,
an overall tagging accuracy of 85.70%; precision, recall of 86%, and f1-score
of 85% is achieved.
  Keywords. Nagamese, NLP, part-of-speech, machine learning, CRF.
\\ ( https://arxiv.org/abs/2509.19343 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19344
Date: Tue, 16 Sep 2025 14:46:34 GMT   (291kb)

Title: Performance of Large Language Models in Answering Critical Care Medicine
  Questions
Authors: Mahmoud Alwakeel, Aditya Nagori, An-Kwok Ian Wong, Neal Chaisson,
  Vijay Krishnamoorthy, Rishikesan Kamaleswaran
Categories: cs.CL
\\
  Large Language Models have been tested on medical student-level questions,
but their performance in specialized fields like Critical Care Medicine (CCM)
is less explored. This study evaluated Meta-Llama 3.1 models (8B and 70B
parameters) on 871 CCM questions. Llama3.1:70B outperformed 8B by 30%, with 60%
average accuracy. Performance varied across domains, highest in Research
(68.4%) and lowest in Renal (47.9%), highlighting the need for broader future
work to improve models across various subspecialty domains.
\\ ( https://arxiv.org/abs/2509.19344 ,  291kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19345
Date: Tue, 16 Sep 2025 16:06:19 GMT   (286kb)

Title: SCORE: A Semantic Evaluation Framework for Generative Document Parsing
Authors: Renyu Li, Antonio Jimeno Yepes, Yao You, Kamil Pluci\'nski, Maximilian
  Operlejn, and Crag Wolfe
Categories: cs.CL cs.AI
\\
  Multi-modal generative document parsing systems challenge traditional
evaluation: unlike deterministic OCR or layout models, they often produce
semantically correct yet structurally divergent outputs. Conventional
metrics-CER, WER, IoU, or TEDS-misclassify such diversity as error, penalizing
valid interpretations and obscuring system behavior.
  We introduce SCORE (Structural and COntent Robust Evaluation), an
interpretation-agnostic framework that integrates (i) adjusted edit distance
for robust content fidelity, (ii) token-level diagnostics to distinguish
hallucinations from omissions, (iii) table evaluation with spatial tolerance
and semantic alignment, and (iv) hierarchy-aware consistency checks. Together,
these dimensions enable evaluation that embraces representational diversity
while enforcing semantic rigor.
  Across 1,114 pages spanning a holistic benchmark and a field dataset, SCORE
consistently revealed cross-dataset performance patterns missed by standard
metrics. In 2-5% of pages with ambiguous table structures, traditional metrics
penalized systems by 12-25% on average, leading to distorted rankings. SCORE
corrected these cases, recovering equivalence between alternative but valid
interpretations. Moreover, by normalizing generative outputs into a
format-agnostic representation, SCORE reproduces traditional scores (e.g.,
table F1 up to 0.93) without requiring object-detection pipelines,
demonstrating that generative parsing alone suffices for comprehensive
evaluation.
  By exposing how interpretive diversity impacts evaluation outcomes and
providing multi-dimensional, interpretable diagnostics, SCORE establishes
foundational principles for semantically grounded, fair, and practical
benchmarking of modern document parsing systems.
\\ ( https://arxiv.org/abs/2509.19345 ,  286kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19346
Date: Tue, 16 Sep 2025 20:58:10 GMT   (1286kb)

Title: Benchmarking ChatGPT and DeepSeek in April 2025: A Novel Dual
  Perspective Sentiment Analysis Using Lexicon-Based and Deep Learning
  Approaches
Authors: Maryam Mahdi Alhusseini, Mohammad-Reza Feizi-Derakhshi
Categories: cs.CL
Comments: 17 pages, 21 figures
\\
  This study presents a novel dual-perspective approach to analyzing user
reviews for ChatGPT and DeepSeek on the Google Play Store, integrating
lexicon-based sentiment analysis (TextBlob) with deep learning classification
models, including Convolutional Neural Networks (CNN) and Bidirectional Long
Short Term Memory (Bi LSTM) Networks. Unlike prior research, which focuses on
either lexicon-based strategies or predictive deep learning models in
isolation, this study conducts an extensive investigation into user
satisfaction with Large Language Model (LLM) based applications. A Dataset of
4,000 authentic user reviews was collected, which were carefully preprocessed
and subjected to oversampling to achieve balanced classes. The balanced test
set of 1,700 Reviews were used for model testing. Results from the experiments
reveal that ChatGPT received significantly more positive sentiment than
DeepSeek. Furthermore, deep learning based classification demonstrated superior
performance over lexicon analysis, with CNN outperforming Bi-LSTM by achieving
96.41 percent accuracy and near perfect classification of negative reviews,
alongside high F1-scores for neutral and positive sentiments. This research
sets a new methodological standard for measuring sentiment in LLM-based
applications and provides practical insights for developers and researchers
seeking to improve user-centric AI system design.
\\ ( https://arxiv.org/abs/2509.19346 ,  1286kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19347
Date: Wed, 17 Sep 2025 08:15:14 GMT   (27kb)

Title: Characterizing Knowledge Graph Tasks in LLM Benchmarks Using Cognitive
  Complexity Frameworks
Authors: Sara Todorovikj and Lars-Peter Meyer and Michael Martin
Categories: cs.CL
Comments: peer reviewed publication at SEMANTiCS 2025 Poster Track
\\
  Large Language Models (LLMs) are increasingly used for tasks involving
Knowledge Graphs (KGs), whose evaluation typically focuses on accuracy and
output correctness. We propose a complementary task characterization approach
using three complexity frameworks from cognitive psychology. Applying this to
the LLM-KG-Bench framework, we highlight value distributions, identify
underrepresented demands and motivate richer interpretation and diversity for
benchmark evaluation tasks.
\\ ( https://arxiv.org/abs/2509.19347 ,  27kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19349
Date: Wed, 17 Sep 2025 17:49:02 GMT   (3337kb)

Title: ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution
Authors: Robert Tjarko Lange, Yuki Imajuku, Edoardo Cetin
Categories: cs.CL cs.LG
Comments: 52 pages, 14 figures
\\
  We introduce ShinkaEvolve: a new open-source framework leveraging large
language models (LLMs) to advance scientific discovery with state-of-the-art
performance and unprecedented efficiency. Recent advances in scaling inference
time compute of LLMs have enabled significant progress in generalized
scientific discovery. These approaches rely on evolutionary agentic harnesses
that leverage LLMs as mutation operators to generate candidate solutions.
However, current code evolution methods suffer from critical limitations: they
are sample inefficient, requiring thousands of samples to identify effective
solutions, and remain closed-source, hindering broad adoption and extension.
ShinkaEvolve addresses these limitations, introducing three key innovations: a
parent sampling technique balancing exploration and exploitation, code novelty
rejection-sampling for efficient search space exploration, and a bandit-based
LLM ensemble selection strategy. We evaluate ShinkaEvolve across diverse tasks,
demonstrating consistent improvements in sample efficiency and solution
quality. ShinkaEvolve discovers a new state-of-the-art circle packing solution
using only 150 samples, designs high-performing agentic harnesses for AIME
mathematical reasoning tasks, identifies improvements to ALE-Bench competitive
programming solutions, and discovers novel mixture-of-expert load balancing
loss functions that illuminate the space of optimization strategies. Our
results demonstrate that ShinkaEvolve achieves broad applicability with
exceptional sample efficiency. By providing open-source accessibility and
cost-efficiency, this work democratizes open-ended discovery across diverse
computational problems.
\\ ( https://arxiv.org/abs/2509.19349 ,  3337kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19352
Date: Thu, 18 Sep 2025 02:46:51 GMT   (537kb)

Title: TriSPrompt: A Hierarchical Soft Prompt Model for Multimodal Rumor
  Detection with Incomplete Modalities
Authors: Jiajun Chen, Yangyang Wu, Xiaoye Miao, Mengying Zhu, Meng Xi
Categories: cs.CL cs.AI
\\
  The widespread presence of incomplete modalities in multimodal data poses a
significant challenge to achieving accurate rumor detection. Existing
multimodal rumor detection methods primarily focus on learning joint modality
representations from \emph{complete} multimodal training data, rendering them
ineffective in addressing the common occurrence of \emph{missing modalities} in
real-world scenarios. In this paper, we propose a hierarchical soft prompt
model \textsf{TriSPrompt}, which integrates three types of prompts,
\textit{i.e.}, \emph{modality-aware} (MA) prompt, \emph{modality-missing} (MM)
prompt, and \emph{mutual-views} (MV) prompt, to effectively detect rumors in
incomplete multimodal data. The MA prompt captures both heterogeneous
information from specific modalities and homogeneous features from available
data, aiding in modality recovery. The MM prompt models missing states in
incomplete data, enhancing the model's adaptability to missing information. The
MV prompt learns relationships between subjective (\textit{i.e.}, text and
image) and objective (\textit{i.e.}, comments) perspectives, effectively
detecting rumors. Extensive experiments on three real-world benchmarks
demonstrate that \textsf{TriSPrompt} achieves an accuracy gain of over 13\%
compared to state-of-the-art methods. The codes and datasets are available at
https: //anonymous.4open.science/r/code-3E88.
\\ ( https://arxiv.org/abs/2509.19352 ,  537kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19354
Date: Thu, 18 Sep 2025 09:46:55 GMT   (21950kb)

Title: RoadMind: Towards a Geospatial AI Expert for Disaster Response
Authors: Ahmed El Fekih Zguir, Ferda Ofli, Muhammad Imran
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) have shown impressive performance across a range
of natural language tasks, but remain limited in their ability to reason about
geospatial data, particularly road networks, distances, and directions. This
gap poses challenges in disaster scenarios, where spatial understanding is
critical for tasks such as evacuation planning and resource allocation. In this
work, we present RoadMind, a self-supervised framework that enhances the
geospatial reasoning capabilities of LLMs using structured data from
OpenStreetMap (OSM). Our automated pipeline extracts road infrastructure data
for a given city and converts it into multiple supervision formats tailored to
key spatial tasks. We pretrain and fine-tune LLMs on these representations
using QLoRA adapters and 4-bit quantized models. We evaluate our approach on
three disaster-prone cities with varying global representation, Los Angeles,
Christchurch, and Manila, across tasks such as road segment identification,
nearest road retrieval, and distance/direction estimation. Our results show
that models trained via RoadMind significantly outperform strong baselines,
including state-of-the-art LLMs equipped with advanced prompt engineering. This
demonstrates the potential of structured geospatial data to enhance language
models with robust spatial reasoning, enabling more effective offline AI
systems for disaster response.
\\ ( https://arxiv.org/abs/2509.19354 ,  21950kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19358
Date: Thu, 18 Sep 2025 13:56:14 GMT   (618kb)

Title: Benchmarking and Improving LLM Robustness for Personalized Generation
Authors: Chimaobi Okite, Naihao Deng, Kiran Bodipati, Huaidian Hou, Joyce Chai,
  Rada Mihalcea
Categories: cs.CL cs.AI
Comments: First draft. First camera-ready version
\\
  Recent years have witnessed a growing interest in personalizing the responses
of large language models (LLMs). While existing evaluations primarily focus on
whether a response aligns with a user's preferences, we argue that factuality
is an equally important yet often overlooked dimension. In the context of
personalization, we define a model as robust if its responses are both
factually accurate and align with the user preferences. To assess this, we
introduce PERG, a scalable framework for evaluating robustness in LLMs, along
with a new dataset, PERGData. We evaluate fourteen models from five different
model families using different prompting methods. Our findings show that
current LLMs struggle with robust personalization: even the strongest models
(GPT-4.1, LLaMA3-70B) fail to maintain correctness in 5% of previously
successful cases without personalization, while smaller models (e.g., 7B-scale)
can fail more than 20% of the time. Further analysis reveals that robustness is
significantly affected by the nature of the query and the type of user
preference. To mitigate these failures, we propose Pref-Aligner, a two-stage
approach that improves robustness by an average of 25% across models. Our work
highlights critical gaps in current evaluation practices and introduces tools
and metrics to support more reliable, user-aligned LLM deployments.
\\ ( https://arxiv.org/abs/2509.19358 ,  618kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19360
Date: Thu, 18 Sep 2025 15:06:46 GMT   (254kb)

Title: Semantic Representation Attack against Aligned Large Language Models
Authors: Jiawei Lian, Jianhong Pan, Lefan Wang, Yi Wang, Shaohui Mei, Lap-Pui
  Chau
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) increasingly employ alignment techniques to
prevent harmful outputs. Despite these safeguards, attackers can circumvent
them by crafting prompts that induce LLMs to generate harmful content.
  Current methods typically target exact affirmative responses, such as ``Sure,
here is...'', suffering from limited convergence, unnatural prompts, and high
computational costs.
  We introduce Semantic Representation Attack, a novel paradigm that
fundamentally reconceptualizes adversarial objectives against aligned LLMs.
  Rather than targeting exact textual patterns, our approach exploits the
semantic representation space comprising diverse responses with equivalent
harmful meanings.
  This innovation resolves the inherent trade-off between attack efficacy and
prompt naturalness that plagues existing methods.
  The Semantic Representation Heuristic Search algorithm is proposed to
efficiently generate semantically coherent and concise adversarial prompts by
maintaining interpretability during incremental expansion.
  We establish rigorous theoretical guarantees for semantic convergence and
demonstrate that our method achieves unprecedented attack success rates
(89.41\% averaged across 18 LLMs, including 100\% on 11 models) while
maintaining stealthiness and efficiency.
  Comprehensive experimental results confirm the overall superiority of our
Semantic Representation Attack.
  The code will be publicly available.
\\ ( https://arxiv.org/abs/2509.19360 ,  254kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19364
Date: Thu, 18 Sep 2025 20:41:20 GMT   (718kb)

Title: The Inadequacy of Offline LLM Evaluations: A Need to Account for
  Personalization in Model Behavior
Authors: Angelina Wang and Daniel E. Ho and Sanmi Koyejo
Categories: cs.CL cs.AI
Comments: forthcoming in Patterns
\\
  Standard offline evaluations for language models -- a series of independent,
state-less inferences made by models -- fail to capture how language models
actually behave in practice, where personalization fundamentally alters model
behavior. For instance, identical benchmark questions to the same language
model can produce markedly different responses when prompted to a state-less
system, in one user's chat session, or in a different user's chat session. In
this work, we provide empirical evidence showcasing this phenomenon by
comparing offline evaluations to field evaluations conducted by having 800 real
users of ChatGPT and Gemini pose benchmark and other provided questions to
their chat interfaces.
\\ ( https://arxiv.org/abs/2509.19364 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19365
Date: Thu, 18 Sep 2025 20:59:11 GMT   (442kb)

Title: LLM-Assisted Topic Reduction for BERTopic on Social Media Data
Authors: Wannes Janssens, Matthias Bogaert, Dirk Van den Poel
Categories: cs.CL cs.LG
Comments: 13 pages, 8 figures. To be published in the Post-Workshop proceedings
  of the ECML PKDD 2025 Conference
\\
  The BERTopic framework leverages transformer embeddings and hierarchical
clustering to extract latent topics from unstructured text corpora. While
effective, it often struggles with social media data, which tends to be noisy
and sparse, resulting in an excessive number of overlapping topics. Recent work
explored the use of large language models for end-to-end topic modelling.
However, these approaches typically require significant computational overhead,
limiting their scalability in big data contexts. In this work, we propose a
framework that combines BERTopic for topic generation with large language
models for topic reduction. The method first generates an initial set of topics
and constructs a representation for each. These representations are then
provided as input to the language model, which iteratively identifies and
merges semantically similar topics. We evaluate the approach across three
Twitter/X datasets and four different language models. Our method outperforms
the baseline approach in enhancing topic diversity and, in many cases,
coherence, with some sensitivity to dataset characteristics and initial
parameter selection.
\\ ( https://arxiv.org/abs/2509.19365 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19368
Date: Fri, 19 Sep 2025 04:51:41 GMT   (490kb)

Title: Pipeline Parallelism is All You Need for Optimized Early-Exit Based
  Self-Speculative Decoding
Authors: Ruanjun Li, Ziheng Liu, Yuanming Shi, Jiawei Shao, Chi Zhang, Xuelong
  Li
Categories: cs.CL cs.AI
Comments: 17 pages, 7 figures
\\
  Large language models (LLMs) deliver impressive generation quality, but incur
very high inference cost because each output token is generated
auto-regressively through all model layers. Early-exit based self-speculative
decoding (EESD) has emerged to mitigate this cost. However, in practice, many
approaches struggle to achieve the expected acceleration in such
draft-then-verify paradigm even with a well-aligned early-exit head and
selected exit position. Our analysis reveals that EESD only pays off when the
vast majority of draft tokens are accepted by the LLM. Otherwise, the draft
cost may overcome the acceleration gain and lead to a negative speedup. To
mitigate this, we propose Pipeline-Parallel Self-Speculative Decoding (PPSD)
that fully pipelines the draft and verification work so that no effort is
wasted on failed predictions. It has two key innovations. We configure the
model layers as a pipeline in which early-exit (draft) computations and
remaining-layer (verification) computations overlap. We interleave drafting and
verification per token. While the LLM is verifying the current token in its
final layers, the early-exit path simultaneously drafts the next token. Such a
verify-while-draft scheme keeps all units busy and validates tokens on-the-fly
analogous to pipelining the speculation and verification stages. Empirical
results confirm that PPSD achieves state-of-the-art acceleration in
self-speculative LLM inference. On diverse benchmarks, PPSD achieves speedup
ratios in the range of 2.01x~3.81x, which gains almost the optimal acceleration
at the fixed acceptance rate and exit position, showcasing its advancement in
providing efficient self-speculation.
\\ ( https://arxiv.org/abs/2509.19368 ,  490kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19369
Date: Fri, 19 Sep 2025 06:25:23 GMT   (517kb)

Title: SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use
Authors: Changhyun Jeon, Jinhee Park, Jungwoo Choi, Keonwoo Kim, Jisu Kim,
  Minji Hong
Categories: cs.CL cs.AI
\\
  We propose a small-scale language model (SLM) based agent architecture,
Planner-Caller-Generator (P-C-G), optimized for Korean tool use. P-C-G
separates planning, calling, and generation by role: the Planner produces an
initial batch plan with limited on-demand replanning; the Caller returns a
normalized call object after joint schema-value validation; and the Generator
integrates tool outputs to produce the final answer. We apply a Korean-first
value policy to reduce execution failures caused by frequent Korean-to-English
code switching in Korean settings. Evaluation assumes Korean queries and Korean
tool/parameter specifications; it covers single-chain, multi-chain,
missing-parameters, and missing-functions scenarios, and is conducted via an
LLM-as-a-Judge protocol averaged over five runs under a unified I/O interface.
Results show that P-C-G delivers competitive tool-use accuracy and end-to-end
quality while reducing tokens and maintaining acceptable latency, indicating
that role-specialized SLMs are a cost-effective alternative for Korean tool-use
agents.
\\ ( https://arxiv.org/abs/2509.19369 ,  517kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19370
Date: Fri, 19 Sep 2025 07:20:53 GMT   (84kb)

Title: Meow: End-to-End Outline Writing for Automatic Academic Survey
Authors: Zhaoyu Ma, Yuan Shan, Jiahao Zhao, Nan Xu, Lei Wang
Categories: cs.CL cs.AI
\\
  As academic paper publication numbers grow exponentially, conducting in-depth
surveys with LLMs automatically has become an inevitable trend. Outline
writing, which aims to systematically organize related works, is critical for
automated survey generation. Yet existing automatic survey methods treat
outline writing as mere workflow steps in the overall pipeline. Such
template-based workflows produce outlines that lack in-depth understanding of
the survey topic and fine-grained styles. To address these limitations, we
propose Meow, the first metadata-driven outline writing framework that produces
organized and faithful outlines efficiently. Specifically, we first formulate
outline writing as an end-to-end task that generates hierarchical structured
outlines from paper metadata. We then curate a high-quality dataset of surveys
from arXiv, bioRxiv, and medRxiv, and establish systematic evaluation metrics
for outline quality assessment. Finally, we employ a two-stage training
approach combining supervised fine-tuning and reinforcement learning. Our 8B
reasoning model demonstrates strong performance with high structural fidelity
and stylistic coherence.
\\ ( https://arxiv.org/abs/2509.19370 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19371
Date: Fri, 19 Sep 2025 07:46:10 GMT   (311kb)

Title: How to inject knowledge efficiently? Knowledge Infusion Scaling Law for
  Pre-training Large Language Models
Authors: Kangtao Lv, Haibin Chen, Yujin Yuan, Langming Liu, Shilei Liu, Yongwei
  Wang, Wenbo Su, Bo Zheng
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) have attracted significant attention due to
their impressive general capabilities across diverse downstream tasks. However,
without domain-specific optimization, they often underperform on specialized
knowledge benchmarks and even produce hallucination. Recent studies show that
strategically infusing domain knowledge during pretraining can substantially
improve downstream performance. A critical challenge lies in balancing this
infusion trade-off: injecting too little domain-specific data yields
insufficient specialization, whereas excessive infusion triggers catastrophic
forgetting of previously acquired knowledge. In this work, we focus on the
phenomenon of memory collapse induced by over-infusion. Through systematic
experiments, we make two key observations, i.e. 1) Critical collapse point:
each model exhibits a threshold beyond which its knowledge retention
capabilities sharply degrade. 2) Scale correlation: these collapse points scale
consistently with the model's size. Building on these insights, we propose a
knowledge infusion scaling law that predicts the optimal amount of domain
knowledge to inject into large LLMs by analyzing their smaller counterparts.
Extensive experiments across different model sizes and pertaining token budgets
validate both the effectiveness and generalizability of our scaling law.
\\ ( https://arxiv.org/abs/2509.19371 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19476
Date: Tue, 23 Sep 2025 18:37:32 GMT   (7847kb)

Title: A Pipeline to Assess Merging Methods via Behavior and Internals
Authors: Yutaro Sigris and Andreas Waldis
Categories: cs.CL
Comments: BlackboxNLP
\\
  Merging methods combine the weights of multiple language models (LMs) to
leverage their capacities, such as for domain adaptation. While existing
studies investigate merged models from a solely behavioral perspective, we
offer the first comprehensive view by assessing and connecting their behavior
and internals. We present a novel evaluation pipeline that first merges
multiple parent LMs, and then evaluates the merged models in comparison to the
initial ones based on their behavior on downstream tasks, like MMLU, and the
internal encoded linguistic competence. We showcase this pipeline by assessing
the merging of instruction fine-tuned with math- and code-adapted LMs from the
Qwen2.5 family. Our results show that merging methods impacts behavior and
internals differently. While the performance of merged models is typically
between that of the two parent models, their encoded information about
linguistic phenomena, particularly in morphology and syntax, can surpass the
parent models. Moreover, we find weak ranking correlation between this behavior
and internal evaluation. With our pipeline and initial results, we emphasize
the need for more comprehensive evaluations of model merging methods to gain a
faithful understanding of their capabilities and reliability, beyond potential
superficial behavioral advances.
\\ ( https://arxiv.org/abs/2509.19476 ,  7847kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19540
Date: Tue, 23 Sep 2025 20:09:32 GMT   (24kb)

Title: Do LLMs Encode Frame Semantics? Evidence from Frame Identification
Authors: Jayanth Krishna Chundru, Rudrashis Poddar, Jie Cao, Tianyu Jiang
Categories: cs.CL
\\
  We investigate whether large language models encode latent knowledge of frame
semantics, focusing on frame identification, a core challenge in frame semantic
parsing that involves selecting the appropriate semantic frame for a target
word in context. Using the FrameNet lexical resource, we evaluate models under
prompt-based inference and observe that they can perform frame identification
effectively even without explicit supervision. To assess the impact of
task-specific training, we fine-tune the model on FrameNet data, which
substantially improves in-domain accuracy while generalizing well to
out-of-domain benchmarks. Further analysis shows that the models can generate
semantically coherent frame definitions, highlighting the model's internalized
understanding of frame semantics.
\\ ( https://arxiv.org/abs/2509.19540 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19557
Date: Tue, 23 Sep 2025 20:29:10 GMT   (1973kb)

Title: Confidence Calibration in Large Language Model-Based Entity Matching
Authors: Iris Kamsteeg, Juan Cardenas-Cartagena, Floris van Beers, Gineke ten
  Holt, Tsegaye Misikir Tashu, Matias Valdenegro-Toro
Categories: cs.CL cs.LG
Comments: 9 pages, 2 figures. UncertaiNLP 2025 Workshop @ EMNLP Camera Ready
\\
  This research aims to explore the intersection of Large Language Models and
confidence calibration in Entity Matching. To this end, we perform an empirical
study to compare baseline RoBERTa confidences for an Entity Matching task
against confidences that are calibrated using Temperature Scaling, Monte Carlo
Dropout and Ensembles. We use the Abt-Buy, DBLP-ACM, iTunes-Amazon and Company
datasets. The findings indicate that the proposed modified RoBERTa model
exhibits a slight overconfidence, with Expected Calibration Error scores
ranging from 0.0043 to 0.0552 across datasets. We find that this overconfidence
can be mitigated using Temperature Scaling, reducing Expected Calibration Error
scores by up to 23.83%.
\\ ( https://arxiv.org/abs/2509.19557 ,  1973kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19563
Date: Tue, 23 Sep 2025 20:43:50 GMT   (7986kb)

Title: Uncertainty in Semantic Language Modeling with PIXELS
Authors: Stefania Radu, Marco Zullich, Matias Valdenegro-Toro
Categories: cs.CL cs.LG
Comments: 9 pages, 6 figures, UncertaiNLP 2025 Workshop @ EMNLP Camera Ready
\\
  Pixel-based language models aim to solve the vocabulary bottleneck problem in
language modeling, but the challenge of uncertainty quantification remains
open. The novelty of this work consists of analysing uncertainty and confidence
in pixel-based language models across 18 languages and 7 scripts, all part of 3
semantically challenging tasks. This is achieved through several methods such
as Monte Carlo Dropout, Transformer Attention, and Ensemble Learning. The
results suggest that pixel-based models underestimate uncertainty when
reconstructing patches. The uncertainty is also influenced by the script, with
Latin languages displaying lower uncertainty. The findings on ensemble learning
show better performance when applying hyperparameter tuning during the named
entity recognition and question-answering tasks across 16 languages.
\\ ( https://arxiv.org/abs/2509.19563 ,  7986kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19567
Date: Tue, 23 Sep 2025 20:47:15 GMT   (546kb)

Title: Retrieval Augmented Generation based context discovery for ASR
Authors: Dimitrios Siskos, Stavros Papadopoulos, Pablo Peso Parada, Jisi Zhang,
  Karthikeyan Saravanan, Anastasios Drosou
Categories: cs.CL eess.AS
Comments: Accepted at EMNLP 2025
\\
  This work investigates retrieval augmented generation as an efficient
strategy for automatic context discovery in context-aware Automatic Speech
Recognition (ASR) system, in order to improve transcription accuracy in the
presence of rare or out-of-vocabulary terms. However, identifying the right
context automatically remains an open challenge. This work proposes an
efficient embedding-based retrieval approach for automatic context discovery in
ASR. To contextualize its effectiveness, two alternatives based on large
language models (LLMs) are also evaluated: (1) large language model (LLM)-based
context generation via prompting, and (2) post-recognition transcript
correction using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech
demonstrate that the proposed approach reduces WER by up to 17% (percentage
difference) relative to using no-context, while the oracle context results in a
reduction of up to 24.1%.
\\ ( https://arxiv.org/abs/2509.19567 ,  546kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19569
Date: Tue, 23 Sep 2025 20:51:51 GMT   (113kb)

Title: ExPe: Exact Positional Encodings for Generative Transformer Models with
  Extrapolating Capabilities
Authors: Aleksis Datseris, Sylvia Vassileva, Ivan Koychev, and Svetla Boytcheva
Categories: cs.CL
\\
  This paper introduces a novel approach to position embeddings in transformer
models, named "Exact Positional Embeddings" (ExPE). An absolute positional
embedding method that can extrapolate to sequences of lengths longer than the
ones it was trained on. Traditional transformer models rely on absolute or
relative position embeddings to incorporate positional information into token
embeddings, which often struggle with extrapolation to sequences longer than
those seen during training. Our proposed method utilizes a novel embedding
strategy that encodes exact positional information by overriding specific
dimensions of the embedding vectors, thereby enabling a more precise
representation of token positions. The proposed approach not only maintains the
integrity of the original embeddings but also enhances the model's ability to
generalize to more extended sequences. In causal language modeling, our ExPE
embeddings significantly reduce perplexity compared to rotary and sinusoidal
embeddings, when tested on sequences longer than those used in training.
\\ ( https://arxiv.org/abs/2509.19569 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19580
Date: Tue, 23 Sep 2025 21:09:24 GMT   (11411kb)

Title: LLMs4All: A Review on Large Language Models for Research and
  Applications in Academic Disciplines
Authors: Yanfang (Fanny) Ye, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Yiyang Li,
  Shifu Hou, Weixiang Sun, Kaiwen Shi, Yijun Ma, Wei Song, Ahmed Abbasi, Ying
  Cheng, Jane Cleland-Huang, Steven Corcelli, Patricia Culligan, Robert
  Goulding, Ming Hu, Ting Hua, John Lalor, Fang Liu, Tengfei Luo, Ed Maginn,
  Nuno Moniz, Jason Rohr, Brett Savoie, Daniel Slate, Tom Stapleford, Matthew
  Webber, Olaf Wiest, Johnny Zhang, Nitesh Chawla
Categories: cs.CL
\\
  Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view
of the world. For example, Large Language Models (LLMs) based applications such
as ChatGPT have shown the capability of generating human-like conversation on
extensive topics. Due to the impressive performance on a variety of
language-related tasks (e.g., open-domain question answering, translation, and
document summarization), one can envision the far-reaching impacts that can be
brought by the LLMs with broader real-world applications (e.g., customer
service, education and accessibility, and scientific discovery). Inspired by
their success, this paper will offer an overview of state-of-the-art LLMs and
their integration into a wide range of academic disciplines, including: (1)
arts, letters, and law (e.g., history, philosophy, political science, arts and
architecture, law), (2) economics and business (e.g., finance, economics,
accounting, marketing), and (3) science and engineering (e.g., mathematics,
physics and mechanical engineering, chemistry and chemical engineering, life
sciences and bioengineering, earth sciences and civil engineering, computer
science and electrical engineering). Integrating humanity and technology, in
this paper, we will explore how LLMs are shaping research and practice in these
fields, while also discussing key limitations, open challenges, and future
directions in the era of generative AI. The review of how LLMs are engaged
across disciplines-along with key observations and insights-can help
researchers and practitioners interested in exploiting LLMs to advance their
works in diverse real-world applications.
\\ ( https://arxiv.org/abs/2509.19580 ,  11411kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19593
Date: Tue, 23 Sep 2025 21:31:14 GMT   (250kb)

Title: GuessingGame: Measuring the Informativeness of Open-Ended Questions in
  Large Language Models
Authors: Dylan Hutson, Daniel Vennemeyer, Aneesh Deshmukh, Justin Zhan, Tianyu
  Jiang
Categories: cs.CL cs.AI
Comments: EMNLP 2025, 17 pages, 2 figures
\\
  We introduce GuessingGame, a protocol for evaluating large language models
(LLMs) as strategic question-askers in open-ended, open-domain settings. A
Guesser LLM identifies a hidden object by posing free-form questions to an
Oracle without predefined choices or candidate lists. To measure question
quality, we propose two information gain (IG) metrics: a Bayesian method that
tracks belief updates over semantic concepts using LLM-scored relevance, and an
entropy-based method that filters candidates via ConceptNet. Both metrics are
model-agnostic and support post hoc analysis. Across 858 games with multiple
models and prompting strategies, higher IG strongly predicts efficiency: a
one-standard-deviation IG increase reduces expected game length by 43\%.
Prompting constraints guided by IG, such as enforcing question diversity,
enable weaker models to significantly improve performance. These results show
that question-asking in LLMs is both measurable and improvable, and crucial for
interactive reasoning.
\\ ( https://arxiv.org/abs/2509.19593 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19595
Date: Tue, 23 Sep 2025 21:34:57 GMT   (16685kb)

Title: Anatomy of a Feeling: Narrating Embodied Emotions via Large
  Vision-Language Models
Authors: Mohammad Saim, Phan Anh Duong, Cat Luong, Aniket Bhanderi, Tianyu
  Jiang
Categories: cs.CL cs.CV
\\
  The embodiment of emotional reactions from body parts contains rich
information about our affective experiences. We propose a framework that
utilizes state-of-the-art large vision-language models (LVLMs) to generate
Embodied LVLM Emotion Narratives (ELENA). These are well-defined, multi-layered
text outputs, primarily comprising descriptions that focus on the salient body
parts involved in emotional reactions. We also employ attention maps and
observe that contemporary models exhibit a persistent bias towards the facial
region. Despite this limitation, we observe that our employed framework can
effectively recognize embodied emotions in face-masked images, outperforming
baselines without any fine-tuning. ELENA opens a new trajectory for embodied
emotion analysis across the modality of vision and enriches modeling in an
affect-aware setting.
\\ ( https://arxiv.org/abs/2509.19595 ,  16685kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19611
Date: Tue, 23 Sep 2025 22:01:52 GMT   (1295kb)

Title: Evaluating Language Translation Models by Playing Telephone
Authors: Syeda Jannatus Saba, Steven Skiena
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Main Conference as a long paper
\\
  Our ability to efficiently and accurately evaluate the quality of machine
translation systems has been outrun by the effectiveness of current language
models--which limits the potential for further improving these models on more
challenging tasks like long-form and literary translation. We propose an
unsupervised method to generate training data for translation evaluation over
different document lengths and application domains by repeated rounds of
translation between source and target languages. We evaluate evaluation systems
trained on texts mechanically generated using both model rotation and language
translation approaches, demonstrating improved performance over a popular
translation evaluation system (xCOMET) on two different tasks: (i) scoring the
quality of a given translation against a human reference and (ii) selecting
which of two translations is generationally closer to an original source
document.
\\ ( https://arxiv.org/abs/2509.19611 ,  1295kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19640
Date: Tue, 23 Sep 2025 23:10:18 GMT   (11430kb)

Title: AutoSpec: An Agentic Framework for Automatically Drafting Patent
  Specification
Authors: Ryan Shea and Zhou Yu
Categories: cs.CL
Comments: EMNLP Findings 2025
\\
  Patents play a critical role in driving technological innovation by granting
inventors exclusive rights to their inventions. However the process of drafting
a patent application is often expensive and time-consuming, making it a prime
candidate for automation. Despite recent advancements in language models,
several challenges hinder the development of robust automated patent drafting
systems. First, the information within a patent application is highly
confidential, which often prevents the use of closed-source LLMs for automating
this task. Second, the process of drafting a patent application is difficult
for even the most advanced language models due to their long context, technical
writing style, and specialized domain knowledge. To address these challenges,
we introduce AutoSpec, a secure, agentic framework for Automatically drafting
patent Specification. Our approach decomposes the drafting process into a
sequence of manageable subtasks, each solvable by smaller, open-source language
models enhanced with custom tools tailored for drafting patent specification.
To assess our system, we design a novel evaluation protocol in collaboration
with experienced patent attorneys. Our automatic and expert evaluations show
that AutoSpec outperforms existing baselines on a patent drafting task.
\\ ( https://arxiv.org/abs/2509.19640 ,  11430kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19657
Date: Wed, 24 Sep 2025 00:25:19 GMT   (6883kb)

Title: Large Language Models for Pedestrian Safety: An Application to
  Predicting Driver Yielding Behavior at Unsignalized Intersections
Authors: Yicheng Yang, Zixian Li, Jean Paul Bizimana, Niaz Zafri, Yongfeng
  Dong, Tianyi Li
Categories: cs.CL cs.AI cs.SI
\\
  Pedestrian safety is a critical component of urban mobility and is strongly
influenced by the interactions between pedestrian decision-making and driver
yielding behavior at crosswalks. Modeling driver--pedestrian interactions at
intersections requires accurately capturing the complexity of these behaviors.
Traditional machine learning models often struggle to capture the nuanced and
context-dependent reasoning required for these multifactorial interactions, due
to their reliance on fixed feature representations and limited
interpretability. In contrast, large language models (LLMs) are suited for
extracting patterns from heterogeneous traffic data, enabling accurate modeling
of driver-pedestrian interactions. Therefore, this paper leverages multimodal
LLMs through a novel prompt design that incorporates domain-specific knowledge,
structured reasoning, and few-shot prompting, enabling interpretable and
context-aware inference of driver yielding behavior, as an example application
of modeling pedestrian--driver interaction. We benchmarked state-of-the-art
LLMs against traditional classifiers, finding that GPT-4o consistently achieves
the highest accuracy and recall, while Deepseek-V3 excels in precision. These
findings highlight the critical trade-offs between model performance and
computational efficiency, offering practical guidance for deploying LLMs in
real-world pedestrian safety systems.
\\ ( https://arxiv.org/abs/2509.19657 ,  6883kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19695
Date: Wed, 24 Sep 2025 02:06:26 GMT   (472kb)

Title: DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy
  with Cognitive Dual-Systems
Authors: Shuyu Zhang, Yifan Wei, Jialuo Yuan, Xinru Wang, Yanmin Zhu, Bin Li
Categories: cs.CL cs.AI cs.IR
\\
  Task oriented dialog systems often rely on static exploration strategies that
do not adapt to dynamic dialog contexts, leading to inefficient exploration and
suboptimal performance. We propose DyBBT, a novel dialog policy learning
framework that formalizes the exploration challenge through a structured
cognitive state space capturing dialog progression, user uncertainty, and slot
dependency. DyBBT proposes a bandit inspired meta-controller that dynamically
switches between a fast intuitive inference (System 1) and a slow deliberative
reasoner (System 2) based on real-time cognitive states and visitation counts.
Extensive experiments on single- and multi-domain benchmarks show that DyBBT
achieves state-of-the-art performance in success rate, efficiency, and
generalization, with human evaluations confirming its decisions are well
aligned with expert judgment. Code is available at
https://github.com/carsonz/DyBBT.
\\ ( https://arxiv.org/abs/2509.19695 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19727
Date: Wed, 24 Sep 2025 03:11:28 GMT   (13222kb)

Title: Personality Vector: Modulating Personality of Large Language Models by
  Model Merging
Authors: Seungjong Sun, Seo Yeon Baek, Jang Hyun Kim
Categories: cs.CL
Comments: EMNLP 2025
\\
  Driven by the demand for personalized AI systems, there is growing interest
in aligning the behavior of large language models (LLMs) with human traits such
as personality. Previous attempts to induce personality in LLMs have shown
promising results, but they struggle to capture the continuous and
multidimensional nature of human traits. In this work, we propose a novel
method for personality modulation in LLMs via model merging. Specifically, we
construct personality vectors by subtracting the weights of a pre-trained model
from those of the fine-tuned model on a given personality trait. By merging
personality vectors, we enable LLMs to exhibit desired personality traits
without additional training. Extensive experiments show that personality
vectors enable continuous control over trait intensity and support the
composition of multiple traits. Furthermore, personality vectors transfer
across diverse downstream models, suggesting that they encode generalizable
representations of personality. Our code is available at here.
\\ ( https://arxiv.org/abs/2509.19727 ,  13222kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19742
Date: Wed, 24 Sep 2025 03:44:16 GMT   (672kb)

Title: HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical
  Collaborative LoRA for Zero-Shot DST
Authors: Shuyu Zhang, Yifan Wei, Xinru Wang, Yanmin Zhu, Yangfan He, Yixuan
  Weng, Bin Li
Categories: cs.CL cs.AI cs.IR
\\
  Zero-shot Dialog State Tracking (zs-DST) is essential for enabling
Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly
data annotation. A central challenge lies in the semantic misalignment between
dynamic dialog contexts and static prompts, leading to inflexible cross-layer
coordination, domain interference, and catastrophic forgetting. To tackle this,
we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a
framework that enhances zero-shot slot inference through robust prompt
alignment. It features a hierarchical LoRA architecture for dynamic
layer-specific processing (combining lower-layer heuristic grouping and
higher-layer full interaction), integrates Spectral Joint Domain-Slot
Clustering to identify transferable associations (feeding an Adaptive Linear
Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization
(SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain
datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving
SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.
\\ ( https://arxiv.org/abs/2509.19742 ,  672kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19745
Date: Wed, 24 Sep 2025 03:54:14 GMT   (1239kb)

Title: PART: Progressive Alignment Representation Training for Multilingual
  Speech-To-Text with LLMs
Authors: Pei Zhang, Andong Chen, Xi Chen, Baosong Yang, Derek F. Wong, Fei
  Huang
Categories: cs.CL cs.SD
\\
  Large language models (LLMs) have expanded from text to speech, giving rise
to Speech Large Models (SLMs) that support recognition, translation, and
synthesis. A key challenge is aligning speech and text representations, which
becomes harder in multilingual settings. Existing methods often freeze LLM
parameters and train encoders on multilingual data, but this forces
cross-language convergence and limits performance. We introduce Progressive
Alignment Representation Training (PART), a multi-stage and multi-task
framework that separates within-language from cross-language alignment. During
cross-language training, LLM parameters are dynamically activated, and
text-based tasks are later introduced to enhance multilingual understanding.
Experiments on CommonVoice 15, Fleurs, Wenetspeech, and CoVoST2 show that PART
surpasses conventional approaches, with analysis confirming its ability to
balance language-specific distinctions and cross-language generalization. These
results demonstrate PART's effectiveness and generality for multilingual speech
modality alignment.
\\ ( https://arxiv.org/abs/2509.19745 ,  1239kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19768
Date: Wed, 24 Sep 2025 05:38:45 GMT   (5092kb)

Title: CHURRO: Making History Readable with an Open-Weight Large
  Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition
Authors: Sina J. Semnani, Han Zhang, Xinyan He, Merve Tekg\"urler, Monica S.
  Lam
Categories: cs.CL cs.CV
Comments: EMNLP 2025
\\
  Accurate text recognition for historical documents can greatly advance the
study and preservation of cultural heritage. Existing vision-language models
(VLMs), however, are designed for modern, standardized texts and are not
equipped to read the diverse languages and scripts, irregular layouts, and
frequent degradation found in historical materials.
  This paper presents CHURRO, a 3B-parameter open-weight VLM specialized for
historical text recognition. The model is trained on CHURRO-DS, the largest
historical text recognition dataset to date. CHURRO-DS unifies 155 historical
corpora comprising 99,491 pages, spanning 22 centuries of textual heritage
across 46 language clusters, including historical variants and dead languages.
  We evaluate several open-weight and closed VLMs and optical character
recognition (OCR) systems on CHURRO-DS and find that CHURRO outperforms all
other VLMs. On the CHURRO-DS test set, CHURRO achieves 82.3% (printed) and
70.1% (handwritten) normalized Levenshtein similarity, surpassing the
second-best model, Gemini 2.5 Pro, by 1.4% and 6.5%, respectively, while being
15.5 times more cost-effective.
  By releasing the model and dataset, we aim to enable community-driven
research to improve the readability of historical texts and accelerate
scholarship.
\\ ( https://arxiv.org/abs/2509.19768 ,  5092kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19770
Date: Wed, 24 Sep 2025 05:41:30 GMT   (9602kb)

Title: EnAnchored-X2X: English-Anchored Optimization for Many-to-Many
  Translation
Authors: Sen Yang, Yu Bao, Yu Lu, Jiajun Chen, Shujian Huang, Shanbo Cheng
Categories: cs.CL
Comments: Accepted to EMNLP 2025
\\
  Large language models (LLMs) have demonstrated strong machine translation
capabilities for English-centric language pairs but underperform in direct
non-English (x2x) translation. This work addresses this limitation through a
synthetic data generation framework that leverages models' established
English-to-x (en2x) capabilities. By extending English parallel corpora into
omnidirectional datasets and developing an English-referenced quality
evaluation proxy, we enable effective collection of high-quality x2x training
data. Combined with preference-based optimization, our method achieves
significant improvement across 72 x2x directions for widely used LLMs, while
generalizing to enhance en2x performance. The results demonstrate that
strategic exploitation of English-centric strengths can bootstrap comprehensive
multilingual translation capabilities in LLMs. We release codes, datasets, and
model checkpoints at https://github.com/NJUNLP/EAX
\\ ( https://arxiv.org/abs/2509.19770 ,  9602kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19775
Date: Wed, 24 Sep 2025 05:56:41 GMT   (1428kb)

Title: bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on
  LLMs
Authors: Wence Ji, Jiancan Wu, Aiying Li, Shuyi Zhang, Junkang Wu, An Zhang,
  Xiang Wang, Xiangnan He
Categories: cs.CL cs.AI cs.CR
\\
  With the rapid advancement of large language models (LLMs), their robustness
against adversarial manipulations, particularly jailbreak backdoor attacks, has
become critically important. Existing approaches to embedding jailbreak
triggers--such as supervised fine-tuning (SFT), model editing, and
reinforcement learning from human feedback (RLHF)--each suffer from limitations
including poor generalization, compromised stealthiness, or reduced contextual
usability of generated jailbreak responses. To overcome these issues, we
propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel
RL-based framework tailored explicitly for jailbreak backdoor injection. By
employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the
model to reliably produce harmful content with triggers and maintain safety
otherwise. Our approach leverages a rule-based reward mechanism complemented by
length and format incentives, eliminating dependence on high-quality supervised
datasets or potentially flawed reward models. Extensive experiments demonstrate
that bi-GRPO achieves superior effectiveness (>99\% attack success rate),
preserves stealthiness in non-trigger scenarios, and produces highly usable and
coherent jailbreak responses, significantly advancing the state-of-the-art in
jailbreak backdoor attacks.
\\ ( https://arxiv.org/abs/2509.19775 ,  1428kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19833
Date: Wed, 24 Sep 2025 07:23:44 GMT   (122kb)

Title: Polarity Detection of Sustainable Detection Goals in News Text
Authors: Andrea Cadeddua, Alessandro Chessa, Vincenzo De Leo, Gianni Fenu,
  Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino, Luca Secchi
Categories: cs.CL cs.AI cs.DL
\\
  The United Nations' Sustainable Development Goals (SDGs) provide a globally
recognised framework for addressing critical societal, environmental, and
economic challenges. Recent developments in natural language processing (NLP)
and large language models (LLMs) have facilitated the automatic classification
of textual data according to their relevance to specific SDGs. Nevertheless, in
many applications, it is equally important to determine the directionality of
this relevance; that is, to assess whether the described impact is positive,
neutral, or negative. To tackle this challenge, we propose the novel task of
SDG polarity detection, which assesses whether a text segment indicates
progress toward a specific SDG or conveys an intention to achieve such
progress. To support research in this area, we introduce SDG-POD, a benchmark
dataset designed specifically for this task, combining original and
synthetically generated data. We perform a comprehensive evaluation using six
state-of-the-art large LLMs, considering both zero-shot and fine-tuned
configurations. Our results suggest that the task remains challenging for the
current generation of LLMs. Nevertheless, some fine-tuned models, particularly
QWQ-32B, achieve good performance, especially on specific Sustainable
Development Goals such as SDG-9 (Industry, Innovation and Infrastructure),
SDG-12 (Responsible Consumption and Production), and SDG-15 (Life on Land).
Furthermore, we demonstrate that augmenting the fine-tuning dataset with
synthetically generated examples yields improved model performance on this
task. This result highlights the effectiveness of data enrichment techniques in
addressing the challenges of this resource-constrained domain. This work
advances the methodological toolkit for sustainability monitoring and provides
actionable insights into the development of efficient, high-performing polarity
detection systems.
\\ ( https://arxiv.org/abs/2509.19833 ,  122kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19834
Date: Wed, 24 Sep 2025 07:26:21 GMT   (3706kb)

Title: TianHui: A Domain-Specific Large Language Model for Diverse Traditional
  Chinese Medicine Scenarios
Authors: Ji Yin, Menglan He, Yujie Zhang, Linshuai Zhang, Tingting Ma, Ce Tian,
  Jie Wu, Lin Xu, Tao Jiang, ((1) School of Intelligent Medicine, Chengdu
  University of Traditional Chinese Medicine, Chengdu, China (2) The
  Acupuncture and Tuina School, Chengdu University of Traditional Chinese
  Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of
  Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD
  School of Intelligent Medicine Chengdu University of Traditional Chinese
  Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of
  Intelligent Medicine Chengdu University of Traditional Chinese Medicine,
  Liutai Avenue Wenjiang District Chengdu, China)
Categories: cs.CL cs.AI
Comments: 46 pages, 5 figures,3 tables
\\
  Domain-specific LLMs in TCM face limitations in research settings due to
constrained adaptability, insufficient evaluation datasets, and limited
computational resources. This study presents TianHui, a specialized TCM LLM
built through contextual data integration and domain knowledge fusion. We
constructed a large-scale TCM corpus (0.97GB unsupervised data + 611,312 QA
pairs) and employed a two-stage training strategy with QLoRA, DeepSpeed Stage
2, and Flash Attention 2. Evaluation on 12 benchmarks showed TianHui ranked
top-three in all metrics for six datasets (APQ, TCMCD, HFR, HCCA, DHPE, TLAW)
and achieved top results in the other six (TCMEE, APR, GCPMI, TCMKQA, TCMRC,
ADTG). Optimal configuration was identified as LoRA rank=128, alpha=256,
epoch=4, dropout=0.2, max length=2048. TianHui enables systematic preservation
and scalable application of TCM knowledge. All resources are open-sourced.
\\ ( https://arxiv.org/abs/2509.19834 ,  3706kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19844
Date: Wed, 24 Sep 2025 07:42:39 GMT   (883kb)

Title: Mah\={a}n\={a}ma: A Unique Testbed for Literary Entity Discovery and
  Linking
Authors: Sujoy Sarkar, Gourav Sarkar, Manoj Balaji Jagadeeshan, Jivnesh
  Sandhan, Amrith Krishna, Pawan Goyal
Categories: cs.CL
Comments: Accepted to EMNLP 2025. This is the authors' version. The official
  version will appear in the ACL Anthology
\\
  High lexical variation, ambiguous references, and long-range dependencies
make entity resolution in literary texts particularly challenging. We present
Mah\={a}n\={a}ma, the first large-scale dataset for end-to-end Entity Discovery
and Linking (EDL) in Sanskrit, a morphologically rich and under-resourced
language. Derived from the Mah\={a}bh\={a}rata, the world's longest epic, the
dataset comprises over 109K named entity mentions mapped to 5.5K unique
entities, and is aligned with an English knowledge base to support
cross-lingual linking. The complex narrative structure of Mah\={a}n\={a}ma,
coupled with extensive name variation and ambiguity, poses significant
challenges to resolution systems. Our evaluation reveals that current
coreference and entity linking models struggle when evaluated on the global
context of the test set. These results highlight the limitations of current
approaches in resolving entities within such complex discourse. Mah\=an\=ama
thus provides a unique benchmark for advancing entity resolution, especially in
literary domains.
\\ ( https://arxiv.org/abs/2509.19844 ,  883kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19858
Date: Wed, 24 Sep 2025 07:57:10 GMT   (461kb)

Title: Benchmarking Gaslighting Attacks Against Speech Large Language Models
Authors: Jinyang Wu, Bin Zhu, Xiandong Zou, Qiquan Zhang, Xu Fang, Pan Zhou
Categories: cs.CL
Comments: 5 pages, 2 figures, 3 tables
\\
  As Speech Large Language Models (Speech LLMs) become increasingly integrated
into voice-based applications, ensuring their robustness against manipulative
or adversarial input becomes critical. Although prior work has studied
adversarial attacks in text-based LLMs and vision-language models, the unique
cognitive and perceptual challenges of speech-based interaction remain
underexplored. In contrast, speech presents inherent ambiguity, continuity, and
perceptual diversity, which make adversarial attacks more difficult to detect.
In this paper, we introduce gaslighting attacks, strategically crafted prompts
designed to mislead, override, or distort model reasoning as a means to
evaluate the vulnerability of Speech LLMs. Specifically, we construct five
manipulation strategies: Anger, Cognitive Disruption, Sarcasm, Implicit, and
Professional Negation, designed to test model robustness across varied tasks.
It is worth noting that our framework captures both performance degradation and
behavioral responses, including unsolicited apologies and refusals, to diagnose
different dimensions of susceptibility. Moreover, acoustic perturbation
experiments are conducted to assess multi-modal robustness. To quantify model
vulnerability, comprehensive evaluation across 5 Speech and multi-modal LLMs on
over 10,000 test samples from 5 diverse datasets reveals an average accuracy
drop of 24.3% under the five gaslighting attacks, indicating significant
behavioral vulnerability. These findings highlight the need for more resilient
and trustworthy speech-based AI systems.
\\ ( https://arxiv.org/abs/2509.19858 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19861
Date: Wed, 24 Sep 2025 08:04:32 GMT   (373kb)

Title: SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational
  Strategies for Depression Detection
Authors: Alba Maria Marmol-Romero, Manuel Garcia-Vega, Miguel Angel
  Garcia-Cumbreras and Arturo Montejo-Raez
Categories: cs.CL
Comments: 16 pages, 10 figures, 8 tables. CLEF (Working Notes). 2025
Journal-ref: CEUR Workshop Proceedings 2025, vol. 4038, pp. 1620-1635
\\
  This paper describes the participation of the SINAI-UJA team in the
eRisk@CLEF 2025 lab. Specifically, we addressed two of the proposed tasks: (i)
Task 2: Contextualized Early Detection of Depression, and (ii) Pilot Task:
Conversational Depression Detection via LLMs. Our approach for Task 2 combines
an extensive preprocessing pipeline with the use of several transformer-based
models, such as RoBERTa Base or MentalRoBERTA Large, to capture the contextual
and sequential nature of multi-user conversations. For the Pilot Task, we
designed a set of conversational strategies to interact with LLM-powered
personas, focusing on maximizing information gain within a limited number of
dialogue turns. In Task 2, our system ranked 8th out of 12 participating teams
based on F1 score. However, a deeper analysis revealed that our models were
among the fastest in issuing early predictions, which is a critical factor in
real-world deployment scenarios. This highlights the trade-off between early
detection and classification accuracy, suggesting potential avenues for
optimizing both jointly in future work. In the Pilot Task, we achieved 1st
place out of 5 teams, obtaining the best overall performance across all
evaluation metrics: DCHR, ADODL and ASHR. Our success in this task demonstrates
the effectiveness of structured conversational design when combined with
powerful language models, reinforcing the feasibility of deploying LLMs in
sensitive mental health assessment contexts.
\\ ( https://arxiv.org/abs/2509.19861 ,  373kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19866
Date: Wed, 24 Sep 2025 08:13:44 GMT   (128kb)

Title: SwissGPC v1.0 -- The Swiss German Podcasts Corpus
Authors: Samuel Stucki, Mark Cieliebak, Jan Deriu
Categories: cs.CL
\\
  We present SwissGPC v1.0, the first mid-to-large-scale corpus of spontaneous
Swiss German speech, developed to support research in ASR, TTS, dialect
identification, and related fields. The dataset consists of links to talk shows
and podcasts hosted on Schweizer Radio und Fernsehen and YouTube, which contain
approximately 5400 hours of raw audio. After segmentation and weak annotation,
nearly 5000 hours of speech were retained, covering the seven major Swiss
German dialect regions alongside Standard German. We describe the corpus
construction methodology, including an automated annotation pipeline, and
provide statistics on dialect distribution, token counts, and segmentation
characteristics. Unlike existing Swiss German speech corpora, which primarily
feature controlled speech, this corpus captures natural, spontaneous
conversations, making it a valuable resource for real-world speech
applications.
\\ ( https://arxiv.org/abs/2509.19866 ,  128kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19880
Date: Wed, 24 Sep 2025 08:32:45 GMT   (1142kb)

Title: Do Before You Judge: Self-Reference as a Pathway to Better LLM
  Evaluation
Authors: Wei-Hsiang Lin, Sheng-Lun Wei, Hen-Hsen Huang, Hsin-Hsi Chen
Categories: cs.CL cs.AI
Comments: Accepted as a long findings paper at EMNLP 2025
\\
  LLM-as-Judge frameworks are increasingly popular for AI evaluation, yet
research findings on the relationship between models' generation and judgment
abilities remain inconsistent. We investigate this relationship through
systematic dataset- and instance-level analyses across 11 models and 21 diverse
tasks. Despite both capabilities relying on the same underlying knowledge, our
analyses reveal they are only weakly correlated, primarily due to LLMs'
sensitivity to the responses being judged. To address this, we propose a
self-reference-guided evaluation strategy that leverages a model's own answers
as references. This approach significantly strengthens the correlation between
generation and judgment abilities, offering a practical path to align these
skills and providing a reliable proxy for model selection in evaluation tasks.
\\ ( https://arxiv.org/abs/2509.19880 ,  1142kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19893
Date: Wed, 24 Sep 2025 08:44:12 GMT   (1031kb)

Title: Future Policy Aware Preference Learning for Mathematical Reasoning
Authors: Minjae Oh, Yunho Choi, Dongmin Choi, Yohan Jo
Categories: cs.CL
Comments: 9 pages
\\
  Preference learning methods such as Direct Preference Optimization (DPO) have
become standard for Large Language Model (LLM) post-training, yet they are
often ineffective for mathematical reasoning. A key challenge is the large
token overlap between preferred and dispreferred trajectories; lowering the
probability of dispreferred trajectories also reduces the probability of shared
useful tokens, leading to over-penalization and overall performance collapse.
As a mitigation, existing algorithms include the probability of a trajectory
under the current policy as a regularization term, which decreases the effect
of the gradient when the probability is low. However, by the time this effect
takes hold, useful tokens may have already been over-penalized as the model has
begun to degrade. To address this, we propose Future Policy Aware (FPA)
preference learning, which replaces the current policy with a future policy in
the regularization term. This future policy is estimated via lightweight,
logit-space extrapolation from a reference model toward the current model. FPA
enables safer training by preemptively regularizing potentially problematic
gradients. We apply FPA to DPO, RPO, and SimPER and evaluate them on the MATH
and GSM8K benchmarks. FPA yields consistent performance gains, with the largest
improvements observed with SimPER, achieving gains of up to 5.75%. We
demonstrate that FPA provides proactive regularization while preserving the
probability of shared, useful mathematical tokens, and enables longer,
degradation-free training with negligible computational overhead. We will
release our code publicly upon publication.
\\ ( https://arxiv.org/abs/2509.19893 ,  1031kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19902
Date: Wed, 24 Sep 2025 08:56:32 GMT   (263kb)

Title: WEST: LLM based Speech Toolkit for Speech Understanding, Generation, and
  Interaction
Authors: Binbin Zhang, Chengdong Liang, Shuai Wang, Xuelong Geng, Zhao Guo,
  Haoyu Li, Hao Yin, Xipeng Yang, Pengshen Zhang, Changwei Ma, Lei Xie
Categories: cs.CL
\\
  In this paper, we present WEST(WE Speech Toolkit), a speech toolkit based on
a large language model (LLM) for speech understanding, generation, and
interaction. There are three key features of WEST: 1) Fully LLM-based: Standing
on the shoulders of giants by reusing mature architectures, ecosystems (e.g.,
Hugging Face), and methods (e.g., sequence packing) from large models. 2)
Full-stack: Supports tasks such as recognition, synthesis, understanding,
dialogue, and multimodal capabilities, with extensibility to incorporate
open-source models. 3) Simple and Stupid: A simple and stupid speech toolkit
that everyone can Touch. In addition, WEST provides two types of recipes,
models, and experimental results. The first is entirely based on open-source
models and open-source data, allowing users to fully reproduce the experiments
in this paper and serving as a verification system or minimal system baseline.
The second is trained on massive data, offering superior performance so the
user can directly apply it out of the box. WEST is publicly avilable at
https://github.com/wenet-e2e/west/
\\ ( https://arxiv.org/abs/2509.19902 ,  263kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19941
Date: Wed, 24 Sep 2025 09:48:26 GMT   (871kb)

Title: CorIL: Towards Enriching Indian Language to Indian Language Parallel
  Corpora and Machine Translation Systems
Authors: Soham Bhattacharjee, Mukund K Roy, Yathish Poojary, Bhargav Dave,
  Mihir Raj, Vandan Mujadia, Baban Gain, Pruthwik Mishra, Arafat Ahsan,
  Parameswari Krishnamurthy, Ashwath Rao, Gurpreet Singh Josan, Preeti Dubey,
  Aadil Amin Kak, Anna Rao Kulkarni, Narendra VG, Sunita Arora, Rakesh
  Balbantray, Prasenjit Majumdar, Karunesh K Arora, Asif Ekbal, Dipti Mishra
  Sharma
Categories: cs.CL cs.AI
\\
  India's linguistic landscape is one of the most diverse in the world,
comprising over 120 major languages and approximately 1,600 additional
languages, with 22 officially recognized as scheduled languages in the Indian
Constitution. Despite recent progress in multilingual neural machine
translation (NMT), high-quality parallel corpora for Indian languages remain
scarce, especially across varied domains. In this paper, we introduce a
large-scale, high-quality annotated parallel corpus covering 11 of these
languages : English, Telugu, Hindi, Punjabi, Odia, Kashmiri, Sindhi, Dogri,
Kannada, Urdu, and Gujarati comprising a total of 772,000 bi-text sentence
pairs. The dataset is carefully curated and systematically categorized into
three key domains: Government, Health, and General, to enable domain-aware
machine translation research and facilitate effective domain adaptation. To
demonstrate the utility of CorIL and establish strong benchmarks for future
research, we fine-tune and evaluate several state-of-the-art NMT models,
including IndicTrans2, NLLB, and BhashaVerse. Our analysis reveals important
performance trends and highlights the corpus's value in probing model
capabilities. For instance, the results show distinct performance patterns
based on language script, with massively multilingual models showing an
advantage on Perso-Arabic scripts (Urdu, Sindhi) while other models excel on
Indic scripts. This paper provides a detailed domain-wise performance analysis,
offering insights into domain sensitivity and cross-script transfer learning.
By publicly releasing CorIL, we aim to significantly improve the availability
of high-quality training data for Indian languages and provide a valuable
resource for the machine translation research community.
\\ ( https://arxiv.org/abs/2509.19941 ,  871kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20004
Date: Wed, 24 Sep 2025 11:24:49 GMT   (110kb)

Title: The Knowledge-Behaviour Disconnect in LLM-based Chatbots
Authors: Jan Broersen
Categories: cs.CL cs.AI
\\
  Large language model-based artificial conversational agents (like ChatGPT)
give answers to all kinds of questions, and often enough these answers are
correct. Just on the basis of that capacity alone, we may attribute knowledge
to them. But do these models use this knowledge as a basis for their own
conversational behaviour? I argue this is not the case, and I will refer to
this failure as a `disconnect'. I further argue this disconnect is fundamental
in the sense that with more data and more training of the LLM on which a
conversational chatbot is based, it will not disappear. The reason is, as I
will claim, that the core technique used to train LLMs does not allow for the
establishment of the connection we are after. The disconnect reflects a
fundamental limitation on the capacities of LLMs, and explains the source of
hallucinations. I will furthermore consider the ethical version of the
disconnect (ethical conversational knowledge not being aligned with ethical
conversational behaviour), since in this domain researchers have come up with
several additional techniques to influence a chatbot's behaviour. I will
discuss how these techniques do nothing to solve the disconnect and can make it
worse.
\\ ( https://arxiv.org/abs/2509.20004 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20007
Date: Wed, 24 Sep 2025 11:27:07 GMT   (254kb)

Title: DiffNator: Generating Structured Explanations of Time-Series Differences
Authors: Kota Dohi and Tomoya Nishida and Harsh Purohit and Takashi Endo and
  Yohei Kawaguchi
Categories: cs.CL
\\
  In many IoT applications, the central interest lies not in individual sensor
signals but in their differences, yet interpreting such differences requires
expert knowledge. We propose DiffNator, a framework for structured explanations
of differences between two time series. We first design a JSON schema that
captures the essential properties of such differences. Using the Time-series
Observations of Real-world IoT (TORI) dataset, we generate paired sequences and
train a model that combine a time-series encoder with a frozen LLM to output
JSON-formatted explanations. Experimental results show that DiffNator generates
accurate difference explanations and substantially outperforms both a visual
question answering (VQA) baseline and a retrieval method using a pre-trained
time-series encoder.
\\ ( https://arxiv.org/abs/2509.20007 ,  254kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20045
Date: Wed, 24 Sep 2025 12:13:53 GMT   (1316kb)

Title: Tokenization and Representation Biases in Multilingual Models on
  Dialectal NLP Tasks
Authors: Vani Kanjirangat, Tanja Samard\v{z}i\'c, Ljiljana Dolamic, Fabio
  Rinaldi
Categories: cs.CL cs.AI
Comments: Accepted in EMNLP-2025 Main conference
\\
  Dialectal data are characterized by linguistic variation that appears small
to humans but has a significant impact on the performance of models. This
dialect gap has been related to various factors (e.g., data size, economic and
social factors) whose impact, however, turns out to be inconsistent. In this
work, we investigate factors impacting the model performance more directly: we
correlate Tokenization Parity (TP) and Information Parity (IP), as measures of
representational biases in pre-trained multilingual models, with the downstream
performance. We compare state-of-the-art decoder-only LLMs with encoder-based
models across three tasks: dialect classification, topic classification, and
extractive question answering, controlling for varying scripts (Latin vs.
non-Latin) and resource availability (high vs. low). Our analysis reveals that
TP is a better predictor of the performance on tasks reliant on syntactic and
morphological cues (e.g., extractive QA), while IP better predicts performance
in semantic tasks (e.g., topic classification). Complementary analyses,
including tokenizer behavior, vocabulary coverage, and qualitative insights,
reveal that the language support claims of LLMs often might mask deeper
mismatches at the script or token level.
\\ ( https://arxiv.org/abs/2509.20045 ,  1316kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20057
Date: Wed, 24 Sep 2025 12:26:33 GMT   (3491kb)

Title: Responsible AI Technical Report
Authors: KT: Soonmin Bae, Wanjin Park, Jeongyeop Kim, Yunjin Park, Jungwon
  Yoon, Junhyung Moon, Myunggyo Oh, Wonhyuk Lee, Junseo Jang, Dongyoung Jung,
  Minwook Ju, Eunmi Kim, Sujin Kim, Youngchol Kim, Somin Lee, Wonyoung Lee,
  Minsung Noh, Hyoungjun Park, Eunyoung Shin
Categories: cs.CL cs.AI
Comments: 23 pages, 8 figures
\\
  KT developed a Responsible AI (RAI) assessment methodology and risk
mitigation technologies to ensure the safety and reliability of AI services. By
analyzing the Basic Act on AI implementation and global AI governance trends,
we established a unique approach for regulatory compliance and systematically
identify and manage all potential risk factors from AI development to
operation. We present a reliable assessment methodology that systematically
verifies model safety and robustness based on KT's AI risk taxonomy tailored to
the domestic environment. We also provide practical tools for managing and
mitigating identified AI risks. With the release of this report, we also
release proprietary Guardrail : SafetyGuard that blocks harmful responses from
AI models in real-time, supporting the enhancement of safety in the domestic AI
development ecosystem. We also believe these research outcomes provide valuable
insights for organizations seeking to develop Responsible AI.
\\ ( https://arxiv.org/abs/2509.20057 ,  3491kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20065
Date: Wed, 24 Sep 2025 12:33:54 GMT   (9616kb)

Title: From Input Perception to Predictive Insight: Modeling Model Blind Spots
  Before They Become Errors
Authors: Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi
Categories: cs.CL
Comments: EMNLP 2025
\\
  Language models often struggle with idiomatic, figurative, or
context-sensitive inputs, not because they produce flawed outputs, but because
they misinterpret the input from the outset. We propose an input-only method
for anticipating such failures using token-level likelihood features inspired
by surprisal and the Uniform Information Density hypothesis. These features
capture localized uncertainty in input comprehension and outperform standard
baselines across five linguistically challenging datasets. We show that
span-localized features improve error detection for larger models, while
smaller models benefit from global patterns. Our method requires no access to
outputs or hidden activations, offering a lightweight and generalizable
approach to pre-generation error prediction.
\\ ( https://arxiv.org/abs/2509.20065 ,  9616kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20072
Date: Wed, 24 Sep 2025 12:44:26 GMT   (604kb)

Title: From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint
  Training
Authors: Tianqiao Liu, Xueyi Li, Hao Wang, Haoxuan Li, Zhichao Chen, Weiqi Luo,
  Zitao Liu
Categories: cs.CL
\\
  Recent advances in large language models have attracted significant interest
in extending their capabilities to multimodal scenarios, particularly for
speech-in speech-out conversational systems. However, existing multimodal
models handling interleaved audio and text, such as MOSHI require complex multi
stage training pipelines, incurring substantial computational costs. Moreover,
these models uniformly apply autoregressive generation to both text and audio
tokens, overlooking a fundamental asymmetry in their dependency structures:
while text tokens exhibit strong target target dependencies requiring causal
ordering, audio tokens are predominantly driven by source target dependencies,
where audio outputs primarily condition on source text rather than preceding
audio tokens. In this work, we propose TtT, a unified audio-text modeling
framework that integrates AR text generation with non-autoregressive audio
diffusion within a single Transformer architecture initialized from a
pretrained LLM.
\\ ( https://arxiv.org/abs/2509.20072 ,  604kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20074
Date: Wed, 24 Sep 2025 12:52:07 GMT   (38kb)

Title: Can Constructions "SCAN" Compositionality ?
Authors: Ganesh Katrapati, Manish Shrivastava
Categories: cs.CL
\\
  Sequence to Sequence models struggle at compositionality and systematic
generalisation even while they excel at many other tasks. We attribute this
limitation to their failure to internalise constructions conventionalised form
meaning pairings that license productive recombination. Building on these
insights, we introduce an unsupervised procedure for mining
pseudo-constructions: variable-slot templates automatically extracted from
training data. When applied to the SCAN dataset, our method yields large gains
out-of-distribution splits: accuracy rises to 47.8 %on ADD JUMP and to 20.3% on
AROUND RIGHT without any architectural changes or additional supervision. The
model also attains competitive performance with? 40% of the original training
data, demonstrating strong data efAciency. Our findings highlight the promise
of construction-aware preprocessing as an alternative to heavy architectural or
training-regime interventions.
\\ ( https://arxiv.org/abs/2509.20074 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20086
Date: Wed, 24 Sep 2025 13:05:09 GMT   (54kb)

Title: OLaPh: Optimal Language Phonemizer
Authors: Johannes Wirth
Categories: cs.CL
Comments: 5 pages, 1 figure, 3 tables
\\
  Phonemization, the conversion of text into phonemes, is a key step in
text-to-speech. Traditional approaches use rule-based transformations and
lexicon lookups, while more advanced methods apply preprocessing techniques or
neural networks for improved accuracy on out-of-domain vocabulary. However, all
systems struggle with names, loanwords, abbreviations, and homographs. This
work presents OLaPh (Optimal Language Phonemizer), a framework that combines
large lexica, multiple NLP techniques, and compound resolution with a
probabilistic scoring function. Evaluations in German and English show improved
accuracy over previous approaches, including on a challenging dataset. To
further address unresolved cases, we train a large language model on
OLaPh-generated data, which achieves even stronger generalization and
performance. Together, the framework and LLM improve phonemization consistency
and provide a freely available resource for future research.
\\ ( https://arxiv.org/abs/2509.20086 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20088
Date: Wed, 24 Sep 2025 13:06:35 GMT   (4579kb)

Title: Causal Understanding by LLMs: The Role of Uncertainty
Authors: Oscar Lithgow-Serrano, Vani Kanjirangat, Alessandro Antonucci
Categories: cs.CL cs.AI
Comments: Accepted in second UncertaiNLP workshop at EMNLP 2025
\\
  Recent papers show LLMs achieve near-random accuracy in causal relation
classification, raising questions about whether such failures arise from
limited pretraining exposure or deeper representational gaps. We investigate
this under uncertainty-based evaluation, testing whether pretraining exposure
to causal examples improves causal understanding >18K PubMed sentences -- half
from The Pile corpus, half post-2024 -- across seven models
(Pythia-1.4B/7B/12B, GPT-J-6B, Dolly-7B/12B, Qwen-7B). We analyze model
behavior through: (i) causal classification, where the model identifies causal
relationships in text, and (ii) verbatim memorization probing, where we assess
whether the model prefers previously seen causal statements over their
paraphrases. Models perform four-way classification
(direct/conditional/correlational/no-relationship) and select between originals
and their generated paraphrases. Results show almost identical accuracy on
seen/unseen sentences (p > 0.05), no memorization bias (24.8% original
selection), and output distribution over the possible options is almost flat,
with entropic values near the maximum (1.35/1.39), confirming random guessing.
Instruction-tuned models show severe miscalibration (Qwen: > 95% confidence,
32.8% accuracy, ECE=0.49). Conditional relations induce highest entropy (+11%
vs. direct). These findings suggest that failures in causal understanding arise
from the lack of structured causal representation, rather than insufficient
exposure to causal examples during pretraining.
\\ ( https://arxiv.org/abs/2509.20088 ,  4579kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20097
Date: Wed, 24 Sep 2025 13:20:37 GMT   (51kb)

Title: Integrated Framework for LLM Evaluation with Answer Generation
Authors: Sujeong Lee, Hayoung Lee, Seongsoo Heo, Wonik Choi
Categories: cs.CL cs.AI
Comments: 16pages
\\
  Reliable evaluation of large language models is essential to ensure their
applicability in practical scenarios. Traditional benchmark-based evaluation
methods often rely on fixed reference answers, limiting their ability to
capture important qualitative aspects of generated responses. To address these
shortcomings, we propose an integrated evaluation framework called
\textit{self-refining descriptive evaluation with expert-driven diagnostics},
SPEED, which utilizes specialized functional experts to perform comprehensive,
descriptive analyses of model outputs. Unlike conventional approaches, SPEED
actively incorporates expert feedback across multiple dimensions, including
hallucination detection, toxicity assessment, and lexical-contextual
appropriateness. Experimental results demonstrate that SPEED achieves robust
and consistent evaluation performance across diverse domains and datasets.
Additionally, by employing relatively compact expert models, SPEED demonstrates
superior resource efficiency compared to larger-scale evaluators. These
findings illustrate that SPEED significantly enhances fairness and
interpretability in LLM evaluations, offering a promising alternative to
existing evaluation methodologies.
\\ ( https://arxiv.org/abs/2509.20097 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20129
Date: Wed, 24 Sep 2025 13:55:56 GMT   (1087kb)

Title: Less is More: The Effectiveness of Compact Typological Language
  Representations
Authors: York Hay Ng, Phuong Hanh Hoang, En-Shiun Annie Lee
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Main Conference
\\
  Linguistic feature datasets such as URIEL+ are valuable for modelling
cross-lingual relationships, but their high dimensionality and sparsity,
especially for low-resource languages, limit the effectiveness of distance
metrics. We propose a pipeline to optimize the URIEL+ typological feature space
by combining feature selection and imputation, producing compact yet
interpretable typological representations. We evaluate these feature subsets on
linguistic distance alignment and downstream tasks, demonstrating that
reduced-size representations of language typology can yield more informative
distance metrics and improve performance in multilingual NLP applications.
\\ ( https://arxiv.org/abs/2509.20129 ,  1087kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20162
Date: Wed, 24 Sep 2025 14:30:16 GMT   (2921kb)

Title: Embedding Domain Knowledge for Large Language Models via Reinforcement
  Learning from Augmented Generation
Authors: Chaojun Nie, Jun Zhou, Guanxiang Wang, Shisong Wud, Zichen Wang
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) often exhibit limited performance on
domain-specific tasks due to the natural disproportionate representation of
specialized information in their training data and the static nature of these
datasets. Knowledge scarcity and temporal lag create knowledge gaps for domain
applications. While post-training on domain datasets can embed knowledge into
models, existing approaches have some limitations. Continual Pre-Training (CPT)
treats all tokens in domain documents with equal importance, failing to
prioritize critical knowledge points, while supervised fine-tuning (SFT) with
question-answer pairs struggles to develop the coherent knowledge structures
necessary for complex reasoning tasks. To address these challenges, we propose
Reinforcement Learning from Augmented Generation (RLAG). Our approach
iteratively cycles between sampling generations and optimizing the model
through calculated rewards, effectively embedding critical and contextually
coherent domain knowledge. We select generated outputs with the highest log
probabilities as the sampling result, then compute three tailored reward
metrics to guide the optimization process. To comprehensively evaluate domain
expertise, we assess answer accuracy and the rationality of explanations
generated for correctly answered questions. Experimental results across
medical, legal, astronomy, and current events datasets demonstrate that our
proposed method significantly outperforms baseline approaches. Our code and
data are open sourced at https://github.com/ChaojunNie/RLAG.
\\ ( https://arxiv.org/abs/2509.20162 ,  2921kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20168
Date: Wed, 24 Sep 2025 14:34:17 GMT   (419kb)

Title: Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in
  Persian
Authors: Ghazal Kalhor and Behnam Bahrak
Categories: cs.CL
Comments: Accepted and forthcoming at the Widening Natural Language Processing
  Workshop (WiNLP 2025) at EMNLP 2025
\\
  Multilingual Large Language Models (LLMs) are increasingly used worldwide,
making it essential to ensure they are free from gender bias to prevent
representational harm. While prior studies have examined such biases in
high-resource languages, low-resource languages remain understudied. In this
paper, we propose a template-based probing methodology, validated against
real-world data, to uncover gender stereotypes in LLMs. As part of this
framework, we introduce the Domain-Specific Gender Skew Index (DS-GSI), a
metric that quantifies deviations from gender parity. We evaluate four
prominent models, GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, and Qwen QwQ 32B,
across four semantic domains, focusing on Persian, a low-resource language with
distinct linguistic features. Our results show that all models exhibit gender
stereotypes, with greater disparities in Persian than in English across all
domains. Among these, sports reflect the most rigid gender biases. This study
underscores the need for inclusive NLP practices and provides a framework for
assessing bias in other low-resource languages.
\\ ( https://arxiv.org/abs/2509.20168 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20186
Date: Wed, 24 Sep 2025 14:45:13 GMT   (253kb)

Title: Thinking Augmented Pre-training
Authors: Liang Wang, Nan Yang, Shaohan Huang, Li Dong, Furu Wei
Categories: cs.CL cs.LG
Comments: 19 pages
\\
  This paper introduces a simple and scalable approach to improve the data
efficiency of large language model (LLM) training by augmenting existing text
data with thinking trajectories. The compute for pre-training LLMs has been
growing at an unprecedented rate, while the availability of high-quality data
remains limited. Consequently, maximizing the utility of available data
constitutes a significant research challenge. A primary impediment is that
certain high-quality tokens are difficult to learn given a fixed model
capacity, as the underlying rationale for a single token can be exceptionally
complex and deep. To address this issue, we propose Thinking augmented
Pre-Training (TPT), a universal methodology that augments text with
automatically generated thinking trajectories. Such augmentation effectively
increases the volume of the training data and makes high-quality tokens more
learnable through step-by-step reasoning and decomposition. We apply TPT across
diverse training configurations up to $100$B tokens, encompassing pre-training
with both constrained and abundant data, as well as mid-training from strong
open-source checkpoints. Experimental results indicate that our method
substantially improves the performance of LLMs across various model sizes and
families. Notably, TPT enhances the data efficiency of LLM pre-training by a
factor of $3$. For a $3$B parameter model, it improves the post-training
performance by over $10\%$ on several challenging reasoning benchmarks.
\\ ( https://arxiv.org/abs/2509.20186 ,  253kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20208
Date: Wed, 24 Sep 2025 15:02:33 GMT   (544kb)

Title: Play by the Type Rules: Inferring Constraints for LLM Functions in
  Declarative Programs
Authors: Parker Glenn, Alfy Samuel, Daben Liu
Categories: cs.CL cs.AI cs.DB
\\
  Integrating LLM powered operators in declarative query languages allows for
the combination of cheap and interpretable functions with powerful,
generalizable language model reasoning. However, in order to benefit from the
optimized execution of a database query language like SQL, generated outputs
must align with the rules enforced by both type checkers and database contents.
Current approaches address this challenge with orchestrations consisting of
many LLM-based post-processing calls to ensure alignment between generated
outputs and database values, introducing performance bottlenecks. We perform a
study on the ability of various sized open-source language models to both parse
and execute functions within a query language based on SQL, showing that small
language models can excel as function executors over hybrid data sources. Then,
we propose an efficient solution to enforce the well-typedness of LLM
functions, demonstrating 7% accuracy improvement on a multi-hop question
answering dataset with 53% improvement in latency over comparable solutions. We
make our implementation available at https://github.com/parkervg/blendsql
\\ ( https://arxiv.org/abs/2509.20208 ,  544kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20209
Date: Wed, 24 Sep 2025 15:02:57 GMT   (102kb)

Title: Low-Resource English-Tigrinya MT: Leveraging Multilingual Models, Custom
  Tokenizers, and Clean Evaluation Benchmarks
Authors: Hailay Kidu Teklehaymanot, Gebrearegawi Gidey, Wolfgang Nejdl
Categories: cs.CL cs.AI
Comments: This submission is 8 pages long, includes 4 tables, and contains all
  required conference details
MSC-class: 68T50, 68T35
ACM-class: I.2.7; H.3.1; I.2.6
\\
  Despite advances in Neural Machine Translation (NMT), low-resource languages
like Tigrinya remain underserved due to persistent challenges, including
limited corpora, inadequate tokenization strategies, and the lack of
standardized evaluation benchmarks. This paper investigates transfer learning
techniques using multilingual pretrained models to enhance translation quality
for morphologically rich, low-resource languages. We propose a refined approach
that integrates language-specific tokenization, informed embedding
initialization, and domain-adaptive fine-tuning. To enable rigorous assessment,
we construct a high-quality, human-aligned English-Tigrinya evaluation dataset
covering diverse domains. Experimental results demonstrate that transfer
learning with a custom tokenizer substantially outperforms zero-shot baselines,
with gains validated by BLEU, chrF, and qualitative human evaluation.
Bonferroni correction is applied to ensure statistical significance across
configurations. Error analysis reveals key limitations and informs targeted
refinements. This study underscores the importance of linguistically aware
modeling and reproducible benchmarks in bridging the performance gap for
underrepresented languages. Resources are available at
https://github.com/hailaykidu/MachineT_TigEng
  and https://huggingface.co/Hailay/MachineT_TigEng
\\ ( https://arxiv.org/abs/2509.20209 ,  102kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20237
Date: Wed, 24 Sep 2025 15:27:44 GMT   (5649kb)

Title: Investigating the Representation of Backchannels and Fillers in
  Fine-tuned Language Models
Authors: Yu Wang, Leyi Lao, Langchu Huang, Gabriel Skantze, Yang Xu, Hendrik
  Buschmeier
Categories: cs.CL
\\
  Backchannels and fillers are important linguistic expressions in dialogue,
but are under-represented in modern transformer-based language models (LMs).
Our work studies the representation of them in language models using three
fine-tuning strategies. The models are trained on three dialogue corpora in
English and Japanese, where backchannels and fillers are preserved and
annotated, to investigate how fine-tuning can help LMs learn their
representations. We first apply clustering analysis to the learnt
representation of backchannels and fillers, and have found increased silhouette
scores in representations from fine-tuned models, which suggests that
fine-tuning enables LMs to distinguish the nuanced semantic variation in
different backchannel and filler use. We also use natural language generation
(NLG) metrics to confirm that the utterances generated by fine-tuned language
models resemble human-produced utterances more closely. Our findings suggest
the potentials of transforming general LMs into conversational LMs that are
more capable of producing human-like languages adequately.
\\ ( https://arxiv.org/abs/2509.20237 ,  5649kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20278
Date: Wed, 24 Sep 2025 16:15:26 GMT   (531kb)

Title: Instruction Boundary: Quantifying Biases in LLM Reasoning under Various
  Coverage
Authors: Zipeng Ling, Yuehao Tang, Chen Huang, Shuliang Liu, Gaoyang Jiang,
  Shenghong Fu, Junqi Yang, Yao Wan, Jiawan Zhang, Kejia Huang, Xuming Hu
Categories: cs.CL
\\
  Large-language-model (LLM) reasoning has long been regarded as a powerful
tool for problem solving across domains, providing non-experts with valuable
advice. However, their limitations - especially those stemming from prompt
design - remain underexplored. Because users may supply biased or incomplete
prompts - often unintentionally - LLMs can be misled, undermining reliability
and creating risks. We refer to this vulnerability as the Instruction Boundary.
To investigate the phenomenon, we distill it into eight concrete facets and
introduce BiasDetector, a framework that measures biases arising from three
instruction types: complete, redundant, and insufficient. We evaluate several
mainstream LLMs and find that, despite high headline accuracy, substantial
biases persist in many downstream tasks as a direct consequence of prompt
coverage. Our empirical study confirms that LLM reasoning reliability can still
be significantly improved. We analyze the practical impact of these biases and
outline mitigation strategies. Our findings underscore the need for developers
to tackle biases and for users to craft options carefully.
\\ ( https://arxiv.org/abs/2509.20278 ,  531kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20287
Date: Wed, 24 Sep 2025 16:21:37 GMT   (7765kb)

Title: Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in
  Evaluation and Meta-Evaluation of Machine Translation
Authors: Behzad Shayegh, Jan-Thorsten Peter, David Vilar, Tobias Domhan, Juraj
  Juraska, Markus Freitag, Lili Mou
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by Tenth Conference on Machine Translation (WMT25)
\\
  We investigate the tradeoff between adequacy and fluency in machine
translation. We show the severity of this tradeoff at the evaluation level and
analyze where popular metrics fall within it. Essentially, current metrics
generally lean toward adequacy, meaning that their scores correlate more
strongly with the adequacy of translations than with fluency. More importantly,
we find that this tradeoff also persists at the meta-evaluation level, and that
the standard WMT meta-evaluation favors adequacy-oriented metrics over
fluency-oriented ones. We show that this bias is partially attributed to the
composition of the systems included in the meta-evaluation datasets. To control
this bias, we propose a method that synthesizes translation systems in
meta-evaluation. Our findings highlight the importance of understanding this
tradeoff in meta-evaluation and its impact on metric rankings.
\\ ( https://arxiv.org/abs/2509.20287 ,  7765kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20315
Date: Wed, 24 Sep 2025 16:54:30 GMT   (1692kb)

Title: Multilingual Hope Speech Detection: A Comparative Study of Logistic
  Regression, mBERT, and XLM-RoBERTa with Active Learning
Authors: T. O. Abiola, K. D. Abiodun, O. E. Olumide, O. O. Adebanji, O. Hiram
  Calvo, Grigori Sidorov
Categories: cs.CL cs.LG
\\
  Hope speech language that fosters encouragement and optimism plays a vital
role in promoting positive discourse online. However, its detection remains
challenging, especially in multilingual and low-resource settings. This paper
presents a multilingual framework for hope speech detection using an active
learning approach and transformer-based models, including mBERT and
XLM-RoBERTa. Experiments were conducted on datasets in English, Spanish,
German, and Urdu, including benchmark test sets from recent shared tasks. Our
results show that transformer models significantly outperform traditional
baselines, with XLM-RoBERTa achieving the highest overall accuracy.
Furthermore, our active learning strategy maintained strong performance even
with small annotated datasets. This study highlights the effectiveness of
combining multilingual transformers with data-efficient training strategies for
hope speech detection.
\\ ( https://arxiv.org/abs/2509.20315 ,  1692kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20317
Date: Wed, 24 Sep 2025 17:01:32 GMT   (1876kb)

Title: SIM-CoT: Supervised Implicit Chain-of-Thought
Authors: Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Jiaqi
  Wang, Xipeng Qiu, Dahua Lin
Categories: cs.CL cs.AI
\\
  Implicit Chain-of-Thought (CoT) methods present a promising, token-efficient
alternative to explicit CoT reasoning in Large Language Models (LLMs), but a
persistent performance gap has limited the application of implicit CoT. We
identify a core latent instability issue by scaling the computational budget of
implicit CoT approaches: as we increase the number of implicit reasoning tokens
to enhance performance, the training process often becomes unstable and
collapses. Our analysis reveals that this instability arises from the latent
representations becoming homogeneous and losing their semantic diversity, a
failure caused by insufficient step-level supervision in existing implicit CoT
approaches. To address this issue, we propose SIM-CoT, a plug-and-play training
module that introduces step-level supervision to stabilize and enrich the
latent reasoning space. Specifically, SIM-CoT employs an auxiliary decoder
during training to align each implicit token with its corresponding explicit
reasoning step, ensuring that latent states capture distinct and meaningful
information. The proposed auxiliary decoder is removed during inference,
preserving the computational efficiency of implicit CoT methods with no added
overhead. In addition, the auxiliary decoder affords interpretability of
implicit reasoning by projecting each latent token onto an explicit reasoning
vocabulary, enabling per-step visualization of semantic roles and diagnosis.
SIM-CoT significantly enhances both the in-domain accuracy and out-of-domain
stability of various implicit CoT methods, boosting baselines like Coconut by
+8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strong
scalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1%
with 2.3\times greater token efficiency, while substantially closing the
performance gap on larger models like LLaMA-3.1 8B.
\\ ( https://arxiv.org/abs/2509.20317 ,  1876kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20319
Date: Wed, 24 Sep 2025 17:02:39 GMT   (754kb)

Title: Z-Scores: A Metric for Linguistically Assessing Disfluency Removal
Authors: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma,
  Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach,
  Jason Kim, Yin Zhang, James Caverlee
Categories: cs.CL cs.AI eess.AS
\\
  Evaluating disfluency removal in speech requires more than aggregate
token-level scores. Traditional word-based metrics such as precision, recall,
and F1 (E-Scores) capture overall performance but cannot reveal why models
succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded
evaluation metric that categorizes system behavior across distinct disfluency
types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust
mapping between generated text and disfluent transcripts, allowing Z-Scores to
expose systematic weaknesses that word-level metrics obscure. By providing
category-specific diagnostics, Z-Scores enable researchers to identify model
failure modes and design targeted interventions -- such as tailored prompts or
data augmentation -- yielding measurable performance improvements. A case study
with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies
hidden in aggregate F1, directly informing model refinement strategies.
\\ ( https://arxiv.org/abs/2509.20319 ,  754kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20321
Date: Wed, 24 Sep 2025 17:08:12 GMT   (179kb)

Title: DRES: Benchmarking LLMs for Disfluency Removal
Authors: Maria Teleki, Sai Janjur, Haoran Liu, Oliver Grabner, Ketan Verma,
  Thomas Docog, Xiangjue Dong, Lingfeng Shi, Cong Wang, Stephanie Birkelbach,
  Jason Kim, Yin Zhang, James Caverlee
Categories: cs.CL cs.AI eess.AS
\\
  Disfluencies -- such as "um," "uh," interjections, parentheticals, and edited
statements -- remain a persistent challenge for speech-driven systems,
degrading accuracy in command interpretation, summarization, and conversational
agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled
text-level benchmark that establishes a reproducible semantic upper bound for
this task. DRES builds on human-annotated Switchboard transcripts, isolating
disfluency removal from ASR errors and acoustic variability. We systematically
evaluate proprietary and open-source LLMs across scales, prompting strategies,
and architectures. Our results reveal that (i) simple segmentation consistently
improves performance, even for long-context models; (ii) reasoning-oriented
models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near
state-of-the-art precision and recall but harms generalization abilities. We
further present a set of LLM-specific error modes and offer nine practical
recommendations (R1-R9) for deploying disfluency removal in speech-driven
pipelines. DRES provides a reproducible, model-agnostic foundation for
advancing robust spoken-language systems.
\\ ( https://arxiv.org/abs/2509.20321 ,  179kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20341
Date: Wed, 24 Sep 2025 17:33:47 GMT   (669kb)

Title: Morphological Synthesizer for Ge'ez Language: Addressing Morphological
  Complexity and Resource Limitations
Authors: Gebrearegawi Gebremariam, Hailay Teklehaymanot, Gebregewergs Mezgebe
Categories: cs.CL cs.AI
Comments: 13 pages,2 images,7 tables
MSC-class: 68T50, 68T35, 68N01
ACM-class: I.2.7; I.2.6; H.3.1
\\
  Ge'ez is an ancient Semitic language renowned for its unique alphabet. It
serves as the script for numerous languages, including Tigrinya and Amharic,
and played a pivotal role in Ethiopia's cultural and religious development
during the Aksumite kingdom era. Ge'ez remains significant as a liturgical
language in Ethiopia and Eritrea, with much of the national identity
documentation recorded in Ge'ez. These written materials are invaluable primary
sources for studying Ethiopian and Eritrean philosophy, creativity, knowledge,
and civilization. Ge'ez has a complex morphological structure with rich
inflectional and derivational morphology, and no usable NLP has been developed
and published until now due to the scarcity of annotated linguistic data,
corpora, labeled datasets, and lexicons. Therefore, we propose a rule-based
Ge'ez morphological synthesizer to generate surface words from root words
according to the morphological structures of the language. We used 1,102 sample
verbs, representing all verb morphological structures, to test and evaluate the
system. The system achieves a performance of 97.4%, outperforming the baseline
model and suggesting that future work should build a comprehensive system
considering morphological variations of the language.
  Keywords: Ge'ez, NLP, morphology, morphological synthesizer, rule-based
\\ ( https://arxiv.org/abs/2509.20341 ,  669kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20354
Date: Wed, 24 Sep 2025 17:56:51 GMT   (649kb)

Title: EmbeddingGemma: Powerful and Lightweight Text Representations
Authors: Henrique Schechter Vera, Sahil Dua, Biao Zhang, Daniel Salz, Ryan
  Mullins, Sindhu Raghuram Panyam, Sara Smoot, Iftekhar Naim, Joe Zou, Feiyang
  Chen, Daniel Cer, Alice Lisak, Min Choi, Lucas Gonzalez, Omar Sanseviero,
  Glenn Cameron, Ian Ballantyne, Kat Black, Kaifeng Chen, Weiyi Wang, Zhe Li,
  Gus Martins, Jinhyuk Lee, Mark Sherwood, Juyeong Ji, Renjie Wu, Jingxiao
  Zheng, Jyotinder Singh, Abheesht Sharma, Divya Sreepat, Aashi Jain, Adham
  Elarabawy, AJ Co, Andreas Doumanoglou, Babak Samari, Ben Hora, Brian Potetz,
  Dahun Kim, Enrique Alfonseca, Fedor Moiseev, Feng Han, Frank Palma Gomez,
  Gustavo Hern\'andez \'Abrego, Hesen Zhang, Hui Hui, Jay Han, Karan Gill, Ke
  Chen, Koert Chen, Madhuri Shanbhogue, Michael Boratko, Paul Suganthan, Sai
  Meher Karthik Duddu, Sandeep Mariserla, Setareh Ariafar, Shanfeng Zhang, et
  al. (32 additional authors not shown)
Categories: cs.CL cs.AI
Comments: 18 pages. Models are available in HuggingFace (at
  https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4),
  Kaggle (at https://www.kaggle.com/models/google/embeddinggemma/), and Vertex
  AI (at
  https://pantheon.corp.google.com/vertex-ai/publishers/google/model-garden/embeddinggemma)
\\
  We introduce EmbeddingGemma, a new lightweight, open text embedding model
based on the Gemma 3 language model family. Our innovative training recipe
strategically captures knowledge from larger models via encoder-decoder
initialization and geometric embedding distillation. We improve model
robustness and expressiveness with a spread-out regularizer, and ensure
generalizability by merging checkpoints from varied, optimized mixtures.
Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual,
English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art
results. Notably, it outperforms prior top models, both proprietary and open,
with fewer than 500M parameters, and provides performance comparable to models
double its size, offering an exceptional performance-to-cost ratio. Remarkably,
this lead persists when quantizing model weights or truncating embedding
outputs. This makes EmbeddingGemma particularly well-suited for low-latency and
high-throughput use cases such as on-device applications. We provide ablation
studies exploring our key design choices. We release EmbeddingGemma to the
community to promote further research.
\\ ( https://arxiv.org/abs/2509.20354 ,  649kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20357
Date: Wed, 24 Sep 2025 17:57:34 GMT   (333kb)

Title: Language Models that Think, Chat Better
Authors: Adithya Bhaskar, Xi Ye, Danqi Chen
Categories: cs.CL
Comments: Preprint; we release our code and models publicly at
  https://github.com/princeton-pli/RLMT
\\
  Reinforcement learning with verifiable rewards (RLVR) improves language model
reasoning by using rule-based rewards in verifiable domains such as mathematics
and code. However, RLVR leads to limited generalization for open-ended tasks --
such as writing outline essays or making meal plans -- where humans reason
routinely. This paper shows that the RLVR paradigm is effective beyond
verifiable domains, and introduces **RL** with **M**odel-rewarded **T**hinking
(**RLMT**) for general-purpose chat capabilities. Using diverse real-world
prompts, RLMT requires LMs to generate long CoT reasoning before response, and
optimizes them with online RL against a preference-based reward model used in
RLHF. Across 40 training runs on Llama-3.1-8B and Qwen-2.5-7B (both base and
instruct) and multiple optimization algorithms (DPO, PPO, and GRPO), RLMT
consistently outperforms standard RLHF pipelines. This includes substantial
gains of 3-7 points on three chat benchmarks (AlpacaEval2, WildBench, and
ArenaHardV2), along with 1-3 point improvements on other tasks like creative
writing and general knowledge. Our best 8B model surpasses GPT-4o in chat and
creative writing and rivals Claude-3.7-Sonnet (Thinking). RLMT can also be
applied directly to base models without an SFT stage, akin to R1-Zero training.
Remarkably, with only 7K prompts, Llama-3.1-8B base trained with our RLMT
recipe outperforms Llama-3.1-8B-Instruct post-trained with a complex
multi-staged pipeline with 25M+ examples. We close with qualitative and
quantitative analyses of how trained models plan their responses. Our results
rethink the post-training pipeline and call upon future work to understand and
employ thinking more broadly.
\\ ( https://arxiv.org/abs/2509.20357 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19378
Date: Sat, 20 Sep 2025 03:34:07 GMT   (20882kb)

Title: Vision-Based Perception for Autonomous Vehicles in Off-Road Environment
  Using Deep Learning
Authors: Nelson Alves Ferreira Neto
Categories: cs.CV cs.AR cs.LG eess.IV eess.SP
Comments: 2022. 117p. Electrical Engineering PhD Thesis - Graduate Program in
  Electrical and Computer Engineering, Federal University of Bahia, 40210-630,
  Salvador, Brazil
\\
  Low-latency intelligent systems are required for autonomous driving on
non-uniform terrain in open-pit mines and developing countries. This work
proposes a perception system for autonomous vehicles on unpaved roads and
off-road environments, capable of navigating rough terrain without a predefined
trail. The Configurable Modular Segmentation Network (CMSNet) framework is
proposed, facilitating different architectural arrangements. CMSNet
configurations were trained to segment obstacles and trafficable ground on new
images from unpaved/off-road scenarios with adverse conditions (night, rain,
dust). We investigated applying deep learning to detect drivable regions
without explicit track boundaries, studied algorithm behavior under visibility
impairment, and evaluated field tests with real-time semantic segmentation. A
new dataset, Kamino, is presented with almost 12,000 images from an operating
vehicle with eight synchronized cameras. The Kamino dataset has a high number
of labeled pixels compared to similar public collections and includes images
from an off-road proving ground emulating a mine under adverse visibility. To
achieve real-time inference, CMSNet CNN layers were methodically removed and
fused using TensorRT, C++, and CUDA. Empirical experiments on two datasets
validated the proposed system's effectiveness.
\\ ( https://arxiv.org/abs/2509.19378 ,  20882kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19402
Date: Tue, 23 Sep 2025 06:35:19 GMT   (2904kb)

Title: Overview of LifeCLEF Plant Identification task 2020
Authors: Herve Goeau, Pierre Bonnet, Alexis Joly
Categories: cs.CV
Comments: 15 pages, 5 figures, CLEF 2020 Conference and Labs of the Evaluation
  Forum, September 05 to 08, 2020, Thessaloniki, Greece
\\
  Automated identification of plants has improved considerably thanks to the
recent progress in deep learning and the availability of training data with
more and more photos in the field. However, this profusion of data only
concerns a few tens of thousands of species, mostly located in North America
and Western Europe, much less in the richest regions in terms of biodiversity
such as tropical countries. On the other hand, for several centuries, botanists
have collected, catalogued and systematically stored plant specimens in
herbaria, particularly in tropical regions, and the recent efforts by the
biodiversity informatics community made it possible to put millions of
digitized sheets online. The LifeCLEF 2020 Plant Identification challenge (or
"PlantCLEF 2020") was designed to evaluate to what extent automated
identification on the flora of data deficient regions can be improved by the
use of herbarium collections. It is based on a dataset of about 1,000 species
mainly focused on the South America's Guiana Shield, an area known to have one
of the greatest diversity of plants in the world. The challenge was evaluated
as a cross-domain classification task where the training set consist of several
hundred thousand herbarium sheets and few thousand of photos to enable learning
a mapping between the two domains. The test set was exclusively composed of
photos in the field. This paper presents the resources and assessments of the
conducted evaluation, summarizes the approaches and systems employed by the
participating research groups, and provides an analysis of the main outcomes.
\\ ( https://arxiv.org/abs/2509.19402 ,  2904kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19552
Date: Tue, 23 Sep 2025 20:25:53 GMT   (12051kb)

Title: iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam
  Video Reasoning
Authors: Manyi Yao, Bingbing Zhuang, Sparsh Garg, Amit Roy-Chowdhury, Christian
  Shelton, Manmohan Chandraker, Abhishek Aich
Categories: cs.CV
\\
  Grounding large language models (LLMs) in domain-specific tasks like post-hoc
dash-cam driving video analysis is challenging due to their general-purpose
training and lack of structured inductive biases. As vision is often the sole
modality available for such analysis (i.e., no LiDAR, GPS, etc.), existing
video-based vision-language models (V-VLMs) struggle with spatial reasoning,
causal inference, and explainability of events in the input video. To this end,
we introduce iFinder, a structured semantic grounding framework that decouples
perception from reasoning by translating dash-cam videos into a hierarchical,
interpretable data structure for LLMs. iFinder operates as a modular,
training-free pipeline that employs pretrained vision models to extract
critical cues -- object pose, lane positions, and object trajectories -- which
are hierarchically organized into frame- and video-level structures. Combined
with a three-block prompting strategy, it enables step-wise, grounded reasoning
for the LLM to refine a peer V-VLM's outputs and provide accurate reasoning.
Evaluations on four public dash-cam video benchmarks show that iFinder's
proposed grounding with domain-specific cues, especially object orientation and
global context, significantly outperforms end-to-end V-VLMs on four zero-shot
driving benchmarks, with up to 39% gains in accident reasoning accuracy. By
grounding LLMs with driving domain-specific representations, iFinder offers a
zero-shot, interpretable, and reliable alternative to end-to-end V-VLMs for
post-hoc driving video understanding.
\\ ( https://arxiv.org/abs/2509.19552 ,  12051kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19562
Date: Tue, 23 Sep 2025 20:42:40 GMT   (387kb)

Title: CURE: Centroid-guided Unsupervised Representation Erasure for Facial
  Recognition Systems
Authors: Fnu Shivam, Nima Najafzadeh, Yenumula Reddy, Prashnna Gyawali
Categories: cs.CV
\\
  In the current digital era, facial recognition systems offer significant
utility and have been widely integrated into modern technological
infrastructures; however, their widespread use has also raised serious privacy
concerns, prompting regulations that mandate data removal upon request. Machine
unlearning has emerged as a powerful solution to address this issue by
selectively removing the influence of specific user data from trained models
while preserving overall model performance. However, existing machine
unlearning techniques largely depend on supervised techniques requiring
identity labels, which are often unavailable in privacy-constrained situations
or in large-scale, noisy datasets. To address this critical gap, we introduce
CURE (Centroid-guided Unsupervised Representation Erasure), the first
unsupervised unlearning framework for facial recognition systems that operates
without the use of identity labels, effectively removing targeted samples while
preserving overall performance. We also propose a novel metric, the Unlearning
Efficiency Score (UES), which balances forgetting and retention stability,
addressing shortcomings in the current evaluation metrics. CURE significantly
outperforms unsupervised variants of existing unlearning methods. Additionally,
we conducted quality-aware unlearning by designating low-quality images as the
forget set, demonstrating its usability and benefits, and highlighting the role
of image quality in machine unlearning.
\\ ( https://arxiv.org/abs/2509.19562 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19589
Date: Tue, 23 Sep 2025 21:28:33 GMT   (8742kb)

Title: Synthesizing Artifact Dataset for Pixel-level Detection
Authors: Dennis Menn, Feng Liang, Diana Marculescu
Categories: cs.CV
Comments: Under submission to WACV
\\
  Artifact detectors have been shown to enhance the performance of
image-generative models by serving as reward models during fine-tuning. These
detectors enable the generative model to improve overall output fidelity and
aesthetics. However, training the artifact detector requires expensive
pixel-level human annotations that specify the artifact regions. The lack of
annotated data limits the performance of the artifact detector. A naive
pseudo-labeling approach-training a weak detector and using it to annotate
unlabeled images-suffers from noisy labels, resulting in poor performance. To
address this, we propose an artifact corruption pipeline that automatically
injects artifacts into clean, high-quality synthetic images on a predetermined
region, thereby producing pixel-level annotations without manual labeling. The
proposed method enables training of an artifact detector that achieves
performance improvements of 13.2% for ConvNeXt and 3.7% for Swin-T, as verified
on human-labeled data, compared to baseline approaches. This work represents an
initial step toward scalable pixel-level artifact annotation datasets that
integrate world knowledge into artifact detection.
\\ ( https://arxiv.org/abs/2509.19589 ,  8742kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19602
Date: Tue, 23 Sep 2025 21:51:04 GMT   (61kb)

Title: Parameter-Efficient Multi-Task Learning via Progressive Task-Specific
  Adaptation
Authors: Neeraj Gangwar, Anshuka Rangi, Rishabh Deshmukh, Holakou Rahmanian,
  Yesh Dattatreya, Nickvash Kani
Categories: cs.CV
\\
  Parameter-efficient fine-tuning methods have emerged as a promising solution
for adapting pre-trained models to various downstream tasks. While these
methods perform well in single-task learning, extending them to multi-task
learning exacerbates common challenges, such as task interference and negative
transfer, due to the limited number of trainable parameters. To address these
issues, we introduce progressive task-specific multi-task adaptation, a novel
parameter-efficient approach for multi-task learning. This approach introduces
adapter modules in a pre-trained model such that these modules are shared
across all tasks in the initial layers and become progressively more
task-specific in the later layers. The motivation is to reduce the conflicts
among tasks by allowing transfer learning across all tasks in the initial
layers and enabling task-specific learning toward the prediction heads.
Additionally, we propose a gradient-based approach for computing task
similarity and use this measure to allocate similar tasks to the shared adapter
modules. Our task similarity method introduces minimal overhead in the
pipeline. We evaluate our approach by adapting the Swin Transformer for dense
prediction tasks. Experiments on the PASCAL and NYUD-v2 datasets demonstrate
that our approach outperforms a fully fine-tuned multi-task model while
requiring only one-fifth of the trainable parameters. This approach achieves
better relative improvement to single-task fine-tuning while reducing the
number of trainable parameters and surpasses the current state-of-the-art
methods for parameter-efficient multi-task learning.
\\ ( https://arxiv.org/abs/2509.19602 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19624
Date: Tue, 23 Sep 2025 22:31:37 GMT   (14234kb)

Title: Raw-JPEG Adapter: Efficient Raw Image Compression with JPEG
Authors: Mahmoud Afifi, Ran Zhang, Michael S. Brown
Categories: cs.CV
\\
  Digital cameras digitize scene light into linear raw representations, which
the image signal processor (ISP) converts into display-ready outputs. While raw
data preserves full sensor information--valuable for editing and vision
tasks--formats such as Digital Negative (DNG) require large storage, making
them impractical in constrained scenarios. In contrast, JPEG is a widely
supported format, offering high compression efficiency and broad compatibility,
but it is not well-suited for raw storage. This paper presents RawJPEG Adapter,
a lightweight, learnable, and invertible preprocessing pipeline that adapts raw
images for standard JPEG compression. Our method applies spatial and optional
frequency-domain transforms, with compact parameters stored in the JPEG comment
field, enabling accurate raw reconstruction. Experiments across multiple
datasets show that our method achieves higher fidelity than direct JPEG
storage, supports other codecs, and provides a favorable trade-off between
compression ratio and reconstruction accuracy.
\\ ( https://arxiv.org/abs/2509.19624 ,  14234kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19644
Date: Tue, 23 Sep 2025 23:21:50 GMT   (12929kb)

Title: The Impact of 2D Segmentation Backbones on Point Cloud Predictions Using
  4D Radar
Authors: William L. Muckelroy III, Mohammed Alsakabi, John M. Dolan, Ozan K.
  Tonguz
Categories: cs.CV cs.RO
\\
  LiDAR's dense, sharp point cloud (PC) representations of the surrounding
environment enable accurate perception and significantly improve road safety by
offering greater scene awareness and understanding. However, LiDAR's high cost
continues to restrict the broad adoption of high-level Autonomous Driving (AD)
systems in commercially available vehicles. Prior research has shown progress
towards circumventing the need for LiDAR by training a neural network, using
LiDAR point clouds as ground truth (GT), to produce LiDAR-like 3D point clouds
using only 4D Radars. One of the best examples is a neural network created to
train a more efficient radar target detector with a modular 2D convolutional
neural network (CNN) backbone and a temporal coherence network at its core that
uses the RaDelft dataset for training (see arXiv:2406.04723). In this work, we
investigate the impact of higher-capacity segmentation backbones on the quality
of the produced point clouds. Our results show that while very high-capacity
models may actually hurt performance, an optimal segmentation backbone can
provide a 23.7% improvement over the state-of-the-art (SOTA).
\\ ( https://arxiv.org/abs/2509.19644 ,  12929kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19659
Date: Wed, 24 Sep 2025 00:33:58 GMT   (1224kb)

Title: Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and
  LLM-as-Judge Assessment
Authors: Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza
Categories: cs.CV
Comments: Accepted to NeurIPS 2025 Workshop (Evaluating the Evolving LLM
  Lifecycle)
\\
  Large vision-language models (VLMs) can jointly interpret images and text,
but they are also prone to absorbing and reproducing harmful social stereotypes
when visual cues such as age, gender, race, clothing, or occupation are
present. To investigate these risks, we introduce a news-image benchmark
consisting of 1,343 image-question pairs drawn from diverse outlets, which we
annotated with ground-truth answers and demographic attributes (age, gender,
race, occupation, and sports). We evaluate a range of state-of-the-art VLMs and
employ a large language model (LLM) as judge, with human verification. Our
findings show that: (i) visual context systematically shifts model outputs in
open-ended settings; (ii) bias prevalence varies across attributes and models,
with particularly high risk for gender and occupation; and (iii) higher
faithfulness does not necessarily correspond to lower bias. We release the
benchmark prompts, evaluation rubric, and code to support reproducible and
fairness-aware multimodal assessment.
\\ ( https://arxiv.org/abs/2509.19659 ,  1224kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19664
Date: Wed, 24 Sep 2025 00:41:40 GMT   (14566kb)

Title: MoTiC: Momentum Tightness and Contrast for Few-Shot Class-Incremental
  Learning
Authors: Zeyu He, Shuai Huang, Yuwu Lu and Ming Zhao
Categories: cs.CV cs.AI
\\
  Few-Shot Class-Incremental Learning (FSCIL) must contend with the dual
challenge of learning new classes from scarce samples while preserving old
class knowledge. Existing methods use the frozen feature extractor and
class-averaged prototypes to mitigate against catastrophic forgetting and
overfitting. However, new-class prototypes suffer significant estimation bias
due to extreme data scarcity, whereas base-class prototypes benefit from
sufficient data. In this work, we theoretically demonstrate that aligning the
new-class priors with old-class statistics via Bayesian analysis reduces
variance and improves prototype accuracy. Furthermore, we propose large-scale
contrastive learning to enforce cross-category feature tightness. To further
enrich feature diversity and inject prior information for new-class prototypes,
we integrate momentum self-supervision and virtual categories into the Momentum
Tightness and Contrast framework (MoTiC), constructing a feature space with
rich representations and enhanced interclass cohesion. Experiments on three
FSCIL benchmarks produce state-of-the-art performances, particularly on the
fine-grained task CUB-200, validating our method's ability to reduce estimation
bias and improve incremental learning robustness.
\\ ( https://arxiv.org/abs/2509.19664 ,  14566kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19665
Date: Wed, 24 Sep 2025 00:49:52 GMT   (24088kb)

Title: Deep Learning for Clouds and Cloud Shadow Segmentation in Methane
  Satellite and Airborne Imaging Spectroscopy
Authors: Manuel Perez-Carrasco, Maya Nasr, Sebastien Roche, Chris Chan Miller,
  Zhan Zhang, Core Francisco Park, Eleanor Walker, Cecilia Garraffo, Douglas
  Finkbeiner, Ritesh Gautam, Steven Wofsy
Categories: cs.CV cs.LG
\\
  Effective cloud and cloud shadow detection is a critical prerequisite for
accurate retrieval of concentrations of atmospheric methane or other trace
gases in hyperspectral remote sensing. This challenge is especially pertinent
for MethaneSAT and for its airborne companion mission, MethaneAIR. In this
study, we use machine learning methods to address the cloud and cloud shadow
detection problem for sensors with these high spatial resolutions instruments.
Cloud and cloud shadows in remote sensing data need to be effectively screened
out as they bias methane retrievals in remote sensing imagery and impact the
quantification of emissions. We deploy and evaluate conventional techniques
including Iterative Logistic Regression (ILR) and Multilayer Perceptron (MLP),
with advanced deep learning architectures, namely UNet and a Spectral Channel
Attention Network (SCAN) method. Our results show that conventional methods
struggle with spatial coherence and boundary definition, affecting the
detection of clouds and cloud shadows. Deep learning models substantially
improve detection quality: UNet performs best in preserving spatial structure,
while SCAN excels at capturing fine boundary details. Notably, SCAN surpasses
UNet on MethaneSAT data, underscoring the benefits of incorporating spectral
attention for satellite specific features. This in depth assessment of various
disparate machine learning techniques demonstrates the strengths and
effectiveness of advanced deep learning architectures in providing robust,
scalable solutions for clouds and cloud shadow screening towards enhancing
methane emission quantification capacity of existing and next generation
hyperspectral missions. Our data and code is publicly available at
https://doi.org/10.7910/DVN/IKLZOJ
\\ ( https://arxiv.org/abs/2509.19665 ,  24088kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19687
Date: Wed, 24 Sep 2025 01:49:59 GMT   (3792kb)

Title: Enhancing Transformer-Based Vision Models: Addressing Feature Map
  Anomalies Through Novel Optimization Strategies
Authors: Sumit Mamtani
Categories: cs.CV
Comments: 8 pages, 8 figures, accepted and presented at IEEE BDAI 2025. The
  final published version will be available on IEEE Xplore
\\
  Vision Transformers (ViTs) have demonstrated superior performance across a
wide range of computer vision tasks. However, structured noise artifacts in
their feature maps hinder downstream applications such as segmentation and
depth estimation. We propose two novel and lightweight optimisation techniques-
Structured Token Augmentation (STA) and Adaptive Noise Filtering (ANF)- to
improve interpretability and mitigate these artefacts. STA enhances token
diversity through spatial perturbations during tokenisation, while ANF applies
learnable inline denoising between transformer layers. These methods are
architecture-agnostic and evaluated across standard benchmarks, including
ImageNet, Ade20k, and NYUv2. Experimental results show consistent improvements
in visual quality and task performance, highlighting the practical
effectiveness of our approach.
\\ ( https://arxiv.org/abs/2509.19687 ,  3792kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19690
Date: Wed, 24 Sep 2025 01:58:22 GMT   (42819kb)

Title: From Prompt to Progression: Taming Video Diffusion Models for Seamless
  Attribute Transition
Authors: Ling Lo, Kelvin C.K. Chan, Wen-Huang Cheng, Ming-Hsuan Yang
Categories: cs.CV
Comments: ICCV 2025
\\
  Existing models often struggle with complex temporal changes, particularly
when generating videos with gradual attribute transitions. The most common
prompt interpolation approach for motion transitions often fails to handle
gradual attribute transitions, where inconsistencies tend to become more
pronounced. In this work, we propose a simple yet effective method to extend
existing models for smooth and consistent attribute transitions, through
introducing frame-wise guidance during the denoising process. Our approach
constructs a data-specific transitional direction for each noisy latent,
guiding the gradual shift from initial to final attributes frame by frame while
preserving the motion dynamics of the video. Moreover, we present the
Controlled-Attribute-Transition Benchmark (CAT-Bench), which integrates both
attribute and motion dynamics, to comprehensively evaluate the performance of
different models. We further propose two metrics to assess the accuracy and
smoothness of attribute transitions. Experimental results demonstrate that our
approach performs favorably against existing baselines, achieving visual
fidelity, maintaining alignment with text prompts, and delivering seamless
attribute transitions. Code and CATBench are released:
https://github.com/lynn-ling-lo/Prompt2Progression.
\\ ( https://arxiv.org/abs/2509.19690 ,  42819kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19691
Date: Wed, 24 Sep 2025 02:00:34 GMT   (1881kb)

Title: Anatomically Constrained Transformers for Cardiac Amyloidosis
  Classification
Authors: Alexander Thorley, Agis Chartsias, Jordan Strom, Roberto Lang, Jeremy
  Slivnick, Jamie O'Driscoll, Rajan Sharma, Dipak Kotecha, Jinming Duan and
  Alberto Gomez
Categories: cs.CV
Comments: Published in MICCAI - ASMUS 2025
\\
  Cardiac amyloidosis (CA) is a rare cardiomyopathy, with typical abnormalities
in clinical measurements from echocardiograms such as reduced global
longitudinal strain of the myocardium. An alternative approach for detecting CA
is via neural networks, using video classification models such as convolutional
neural networks. These models process entire video clips, but provide no
assurance that classification is based on clinically relevant features known to
be associated with CA. An alternative paradigm for disease classification is to
apply models to quantitative features such as strain, ensuring that the
classification relates to clinically relevant features. Drawing inspiration
from this approach, we explicitly constrain a transformer model to the
anatomical region where many known CA abnormalities occur -- the myocardium,
which we embed as a set of deforming points and corresponding sampled image
patches into input tokens. We show that our anatomical constraint can also be
applied to the popular self-supervised learning masked autoencoder
pre-training, where we propose to mask and reconstruct only anatomical patches.
We show that by constraining both the transformer and pre-training task to the
myocardium where CA imaging features are localized, we achieve increased
performance on a CA classification task compared to full video transformers.
Our model provides an explicit guarantee that the classification is focused on
only anatomical regions of the echo, and enables us to visualize transformer
attention scores over the deforming myocardium.
\\ ( https://arxiv.org/abs/2509.19691 ,  1881kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19694
Date: Wed, 24 Sep 2025 02:04:53 GMT   (766kb)

Title: Learning to Stop: Reinforcement Learning for Efficient Patient-Level
  Echocardiographic Classification
Authors: Woo-Jin Cho Kim, Jorge Oliveira, Arian Beqiri, Alex Thorley, Jordan
  Strom, Jamie O'Driscoll, Rajan Sharma, Jeremy Slivnick, Roberto Lang, Alberto
  Gomez and Agisilaos Chartsias
Categories: cs.CV
Comments: published in MICCAI-ASMUS 2025
\\
  Guidelines for transthoracic echocardiographic examination recommend the
acquisition of multiple video clips from different views of the heart,
resulting in a large number of clips. Typically, automated methods, for
instance disease classifiers, either use one clip or average predictions from
all clips. Relying on one clip ignores complementary information available from
other clips, while using all clips is computationally expensive and may be
prohibitive for clinical adoption.
  To select the optimal subset of clips that maximize performance for a
specific task (image-based disease classification), we propose a method
optimized through reinforcement learning. In our method, an agent learns to
either keep processing view-specific clips to reduce the disease classification
uncertainty, or stop processing if the achieved classification confidence is
sufficient. Furthermore, we propose a learnable attention-based aggregation
method as a flexible way of fusing information from multiple clips. The
proposed method obtains an AUC of 0.91 on the task of detecting cardiac
amyloidosis using only 30% of all clips, exceeding the performance achieved
from using all clips and from other benchmarks.
\\ ( https://arxiv.org/abs/2509.19694 ,  766kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19711
Date: Wed, 24 Sep 2025 02:44:53 GMT   (2395kb)

Title: Towards Robust In-Context Learning for Medical Image Segmentation via
  Data Synthesis
Authors: Jiesi Hu, Yanwu Yang, Zhiyu Ye, Chenfei Ye, Hanyang Peng, Jianfeng
  Cao, Ting Ma
Categories: cs.CV
\\
  The rise of In-Context Learning (ICL) for universal medical image
segmentation has introduced an unprecedented demand for large-scale, diverse
datasets for training, exacerbating the long-standing problem of data scarcity.
While data synthesis offers a promising solution, existing methods often fail
to simultaneously achieve both high data diversity and a domain distribution
suitable for medical data. To bridge this gap, we propose \textbf{SynthICL}, a
novel data synthesis framework built upon domain randomization. SynthICL
ensures realism by leveraging anatomical priors from real-world datasets,
generates diverse anatomical structures to cover a broad data distribution, and
explicitly models inter-subject variations to create data cohorts suitable for
ICL. Extensive experiments on four held-out datasets validate our framework's
effectiveness, showing that models trained with our data achieve performance
gains of up to 63\% in average Dice and substantially enhanced generalization
to unseen anatomical domains. Our work helps mitigate the data bottleneck for
ICL-based segmentation, paving the way for robust models. Our code and the
generated dataset are publicly available at
https://github.com/jiesihu/Neuroverse3D.
\\ ( https://arxiv.org/abs/2509.19711 ,  2395kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19713
Date: Wed, 24 Sep 2025 02:50:55 GMT   (4134kb)

Title: VIMD: Monocular Visual-Inertial Motion and Depth Estimation
Authors: Saimouli Katragadda, Guoquan Huang
Categories: cs.CV cs.RO
\\
  Accurate and efficient dense metric depth estimation is crucial for 3D visual
perception in robotics and XR. In this paper, we develop a monocular
visual-inertial motion and depth (VIMD) learning framework to estimate dense
metric depth by leveraging accurate and efficient MSCKF-based monocular
visual-inertial motion tracking. At the core the proposed VIMD is to exploit
multi-view information to iteratively refine per-pixel scale, instead of
globally fitting an invariant affine model as in the prior work. The VIMD
framework is highly modular, making it compatible with a variety of existing
depth estimation backbones. We conduct extensive evaluations on the TartanAir
and VOID datasets and demonstrate its zero-shot generalization capabilities on
the AR Table dataset. Our results show that VIMD achieves exceptional accuracy
and robustness, even with extremely sparse points as few as 10-20 metric depth
points per image. This makes the proposed VIMD a practical solution for
deployment in resource constrained settings, while its robust performance and
strong generalization capabilities offer significant potential across a wide
range of scenarios.
\\ ( https://arxiv.org/abs/2509.19713 ,  4134kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19719
Date: Wed, 24 Sep 2025 03:02:38 GMT   (2380kb)

Title: Frequency-domain Multi-modal Fusion for Language-guided Medical Image
  Segmentation
Authors: Bo Yu, Jianhua Yang, Zetao Du, Yan Huang, Chenglong Li, Liang Wang
Categories: cs.CV
Comments: Accepted by MICCAI 2025
DOI: 10.1007/978-3-032-05114-1_27
\\
  Automatically segmenting infected areas in radiological images is essential
for diagnosing pulmonary infectious diseases. Recent studies have demonstrated
that the accuracy of the medical image segmentation can be improved by
incorporating clinical text reports as semantic guidance. However, the complex
morphological changes of lesions and the inherent semantic gap between
vision-language modalities prevent existing methods from effectively enhancing
the representation of visual features and eliminating semantically irrelevant
information, ultimately resulting in suboptimal segmentation performance. To
address these problems, we propose a Frequency-domain Multi-modal Interaction
model (FMISeg) for language-guided medical image segmentation. FMISeg is a late
fusion model that establishes interaction between linguistic features and
frequency-domain visual features in the decoder. Specifically, to enhance the
visual representation, our method introduces a Frequency-domain Feature
Bidirectional Interaction (FFBI) module to effectively fuse frequency-domain
features. Furthermore, a Language-guided Frequency-domain Feature Interaction
(LFFI) module is incorporated within the decoder to suppress semantically
irrelevant visual features under the guidance of linguistic information.
Experiments on QaTa-COV19 and MosMedData+ demonstrated that our method
outperforms the state-of-the-art methods qualitatively and quantitatively.
\\ ( https://arxiv.org/abs/2509.19719 ,  2380kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19726
Date: Wed, 24 Sep 2025 03:09:52 GMT   (4783kb)

Title: PolGS: Polarimetric Gaussian Splatting for Fast Reflective Surface
  Reconstruction
Authors: Yufei Han, Bowen Tie, Heng Guo, Youwei Lyu, Si Li, Boxin Shi, Yunpeng
  Jia, Zhanyu Ma
Categories: cs.CV
Comments: Accepted by ICCV 2025
\\
  Efficient shape reconstruction for surfaces with complex reflectance
properties is crucial for real-time virtual reality. While 3D Gaussian
Splatting (3DGS)-based methods offer fast novel view rendering by leveraging
their explicit surface representation, their reconstruction quality lags behind
that of implicit neural representations, particularly in the case of recovering
surfaces with complex reflective reflectance. To address these problems, we
propose PolGS, a Polarimetric Gaussian Splatting model allowing fast reflective
surface reconstruction in 10 minutes. By integrating polarimetric constraints
into the 3DGS framework, PolGS effectively separates specular and diffuse
components, enhancing reconstruction quality for challenging reflective
materials. Experimental results on the synthetic and real-world dataset
validate the effectiveness of our method.
\\ ( https://arxiv.org/abs/2509.19726 ,  4783kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19731
Date: Wed, 24 Sep 2025 03:20:44 GMT   (22027kb)

Title: CAMILA: Context-Aware Masking for Image Editing with Language Alignment
Authors: Hyunseung Kim, Chiho Choi, Srikanth Malla, Sai Prahladh Padmanabhan,
  Saurabh Bagchi, Joon Hee Choi
Categories: cs.CV
\\
  Text-guided image editing has been allowing users to transform and synthesize
images through natural language instructions, offering considerable
flexibility. However, most existing image editing models naively attempt to
follow all user instructions, even if those instructions are inherently
infeasible or contradictory, often resulting in nonsensical output. To address
these challenges, we propose a context-aware method for image editing named as
CAMILA (Context-Aware Masking for Image Editing with Language Alignment).
CAMILA is designed to validate the contextual coherence between instructions
and the image, ensuring that only relevant edits are applied to the designated
regions while ignoring non-executable instructions. For comprehensive
evaluation of this new method, we constructed datasets for both single- and
multi-instruction image editing, incorporating the presence of infeasible
requests. Our method achieves better performance and higher semantic alignment
than state-of-the-art models, demonstrating its effectiveness in handling
complex instruction challenges while preserving image integrity.
\\ ( https://arxiv.org/abs/2509.19731 ,  22027kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19733
Date: Wed, 24 Sep 2025 03:26:25 GMT   (2221kb)

Title: Robust RGB-T Tracking via Learnable Visual Fourier Prompt Fine-tuning
  and Modality Fusion Prompt Generation
Authors: Hongtao Yang, Bineng Zhong, Qihua Liang, Zhiruo Zhu, Yaozong Zheng,
  Ning Li
Categories: cs.CV
Comments: Accepted by TMM2025
\\
  Recently, visual prompt tuning is introduced to RGB-Thermal (RGB-T) tracking
as a parameter-efficient finetuning (PEFT) method. However, these PEFT-based
RGB-T tracking methods typically rely solely on spatial domain information as
prompts for feature extraction. As a result, they often fail to achieve optimal
performance by overlooking the crucial role of frequency-domain information in
prompt learning. To address this issue, we propose an efficient Visual Fourier
Prompt Tracking (named VFPTrack) method to learn modality-related prompts via
Fast Fourier Transform (FFT). Our method consists of symmetric feature
extraction encoder with shared parameters, visual fourier prompts, and Modality
Fusion Prompt Generator that generates bidirectional interaction prompts
through multi-modal feature fusion. Specifically, we first use a frozen feature
extraction encoder to extract RGB and thermal infrared (TIR) modality features.
Then, we combine the visual prompts in the spatial domain with the frequency
domain prompts obtained from the FFT, which allows for the full extraction and
understanding of modality features from different domain information. Finally,
unlike previous fusion methods, the modality fusion prompt generation module we
use combines features from different modalities to generate a fused modality
prompt. This modality prompt is interacted with each individual modality to
fully enable feature interaction across different modalities. Extensive
experiments conducted on three popular RGB-T tracking benchmarks show that our
method demonstrates outstanding performance.
\\ ( https://arxiv.org/abs/2509.19733 ,  2221kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19743
Date: Wed, 24 Sep 2025 03:47:04 GMT   (14094kb)

Title: Rectified Decoupled Dataset Distillation: A Closer Look for Fair and
  Comprehensive Evaluation
Authors: Xinhao Zhong, Shuoyang Sun, Xulin Gu, Chenyang Zhu, Bin Chen, Yaowei
  Wang
Categories: cs.CV
\\
  Dataset distillation aims to generate compact synthetic datasets that enable
models trained on them to achieve performance comparable to those trained on
full real datasets, while substantially reducing storage and computational
costs. Early bi-level optimization methods (e.g., MTT) have shown promising
results on small-scale datasets, but their scalability is limited by high
computational overhead. To address this limitation, recent decoupled dataset
distillation methods (e.g., SRe$^2$L) separate the teacher model pre-training
from the synthetic data generation process. These methods also introduce random
data augmentation and epoch-wise soft labels during the post-evaluation phase
to improve performance and generalization. However, existing decoupled
distillation methods suffer from inconsistent post-evaluation protocols, which
hinders progress in the field. In this work, we propose Rectified Decoupled
Dataset Distillation (RD$^3$), and systematically investigate how different
post-evaluation settings affect test accuracy. We further examine whether the
reported performance differences across existing methods reflect true
methodological advances or stem from discrepancies in evaluation procedures.
Our analysis reveals that much of the performance variation can be attributed
to inconsistent evaluation rather than differences in the intrinsic quality of
the synthetic data. In addition, we identify general strategies that improve
the effectiveness of distilled datasets across settings. By establishing a
standardized benchmark and rigorous evaluation protocol, RD$^3$ provides a
foundation for fair and reproducible comparisons in future dataset distillation
research.
\\ ( https://arxiv.org/abs/2509.19743 ,  14094kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19746
Date: Wed, 24 Sep 2025 03:55:44 GMT   (1378kb)

Title: nnFilterMatch: A Unified Semi-Supervised Learning Framework with
  Uncertainty-Aware Pseudo-Label Filtering for Efficient Medical Segmentation
Authors: Yi Yang
Categories: cs.CV
\\
  Semi-supervised learning (SSL) has emerged as a promising paradigm in medical
image segmentation, offering competitive performance while substantially
reducing the need for extensive manual annotation. When combined with active
learning (AL), these strategies further minimize annotation burden by
selectively incorporating the most informative samples. However, conventional
SSL_AL hybrid approaches often rely on iterative and loop-based retraining
cycles after each annotation round, incurring significant computational
overhead and limiting scalability in clinical applications. In this study, we
present a novel, annotation-efficient, and self-adaptive deep segmentation
framework that integrates SSL with entropy-based pseudo-label filtering
(FilterMatch), an AL-inspired mechanism, within the single-pass nnU-Net
training segmentation framework (nnFilterMatch). By selectively excluding
high-confidence pseudo-labels during training, our method circumvents the need
for retraining loops while preserving the benefits of uncertainty-guided
learning. We validate the proposed framework across multiple clinical
segmentation benchmarks and demonstrate that it achieves performance comparable
to or exceeding fully supervised models, even with only 5\%--20\% labeled data.
This work introduces a scalable, end-to-end learning strategy for reducing
annotation demands in medical image segmentation without compromising accuracy.
Code is available here: https://github.com/Ordi117/nnFilterMatch.git.
\\ ( https://arxiv.org/abs/2509.19746 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19749
Date: Wed, 24 Sep 2025 04:01:57 GMT   (8171kb)

Title: Talking Head Generation via AU-Guided Landmark Prediction
Authors: Shao-Yu Chang, Jingyi Xu, Hieu Le, Dimitris Samaras
Categories: cs.CV
\\
  We propose a two-stage framework for audio-driven talking head generation
with fine-grained expression control via facial Action Units (AUs). Unlike
prior methods relying on emotion labels or implicit AU conditioning, our model
explicitly maps AUs to 2D facial landmarks, enabling physically grounded,
per-frame expression control. In the first stage, a variational motion
generator predicts temporally coherent landmark sequences from audio and AU
intensities. In the second stage, a diffusion-based synthesizer generates
realistic, lip-synced videos conditioned on these landmarks and a reference
image. This separation of motion and appearance improves expression accuracy,
temporal stability, and visual realism. Experiments on the MEAD dataset show
that our method outperforms state-of-the-art baselines across multiple metrics,
demonstrating the effectiveness of explicit AU-to-landmark modeling for
expressive talking head generation.
\\ ( https://arxiv.org/abs/2509.19749 ,  8171kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19753
Date: Wed, 24 Sep 2025 04:08:19 GMT   (373kb)

Title: ExpFace: Exponential Angular Margin Loss for Deep Face Recognition
Authors: Jinhui Zheng, Xueyuan Gong
Categories: cs.CV cs.AI
\\
  Face recognition is an open-set problem requiring high discriminative power
to ensure that intra-class distances remain smaller than inter-class distances.
Margin-based softmax losses, such as SphereFace, CosFace, and ArcFace, have
been widely adopted to enhance intra-class compactness and inter-class
separability, yet they overlook the impact of noisy samples. By examining the
distribution of samples in the angular space, we observe that clean samples
predominantly cluster in the center region, whereas noisy samples tend to shift
toward the peripheral region. Motivated by this observation, we propose the
Exponential Angular Margin Loss (ExpFace), which introduces an angular
exponential term as the margin. This design applies a larger penalty in the
center region and a smaller penalty in the peripheral region within the angular
space, thereby emphasizing clean samples while suppressing noisy samples. We
present a unified analysis of ExpFace and classical margin-based softmax losses
in terms of margin embedding forms, similarity curves, and gradient curves,
showing that ExpFace not only avoids the training instability of SphereFace and
the non-monotonicity of ArcFace, but also exhibits a similarity curve that
applies penalties in the same manner as the decision boundary in the angular
space. Extensive experiments demonstrate that ExpFace achieves state-of-the-art
performance. To facilitate future research, we have released the source code
at: https://github.com/dfr-code/ExpFace.
\\ ( https://arxiv.org/abs/2509.19753 ,  373kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19760
Date: Wed, 24 Sep 2025 04:54:37 GMT   (9296kb)

Title: Logics-Parsing Technical Report
Authors: Xiangyang Chen, Shuzhao Li, Xiuwen Zhu, Yongfan Chen, Fan Yang, Cheng
  Fang, Lin Qu, Xiaoxiao Xu, Hu Wei, Minggang Wu
Categories: cs.CV
\\
  Recent advances in Large Vision-Language models (LVLM) have spurred
significant progress in document parsing task. Compared to traditional
pipeline-based methods, end-to-end paradigms have shown their excellence in
converting PDF images into structured outputs through integrated Optical
Character Recognition (OCR), table recognition, mathematical formula
recognition and so on. However, the absence of explicit analytical stages for
document layouts and reading orders limits the LVLM's capability in handling
complex document types such as multi-column newspapers or posters. To address
this limitation, we propose in this report Logics-Parsing: an end-to-end
LVLM-based model augmented with reinforcement learning. Our model incorporates
meticulously designed reward mechanisms to optimize complex layout analysis and
reading order inference. In addition, we expand the model's versatility by
incorporating diverse data types such as chemical formulas and handwritten
Chinese characters into supervised fine-tuning. Finally, to enable rigorous
evaluation of our approach, we introduce LogicsParsingBench, a curated set of
1,078 page-level PDF images spanning nine major categories and over twenty
sub-categories, which will be released later. Comprehensive experiments
conducted on LogicsParsingBench have validated the efficacy and
State-of-the-art (SOTA) performance of our proposed model across diverse
document analysis scenarios. Project Page:
https://github.com/alibaba/Logics-Parsing
\\ ( https://arxiv.org/abs/2509.19760 ,  9296kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19778
Date: Wed, 24 Sep 2025 06:00:37 GMT   (323kb)

Title: Sex-based Bias Inherent in the Dice Similarity Coefficient: A Model
  Independent Analysis for Multiple Anatomical Structures
Authors: Hartmut H\"antze, Myrthe Buser, Alessa Hering, Lisa C. Adams, Keno K.
  Bressem
Categories: cs.CV
ACM-class: J.3
Journal-ref: Fairness of AI in Medical Imaging. FAIMI 2025. Lecture Notes in
  Computer Science, vol 15976
DOI: 10.1007/978-3-032-05870-6_13
\\
  Overlap-based metrics such as the Dice Similarity Coefficient (DSC) penalize
segmentation errors more heavily in smaller structures. As organ size differs
by sex, this implies that a segmentation error of equal magnitude may result in
lower DSCs in women due to their smaller average organ volumes compared to men.
While previous work has examined sex-based differences in models or datasets,
no study has yet investigated the potential bias introduced by the DSC itself.
This study quantifies sex-based differences of the DSC and the normalized DSC
in an idealized setting independent of specific models. We applied
equally-sized synthetic errors to manual MRI annotations from 50 participants
to ensure sex-based comparability. Even minimal errors (e.g., a 1 mm boundary
shift) produced systematic DSC differences between sexes. For small structures,
average DSC differences were around 0.03; for medium-sized structures around
0.01. Only large structures (i.e., lungs and liver) were mostly unaffected,
with sex-based DSC differences close to zero. These findings underline that
fairness studies using the DSC as an evaluation metric should not expect
identical scores between men and women, as the metric itself introduces bias. A
segmentation model may perform equally well across sexes in terms of error
magnitude, even if observed DSC values suggest otherwise. Importantly, our work
raises awareness of a previously underexplored source of sex-based differences
in segmentation performance. One that arises not from model behavior, but from
the metric itself. Recognizing this factor is essential for more accurate and
fair evaluations in medical image analysis.
\\ ( https://arxiv.org/abs/2509.19778 ,  323kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19779
Date: Wed, 24 Sep 2025 06:01:37 GMT   (12859kb)

Title: EfficienT-HDR: An Efficient Transformer-Based Framework via
  Multi-Exposure Fusion for HDR Reconstruction
Authors: Yu-Shen Huang, Tzu-Han Chen, Cheng-Yen Hsiao, and Shaou-Gang Miaou
Categories: cs.CV
Comments: 10 pages, 9 figures
\\
  Achieving high-quality High Dynamic Range (HDR) imaging on
resource-constrained edge devices is a critical challenge in computer vision,
as its performance directly impacts downstream tasks such as intelligent
surveillance and autonomous driving. Multi-Exposure Fusion (MEF) is a
mainstream technique to achieve this goal; however, existing methods generally
face the dual bottlenecks of high computational costs and ghosting artifacts,
hindering their widespread deployment. To this end, this study proposes a
light-weight Vision Transformer architecture designed explicitly for HDR
reconstruction to overcome these limitations. This study is based on the
Context-Aware Vision Transformer and begins by converting input images to the
YCbCr color space to separate luminance and chrominance information. It then
employs an Intersection-Aware Adaptive Fusion (IAAF) module to suppress
ghosting effectively. To further achieve a light-weight design, we introduce
Inverted Residual Embedding (IRE), Dynamic Tanh (DyT), and propose Enhanced
Multi-Scale Dilated Convolution (E-MSDC) to reduce computational complexity at
multiple levels. Our study ultimately contributes two model versions: a main
version for high visual quality and a light-weight version with advantages in
computational efficiency, both of which achieve an excellent balance between
performance and image quality. Experimental results demonstrate that, compared
to the baseline, the main version reduces FLOPS by approximately 67% and
increases inference speed by more than fivefold on CPU and 2.5 times on an edge
device. These results confirm that our method provides an efficient and
ghost-free HDR imaging solution for edge devices, demonstrating versatility and
practicality across various dynamic scenarios.
\\ ( https://arxiv.org/abs/2509.19779 ,  12859kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19793
Date: Wed, 24 Sep 2025 06:27:15 GMT   (1883kb)

Title: BiTAA: A Bi-Task Adversarial Attack for Object Detection and Depth
  Estimation via 3D Gaussian Splatting
Authors: Yixun Zhang, Feng Zhou and Jianqin Yin
Categories: cs.CV
Comments: Intend to submit to RA-L
\\
  Camera-based perception is critical to autonomous driving yet remains
vulnerable to task-specific adversarial manipulations in object detection and
monocular depth estimation. Most existing 2D/3D attacks are developed in task
silos, lack mechanisms to induce controllable depth bias, and offer no
standardized protocol to quantify cross-task transfer, leaving the interaction
between detection and depth underexplored. We present BiTAA, a bi-task
adversarial attack built on 3D Gaussian Splatting that yields a single
perturbation capable of simultaneously degrading detection and biasing
monocular depth. Specifically, we introduce a dual-model attack framework that
supports both full-image and patch settings and is compatible with common
detectors and depth estimators, with optional expectation-over-transformation
(EOT) for physical reality. In addition, we design a composite loss that
couples detection suppression with a signed, magnitude-controlled log-depth
bias within regions of interest (ROIs) enabling controllable near or far
misperception while maintaining stable optimization across tasks. We also
propose a unified evaluation protocol with cross-task transfer metrics and
real-world evaluations, showing consistent cross-task degradation and a clear
asymmetry between Det to Depth and from Depth to Det transfer. The results
highlight practical risks for multi-task camera-only perception and motivate
cross-task-aware defenses in autonomous driving scenarios.
\\ ( https://arxiv.org/abs/2509.19793 ,  1883kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19805
Date: Wed, 24 Sep 2025 06:42:32 GMT   (6280kb)

Title: StrCGAN: A Generative Framework for Stellar Image Restoration
Authors: Shantanusinh Parmar
Categories: cs.CV astro-ph.IM astro-ph.SR
\\
  We introduce StrCGAN (Stellar Cyclic GAN), a generative model designed to
enhance low-resolution astrophotography images. Our goal is to reconstruct
high-fidelity ground truth-like representations of celestial objects, a task
that is challenging due to the limited resolution and quality of
small-telescope observations such as the MobilTelesco dataset. Traditional
models such as CycleGAN provide a foundation for image-to-image translation but
are restricted to 2D mappings and often distort the morphology of stars and
galaxies. To overcome these limitations, we extend the CycleGAN framework with
three key innovations: 3D convolutional layers to capture volumetric spatial
correlations, multi-spectral fusion to align optical and near-infrared (NIR)
domains, and astrophysical regularization modules to preserve stellar
morphology. Ground-truth references from multi-mission all-sky surveys spanning
optical to NIR guide the training process, ensuring that reconstructions remain
consistent across spectral bands. Together, these components allow StrCGAN to
generate reconstructions that are not only visually sharper but also physically
consistent, outperforming standard GAN models in the task of astrophysical
image enhancement.
\\ ( https://arxiv.org/abs/2509.19805 ,  6280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19819
Date: Wed, 24 Sep 2025 07:01:49 GMT   (297kb)

Title: Adaptive Model Ensemble for Continual Learning
Authors: Yuchuan Mao, Zhi Gao, Xiaomeng Fan, Yuwei Wu, Yunde Jia, Chenchen Jing
Categories: cs.CV
\\
  Model ensemble is an effective strategy in continual learning, which
alleviates catastrophic forgetting by interpolating model parameters, achieving
knowledge fusion learned from different tasks. However, existing model ensemble
methods usually encounter the knowledge conflict issue at task and layer
levels, causing compromised learning performance in both old and new tasks. To
solve this issue, we propose meta-weight-ensembler that adaptively fuses
knowledge of different tasks for continual learning. Concretely, we employ a
mixing coefficient generator trained via meta-learning to generate appropriate
mixing coefficients for model ensemble to address the task-level knowledge
conflict. The mixing coefficient is individually generated for each layer to
address the layer-level knowledge conflict. In this way, we learn the prior
knowledge about adaptively accumulating knowledge of different tasks in a fused
model, achieving efficient learning in both old and new tasks.
Meta-weight-ensembler can be flexibly combined with existing continual learning
methods to boost their ability of alleviating catastrophic forgetting.
Experiments on multiple continual learning datasets show that
meta-weight-ensembler effectively alleviates catastrophic forgetting and
achieves state-of-the-art performance.
\\ ( https://arxiv.org/abs/2509.19819 ,  297kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19841
Date: Wed, 24 Sep 2025 07:34:09 GMT   (16835kb)

Title: ThinkFake: Reasoning in Multimodal Large Language Models for
  AI-Generated Image Detection
Authors: Tai-Ming Huang, Wei-Tung Lin, Kai-Lung Hua, Wen-Huang Cheng, Junichi
  Yamagishi, Jun-Cheng Chen
Categories: cs.CV
\\
  The increasing realism of AI-generated images has raised serious concerns
about misinformation and privacy violations, highlighting the urgent need for
accurate and interpretable detection methods. While existing approaches have
made progress, most rely on binary classification without explanations or
depend heavily on supervised fine-tuning, resulting in limited generalization.
In this paper, we propose ThinkFake, a novel reasoning-based and generalizable
framework for AI-generated image detection. Our method leverages a Multimodal
Large Language Model (MLLM) equipped with a forgery reasoning prompt and is
trained using Group Relative Policy Optimization (GRPO) reinforcement learning
with carefully designed reward functions. This design enables the model to
perform step-by-step reasoning and produce interpretable, structured outputs.
We further introduce a structured detection pipeline to enhance reasoning
quality and adaptability. Extensive experiments show that ThinkFake outperforms
state-of-the-art methods on the GenImage benchmark and demonstrates strong
zero-shot generalization on the challenging LOKI benchmark. These results
validate our framework's effectiveness and robustness. Code will be released
upon acceptance.
\\ ( https://arxiv.org/abs/2509.19841 ,  16835kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19843
Date: Wed, 24 Sep 2025 07:39:16 GMT   (4458kb)

Title: PersONAL: Towards a Comprehensive Benchmark for Personalized Embodied
  Agents
Authors: Filippo Ziliotto, Jelin Raphael Akkara, Alessandro Daniele, Lamberto
  Ballan, Luciano Serafini, Tommaso Campari
Categories: cs.CV cs.RO
\\
  Recent advances in Embodied AI have enabled agents to perform increasingly
complex tasks and adapt to diverse environments. However, deploying such agents
in realistic human-centered scenarios, such as domestic households, remains
challenging, particularly due to the difficulty of modeling individual human
preferences and behaviors. In this work, we introduce PersONAL (PERSonalized
Object Navigation And Localization, a comprehensive benchmark designed to study
personalization in Embodied AI. Agents must identify, retrieve, and navigate to
objects associated with specific users, responding to natural-language queries
such as "find Lily's backpack". PersONAL comprises over 2,000 high-quality
episodes across 30+ photorealistic homes from the HM3D dataset. Each episode
includes a natural-language scene description with explicit associations
between objects and their owners, requiring agents to reason over user-specific
semantics. The benchmark supports two evaluation modes: (1) active navigation
in unseen environments, and (2) object grounding in previously mapped scenes.
Experiments with state-of-the-art baselines reveal a substantial gap to human
performance, highlighting the need for embodied agents capable of perceiving,
reasoning, and memorizing over personalized information; paving the way towards
real-world assistive robot.
\\ ( https://arxiv.org/abs/2509.19843 ,  4458kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19870
Date: Wed, 24 Sep 2025 08:15:28 GMT   (1388kb)

Title: FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models
Authors: Xin Wang, Jie Li, Zejia Weng, Yixu Wang, Yifeng Gao, Tianyu Pang, Chao
  Du, Yan Teng, Yingchun Wang, Zuxuan Wu, Xingjun Ma, Yu-Gang Jiang
Categories: cs.CV
\\
  Vision-Language-Action (VLA) models are driving rapid progress in robotics by
enabling agents to interpret multimodal inputs and execute complex,
long-horizon tasks. However, their safety and robustness against adversarial
attacks remain largely underexplored. In this work, we identify and formalize a
critical adversarial vulnerability in which adversarial images can "freeze" VLA
models and cause them to ignore subsequent instructions. This threat
effectively disconnects the robot's digital mind from its physical actions,
potentially inducing inaction during critical interventions. To systematically
study this vulnerability, we propose FreezeVLA, a novel attack framework that
generates and evaluates action-freezing attacks via min-max bi-level
optimization. Experiments on three state-of-the-art VLA models and four robotic
benchmarks show that FreezeVLA attains an average attack success rate of 76.2%,
significantly outperforming existing methods. Moreover, adversarial images
generated by FreezeVLA exhibit strong transferability, with a single image
reliably inducing paralysis across diverse language prompts. Our findings
expose a critical safety risk in VLA models and highlight the urgent need for
robust defense mechanisms.
\\ ( https://arxiv.org/abs/2509.19870 ,  1388kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19875
Date: Wed, 24 Sep 2025 08:25:37 GMT   (1191kb)

Title: Adaptive Guidance Semantically Enhanced via Multimodal LLM for
  Edge-Cloud Object Detection
Authors: Yunqing Hu, Zheming Yang, Chang Zhao, Wen Ji
Categories: cs.CV cs.AI
\\
  Traditional object detection methods face performance degradation challenges
in complex scenarios such as low-light conditions and heavy occlusions due to a
lack of high-level semantic understanding. To address this, this paper proposes
an adaptive guidance-based semantic enhancement edge-cloud collaborative object
detection method leveraging Multimodal Large Language Models (MLLM), achieving
an effective balance between accuracy and efficiency. Specifically, the method
first employs instruction fine-tuning to enable the MLLM to generate structured
scene descriptions. It then designs an adaptive mapping mechanism that
dynamically converts semantic information into parameter adjustment signals for
edge detectors, achieving real-time semantic enhancement. Within an edge-cloud
collaborative inference framework, the system automatically selects between
invoking cloud-based semantic guidance or directly outputting edge detection
results based on confidence scores. Experiments demonstrate that the proposed
method effectively enhances detection accuracy and efficiency in complex
scenes. Specifically, it can reduce latency by over 79% and computational cost
by 70% in low-light and highly occluded scenes while maintaining accuracy.
\\ ( https://arxiv.org/abs/2509.19875 ,  1191kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19895
Date: Wed, 24 Sep 2025 08:47:34 GMT   (47831kb)

Title: Generalized Shortest Path-based Superpixels for 3D Spherical Image
  Segmentation
Authors: R\'emi Giraud, Rodrigo Borba Pinheiro, Yannick Berthoumieu
Categories: cs.CV
Journal-ref: Pattern Recognition 2023
\\
  The growing use of wide angle image capture devices and the need for fast and
accurate image analysis in computer visions have enforced the need for
dedicated under-representation approaches. Most recent decomposition methods
segment an image into a small number of irregular homogeneous regions, called
superpixels. Nevertheless, these approaches are generally designed to segment
standard 2D planar images, i.e., captured with a 90o angle view without
distortion. In this work, we introduce a new general superpixel method called
SphSPS (for Spherical Shortest Path-based Superpixels)1 , dedicated to wide
360o spherical or omnidirectional images. Our method respects the geometry of
the 3D spherical acquisition space and generalizes the notion of shortest path
between a pixel and a superpixel center, to fastly extract relevant clustering
features. We demonstrate that considering the geometry of the acquisition space
to compute the shortest path enables to jointly improve the segmentation
accuracy and the shape regularity of superpixels. To evaluate this regularity
aspect, we also generalize a global regularity metric to the spherical space,
addressing the limitations of the only existing spherical compactness measure.
Finally, the proposed SphSPS method is validated on the reference 360o
spherical panorama segmentation dataset and on synthetic road omnidirectional
images. Our method significantly outperforms both planar and spherical
state-of-the-art approaches in terms of segmentation accuracy,robustness to
noise and regularity, providing a very interesting tool for superpixel-based
applications on 360o images.
\\ ( https://arxiv.org/abs/2509.19895 ,  47831kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19896
Date: Wed, 24 Sep 2025 08:48:29 GMT   (909kb)

Title: Efficient Cell Painting Image Representation Learning via Cross-Well
  Aligned Masked Siamese Network
Authors: Pin-Jui Huang, Yu-Hsuan Liao, SooHeon Kim, NoSeong Park, JongBae Park,
  DongMyung Shin
Categories: cs.CV
Comments: 9 pages, 3 figures, reference 4 pages
\\
  Computational models that predict cellular phenotypic responses to chemical
and genetic perturbations can accelerate drug discovery by prioritizing
therapeutic hypotheses and reducing costly wet-lab iteration. However,
extracting biologically meaningful and batch-robust cell painting
representations remains challenging. Conventional self-supervised and
contrastive learning approaches often require a large-scale model and/or a huge
amount of carefully curated data, still struggling with batch effects. We
present Cross-Well Aligned Masked Siamese Network (CWA-MSN), a novel
representation learning framework that aligns embeddings of cells subjected to
the same perturbation across different wells, enforcing semantic consistency
despite batch effects. Integrated into a masked siamese architecture, this
alignment yields features that capture fine-grained morphology while remaining
data- and parameter-efficient. For instance, in a gene-gene relationship
retrieval benchmark, CWA-MSN outperforms the state-of-the-art publicly
available self-supervised (OpenPhenom) and contrastive learning (CellCLIP)
methods, improving the benchmark scores by +29\% and +9\%, respectively, while
training on substantially fewer data (e.g., 0.2M images for CWA-MSN vs. 2.2M
images for OpenPhenom) or smaller model size (e.g., 22M parameters for CWA-MSN
vs. 1.48B parameters for CellCLIP). Extensive experiments demonstrate that
CWA-MSN is a simple and effective way to learn cell image representation,
enabling efficient phenotype modeling even under limited data and parameter
budgets.
\\ ( https://arxiv.org/abs/2509.19896 ,  909kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19898
Date: Wed, 24 Sep 2025 08:50:13 GMT   (20288kb)

Title: Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based
  Intermediate View Rendering
Authors: Jiangxue Yu, Hui Wang, San Jiang, Xing Zhang, Dejin Zhang, Qingquan Li
Categories: cs.CV
\\
  The integration of aerial and ground images has been a promising solution in
3D modeling of complex scenes, which is seriously restricted by finding
reliable correspondences. The primary contribution of this study is a feature
matching algorithm for aerial and ground images, whose core idea is to generate
intermediate views to alleviate perspective distortions caused by the extensive
viewpoint changes. First, by using aerial images only, sparse models are
reconstructed through an incremental SfM (Structure from Motion) engine due to
their large scene coverage. Second, 3D Gaussian Splatting is then adopted for
scene rendering by taking as inputs sparse points and oriented images. For
accurate view rendering, a render viewpoint determination algorithm is designed
by using the oriented camera poses of aerial images, which is used to generate
high-quality intermediate images that can bridge the gap between aerial and
ground images. Third, with the aid of intermediate images, reliable feature
matching is conducted for match pairs from render-aerial and render-ground
images, and final matches can be generated by transmitting correspondences
through intermediate views. By using real aerial and ground datasets, the
validation of the proposed solution has been verified in terms of feature
matching and scene rendering and compared comprehensively with widely used
methods. The experimental results demonstrate that the proposed solution can
provide reliable feature matches for aerial and ground images with an obvious
increase in the number of initial and refined matches, and it can provide
enough matches to achieve accurate ISfM reconstruction and complete 3DGS-based
scene rendering.
\\ ( https://arxiv.org/abs/2509.19898 ,  20288kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19936
Date: Wed, 24 Sep 2025 09:43:34 GMT   (16287kb)

Title: CapStARE: Capsule-based Spatiotemporal Architecture for Robust and
  Efficient Gaze Estimation
Authors: Miren Samaniego, Igor Rodriguez and Elena Lazkano
Categories: cs.CV
\\
  We introduce CapStARE, a capsule-based spatio-temporal architecture for gaze
estimation that integrates a ConvNeXt backbone, capsule formation with
attention routing, and dual GRU decoders specialized for slow and rapid gaze
dynamics. This modular design enables efficient part-whole reasoning and
disentangled temporal modeling, achieving state-of-the-art performance on
ETH-XGaze (3.36) and MPIIFaceGaze (2.65) while maintaining real-time inference
(< 10 ms). The model also generalizes well to unconstrained conditions in
Gaze360 (9.06) and human-robot interaction scenarios in RT-GENE (4.76),
outperforming or matching existing methods with fewer parameters and greater
interpretability. These results demonstrate that CapStARE offers a practical
and robust solution for real-time gaze estimation in interactive systems. The
related code and results for this article can be found on:
https://github.com/toukapy/capsStare
\\ ( https://arxiv.org/abs/2509.19936 ,  16287kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19937
Date: Wed, 24 Sep 2025 09:44:37 GMT   (43839kb)

Title: GS-RoadPatching: Inpainting Gaussians via 3D Searching and Placing for
  Driving Scenes
Authors: Guo Chen, Jiarun Liu, Sicong Du, Chenming Wu, Deqi Li, Shi-Sheng
  Huang, Guofeng Zhang, Sheng Yang
Categories: cs.CV
DOI: 10.1145/3757377.3763892
\\
  This paper presents GS-RoadPatching, an inpainting method for driving scene
completion by referring to completely reconstructed regions, which are
represented by 3D Gaussian Splatting (3DGS). Unlike existing 3DGS inpainting
methods that perform generative completion relying on 2D perspective-view-based
diffusion or GAN models to predict limited appearance or depth cues for missing
regions, our approach enables substitutional scene inpainting and editing
directly through the 3DGS modality, extricating it from requiring
spatial-temporal consistency of 2D cross-modals and eliminating the need for
time-intensive retraining of Gaussians. Our key insight is that the highly
repetitive patterns in driving scenes often share multi-modal similarities
within the implicit 3DGS feature space and are particularly suitable for
structural matching to enable effective 3DGS-based substitutional inpainting.
Practically, we construct feature-embedded 3DGS scenes to incorporate a patch
measurement method for abstracting local context at different scales and,
subsequently, propose a structural search method to find candidate patches in
3D space effectively. Finally, we propose a simple yet effective
substitution-and-fusion optimization for better visual harmony. We conduct
extensive experiments on multiple publicly available datasets to demonstrate
the effectiveness and efficiency of our proposed method in driving scenes, and
the results validate that our method achieves state-of-the-art performance
compared to the baseline methods in terms of both quality and interoperability.
Additional experiments in general scenes also demonstrate the applicability of
the proposed 3D inpainting strategy. The project page and code are available
at: https://shanzhaguoo.github.io/GS-RoadPatching/
\\ ( https://arxiv.org/abs/2509.19937 ,  43839kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19943
Date: Wed, 24 Sep 2025 09:50:01 GMT   (6535kb)

Title: Interpreting ResNet-based CLIP via Neuron-Attention Decomposition
Authors: Edmund Bu and Yossi Gandelsman
Categories: cs.CV cs.AI
Comments: NeurIPS 2025 Workshop on Mechanistic Interpretability
\\
  We present a novel technique for interpreting the neurons in CLIP-ResNet by
decomposing their contributions to the output into individual computation
paths. More specifically, we analyze all pairwise combinations of neurons and
the following attention heads of CLIP's attention-pooling layer. We find that
these neuron-head pairs can be approximated by a single direction in
CLIP-ResNet's image-text embedding space. Leveraging this insight, we interpret
each neuron-head pair by associating it with text. Additionally, we find that
only a sparse set of the neuron-head pairs have a significant contribution to
the output value, and that some neuron-head pairs, while polysemantic,
represent sub-concepts of their corresponding neurons. We use these
observations for two applications. First, we employ the pairs for training-free
semantic segmentation, outperforming previous methods for CLIP-ResNet. Second,
we utilize the contributions of neuron-head pairs to monitor dataset
distribution shifts. Our results demonstrate that examining individual
computation paths in neural networks uncovers interpretable units, and that
such units can be utilized for downstream tasks.
\\ ( https://arxiv.org/abs/2509.19943 ,  6535kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19952
Date: Wed, 24 Sep 2025 10:00:05 GMT   (8373kb)

Title: When Words Can't Capture It All: Towards Video-Based User Complaint Text
  Generation with Multimodal Video Complaint Dataset
Authors: Sarmistha Das, R E Zera Marveen Lyngkhoi, Kirtan Jain, Vinayak Goyal,
  Sriparna Saha, and Manish Gupta
Categories: cs.CV cs.AI
\\
  While there exists a lot of work on explainable complaint mining,
articulating user concerns through text or video remains a significant
challenge, often leaving issues unresolved. Users frequently struggle to
express their complaints clearly in text but can easily upload videos depicting
product defects (e.g., vague text such as `worst product' paired with a
5-second video depicting a broken headphone with the right earcup). This paper
formulates a new task in the field of complaint mining to aid the common users'
need to write an expressive complaint, which is Complaint Description from
Videos (CoD-V) (e.g., to help the above user articulate her complaint about the
defective right earcup). To this end, we introduce ComVID, a video complaint
dataset containing 1,175 complaint videos and the corresponding descriptions,
also annotated with the emotional state of the complainer. Additionally, we
present a new complaint retention (CR) evaluation metric that discriminates the
proposed (CoD-V) task against standard video summary generation and description
tasks. To strengthen this initiative, we introduce a multimodal
Retrieval-Augmented Generation (RAG) embedded VideoLLaMA2-7b model, designed to
generate complaints while accounting for the user's emotional state. We conduct
a comprehensive evaluation of several Video Language Models on several tasks
(pre-trained and fine-tuned versions) with a range of established evaluation
metrics, including METEOR, perplexity, and the Coleman-Liau readability score,
among others. Our study lays the foundation for a new research direction to
provide a platform for users to express complaints through video. Dataset and
resources are available at: https://github.com/sarmistha-D/CoD-V.
\\ ( https://arxiv.org/abs/2509.19952 ,  8373kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19965
Date: Wed, 24 Sep 2025 10:21:29 GMT   (17290kb)

Title: SynchroRaMa : Lip-Synchronized and Emotion-Aware Talking Face Generation
  via Multi-Modal Emotion Embedding
Authors: Phyo Thet Yee, Dimitrios Kollias, Sudeepta Mishra, Abhinav Dhall
Categories: cs.CV
Comments: Accepted at WACV 2026, project page :
  https://novicemm.github.io/synchrorama
\\
  Audio-driven talking face generation has received growing interest,
particularly for applications requiring expressive and natural human-avatar
interaction. However, most existing emotion-aware methods rely on a single
modality (either audio or image) for emotion embedding, limiting their ability
to capture nuanced affective cues. Additionally, most methods condition on a
single reference image, restricting the model's ability to represent dynamic
changes in actions or attributes across time. To address these issues, we
introduce SynchroRaMa, a novel framework that integrates a multi-modal emotion
embedding by combining emotional signals from text (via sentiment analysis) and
audio (via speech-based emotion recognition and audio-derived valence-arousal
features), enabling the generation of talking face videos with richer and more
authentic emotional expressiveness and fidelity. To ensure natural head motion
and accurate lip synchronization, SynchroRaMa includes an audio-to-motion (A2M)
module that generates motion frames aligned with the input audio. Finally,
SynchroRaMa incorporates scene descriptions generated by Large Language Model
(LLM) as additional textual input, enabling it to capture dynamic actions and
high-level semantic attributes. Conditioning the model on both visual and
textual cues enhances temporal consistency and visual realism. Quantitative and
qualitative experiments on benchmark datasets demonstrate that SynchroRaMa
outperforms the state-of-the-art, achieving improvements in image quality,
expression preservation, and motion realism. A user study further confirms that
SynchroRaMa achieves higher subjective ratings than competing methods in
overall naturalness, motion diversity, and video smoothness. Our project page
is available at <https://novicemm.github.io/synchrorama>.
\\ ( https://arxiv.org/abs/2509.19965 ,  17290kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19973
Date: Wed, 24 Sep 2025 10:28:06 GMT   (11073kb)

Title: OmniScene: Attention-Augmented Multimodal 4D Scene Understanding for
  Autonomous Driving
Authors: Pei Liu, Hongliang Lu, Haichao Liu, Haipeng Liu, Xin Liu, Ruoyu Yao,
  Shengbo Eben Li, Jun Ma
Categories: cs.CV
\\
  Human vision is capable of transforming two-dimensional observations into an
egocentric three-dimensional scene understanding, which underpins the ability
to translate complex scenes and exhibit adaptive behaviors. This capability,
however, remains lacking in current autonomous driving systems, where
mainstream approaches primarily rely on depth-based 3D reconstruction rather
than true scene understanding. To address this limitation, we propose a novel
human-like framework called OmniScene. First, we introduce the OmniScene
Vision-Language Model (OmniVLM), a vision-language framework that integrates
multi-view and temporal perception for holistic 4D scene understanding. Then,
harnessing a teacher-student OmniVLM architecture and knowledge distillation,
we embed textual representations into 3D instance features for semantic
supervision, enriching feature learning, and explicitly capturing human-like
attentional semantics. These feature representations are further aligned with
human driving behaviors, forming a more human-like
perception-understanding-action architecture. In addition, we propose a
Hierarchical Fusion Strategy (HFS) to address imbalances in modality
contributions during multimodal integration. Our approach adaptively calibrates
the relative significance of geometric and semantic features at multiple
abstraction levels, enabling the synergistic use of complementary cues from
visual and textual modalities. This learnable dynamic fusion enables a more
nuanced and effective exploitation of heterogeneous information. We evaluate
OmniScene comprehensively on the nuScenes dataset, benchmarking it against over
ten state-of-the-art models across various tasks. Our approach consistently
achieves superior results, establishing new benchmarks in perception,
prediction, planning, and visual question answering.
\\ ( https://arxiv.org/abs/2509.19973 ,  11073kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19979
Date: Wed, 24 Sep 2025 10:34:24 GMT   (6352kb)

Title: CamPVG: Camera-Controlled Panoramic Video Generation with Epipolar-Aware
  Diffusion
Authors: Chenhao Ji, Chaohui Yu, Junyao Gao, Fan Wang and Cairong Zhao
Categories: cs.CV
Comments: SIGGRAPH Asia 2025
\\
  Recently, camera-controlled video generation has seen rapid development,
offering more precise control over video generation. However, existing methods
predominantly focus on camera control in perspective projection video
generation, while geometrically consistent panoramic video generation remains
challenging. This limitation is primarily due to the inherent complexities in
panoramic pose representation and spherical projection. To address this issue,
we propose CamPVG, the first diffusion-based framework for panoramic video
generation guided by precise camera poses. We achieve camera position encoding
for panoramic images and cross-view feature aggregation based on spherical
projection. Specifically, we propose a panoramic Pl\"ucker embedding that
encodes camera extrinsic parameters through spherical coordinate
transformation. This pose encoder effectively captures panoramic geometry,
overcoming the limitations of traditional methods when applied to
equirectangular projections. Additionally, we introduce a spherical epipolar
module that enforces geometric constraints through adaptive attention masking
along epipolar lines. This module enables fine-grained cross-view feature
aggregation, substantially enhancing the quality and consistency of generated
panoramic videos. Extensive experiments demonstrate that our method generates
high-quality panoramic videos consistent with camera trajectories, far
surpassing existing methods in panoramic video generation.
\\ ( https://arxiv.org/abs/2509.19979 ,  6352kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19990
Date: Wed, 24 Sep 2025 10:50:44 GMT   (3008kb)

Title: SDE-DET: A Precision Network for Shatian Pomelo Detection in Complex
  Orchard Environments
Authors: Yihao Hu, Pan Wang, Xiaodong Bai, Shijie Cai, Hang Wang, Huazhong Liu,
  Aiping Yang, Xiangxiang Li, Meiping Ding, Hongyan Liu, Jianguo Yao
Categories: cs.CV cs.AI
\\
  Pomelo detection is an essential process for their localization, automated
robotic harvesting, and maturity analysis. However, detecting Shatian pomelo in
complex orchard environments poses significant challenges, including
multi-scale issues, obstructions from trunks and leaves, small object
detection, etc. To address these issues, this study constructs a custom dataset
STP-AgriData and proposes the SDE-DET model for Shatian pomelo detection.
SDE-DET first utilizes the Star Block to effectively acquire high-dimensional
information without increasing the computational overhead. Furthermore, the
presented model adopts Deformable Attention in its backbone, to enhance its
ability to detect pomelos under occluded conditions. Finally, multiple
Efficient Multi-Scale Attention mechanisms are integrated into our model to
reduce the computational overhead and extract deep visual representations,
thereby improving the capacity for small object detection. In the experiment,
we compared SDE-DET with the Yolo series and other mainstream detection models
in Shatian pomelo detection. The presented SDE-DET model achieved scores of
0.883, 0.771, 0.838, 0.497, and 0.823 in Precision, Recall, mAP@0.5,
mAP@0.5:0.95 and F1-score, respectively. SDE-DET has achieved state-of-the-art
performance on the STP-AgriData dataset. Experiments indicate that the SDE-DET
provides a reliable method for Shatian pomelo detection, laying the foundation
for the further development of automatic harvest robots.
\\ ( https://arxiv.org/abs/2509.19990 ,  3008kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19994
Date: Wed, 24 Sep 2025 11:00:43 GMT   (20215kb)

Title: Improving Generalizability and Undetectability for Targeted Adversarial
  Attacks on Multimodal Pre-trained Models
Authors: Zhifang Zhang, Jiahan Zhang, Shengjie Zhou, Qi Wei, Shuo He, Feng Liu,
  Lei Feng
Categories: cs.CV
\\
  Multimodal pre-trained models (e.g., ImageBind), which align distinct data
modalities into a shared embedding space, have shown remarkable success across
downstream tasks. However, their increasing adoption raises serious security
concerns, especially regarding targeted adversarial attacks. In this paper, we
show that existing targeted adversarial attacks on multimodal pre-trained
models still have limitations in two aspects: generalizability and
undetectability. Specifically, the crafted targeted adversarial examples (AEs)
exhibit limited generalization to partially known or semantically similar
targets in cross-modal alignment tasks (i.e., limited generalizability) and can
be easily detected by simple anomaly detection methods (i.e., limited
undetectability). To address these limitations, we propose a novel method
called Proxy Targeted Attack (PTA), which leverages multiple source-modal and
target-modal proxies to optimize targeted AEs, ensuring they remain evasive to
defenses while aligning with multiple potential targets. We also provide
theoretical analyses to highlight the relationship between generalizability and
undetectability and to ensure optimal generalizability while meeting the
specified requirements for undetectability. Furthermore, experimental results
demonstrate that our PTA can achieve a high success rate across various related
targets and remain undetectable against multiple anomaly detection methods.
\\ ( https://arxiv.org/abs/2509.19994 ,  20215kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19997
Date: Wed, 24 Sep 2025 11:02:56 GMT   (886kb)

Title: Anomaly Detection by Clustering DINO Embeddings using a Dirichlet
  Process Mixture
Authors: Nico Schulthess, Ender Konukoglu
Categories: cs.CV cs.LG
Comments: Paper accepted at MICCAI 2025
\\
  In this work, we leverage informative embeddings from foundational models for
unsupervised anomaly detection in medical imaging. For small datasets, a
memory-bank of normative features can directly be used for anomaly detection
which has been demonstrated recently. However, this is unsuitable for large
medical datasets as the computational burden increases substantially.
Therefore, we propose to model the distribution of normative DINOv2 embeddings
with a Dirichlet Process Mixture model (DPMM), a non-parametric mixture model
that automatically adjusts the number of mixture components to the data at
hand. Rather than using a memory bank, we use the similarity between the
component centers and the embeddings as anomaly score function to create a
coarse anomaly segmentation mask. Our experiments show that through DPMM
embeddings of DINOv2, despite being trained on natural images, achieve very
competitive anomaly detection performance on medical imaging benchmarks and can
do this while at least halving the computation time at inference. Our analysis
further indicates that normalized DINOv2 embeddings are generally more aligned
with anatomical structures than unnormalized features, even in the presence of
anomalies, making them great representations for anomaly detection. The code is
available at https://github.com/NicoSchulthess/anomalydino-dpmm.
\\ ( https://arxiv.org/abs/2509.19997 ,  886kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20003
Date: Wed, 24 Sep 2025 11:22:30 GMT   (1562kb)

Title: Table Detection with Active Learning
Authors: Somraj Gautam, Nachiketa Purohit, Gaurav Harit
Categories: cs.CV cs.AI cs.CL cs.LG
Comments: Accepted in ICDAR 2025
\\
  Efficient data annotation remains a critical challenge in machine learning,
particularly for object detection tasks requiring extensive labeled data.
Active learning (AL) has emerged as a promising solution to minimize annotation
costs by selecting the most informative samples. While traditional AL
approaches primarily rely on uncertainty-based selection, recent advances
suggest that incorporating diversity-based strategies can enhance sampling
efficiency in object detection tasks. Our approach ensures the selection of
representative examples that improve model generalization. We evaluate our
method on two benchmark datasets (TableBank-LaTeX, TableBank-Word) using
state-of-the-art table detection architectures, CascadeTabNet and YOLOv9. Our
results demonstrate that AL-based example selection significantly outperforms
random sampling, reducing annotation effort given a limited budget while
maintaining comparable performance to fully supervised models. Our method
achieves higher mAP scores within the same annotation budget.
\\ ( https://arxiv.org/abs/2509.20003 ,  1562kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20006
Date: Wed, 24 Sep 2025 11:25:44 GMT   (6037kb)

Title: Does the Manipulation Process Matter? RITA: Reasoning Composite Image
  Manipulations via Reversely-Ordered Incremental-Transition Autoregression
Authors: Xuekang Zhu, Ji-Zhe Zhou, Kaiwen Feng, Chenfan Qu, Yunfei Wang, Liting
  Zhou, Jian liu
Categories: cs.CV
\\
  Image manipulations often entail a complex manipulation process, comprising a
series of editing operations to create a deceptive image, exhibiting
sequentiality and hierarchical characteristics. However, existing IML methods
remain manipulation-process-agnostic, directly producing localization masks in
a one-shot prediction paradigm without modeling the underlying editing steps.
This one-shot paradigm compresses the high-dimensional compositional space into
a single binary mask, inducing severe dimensional collapse, thereby creating a
fundamental mismatch with the intrinsic nature of the IML task.
  To address this, we are the first to reformulate image manipulation
localization as a conditional sequence prediction task, proposing the RITA
framework. RITA predicts manipulated regions layer-by-layer in an ordered
manner, using each step's prediction as the condition for the next, thereby
explicitly modeling temporal dependencies and hierarchical structures among
editing operations.
  To enable training and evaluation, we synthesize multi-step manipulation data
and construct a new benchmark HSIM. We further propose the HSS metric to assess
sequential order and hierarchical alignment. Extensive experiments show RITA
achieves SOTA on traditional benchmarks and provides a solid foundation for the
novel hierarchical localization task, validating its potential as a general and
effective paradigm. The code and dataset will be publicly available.
\\ ( https://arxiv.org/abs/2509.20006 ,  6037kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20022
Date: Wed, 24 Sep 2025 11:37:52 GMT   (1847kb)

Title: PS3: A Multimodal Transformer Integrating Pathology Reports with
  Histology Images and Biological Pathways for Cancer Survival Prediction
Authors: Manahil Raza, Ayesha Azam, Talha Qaiser and Nasir Rajpoot
Categories: cs.CV
Comments: Accepted at ICCV 2025. Copyright 2025 IEEE. Personal use of this
  material is permitted. Permission from IEEE must be obtained for all other
  uses including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works
\\
  Current multimodal fusion approaches in computational oncology primarily
focus on integrating multi-gigapixel histology whole slide images (WSIs) with
genomic or transcriptomic data, demonstrating improved survival prediction. We
hypothesize that incorporating pathology reports can further enhance prognostic
performance. Pathology reports, as essential components of clinical workflows,
offer readily available complementary information by summarizing
histopathological findings and integrating expert interpretations and clinical
context. However, fusing these modalities poses challenges due to their
heterogeneous nature. WSIs are high-dimensional, each containing several
billion pixels, whereas pathology reports consist of concise text summaries of
varying lengths, leading to potential modality imbalance. To address this, we
propose a prototype-based approach to generate balanced representations, which
are then integrated using a Transformer-based fusion model for survival
prediction that we term PS3 (Predicting Survival from Three Modalities).
Specifically, we present: (1) Diagnostic prototypes from pathology reports,
leveraging self-attention to extract diagnostically relevant sections and
standardize text representation; (2) Histological prototypes to compactly
represent key morphological patterns in WSIs; and (3) Biological pathway
prototypes to encode transcriptomic expressions, accurately capturing cellular
functions. PS3, the three-modal transformer model, processes the resulting
prototype-based multimodal tokens and models intra-modal and cross-modal
interactions across pathology reports, WSIs and transcriptomic data. The
proposed model outperforms state-of-the-art methods when evaluated against
clinical, unimodal and multimodal baselines on six datasets from The Cancer
Genome Atlas (TCGA). The code is available at: https://github.com/manahilr/PS3.
\\ ( https://arxiv.org/abs/2509.20022 ,  1847kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20024
Date: Wed, 24 Sep 2025 11:39:40 GMT   (2319kb)

Title: Generative Adversarial Networks Applied for Privacy Preservation in
  Biometric-Based Authentication and Identification
Authors: Lubos Mjachky and Ivan Homoliak
Categories: cs.CV cs.AI cs.CR
\\
  Biometric-based authentication systems are getting broadly adopted in many
areas. However, these systems do not allow participating users to influence the
way their data is used. Furthermore, the data may leak and can be misused
without the users' knowledge. In this paper, we propose a new authentication
method that preserves the privacy of individuals and is based on a generative
adversarial network (GAN). Concretely, we suggest using the GAN for translating
images of faces to a visually private domain (e.g., flowers or shoes).
Classifiers, which are used for authentication purposes, are then trained on
the images from the visually private domain. Based on our experiments, the
method is robust against attacks and still provides meaningful utility.
\\ ( https://arxiv.org/abs/2509.20024 ,  2319kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20028
Date: Wed, 24 Sep 2025 11:46:15 GMT   (10292kb)

Title: Predictive Quality Assessment for Mobile Secure Graphics
Authors: Cas Steigstra, Sergey Milyaev and Shaodi You
Categories: cs.CV cs.LG
Comments: 8 pages, to appear at ICCV 2025 MIPI Workshop (IEEE)
ACM-class: I.2.10; I.4.8
\\
  The reliability of secure graphic verification, a key anti-counterfeiting
tool, is undermined by poor image acquisition on smartphones. Uncontrolled user
captures of these high-entropy patterns cause high false rejection rates,
creating a significant 'reliability gap'. To bridge this gap, we depart from
traditional perceptual IQA and introduce a framework that predictively
estimates a frame's utility for the downstream verification task. We propose a
lightweight model to predict a quality score for a video frame, determining its
suitability for a resource-intensive oracle model. Our framework is validated
using re-contextualized FNMR and ISRR metrics on a large-scale dataset of
32,000+ images from 105 smartphones. Furthermore, a novel cross-domain analysis
on graphics from different industrial printing presses reveals a key finding: a
lightweight probe on a frozen, ImageNet-pretrained network generalizes better
to an unseen printing technology than a fully fine-tuned model. This provides a
key insight for real-world generalization: for domain shifts from physical
manufacturing, a frozen general-purpose backbone can be more robust than full
fine-tuning, which can overfit to source-domain artifacts.
\\ ( https://arxiv.org/abs/2509.20028 ,  10292kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20073
Date: Wed, 24 Sep 2025 12:50:04 GMT   (5454kb)

Title: SHMoAReg: Spark Deformable Image Registration via Spatial Heterogeneous
  Mixture of Experts and Attention Heads
Authors: Yuxi Zheng, Jianhui Feng, Tianran Li, Marius Staring, Yuchuan Qiao
Categories: cs.CV
\\
  Encoder-Decoder architectures are widely used in deep learning-based
Deformable Image Registration (DIR), where the encoder extracts multi-scale
features and the decoder predicts deformation fields by recovering spatial
locations. However, current methods lack specialized extraction of features
(that are useful for registration) and predict deformation jointly and
homogeneously in all three directions. In this paper, we propose a novel
expert-guided DIR network with Mixture of Experts (MoE) mechanism applied in
both encoder and decoder, named SHMoAReg. Specifically, we incorporate Mixture
of Attention heads (MoA) into encoder layers, while Spatial Heterogeneous
Mixture of Experts (SHMoE) into the decoder layers. The MoA enhances the
specialization of feature extraction by dynamically selecting the optimal
combination of attention heads for each image token. Meanwhile, the SHMoE
predicts deformation fields heterogeneously in three directions for each voxel
using experts with varying kernel sizes. Extensive experiments conducted on two
publicly available datasets show consistent improvements over various methods,
with a notable increase from 60.58% to 65.58% in Dice score for the abdominal
CT dataset. Furthermore, SHMoAReg enhances model interpretability by
differentiating experts' utilities across/within different resolution layers.
To the best of our knowledge, we are the first to introduce MoE mechanism into
DIR tasks. The code will be released soon.
\\ ( https://arxiv.org/abs/2509.20073 ,  5454kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20091
Date: Wed, 24 Sep 2025 13:11:37 GMT   (8315kb)

Title: Unleashing the Potential of the Semantic Latent Space in Diffusion
  Models for Image Dehazing
Authors: Zizheng Yang, Hu Yu, Bing Li, Jinghao Zhang, Jie Huang and Feng Zhao
Categories: cs.CV
\\
  Diffusion models have recently been investigated as powerful generative
solvers for image dehazing, owing to their remarkable capability to model the
data distribution. However, the massive computational burden imposed by the
retraining of diffusion models, coupled with the extensive sampling steps
during the inference, limit the broader application of diffusion models in
image dehazing. To address these issues, we explore the properties of hazy
images in the semantic latent space of frozen pre-trained diffusion models, and
propose a Diffusion Latent Inspired network for Image Dehazing, dubbed
DiffLI$^2$D. Specifically, we first reveal that the semantic latent space of
pre-trained diffusion models can represent the content and haze characteristics
of hazy images, as the diffusion time-step changes. Building upon this insight,
we integrate the diffusion latent representations at different time-steps into
a delicately designed dehazing network to provide instructions for image
dehazing. Our DiffLI$^2$D avoids re-training diffusion models and iterative
sampling process by effectively utilizing the informative representations
derived from the pre-trained diffusion models, which also offers a novel
perspective for introducing diffusion models to image dehazing. Extensive
experiments on multiple datasets demonstrate that the proposed method achieves
superior performance to existing image dehazing methods. Code is available at
https://github.com/aaaasan111/difflid.
\\ ( https://arxiv.org/abs/2509.20091 ,  8315kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20107
Date: Wed, 24 Sep 2025 13:32:07 GMT   (5690kb)

Title: Hyperspectral Adapter for Semantic Segmentation with Vision Foundation
  Models
Authors: JuanaJuana Valeria Hurtado, Rohit Mohan, and Abhinav Valada
Categories: cs.CV cs.AI cs.LG cs.RO
\\
  Hyperspectral imaging (HSI) captures spatial information along with dense
spectral measurements across numerous narrow wavelength bands. This rich
spectral content has the potential to facilitate robust robotic perception,
particularly in environments with complex material compositions, varying
illumination, or other visually challenging conditions. However, current HSI
semantic segmentation methods underperform due to their reliance on
architectures and learning frameworks optimized for RGB inputs. In this work,
we propose a novel hyperspectral adapter that leverages pretrained vision
foundation models to effectively learn from hyperspectral data. Our
architecture incorporates a spectral transformer and a spectrum-aware spatial
prior module to extract rich spatial-spectral features. Additionally, we
introduce a modality-aware interaction block that facilitates effective
integration of hyperspectral representations and frozen vision Transformer
features through dedicated extraction and injection mechanisms. Extensive
evaluations on three benchmark autonomous driving datasets demonstrate that our
architecture achieves state-of-the-art semantic segmentation performance while
directly using HSI inputs, outperforming both vision-based and hyperspectral
segmentation methods. We make the code available at
https://hyperspectraladapter.cs.uni-freiburg.de.
\\ ( https://arxiv.org/abs/2509.20107 ,  5690kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20119
Date: Wed, 24 Sep 2025 13:41:04 GMT   (210kb)

Title: A Simple Data Augmentation Strategy for Text-in-Image Scientific VQA
Authors: Belal Shoer, Yova Kementchedjhieva
Categories: cs.CV
Comments: Accepted at WiNLP, 2025
\\
  Scientific visual question answering poses significant challenges for
vision-language models due to the complexity of scientific figures and their
multimodal context. Traditional approaches treat the figure and accompanying
text (e.g., questions and answer options) as separate inputs. EXAMS-V
introduced a new paradigm by embedding both visual and textual content into a
single image. However, even state-of-the-art proprietary models perform poorly
on this setup in zero-shot settings, underscoring the need for task-specific
fine-tuning. To address the scarcity of training data in this "text-in-image"
format, we synthesize a new dataset by converting existing separate image-text
pairs into unified images. Fine-tuning a small multilingual multimodal model on
a mix of our synthetic data and EXAMS-V yields notable gains across 13
languages, demonstrating strong average improvements and cross-lingual
transfer.
\\ ( https://arxiv.org/abs/2509.20119 ,  210kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20146
Date: Wed, 24 Sep 2025 14:09:55 GMT   (3058kb)

Title: EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language
  Models
Authors: Botai Yuan, Yutian Zhou, Yingjie Wang, Fushuo Huo, Yongcheng Jing, Li
  Shen, Ying Wei, Zhiqi Shen, Ziwei Liu, Tianwei Zhang, Jie Yang, Dacheng Tao
Categories: cs.CV cs.AI
Comments: 29 pages, 6 figures
\\
  Recent benchmarks for medical Large Vision-Language Models (LVLMs) emphasize
leaderboard accuracy, overlooking reliability and safety. We study sycophancy
-- models' tendency to uncritically echo user-provided information -- in
high-stakes clinical settings. We introduce EchoBench, a benchmark to
systematically evaluate sycophancy in medical LVLMs. It contains 2,122 images
across 18 departments and 20 modalities with 90 prompts that simulate biased
inputs from patients, medical students, and physicians. We evaluate
medical-specific, open-source, and proprietary LVLMs. All exhibit substantial
sycophancy; the best proprietary model (Claude 3.7 Sonnet) still shows 45.98%
sycophancy, and GPT-4.1 reaches 59.15%. Many medical-specific models exceed 95%
sycophancy despite only moderate accuracy. Fine-grained analyses by bias type,
department, perceptual granularity, and modality identify factors that increase
susceptibility. We further show that higher data quality/diversity and stronger
domain knowledge reduce sycophancy without harming unbiased accuracy. EchoBench
also serves as a testbed for mitigation: simple prompt-level interventions
(negative prompting, one-shot, few-shot) produce consistent reductions and
motivate training- and decoding-time strategies. Our findings highlight the
need for robust evaluation beyond accuracy and provide actionable guidance
toward safer, more trustworthy medical LVLMs.
\\ ( https://arxiv.org/abs/2509.20146 ,  3058kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20148
Date: Wed, 24 Sep 2025 14:11:59 GMT   (2976kb)

Title: Smaller is Better: Enhancing Transparency in Vehicle AI Systems via
  Pruning
Authors: Sanish Suwal, Shaurya Garg, Dipkamal Bhusal, Michael Clifford, Nidhi
  Rastogi
Categories: cs.CV
Comments: 17 pages
\\
  Connected and autonomous vehicles continue to heavily rely on AI systems,
where transparency and security are critical for trust and operational safety.
Post-hoc explanations provide transparency to these black-box like AI models
but the quality and reliability of these explanations is often questioned due
to inconsistencies and lack of faithfulness in representing model decisions.
This paper systematically examines the impact of three widely used training
approaches, namely natural training, adversarial training, and pruning, affect
the quality of post-hoc explanations for traffic sign classifiers. Through
extensive empirical evaluation, we demonstrate that pruning significantly
enhances the comprehensibility and faithfulness of explanations (using saliency
maps). Our findings reveal that pruning not only improves model efficiency but
also enforces sparsity in learned representation, leading to more interpretable
and reliable decisions. Additionally, these insights suggest that pruning is a
promising strategy for developing transparent deep learning models, especially
in resource-constrained vehicular AI systems.
\\ ( https://arxiv.org/abs/2509.20148 ,  2976kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20152
Date: Wed, 24 Sep 2025 14:17:39 GMT   (3718kb)

Title: C$^2$MIL: Synchronizing Semantic and Topological Causalities in Multiple
  Instance Learning for Robust and Interpretable Survival Analysis
Authors: Min Cen, Zhenfeng Zhuang, Yuzhe Zhang, Min Zeng, Baptiste Magnier,
  Lequan Yu, Hong Zhang, Liansheng Wang
Categories: cs.CV
\\
  Graph-based Multiple Instance Learning (MIL) is widely used in survival
analysis with Hematoxylin and Eosin (H\&E)-stained whole slide images (WSIs)
due to its ability to capture topological information. However, variations in
staining and scanning can introduce semantic bias, while topological subgraphs
that are not relevant to the causal relationships can create noise, resulting
in biased slide-level representations. These issues can hinder both the
interpretability and generalization of the analysis. To tackle this, we
introduce a dual structural causal model as the theoretical foundation and
propose a novel and interpretable dual causal graph-based MIL model, C$^2$MIL.
C$^2$MIL incorporates a novel cross-scale adaptive feature disentangling module
for semantic causal intervention and a new Bernoulli differentiable causal
subgraph sampling method for topological causal discovery. A joint optimization
strategy combining disentangling supervision and contrastive learning enables
simultaneous refinement of both semantic and topological causalities.
Experiments demonstrate that C$^2$MIL consistently improves generalization and
interpretability over existing methods and can serve as a causal enhancement
for diverse MIL baselines. The code is available at
https://github.com/mimic0127/C2MIL.
\\ ( https://arxiv.org/abs/2509.20152 ,  3718kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20154
Date: Wed, 24 Sep 2025 14:19:33 GMT   (2844kb)

Title: U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT
Authors: Zhi Qin Tan, Xiatian Zhu, Owen Addison, Yunpeng Li
Categories: cs.CV cs.AI
\\
  Accurate segmentation of teeth and pulp in Cone-Beam Computed Tomography
(CBCT) is vital for clinical applications like treatment planning and
diagnosis. However, this process requires extensive expertise and is
exceptionally time-consuming, highlighting the critical need for automated
algorithms that can effectively utilize unlabeled data. In this paper, we
propose U-Mamba2-SSL, a novel semi-supervised learning framework that builds on
the U-Mamba2 model and employs a multi-stage training strategy. The framework
first pre-trains U-Mamba2 in a self-supervised manner using a disruptive
autoencoder. It then leverages unlabeled data through consistency
regularization, where we introduce input and feature perturbations to ensure
stable model outputs. Finally, a pseudo-labeling strategy is implemented with a
reduced loss weighting to minimize the impact of potential errors. U-Mamba2-SSL
achieved an average score of 0.872 and a DSC of 0.969 on the validation
dataset, demonstrating the superior performance of our approach. The code is
available at https://github.com/zhiqin1998/UMamba2.
\\ ( https://arxiv.org/abs/2509.20154 ,  2844kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20171
Date: Wed, 24 Sep 2025 14:36:35 GMT   (37745kb)

Title: Optical Ocean Recipes: Creating Realistic Datasets to Facilitate
  Underwater Vision Research
Authors: Patricia Sch\"ontag, David Nakath, Judith Fischer, R\"udiger
  R\"ottgers, Kevin K\"oser
Categories: cs.CV
Comments: 26 pages, 9 figures, submitted to IEEE Journal of Ocean Engineering
\\
  The development and evaluation of machine vision in underwater environments
remains challenging, often relying on trial-and-error-based testing tailored to
specific applications. This is partly due to the lack of controlled,
ground-truthed testing environments that account for the optical challenges,
such as color distortion from spectrally variant light attenuation, reduced
contrast and blur from backscatter and volume scattering, and dynamic light
patterns from natural or artificial illumination. Additionally, the appearance
of ocean water in images varies significantly across regions, depths, and
seasons. However, most machine vision evaluations are conducted under specific
optical water types and imaging conditions, therefore often lack
generalizability. Exhaustive testing across diverse open-water scenarios is
technically impractical. To address this, we introduce the \textit{Optical
Ocean Recipes}, a framework for creating realistic datasets under controlled
underwater conditions. Unlike synthetic or open-water data, these recipes,
using calibrated color and scattering additives, enable repeatable and
controlled testing of the impact of water composition on image appearance.
Hence, this provides a unique framework for analyzing machine vision in
realistic, yet controlled underwater scenarios. The controlled environment
enables the creation of ground-truth data for a range of vision tasks,
including water parameter estimation, image restoration, segmentation, visual
SLAM, and underwater image synthesis. We provide a demonstration dataset
generated using the Optical Ocean Recipes and briefly demonstrate the use of
our system for two underwater vision tasks. The dataset and evaluation code
will be made available.
\\ ( https://arxiv.org/abs/2509.20171 ,  37745kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20196
Date: Wed, 24 Sep 2025 14:52:01 GMT   (5592kb)

Title: Universal Camouflage Attack on Vision-Language Models for Autonomous
  Driving
Authors: Dehong Kong, Sifan Yu, Siyuan Liang, Jiawei Liang, Jianhou Gan, Aishan
  Liu, Wenqi Ren
Categories: cs.CV cs.LG
\\
  Visual language modeling for automated driving is emerging as a promising
research direction with substantial improvements in multimodal reasoning
capabilities. Despite its advanced reasoning abilities, VLM-AD remains
vulnerable to serious security threats from adversarial attacks, which involve
misleading model decisions through carefully crafted perturbations. Existing
attacks have obvious challenges: 1) Physical adversarial attacks primarily
target vision modules. They are difficult to directly transfer to VLM-AD
systems because they typically attack low-level perceptual components. 2)
Adversarial attacks against VLM-AD have largely concentrated on the digital
level. To address these challenges, we propose the first Universal Camouflage
Attack (UCA) framework for VLM-AD. Unlike previous methods that focus on
optimizing the logit layer, UCA operates in the feature space to generate
physically realizable camouflage textures that exhibit strong generalization
across different user commands and model architectures. Motivated by the
observed vulnerability of encoder and projection layers in VLM-AD, UCA
introduces a feature divergence loss (FDL) that maximizes the representational
discrepancy between clean and adversarial images. In addition, UCA incorporates
a multi-scale learning strategy and adjusts the sampling ratio to enhance its
adaptability to changes in scale and viewpoint diversity in real-world
scenarios, thereby improving training stability. Extensive experiments
demonstrate that UCA can induce incorrect driving commands across various
VLM-AD models and driving scenarios, significantly surpassing existing
state-of-the-art attack methods (improving 30\% in 3-P metrics). Furthermore,
UCA exhibits strong attack robustness under diverse viewpoints and dynamic
conditions, indicating high potential for practical deployment.
\\ ( https://arxiv.org/abs/2509.20196 ,  5592kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20207
Date: Wed, 24 Sep 2025 15:02:03 GMT   (11785kb)

Title: PU-Gaussian: Point Cloud Upsampling using 3D Gaussian Representation
Authors: Mahmoud Khater, Mona Strauss, Philipp von Olshausen, and Alexander
  Reiterer
Categories: cs.CV
Comments: Accepted for the ICCV 2025 e2e3D Workshop. To be published in the
  Proceedings of the IEEE/CVF International Conference on Computer Vision
  Workshops (ICCVW)
\\
  Point clouds produced by 3D sensors are often sparse and noisy, posing
challenges for tasks requiring dense and high-fidelity 3D representations.
Prior work has explored both implicit feature-based upsampling and
distance-function learning to address this, but often at the expense of
geometric interpretability or robustness to input sparsity. To overcome these
limitations, we propose PU-Gaussian, a novel upsampling network that models the
local neighborhood around each point using anisotropic 3D Gaussian
distributions. These Gaussians capture the underlying geometric structure,
allowing us to perform upsampling explicitly in the local geometric domain by
direct point sampling. The sampling process generates a dense, but coarse,
point cloud. A subsequent refinement network adjusts the coarse output to
produce a more uniform distribution and sharper edges. We perform extensive
testing on the PU1K and PUGAN datasets, demonstrating that PU-Gaussian achieves
state-of-the-art performance. We make code and model weights publicly available
at https://github.com/mvg-inatech/PU-Gaussian.git.
\\ ( https://arxiv.org/abs/2509.20207 ,  11785kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20234
Date: Wed, 24 Sep 2025 15:24:43 GMT   (7384kb)

Title: ImageNet-trained CNNs are not biased towards texture: Revisiting feature
  reliance through controlled suppression
Authors: Tom Burgert, Oliver Stoll, Paolo Rota, Beg\"um Demir
Categories: cs.CV cs.AI cs.LG
Comments: Accepted at NeurIPS 2025 (oral)
\\
  The hypothesis that Convolutional Neural Networks (CNNs) are inherently
texture-biased has shaped much of the discourse on feature use in deep
learning. We revisit this hypothesis by examining limitations in the
cue-conflict experiment by Geirhos et al. To address these limitations, we
propose a domain-agnostic framework that quantifies feature reliance through
systematic suppression of shape, texture, and color cues, avoiding the
confounds of forced-choice conflicts. By evaluating humans and neural networks
under controlled suppression conditions, we find that CNNs are not inherently
texture-biased but predominantly rely on local shape features. Nonetheless,
this reliance can be substantially mitigated through modern training strategies
or architectures (ConvNeXt, ViTs). We further extend the analysis across
computer vision, medical imaging, and remote sensing, revealing that reliance
patterns differ systematically: computer vision models prioritize shape,
medical imaging models emphasize color, and remote sensing models exhibit a
stronger reliance towards texture. Code is available at
https://github.com/tomburgert/feature-reliance.
\\ ( https://arxiv.org/abs/2509.20234 ,  7384kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20242
Date: Wed, 24 Sep 2025 15:32:39 GMT   (4545kb)

Title: An Anisotropic Cross-View Texture Transfer with Multi-Reference
  Non-Local Attention for CT Slice Interpolation
Authors: Kwang-Hyun Uhm, Hyunjun Cho, Sung-Hoo Hong, Seung-Won Jung
Categories: cs.CV
Comments: Accepted to IEEE Transactions on Medical Imaging (TMI), 2025
DOI: 10.1109/TMI.2025.3596957
\\
  Computed tomography (CT) is one of the most widely used non-invasive imaging
modalities for medical diagnosis. In clinical practice, CT images are usually
acquired with large slice thicknesses due to the high cost of memory storage
and operation time, resulting in an anisotropic CT volume with much lower
inter-slice resolution than in-plane resolution. Since such inconsistent
resolution may lead to difficulties in disease diagnosis, deep learning-based
volumetric super-resolution methods have been developed to improve inter-slice
resolution. Most existing methods conduct single-image super-resolution on the
through-plane or synthesize intermediate slices from adjacent slices; however,
the anisotropic characteristic of 3D CT volume has not been well explored. In
this paper, we propose a novel cross-view texture transfer approach for CT
slice interpolation by fully utilizing the anisotropic nature of 3D CT volume.
Specifically, we design a unique framework that takes high-resolution in-plane
texture details as a reference and transfers them to low-resolution
through-plane images. To this end, we introduce a multi-reference non-local
attention module that extracts meaningful features for reconstructing
through-plane high-frequency details from multiple in-plane images. Through
extensive experiments, we demonstrate that our method performs significantly
better in CT slice interpolation than existing competing methods on public CT
datasets including a real-paired benchmark, verifying the effectiveness of the
proposed framework. The source code of this work is available at
https://github.com/khuhm/ACVTT.
\\ ( https://arxiv.org/abs/2509.20242 ,  4545kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20251
Date: Wed, 24 Sep 2025 15:37:17 GMT   (11732kb)

Title: 4D Driving Scene Generation With Stereo Forcing
Authors: Hao Lu, Zhuang Ma, Guangfeng Jiang, Wenhang Ge, Bohan Li, Yuzhan Cai,
  Wenzhao Zheng, Yunpeng Zhang, Yingcong Chen
Categories: cs.CV
\\
  Current generative models struggle to synthesize dynamic 4D driving scenes
that simultaneously support temporal extrapolation and spatial novel view
synthesis (NVS) without per-scene optimization. Bridging generation and novel
view synthesis remains a major challenge. We present PhiGenesis, a unified
framework for 4D scene generation that extends video generation techniques with
geometric and temporal consistency. Given multi-view image sequences and camera
parameters, PhiGenesis produces temporally continuous 4D Gaussian splatting
representations along target 3D trajectories. In its first stage, PhiGenesis
leverages a pre-trained video VAE with a novel range-view adapter to enable
feed-forward 4D reconstruction from multi-view images. This architecture
supports single-frame or video inputs and outputs complete 4D scenes including
geometry, semantics, and motion. In the second stage, PhiGenesis introduces a
geometric-guided video diffusion model, using rendered historical 4D scenes as
priors to generate future views conditioned on trajectories. To address
geometric exposure bias in novel views, we propose Stereo Forcing, a novel
conditioning strategy that integrates geometric uncertainty during denoising.
This method enhances temporal coherence by dynamically adjusting generative
influence based on uncertainty-aware perturbations. Our experimental results
demonstrate that our method achieves state-of-the-art performance in both
appearance and geometric reconstruction, temporal generation and novel view
synthesis (NVS) tasks, while simultaneously delivering competitive performance
in downstream evaluations. Homepage is at
\href{https://jiangxb98.github.io/PhiGensis}{PhiGensis}.
\\ ( https://arxiv.org/abs/2509.20251 ,  11732kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20271
Date: Wed, 24 Sep 2025 16:04:39 GMT   (3134kb)

Title: A Versatile Foundation Model for AI-enabled Mammogram Interpretation
Authors: Fuxiang Huang, Jiayi Zhu, Yunfang Yu, Yu Xie, Yuan Guo, Qingcong Kong,
  Mingxiang Wu, Xinrui Jiang, Shu Yang, Jiabo Ma, Ziyi Liu, Zhe Xu, Zhixuan
  Chen, Yujie Tan, Zifan He, Luhui Mao, Xi Wang, Junlin Hou, Lei Zhang, Qiong
  Luo, Zhenhui Li, Herui Yao, and Hao Chen
Categories: cs.CV
Comments: 64 pages, 7 figures, 40 tables
\\
  Breast cancer is the most commonly diagnosed cancer and the leading cause of
cancer-related mortality in women globally. Mammography is essential for the
early detection and diagnosis of breast lesions. Despite recent progress in
foundation models (FMs) for mammogram analysis, their clinical translation
remains constrained by several fundamental limitations, including insufficient
diversity in training data, limited model generalizability, and a lack of
comprehensive evaluation across clinically relevant tasks. Here, we introduce
VersaMammo, a versatile foundation model for mammograms, designed to overcome
these limitations. We curated the largest multi-institutional mammogram dataset
to date, comprising 706,239 images from 21 sources. To improve generalization,
we propose a two-stage pre-training strategy to develop VersaMammo, a mammogram
foundation model. First, a teacher model is trained via self-supervised
learning to extract transferable features from unlabeled mammograms. Then,
supervised learning combined with knowledge distillation transfers both
features and clinical knowledge into VersaMammo. To ensure a comprehensive
evaluation, we established a benchmark comprising 92 specific tasks, including
68 internal tasks and 24 external validation tasks, spanning 5 major clinical
task categories: lesion detection, segmentation, classification, image
retrieval, and visual question answering. VersaMammo achieves state-of-the-art
performance, ranking first in 50 out of 68 specific internal tasks and 20 out
of 24 external validation tasks, with average ranks of 1.5 and 1.2,
respectively. These results demonstrate its superior generalization and
clinical utility, offering a substantial advancement toward reliable and
scalable breast cancer screening and diagnosis.
\\ ( https://arxiv.org/abs/2509.20271 ,  3134kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20279
Date: Wed, 24 Sep 2025 16:15:28 GMT   (28695kb)

Title: A co-evolving agentic AI system for medical imaging analysis
Authors: Songhao Li, Jonathan Xu, Tiancheng Bao, Yuxuan Liu, Yuchen Liu, Yihang
  Liu, Lilin Wang, Wenhui Lei, Sheng Wang, Yinuo Xu, Yan Cui, Jialu Yao,
  Shunsuke Koga, and Zhi Huang
Categories: cs.CV q-bio.QM
\\
  Agentic AI is rapidly advancing in healthcare and biomedical research.
However, in medical image analysis, their performance and adoption remain
limited due to the lack of a robust ecosystem, insufficient toolsets, and the
absence of real-time interactive expert feedback. Here we present "TissueLab",
a co-evolving agentic AI system that allows researchers to ask direct
questions, automatically plan and generate explainable workflows, and conduct
real-time analyses where experts can visualize intermediate results and refine
them. TissueLab integrates tool factories across pathology, radiology, and
spatial omics domains. By standardizing inputs, outputs, and capabilities of
diverse tools, the system determines when and how to invoke them to address
research and clinical questions. Across diverse tasks with clinically
meaningful quantifications that inform staging, prognosis, and treatment
planning, TissueLab achieves state-of-the-art performance compared with
end-to-end vision-language models (VLMs) and other agentic AI systems such as
GPT-5. Moreover, TissueLab continuously learns from clinicians, evolving toward
improved classifiers and more effective decision strategies. With active
learning, it delivers accurate results in unseen disease contexts within
minutes, without requiring massive datasets or prolonged retraining. Released
as a sustainable open-source ecosystem, TissueLab aims to accelerate
computational research and translational adoption in medical imaging while
establishing a foundation for the next generation of medical AI.
\\ ( https://arxiv.org/abs/2509.20279 ,  28695kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20280
Date: Wed, 24 Sep 2025 16:15:42 GMT   (35304kb)

Title: HiPerformer: A High-Performance Global-Local Segmentation Model with
  Modular Hierarchical Fusion Strategy
Authors: Dayu Tan, Zhenpeng Xu, Yansen Su, Xin Peng, Chunhou Zheng, and Weimin
  Zhong
Categories: cs.CV
\\
  Both local details and global context are crucial in medical image
segmentation, and effectively integrating them is essential for achieving high
accuracy. However, existing mainstream methods based on CNN-Transformer hybrid
architectures typically employ simple feature fusion techniques such as serial
stacking, endpoint concatenation, or pointwise addition, which struggle to
address the inconsistencies between features and are prone to information
conflict and loss. To address the aforementioned challenges, we innovatively
propose HiPerformer. The encoder of HiPerformer employs a novel modular
hierarchical architecture that dynamically fuses multi-source features in
parallel, enabling layer-wise deep integration of heterogeneous information.
The modular hierarchical design not only retains the independent modeling
capability of each branch in the encoder, but also ensures sufficient
information transfer between layers, effectively avoiding the degradation of
features and information loss that come with traditional stacking methods.
Furthermore, we design a Local-Global Feature Fusion (LGFF) module to achieve
precise and efficient integration of local details and global semantic
information, effectively alleviating the feature inconsistency problem and
resulting in a more comprehensive feature representation. To further enhance
multi-scale feature representation capabilities and suppress noise
interference, we also propose a Progressive Pyramid Aggregation (PPA) module to
replace traditional skip connections. Experiments on eleven public datasets
demonstrate that the proposed method outperforms existing segmentation
techniques, demonstrating higher segmentation accuracy and robustness. The code
is available at https://github.com/xzphappy/HiPerformer.
\\ ( https://arxiv.org/abs/2509.20280 ,  35304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20281
Date: Wed, 24 Sep 2025 16:15:43 GMT   (5472kb)

Title: PerFace: Metric Learning in Perceptual Facial Similarity for Enhanced
  Face Anonymization
Authors: Haruka Kumagai, Leslie W\"ohler, Satoshi Ikehata, Kiyoharu Aizawa
Categories: cs.CV
\\
  In response to rising societal awareness of privacy concerns, face
anonymization techniques have advanced, including the emergence of
face-swapping methods that replace one identity with another. Achieving a
balance between anonymity and naturalness in face swapping requires careful
selection of identities: overly similar faces compromise anonymity, while
dissimilar ones reduce naturalness. Existing models, however, focus on binary
identity classification "the same person or not", making it difficult to
measure nuanced similarities such as "completely different" versus "highly
similar but different." This paper proposes a human-perception-based face
similarity metric, creating a dataset of 6,400 triplet annotations and metric
learning to predict the similarity. Experimental results demonstrate
significant improvements in both face similarity prediction and attribute-based
face classification tasks over existing methods.
\\ ( https://arxiv.org/abs/2509.20281 ,  5472kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20295
Date: Wed, 24 Sep 2025 16:28:15 GMT   (6192kb)

Title: FAST: Foreground-aware Diffusion with Accelerated Sampling Trajectory
  for Segmentation-oriented Anomaly Synthesis
Authors: Xichen Xu, Yanshu Wang, Jinbao Wang, Xiaoning Lei, Guoyang Xie,
  Guannan Jiang, Zhichao Lu
Categories: cs.CV
\\
  Industrial anomaly segmentation relies heavily on pixel-level annotations,
yet real-world anomalies are often scarce, diverse, and costly to label.
Segmentation-oriented industrial anomaly synthesis (SIAS) has emerged as a
promising alternative; however, existing methods struggle to balance sampling
efficiency and generation quality. Moreover, most approaches treat all spatial
regions uniformly, overlooking the distinct statistical differences between
anomaly and background areas. This uniform treatment hinders the synthesis of
controllable, structure-specific anomalies tailored for segmentation tasks. In
this paper, we propose FAST, a foreground-aware diffusion framework featuring
two novel modules: the Anomaly-Informed Accelerated Sampling (AIAS) and the
Foreground-Aware Reconstruction Module (FARM). AIAS is a training-free sampling
algorithm specifically designed for segmentation-oriented industrial anomaly
synthesis, which accelerates the reverse process through coarse-to-fine
aggregation and enables the synthesis of state-of-the-art segmentation-oriented
anomalies in as few as 10 steps. Meanwhile, FARM adaptively adjusts the
anomaly-aware noise within the masked foreground regions at each sampling step,
preserving localized anomaly signals throughout the denoising trajectory.
Extensive experiments on multiple industrial benchmarks demonstrate that FAST
consistently outperforms existing anomaly synthesis methods in downstream
segmentation tasks. We release the code at:
https://anonymous.4open.science/r/NeurIPS-938.
\\ ( https://arxiv.org/abs/2509.20295 ,  6192kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20318
Date: Wed, 24 Sep 2025 17:01:50 GMT   (8062kb)

Title: A Comprehensive Evaluation of YOLO-based Deer Detection Performance on
  Edge Devices
Authors: Bishal Adhikari, Jiajia Li, Eric S. Michel, Jacob Dykes, Te-Ming Paul
  Tseng, Mary Love Tagert, Dong Chen
Categories: cs.CV
Comments: 13 pages, 7 figures
\\
  The escalating economic losses in agriculture due to deer intrusion,
estimated to be in the hundreds of millions of dollars annually in the U.S.,
highlight the inadequacy of traditional mitigation strategies since these
methods are often labor-intensive, costly, and ineffective for modern farming
systems. To overcome this, there is a critical need for intelligent, autonomous
solutions which require accurate and efficient deer detection. But the progress
in this field is impeded by a significant gap in the literature, mainly the
lack of a domain-specific, practical dataset and limited study on the on-field
deployability of deer detection systems. Addressing this gap, this study
presents a comprehensive evaluation of state-of-the-art deep learning models
for deer detection in challenging real-world scenarios. The contributions of
this work are threefold. First, we introduce a curated, publicly available
dataset of 3,095 annotated images with bounding-box annotations of deer,
derived from the Idaho Cameratraps project. Second, we provide an extensive
comparative analysis of 12 model variants across four recent YOLO
architectures(v8, v9, v10, and v11). Finally, we benchmarked performance on a
high-end NVIDIA RTX 5090 GPU and evaluated on two representative edge computing
platforms: Raspberry Pi 5 and NVIDIA Jetson AGX Xavier. Results show that the
real-time detection is not feasible in Raspberry Pi without hardware-specific
model optimization, while NVIDIA Jetson provides greater than 30 FPS with
GPU-accelerated inference on 's' and 'n' series models. This study also reveals
that smaller, architecturally advanced models such as YOLOv11n, YOLOv8s, and
YOLOv9s offer the optimal balance of high accuracy (AP@.5 > 0.85) and
computational efficiency (FPS > 30). To support further research, both the
source code and datasets are publicly available at
https://github.com/WinnerBishal/track-the-deer.
\\ ( https://arxiv.org/abs/2509.20318 ,  8062kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20343
Date: Wed, 24 Sep 2025 17:35:23 GMT   (23075kb)

Title: Efficient Encoder-Free Pose Conditioning and Pose Control for Virtual
  Try-On
Authors: Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee
  Kiat Koo, Karim Bouyarmane
Categories: cs.CV
Comments: Submitted to CVPR 2025 and Published at CVPR 2025 AI for Content
  Creation workshop
\\
  As online shopping continues to grow, the demand for Virtual Try-On (VTON)
technology has surged, allowing customers to visualize products on themselves
by overlaying product images onto their own photos. An essential yet
challenging condition for effective VTON is pose control, which ensures
accurate alignment of products with the user's body while supporting diverse
orientations for a more immersive experience. However, incorporating pose
conditions into VTON models presents several challenges, including selecting
the optimal pose representation, integrating poses without additional
parameters, and balancing pose preservation with flexible pose control.
  In this work, we build upon a baseline VTON model that concatenates the
reference image condition without external encoder, control network, or complex
attention layers. We investigate methods to incorporate pose control into this
pure concatenation paradigm by spatially concatenating pose data, comparing
performance using pose maps and skeletons, without adding any additional
parameters or module to the baseline model. Our experiments reveal that pose
stitching with pose maps yields the best results, enhancing both pose
preservation and output realism. Additionally, we introduce a mixed-mask
training strategy using fine-grained and bounding box masks, allowing the model
to support flexible product integration across varied poses and conditions.
\\ ( https://arxiv.org/abs/2509.20343 ,  23075kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20358
Date: Wed, 24 Sep 2025 17:58:04 GMT   (23640kb)

Title: PhysCtrl: Generative Physics for Controllable and Physics-Grounded Video
  Generation
Authors: Chen Wang, Chuhao Chen, Yiming Huang, Zhiyang Dou, Yuan Liu, Jiatao
  Gu, Lingjie Liu
Categories: cs.CV
Comments: Accepted by NeurIPS 2025. This is the preview version; the
  camera-ready version is still in preparation
\\
  Existing video generation models excel at producing photo-realistic videos
from text or images, but often lack physical plausibility and 3D
controllability. To overcome these limitations, we introduce PhysCtrl, a novel
framework for physics-grounded image-to-video generation with physical
parameters and force control. At its core is a generative physics network that
learns the distribution of physical dynamics across four materials (elastic,
sand, plasticine, and rigid) via a diffusion model conditioned on physics
parameters and applied forces. We represent physical dynamics as 3D point
trajectories and train on a large-scale synthetic dataset of 550K animations
generated by physics simulators. We enhance the diffusion model with a novel
spatiotemporal attention block that emulates particle interactions and
incorporates physics-based constraints during training to enforce physical
plausibility. Experiments show that PhysCtrl generates realistic,
physics-grounded motion trajectories which, when used to drive image-to-video
models, yield high-fidelity, controllable videos that outperform existing
methods in both visual quality and physical plausibility. Project Page:
https://cwchenwang.github.io/physctrl
\\ ( https://arxiv.org/abs/2509.20358 ,  23640kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20360
Date: Wed, 24 Sep 2025 17:59:30 GMT   (12927kb)

Title: EditVerse: Unifying Image and Video Editing and Generation with
  In-Context Learning
Authors: Xuan Ju, Tianyu Wang, Yuqian Zhou, He Zhang, Qing Liu, Nanxuan Zhao,
  Zhifei Zhang, Yijun Li, Yuanhao Cai, Shaoteng Liu, Daniil Pakhomov, Zhe Lin,
  Soo Ye Kim, Qiang Xu
Categories: cs.CV
\\
  Recent advances in foundation models highlight a clear trend toward
unification and scaling, showing emergent capabilities across diverse domains.
While image generation and editing have rapidly transitioned from task-specific
to unified frameworks, video generation and editing remain fragmented due to
architectural limitations and data scarcity. In this work, we introduce
EditVerse, a unified framework for image and video generation and editing
within a single model. By representing all modalities, i.e., text, image, and
video, as a unified token sequence, EditVerse leverages self-attention to
achieve robust in-context learning, natural cross-modal knowledge transfer, and
flexible handling of inputs and outputs with arbitrary resolutions and
durations. To address the lack of video editing training data, we design a
scalable data pipeline that curates 232K video editing samples and combines
them with large-scale image and video datasets for joint training. Furthermore,
we present EditVerseBench, the first benchmark for instruction-based video
editing covering diverse tasks and resolutions. Extensive experiments and user
studies demonstrate that EditVerse achieves state-of-the-art performance,
surpassing existing open-source and commercial models, while exhibiting
emergent editing and generation abilities across modalities.
\\ ( https://arxiv.org/abs/2509.20360 ,  12927kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19478
Date: Tue, 23 Sep 2025 18:38:33 GMT   (250kb)

Title: Investigating Sharding Advancements, Methodologies, and Adoption
  Potential in Hedera
Authors: Ziwei Wang, Cong Wu, Paolo Tasca
Categories: cs.DC
\\
  Sharding has emerged as a critical solution to address the scalability
challenges faced by blockchain networks, enabling them to achieve higher
transaction throughput, reduced latency, and optimized resource usage. This
paper investigates the advancements, methodologies, and adoption potential of
sharding in the context of Hedera, a distributed ledger technology known for
its unique Gossip about Gossip protocol and asynchronous Byzantine Fault
Tolerance (ABFT). We explore various academic and industrial sharding
techniques, emphasizing their benefits and trade-offs. Building on these
insights, we propose a hybrid sharding solution for Hedera that partitions the
network into local and global committees, facilitating efficient cross-shard
transactions and ensuring robust security through dynamic reconfiguration. Our
analysis highlights significant reductions in storage and communication
overhead, improved scalability, and enhanced fault tolerance, demonstrating the
feasibility and advantages of integrating sharding into Hedera's architecture.
\\ ( https://arxiv.org/abs/2509.19478 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19532
Date: Tue, 23 Sep 2025 19:53:43 GMT   (1220kb)

Title: To Stream or Not to Stream: Towards A Quantitative Model for Remote HPC
  Processing Decisions
Authors: Flavio Castro, Weijian Zheng, Joaquin Chung, Ian Foster, Rajkumar
  Kettimuthu
Categories: cs.DC cs.NI
\\
  Modern scientific instruments generate data at rates that increasingly exceed
local compute capabilities and, when paired with the staging and I/O overheads
of file-based transfers, also render file-based use of remote HPC resources
impractical for time-sensitive analysis and experimental steering. Real-time
streaming frameworks promise to reduce latency and improve system efficiency,
but lack a principled way to assess their feasibility. In this work, we
introduce a quantitative framework and an accompanying Streaming Speed Score to
evaluate whether remote high-performance computing (HPC) resources can provide
timely data processing compared to local alternatives. Our model incorporates
key parameters including data generation rate, transfer efficiency, remote
processing power, and file input/output overhead to compute total processing
completion time and identify operational regimes where streaming is beneficial.
We motivate our methodology with use cases from facilities such as APS, FRIB,
LCLS-II, and the LHC, and validate our approach through an illustrative case
study based on LCLS-II data. Our measurements show that streaming can achieve
up to 97% lower end-to-end completion time than file-based methods under high
data rates, while worst-case congestion can increase transfer times by over an
order of magnitude, underscoring the importance of tail latency in streaming
feasibility decisions.
\\ ( https://arxiv.org/abs/2509.19532 ,  1220kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19539
Date: Tue, 23 Sep 2025 20:07:53 GMT   (416kb)

Title: A Survey of Recent Advancements in Secure Peer-to-Peer Networks
Authors: Raj Patel, Umesh Biswas, Surya Kodipaka, Will Carroll, Preston
  Peranich, and Maxwell Young
Categories: cs.DC cs.CR
Comments: 30 pages, 4 figures, 2 tables
\\
  Peer-to-peer (P2P) networks are a cornerstone of modern computing, and their
security is an active area of research. Many defenses with strong security
guarantees have been proposed; however, the most-recent survey is over a decade
old. This paper delivers an updated review of recent theoretical advances that
address classic threats, such as the Sybil and routing attacks, while
highlighting how emerging trends -- such as machine learning, social networks,
and dynamic systems -- pose new challenges and drive novel solutions. We
evaluate the strengths and weaknesses of these solutions and suggest directions
for future research.
\\ ( https://arxiv.org/abs/2509.19539 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19701
Date: Wed, 24 Sep 2025 02:18:26 GMT   (681kb)

Title: Characterizing Adaptive Mesh Refinement on Heterogeneous Platforms with
  Parthenon-VIBE
Authors: Akash Poptani, Alireza Khadem, Scott Mahlke, Jonah Miller, Joshua
  Dolence, Reetuparna Das
Categories: cs.DC cs.PF
Comments: Accepted to appear at IISWC 2025
\\
  Hero-class HPC simulations rely on Adaptive Mesh Refinement (AMR) to reduce
compute and memory demands while maintaining accuracy. This work analyzes the
performance of Parthenon, a block-structured AMR benchmark, on CPU-GPU systems.
We show that smaller mesh blocks and deeper AMR levels degrade GPU performance
due to increased communication, serial overheads, and inefficient GPU
utilization. Through detailed profiling, we identify inefficiencies, low
occupancy, and memory access bottlenecks. We further analyze rank scalability
and memory constraints, and propose optimizations to improve GPU throughput and
reduce memory footprint. Our insights can inform future AMR deployments on
Department of Energy's upcoming heterogeneous supercomputers.
\\ ( https://arxiv.org/abs/2509.19701 ,  681kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19729
Date: Wed, 24 Sep 2025 03:15:37 GMT   (756kb)

Title: Gyges: Dynamic Cross-Instance Parallelism Transformation for Efficient
  LLM Inference
Authors: Haoyu Chen, Xue Li, Kun Qian, Yu Guan, Jin Zhao, Xin Wang
Categories: cs.DC
Comments: 12 pages, 15 figures
\\
  Efficiently processing the dynamics of requests, especially the context
length variance, is important in Large Language Model (LLM) serving scenarios.
However, there is an intrinsic trade-off: while leveraging parallelism
strategies, such as Tensor Parallelism (TP), can coordinate multiple GPUs to
accommodate larger context lengths, it inevitably results in degraded overall
throughput. In this paper, we propose Cross-Instance Parallelism Transformation
(Gyges), which adaptively adjusts the parallelism strategies of running
instances to align with the dynamics of incoming requests. We design (1) a
page-friendly, header-centric layout to accelerate KV cache transformations;
(2) dedicated weight padding to accelerate model weight transformations; and
(3) a transformation-aware scheduler to cooperatively schedule requests and
parallelism transformations, optimizing the overall performance. Evaluations
using real-world traces show that Gyges improves throughput by 1.75x-6.57x
compared to state-of-the-art solutions.
\\ ( https://arxiv.org/abs/2509.19729 ,  756kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19836
Date: Wed, 24 Sep 2025 07:27:40 GMT   (1566kb)

Title: BurstEngine: an Efficient Distributed Framework for Training
  Transformers on Extremely Long Sequences of over 1M Tokens
Authors: Ao Sun, Weilin Zhao, Xu Han, Cheng Yang, Zhiyuan Liu, Chuan Shi,
  Maosong sun
Categories: cs.DC
\\
  Existing methods for training LLMs on long-sequence data, such as Tensor
Parallelism and Context Parallelism, exhibit low Model FLOPs Utilization as
sequence lengths and number of GPUs increase, especially when sequence lengths
exceed 1M tokens. To address these challenges, we propose BurstEngine, an
efficient framework designed to train LLMs on long-sequence data. BurstEngine
introduces BurstAttention, an optimized distributed attention with lower
communication cost than RingAttention. BurstAttention leverages topology-aware
ring communication to fully utilize network bandwidth and incorporates
fine-grained communication-computation overlap. Furthermore, BurstEngine
introduces sequence-level selective checkpointing and fuses the language
modeling head with the loss function to reduce memory cost. Additionally,
BurstEngine introduces workload balance optimization for various types of
attention masking. By integrating these optimizations, BurstEngine achieves a
$1.2\times$ speedup with much lower memory overhead than the state-of-the-art
baselines when training LLMs on extremely long sequences of over 1M tokens. We
have made our code publicly available on GitHub:
https://github.com/thunlp/BurstEngine.
\\ ( https://arxiv.org/abs/2509.19836 ,  1566kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20160
Date: Wed, 24 Sep 2025 14:28:37 GMT   (404kb)

Title: Characterizing the Performance of Accelerated Jetson Edge Devices for
  Training Deep Learning Models
Authors: Prashanthi S. K. and Sai Anuroop Kesanapalli and Yogesh Simmhan
Categories: cs.DC
Comments: Preprint of article in ACM SIGMETRICS 2023
DOI: 10.1145/3570604
\\
  Deep Neural Networks (DNNs) have had a significant impact on domains like
autonomous vehicles and smart cities through low-latency inferencing on edge
computing devices close to the data source. However, DNN training on the edge
is poorly explored. Techniques like federated learning and the growing capacity
of GPU-accelerated edge devices like NVIDIA Jetson motivate the need for a
holistic characterization of DNN training on the edge. Training DNNs is
resource-intensive and can stress an edge's GPU, CPU, memory and storage
capacities. Edge devices also have different resources compared to workstations
and servers, such as slower shared memory and diverse storage media. Here, we
perform a principled study of DNN training on individual devices of three
contemporary Jetson device types: AGX Xavier, Xavier NX and Nano for three
diverse DNN model--dataset combinations. We vary device and training parameters
such as I/O pipelining and parallelism, storage media, mini-batch sizes and
power modes, and examine their effect on CPU and GPU utilization, fetch stalls,
training time, energy usage, and variability. Our analysis exposes several
resource inter-dependencies and counter-intuitive insights, while also helping
quantify known wisdom. Our rigorous study can help tune the training
performance on the edge, trade-off time and energy usage on constrained
devices, and even select an ideal edge hardware for a DNN workload, and, in
future, extend to federated learning too. As an illustration, we use these
results to build a simple model to predict the training time and energy per
epoch for any given DNN across different power modes, with minimal additional
profiling.
\\ ( https://arxiv.org/abs/2509.20160 ,  404kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20189
Date: Wed, 24 Sep 2025 14:46:07 GMT   (517kb)

Title: Pagoda: An Energy and Time Roofline Study for DNN Workloads on Edge
  Accelerators
Authors: Prashanthi S. K., Kunal Kumar Sahoo, Amartya Ranjan Saikia, Pranav
  Gupta, Atharva Vinay Joshi, Priyanshu Pansari, Yogesh Simmhan
Categories: cs.DC
\\
  Edge accelerators such as Nvidia Jetsons are becoming an integral part of the
computing continuum, and are often used for DNN inferencing and training.
Nvidia Jetson edge devices have $2000$+ CUDA cores within a $70$W power
envelope and offer $1000$s of power modes to customize CPU, GPU and memory
frequencies. Their widely varying power--performance trade-offs can be
exploited for energy and power-constrained deployments. While data-driven
methods to predict the power and latency of DNN workloads for edge devices
exist, there is a lack of principled study to understand why edge accelerators
and their power modes perform the way they do. We develop a time roofline and a
novel energy roofline model for the Jetson Orin AGX for diverse power modes,
and couple it with an analytical model of the compute (FLOP) and memory access
(bytes) for DNN inference workloads to analyze them from first principles.
These reveal unique, sometimes counter-intuitive, insights into the power and
performance behavior of DNN workloads on edge accelerators, e.g., the default
power mode MAXN is not the most energy efficient and time efficiency implies
energy efficiency for all power modes. We also extend our analytical roofline
models to DNN training. Finally, we apply these methods to tune the power mode
(and hence the roofline) of the edge device to optimize the latency and energy
for DNN inference, with up to $15\%$ lower energy and minimal degradation in
inference time.
\\ ( https://arxiv.org/abs/2509.20189 ,  517kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20205
Date: Wed, 24 Sep 2025 15:01:25 GMT   (1776kb)

Title: Fulcrum: Optimizing Concurrent DNN Training and Inferencing on Edge
  Accelerators
Authors: Prashanthi S. K., Saisamarth Taluri, Pranav Gupta, Amartya Ranjan
  Saikia, Kunal Kumar Sahoo, Atharva Vinay Joshi, Lakshya Karwa, Kedar Dhule,
  Yogesh Simmhan
Categories: cs.DC
\\
  The proliferation of GPU accelerated edge devices like Nvidia Jetsons and the
rise in privacy concerns are placing an emphasis on concurrent DNN training and
inferencing on edge devices. Inference and training have different computing
and QoS goals. But edge accelerators like Jetson do not support native GPU
sharing and expose 1000s of power modes. This requires careful time-sharing of
concurrent workloads to meet power--performance goals, while limiting costly
profiling. In this paper, we design an intelligent time-slicing approach for
concurrent DNN training and inferencing on Jetsons. We formulate an
optimization problem to interleave training and inferencing minibatches, and
decide the device power mode and inference minibatch size, while maximizing the
training throughput and staying within latency and power budgets, with modest
profiling costs. We propose GMD, an efficient multi-dimensional gradient
descent search which profiles just $15$ power modes; and ALS, an Active
Learning technique which identifies reusable Pareto-optimal power modes, but
profiles $50$--$150$ power modes. We evaluate these within our Fulcrum
scheduler for $273,000+$ configurations across $15$ DNN workloads. We also
evaluate our strategies on dynamic arrival inference and concurrent inferences.
ALS and GMD outperform simpler and more complex baselines with larger-scale
profiling. Their solutions satisfy the latency and power budget for $>97\%$ of
our runs, and on average are within $7\%$ of the optimal throughput.
\\ ( https://arxiv.org/abs/2509.20205 ,  1776kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20223
Date: Wed, 24 Sep 2025 15:16:09 GMT   (408kb)

Title: An Empirical Analysis of Secure Federated Learning for Autonomous
  Vehicle Applications
Authors: Md Jueal Mia, M. Hadi Amini
Categories: cs.DC
Comments: i3CE 2024, 2024 ASCE International Conference on Computing in Civil
  Engineering
\\
  Federated Learning lends itself as a promising paradigm in enabling
distributed learning for autonomous vehicles applications and ensuring data
privacy while enhancing and refining predictive model performance through
collaborative training on edge client vehicles. However, it remains vulnerable
to various categories of cyber-attacks, necessitating more robust security
measures to effectively mitigate potential threats. Poisoning attacks and
inference attacks are commonly initiated within the federated learning
environment to compromise secure system performance. Secure aggregation can
limit the disclosure of sensitive information from outsider and insider
attackers of the federated learning environment. In this study, our aim is to
conduct an empirical analysis on the transportation image dataset (e.g., LISA
traffic light) using various secure aggregation techniques and multiparty
computation in the presence of diverse categories of cyber-attacks. Multiparty
computation serves as a state-of-the-art security mechanism, offering standard
privacy for secure aggregation of edge autonomous vehicles local model updates
through various security protocols. The presence of adversaries can mislead the
autonomous vehicle learning model, leading to the misclassification of traffic
lights, and resulting in detrimental impacts. This empirical study explores the
resilience of various secure federated learning aggregation techniques and
multiparty computation in safeguarding autonomous vehicle applications against
various cyber threats during both training and inference times.
\\ ( https://arxiv.org/abs/2509.20223 ,  408kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20340
Date: Wed, 24 Sep 2025 17:33:31 GMT   (6925kb)

Title: xGFabric: Coupling Sensor Networks and HPC Facilities with Private 5G
  Wireless Networks for Real-Time Digital Agriculture
Authors: Liubov Kurafeeva, Alan Subedi, Ryan Hartung, Michael Fay, Avhishek
  Biswas, Shantenu Jha, Ozgur O. Kilic, Chandra Krintz, Andre Merzky, Douglas
  Thain, Mehmet C. Vuran, Rich Wolski
Categories: cs.DC
Comments: 8 pages with 7 figures followed by 3 pages of reproducibility
  appendix. This paper will be published following the SC 2025 conference on
  November 16-21, 2025 at St Louis, MO, USA. ISBN: 978-8-4007-1871-7/2025/11
DOI: 10.1145/3731599.3767589
\\
  Advanced scientific applications require coupling distributed sensor networks
with centralized high-performance computing facilities. Citrus Under Protective
Screening (CUPS) exemplifies this need in digital agriculture, where citrus
research facilities are instrumented with numerous sensors monitoring
environmental conditions and detecting protective screening damage. CUPS
demands access to computational fluid dynamics codes for modeling environmental
conditions and guiding real-time interventions like water application or
robotic repairs. These computing domains have contrasting properties: sensor
networks provide low-performance, limited-capacity, unreliable data access,
while high-performance facilities offer enormous computing power through
high-latency batch processing. Private 5G networks present novel capabilities
addressing this challenge by providing low latency, high throughput, and
reliability necessary for near-real-time coupling of edge sensor networks with
HPC simulations. This work presents xGFabric, an end-to-end system coupling
sensor networks with HPC facilities through Private 5G networks. The prototype
connects remote sensors via 5G network slicing to HPC systems, enabling
real-time digital agriculture simulation.
\\ ( https://arxiv.org/abs/2509.20340 ,  6925kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19512
Date: Tue, 23 Sep 2025 19:30:30 GMT   (388kb)

Title: The Heterogeneous Multi-Agent Challenge
Authors: Charles Dansereau, Junior-Samuel Lopez-Yepez, Karthik Soma, Antoine
  Fagette
Categories: cs.MA cs.AI
Comments: 7 pages. To Appear at ECAI 2025
\\
  Multi-Agent Reinforcement Learning (MARL) is a growing research area which
gained significant traction in recent years, extending Deep RL applications to
a much wider range of problems. A particularly challenging class of problems in
this domain is Heterogeneous Multi-Agent Reinforcement Learning (HeMARL), where
agents with different sensors, resources, or capabilities must cooperate based
on local information. The large number of real-world situations involving
heterogeneous agents makes it an attractive research area, yet underexplored,
as most MARL research focuses on homogeneous agents (e.g., a swarm of identical
robots). In MARL and single-agent RL, standardized environments such as ALE and
SMAC have allowed to establish recognized benchmarks to measure progress.
However, there is a clear lack of such standardized testbed for cooperative
HeMARL. As a result, new research in this field often uses simple environments,
where most algorithms perform near optimally, or uses weakly heterogeneous MARL
environments.
\\ ( https://arxiv.org/abs/2509.19512 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19599
Date: Tue, 23 Sep 2025 21:46:38 GMT   (2154kb)

Title: Knowledge Base-Aware Orchestration: A Dynamic, Privacy-Preserving Method
  for Multi-Agent Systems
Authors: Danilo Trombino, Vincenzo Pecorella, Alessandro de Giulii, Davide
  Tresoldi
Categories: cs.MA cs.AI
\\
  Multi-agent systems (MAS) are increasingly tasked with solving complex,
knowledge-intensive problems where effective agent orchestration is critical.
Conventional orchestration methods rely on static agent descriptions, which
often become outdated or incomplete. This limitation leads to inefficient task
routing, particularly in dynamic environments where agent capabilities
continuously evolve. We introduce Knowledge Base-Aware (KBA) Orchestration, a
novel approach that augments static descriptions with dynamic,
privacy-preserving relevance signals derived from each agent's internal
knowledge base (KB). In the proposed framework, when static descriptions are
insufficient for a clear routing decision, the orchestrator prompts the
subagents in parallel. Each agent then assesses the task's relevance against
its private KB, returning a lightweight ACK signal without exposing the
underlying data. These collected signals populate a shared semantic cache,
providing dynamic indicators of agent suitability for future queries. By
combining this novel mechanism with static descriptions, our method achieves
more accurate and adaptive task routing preserving agent autonomy and data
confidentiality. Benchmarks show that our KBA Orchestration significantly
outperforms static description-driven methods in routing precision and overall
system efficiency, making it suitable for large-scale systems that require
higher accuracy than standard description-driven routing.
\\ ( https://arxiv.org/abs/2509.19599 ,  2154kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2509.19153 (*cross-listing*)
Date: Tue, 23 Sep 2025 15:32:13 GMT   (83kb)

Title: LLMs as verification oracles for Solidity
Authors: Massimo Bartoletti and Enrico Lipparini and Livio Pompianu
Categories: cs.CR cs.AI cs.SE
\\
  Ensuring the correctness of smart contracts is critical, as even subtle flaws
can lead to severe financial losses. While bug detection tools able to spot
common vulnerability patterns can serve as a first line of defense, most
real-world exploits and losses stem from errors in the contract business logic.
Formal verification tools such as SolCMC and the Certora Prover address this
challenge, but their impact remains limited by steep learning curves and
restricted specification languages. Recent works have begun to explore the use
of large language models (LLMs) for security-related tasks such as
vulnerability detection and test generation. Yet, a fundamental question
remains open: can LLMs serve as verification oracles, capable of reasoning
about arbitrary contract-specific properties? In this paper, we provide the
first systematic evaluation of GPT-5, a state-of-the-art reasoning LLM, in this
role. We benchmark its performance on a large dataset of verification tasks,
compare its outputs against those of established formal verification tools, and
assess its practical effectiveness in real-world auditing scenarios. Our study
combines quantitative metrics with qualitative analysis, and shows that recent
reasoning-oriented LLMs can be surprisingly effective as verification oracles,
suggesting a new frontier in the convergence of AI and formal methods for
secure smart contract development and auditing.
\\ ( https://arxiv.org/abs/2509.19153 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19305 (*cross-listing*)
Date: Thu, 4 Sep 2025 08:50:31 GMT   (1459kb)

Title: Wavelet Fourier Diffuser: Frequency-Aware Diffusion Model for
  Reinforcement Learning
Authors: Yifu Luo, Yongzhe Chang, Xueqian Wang
Categories: cs.LG cs.AI eess.SP
\\
  Diffusion probability models have shown significant promise in offline
reinforcement learning by directly modeling trajectory sequences. However,
existing approaches primarily focus on time-domain features while overlooking
frequency-domain features, leading to frequency shift and degraded performance
according to our observation. In this paper, we investigate the RL problem from
a new perspective of the frequency domain. We first observe that
time-domain-only approaches inadvertently introduce shifts in the low-frequency
components of the frequency domain, which results in trajectory instability and
degraded performance. To address this issue, we propose Wavelet Fourier
Diffuser (WFDiffuser), a novel diffusion-based RL framework that integrates
Discrete Wavelet Transform to decompose trajectories into low- and
high-frequency components. To further enhance diffusion modeling for each
component, WFDiffuser employs Short-Time Fourier Transform and cross attention
mechanisms to extract frequency-domain features and facilitate cross-frequency
interaction. Extensive experiment results on the D4RL benchmark demonstrate
that WFDiffuser effectively mitigates frequency shift, leading to smoother,
more stable trajectories and improved decision-making performance over existing
methods.
\\ ( https://arxiv.org/abs/2509.19305 ,  1459kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19306 (*cross-listing*)
Date: Fri, 5 Sep 2025 06:38:36 GMT   (234kb)

Title: A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous
  Wireless Networks
Authors: Jingyi Wang, Zhongyuan Zhao, Qingtian Wang, Zexu Li, Yue Wang, Tony Q.
  S. Quek
Categories: eess.SP cs.AI cs.IT cs.NI math.IT
\\
  Edge intelligence has emerged as a promising strategy to deliver low-latency
and ubiquitous services for mobile devices. Recent advances in fine-tuning
mechanisms of foundation models have enabled edge intelligence by integrating
low-rank adaptation (LoRA) with federated learning. However, in wireless
networks, the device heterogeneity and resource constraints on edge devices
pose great threats to the performance of federated fine-tuning. To tackle these
issues, we propose to optimize federated fine-tuning in heterogenous wireless
networks via online learning. First, the framework of switching-based federated
fine-tuning in wireless networks is provided. The edge devices switches to LoRA
modules dynamically for federated fine-tuning with base station to jointly
mitigate the impact of device heterogeneity and transmission unreliability.
Second, a tractable upper bound on the inference risk gap is derived based on
theoretical analysis. To improve the generalization capability, we formulate a
non-convex mixed-integer programming problem with long-term constraints, and
decouple it into model switching, transmit power control, and bandwidth
allocation subproblems. An online optimization algorithm is developed to solve
the problems with polynomial computational complexity. Finally, the simulation
results on the SST-2 and QNLI data sets demonstrate the performance gains in
test accuracy and energy efficiency.
\\ ( https://arxiv.org/abs/2509.19306 ,  234kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19312 (*cross-listing*)
Date: Tue, 9 Sep 2025 11:25:51 GMT   (541kb)

Title: E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal
  Transmission and Fusion
Authors: Minghui Wu and Zhen Gao
Categories: eess.SP cs.AI cs.IT cs.LG math.IT
\\
  Massive multiple-input multiple-output (MIMO) promises high spectral
efficiency but also leads to high-dimensional downlink channel state
information (CSI), which complicates real-time channel acquisition and
precoding. To address this, we propose an end-to-end (E2E) uplink-downlink CSI
fusion precoding network that jointly models downlink CSI reference signal
(CSI-RS) design, CSI feedback, and base-station (BS) precoding within a single
E2E neural architecture. Concretely, a projection network built on the MAXIM
architecture takes uplink sounding reference signals (SRS) as input and outputs
frequency-, beam-, and port-domain projection matrices for designing downlink
CSI-RS. User equipment (UE) then compresses/quantizes the resulting CSI-RS
observations and feeds back a compact representation. At the base station (BS),
two complementary branches produce candidate precoders: one is a feedback-only
precoding network driven by quantized downlink observations, and the other is
an SRS-only precoding network driven by uplink SRS. These candidate precoders
are subsequently combined by a fusion precoding network to yield the final
transmit precoder. All the modules are trained with a
spectral-efficiency-oriented loss under a three-stage schedule. Simulation
results show that the proposed approach effectively harnesses both SRS-derived
information and UE feedback, achieving markedly better performance than
conventional baselines.
\\ ( https://arxiv.org/abs/2509.19312 ,  541kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19315 (*cross-listing*)
Date: Wed, 10 Sep 2025 05:24:00 GMT   (5213kb)

Title: Advancing Few-Shot Pediatric Arrhythmia Classification with a Novel
  Contrastive Loss and Multimodal Learning
Authors: Yiqiao Chen, Zijian Huang, Zhenghui Feng
Categories: eess.SP cs.AI cs.LG
Comments: 12pages, 10 figures
\\
  Pediatric arrhythmias are a major risk factor for disability and sudden
cardiac death, yet their automated classification remains challenging due to
class imbalance, few-shot categories, and complex signal characteristics, which
severely limit the efficiency and reliability of early screening and clinical
intervention. To address this problem, we propose a multimodal end-to-end deep
learning framework that combines dual-branch convolutional encoders for ECG and
IEGM, semantic attention for cross-modal feature alignment, and a lightweight
Transformer encoder for global dependency modeling. In addition, we introduce a
new contrastive loss fucntion named Adaptive Global Class-Aware Contrastive
Loss (AGCACL) to enhance intra-class compactness and inter-class separability
through class prototypes and a global similarity matrix. To the best of our
knowledge, this is the first systematic study based on the Leipzig Heart Center
pediatric/congenital ECG+IEGM dataset, for which we also provide a complete and
reproducible preprocessing pipeline. Experimental results demonstrate that the
proposed method achieves the overall best performance on this dataset,
including 97.76\% Top-1 Accuracy, 94.08\% Macro Precision, 91.97\% Macro
Recall, 92.97\% Macro F1, and 92.36\% Macro F2, with improvements of +13.64,
+15.96, +19.82, and +19.44 percentage points over the strongest baseline in
Macro Precision/Recall/F1/F2, respectively. These findings indicate that the
framework significantly improves the detectability and robustness for minority
arrhythmia classes, offering potential clinical value for rhythm screening,
pre-procedural assessment, and postoperative follow-up in pediatric and
congenital heart disease populations.
\\ ( https://arxiv.org/abs/2509.19315 ,  5213kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19328 (*cross-listing*)
Date: Sun, 14 Sep 2025 01:26:32 GMT   (1095kb)

Title: Human Activity Recognition Based on Electrocardiogram Data Only
Authors: Sina Montazeri, Waltenegus Dargie, Yunhe Feng, Kewei Sha
Categories: eess.SP cs.AI cs.LG
Comments: This is a preprint version. Content may change before final
  publication
\\
  Human activity recognition is critical for applications such as early
intervention and health analytics. Traditional activity recognition relies on
inertial measurement units (IMUs), which are resource intensive and require
calibration. Although electrocardiogram (ECG)-based methods have been explored,
these have typically served as supplements to IMUs or have been limited to
broad categorical classification such as fall detection or active vs. inactive
in daily activities. In this paper, we advance the field by demonstrating, for
the first time, robust recognition of activity only with ECG in six distinct
activities, which is beyond the scope of previous work. We design and evaluate
three new deep learning models, including a CNN classifier with
Squeeze-and-Excitation blocks for channel-wise feature recalibration, a ResNet
classifier with dilated convolutions for multiscale temporal dependency
capture, and a novel CNNTransformer hybrid combining convolutional feature
extraction with attention mechanisms for long-range temporal relationship
modeling. Tested on data from 54 subjects for six activities, all three models
achieve over 94% accuracy for seen subjects, while CNNTransformer hybrid
reaching the best accuracy of 72% for unseen subjects, a result that can be
further improved by increasing the training population. This study demonstrates
the first successful ECG-only activity classification in multiple physical
activities, offering significant potential for developing next-generation
wearables capable of simultaneous cardiac monitoring and activity recognition
without additional motion sensors.
\\ ( https://arxiv.org/abs/2509.19328 ,  1095kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19330 (*cross-listing*)
Date: Sun, 14 Sep 2025 03:50:07 GMT   (515kb)

Title: LibEMER: A novel benchmark and algorithms library for EEG-based
  Multimodal Emotion Recognition
Authors: Zejun Liu, Yunshan Chen, Chengxi Xie, Huan Liu
Categories: eess.SP cs.AI cs.HC cs.LG cs.MM
Comments: 5 pages, 2 figures
\\
  EEG-based multimodal emotion recognition(EMER) has gained significant
attention and witnessed notable advancements, the inherent complexity of human
neural systems has motivated substantial efforts toward multimodal approaches.
However, this field currently suffers from three critical limitations: (i) the
absence of open-source implementations. (ii) the lack of standardized and
transparent benchmarks for fair performance analysis. (iii) in-depth discussion
regarding main challenges and promising research directions is a notable
scarcity. To address these challenges, we introduce LibEMER, a unified
evaluation framework that provides fully reproducible PyTorch implementations
of curated deep learning methods alongside standardized protocols for data
preprocessing, model realization, and experimental setups. This framework
enables unbiased performance assessment on three widely-used public datasets
across two learning tasks. The open-source library is publicly accessible at:
https://anonymous.4open.science/r/2025ULUIUBUEUMUEUR485384
\\ ( https://arxiv.org/abs/2509.19330 ,  515kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19331 (*cross-listing*)
Date: Sun, 14 Sep 2025 15:24:43 GMT   (255kb)

Title: Holographic Transformers for Complex-Valued Signal Processing:
  Integrating Phase Interference into Self-Attention
Authors: Enhao Huang, Zhiyu Zhang, Tianxiang Xu, Chunshu Xia, Kaichun Hu,
  Yuchen Yang, Tongtong Pan, Dong Dong, Zhan Qin
Categories: eess.SP cs.AI cs.LG
\\
  Complex-valued signals encode both amplitude and phase, yet most deep models
treat attention as real-valued correlation, overlooking interference effects.
We introduce the Holographic Transformer, a physics-inspired architecture that
incorporates wave interference principles into self-attention. Holographic
attention modulates interactions by relative phase and coherently superimposes
values, ensuring consistency between amplitude and phase. A dual-headed decoder
simultaneously reconstructs the input and predicts task outputs, preventing
phase collapse when losses prioritize magnitude over phase. We demonstrate that
holographic attention implements a discrete interference operator and maintains
phase consistency under linear mixing. Experiments on PolSAR image
classification and wireless channel prediction show strong performance,
achieving high classification accuracy and F1 scores, low regression error, and
increased robustness to phase perturbations. These results highlight that
enforcing physical consistency in attention leads to generalizable improvements
in complex-valued learning and provides a unified, physics-based framework for
coherent signal modeling. The code is available at
https://github.com/EonHao/Holographic-Transformers.
\\ ( https://arxiv.org/abs/2509.19331 ,  255kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19335 (*cross-listing*)
Date: Mon, 15 Sep 2025 06:46:39 GMT   (2499kb)

Title: CSIYOLO: An Intelligent CSI-based Scatter Sensing Framework for
  Integrated Sensing and Communication Systems
Authors: Xudong Zhang, Jingbo Tan, Zhizhen Ren, Jintao Wang, Yihua Ma, Jian
  Song
Categories: eess.SP cs.AI
Comments: 13 pages, 16 figures, 3 tables. This work has been submitted to the
  IEEE for possible publication
\\
  ISAC is regarded as a promising technology for next-generation communication
systems, enabling simultaneous data transmission and target sensing. Among
various tasks in ISAC, scatter sensing plays a crucial role in exploiting the
full potential of ISAC and supporting applications such as autonomous driving
and low-altitude economy. However, most existing methods rely on either
waveform and hardware modifications or traditional signal processing schemes,
leading to poor compatibility with current communication systems and limited
sensing accuracy. To address these challenges, we propose CSIYOLO, a framework
that performs scatter localization only using estimated CSI from a single base
station-user equipment pair. This framework comprises two main components:
anchor-based scatter parameter detection and CSI-based scatter localization.
First, by formulating scatter parameter extraction as an image detection
problem, we propose an anchor-based scatter parameter detection method inspired
by You Only Look Once architectures. After that, a CSI-based localization
algorithm is derived to determine scatter locations with extracted parameters.
Moreover, to improve localization accuracy and implementation efficiency, we
design an extendable network structure with task-oriented optimizations,
enabling multi-scale anchor detection and better adaptation to CSI
characteristics. A noise injection training strategy is further designed to
enhance robustness against channel estimation errors. Since the proposed
framework operates solely on estimated CSI without modifying waveforms or
signal processing pipelines, it can be seamlessly integrated into existing
communication systems as a plugin. Experiments show that our proposed method
can significantly outperform existing methods in scatter localization accuracy
with relatively low complexities under varying numbers of scatters and
estimation errors.
\\ ( https://arxiv.org/abs/2509.19335 ,  2499kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19337 (*cross-listing*)
Date: Mon, 15 Sep 2025 18:03:19 GMT   (2002kb)

Title: Radio Propagation Modelling: To Differentiate or To Deep Learn, That Is
  The Question
Authors: Stefanos Bakirtzis, Paul Almasan, Jos\'e Su\'arez-Varela, Gabriel O.
  Ferreira, Michail Kalntis, Andr\'e Felipe Zanella, Ian Wassell, and Andra
  Lutu
Categories: cs.NI cs.AI
\\
  Differentiable ray tracing has recently challenged the status quo in radio
propagation modelling and digital twinning. Promising unprecedented speed and
the ability to learn from real-world data, it offers a real alternative to
conventional deep learning (DL) models. However, no experimental evaluation on
production-grade networks has yet validated its assumed scalability or
practical benefits. This leaves mobile network operators (MNOs) and the
research community without clear guidance on its applicability. In this paper,
we fill this gap by employing both differentiable ray tracing and DL models to
emulate radio coverage using extensive real-world data collected from the
network of a major MNO, covering 13 cities and more than 10,000 antennas. Our
results show that, while differentiable ray-tracing simulators have contributed
to reducing the efficiency-accuracy gap, they struggle to generalize from
real-world data at a large scale, and they remain unsuitable for real-time
applications. In contrast, DL models demonstrate higher accuracy and faster
adaptation than differentiable ray-tracing simulators across urban, suburban,
and rural deployments, achieving accuracy gains of up to 3 dB. Our experimental
results aim to provide timely insights into a fundamental open question with
direct implications on the wireless ecosystem and future research.
\\ ( https://arxiv.org/abs/2509.19337 ,  2002kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19339 (*cross-listing*)
Date: Tue, 16 Sep 2025 01:32:04 GMT   (36688kb)

Title: Multi-population Ensemble Genetic Programming via Cooperative
  Coevolution and Multi-view Learning for Classification
Authors: Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad
  Reza Nikoo, Fang Chen, Amir H. Gandomi
Categories: cs.NE cs.AI
Comments: 59 Pages, 68 Figures, 27 Tables
MSC-class: 68T20
\\
  This paper introduces Multi-population Ensemble Genetic Programming (MEGP), a
computational intelligence framework that integrates cooperative coevolution
and the multiview learning paradigm to address classification challenges in
high-dimensional and heterogeneous feature spaces. MEGP decomposes the input
space into conditionally independent feature subsets, enabling multiple
subpopulations to evolve in parallel while interacting through a dynamic
ensemble-based fitness mechanism. Each individual encodes multiple genes whose
outputs are aggregated via a differentiable softmax-based weighting layer,
enhancing both model interpretability and adaptive decision fusion. A hybrid
selection mechanism incorporating both isolated and ensemble-level fitness
promotes inter-population cooperation while preserving intra-population
diversity. This dual-level evolutionary dynamic facilitates structured search
exploration and reduces premature convergence. Experimental evaluations across
eight benchmark datasets demonstrate that MEGP consistently outperforms a
baseline GP model in terms of convergence behavior and generalization
performance. Comprehensive statistical analyses validate significant
improvements in Log-Loss, Precision, Recall, F1 score, and AUC. MEGP also
exhibits robust diversity retention and accelerated fitness gains throughout
evolution, highlighting its effectiveness for scalable, ensemble-driven
evolutionary learning. By unifying population-based optimization, multi-view
representation learning, and cooperative coevolution, MEGP contributes a
structurally adaptive and interpretable framework that advances emerging
directions in evolutionary machine learning.
\\ ( https://arxiv.org/abs/2509.19339 ,  36688kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19340 (*cross-listing*)
Date: Tue, 16 Sep 2025 08:48:44 GMT   (7468kb)

Title: Joint Channel Estimation and Computation Offloading in Fluid
  Antenna-assisted MEC Networks
Authors: Ying Ju, Mingdong Li, Haoyu Wang, Lei Liu, Youyang Qu, Mianxiong Dong,
  Victor C. M. Leung, and Chau Yuen
Categories: eess.SP cs.AI cs.IT cs.NI math.IT
\\
  With the emergence of fluid antenna (FA) in wireless communications, the
capability to dynamically adjust port positions offers substantial benefits in
spatial diversity and spectrum efficiency, which are particularly valuable for
mobile edge computing (MEC) systems. Therefore, we propose an FA-assisted MEC
offloading framework to minimize system delay. This framework faces two severe
challenges, which are the complexity of channel estimation due to dynamic port
configuration and the inherent non-convexity of the joint optimization problem.
Firstly, we propose Information Bottleneck Metric-enhanced Channel Compressed
Sensing (IBM-CCS), which advances FA channel estimation by integrating
information relevance into the sensing process and capturing key features of FA
channels effectively. Secondly, to address the non-convex and high-dimensional
optimization problem in FA-assisted MEC systems, which includes FA port
selection, beamforming, power control, and resource allocation, we propose a
game theory-assisted Hierarchical Twin-Dueling Multi-agent Algorithm (HiTDMA)
based offloading scheme, where the hierarchical structure effectively decouples
and coordinates the optimization tasks between the user side and the base
station side. Crucially, the game theory effectively reduces the dimensionality
of power control variables, allowing deep reinforcement learning (DRL) agents
to achieve improved optimization efficiency. Numerical results confirm that the
proposed scheme significantly reduces system delay and enhances offloading
performance, outperforming benchmarks. Additionally, the IBM-CCS channel
estimation demonstrates superior accuracy and robustness under varying port
densities, contributing to efficient communication under imperfect CSI.
\\ ( https://arxiv.org/abs/2509.19340 ,  7468kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19341 (*cross-listing*)
Date: Tue, 16 Sep 2025 09:14:15 GMT   (1167kb)

Title: Fine-Grained AI Model Caching and Downloading With Coordinated
  Multipoint Broadcasting in Multi-Cell Edge Networks
Authors: Yang Fu, Peng Qin, Yueyue Zhang, Yifei Wang
Categories: cs.NI cs.AI cs.LG
\\
  6G networks are envisioned to support on-demand AI model downloading to
accommodate diverse inference requirements of end users. By proactively caching
models at edge nodes, users can retrieve the requested models with low latency
for on-device AI inference. However, the substantial size of contemporary AI
models poses significant challenges for edge caching under limited storage
capacity, as well as for the concurrent delivery of heterogeneous models over
wireless channels. To address these challenges, we propose a fine-grained AI
model caching and downloading system that exploits parameter reusability,
stemming from the common practice of fine-tuning task-specific models from a
shared pre-trained model with frozen parameters. This system selectively caches
model parameter blocks (PBs) at edge nodes, eliminating redundant storage of
reusable parameters across different cached models. Additionally, it
incorporates coordinated multipoint (CoMP) broadcasting to simultaneously
deliver reusable PBs to multiple users, thereby enhancing downlink spectrum
utilization. Under this arrangement, we formulate a model downloading delay
minimization problem to jointly optimize PB caching, migration (among edge
nodes), and broadcasting beamforming. To tackle this intractable problem, we
develop a distributed multi-agent learning framework that enables edge nodes to
explicitly learn mutual influence among their actions, thereby facilitating
cooperation. Furthermore, a data augmentation approach is proposed to
adaptively generate synthetic training samples through a predictive model,
boosting sample efficiency and accelerating policy learning. Both theoretical
analysis and simulation experiments validate the superior convergence
performance of the proposed learning framework.
\\ ( https://arxiv.org/abs/2509.19341 ,  1167kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19351 (*cross-listing*)
Date: Thu, 18 Sep 2025 00:12:58 GMT   (3959kb)

Title: The Impact of Structural Changes on Learning Capacity in the Fly
  Olfactory Neural Circuit
Authors: Katherine Xie, Gabriel Koch Ocker
Categories: q-bio.NC cs.AI cs.LG cs.NE
\\
  The Drosophila mushroom body (MB) is known to be involved in olfactory
learning and memory; the synaptic plasticity of the Kenyon cell (KC) to
mushroom body output neuron (MBON) synapses plays a key role in the learning
process. Previous research has focused on projection neuron (PN) to Kenyon cell
(KC) connectivity within the MB; we examine how perturbations to the mushroom
body circuit structure and changes in connectivity, specifically within the KC
to mushroom body output neuron (MBON) neural circuit, affect the MBONs' ability
to distinguish between odor classes. We constructed a neural network that
incorporates the connectivity between PNs, KCs, and MBONs. To train our model,
we generated ten artificial input classes, which represent the projection
neuron activity in response to different odors. We collected data on the number
of KC-to-MBON connections, MBON error rates, and KC-to-MBON synaptic weights,
among other metrics. We observed that MBONs with very few presynaptic KCs
consistently performed worse than others in the odor classification task. The
developmental types of KCs also played a significant role in each MBON's
output. We performed random and targeted KC ablation and observed that ablating
developmentally mature KCs had a greater negative impact on MBONs' learning
capacity than ablating immature KCs. Random and targeted pruning of KC-MBON
synaptic connections yielded results largely consistent with the ablation
experiments. To further explore the various types of KCs, we also performed
rewiring experiments in the PN to KC circuit. Our study furthers our
understanding of olfactory neuroplasticity and provides important clues to
understanding learning and memory in general. Understanding how the olfactory
circuits process and learn can also have potential applications in artificial
intelligence and treatments for neurodegenerative diseases.
\\ ( https://arxiv.org/abs/2509.19351 ,  3959kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19359 (*cross-listing*)
Date: Thu, 18 Sep 2025 14:06:40 GMT   (1598kb)

Title: Anti-Money Laundering Systems Using Deep Learning
Authors: Mashkhal Abdalwahid Sidiq, Yimamu Kirubel Wondaferew
Categories: cs.LG cs.AI
Comments: 22 pages, 9 figures
\\
  In this paper, we focused on using deep learning methods for detecting money
laundering in financial transaction networks, in order to demonstrate that it
can be used as a complement or instead of the more commonly used rule-based
systems and conventional Anti-Money Laundering (AML) systems. The paper
explores the pivotal role played by Anti-Money Laundering (AML) activities in
the global financial industry. It underscores the drawbacks of conventional AML
systems, which exhibit high rates of false positives and lack the
sophistication to uncover intricate money laundering schemes. To tackle these
challenges, the paper proposes an advanced AML system that capitalizes on link
analysis using deep learning techniques. At the heart of this system lies the
utilization of centrality algorithms like Degree Centrality, Closeness
Centrality, Betweenness Centrality, and PageRank. These algorithms enhance the
system's capability to identify suspicious activities by examining the
influence and interconnections within networks of financial transactions. The
significance of Anti-Money Laundering (AML) efforts within the global financial
sector is discussed in this paper. It highlights the limitations of traditional
AML systems. The results showed the practicality and superiority of the new
implementation of the GCN model, which is a preferable method for connectively
structured data, meaning that a transaction or account is analyzed in the
context of its financial environment. In addition, the paper delves into the
prospects of Anti-Money Laundering (AML) efforts, proposing the integration of
emerging technologies such as deep learning and centrality algorithms. This
integration holds promise for enhancing the effectiveness of AML systems by
refining their capabilities.
\\ ( https://arxiv.org/abs/2509.19359 ,  1598kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19362 (*cross-listing*)
Date: Thu, 18 Sep 2025 15:47:05 GMT   (4719kb)

Title: DeepACTIF: Efficient Feature Attribution via Activation Traces in Neural
  Sequence Models
Authors: Benedikt W. Hosp
Categories: cs.LG cs.AI
\\
  Feature attribution is essential for interpreting deep learning models,
particularly in time-series domains such as healthcare, biometrics, and
human-AI interaction. However, standard attribution methods, such as Integrated
Gradients or SHAP, are computationally intensive and not well-suited for
real-time applications. We present DeepACTIF, a lightweight and
architecture-aware feature attribution method that leverages internal
activations of sequence models to estimate feature importance efficiently.
Focusing on LSTM-based networks, we introduce an inverse-weighted aggregation
scheme that emphasises stability and magnitude of activations across time
steps. Our evaluation across three biometric gaze datasets shows that DeepACTIF
not only preserves predictive performance under severe feature reduction (top
10% of features) but also significantly outperforms established methods,
including SHAP, IG, and DeepLIFT, in terms of both accuracy and statistical
robustness. Using Wilcoxon signed-rank tests and effect size analysis, we
demonstrate that DeepACTIF yields more informative feature rankings with
significantly lower error across all top-k conditions (10 - 40%). Our
experiments demonstrate that DeepACTIF not only reduces computation time and
memory usage by orders of magnitude but also preserves model accuracy when
using only top-ranked features. That makes DeepACTIF a viable solution for
real-time interpretability on edge devices such as mobile XR headsets or
embedded health monitors.
\\ ( https://arxiv.org/abs/2509.19362 ,  4719kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19363 (*cross-listing*)
Date: Thu, 18 Sep 2025 20:09:07 GMT   (610kb)

Title: Analyzing the Impact of Credit Card Fraud on Economic Fluctuations of
  American Households Using an Adaptive Neuro-Fuzzy Inference System
Authors: Zhuqi Wang, Qinghe Zhang, Zhuopei Cheng
Categories: cs.LG cs.AI
\\
  Credit card fraud is assuming growing proportions as a major threat to the
financial position of American household, leading to unpredictable changes in
household economic behavior. To solve this problem, in this paper, a new hybrid
analysis method is presented by using the Enhanced ANFIS. The model proposes
several advances of the conventional ANFIS framework and employs a
multi-resolution wavelet decomposition module and a temporal attention
mechanism. The model performs discrete wavelet transformations on historical
transaction data and macroeconomic indicators to generate localized economic
shock signals. The transformed features are then fed into a deep fuzzy rule
library which is based on Takagi-Sugeno fuzzy rules with adaptive Gaussian
membership functions. The model proposes a temporal attention encoder that
adaptively assigns weights to multi-scale economic behavior patterns,
increasing the effectiveness of relevance assessment in the fuzzy inference
stage and enhancing the capture of long-term temporal dependencies and
anomalies caused by fraudulent activities. The proposed method differs from
classical ANFIS which has fixed input-output relations since it integrates
fuzzy rule activation with the wavelet basis selection and the temporal
correlation weights via a modular training procedure. Experimental results show
that the RMSE was reduced by 17.8% compared with local neuro-fuzzy models and
conventional LSTM models.
\\ ( https://arxiv.org/abs/2509.19363 ,  610kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19366 (*cross-listing*)
Date: Fri, 19 Sep 2025 01:27:18 GMT   (1081kb)

Title: Unsupervised Outlier Detection in Audit Analytics: A Case Study Using
  USA Spending Data
Authors: Buhe Li, Berkay Kaplan, Maksym Lazirko, Aleksandr Kogan
Categories: cs.LG cs.AI
\\
  This study investigates the effectiveness of unsupervised outlier detection
methods in audit analytics, utilizing USA spending data from the U.S.
Department of Health and Human Services (DHHS) as a case example. We employ and
compare multiple outlier detection algorithms, including Histogram-based
Outlier Score (HBOS), Robust Principal Component Analysis (PCA), Minimum
Covariance Determinant (MCD), and K-Nearest Neighbors (KNN) to identify
anomalies in federal spending patterns. The research addresses the growing need
for efficient and accurate anomaly detection in large-scale governmental
datasets, where traditional auditing methods may fall short. Our methodology
involves data preparation, algorithm implementation, and performance evaluation
using precision, recall, and F1 scores. Results indicate that a hybrid
approach, combining multiple detection strategies, enhances the robustness and
accuracy of outlier identification in complex financial data. This study
contributes to the field of audit analytics by providing insights into the
comparative effectiveness of various outlier detection models and demonstrating
the potential of unsupervised learning techniques in improving audit quality
and efficiency. The findings have implications for auditors, policymakers, and
researchers seeking to leverage advanced analytics in governmental financial
oversight and risk management.
\\ ( https://arxiv.org/abs/2509.19366 ,  1081kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19372 (*cross-listing*)
Date: Fri, 19 Sep 2025 10:54:22 GMT   (61kb)

Title: Representation-based Broad Hallucination Detectors Fail to Generalize
  Out of Distribution
Authors: Zuzanna Dubanowska, Maciej \.Zelaszczyk, Micha{\l} Brzozowski, Paolo
  Mandica, Micha{\l} Karpowicz
Categories: cs.LG cs.AI
Comments: Accepted in EMNLP 2025 Findings
\\
  We critically assess the efficacy of the current SOTA in hallucination
detection and find that its performance on the RAGTruth dataset is largely
driven by a spurious correlation with data. Controlling for this effect,
state-of-the-art performs no better than supervised linear probes, while
requiring extensive hyperparameter tuning across datasets. Out-of-distribution
generalization is currently out of reach, with all of the analyzed methods
performing close to random. We propose a set of guidelines for hallucination
detection and its evaluation.
\\ ( https://arxiv.org/abs/2509.19372 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19375 (*cross-listing*)
Date: Fri, 19 Sep 2025 21:22:29 GMT   (48kb)

Title: Uncertainty Quantification of Large Language Models using Approximate
  Bayesian Computation
Authors: Mridul Sharma (1), Adeetya Patel (1), Zaneta D' Souza (1), Samira
  Abbasgholizadeh Rahimi (1 and 3), Siva Reddy (2 and 3), Sreenath Madathil (1)
  ((1) Faculty of Dental Medicine and Oral Health Sciences, McGill University,
  Montreal, Canada (2) School of Computer Science, McGill University, Montreal,
  Canada (3) Mila-Quebec Artificial Intelligence Institute, Montreal, Canada)
Categories: cs.LG cs.AI stat.ML
\\
  Despite their widespread applications, Large Language Models (LLMs) often
struggle to express uncertainty, posing a challenge for reliable deployment in
high stakes and safety critical domains like clinical diagnostics. Existing
standard baseline methods such as model logits and elicited probabilities
produce overconfident and poorly calibrated estimates. In this work, we propose
Approximate Bayesian Computation (ABC), a likelihood-free Bayesian inference,
based approach that treats LLMs as a stochastic simulator to infer posterior
distributions over predictive probabilities. We evaluate our ABC approach on
two clinically relevant benchmarks: a synthetic oral lesion diagnosis dataset
and the publicly available GretelAI symptom-to-diagnosis dataset. Compared to
standard baselines, our approach improves accuracy by up to 46.9\%, reduces
Brier scores by 74.4\%, and enhances calibration as measured by Expected
Calibration Error (ECE) and predictive entropy.
\\ ( https://arxiv.org/abs/2509.19375 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19376 (*cross-listing*)
Date: Sat, 20 Sep 2025 00:19:37 GMT   (26kb)

Title: Solving Freshness in RAG: A Simple Recency Prior and the Limits of
  Heuristic Trend Detection
Authors: Matthew Grofsky
Categories: cs.LG cs.AI
DOI: 10.36227/techrxiv.175832475.57637876/v1
\\
  We address temporal failures in RAG systems using two methods on
cybersecurity data. A simple recency prior achieved an accuracy of 1.00 on
freshness tasks. In contrast, a clustering heuristic for topic evolution failed
(0.08 F1-score), showing trend detection requires methods beyond simple
heuristics.
\\ ( https://arxiv.org/abs/2509.19376 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19379 (*cross-listing*)
Date: Sat, 20 Sep 2025 05:44:02 GMT   (275kb)

Title: Learning from Observation: A Survey of Recent Advances
Authors: Returaj Burnwal, Hriday Mehta, Nirav Pravinbhai Bhatt, Balaraman
  Ravindran
Categories: cs.LG cs.AI cs.RO stat.ML
\\
  Imitation Learning (IL) algorithms offer an efficient way to train an agent
by mimicking an expert's behavior without requiring a reward function. IL
algorithms often necessitate access to state and action information from expert
demonstrations. Although expert actions can provide detailed guidance,
requiring such action information may prove impractical for real-world
applications where expert actions are difficult to obtain. To address this
limitation, the concept of learning from observation (LfO) or state-only
imitation learning (SOIL) has recently gained attention, wherein the imitator
only has access to expert state visitation information. In this paper, we
present a framework for LfO and use it to survey and classify existing LfO
methods in terms of their trajectory construction, assumptions and algorithm's
design choices. This survey also draws connections between several related
fields like offline RL, model-based RL and hierarchical RL. Finally, we use our
framework to identify open problems and suggest future research directions.
\\ ( https://arxiv.org/abs/2509.19379 ,  275kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19384 (*cross-listing*)
Date: Sun, 21 Sep 2025 14:12:28 GMT   (2541kb)

Title: Data-Driven Reconstruction of Significant Wave Heights from Sparse
  Observations
Authors: Hongyuan Shi, Yilin Zhai, Ping Dong, Zaijin You, Chao Zhan, Qing Wang
Categories: eess.SP cs.AI cs.LG physics.ao-ph
\\
  Reconstructing high-resolution regional significant wave height fields from
sparse and uneven buoy observations remains a core challenge for ocean
monitoring and risk-aware operations. We introduce AUWave, a hybrid deep
learning framework that fuses a station-wise sequence encoder (MLP) with a
multi-scale U-Net enhanced by a bottleneck self-attention layer to recover
32$\times$32 regional SWH fields. A systematic Bayesian hyperparameter search
with Optuna identifies the learning rate as the dominant driver of
generalization, followed by the scheduler decay and the latent dimension. Using
NDBC buoy observations and ERA5 reanalysis over the Hawaii region, AUWave
attains a minimum validation loss of 0.043285 and a slightly right-skewed RMSE
distribution. Spatial errors are lowest near observation sites and increase
with distance, reflecting identifiability limits under sparse sampling.
Sensitivity experiments show that AUWave consistently outperforms a
representative baseline in data-richer configurations, while the baseline is
only marginally competitive in the most underdetermined single-buoy cases. The
architecture's multi-scale and attention components translate into accuracy
gains when minimal but non-trivial spatial anchoring is available. Error maps
and buoy ablations reveal key anchor stations whose removal disproportionately
degrades performance, offering actionable guidance for network design. AUWave
provides a scalable pathway for gap filling, high-resolution priors for data
assimilation, and contingency reconstruction.
\\ ( https://arxiv.org/abs/2509.19384 ,  2541kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19391 (*cross-listing*)
Date: Mon, 22 Sep 2025 17:15:23 GMT   (203kb)

Title: TensLoRA: Tensor Alternatives for Low-Rank Adaptation
Authors: Axel Marmoret, Reda Bensaid, Jonathan Lys, Vincent Gripon,
  Fran\c{c}ois Leduc-Primeau
Categories: cs.LG cs.AI
Comments: Submitted at ICASSP 2026. 5 pages, 1 figure, 2 tables. Code can be
  found at https://github.com/ax-le/TensLoRA
MSC-class: 68T
ACM-class: I.2.6; I.2.7; I.2.10
\\
  Low-Rank Adaptation (LoRA) is widely used to efficiently adapt Transformers
by adding trainable low-rank matrices to attention projections. While
effective, these matrices are considered independent for each attention
projection (Query, Key, and Value) and each layer. Recent extensions have
considered joint, tensor-based adaptations, but only in limited forms and
without a systematic framework. We introduce TensLoRA, a unified framework that
aggregates LoRA updates into higher-order tensors and models a broad family of
tensor-based low-rank adaptations. Our formulation generalizes existing
tensor-based methods and enables mode-specific compression rates, allowing
parameter budgets to be tailored according to the modality and task.
Experiments on vision and language benchmarks reveal that the tensor
construction directly impacts performance, sometimes better than standard LoRA
under similar parameter counts.
\\ ( https://arxiv.org/abs/2509.19391 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19396 (*cross-listing*)
Date: Tue, 23 Sep 2025 03:40:22 GMT   (1629kb)

Title: OmniFed: A Modular Framework for Configurable Federated Learning from
  Edge to HPC
Authors: Sahil Tyagi, Andrei Cozma, Olivera Kotevska, Feiyi Wang
Categories: cs.LG cs.AI cs.CR cs.DC
\\
  Federated Learning (FL) is critical for edge and High Performance Computing
(HPC) where data is not centralized and privacy is crucial. We present OmniFed,
a modular framework designed around decoupling and clear separation of concerns
for configuration, orchestration, communication, and training logic. Its
architecture supports configuration-driven prototyping and code-level
override-what-you-need customization. We also support different topologies,
mixed communication protocols within a single deployment, and popular training
algorithms. It also offers optional privacy mechanisms including Differential
Privacy (DP), Homomorphic Encryption (HE), and Secure Aggregation (SA), as well
as compression strategies. These capabilities are exposed through well-defined
extension points, allowing users to customize topology and orchestration,
learning logic, and privacy/compression plugins, all while preserving the
integrity of the core system. We evaluate multiple models and algorithms to
measure various performance metrics. By unifying topology configuration,
mixed-protocol communication, and pluggable modules in one stack, OmniFed
streamlines FL deployment across heterogeneous environments. Github repository
is available at https://github.com/at-aaims/OmniFed.
\\ ( https://arxiv.org/abs/2509.19396 ,  1629kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19397 (*cross-listing*)
Date: Tue, 23 Sep 2025 03:54:39 GMT   (2282kb)

Title: Self-Alignment Learning to Improve Myocardial Infarction Detection from
  Single-Lead ECG
Authors: Jiarui Jin, Xiaocheng Fang, Haoyu Wang, Jun Li, Che Liu, Donglin Xie,
  Hongyan Li, Shenda Hong
Categories: eess.SP cs.AI cs.LG
\\
  Myocardial infarction is a critical manifestation of coronary artery disease,
yet detecting it from single-lead electrocardiogram (ECG) remains challenging
due to limited spatial information. An intuitive idea is to convert single-lead
into multiple-lead ECG for classification by pre-trained models, but generative
methods optimized at the signal level in most cases leave a large latent space
gap, ultimately degrading diagnostic performance. This naturally raises the
question of whether latent space alignment could help. However, most prior ECG
alignment methods focus on learning transformation invariance, which mismatches
the goal of single-lead detection. To address this issue, we propose SelfMIS, a
simple yet effective alignment learning framework to improve myocardial
infarction detection from single-lead ECG. Discarding manual data
augmentations, SelfMIS employs a self-cutting strategy to pair multiple-lead
ECG with their corresponding single-lead segments and directly align them in
the latent space. This design shifts the learning objective from pursuing
transformation invariance to enriching the single-lead representation,
explicitly driving the single-lead ECG encoder to learn a representation
capable of inferring global cardiac context from the local signal.
Experimentally, SelfMIS achieves superior performance over baseline models
across nine myocardial infarction types while maintaining a simpler
architecture and lower computational overhead, thereby substantiating the
efficacy of direct latent space alignment. Our code and checkpoint will be
publicly available after acceptance.
\\ ( https://arxiv.org/abs/2509.19397 ,  2282kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19398 (*cross-listing*)
Date: Tue, 23 Sep 2025 04:53:51 GMT   (476kb)

Title: FedOC: Multi-Server FL with Overlapping Client Relays in Wireless Edge
  Networks
Authors: Yun Ji, Zeyu Chen, Xiaoxiong Zhong, Yanan Ma, Sheng Zhang, and Yuguang
  Fang
Categories: cs.NI cs.AI
\\
  Multi-server Federated Learning (FL) has emerged as a promising solution to
mitigate communication bottlenecks of single-server FL. We focus on a typical
multi-server FL architecture, where the regions covered by different edge
servers (ESs) may overlap. A key observation of this architecture is that
clients located in the overlapping areas can access edge models from multiple
ESs. Building on this insight, we propose FedOC (Federated learning with
Overlapping Clients), a novel framework designed to fully exploit the potential
of these overlapping clients. In FedOC, overlapping clients could serve dual
roles: (1) as Relay Overlapping Clients (ROCs), they forward edge models
between neighboring ESs in real time to facilitate model sharing among
different ESs; and (2) as Normal Overlapping Clients (NOCs), they dynamically
select their initial model for local training based on the edge model delivery
time, which enables indirect data fusion among different regions of ESs. The
overall FedOC workflow proceeds as follows: in every round, each client trains
local model based on the earliest received edge model and transmits to the
respective ESs for model aggregation. Then each ES transmits the aggregated
edge model to neighboring ESs through ROC relaying. Upon receiving the relayed
models, each ES performs a second aggregation and subsequently broadcasts the
updated model to covered clients. The existence of ROCs enables the model of
each ES to be disseminated to the other ESs in a decentralized manner, which
indirectly achieves intercell model and speeding up the training process,
making it well-suited for latency-sensitive edge environments. Extensive
experimental results show remarkable performance gains of our scheme compared
to existing methods.
\\ ( https://arxiv.org/abs/2509.19398 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19403 (*cross-listing*)
Date: Tue, 23 Sep 2025 07:38:37 GMT   (1009kb)

Title: Online Adaptation via Dual-Stage Alignment and Self-Supervision for
  Fast-Calibration Brain-Computer Interfaces
Authors: Sheng-Bin Duan, Jian-Long Hao, Tian-Yu Xiang, Xiao-Hu Zhou, Mei-Jiang
  Gui, Xiao-Liang Xie, Shi-Qi Liu, and Zeng-Guang Hou
Categories: eess.SP cs.AI cs.LG
\\
  Individual differences in brain activity hinder the online application of
electroencephalogram (EEG)-based brain computer interface (BCI) systems. To
overcome this limitation, this study proposes an online adaptation algorithm
for unseen subjects via dual-stage alignment and self-supervision. The
alignment process begins by applying Euclidean alignment in the EEG data space
and then updates batch normalization statistics in the representation space.
Moreover, a self-supervised loss is designed to update the decoder. The loss is
computed by soft pseudo-labels derived from the decoder as a proxy for the
unknown ground truth, and is calibrated by Shannon entropy to facilitate
self-supervised training. Experiments across five public datasets and seven
decoders show the proposed algorithm can be integrated seamlessly regardless of
BCI paradigm and decoder architecture. In each iteration, the decoder is
updated with a single online trial, which yields average accuracy gains of 4.9%
on steady-state visual evoked potentials (SSVEP) and 3.6% on motor imagery.
These results support fast-calibration operation and show that the proposed
algorithm has great potential for BCI applications.
\\ ( https://arxiv.org/abs/2509.19403 ,  1009kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19405 (*cross-listing*)
Date: Tue, 23 Sep 2025 09:09:45 GMT   (15720kb)

Title: Improving Outdoor Multi-cell Fingerprinting-based Positioning via Mobile
  Data Augmentation
Authors: Tony Chahoud, Lorenzo Mario Amorosa, Riccardo Marini, and Luca De
  Nardis
Categories: cs.NI cs.AI
\\
  Accurate outdoor positioning in cellular networks is hindered by sparse,
heterogeneous measurement collections and the high cost of exhaustive site
surveys. This paper introduces a lightweight, modular mobile data augmentation
framework designed to enhance multi-cell fingerprinting-based positioning using
operator-collected minimization of drive test (MDT) records. The proposed
approach decouples spatial and radio-feature synthesis: kernel density
estimation (KDE) models the empirical spatial distribution to generate
geographically coherent synthetic locations, while a k-nearest-neighbor
(KNN)-based block produces augmented per-cell radio fingerprints. The
architecture is intentionally training-free, interpretable, and suitable for
distributed or on-premise operator deployments, supporting privacy-aware
workflows. We both validate each augmentation module independently and assess
its end-to-end impact on fingerprinting-based positioning using a real-world
MDT dataset provided by an Italian mobile network operator across diverse urban
and peri-urban scenarios. Results show that the proposed KDE-KNN augmentation
consistently improves positioning performance, with the largest benefits in
sparsely sampled or structurally complex regions; we also observe
region-dependent saturation effects as augmentation increases. The framework
offers a practical, low-complexity path to enhance operator positioning
services using existing mobile data traces.
\\ ( https://arxiv.org/abs/2509.19405 ,  15720kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19406 (*cross-listing*)
Date: Tue, 23 Sep 2025 09:20:00 GMT   (6220kb)

Title: TimeMosaic: Temporal Heterogeneity Guided Time Series Forecasting via
  Adaptive Granularity Patch and Segment-wise Decoding
Authors: Kuiye Ding and Fanda Fan and Chunyi Hou and Zheya Wang and Lei Wang
  and Zhengxin Yang and Jianfeng Zhan
Categories: cs.LG cs.AI
\\
  Multivariate time series forecasting is essential in domains such as finance,
transportation, climate, and energy. However, existing patch-based methods
typically adopt fixed-length segmentation, overlooking the heterogeneity of
local temporal dynamics and the decoding heterogeneity of forecasting. Such
designs lose details in information-dense regions, introduce redundancy in
stable segments, and fail to capture the distinct complexities of short-term
and long-term horizons. We propose TimeMosaic, a forecasting framework that
aims to address temporal heterogeneity. TimeMosaic employs adaptive patch
embedding to dynamically adjust granularity according to local information
density, balancing motif reuse with structural clarity while preserving
temporal continuity. In addition, it introduces segment-wise decoding that
treats each prediction horizon as a related subtask and adapts to
horizon-specific difficulty and information requirements, rather than applying
a single uniform decoder. Extensive evaluations on benchmark datasets
demonstrate that TimeMosaic delivers consistent improvements over existing
methods, and our model trained on the large-scale corpus with 321 billion
observations achieves performance competitive with state-of-the-art TSFMs.
\\ ( https://arxiv.org/abs/2509.19406 ,  6220kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19412 (*cross-listing*)
Date: Tue, 23 Sep 2025 14:48:35 GMT   (812kb)

Title: EngravingGNN: A Hybrid Graph Neural Network for End-to-End Piano Score
  Engraving
Authors: Emmanouil Karystinaios, Francesco Foscarin, Gerhard Widmer
Categories: cs.GR cs.AI
Comments: Accepted at the International Conference on Technologies for Music
  Notation and Representation (TENOR) 2025
\\
  This paper focuses on automatic music engraving, i.e., the creation of a
humanly-readable musical score from musical content. This step is fundamental
for all applications that include a human player, but it remains a mostly
unexplored topic in symbolic music processing. In this work, we formalize the
problem as a collection of interdependent subtasks, and propose a unified graph
neural network (GNN) framework that targets the case of piano music and
quantized symbolic input. Our method employs a multi-task GNN to jointly
predict voice connections, staff assignments, pitch spelling, key signature,
stem direction, octave shifts, and clef signs. A dedicated postprocessing
pipeline generates print-ready MusicXML/MEI outputs. Comprehensive evaluation
on two diverse piano corpora (J-Pop and DCML Romantic) demonstrates that our
unified model achieves good accuracy across all subtasks, compared to existing
systems that only specialize in specific subtasks. These results indicate that
a shared GNN encoder with lightweight task-specific decoders in a multi-task
setting offers a scalable and effective solution for automatic music engraving.
\\ ( https://arxiv.org/abs/2509.19412 ,  812kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19419 (*cross-listing*)
Date: Tue, 23 Sep 2025 16:16:02 GMT   (1623kb)

Title: Probabilistic Runtime Verification, Evaluation and Risk Assessment of
  Visual Deep Learning Systems
Authors: Birk Torpmann-Hagen, P{\aa}l Halvorsen, Michael A. Riegler, Dag
  Johansen
Categories: cs.LG cs.AI
\\
  Despite achieving excellent performance on benchmarks, deep neural networks
often underperform in real-world deployment due to sensitivity to minor, often
imperceptible shifts in input data, known as distributional shifts. These
shifts are common in practical scenarios but are rarely accounted for during
evaluation, leading to inflated performance metrics. To address this gap, we
propose a novel methodology for the verification, evaluation, and risk
assessment of deep learning systems. Our approach explicitly models the
incidence of distributional shifts at runtime by estimating their probability
from outputs of out-of-distribution detectors. We combine these estimates with
conditional probabilities of network correctness, structuring them in a binary
tree. By traversing this tree, we can compute credible and precise estimates of
network accuracy. We assess our approach on five different datasets, with which
we simulate deployment conditions characterized by differing frequencies of
distributional shift. Our approach consistently outperforms conventional
evaluation, with accuracy estimation errors typically ranging between 0.01 and
0.1. We further showcase the potential of our approach on a medical
segmentation benchmark, wherein we apply our methods towards risk assessment by
associating costs with tree nodes, informing cost-benefit analyses and
value-judgments. Ultimately, our approach offers a robust framework for
improving the reliability and trustworthiness of deep learning systems,
particularly in safety-critical applications, by providing more accurate
performance estimates and actionable risk assessments.
\\ ( https://arxiv.org/abs/2509.19419 ,  1623kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19454 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:11:53 GMT   (9794kb)

Title: ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data
  Augmentation
Authors: Jason Chen, I-Chun Arthur Liu, Gaurav Sukhatme, Daniel Seita
Categories: cs.RO cs.AI cs.CV cs.LG
\\
  Training robust bimanual manipulation policies via imitation learning
requires demonstration data with broad coverage over robot poses, contacts, and
scene contexts. However, collecting diverse and precise real-world
demonstrations is costly and time-consuming, which hinders scalability. Prior
works have addressed this with data augmentation, typically for either
eye-in-hand (wrist camera) setups with RGB inputs or for generating novel
images without paired actions, leaving augmentation for eye-to-hand
(third-person) RGB-D training with new action labels less explored. In this
paper, we propose Synthetic Robot Pose Generation for RGB-D Bimanual Data
Augmentation (ROPA), an offline imitation learning data augmentation method
that fine-tunes Stable Diffusion to synthesize third-person RGB and RGB-D
observations of novel robot poses. Our approach simultaneously generates
corresponding joint-space action labels while employing constrained
optimization to enforce physical consistency through appropriate
gripper-to-object contact constraints in bimanual scenarios. We evaluate our
method on 5 simulated and 3 real-world tasks. Our results across 2625
simulation trials and 300 real-world trials demonstrate that ROPA outperforms
baselines and ablations, showing its potential for scalable RGB and RGB-D data
augmentation in eye-to-hand bimanual manipulation. Our project website is
available at: https://ropaaug.github.io/.
\\ ( https://arxiv.org/abs/2509.19454 ,  9794kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19460 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:15:32 GMT   (1963kb)

Title: Self-evolved Imitation Learning in Simulated World
Authors: Yifan Ye, Jun Cen, Jing Chen, Zhihe Lu
Categories: cs.RO cs.AI cs.LG
\\
  Imitation learning has been a trend recently, yet training a generalist agent
across multiple tasks still requires large-scale expert demonstrations, which
are costly and labor-intensive to collect. To address the challenge of limited
supervision, we propose Self-Evolved Imitation Learning (SEIL), a framework
that progressively improves a few-shot model through simulator interactions.
The model first attempts tasksin the simulator, from which successful
trajectories are collected as new demonstrations for iterative refinement. To
enhance the diversity of these demonstrations, SEIL employs dual-level
augmentation: (i) Model-level, using an Exponential Moving Average (EMA) model
to collaborate with the primary model, and (ii) Environment-level, introducing
slight variations in initial object positions. We further introduce a
lightweight selector that filters complementary and informative trajectories
from the generated pool to ensure demonstration quality. These curated samples
enable the model to achieve competitive performance with far fewer training
examples. Extensive experiments on the LIBERO benchmark show that SEIL achieves
a new state-of-the-art performance in few-shot imitation learning scenarios.
Code is available at https://github.com/Jasper-aaa/SEIL.git.
\\ ( https://arxiv.org/abs/2509.19460 ,  1963kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19465 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:19:50 GMT   (428kb)

Title: A Realistic Evaluation of Cross-Frequency Transfer Learning and
  Foundation Forecasting Models
Authors: Kin G. Olivares, Malcolm Wolff, Tatiana Konstantinova, Shankar
  Ramasubramanian, Andrew Gordon Wilson, Andres Potapczynski, Willa Potosnak,
  Mengfei Cao, Boris Oreshkin, Dmitry Efimov
Categories: cs.LG cs.AI stat.AP
Comments: Thirty-Ninth Annual Conference on Neural Information Processing
  Systems {NeurIPS 2025}. Recent Advances in Time Series Foundation Models Have
  We Reached the 'BERT Moment'?
\\
  Cross-frequency transfer learning (CFTL) has emerged as a popular framework
for curating large-scale time series datasets to pre-train foundation
forecasting models (FFMs). Although CFTL has shown promise, current
benchmarking practices fall short of accurately assessing its performance. This
shortcoming stems from many factors: an over-reliance on small-scale evaluation
datasets; inadequate treatment of sample size when computing summary
statistics; reporting of suboptimal statistical models; and failing to account
for non-negligible risks of overlap between pre-training and test datasets. To
address these limitations, we introduce a unified reimplementation of
widely-adopted neural forecasting networks, adapting them for the CFTL setup;
we pre-train only on proprietary and synthetic data, being careful to prevent
test leakage; and we evaluate on 15 large, diverse public forecast competition
datasets. Our empirical analysis reveals that statistical models' accuracy is
frequently underreported. Notably, we confirm that statistical models and their
ensembles consistently outperform existing FFMs by more than 8.2% in sCRPS, and
by more than 20% MASE, across datasets. However, we also find that synthetic
dataset pre-training does improve the accuracy of a FFM by 7% percent.
\\ ( https://arxiv.org/abs/2509.19465 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19485 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:47:59 GMT   (548kb)

Title: Identifying and Addressing User-level Security Concerns in Smart Homes
  Using "Smaller" LLMs
Authors: Hafijul Hoque Chowdhury, Riad Ahmed Anonto, Sourov Jajodia, Suryadipta
  Majumdar, Md. Shohrab Hossain
Categories: cs.CR cs.AI
Comments: 10 pages, accepted at PST 2025
\\
  With the rapid growth of smart home IoT devices, users are increasingly
exposed to various security risks, as evident from recent studies. While
seeking answers to know more on those security concerns, users are mostly left
with their own discretion while going through various sources, such as online
blogs and technical manuals, which may render higher complexity to regular
users trying to extract the necessary information. This requirement does not go
along with the common mindsets of smart home users and hence threatens the
security of smart homes furthermore. In this paper, we aim to identify and
address the major user-level security concerns in smart homes. Specifically, we
develop a novel dataset of Q&A from public forums, capturing practical security
challenges faced by smart home users. We extract major security concerns in
smart homes from our dataset by leveraging the Latent Dirichlet Allocation
(LDA). We fine-tune relatively "smaller" transformer models, such as T5 and
Flan-T5, on this dataset to build a QA system tailored for smart home security.
Unlike larger models like GPT and Gemini, which are powerful but often resource
hungry and require data sharing, smaller models are more feasible for
deployment in resource-constrained or privacy-sensitive environments like smart
homes. The dataset is manually curated and supplemented with synthetic data to
explore its potential impact on model performance. This approach significantly
improves the system's ability to deliver accurate and relevant answers, helping
users address common security concerns with smart home IoT devices. Our
experiments on real-world user concerns show that our work improves the
performance of the base models.
\\ ( https://arxiv.org/abs/2509.19485 ,  548kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19495 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:04:18 GMT   (1754kb)

Title: ArtiFree: Detecting and Reducing Generative Artifacts in Diffusion-based
  Speech Enhancement
Authors: Bhawana Chhaglani, Yang Gao, Julius Richter, Xilin Li, Syavosh
  Zadissa, Tarun Pruthi, Andrew Lovitt
Categories: cs.SD cs.AI
\\
  Diffusion-based speech enhancement (SE) achieves natural-sounding speech and
strong generalization, yet suffers from key limitations like generative
artifacts and high inference latency. In this work, we systematically study
artifact prediction and reduction in diffusion-based SE. We show that variance
in speech embeddings can be used to predict phonetic errors during inference.
Building on these findings, we propose an ensemble inference method guided by
semantic consistency across multiple diffusion runs. This technique reduces WER
by 15% in low-SNR conditions, effectively improving phonetic accuracy and
semantic plausibility. Finally, we analyze the effect of the number of
diffusion steps, showing that adaptive diffusion steps balance artifact
suppression and latency. Our findings highlight semantic priors as a powerful
tool to guide generative SE toward artifact-free outputs.
\\ ( https://arxiv.org/abs/2509.19495 ,  1754kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19497 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:09:31 GMT   (43kb)

Title: Generative AI as a catalyst for democratic Innovation: Enhancing citizen
  engagement in participatory budgeting
Authors: Italo Alberto do Nascimento Sousa, Jorge Machado, Jose Carlos Vaz
Categories: cs.CY cs.AI
Comments: 19 pages, VI International Meeting on Participation, Democracy and
  Public Policies
\\
  This research examines the role of Generative Artificial Intelligence (AI) in
enhancing citizen engagement in participatory budgeting. In response to
challenges like declining civic participation and increased societal
polarization, the study explores how online political participation can
strengthen democracy and promote social equity. By integrating Generative AI
into public consultation platforms, the research aims to improve citizen
proposal formulation and foster effective dialogue between citizens and
government. It assesses the capacities governments need to implement
AI-enhanced participatory tools, considering technological dependencies and
vulnerabilities. Analyzing technological structures, actors, interests, and
strategies, the study contributes to understanding how technological
advancements can reshape participatory institutions to better facilitate
citizen involvement. Ultimately, the research highlights how Generative AI can
transform participatory institutions, promoting inclusive, democratic
engagement and empowering citizens.
\\ ( https://arxiv.org/abs/2509.19497 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19509 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:26:31 GMT   (123kb)

Title: AIRwaves at CheckThat! 2025: Retrieving Scientific Sources for Implicit
  Claims on Social Media with Dual Encoders and Neural Re-Ranking
Authors: Cem Ashbaugh and Leon Baumg\"artner and Tim Gress and Nikita Sidorov
  and Daniel Werner
Categories: cs.IR cs.AI cs.LG
Comments: CLEF 2025 (Conference and Labs of the Evaluation Forum)
\\
  Linking implicit scientific claims made on social media to their original
publications is crucial for evidence-based fact-checking and scholarly
discourse, yet it is hindered by lexical sparsity, very short queries, and
domain-specific language. Team AIRwaves ranked second in Subtask 4b of the
CLEF-2025 CheckThat! Lab with an evidence-retrieval approach that markedly
outperforms the competition baseline. The optimized sparse-retrieval
baseline(BM25) achieves MRR@5 = 0.5025 on the gold label blind test set. To
surpass this baseline, a two-stage retrieval pipeline is introduced: (i) a
first stage that uses a dual encoder based on E5-large, fine-tuned using
in-batch and mined hard negatives and enhanced through chunked tokenization and
rich document metadata; and (ii) a neural re-ranking stage using a SciBERT
cross-encoder. Replacing purely lexical matching with neural representations
lifts performance to MRR@5 = 0.6174, and the complete pipeline further improves
to MRR@5 = 0.6828. The findings demonstrate that coupling dense retrieval with
neural re-rankers delivers a powerful and efficient solution for tweet-to-study
matching and provides a practical blueprint for future evidence-retrieval
pipelines.
\\ ( https://arxiv.org/abs/2509.19509 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19515 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:33:41 GMT   (396kb)

Title: A Longitudinal Randomized Control Study of Companion Chatbot Use:
  Anthropomorphism and Its Mediating Role on Social Impacts
Authors: Rose E. Guingrich, Michael S. A. Graziano
Categories: cs.HC cs.AI cs.CY
\\
  Relationships with social artificial intelligence (AI) agents are on the
rise. People report forming friendships, mentorships, and romantic partnerships
with chatbots such as Replika, a type of social AI agent that is designed
specifically for companionship. Concerns that companion chatbot relationships
may harm or replace human ones have been raised, but whether and how these
social consequences occur remains unclear. Prior research suggests that
people's states of social need and their anthropomorphism of the AI agent may
play a role in how human-AI interaction impacts human-human interaction. In
this longitudinal study (N = 183), participants were randomly assigned to
converse with a companion chatbot over text or to play text-based word games
for 10 minutes a day for 21 consecutive days. During these 21 days,
participants also completed four surveys and two audio-recorded interviews. We
found that people's social health and relationships were not significantly
impacted by interacting with a companion chatbot across 21 days compared to the
control group. However, people who had a higher desire to socially connect
anthropomorphized the chatbot more. Those who anthropomorphized the chatbot
more indicated that the human-chatbot interaction had greater impacts on their
social interactions and relationships with family and friends. A mediation
analysis suggested that the impact of human-AI interaction on human-human
social outcomes was mediated by the extent to which people anthropomorphized
the AI agent, which itself was related to the desire to socially connect.
\\ ( https://arxiv.org/abs/2509.19515 ,  396kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19533 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:57:29 GMT   (5005kb)

Title: Semantic-Aware Fuzzing: An Empirical Framework for LLM-Guided,
  Reasoning-Driven Input Mutation
Authors: Mengdi Lu, Steven Ding, Furkan Alaca, and Philippe Charland
Categories: cs.SE cs.AI cs.CR
\\
  Security vulnerabilities in Internet-of-Things devices, mobile platforms, and
autonomous systems remain critical. Traditional mutation-based fuzzers -- while
effectively explore code paths -- primarily perform byte- or bit-level edits
without semantic reasoning. Coverage-guided tools such as AFL++ use
dictionaries, grammars, and splicing heuristics to impose shallow structural
constraints, leaving deeper protocol logic, inter-field dependencies, and
domain-specific semantics unaddressed. Conversely, reasoning-capable large
language models (LLMs) can leverage pretraining knowledge to understand input
formats, respect complex constraints, and propose targeted mutations, much like
an experienced reverse engineer or testing expert. However, lacking ground
truth for "correct" mutation reasoning makes supervised fine-tuning
impractical, motivating explorations of off-the-shelf LLMs via prompt-based
few-shot learning. To bridge this gap, we present an open-source microservices
framework that integrates reasoning LLMs with AFL++ on Google's FuzzBench,
tackling asynchronous execution and divergent hardware demands (GPU- vs.
CPU-intensive) of LLMs and fuzzers. We evaluate four research questions: (R1)
How can reasoning LLMs be integrated into the fuzzing mutation loop? (R2) Do
few-shot prompts yield higher-quality mutations than zero-shot? (R3) Can prompt
engineering with off-the-shelf models improve fuzzing directly? and (R4) Which
open-source reasoning LLMs perform best under prompt-only conditions?
Experiments with Llama3.3, Deepseek-r1-Distill-Llama-70B, QwQ-32B, and Gemma3
highlight Deepseek as the most promising. Mutation effectiveness depends more
on prompt complexity and model choice than shot count. Response latency and
throughput bottlenecks remain key obstacles, offering directions for future
work.
\\ ( https://arxiv.org/abs/2509.19533 ,  5005kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19538 (*cross-listing*)
Date: Tue, 23 Sep 2025 20:06:26 GMT   (56kb)

Title: DAWM: Diffusion Action World Models for Offline Reinforcement Learning
  via Action-Inferred Transitions
Authors: Zongyue Li, Xiao Han, Yusong Li, Niklas Strauss, Matthias Schubert
Categories: cs.LG cs.AI
Comments: ICML2025 workshop Building Physically Plausible World Models
\\
  Diffusion-based world models have demonstrated strong capabilities in
synthesizing realistic long-horizon trajectories for offline reinforcement
learning (RL). However, many existing methods do not directly generate actions
alongside states and rewards, limiting their compatibility with standard
value-based offline RL algorithms that rely on one-step temporal difference
(TD) learning. While prior work has explored joint modeling of states, rewards,
and actions to address this issue, such formulations often lead to increased
training complexity and reduced performance in practice. We propose
\textbf{DAWM}, a diffusion-based world model that generates future state-reward
trajectories conditioned on the current state, action, and return-to-go, paired
with an inverse dynamics model (IDM) for efficient action inference. This
modular design produces complete synthetic transitions suitable for one-step
TD-based offline RL, enabling effective and computationally efficient training.
Empirically, we show that conservative offline RL algorithms such as TD3BC and
IQL benefit significantly from training on these augmented trajectories,
consistently outperforming prior diffusion-based baselines across multiple
tasks in the D4RL benchmark.
\\ ( https://arxiv.org/abs/2509.19538 ,  56kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19554 (*cross-listing*)
Date: Tue, 23 Sep 2025 20:27:19 GMT   (21420kb)

Title: Learning Dynamics of Deep Learning -- Force Analysis of Deep Neural
  Networks
Authors: Yi Ren
Categories: cs.LG cs.AI
Comments: 175 pages
\\
  This thesis explores how deep learning models learn over time, using ideas
inspired by force analysis. Specifically, we zoom in on the model's training
procedure to see how one training example affects another during learning, like
analyzing how forces move objects. We break this influence into two parts: how
similar the two examples are, and how strong the updating force is. This
framework helps us understand a wide range of the model's behaviors in
different real systems. For example, it explains why certain examples have
non-trivial learning paths, why (and why not) some LLM finetuning methods work,
and why simpler, more structured patterns tend to be learned more easily. We
apply this approach to various learning tasks and uncover new strategies for
improving model training. While the method is still developing, it offers a new
way to interpret models' behaviors systematically.
\\ ( https://arxiv.org/abs/2509.19554 ,  21420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19586 (*cross-listing*)
Date: Tue, 23 Sep 2025 21:23:36 GMT   (17864kb)

Title: A Foundation Chemical Language Model for Comprehensive Fragment-Based
  Drug Discovery
Authors: Alexander Ho, Sukyeong Lee, Francis T.F. Tsai
Categories: cs.LG cs.AI q-bio.BM
\\
  We introduce FragAtlas-62M, a specialized foundation model trained on the
largest fragment dataset to date. Built on the complete ZINC-22 fragment subset
comprising over 62 million molecules, it achieves unprecedented coverage of
fragment chemical space. Our GPT-2 based model (42.7M parameters) generates
99.90% chemically valid fragments. Validation across 12 descriptors and three
fingerprint methods shows generated fragments closely match the training
distribution (all effect sizes < 0.4). The model retains 53.6% of known ZINC
fragments while producing 22% novel structures with practical relevance. We
release FragAtlas-62M with training code, preprocessed data, documentation, and
model weights to accelerate adoption.
\\ ( https://arxiv.org/abs/2509.19586 ,  17864kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19587 (*cross-listing*)
Date: Tue, 23 Sep 2025 21:23:37 GMT   (725kb)

Title: Reverse Engineering User Stories from Code using Large Language Models
Authors: Mohamed Ouf and Haoyu Li and Michael Zhang and Mariam Guizani
Categories: cs.SE cs.AI
\\
  User stories are essential in agile development, yet often missing or
outdated in legacy and poorly documented systems. We investigate whether large
language models (LLMs) can automatically recover user stories directly from
source code and how prompt design impacts output quality. Using 1,750 annotated
C++ snippets of varying complexity, we evaluate five state-of-the-art LLMs
across six prompting strategies. Results show that all models achieve, on
average, an F1 score of 0.8 for code up to 200 NLOC. Our findings show that a
single illustrative example enables the smallest model (8B) to match the
performance of a much larger 70B model. In contrast, structured reasoning via
Chain-of-Thought offers only marginal gains, primarily for larger models.
\\ ( https://arxiv.org/abs/2509.19587 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19592 (*cross-listing*)
Date: Tue, 23 Sep 2025 21:31:00 GMT   (188kb)

Title: Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech
  Generation
Authors: Roy Fejgin, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Ryan
  Langman Jaehyeon Kim, Subhankar Ghosh, Shehzeen Hussain, Jason Li
Categories: eess.AS cs.AI cs.CL cs.SD
Comments: This work has been submitted to the IEEE for possible publication
\\
  Speech generation models based on large language models (LLMs) typically
operate on discrete acoustic codes, which differ fundamentally from text tokens
due to their multicodebook structure. At each timestep, models must predict N
codebook entries jointly, introducing dependencies that challenge simple
parallel prediction approaches. Parallel prediction assumes independence among
codebooks, yielding efficient decoding but often at the cost of reduced
fidelity. To address this, hierarchical strategies employ a local transformer
(LT) to refine predictions and capture intra-timestep dependencies. In this
work, we systematically investigate two LT architectures: an autoregressive
transformer that generates codebooks sequentially, and a MaskGIT-based
transformer that performs iterative masked prediction. Both designs further
enable frame stacking, where the primary transformer predicts multiple frames
jointly, and the LT decodes their codebooks, offering improvements in speed
without compromising perceptual quality. Through extensive analysis, we
characterize the tradeoffs between parallel and iterative sampling strategies
across different throughput and quality regimes. Finally, we propose practical
guidelines for selecting decoding strategies based on deployment priorities
such as computational efficiency and synthesis fidelity.
\\ ( https://arxiv.org/abs/2509.19592 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19631 (*cross-listing*)
Date: Tue, 23 Sep 2025 22:45:13 GMT   (45kb)

Title: Advancing Speech Summarization in Multi-modal LLMs with Reinforcement
  Learning
Authors: Shaoshi Ling, Gang Liu, Guoli Ye, Jinyu Li
Categories: eess.AS cs.AI cs.CL
\\
  Speech summarization is a critical component of spoken content understanding,
particularly in the era of rapidly growing spoken and audiovisual data. Recent
advances in multi-modal large language models (MLLMs), leveraging the power of
LLMs, enable generating textual summaries directly from speech without
intermediate transcriptions, while supporting controllable styles and zero-shot
generalization. However, open-source MLLMs continue to lag behind the
state-of-the-art text-based LLMs, limiting their practical deployment for
speech summarization. In this work, we present a novel multi-stage
reinforcement learning training framework to enhance the speech summarization
capabilities in MLLMs. Our model delivers substantial improvements over strong
baselines, outperforms much larger MLLMs, and significantly narrows the gap
with state-of-the-art text-based LLMs.
\\ ( https://arxiv.org/abs/2509.19631 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19633 (*cross-listing*)
Date: Tue, 23 Sep 2025 22:46:19 GMT   (471kb)

Title: Mamba Modulation: On the Length Generalization of Mamba
Authors: Peng Lu, Jerry Huang, Qiuhao Zeng, Xinyu Wang, Boxing Wang, Philippe
  Langlais, Yufei Cui
Categories: cs.LG cs.AI stat.ML
Comments: Accepted to The Thirty-Ninth Annual Conference on Neural Information
  Processing Systems (NeurIPS) 2025. First two authors contributed equally
\\
  The quadratic complexity of the attention mechanism in Transformer models has
motivated the development of alternative architectures with sub-quadratic
scaling, such as state-space models. Among these, Mamba has emerged as a
leading architecture, achieving state-of-the-art results across a range of
language modeling tasks. However, Mamba's performance significantly
deteriorates when applied to contexts longer than those seen during
pre-training, revealing a sharp sensitivity to context length extension.
Through detailed analysis, we attribute this limitation to the
out-of-distribution behaviour of its state-space dynamics, particularly within
the parameterization of the state transition matrix $\mathbf{A}$. Unlike recent
works which attribute this sensitivity to the vanished accumulation of
discretization time steps, $\exp(-\sum_{t=1}^N\Delta_t)$, we establish a
connection between state convergence behavior as the input length approaches
infinity and the spectrum of the transition matrix $\mathbf{A}$, offering a
well-founded explanation of its role in length extension. Next, to overcome
this challenge, we propose an approach that applies spectrum scaling to
pre-trained Mamba models to enable robust long-context generalization by
selectively modulating the spectrum of $\mathbf{A}$ matrices in each layer. We
show that this can significantly improve performance in settings where simply
modulating $\Delta_t$ fails, validating our insights and providing avenues for
better length generalization of state-space models with structured transition
matrices.
\\ ( https://arxiv.org/abs/2509.19633 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19645 (*cross-listing*)
Date: Tue, 23 Sep 2025 23:52:07 GMT   (1090kb)

Title: Are We Scaling the Right Thing? A System Perspective on Test-Time
  Scaling
Authors: Youpeng Zhao, Jinpeng LV, Di Wu, Jun Wang, Christopher Gooley
Categories: cs.PF cs.AI
\\
  Test-time scaling (TTS) has recently emerged as a promising direction to
exploit the hidden reasoning capabilities of pre-trained large language models
(LLMs). However, existing scaling methods narrowly focus on the compute-optimal
Pareto-frontier, ignoring the simple fact that compute-optimal is not always
system-optimal. In this work, we propose a system-driven perspective on TTS,
analyzing how reasoning models scale against practical metrics, such as latency
and cost-per-token. By evaluating the impact of popular optimizations such as
tensor parallelism and speculative decoding, our preliminary analysis reveals
the limitations of current methods and calls for a paradigm shift toward
holistic, system-aware evaluations that capture the true essence of scaling
laws at inference time.
\\ ( https://arxiv.org/abs/2509.19645 ,  1090kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19646 (*cross-listing*)
Date: Tue, 23 Sep 2025 23:52:47 GMT   (317kb)

Title: Where 6G Stands Today: Evolution, Enablers, and Research Gaps
Authors: Salma Tika, Abdelkrim Haqiq, Essaid Sabir, Elmahdi Driouch
Categories: cs.NI cs.AI
Comments: 8 pages, 2 figures, conference, 2 tables
\\
  As the fifth-generation (5G) mobile communication system continues its global
deployment, both industry and academia have started conceptualizing the 6th
generation (6G) to address the growing need for a progressively advanced and
digital society. Even while 5G offers considerable advancements over LTE, it
could struggle to be sufficient to meet all of the requirements, including
ultra-high reliability, seamless automation, and ubiquitous coverage. In
response, 6G is supposed to bring out a highly intelligent, automated, and
ultra-reliable communication system that can handle a vast number of connected
devices. This paper offers a comprehensive overview of 6G, beginning with its
main stringent requirements while focusing on key enabling technologies such as
terahertz (THz) communications, intelligent reflecting surfaces, massive MIMO
and AI-driven networking that will shape the 6G networks. Furthermore, the
paper lists various 6G applications and usage scenarios that will benefit from
these advancements. At the end, we outline the potential challenges that must
be addressed to achieve the 6G promises.
\\ ( https://arxiv.org/abs/2509.19646 ,  317kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19658 (*cross-listing*)
Date: Wed, 24 Sep 2025 00:26:15 GMT   (2963kb)

Title: RoboSSM: Scalable In-context Imitation Learning via State-Space Models
Authors: Youngju Yoo, Jiaheng Hu, Yifeng Zhu, Bo Liu, Qiang Liu, Roberto
  Mart\'in-Mart\'in, Peter Stone
Categories: cs.RO cs.AI
Comments: 8 pages, 11 figures
\\
  In-context imitation learning (ICIL) enables robots to learn tasks from
prompts consisting of just a handful of demonstrations. By eliminating the need
for parameter updates at deployment time, this paradigm supports few-shot
adaptation to novel tasks. However, recent ICIL methods rely on Transformers,
which have computational limitations and tend to underperform when handling
longer prompts than those seen during training. In this work, we introduce
RoboSSM, a scalable recipe for in-context imitation learning based on
state-space models (SSM). Specifically, RoboSSM replaces Transformers with
Longhorn -- a state-of-the-art SSM that provides linear-time inference and
strong extrapolation capabilities, making it well-suited for long-context
prompts. We evaluate our approach on the LIBERO benchmark and compare it
against strong Transformer-based ICIL baselines. Experiments show that RoboSSM
extrapolates effectively to varying numbers of in-context demonstrations,
yields high performance on unseen tasks, and remains robust in long-horizon
scenarios. These results highlight the potential of SSMs as an efficient and
scalable backbone for ICIL. Our code is available at
https://github.com/youngjuY/RoboSSM.
\\ ( https://arxiv.org/abs/2509.19658 ,  2963kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19668 (*cross-listing*)
Date: Wed, 24 Sep 2025 01:00:27 GMT   (156kb)

Title: Selective Classifier-free Guidance for Zero-shot Text-to-speech
Authors: John Zheng, Farhad Maleki
Categories: eess.AS cs.AI cs.SD
Comments: 5 pages, 7 figures, 1 table. Submitted to ICASSP 2026
\\
  In zero-shot text-to-speech, achieving a balance between fidelity to the
target speaker and adherence to text content remains a challenge. While
classifier-free guidance (CFG) strategies have shown promising results in image
generation, their application to speech synthesis are underexplored. Separating
the conditions used for CFG enables trade-offs between different desired
characteristics in speech synthesis. In this paper, we evaluate the
adaptability of CFG strategies originally developed for image generation to
speech synthesis and extend separated-condition CFG approaches for this domain.
Our results show that CFG strategies effective in image generation generally
fail to improve speech synthesis. We also find that we can improve speaker
similarity while limiting degradation of text adherence by applying standard
CFG during early timesteps and switching to selective CFG only in later
timesteps. Surprisingly, we observe that the effectiveness of a selective CFG
strategy is highly text-representation dependent, as differences between the
two languages of English and Mandarin can lead to different results even with
the same model.
\\ ( https://arxiv.org/abs/2509.19668 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19669 (*cross-listing*)
Date: Wed, 24 Sep 2025 01:02:24 GMT   (5106kb)

Title: Games Are Not Equal: Classifying Cloud Gaming Contexts for Effective
  User Experience Measurement
Authors: Yifan Wang and Minzhao Lyu and Vijay Sivaraman
Categories: cs.NI cs.AI
Comments: This paper is accepted at ACM Internet Measurement Conference (IMC)
  2025. In Proc. ACM IMC, Oct, 2025, Madison, WI, USA
DOI: 10.1145/3730567.3764455
\\
  To tap into the growing market of cloud gaming, whereby game graphics is
rendered in the cloud and streamed back to the user as a video feed, network
operators are creating monetizable assurance services that dynamically
provision network resources. However, without accurately measuring cloud gaming
user experience, they cannot assess the effectiveness of their provisioning
methods. Basic measures such as bandwidth and frame rate by themselves do not
suffice, and can only be interpreted in the context of the game played and the
player activity within the game. This paper equips the network operator with a
method to obtain a real-time measure of cloud gaming experience by analyzing
network traffic, including contextual factors such as the game title and player
activity stage. Our method is able to classify the game title within the first
five seconds of game launch, and continuously assess the player activity stage
as being active, passive, or idle. We deploy it in an ISP hosting NVIDIA cloud
gaming servers for the region. We provide insights from hundreds of thousands
of cloud game streaming sessions over a three-month period into the dependence
of bandwidth consumption and experience level on the gameplay contexts.
\\ ( https://arxiv.org/abs/2509.19669 ,  5106kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19676 (*cross-listing*)
Date: Wed, 24 Sep 2025 01:17:24 GMT   (1509kb)

Title: Thinking While Listening: Simple Test Time Scaling For Audio
  Classification
Authors: Prateek Verma, Mert Pilanci
Categories: cs.SD cs.AI cs.LG eess.AS
Comments: 6 pages, 3 figures, 2 Tables, ICASSP 2026
\\
  We propose a framework that enables neural models to "think while listening"
to everyday sounds, thereby enhancing audio classification performance.
Motivated by recent advances in the reasoning capabilities of large language
models, we address two central questions: (i) how can thinking be incorporated
into existing audio classification pipelines to enable reasoning in the
category space and improve performance, and (ii) can a new architecture be
designed from the ground up to support both thinking and test-time scaling? We
demonstrate that in both settings, our models exhibit improved classification
accuracy. Leveraging test-time scaling, we observe consistent gains as the
number of sampled traces increases. Furthermore, we evaluate two open-source
reasoning models, GPT-OSS-20B and Qwen3-14B, showing that while such models are
capable of zero-shot reasoning, a lightweight approach--retraining only the
embedding matrix of a frozen, smaller model like GPT-2--can surpass the
performance of billion-parameter text-based reasoning models.
\\ ( https://arxiv.org/abs/2509.19676 ,  1509kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19680 (*cross-listing*)
Date: Wed, 24 Sep 2025 01:33:05 GMT   (8325kb)

Title: PolicyPad: Collaborative Prototyping of LLM Policies
Authors: K. J. Kevin Feng, Tzu-Sheng Kuo, Quan Ze (Jim) Chen, Inyoung Cheong,
  Kenneth Holstein, Amy X. Zhang
Categories: cs.HC cs.AI
\\
  As LLMs gain adoption in high-stakes domains like mental health, domain
experts are increasingly consulted to provide input into policies governing
their behavior. From an observation of 19 policymaking workshops with 9 experts
over 15 weeks, we identified opportunities to better support rapid
experimentation, feedback, and iteration for collaborative policy design
processes. We present PolicyPad, an interactive system that facilitates the
emerging practice of LLM policy prototyping by drawing from established UX
prototyping practices, including heuristic evaluation and storyboarding. Using
PolicyPad, policy designers can collaborate on drafting a policy in real time
while independently testing policy-informed model behavior with usage
scenarios. We evaluate PolicyPad through workshops with 8 groups of 22 domain
experts in mental health and law, finding that PolicyPad enhanced collaborative
dynamics during policy design, enabled tight feedback loops, and led to novel
policy contributions. Overall, our work paves participatory paths for advancing
AI alignment and safety.
\\ ( https://arxiv.org/abs/2509.19680 ,  8325kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19696 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:07:17 GMT   (5312kb)

Title: Diffusion-Based Impedance Learning for Contact-Rich Manipulation Tasks
Authors: Noah Geiger, Tamim Asfour, Neville Hogan and Johannes Lachner
Categories: cs.RO cs.AI cs.LG
Comments: 15 pages, 12 figures
\\
  Learning methods excel at motion generation in the information domain but are
not primarily designed for physical interaction in the energy domain. Impedance
Control shapes physical interaction but requires task-aware tuning by selecting
feasible impedance parameters. We present Diffusion-Based Impedance Learning, a
framework that combines both domains. A Transformer-based Diffusion Model with
cross-attention to external wrenches reconstructs a simulated Zero-Force
Trajectory (sZFT). This captures both translational and rotational task-space
behavior. For rotations, we introduce a novel SLERP-based quaternion noise
scheduler that ensures geometric consistency. The reconstructed sZFT is then
passed to an energy-based estimator that updates stiffness and damping
parameters. A directional rule is applied that reduces impedance along non task
axes while preserving rigidity along task directions. Training data were
collected for a parkour scenario and robotic-assisted therapy tasks using
teleoperation with Apple Vision Pro. With only tens of thousands of samples,
the model achieved sub-millimeter positional accuracy and sub-degree rotational
accuracy. Its compact model size enabled real-time torque control and
autonomous stiffness adaptation on a KUKA LBR iiwa robot. The controller
achieved smooth parkour traversal within force and velocity limits and 30/30
success rates for cylindrical, square, and star peg insertions without any
peg-specific demonstrations in the training data set. All code for the
Transformer-based Diffusion Model, the robot controller, and the Apple Vision
Pro telemanipulation framework is publicly available. These results mark an
important step towards Physical AI, fusing model-based control for physical
interaction with learning-based methods for trajectory generation.
\\ ( https://arxiv.org/abs/2509.19696 ,  5312kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19698 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:11:13 GMT   (1840kb)

Title: A Unified Noise-Curvature View of Loss of Trainability
Authors: Gunbir Singh Baveja and Mark Schmidt
Categories: cs.LG cs.AI
\\
  Loss of trainability (LoT) in continual learning occurs when gradient steps
no longer yield improvement as tasks evolve, so accuracy stalls or degrades
despite adequate capacity and supervision. We analyze LoT incurred with Adam
through an optimization lens and find that single indicators such as Hessian
rank, sharpness level, weight or gradient norms, gradient-to-parameter ratios,
and unit-sign entropy are not reliable predictors. Instead we introduce two
complementary criteria: a batch-size-aware gradient-noise bound and a curvature
volatility-controlled bound that combine into a per-layer predictive threshold
that anticipates trainability behavior. Using this threshold, we build a simple
per-layer scheduler that keeps each layers effective step below a safe limit,
stabilizing training and improving accuracy across concatenated ReLU (CReLU),
Wasserstein regularization, and L2 weight decay, with learned learning-rate
trajectories that mirror canonical decay.
\\ ( https://arxiv.org/abs/2509.19698 ,  1840kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19702 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:19:04 GMT   (1252kb)

Title: Linear Transformers Implicitly Discover Unified Numerical Algorithms
Authors: Patrick Lutz, Aditya Gangrade, Hadi Daneshmand, Venkatesh Saligrama
Categories: cs.LG cs.AI
Comments: To appear at NeurIPS 2025
\\
  We train a linear attention transformer on millions of masked-block matrix
completion tasks: each prompt is masked low-rank matrix whose missing block may
be (i) a scalar prediction target or (ii) an unseen kernel slice of Nystr\"om
extrapolation. The model sees only input-output pairs and a mean-squared loss;
it is given no normal equations, no handcrafted iterations, and no hint that
the tasks are related. Surprisingly, after training, algebraic unrolling
reveals the same parameter-free update rule across three distinct computational
regimes (full visibility, rank-limited updates, and distributed computation).
We prove that this rule achieves second-order convergence on full-batch
problems, cuts distributed iteration complexity, and remains accurate with
rank-limited attention. Thus, a transformer trained solely to patch missing
blocks implicitly discovers a unified, resource-adaptive iterative solver
spanning prediction, estimation, and Nystr\"om extrapolation, highlighting a
powerful capability of in-context learning.
\\ ( https://arxiv.org/abs/2509.19702 ,  1252kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19705 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:31:43 GMT   (267kb)

Title: Causal Machine Learning for Surgical Interventions
Authors: J. Ben Tamo, Nishant S. Chouhan, Micky C. Nnamdi, Yining Yuan, Shreya
  S. Chivilkar, Wenqi Shi, Steven W. Hwang, B. Randall Brenn, and May D. Wang
Categories: cs.LG cs.AI stat.AP stat.ME
DOI: 10.26599/BDMA.2025.9020093
\\
  Surgical decision-making is complex and requires understanding causal
relationships between patient characteristics, interventions, and outcomes. In
high-stakes settings like spinal fusion or scoliosis correction, accurate
estimation of individualized treatment effects (ITEs) remains limited due to
the reliance on traditional statistical methods that struggle with complex,
heterogeneous data. In this study, we develop a multi-task meta-learning
framework, X-MultiTask, for ITE estimation that models each surgical decision
(e.g., anterior vs. posterior approach, surgery vs. no surgery) as a distinct
task while learning shared representations across tasks. To strengthen causal
validity, we incorporate the inverse probability weighting (IPW) into the
training objective. We evaluate our approach on two datasets: (1) a public
spinal fusion dataset (1,017 patients) to assess the effect of anterior vs.
posterior approaches on complication severity; and (2) a private AIS dataset
(368 patients) to analyze the impact of posterior spinal fusion (PSF) vs.
non-surgical management on patient-reported outcomes (PROs). Our model achieves
the highest average AUC (0.84) in the anterior group and maintains competitive
performance in the posterior group (0.77). It outperforms baselines in
treatment effect estimation with the lowest overall $\epsilon_{\text{NN-PEHE}}$
(0.2778) and $\epsilon_{\text{ATE}}$ (0.0763). Similarly, when predicting PROs
in AIS, X-MultiTask consistently shows superior performance across all domains,
with $\epsilon_{\text{NN-PEHE}}$ = 0.2551 and $\epsilon_{\text{ATE}}$ = 0.0902.
By providing robust, patient-specific causal estimates, X-MultiTask offers a
powerful tool to advance personalized surgical care and improve patient
outcomes. The code is available at https://github.com/Wizaaard/X-MultiTask.
\\ ( https://arxiv.org/abs/2509.19705 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19708 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:34:11 GMT   (5477kb)

Title: Intuition to Evidence: Measuring AI's True Impact on Developer
  Productivity
Authors: Anand Kumar, Vishal Khare, Deepak Sharma, Satyam Kumar, Vijay Saini,
  Anshul Yadav, Sachendra Jain, Ankit Rana, Pratham Verma, Vaibhav Meena,
  Avinash Edubilli
Categories: cs.SE cs.AI cs.LG
Comments: 16 pages, 10 figures, 5 tables
\\
  We present a comprehensive real-world evaluation of AI-assisted software
development tools deployed at enterprise scale. Over one year, 300 engineers
across multiple teams integrated an in-house AI platform (DeputyDev) that
combines code generation and automated review capabilities into their daily
workflows. Through rigorous cohort analysis, our study demonstrates
statistically significant productivity improvements, including an overall 31.8%
reduction in PR review cycle time.
  Developer adoption was strong, with 85% satisfaction for code review features
and 93% expressing a desire to continue using the platform. Adoption patterns
showed systematic scaling from 4% engagement in month 1 to 83% peak usage by
month 6, stabilizing at 60% active engagement. Top adopters achieved a 61%
increase in code volume pushed to production, contributing to approximately 30
to 40% of code shipped to production through this tool, accounting for an
overall 28% increase in code shipment volume.
  Unlike controlled benchmark evaluations, our longitudinal analysis provides
empirical evidence from production environments, revealing both the
transformative potential and practical deployment challenges of integrating AI
into enterprise software development workflows.
\\ ( https://arxiv.org/abs/2509.19708 ,  5477kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19715 (*cross-listing*)
Date: Wed, 24 Sep 2025 02:54:09 GMT   (1490kb)

Title: SMILES-Inspired Transfer Learning for Quantum Operators in Generative
  Quantum Eigensolver
Authors: Zhi Yin, Xiaoran Li, Shengyu Zhang, Xin Li, Xiaojin Zhang
Categories: physics.chem-ph cs.AI
Comments: 7 pages, 5 figures
\\
  Given the inherent limitations of traditional Variational Quantum
Eigensolver(VQE) algorithms, the integration of deep generative models into
hybrid quantum-classical frameworks, specifically the Generative Quantum
Eigensolver(GQE), represents a promising innovative approach. However, taking
the Unitary Coupled Cluster with Singles and Doubles(UCCSD) ansatz which is
widely used in quantum chemistry as an example, different molecular systems
require constructions of distinct quantum operators. Considering the similarity
of different molecules, the construction of quantum operators utilizing the
similarity can reduce the computational cost significantly. Inspired by the
SMILES representation method in computational chemistry, we developed a
text-based representation approach for UCCSD quantum operators by leveraging
the inherent representational similarities between different molecular systems.
This framework explores text pattern similarities in quantum operators and
employs text similarity metrics to establish a transfer learning framework. Our
approach with a naive baseline setting demonstrates knowledge transfer between
different molecular systems for ground-state energy calculations within the GQE
paradigm. This discovery offers significant benefits for hybrid
quantum-classical computation of molecular ground-state energies, substantially
reducing computational resource requirements.
\\ ( https://arxiv.org/abs/2509.19715 ,  1490kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19750 (*cross-listing*)
Date: Wed, 24 Sep 2025 04:05:22 GMT   (2489kb)

Title: Cuffless Blood Pressure Prediction from Speech Sentences using Deep
  Learning Methods
Authors: Kainat
Categories: cs.LG cs.AI
Comments: MS Thesis
\\
  This research presents a novel method for noninvasive arterial blood pressure
ABP prediction using speech signals employing a BERT based regression model
Arterial blood pressure is a vital indicator of cardiovascular health and
accurate monitoring is essential in preventing hypertension related
complications Traditional cuff based methods often yield inconsistent results
due to factors like whitecoat and masked hypertension Our approach leverages
the acoustic characteristics of speech capturing voice features to establish
correlations with blood pressure levels Utilizing advanced deep learning
techniques we analyze speech signals to extract relevant patterns enabling real
time monitoring without the discomfort of conventional methods In our study we
employed a dataset comprising recordings from 95 participants ensuring diverse
representation The BERT model was fine tuned on extracted features from speech
leading to impressive performance metrics achieving a mean absolute error MAE
of 136 mmHg for systolic blood pressure SBP and 124 mmHg for diastolic blood
pressure DBP with R scores of 099 and 094 respectively These results indicate
the models robustness in accurately predicting blood pressure levels
Furthermore the training and validation loss analysis demonstrates effective
learning and minimal overfitting Our findings suggest that integrating deep
learning with speech analysis presents a viable alternative for blood pressure
monitoring paving the way for improved applications in telemedicine and remote
health monitoring By providing a user friendly and accurate method for blood
pressure assessment this research has significant implications for enhancing
patient care and proactive management of cardiovascular health
\\ ( https://arxiv.org/abs/2509.19750 ,  2489kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19757 (*cross-listing*)
Date: Wed, 24 Sep 2025 04:26:25 GMT   (250kb)

Title: ARCADE: A Real-Time Data System for Hybrid and Continuous Query
  Processing across Diverse Data Modalities
Authors: Jingyi Yang, Songsong Mo, Jiachen Shi, Zihao Yu, Kunhao Shi, Xuchen
  Ding, Gao Cong
Categories: cs.DB cs.AI
\\
  The explosive growth of multimodal data - spanning text, image, video,
spatial, and relational modalities, coupled with the need for real-time
semantic search and retrieval over these data - has outpaced the capabilities
of existing multimodal and real-time database systems, which either lack
efficient ingestion and continuous query capability, or fall short in
supporting expressive hybrid analytics. We introduce ARCADE, a real-time data
system that efficiently supports high-throughput ingestion and expressive
hybrid and continuous query processing across diverse data types. ARCADE
introduces unified disk-based secondary index on LSM-based storage for vector,
spatial, and text data modalities, a comprehensive cost-based query optimizer
for hybrid queries, and an incremental materialized view framework for
efficient continuous queries. Built on open-source RocksDB storage and MySQL
query engine, ARCADE outperforms leading multimodal data systems by up to 7.4x
on read-heavy and 1.4x on write-heavy workloads.
\\ ( https://arxiv.org/abs/2509.19757 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19766 (*cross-listing*)
Date: Tue, 23 Sep 2025 17:33:05 GMT   (2167kb)

Title: Dynamicasome: a molecular dynamics-guided and AI-driven pathogenicity
  prediction catalogue for all genetic mutations
Authors: Naeyma N Islam, Mathew A Coban, Jessica M Fuller, Caleb Weber, Rohit
  Chitale, Benjamin Jussila, Trisha J. Brock, Cui Tao, Thomas R Caulfield
Categories: q-bio.QM cs.AI physics.bio-ph q-bio.MN
Comments: 14 pages , 6 Figures, 2 Tables
Journal-ref: Communications Biology (Nature) (2025) 8:958
DOI: 10.1038/s42003-025-08334-y
\\
  Advances in genomic medicine accelerate the identi cation of mutations in
disease-associated genes, but the pathogenicity of many mutations remains
unknown, hindering their use in diagnostics and clinical decision-making.
Predictive AI models are generated to combat this issue, but current tools
display low accuracy when tested against functionally validated datasets. We
show that integrating detailed conformational data extracted from molecular
dynamics simulations (MDS) into advanced AI-based models increases their
predictive power. We carry out an exhaustive mutational analysis of the disease
gene PMM2 and subject structural models of each variant to MDS. AI models
trained on this dataset outperform existing tools when predicting the known
pathogenicity of mutations. Our best performing model, a neuronal networks
model, also predicts the pathogenicity of several PMM2 mutations currently
considered of unknown signi cance. We believe this model helps alleviate the
burden of unknown variants in genomic medicine.
\\ ( https://arxiv.org/abs/2509.19766 ,  2167kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19767 (*cross-listing*)
Date: Wed, 24 Sep 2025 05:33:53 GMT   (3508kb)

Title: FusedANN: Convexified Hybrid ANN via Attribute-Vector Fusion
Authors: Alireza Heidari, Wei Zhang, Ying Xiong
Categories: cs.IR cs.AI cs.DB math.OC
Comments: 62 pages,12 figures
\\
  Vector search powers transformers technology, but real-world use demands
hybrid queries that combine vector similarity with attribute filters (e.g.,
"top document in category X, from 2023"). Current solutions trade off recall,
speed, and flexibility, relying on fragile index hacks that don't scale. We
introduce FusedANN (Fused Attribute-Vector Nearest Neighbor), a geometric
framework that elevates filtering to ANN optimization constraints and
introduces a convex fused space via a Lagrangian-like relaxation. Our method
jointly embeds attributes and vectors through transformer-based
convexification, turning hard filters into continuous, weighted penalties that
preserve top-k semantics while enabling efficient approximate search. We prove
that FusedANN reduces to exact filtering under high selectivity, gracefully
relaxes to semantically nearest attributes when exact matches are insufficient,
and preserves downstream ANN alpha-approximation guarantees. Empirically,
FusedANN improves query throughput by eliminating brittle filtering stages,
achieving superior recall-latency tradeoffs on standard hybrid benchmarks
without specialized index hacks, delivering up to 3 times higher throughput and
better recall than state-of-the-art hybrid and graph-based systems.
Theoretically, we provide explicit error bounds and parameter selection rules
that make FusedANN practical for production. This establishes a principled,
scalable, and verifiable bridge between symbolic constraints and vector
similarity, unlocking a new generation of filtered retrieval systems for large,
hybrid, and dynamic NLP/ML workloads.
\\ ( https://arxiv.org/abs/2509.19767 ,  3508kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19771 (*cross-listing*)
Date: Wed, 24 Sep 2025 05:42:38 GMT   (929kb)

Title: Frictional Q-Learning
Authors: Hyunwoo Kim and Hyo Kyung Lee
Categories: cs.LG cs.AI
\\
  We draw an analogy between static friction in classical mechanics and
extrapolation error in off-policy RL, and use it to formulate a constraint that
prevents the policy from drifting toward unsupported actions. In this study, we
present Frictional Q-learning, a deep reinforcement learning algorithm for
continuous control, which extends batch-constrained reinforcement learning. Our
algorithm constrains the agent's action space to encourage behavior similar to
that in the replay buffer, while maintaining a distance from the manifold of
the orthonormal action space. The constraint preserves the simplicity of
batch-constrained, and provides an intuitive physical interpretation of
extrapolation error. Empirically, we further demonstrate that our algorithm is
robustly trained and achieves competitive performance across standard
continuous control benchmarks.
\\ ( https://arxiv.org/abs/2509.19771 ,  929kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19773 (*cross-listing*)
Date: Wed, 24 Sep 2025 05:52:02 GMT   (4749kb)

Title: Sobolev acceleration for neural networks
Authors: Jong Kwon Oh, Hanbaek Lyu, Hwijae Son
Categories: cs.LG cs.AI
\\
  Sobolev training, which integrates target derivatives into the loss
functions, has been shown to accelerate convergence and improve generalization
compared to conventional $L^2$ training. However, the underlying mechanisms of
this training method remain only partially understood. In this work, we present
the first rigorous theoretical framework proving that Sobolev training
accelerates the convergence of Rectified Linear Unit (ReLU) networks. Under a
student-teacher framework with Gaussian inputs and shallow architectures, we
derive exact formulas for population gradients and Hessians, and quantify the
improvements in conditioning of the loss landscape and gradient-flow
convergence rates. Extensive numerical experiments validate our theoretical
findings and show that the benefits of Sobolev training extend to modern deep
learning tasks.
\\ ( https://arxiv.org/abs/2509.19773 ,  4749kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19774 (*cross-listing*)
Date: Wed, 24 Sep 2025 05:54:33 GMT   (8667kb)

Title: PPGFlowECG: Latent Rectified Flow with Cross-Modal Encoding for
  PPG-Guided ECG Generation and Cardiovascular Disease Detection
Authors: Xiaocheng Fang, Jiarui Jin, Haoyu Wang, Che Liu, Jieyi Cai, Guangkun
  Nie, Jun Li, Hongyan Li, Shenda Hong
Categories: cs.LG cs.AI eess.SP
\\
  In clinical practice, electrocardiography (ECG) remains the gold standard for
cardiac monitoring, providing crucial insights for diagnosing a wide range of
cardiovascular diseases (CVDs). However, its reliance on specialized equipment
and trained personnel limits feasibility for continuous routine monitoring.
Photoplethysmography (PPG) offers accessible, continuous monitoring but lacks
definitive electrophysiological information, preventing conclusive diagnosis.
Generative models present a promising approach to translate PPG into clinically
valuable ECG signals, yet current methods face substantial challenges,
including the misalignment of physiological semantics in generative models and
the complexity of modeling in high-dimensional signals. To this end, we propose
PPGFlowECG, a two-stage framework that aligns PPG and ECG in a shared latent
space via the CardioAlign Encoder and employs latent rectified flow to generate
ECGs with high fidelity and interpretability. To the best of our knowledge,
this is the first study to experiment on MCMED, a newly released clinical-grade
dataset comprising over 10 million paired PPG-ECG samples from more than
118,000 emergency department visits with expert-labeled cardiovascular disease
annotations. Results demonstrate the effectiveness of our method for PPG-to-ECG
translation and cardiovascular disease detection. Moreover, cardiologist-led
evaluations confirm that the synthesized ECGs achieve high fidelity and improve
diagnostic reliability, underscoring our method's potential for real-world
cardiovascular screening.
\\ ( https://arxiv.org/abs/2509.19774 ,  8667kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19789 (*cross-listing*)
Date: Wed, 24 Sep 2025 06:19:31 GMT   (1546kb)

Title: RDAR: Reward-Driven Agent Relevance Estimation for Autonomous Driving
Authors: Carlo Bosio, Greg Woelki, Noureldin Hendy, Nicholas Roy, Byungsoo Kim
Categories: cs.LG cs.AI cs.RO
Comments: 10 pages, 6 figures
\\
  Human drivers focus only on a handful of agents at any one time. On the other
hand, autonomous driving systems process complex scenes with numerous agents,
regardless of whether they are pedestrians on a crosswalk or vehicles parked on
the side of the road. While attention mechanisms offer an implicit way to
reduce the input to the elements that affect decisions, existing attention
mechanisms for capturing agent interactions are quadratic, and generally
computationally expensive. We propose RDAR, a strategy to learn per-agent
relevance -- how much each agent influences the behavior of the controlled
vehicle -- by identifying which agents can be excluded from the input to a
pre-trained behavior model. We formulate the masking procedure as a Markov
Decision Process where the action consists of a binary mask indicating agent
selection. We evaluate RDAR on a large-scale driving dataset, and demonstrate
its ability to learn an accurate numerical measure of relevance by achieving
comparable driving performance, in terms of overall progress, safety and
performance, while processing significantly fewer agents compared to a state of
the art behavior model.
\\ ( https://arxiv.org/abs/2509.19789 ,  1546kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19814 (*cross-listing*)
Date: Wed, 24 Sep 2025 06:52:53 GMT   (113kb)

Title: Causal Inference under Threshold Manipulation: Bayesian Mixture Modeling
  and Heterogeneous Treatment Effects
Authors: Kohsuke Kubota and Shonosuke Sugasawa
Categories: stat.ME cs.AI
Comments: Submitted to AAAI 2026
\\
  Many marketing applications, including credit card incentive programs, offer
rewards to customers who exceed specific spending thresholds to encourage
increased consumption. Quantifying the causal effect of these thresholds on
customers is crucial for effective marketing strategy design. Although
regression discontinuity design is a standard method for such causal inference
tasks, its assumptions can be violated when customers, aware of the thresholds,
strategically manipulate their spending to qualify for the rewards. To address
this issue, we propose a novel framework for estimating the causal effect under
threshold manipulation. The main idea is to model the observed spending
distribution as a mixture of two distributions: one representing customers
strategically affected by the threshold, and the other representing those
unaffected. To fit the mixture model, we adopt a two-step Bayesian approach
consisting of modeling non-bunching customers and fitting a mixture model to a
sample around the threshold. We show posterior contraction of the resulting
posterior distribution of the causal effect under large samples. Furthermore,
we extend this framework to a hierarchical Bayesian setting to estimate
heterogeneous causal effects across customer subgroups, allowing for stable
inference even with small subgroup sample sizes. We demonstrate the
effectiveness of our proposed methods through simulation studies and illustrate
their practical implications using a real-world marketing dataset.
\\ ( https://arxiv.org/abs/2509.19814 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19830 (*cross-listing*)
Date: Wed, 24 Sep 2025 07:22:03 GMT   (67kb)

Title: On the Rate of Convergence of Kolmogorov-Arnold Network Regression
  Estimators
Authors: Wei Liu, Eleni Chatzi, Zhilu Lai
Categories: cs.LG cs.AI stat.ML
\\
  Kolmogorov-Arnold Networks (KANs) offer a structured and interpretable
framework for multivariate function approximation by composing univariate
transformations through additive or multiplicative aggregation. This paper
establishes theoretical convergence guarantees for KANs when the univariate
components are represented by B-splines. We prove that both additive and hybrid
additive-multiplicative KANs attain the minimax-optimal convergence rate
$O(n^{-2r/(2r+1)})$ for functions in Sobolev spaces of smoothness $r$. We
further derive guidelines for selecting the optimal number of knots in the
B-splines. The theory is supported by simulation studies that confirm the
predicted convergence rates. These results provide a theoretical foundation for
using KANs in nonparametric regression and highlight their potential as a
structured alternative to existing methods.
\\ ( https://arxiv.org/abs/2509.19830 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19849 (*cross-listing*)
Date: Wed, 24 Sep 2025 07:47:02 GMT   (1860kb,A)

Title: Analyzing Generalization in Pre-Trained Symbolic Regression
Authors: Henrik Voigt, Paul Kahlmeyer, Kai Lawonn, Michael Habeck, Joachim
  Giesen
Categories: cs.LG cs.AI
\\
  Symbolic regression algorithms search a space of mathematical expressions for
formulas that explain given data. Transformer-based models have emerged as a
promising, scalable approach shifting the expensive combinatorial search to a
large-scale pre-training phase. However, the success of these models is
critically dependent on their pre-training data. Their ability to generalize to
problems outside of this pre-training distribution remains largely unexplored.
In this work, we conduct a systematic empirical study to evaluate the
generalization capabilities of pre-trained, transformer-based symbolic
regression. We rigorously test performance both within the pre-training
distribution and on a series of out-of-distribution challenges for several
state of the art approaches. Our findings reveal a significant dichotomy: while
pre-trained models perform well in-distribution, the performance consistently
degrades in out-of-distribution scenarios. We conclude that this generalization
gap is a critical barrier for practitioners, as it severely limits the
practical use of pre-trained approaches for real-world applications.
\\ ( https://arxiv.org/abs/2509.19849 ,  1860kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19852 (*cross-listing*)
Date: Wed, 24 Sep 2025 07:47:52 GMT   (532kb)

Title: Eliminating stability hallucinations in llm-based tts models via
  attention guidance
Authors: ShiMing Wang, ZhiHao Du, Yang Xiang, TianYu Zhao, Han Zhao, Qian Chen,
  XianGang Li, HanJie Guo, ZhenHua Ling
Categories: cs.SD cs.AI
Comments: 5 pages, submitted to ICASSP2026
\\
  This paper focuses on resolving stability hallucinations (e.g., repetitive or
omitted speech) in LLM-based Text-to-Speech (TTS) models by improving and
leveraging the attention mechanism. First, we analyzed the alignment mechanism
between text tokens and speech tokens in LLMs. We then proposed a metric termed
the Optimal Alignment Score (OAS), which employs the Viterbi algorithm to
evaluate text-speech alignment quality. Subsequently, OAS was integrated into
the training of CosyVoice2 to assist LLMs in learning continuous, stable
alignment. Additionally, the pre-trained attention value is employed to guide
the training of the student CosyVoice2 via chain-of-thought (CoT), which
further reduces stability hallucinations in synthesized speech. Experiments on
the Seed-TTS-Eval and CV3-Eval test sets demonstrate that the proposed methods
can effectively reduce the stability hallucinations of CosyVoice2 without
introducing additional negative effects. The appendix is available at
https://wsmzzz.github.io/llm_attn.
\\ ( https://arxiv.org/abs/2509.19852 ,  532kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19855 (*cross-listing*)
Date: Wed, 24 Sep 2025 07:54:01 GMT   (3739kb)

Title: CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for
  Collaborative LLM Training in Heterogeneous Edge Networks
Authors: Jiewei Chen, Xiumei Deng, Zehui Xiong, Shaoyong Guo, Xuesong Qiu, Ping
  Wang, Dusit Niyato
Categories: eess.SY cs.AI cs.NI cs.SY
Comments: Submitted to IEEE for review
\\
  The increasing demand for intelligent mobile applications has made
multi-agent collaboration with Transformer-based large language models (LLMs)
essential in mobile edge computing (MEC) networks. However, training LLMs in
such environments remains challenging due to heavy computation, high end-to-end
latency, and limited model generalization. We introduce CollaPipe, a hybrid
distributed learning framework that integrates collaborative pipeline
parallelism with federated aggregation to support self-evolving intelligent
networks. In CollaPipe, the encoder part is adaptively partitioned into
variable-sized segments and deployed across mobile devices for
pipeline-parallel training, while the decoder is deployed on edge servers to
handle generative tasks. Then we perform global model update via federated
aggregation. To enhance training efficiency, we formulate a joint optimization
problem that adaptively allocates model segments, micro-batches, bandwidth, and
transmission power. We derive and use a closed-form convergence bound to design
an Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based
on Lyapunov optimization, ensuring system stability under long-term
constraints. Extensive experiments on downstream tasks with Transformer and
BERT models show that CollaPipe improves computation efficiency by up to
15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device
memory usage by more than half, enabling online learning in heterogeneous and
dynamic communication environments.
\\ ( https://arxiv.org/abs/2509.19855 ,  3739kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19877 (*cross-listing*)
Date: Wed, 24 Sep 2025 08:30:58 GMT   (31242kb)

Title: Advancing Universal Deep Learning for Electronic-Structure Hamiltonian
  Prediction of Materials
Authors: Shi Yin, Zujian Dai, Xinyang Pan, Lixin He
Categories: cs.LG cond-mat.mtrl-sci cs.AI physics.comp-ph
\\
  Deep learning methods for electronic-structure Hamiltonian prediction has
offered significant computational efficiency advantages over traditional DFT
methods, yet the diversity of atomic types, structural patterns, and the
high-dimensional complexity of Hamiltonians pose substantial challenges to the
generalization performance. In this work, we contribute on both the methodology
and dataset sides to advance universal deep learning paradigm for Hamiltonian
prediction. On the method side, we propose NextHAM, a neural E(3)-symmetry and
expressive correction method for efficient and generalizable materials
electronic-structure Hamiltonian prediction. First, we introduce the
zeroth-step Hamiltonians, which can be efficiently constructed by the initial
charge density of DFT, as informative descriptors of neural regression model in
the input level and initial estimates of the target Hamiltonian in the output
level, so that the regression model directly predicts the correction terms to
the target ground truths, thereby significantly simplifying the input-output
mapping for learning. Second, we present a neural Transformer architecture with
strict E(3)-Symmetry and high non-linear expressiveness for Hamiltonian
prediction. Third, we propose a novel training objective to ensure the accuracy
performance of Hamiltonians in both real space and reciprocal space, preventing
error amplification and the occurrence of "ghost states" caused by the large
condition number of the overlap matrix. On the dataset side, we curate a
high-quality broad-coverage large benchmark, namely Materials-HAM-SOC,
comprising 17,000 material structures spanning 68 elements from six rows of the
periodic table and explicitly incorporating SOC effects. Experimental results
on Materials-HAM-SOC demonstrate that NextHAM achieves excellent accuracy and
efficiency in predicting Hamiltonians and band structures.
\\ ( https://arxiv.org/abs/2509.19877 ,  31242kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19883 (*cross-listing*)
Date: Wed, 24 Sep 2025 08:34:19 GMT   (8101kb)

Title: CoMelSinger: Discrete Token-Based Zero-Shot Singing Synthesis With
  Structured Melody Control and Guidance
Authors: Junchuan Zhao, Wei Zeng, Tianle Lyu, Ye Wang
Categories: cs.SD cs.AI
Comments: 13 pages, 5 figures, 5 tables
\\
  Singing Voice Synthesis (SVS) aims to generate expressive vocal performances
from structured musical inputs such as lyrics and pitch sequences. While recent
progress in discrete codec-based speech synthesis has enabled zero-shot
generation via in-context learning, directly extending these techniques to SVS
remains non-trivial due to the requirement for precise melody control. In
particular, prompt-based generation often introduces prosody leakage, where
pitch information is inadvertently entangled within the timbre prompt,
compromising controllability. We present CoMelSinger, a zero-shot SVS framework
that enables structured and disentangled melody control within a discrete codec
modeling paradigm. Built on the non-autoregressive MaskGCT architecture,
CoMelSinger replaces conventional text inputs with lyric and pitch tokens,
preserving in-context generalization while enhancing melody conditioning. To
suppress prosody leakage, we propose a coarse-to-fine contrastive learning
strategy that explicitly regularizes pitch redundancy between the acoustic
prompt and melody input. Furthermore, we incorporate a lightweight encoder-only
Singing Voice Transcription (SVT) module to align acoustic tokens with pitch
and duration, offering fine-grained frame-level supervision. Experimental
results demonstrate that CoMelSinger achieves notable improvements in pitch
accuracy, timbre consistency, and zero-shot transferability over competitive
baselines.
\\ ( https://arxiv.org/abs/2509.19883 ,  8101kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19885 (*cross-listing*)
Date: Wed, 24 Sep 2025 08:34:46 GMT   (1670kb)

Title: Towards Self-Supervised Foundation Models for Critical Care Time Series
Authors: Katja Naasunnguaq Jagd, Rachael DeVries, Ole Winther
Categories: cs.LG cs.AI
Comments: Accepted to NeurIPS 2025 workshop Learning from Time Series for
  Health (TS4H)
\\
  Domain-specific foundation models for healthcare have expanded rapidly in
recent years, yet foundation models for critical care time series remain
relatively underexplored due to the limited size and availability of datasets.
In this work, we introduce an early-stage pre-trained foundation model for
critical care time-series based on the Bi-Axial Transformer (BAT), trained on
pooled electronic health record datasets. We demonstrate effective transfer
learning by fine-tuning the model on a dataset distinct from the training
sources for mortality prediction, where it outperforms supervised baselines,
particularly for small datasets ($<5,000$). These contributions highlight the
potential of self-supervised foundation models for critical care times series
to support generalizable and robust clinical applications in resource-limited
settings.
\\ ( https://arxiv.org/abs/2509.19885 ,  1670kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19924 (*cross-listing*)
Date: Wed, 24 Sep 2025 09:25:15 GMT   (5164kb)

Title: Exploration with Foundation Models: Capabilities, Limitations, and
  Hybrid Approaches
Authors: Remo Sasso, Michelangelo Conserva, Dominik Jeurissen, Paulo Rauber
Categories: cs.LG cs.AI
Comments: 16 pages, 7 figures. Accepted for presentation at the 39th Conference
  on Neural Information Processing Systems (NeurIPS 2025) Workshop on the
  Foundations of Reasoning in Language Models (FoRLM)
MSC-class: 68T05
ACM-class: I.2.6; I.2.8
\\
  Exploration in reinforcement learning (RL) remains challenging, particularly
in sparse-reward settings. While foundation models possess strong semantic
priors, their capabilities as zero-shot exploration agents in classic RL
benchmarks are not well understood. We benchmark LLMs and VLMs on multi-armed
bandits, Gridworlds, and sparse-reward Atari to test zero-shot exploration. Our
investigation reveals a key limitation: while VLMs can infer high-level
objectives from visual input, they consistently fail at precise low-level
control: the "knowing-doing gap". To analyze a potential bridge for this gap,
we investigate a simple on-policy hybrid framework in a controlled, best-case
scenario. Our results in this idealized setting show that VLM guidance can
significantly improve early-stage sample efficiency, providing a clear analysis
of the potential and constraints of using foundation models to guide
exploration rather than for end-to-end control.
\\ ( https://arxiv.org/abs/2509.19924 ,  5164kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19927 (*cross-listing*)
Date: Wed, 24 Sep 2025 09:35:52 GMT   (1115kb)

Title: TABFAIRGDT: A Fast Fair Tabular Data Generator using Autoregressive
  Decision Trees
Authors: Emmanouil Panagiotou, Beno\^it Ronval, Arjun Roy, Ludwig Bothmann,
  Bernd Bischl, Siegfried Nijssen, Eirini Ntoutsi
Categories: cs.LG cs.AI
Comments: Paper accepted at IEEE ICDM 2025: IEEE International Conference on
  Data Mining 2025, November 12-15, 2025, Washington DC, USA
\\
  Ensuring fairness in machine learning remains a significant challenge, as
models often inherit biases from their training data. Generative models have
recently emerged as a promising approach to mitigate bias at the data level
while preserving utility. However, many rely on deep architectures, despite
evidence that simpler models can be highly effective for tabular data. In this
work, we introduce TABFAIRGDT, a novel method for generating fair synthetic
tabular data using autoregressive decision trees. To enforce fairness, we
propose a soft leaf resampling technique that adjusts decision tree outputs to
reduce bias while preserving predictive performance. Our approach is
non-parametric, effectively capturing complex relationships between mixed
feature types, without relying on assumptions about the underlying data
distributions. We evaluate TABFAIRGDT on benchmark fairness datasets and
demonstrate that it outperforms state-of-the-art (SOTA) deep generative models,
achieving better fairness-utility trade-off for downstream tasks, as well as
higher synthetic data quality. Moreover, our method is lightweight, highly
efficient, and CPU-compatible, requiring no data pre-processing. Remarkably,
TABFAIRGDT achieves a 72% average speedup over the fastest SOTA baseline across
various dataset sizes, and can generate fair synthetic data for medium-sized
datasets (10 features, 10K samples) in just one second on a standard CPU,
making it an ideal solution for real-world fairness-sensitive applications.
\\ ( https://arxiv.org/abs/2509.19927 ,  1115kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19939 (*cross-listing*)
Date: Wed, 24 Sep 2025 09:46:10 GMT   (31676kb)

Title: AJAHR: Amputated Joint Aware 3D Human Mesh Recovery
Authors: Hyunjin Cho, Giyun Choi, Jongwon Choi
Categories: cs.GR cs.AI cs.CV
Comments: 8pages, Project Page: https://chojinie.github.io/project_AJAHR/
\\
  Existing human mesh recovery methods assume a standard human body structure,
overlooking diverse anatomical conditions such as limb loss. This assumption
introduces bias when applied to individuals with amputations - a limitation
further exacerbated by the scarcity of suitable datasets. To address this gap,
we propose Amputated Joint Aware 3D Human Mesh Recovery (AJAHR), which is an
adaptive pose estimation framework that improves mesh reconstruction for
individuals with limb loss. Our model integrates a body-part amputation
classifier, jointly trained with the mesh recovery network, to detect potential
amputations. We also introduce Amputee 3D (A3D), which is a synthetic dataset
offering a wide range of amputee poses for robust training. While maintaining
competitive performance on non-amputees, our approach achieves state-of-the-art
results for amputated individuals. Additional materials can be found at the
project webpage.
\\ ( https://arxiv.org/abs/2509.19939 ,  31676kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19947 (*cross-listing*)
Date: Wed, 24 Sep 2025 09:58:31 GMT   (4301kb)

Title: A Set of Generalized Components to Achieve Effective Poison-only
  Clean-label Backdoor Attacks with Collaborative Sample Selection and Triggers
Authors: Zhixiao Wu, Yao Lu, Jie Wen, Hao Sun, Qi Zhou, Guangming Lu
Categories: cs.CR cs.AI
Comments: 31 pages, 16 figures, accepted in Neurips 2025
\\
  Poison-only Clean-label Backdoor Attacks aim to covertly inject
attacker-desired behavior into DNNs by merely poisoning the dataset without
changing the labels. To effectively implant a backdoor, multiple
\textbf{triggers} are proposed for various attack requirements of Attack
Success Rate (ASR) and stealthiness. Additionally, sample selection enhances
clean-label backdoor attacks' ASR by meticulously selecting ``hard'' samples
instead of random samples to poison. Current methods 1) usually handle the
sample selection and triggers in isolation, leading to severely limited
improvements on both ASR and stealthiness. Consequently, attacks exhibit
unsatisfactory performance on evaluation metrics when converted to PCBAs via a
mere stacking of methods. Therefore, we seek to explore the bidirectional
collaborative relations between the sample selection and triggers to address
the above dilemma. 2) Since the strong specificity within triggers, the simple
combination of sample selection and triggers fails to substantially enhance
both evaluation metrics, with generalization preserved among various attacks.
Therefore, we seek to propose a set of components to significantly improve both
stealthiness and ASR based on the commonalities of attacks. Specifically,
Component A ascertains two critical selection factors, and then makes them an
appropriate combination based on the trigger scale to select more reasonable
``hard'' samples for improving ASR. Component B is proposed to select samples
with similarities to relevant trigger implanted samples to promote
stealthiness. Component C reassigns trigger poisoning intensity on RGB colors
through distinct sensitivity of the human visual system to RGB for higher ASR,
with stealthiness ensured by sample selection, including Component B.
Furthermore, all components can be strategically integrated into diverse PCBAs.
\\ ( https://arxiv.org/abs/2509.19947 ,  4301kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19953 (*cross-listing*)
Date: Wed, 24 Sep 2025 10:01:02 GMT   (1100kb)

Title: 2025 Southeast Asia Eleven Nations Influence Index Report
Authors: Wei Meng
Categories: physics.soc-ph cs.AI
Comments: The document delivers a robust reproducible index (SAII v3) that
  advances quantitative IR methods and offers actionable insights into
  Southeast Asia's stratified power structure
MSC-class: 62P25, 91D10, 91B84, 68T09
ACM-class: I.2.7; H.2.8; J.4; K.4.1
\\
  This study constructs a fully data-driven and reproducible Southeast Asia
Influence Index (SAII v3) to reduce bias from expert scoring and subjective
weighting while mapping hierarchical power structures across the eleven ASEAN
nations. We aggregate authoritative open-source indicators across four
dimensions (economic, military, diplomatic, socio-technological) and apply a
three-tiered standardization chain quantile-Box-Cox-min-max to mitigate
outliers and skewness. Weights are obtained through equal-weight integration of
Entropy Weighting Method (EWM), CRITIC, and PCA. Robustness is assessed via
Kendall's tau, +/-20% weight perturbation, and 10,000 bootstrap iterations,
with additional checks including +/-10% dimensional sensitivity and V2-V3 bump
chart comparisons. Results show integrated weights: Economy 35-40%, Military
20-25%, Diplomacy about 20%, Socio-Technology about 15%. The regional landscape
exhibits a one-strong, two-medium, three-stable, and multiple-weak pattern:
Indonesia, Singapore, and Malaysia lead, while Thailand, the Philippines, and
Vietnam form a mid-tier competitive band. V2 and V3 rankings are highly
consistent (Kendall's tau = 0.818), though small mid-tier reorderings appear
(Thailand and the Philippines rise, Vietnam falls), indicating that v3 is more
sensitive to structural equilibrium. ASEAN-11 average sensitivity highlights
military and socio-technological dimensions as having the largest marginal
effects (+/-0.002). In conclusion, SAII v3 delivers algorithmic weighting and
auditable reproducibility, reveals multidimensional drivers of influence in
Southeast Asia, and provides actionable quantitative evidence for resource
allocation and policy prioritization by regional governments and external
partners.
\\ ( https://arxiv.org/abs/2509.19953 ,  1100kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19972 (*cross-listing*)
Date: Wed, 24 Sep 2025 10:27:45 GMT   (3337kb)

Title: An effective control of large systems of active particles: An
  application to evacuation problem
Authors: Albina Klepach, Egor E. Nuzhin, Alexey A. Tsukanov, Nikolay V.
  Brilliantov
Categories: cs.RO cs.AI
DOI: 10.2139/ssrn.5370927
\\
  Manipulation of large systems of active particles is a serious challenge
across diverse domains, including crowd management, control of robotic swarms,
and coordinated material transport. The development of advanced control
strategies for complex scenarios is hindered, however, by the lack of
scalability and robustness of the existing methods, in particular, due to the
need of an individual control for each agent. One possible solution involves
controlling a system through a leader or a group of leaders, which other agents
tend to follow. Using such an approach we develop an effective control strategy
for a leader, combining reinforcement learning (RL) with artificial forces
acting on the system. To describe the guidance of active particles by a leader
we introduce the generalized Vicsek model. This novel method is then applied to
the problem of the effective evacuation by a robot-rescuer (leader) of large
groups of people from hazardous places. We demonstrate, that while a
straightforward application of RL yields suboptimal results, even for advanced
architectures, our approach provides a robust and efficient evacuation
strategy. The source code supporting this study is publicly available at:
https://github.com/cinemere/evacuation.
\\ ( https://arxiv.org/abs/2509.19972 ,  3337kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19996 (*cross-listing*)
Date: Wed, 24 Sep 2025 11:02:13 GMT   (187kb)

Title: Choosing to Be Green: Advancing Green AI via Dynamic Model Selection
Authors: Emilio Cruciani, Roberto Verdecchia
Categories: cs.CY cs.AI
Comments: 2nd Workshop on Green-Aware Artificial Intelligence (Green-Aware
  2025). 9 pages, 1 figure
\\
  Artificial Intelligence is increasingly pervasive across domains, with ever
more complex models delivering impressive predictive performance. This fast
technological advancement however comes at a concerning environmental cost,
with state-of-the-art models - particularly deep neural networks and large
language models - requiring substantial computational resources and energy. In
this work, we present the intuition of Green AI dynamic model selection, an
approach based on dynamic model selection that aims at reducing the
environmental footprint of AI by selecting the most sustainable model while
minimizing potential accuracy loss. Specifically, our approach takes into
account the inference task, the environmental sustainability of available
models, and accuracy requirements to dynamically choose the most suitable
model. Our approach presents two different methods, namely Green AI dynamic
model cascading and Green AI dynamic model routing. We demonstrate the
effectiveness of our approach via a proof of concept empirical example based on
a real-world dataset. Our results show that Green AI dynamic model selection
can achieve substantial energy savings (up to ~25%) while substantially
retaining the accuracy of the most energy greedy solution (up to ~95%). As
conclusion, our preliminary findings highlight the potential that hybrid,
adaptive model selection strategies withhold to mitigate the energy demands of
modern AI systems without significantly compromising accuracy requirements.
\\ ( https://arxiv.org/abs/2509.19996 ,  187kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20048 (*cross-listing*)
Date: Wed, 24 Sep 2025 12:15:35 GMT   (564kb)

Title: Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for
  Biosignal Representations
Authors: Rami Zewail
Categories: cs.LG cs.AI eess.SP
\\
  Learning robust representations for biosignals is often hampered by the
challenge of designing effective data augmentations.Traditional methods can
fail to capture the complex variations inherent in physiological data. Within
this context, we propose a novel hybrid framework, Diffusion-Augmented
Contrastive Learning (DACL), that fuses concepts from diffusion models and
supervised contrastive learning. The DACL framework operates on a latent space
created by a lightweight Variational Autoencoder (VAE) trained on our novel
Scattering Transformer (ST) features [12]. It utilizes the diffusion forward
process as a principled data augmentation technique to generate multiple noisy
views of these latent embeddings. A U-Net style encoder is then trained with a
supervised contrastive objective to learn a representation that balances class
discrimination with robustness to noise across various diffusion time steps. We
evaluated this proof-of-concept method on the PhysioNet 2017 ECG dataset,
achieving a competitive AUROC of 0.7815. This work establishes a new paradigm
for representation learning by using the diffusion process itself to drive the
contrastive objective, creating noise-invariant embeddings that demonstrate a
strong foundation for class separability.
\\ ( https://arxiv.org/abs/2509.20048 ,  564kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20049 (*cross-listing*)
Date: Wed, 24 Sep 2025 12:15:37 GMT   (10748kb)

Title: Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven
  Functional Space Discovery for Interpretable Machine Learning
Authors: Alastair Poole, Stig McArthur, Saravan Kumar
Categories: cs.NE cs.AI cs.LG
\\
  Kolmogorov-Arnold Networks (KANs) relocate learnable nonlinearities from
nodes to edges, demonstrating remarkable capabilities in scientific machine
learning and interpretable modeling. However, current KAN implementations
suffer from fundamental inefficiencies due to redundancy in high-dimensional
spline parameter spaces, where numerous distinct parameterisations yield
functionally equivalent behaviors. This redundancy manifests as a "nuisance
space" in the model's Jacobian, leading to susceptibility to overfitting and
poor generalization. We introduce Projective Kolmogorov-Arnold Networks
(P-KANs), a novel training framework that guides edge function discovery
towards interpretable functional representations through entropy-minimisation
techniques from signal analysis and sparse dictionary learning. Rather than
constraining functions to predetermined spaces, our approach maintains spline
space flexibility while introducing "gravitational" terms that encourage
convergence towards optimal functional representations. Our key insight
recognizes that optimal representations can be identified through entropy
analysis of projection coefficients, compressing edge functions to
lower-parameter projective spaces (Fourier, Chebyshev, Bessel). P-KANs
demonstrate superior performance across multiple domains, achieving up to 80%
parameter reduction while maintaining representational capacity, significantly
improved robustness to noise compared to standard KANs, and successful
application to industrial automated fiber placement prediction. Our approach
enables automatic discovery of mixed functional representations where different
edges converge to different optimal spaces, providing both compression benefits
and enhanced interpretability for scientific machine learning applications.
\\ ( https://arxiv.org/abs/2509.20049 ,  10748kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20051 (*cross-listing*)
Date: Wed, 24 Sep 2025 12:19:18 GMT   (2093kb)

Title: One Filters All: A Generalist Filter for State Estimation
Authors: Shiqi Liu, Wenhan Cao, Chang Liu, Zeyu He, Tianyi Zhang, Shengbo Eben
  Li
Categories: cs.LG cs.AI
Comments: NeurIPS 2025
\\
  Estimating hidden states in dynamical systems, also known as optimal
filtering, is a long-standing problem in various fields of science and
engineering. In this paper, we introduce a general filtering framework,
\textbf{LLM-Filter}, which leverages large language models (LLMs) for state
estimation by embedding noisy observations with text prototypes. In various
experiments for classical dynamical systems, we find that first, state
estimation can significantly benefit from the reasoning knowledge embedded in
pre-trained LLMs. By achieving proper modality alignment with the frozen LLM,
LLM-Filter outperforms the state-of-the-art learning-based approaches. Second,
we carefully design the prompt structure, System-as-Prompt (SaP), incorporating
task instructions that enable the LLM to understand the estimation tasks.
Guided by these prompts, LLM-Filter exhibits exceptional generalization,
capable of performing filtering tasks accurately in changed or even unseen
environments. We further observe a scaling-law behavior in LLM-Filter, where
accuracy improves with larger model sizes and longer training times. These
findings make LLM-Filter a promising foundation model of filtering.
\\ ( https://arxiv.org/abs/2509.20051 ,  2093kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20109 (*cross-listing*)
Date: Wed, 24 Sep 2025 13:35:15 GMT   (19252kb)

Title: Discrete Diffusion for Reflective Vision-Language-Action Models in
  Autonomous Driving
Authors: Pengxiang Li, Yinan Zheng, Yue Wang, Huimin Wang, Hang Zhao, Jingjing
  Liu, Xianyuan Zhan, Kun Zhan, Xianpeng Lang
Categories: cs.RO cs.AI cs.CL
\\
  End-to-End (E2E) solutions have emerged as a mainstream approach for
autonomous driving systems, with Vision-Language-Action (VLA) models
representing a new paradigm that leverages pre-trained multimodal knowledge
from Vision-Language Models (VLMs) to interpret and interact with complex
real-world environments. However, these methods remain constrained by the
limitations of imitation learning, which struggles to inherently encode
physical rules during training. Existing approaches often rely on complex
rule-based post-refinement, employ reinforcement learning that remains largely
limited to simulation, or utilize diffusion guidance that requires
computationally expensive gradient calculations. To address these challenges,
we introduce ReflectDrive, a novel learning-based framework that integrates a
reflection mechanism for safe trajectory generation via discrete diffusion. We
first discretize the two-dimensional driving space to construct an action
codebook, enabling the use of pre-trained Diffusion Language Models for
planning tasks through fine-tuning. Central to our approach is a safety-aware
reflection mechanism that performs iterative self-correction without gradient
computation. Our method begins with goal-conditioned trajectory generation to
model multi-modal driving behaviors. Based on this, we apply local search
methods to identify unsafe tokens and determine feasible solutions, which then
serve as safe anchors for inpainting-based regeneration. Evaluated on the
NAVSIM benchmark, ReflectDrive demonstrates significant advantages in
safety-critical trajectory generation, offering a scalable and reliable
solution for autonomous driving systems.
\\ ( https://arxiv.org/abs/2509.20109 ,  19252kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20113 (*cross-listing*)
Date: Wed, 24 Sep 2025 13:37:53 GMT   (1766kb)

Title: Discovering Association Rules in High-Dimensional Small Tabular Data
Authors: Erkan Karabulut, Daniel Daza, Paul Groth, Victoria Degeler
Categories: cs.LG cs.AI
Comments: This paper was accepted at ECAI 2025 Workshop: 1st International
  Workshop on Advanced Neuro-Symbolic Applications (ANSyA)
\\
  Association Rule Mining (ARM) aims to discover patterns between features in
datasets in the form of propositional rules, supporting both knowledge
discovery and interpretable machine learning in high-stakes decision-making.
However, in high-dimensional settings, rule explosion and computational
overhead render popular algorithmic approaches impractical without effective
search space reduction, challenges that propagate to downstream tasks.
Neurosymbolic methods, such as Aerial+, have recently been proposed to address
the rule explosion in ARM. While they tackle the high dimensionality of the
data, they also inherit limitations of neural networks, particularly reduced
performance in low-data regimes.
  This paper makes three key contributions to association rule discovery in
high-dimensional tabular data. First, we empirically show that Aerial+ scales
one to two orders of magnitude better than state-of-the-art algorithmic and
neurosymbolic baselines across five real-world datasets. Second, we introduce
the novel problem of ARM in high-dimensional, low-data settings, such as gene
expression data from the biomedicine domain with around 18k features and 50
samples. Third, we propose two fine-tuning approaches to Aerial+ using tabular
foundation models. Our proposed approaches are shown to significantly improve
rule quality on five real-world datasets, demonstrating their effectiveness in
low-data, high-dimensional scenarios.
\\ ( https://arxiv.org/abs/2509.20113 ,  1766kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20128 (*cross-listing*)
Date: Wed, 24 Sep 2025 13:54:52 GMT   (1540kb)

Title: KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial
  Animation
Authors: Tianle Lyu, Junchuan Zhao, Ye Wang
Categories: cs.GR cs.AI cs.CV cs.MM
Comments: 5 pages, 3 figures, 3 tables
\\
  Audio-driven facial animation has made significant progress in multimedia
applications, with diffusion models showing strong potential for talking-face
synthesis. However, most existing works treat speech features as a monolithic
representation and fail to capture their fine-grained roles in driving
different facial motions, while also overlooking the importance of modeling
keyframes with intense dynamics. To address these limitations, we propose
KSDiff, a Keyframe-Augmented Speech-Aware Dual-Path Diffusion framework.
Specifically, the raw audio and transcript are processed by a Dual-Path Speech
Encoder (DPSE) to disentangle expression-related and head-pose-related
features, while an autoregressive Keyframe Establishment Learning (KEL) module
predicts the most salient motion frames. These components are integrated into a
Dual-path Motion generator to synthesize coherent and realistic facial motions.
Extensive experiments on HDTF and VoxCeleb demonstrate that KSDiff achieves
state-of-the-art performance, with improvements in both lip synchronization
accuracy and head-pose naturalness. Our results highlight the effectiveness of
combining speech disentanglement with keyframe-aware diffusion for talking-head
generation.
\\ ( https://arxiv.org/abs/2509.20128 ,  1540kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20153 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:18:41 GMT   (22kb)

Title: Affective Computing and Emotional Data: Challenges and Implications in
  Privacy Regulations, The AI Act, and Ethics in Large Language Models
Authors: Nicola Fabiano
Categories: cs.CY cs.AI
\\
  This paper examines the integration of emotional intelligence into artificial
intelligence systems, with a focus on affective computing and the growing
capabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to
recognize and respond to human emotions. Drawing on interdisciplinary research
that combines computer science, psychology, and neuroscience, the study
analyzes foundational neural architectures - CNNs for processing facial
expressions and RNNs for sequential data, such as speech and text - that enable
emotion recognition. It examines the transformation of human emotional
experiences into structured emotional data, addressing the distinction between
explicit emotional data collected with informed consent in research settings
and implicit data gathered passively through everyday digital interactions.
That raises critical concerns about lawful processing, AI transparency, and
individual autonomy over emotional expressions in digital environments. The
paper explores implications across various domains, including healthcare,
education, and customer service, while addressing challenges of cultural
variations in emotional expression and potential biases in emotion recognition
systems across different demographic groups. From a regulatory perspective, the
paper examines emotional data in the context of the GDPR and the EU AI Act
frameworks, highlighting how emotional data may be considered sensitive
personal data that requires robust safeguards, including purpose limitation,
data minimization, and meaningful consent mechanisms.
\\ ( https://arxiv.org/abs/2509.20153 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20166 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:33:07 GMT   (7423kb)

Title: CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and
  Threat Intelligence Reasoning
Authors: Lauren Deason, Adam Bali, Ciprian Bejean, Diana Bolocan, James
  Crnkovich, Ioana Croitoru, Krishna Durai, Chase Midler, Calin Miron, David
  Molnar, Brad Moon, Bruno Ostarcevic, Alberto Peltea, Matt Rosenberg, Catalin
  Sandu, Arthur Saputkin, Sagar Shah, Daniel Stan, Ernest Szocs, Shengye Wan,
  Spencer Whitman, Sven Krasser, Joshua Saxe
Categories: cs.CR cs.AI
\\
  Today's cyber defenders are overwhelmed by a deluge of security alerts,
threat intelligence signals, and shifting business context, creating an urgent
need for AI systems to enhance operational security work. While Large Language
Models (LLMs) have the potential to automate and scale Security Operations
Center (SOC) operations, existing evaluations do not fully assess the scenarios
most relevant to real-world defenders. This lack of informed evaluation impacts
both AI developers and those applying LLMs to SOC automation. Without clear
insight into LLM performance in real-world security scenarios, developers lack
a north star for development, and users cannot reliably select the most
effective models. Meanwhile, malicious actors are using AI to scale cyber
attacks, highlighting the need for open source benchmarks to drive adoption and
community-driven improvement among defenders and model developers. To address
this, we introduce CyberSOCEval, a new suite of open source benchmarks within
CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in
two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive
domains with inadequate coverage in current benchmarks. Our evaluations show
that larger, more modern LLMs tend to perform better, confirming the training
scaling laws paradigm. We also find that reasoning models leveraging test time
scaling do not achieve the same boost as in coding and math, suggesting these
models have not been trained to reason about cybersecurity analysis, and
pointing to a key opportunity for improvement. Finally, current LLMs are far
from saturating our evaluations, showing that CyberSOCEval presents a
significant challenge for AI developers to improve cyber defense capabilities.
\\ ( https://arxiv.org/abs/2509.20166 ,  7423kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20182 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:44:28 GMT   (955kb)

Title: Automated Multi-Agent Workflows for RTL Design
Authors: Amulya Bhattaram, Janani Ramamoorthy, Ranit Gupta, Diana Marculescu,
  Dimitrios Stamoulis
Categories: cs.AR cs.AI
Comments: Accepted: ML for Systems Workshop NeurIPS 2025
\\
  The rise of agentic AI workflows unlocks novel opportunities for computer
systems design and optimization. However, for specialized domains such as
program synthesis, the relative scarcity of HDL and proprietary EDA resources
online compared to more common programming tasks introduces challenges, often
necessitating task-specific fine-tuning, high inference costs, and
manually-crafted agent orchestration. In this work, we present VeriMaAS, a
multi-agent framework designed to automatically compose agentic workflows for
RTL code generation. Our key insight is to integrate formal verification
feedback from HDL tools directly into workflow generation, reducing the cost of
gradient-based updates or prolonged reasoning traces. Our method improves
synthesis performance by 5-7% for pass@k over fine-tuned baselines, while
requiring only a few hundred training examples, representing an
order-of-magnitude reduction in supervision cost.
\\ ( https://arxiv.org/abs/2509.20182 ,  955kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20184 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:45:00 GMT   (471kb)

Title: An Improved Time Series Anomaly Detection by Applying Structural
  Similarity
Authors: Tiejun Wang, Rui Wang, Xudong Mou, Mengyuan Ma, Tianyu Wo, Renyu Yang,
  Xudong Liu
Categories: cs.LG cs.AI
\\
  Effective anomaly detection in time series is pivotal for modern industrial
applications and financial systems. Due to the scarcity of anomaly labels and
the high cost of manual labeling, reconstruction-based unsupervised approaches
have garnered considerable attention. However, accurate anomaly detection
remains an unsettled challenge, since the optimization objectives of
reconstruction-based methods merely rely on point-by-point distance measures,
ignoring the potential structural characteristics of time series and thus
failing to tackle complex pattern-wise anomalies. In this paper, we propose
StrAD, a novel structure-enhanced anomaly detection approach to enrich the
optimization objective by incorporating structural information hidden in the
time series and steering the data reconstruction procedure to better capture
such structural features. StrAD accommodates the trend, seasonality, and shape
in the optimization objective of the reconstruction model to learn latent
structural characteristics and capture the intrinsic pattern variation of time
series. The proposed structure-aware optimization objective mechanism can
assure the alignment between the original data and the reconstructed data in
terms of structural features, thereby keeping consistency in global fluctuation
and local characteristics. The mechanism is pluggable and applicable to any
reconstruction-based methods, enhancing the model sensitivity to both
point-wise anomalies and pattern-wise anomalies. Experimental results show that
StrAD improves the performance of state-of-the-art reconstruction-based models
across five real-world anomaly detection datasets.
\\ ( https://arxiv.org/abs/2509.20184 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20187 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:45:35 GMT   (530kb)

Title: How People Manage Knowledge in their "Second Brains"- A Case Study with
  Industry Researchers Using Obsidian
Authors: Juliana Jansen Ferreira, Vin\'icius Segura, Joana Gabriela Souza, and
  Joao Henrique Gallas Brasil
Categories: cs.HC cs.AI
Comments: 9 pages, 3 figures
DOI: 10.1007/978-3-032-05008-3_15
\\
  People face overwhelming information during work activities, necessitating
effective organization and management strategies. Even in personal lives,
individuals must keep, annotate, organize, and retrieve knowledge from daily
routines. The collection of records for future reference is known as a personal
knowledge base. Note-taking applications are valuable tools for building and
maintaining these bases, often called a ''second brain''. This paper presents a
case study on how people build and explore personal knowledge bases for various
purposes. We selected the note-taking tool Obsidian and researchers from a
Brazilian lab for an in-depth investigation. Our investigation reveals
interesting findings about how researchers build and explore their personal
knowledge bases. A key finding is that participants' knowledge retrieval
strategy influences how they build and maintain their content. We suggest
potential features for an AI system to support this process.
\\ ( https://arxiv.org/abs/2509.20187 ,  530kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20190 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:46:42 GMT   (127kb)

Title: STAF: Leveraging LLMs for Automated Attack Tree-Based Security Test
  Generation
Authors: Tanmay Khule, Stefan Marksteiner, Jose Alguindigue, Hannes Fuchs,
  Sebastian Fischmeister, Apurva Narayan
Categories: cs.CR cs.AI
Comments: 18 pages, 2 figures, accepted for 23rd escar Europe (Nov 05-06, 2025,
  Frankfurt, Germany)
\\
  In modern automotive development, security testing is critical for
safeguarding systems against increasingly advanced threats. Attack trees are
widely used to systematically represent potential attack vectors, but
generating comprehensive test cases from these trees remains a labor-intensive,
error-prone task that has seen limited automation in the context of testing
vehicular systems. This paper introduces STAF (Security Test Automation
Framework), a novel approach to automating security test case generation.
Leveraging Large Language Models (LLMs) and a four-step self-corrective
Retrieval-Augmented Generation (RAG) framework, STAF automates the generation
of executable security test cases from attack trees, providing an end-to-end
solution that encompasses the entire attack surface. We particularly show the
elements and processes needed to provide an LLM to actually produce sensible
and executable automotive security test suites, along with the integration with
an automated testing framework. We further compare our tailored approach with
general purpose (vanilla) LLMs and the performance of different LLMs (namely
GPT-4.1 and DeepSeek) using our approach. We also demonstrate the method of our
operation step-by-step in a concrete case study. Our results show significant
improvements in efficiency, accuracy, scalability, and easy integration in any
workflow, marking a substantial advancement in automating automotive security
testing methodologies. Using TARAs as an input for verfication tests, we create
synergies by connecting two vital elements of a secure automotive development
process.
\\ ( https://arxiv.org/abs/2509.20190 ,  127kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20214 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:10:44 GMT   (65kb)

Title: Q-Palette: Fractional-Bit Quantizers Toward Optimal Bit Allocation for
  Efficient LLM Deployment
Authors: Deokjae Lee and Hyun Oh Song
Categories: cs.LG cs.AI
Comments: NeurIPS 2025
\\
  We study weight-only post-training quantization (PTQ), which quantizes the
weights of a large language model (LLM) without retraining, using little or no
calibration data. Weight-only PTQ is crucial for reducing the memory footprint
and latency of LLM inference, especially in memory-bound, small-batch inference
scenarios, such as personalized inference on edge devices. Despite its
importance, irregular weight distributions with heavy-tailed outliers in LLMs
complicate quantization, recently motivating rotation-based methods that
transform weights into near-Gaussian distributions, which are more regular with
fewer outliers, thereby reducing quantization error. In this work, we first
derive the information-theoretically optimal bit allocation for Gaussianized
weights under given bit budgets, revealing that fine-grained fractional-bit
quantizers approaching the Gaussian distortion-rate bound are essential to
achieve near-optimal quantization performance. To bridge this theoretical
insight and practical implementation, we introduce Q-Palette, a versatile
collection of fractional-bit quantizers that range from trellis-coded
quantizers offering near-optimal distortion to simpler vector and scalar
quantizers optimized for faster inference, all efficiently implemented with
optimized CUDA kernels across various bitwidths. Furthermore, leveraging
Q-Palette as a foundational component, we propose a novel mixed-scheme
quantization framework, jointly optimizing quantizer choices and layer fusion
decisions given resource constraints. The code is available at
https://github.com/snu-mllab/Q-Palette.
\\ ( https://arxiv.org/abs/2509.20214 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20215 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:12:21 GMT   (3872kb)

Title: The Cream Rises to the Top: Efficient Reranking Method for Verilog Code
  Generation
Authors: Guang Yang, Wei Zheng, Xiang Chen, Yifan Sun, Fengji Zhang, Terry Yue
  Zhuo
Categories: cs.SE cs.AI cs.AR
Comments: Under review ICASSP 2026
\\
  LLMs face significant challenges in Verilog generation due to limited
domain-specific knowledge. While sampling techniques improve pass@k metrics,
hardware engineers need one trustworthy solution rather than uncertain
candidates. To bridge this gap, we formulate it as a semantic alignment problem
between requirements and Verilog implementations, and propose VCD-RNK, a
discriminator model tailored for efficient Verilog code reranking.
Specifically, VCD-RNKincorporates Verilog-specific reasoning by distilling
expert knowledge across three dimensions: code semantic analysis, test case
generation, and functional correctness assessment. By explicitly simulating the
above reasoning processes during inference, VCD-RNK effectively avoids
computationally intensive test execution in existing methods.
\\ ( https://arxiv.org/abs/2509.20215 ,  3872kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20225 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:18:32 GMT   (924kb)

Title: Multimodal Representation-disentangled Information Bottleneck for
  Multimodal Recommendation
Authors: Hui Wang, Jinghui Qin, Wushao Wen, Qingling Li, Shanshan Zhong,
  Zhongzhan Huang
Categories: cs.IR cs.AI
\\
  Multimodal data has significantly advanced recommendation systems by
integrating diverse information sources to model user preferences and item
characteristics. However, these systems often struggle with redundant and
irrelevant information, which can degrade performance. Most existing methods
either fuse multimodal information directly or use rigid architectural
separation for disentanglement, failing to adequately filter noise and model
the complex interplay between modalities. To address these challenges, we
propose a novel framework, the Multimodal Representation-disentangled
Information Bottleneck (MRdIB). Concretely, we first employ a Multimodal
Information Bottleneck to compress the input representations, effectively
filtering out task-irrelevant noise while preserving rich semantic information.
Then, we decompose the information based on its relationship with the
recommendation target into unique, redundant, and synergistic components. We
achieve this decomposition with a series of constraints: a unique information
learning objective to preserve modality-unique signals, a redundant information
learning objective to minimize overlap, and a synergistic information learning
objective to capture emergent information. By optimizing these objectives,
MRdIB guides a model to learn more powerful and disentangled representations.
Extensive experiments on several competitive models and three benchmark
datasets demonstrate the effectiveness and versatility of our MRdIB in
enhancing multimodal recommendation.
\\ ( https://arxiv.org/abs/2509.20225 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20230 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:23:46 GMT   (1311kb)

Title: Beyond Sharp Minima: Robust LLM Unlearning via Feedback-Guided
  Multi-Point Optimization
Authors: Wenhan Wu, Zheyuan Liu, Chongyang Gao, Ren Wang, Kaize Ding
Categories: cs.LG cs.AI
\\
  Current LLM unlearning methods face a critical security vulnerability that
undermines their fundamental purpose: while they appear to successfully remove
sensitive or harmful knowledge, this ``forgotten" information remains
precariously recoverable through relearning attacks. We identify that the root
cause is that conventional methods optimizing the forgetting loss at individual
data points will drive model parameters toward sharp minima in the loss
landscape. In these unstable regions, even minimal parameter perturbations can
drastically alter the model's behaviors. Consequently, relearning attacks
exploit this vulnerability by using just a few fine-tuning samples to navigate
the steep gradients surrounding these unstable regions, thereby rapidly
recovering knowledge that was supposedly erased. This exposes a critical
robustness gap between apparent unlearning and actual knowledge removal. To
address this issue, we propose StableUN, a bi-level feedback-guided
optimization framework that explicitly seeks more stable parameter regions via
neighborhood-aware optimization. It integrates forgetting feedback, which uses
adversarial perturbations to probe parameter neighborhoods, with remembering
feedback to preserve model utility, aligning the two objectives through
gradient projection. Experiments on WMDP and MUSE benchmarks demonstrate that
our method is significantly more robust against both relearning and
jailbreaking attacks while maintaining competitive utility performance.
\\ ( https://arxiv.org/abs/2509.20230 ,  1311kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20240 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:31:49 GMT   (2257kb)

Title: A HyperGraphMamba-Based Multichannel Adaptive Model for ncRNA
  Classification
Authors: Xin An, Ruijie Li, Qiao Ning, Hui Li, Qian Ma, Shikai Guo
Categories: cs.LG cs.AI
Comments: 9 pages, 17 figures (including subfigures), 1 table. Xin An and
  Ruijie Li contributed equally to this work and should be considered co-first
  authors
\\
  Non-coding RNAs (ncRNAs) play pivotal roles in gene expression regulation and
the pathogenesis of various diseases. Accurate classification of ncRNAs is
essential for functional annotation and disease diagnosis. To address existing
limitations in feature extraction depth and multimodal fusion, we propose
HGMamba-ncRNA, a HyperGraphMamba-based multichannel adaptive model, which
integrates sequence, secondary structure, and optionally available expression
features of ncRNAs to enhance classification performance. Specifically, the
sequence of ncRNA is modeled using a parallel Multi-scale Convolution and LSTM
architecture (MKC-L) to capture both local patterns and long-range dependencies
of nucleotides. The structure modality employs a multi-scale graph transformer
(MSGraphTransformer) to represent the multi-level topological characteristics
of ncRNA secondary structures. The expression modality utilizes a Chebyshev
Polynomial-based Kolmogorov-Arnold Network (CPKAN) to effectively model and
interpret high-dimensional expression profiles. Finally, by incorporating
virtual nodes to facilitate efficient and comprehensive multimodal interaction,
HyperGraphMamba is proposed to adaptively align and integrate multichannel
heterogeneous modality features. Experiments conducted on three public datasets
demonstrate that HGMamba-ncRNA consistently outperforms state-of-the-art
methods in terms of accuracy and other metrics. Extensive empirical studies
further confirm the model's robustness, effectiveness, and strong
transferability, offering a novel and reliable strategy for complex ncRNA
functional classification. Code and datasets are available at
https://anonymous.4open.science/r/HGMamba-ncRNA-94D0.
\\ ( https://arxiv.org/abs/2509.20240 ,  2257kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20253 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:38:41 GMT   (352kb)

Title: AnchDrive: Bootstrapping Diffusion Policies with Hybrid Trajectory
  Anchors for End-to-End Driving
Authors: Jinhao Chai, Anqing Jiang, Hao Jiang, Shiyi Mu, Zichong Gu, and
  Shugong Xu
Categories: cs.RO cs.AI
Comments: IWACIII 2025
\\
  End-to-end multi-modal planning has become a transformative paradigm in
autonomous driving, effectively addressing behavioral multi-modality and the
generalization challenge in long-tail scenarios. We propose AnchDrive, a
framework for end-to-end driving that effectively bootstraps a diffusion policy
to mitigate the high computational cost of traditional generative models.
Rather than denoising from pure noise, AnchDrive initializes its planner with a
rich set of hybrid trajectory anchors. These anchors are derived from two
complementary sources: a static vocabulary of general driving priors and a set
of dynamic, context-aware trajectories. The dynamic trajectories are decoded in
real-time by a Transformer that processes dense and sparse perceptual features.
The diffusion model then learns to refine these anchors by predicting a
distribution of trajectory offsets, enabling fine-grained refinement. This
anchor-based bootstrapping design allows for efficient generation of diverse,
high-quality trajectories. Experiments on the NAVSIM benchmark confirm that
AnchDrive sets a new state-of-the-art and shows strong gen?eralizability
\\ ( https://arxiv.org/abs/2509.20253 ,  352kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20277 (*cross-listing*)
Date: Wed, 24 Sep 2025 16:15:17 GMT   (1258kb)

Title: Investigating Security Implications of Automatically Generated Code on
  the Software Supply Chain
Authors: Xiaofan Li and Xing Gao
Categories: cs.CR cs.AI
\\
  In recent years, various software supply chain (SSC) attacks have posed
significant risks to the global community. Severe consequences may arise if
developers integrate insecure code snippets that are vulnerable to SSC attacks
into their products. Particularly, code generation techniques, such as large
language models (LLMs), have been widely utilized in the developer community.
However, LLMs are known to suffer from inherent issues when generating code,
including fabrication, misinformation, and reliance on outdated training data,
all of which can result in serious software supply chain threats. In this
paper, we investigate the security threats to the SSC that arise from these
inherent issues. We examine three categories of threats, including eleven
potential SSC-related threats, related to external components in source code,
and continuous integration configuration files. We find some threats in
LLM-generated code could enable attackers to hijack software and workflows,
while some others might cause potential hidden threats that compromise the
security of the software over time. To understand these security impacts and
severity, we design a tool, SSCGuard, to generate 439,138 prompts based on
SSC-related questions collected online, and analyze the responses of four
popular LLMs from GPT and Llama. Our results show that all identified
SSC-related threats persistently exist. To mitigate these risks, we propose a
novel prompt-based defense mechanism, namely Chain-of-Confirmation, to reduce
fabrication, and a middleware-based defense that informs users of various SSC
threats.
\\ ( https://arxiv.org/abs/2509.20277 ,  1258kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20290 (*cross-listing*)
Date: Wed, 24 Sep 2025 16:25:13 GMT   (6744kb)

Title: PGCLODA: Prompt-Guided Graph Contrastive Learning for
  Oligopeptide-Infectious Disease Association Prediction
Authors: Dayu Tan, Jing Chen, Xiaoping Zhou, Yansen Su and Chunhou Zheng
Categories: cs.LG cs.AI q-bio.QM
Comments: 12page and 8 figures
\\
  Infectious diseases continue to pose a serious threat to public health,
underscoring the urgent need for effective computational approaches to screen
novel anti-infective agents. Oligopeptides have emerged as promising candidates
in antimicrobial research due to their structural simplicity, high
bioavailability, and low susceptibility to resistance. Despite their potential,
computational models specifically designed to predict associations between
oligopeptides and infectious diseases remain scarce. This study introduces a
prompt-guided graph-based contrastive learning framework (PGCLODA) to uncover
potential associations. A tripartite graph is constructed with oligopeptides,
microbes, and diseases as nodes, incorporating both structural and semantic
information. To preserve critical regions during contrastive learning, a
prompt-guided graph augmentation strategy is employed to generate meaningful
paired views. A dual encoder architecture, integrating Graph Convolutional
Network (GCN) and Transformer, is used to jointly capture local and global
features. The fused embeddings are subsequently input into a multilayer
perceptron (MLP) classifier for final prediction. Experimental results on a
benchmark dataset indicate that PGCLODA consistently outperforms
state-of-the-art models in AUROC, AUPRC, and accuracy. Ablation and
hyperparameter studies confirm the contribution of each module. Case studies
further validate the generalization ability of PGCLODA and its potential to
uncover novel, biologically relevant associations. These findings offer
valuable insights for mechanism-driven discovery and oligopeptide-based drug
development. The source code of PGCLODA is available online at
https://github.com/jjnlcode/PGCLODA.
\\ ( https://arxiv.org/abs/2509.20290 ,  6744kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20293 (*cross-listing*)
Date: Wed, 24 Sep 2025 16:26:47 GMT   (2943kb)

Title: When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks
  Silently Undermine Validity
Authors: Benjamin Feuer, Chiung-Yi Tseng, Astitwa Sarthak Lathe, Oussama
  Elachqar, John P Dickerson
Categories: cs.LG cs.AI
\\
  LLM-judged benchmarks are increasingly used to evaluate complex model
behaviors, yet their design introduces failure modes absent in conventional
ground-truth based benchmarks. We argue that without tight objectives and
verifiable constructions, benchmark rankings can produce high-confidence
rankings that are in fact largely noise. We introduce two mechanisms to
diagnose these issues. Schematic adherence quantifies how much of a judge's
overall verdict is explained by the explicit evaluation schema, revealing
unexplained variance when judges deviate from their own rubric. Psychometric
validity aggregates internal consistency and discriminant validity signals to
quantify irreducible uncertainty in any benchmarking run. Applying these tools
to Arena-Hard Auto, we find severe schema incoherence and factor collapse
across popular judges: for example, unexplained variance exceeding 90 percent
for DeepSeek-R1-32B and factor correlations above 0.93 for most criteria. We
also show that the ELO-style aggregation used by Arena-Hard Auto collapses and
masks genuine ranking uncertainty. Our results highlight design failures that
undermine validity and offer actionable principles for building better-scoped,
reliability-aware LLM-judged benchmarks. We release our code at
https://anonymous.4open.science/r/judgment-to-noise-947D/README.md
\\ ( https://arxiv.org/abs/2509.20293 ,  2943kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20324 (*cross-listing*)
Date: Wed, 24 Sep 2025 17:11:35 GMT   (233kb)

Title: RAG Security and Privacy: Formalizing the Threat Model and Attack
  Surface
Authors: Atousa Arzanipour and Rouzbeh Behnia and Reza Ebrahimi and Kaushik
  Dutta
Categories: cs.CR cs.AI
Comments: Accepted at the 5th ICDM Workshop on September 20, 2025
\\
  Retrieval-Augmented Generation (RAG) is an emerging approach in natural
language processing that combines large language models (LLMs) with external
document retrieval to produce more accurate and grounded responses. While RAG
has shown strong potential in reducing hallucinations and improving factual
consistency, it also introduces new privacy and security challenges that differ
from those faced by traditional LLMs. Existing research has demonstrated that
LLMs can leak sensitive information through training data memorization or
adversarial prompts, and RAG systems inherit many of these vulnerabilities. At
the same time, reliance of RAG on an external knowledge base opens new attack
surfaces, including the potential for leaking information about the presence or
content of retrieved documents, or for injecting malicious content to
manipulate model behavior. Despite these risks, there is currently no formal
framework that defines the threat landscape for RAG systems. In this paper, we
address a critical gap in the literature by proposing, to the best of our
knowledge, the first formal threat model for retrieval-RAG systems. We
introduce a structured taxonomy of adversary types based on their access to
model components and data, and we formally define key threat vectors such as
document-level membership inference and data poisoning, which pose serious
privacy and integrity risks in real-world deployments. By establishing formal
definitions and attack models, our work lays the foundation for a more rigorous
and principled understanding of privacy and security in RAG systems.
\\ ( https://arxiv.org/abs/2509.20324 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20328 (*cross-listing*)
Date: Wed, 24 Sep 2025 17:17:27 GMT   (29344kb)

Title: Video models are zero-shot learners and reasoners
Authors: Thadd\"aus Wiedemer, Yuxuan Li, Paul Vicol, Shixiang Shane Gu, Nick
  Matarese, Kevin Swersky, Been Kim, Priyank Jaini, Robert Geirhos
Categories: cs.LG cs.AI cs.CV cs.RO
Comments: Project page: https://video-zero-shot.github.io/
\\
  The remarkable zero-shot capabilities of Large Language Models (LLMs) have
propelled natural language processing from task-specific models to unified,
generalist foundation models. This transformation emerged from simple
primitives: large, generative models trained on web-scale data. Curiously, the
same primitives apply to today's generative video models. Could video models be
on a trajectory towards general-purpose vision understanding, much like LLMs
developed general-purpose language understanding? We demonstrate that Veo 3 can
solve a broad variety of tasks it wasn't explicitly trained for: segmenting
objects, detecting edges, editing images, understanding physical properties,
recognizing object affordances, simulating tool use, and more. These abilities
to perceive, model, and manipulate the visual world enable early forms of
visual reasoning like maze and symmetry solving. Veo's emergent zero-shot
capabilities indicate that video models are on a path to becoming unified,
generalist vision foundation models.
\\ ( https://arxiv.org/abs/2509.20328 ,  29344kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20336 (*cross-listing*)
Date: Wed, 24 Sep 2025 17:25:05 GMT   (1113kb)

Title: Uncovering Graph Reasoning in Decoder-only Transformers with Circuit
  Tracing
Authors: Xinnan Dai, Chung-Hsiang Lo, Kai Guo, Shenglai Zeng, Dongsheng Luo,
  Jiliang Tang
Categories: cs.LG cs.AI
Comments: Accepted by the Workshop on Efficient Reasoning, Neurips 2025
\\
  Transformer-based LLMs demonstrate strong performance on graph reasoning
tasks, yet their internal mechanisms remain underexplored. To uncover these
reasoning process mechanisms in a fundamental and unified view, we set the
basic decoder-only transformers and explain them using the circuit-tracer
framework. Through this lens, we visualize reasoning traces and identify two
core mechanisms in graph reasoning: token merging and structural memorization,
which underlie both path reasoning and substructure extraction tasks. We
further quantify these behaviors and analyze how they are influenced by graph
density and model size. Our study provides a unified interpretability framework
for understanding structural reasoning in decoder-only Transformers.
\\ ( https://arxiv.org/abs/2509.20336 ,  1113kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20338 (*cross-listing*)
Date: Wed, 24 Sep 2025 17:29:56 GMT   (2982kb)

Title: Adaptive Event-Triggered Policy Gradient for Multi-Agent Reinforcement
  Learning
Authors: Umer Siddique, Abhinav Sinha, and Yongcan Cao
Categories: eess.SY cs.AI cs.MA cs.SY math.DS
\\
  Conventional multi-agent reinforcement learning (MARL) methods rely on
time-triggered execution, where agents sample and communicate actions at fixed
intervals. This approach is often computationally expensive and
communication-intensive. To address this limitation, we propose ET-MAPG
(Event-Triggered Multi-Agent Policy Gradient reinforcement learning), a
framework that jointly learns an agent's control policy and its
event-triggering policy. Unlike prior work that decouples these mechanisms,
ET-MAPG integrates them into a unified learning process, enabling agents to
learn not only what action to take but also when to execute it. For scenarios
with inter-agent communication, we introduce AET-MAPG, an attention-based
variant that leverages a self-attention mechanism to learn selective
communication patterns. AET-MAPG empowers agents to determine not only when to
trigger an action but also with whom to communicate and what information to
exchange, thereby optimizing coordination. Both methods can be integrated with
any policy gradient MARL algorithm. Extensive experiments across diverse MARL
benchmarks demonstrate that our approaches achieve performance comparable to
state-of-the-art, time-triggered baselines while significantly reducing both
computational load and communication overhead.
\\ ( https://arxiv.org/abs/2509.20338 ,  2982kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19508 (*cross-listing*)
Date: Tue, 23 Sep 2025 19:26:16 GMT   (9420kb)

Title: STARQA: A Question Answering Dataset for Complex Analytical Reasoning
  over Structured Databases
Authors: Mounica Maddela, Lingjue Xie, Daniel Preotiuc-Pietro, Mausam
Categories: cs.DB cs.CL
Comments: Accepted to EMNLP 2025 long paper
\\
  Semantic parsing methods for converting text to SQL queries enable question
answering over structured data and can greatly benefit analysts who routinely
perform complex analytics on vast data stored in specialized relational
databases. Although several benchmarks measure the abilities of text to SQL,
the complexity of their questions is inherently limited by the level of
expressiveness in query languages and none focus explicitly on questions
involving complex analytical reasoning which require operations such as
calculations over aggregate analytics, time series analysis or scenario
understanding. In this paper, we introduce STARQA, the first public
human-created dataset of complex analytical reasoning questions and answers on
three specialized-domain databases. In addition to generating SQL directly
using LLMs, we evaluate a novel approach (Text2SQLCode) that decomposes the
task into a combination of SQL and Python: SQL is responsible for data
fetching, and Python more naturally performs reasoning. Our results demonstrate
that identifying and combining the abilities of SQL and Python is beneficial
compared to using SQL alone, yet the dataset still remains quite challenging
for the existing state-of-the-art LLMs.
\\ ( https://arxiv.org/abs/2509.19508 ,  9420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19628 (*cross-listing*)
Date: Tue, 23 Sep 2025 22:40:31 GMT   (376kb)

Title: Multimodal Language Models with Modality-Specific Experts for Financial
  Forecasting from Interleaved Sequences of Text and Time Series
Authors: Ross Koval, Nicholas Andrews, Xifeng Yan
Categories: cs.CE cs.CL q-fin.CP
Comments: Preprint
ACM-class: I.2.7; J.4
\\
  Text and time series data offer complementary views of financial markets:
news articles provide narrative context about company events, while stock
prices reflect how markets react to those events. However, despite their
complementary nature, effectively integrating these interleaved modalities for
improved forecasting remains challenging. In this work, we propose a unified
neural architecture that models these interleaved sequences using
modality-specific experts, allowing the model to learn unique time series
patterns, while still enabling joint reasoning across modalities and preserving
pretrained language understanding capabilities. To further improve multimodal
understanding, we introduce a cross-modal alignment framework with a salient
token weighting mechanism that learns to align representations across
modalities with a focus on the most informative tokens. We demonstrate the
effectiveness of our approach on a large-scale financial forecasting task,
achieving state-of-the-art performance across a wide variety of strong unimodal
and multimodal baselines. We develop an interpretability method that reveals
insights into the value of time series-context and reinforces the design of our
cross-modal alignment objective. Finally, we demonstrate that these
improvements translate to meaningful economic gains in investment simulations.
\\ ( https://arxiv.org/abs/2509.19628 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19643 (*cross-listing*)
Date: Tue, 23 Sep 2025 23:19:28 GMT   (1574kb)

Title: Human-AI Narrative Synthesis to Foster Shared Understanding in Civic
  Decision-Making
Authors: Cassandra Overney, Hang Jiang, Urooj Haider, Cassandra Moe, Jasmine
  Mangat, Frank Pantano, Effie G. McMillian, Paul Riggins, Nabeel Gillani
Categories: cs.HC cs.CL
\\
  Community engagement processes in representative political contexts, like
school districts, generate massive volumes of feedback that overwhelm
traditional synthesis methods, creating barriers to shared understanding not
only between civic leaders and constituents but also among community members.
To address these barriers, we developed StoryBuilder, a human-AI collaborative
pipeline that transforms community input into accessible first-person
narratives. Using 2,480 community responses from an ongoing school rezoning
process, we generated 124 composite stories and deployed them through a
mobile-friendly StorySharer interface. Our mixed-methods evaluation combined a
four-month field deployment, user studies with 21 community members, and a
controlled experiment examining how narrative composition affects participant
reactions. Field results demonstrate that narratives helped community members
relate across diverse perspectives. In the experiment, experience-grounded
narratives generated greater respect and trust than opinion-heavy narratives.
We contribute a human-AI narrative synthesis system and insights on its varied
acceptance and effectiveness in a real-world civic context.
\\ ( https://arxiv.org/abs/2509.19643 ,  1574kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19803 (*cross-listing*)
Date: Wed, 24 Sep 2025 06:38:58 GMT   (368kb)

Title: VCRL: Variance-based Curriculum Reinforcement Learning for Large
  Language Models
Authors: Guochao Jiang, Wenfeng Feng, Guofeng Quan, Chuzhan Hao, Yuewei Zhang,
  Guohua Liu, Hao Wang
Categories: cs.LG cs.CL
\\
  Policy-based reinforcement learning currently plays an important role in
improving LLMs on mathematical reasoning tasks. However, existing rollout-based
reinforcement learning methods (GRPO, DAPO, GSPO, etc.) fail to explicitly
consider LLMs' learning ability for samples of different difficulty levels,
which is contrary to the human cognitive process of mathematical reasoning
tasks from easy to difficult. Intuitively, we find that the variance of the
rollout group's reward in RLVR partly reflects the difficulty of the current
sample for LLMs. Samples that are too easy or too difficult have a lower
variance, while samples with moderate difficulty have a higher variance. Based
on this, we propose VCRL, a curriculum reinforcement learning framework that
dynamically controls the difficulty of training samples based on the variance
of group rewards. Experiments on five mathematical benchmarks and two models
reveal the advantages of VCRL over the current LLM RL baselines.
\\ ( https://arxiv.org/abs/2509.19803 ,  368kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19894 (*cross-listing*)
Date: Wed, 24 Sep 2025 08:46:29 GMT   (420kb)

Title: PromptCoT 2.0: Scaling Prompt Synthesis for Large Language Model
  Reasoning
Authors: Xueliang Zhao, Wei Wu, Jian Guan, Zhuocheng Gong, Lingpeng Kong
Categories: cs.LG cs.CL
Comments: Preprint
\\
  Large language models (LLMs) are evolving from conversational systems into
strong reasoners for tasks such as Olympiad mathematics and competitive
programming. While scaling parameters and test-time computation has driven
progress, a key bottleneck is the lack of high-quality training problems:
human-curated datasets are costly and limited, while existing synthetic corpora
are often too easy or narrow. PromptCoT 1.0 showed that injecting rationales
into prompt synthesis increases problem difficulty. Building on this, we
present PromptCoT 2.0, a scalable framework that replaces hand-crafted
heuristics with an expectation-maximization (EM) loop, where rationales are
iteratively refined to guide prompt construction. This produces problems that
are both harder and more diverse than prior corpora. The synthetic prompts
support two post-training regimes: (1) Self-Play, where strong models improve
autonomously via verifiable feedback without stronger teachers; and (2)
Supervised Fine-Tuning (SFT), where weaker models learn from teacher-distilled
traces. Extensive experiments demonstrate the effectiveness of this approach.
In self-play, applying PromptCoT 2.0 to Qwen3-30B-A3B-Thinking-2507 sets new
state-of-the-art results at the 30B scale, with +4.4, +4.8, and +5.3 on AIME
24/25 and HMMT 25, +6.1 and +5.0 on LiveCodeBench v5/v6, and +35 Elo on
Codeforces. In SFT, training Qwen2.5-7B-Instruct solely on synthetic prompts
boosts accuracy to 73.1 (AIME 24), 65.6 (AIME 25), and 53.4 (LiveCodeBench v5),
surpassing models trained on human or hybrid data. Analyses further confirm
that PromptCoT 2.0 yields fundamentally harder and distributionally distinct
problems. These results establish prompt synthesis as a new axis for scaling
reasoning and position PromptCoT 2.0 as a scalable foundation for future
open-source models. The implementation is available at
https://github.com/inclusionAI/PromptCoT.
\\ ( https://arxiv.org/abs/2509.19894 ,  420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20228 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:22:23 GMT   (2860kb)

Title: Muse-it: A Tool for Analyzing Music Discourse on Reddit
Authors: Jatin Agarwala, George Paul, Nemani Harsha Vardhan, Vinoo Alluri
Categories: cs.IR cs.CL cs.HC cs.MM cs.SI
\\
  Music engagement spans diverse interactions with music, from selection and
emotional response to its impact on behavior, identity, and social connections.
Social media platforms provide spaces where such engagement can be observed in
natural, unprompted conversations. Advances in natural language processing
(NLP) and big data analytics make it possible to analyze these discussions at
scale, extending music research to broader contexts. Reddit, in particular,
offers anonymity that encourages diverse participation and yields rich
discourse on music in ecological settings. Yet the scale of this data requires
tools to extract, process, and analyze it effectively. We present Muse-it, a
platform that retrieves comprehensive Reddit data centered on user-defined
queries. It aggregates posts from across subreddits, supports topic modeling,
temporal trend analysis, and clustering, and enables efficient study of
large-scale discourse. Muse-it also identifies music-related hyperlinks (e.g.,
Spotify), retrieves track-level metadata such as artist, album, release date,
genre, popularity, and lyrics, and links these to the discussions. An
interactive interface provides dynamic visualizations of the collected data.
Muse-it thus offers an accessible way for music researchers to gather and
analyze big data, opening new avenues for understanding music engagement as it
naturally unfolds online.
\\ ( https://arxiv.org/abs/2509.20228 ,  2860kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20265 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:52:36 GMT   (986kb)

Title: Failure Modes of Maximum Entropy RLHF
Authors: \"Omer Veysel \c{C}a\u{g}atan and Bar{\i}\c{s} Akg\"un
Categories: cs.LG cs.CL
Comments: 26 pages, 9 figures
\\
  In this paper, we show that Simple Preference Optimization (SimPO) can be
derived as Maximum Entropy Reinforcement Learning with length-normalized
temperature, providing a theoretical foundation for this reference-free method.
Motivated by SimPO's strong performance in offline preference optimization, we
investigate whether Maximum Entropy RL can achieve similar results in online
RLHF settings. Our experiments find that Maximum Entropy RL consistently
exhibits overoptimization and unstable KL dynamics, even at very low learning
rates. Unlike KL-constrained methods that maintain stable training, entropy
regularization fails to prevent reward hacking and appears to correlate with
overoptimization. Lastly, we discuss possible explanations for why SimPO
succeeds in offline settings while Maximum Entropy RL struggles in online
scenarios. Our findings suggest that reference-free approaches may face
distinct challenges when applied to online or offline preference learning.
\\ ( https://arxiv.org/abs/2509.20265 ,  986kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19353 (*cross-listing*)
Date: Thu, 18 Sep 2025 03:24:58 GMT   (857kb)

Title: Frequency-Aware Ensemble Learning for BraTS 2025 Pediatric Brain Tumor
  Segmentation
Authors: Yuxiao Yi, Qingyao Zhuang, Zhi-Qin John Xu
Categories: eess.IV cs.CV
Comments: 11 pages, 3 figures, conference, miccai brats challenge
\\
  Pediatric brain tumor segmentation presents unique challenges due to the
rarity and heterogeneity of these malignancies, yet remains critical for
clinical diagnosis and treatment planning. We propose an ensemble approach
integrating nnU-Net, Swin UNETR, and HFF-Net for the BraTS-PED 2025 challenge.
Our method incorporates three key extensions: adjustable initialization scales
for optimal nnU-Net complexity control, transfer learning from BraTS 2021
pre-trained models to enhance Swin UNETR's generalization on pediatric dataset,
and frequency domain decomposition for HFF-Net to separate low-frequency tissue
contours from high-frequency texture details. Our final ensemble combines
nnU-Net ($\gamma=0.7$), fine-tuned Swin UNETR, and HFF-Net, achieving Dice
scores of 72.3% (ET), 95.6% (NET), 68.9% (CC), 89.5% (ED), 92.3% (TC), and
92.3% (WT), respectively.
\\ ( https://arxiv.org/abs/2509.19353 ,  857kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19452 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:07:10 GMT   (17861kb)

Title: HUNT: High-Speed UAV Navigation and Tracking in Unstructured
  Environments via Instantaneous Relative Frames
Authors: Alessandro Saviolo, Jeffrey Mao, Giuseppe Loianno
Categories: cs.RO cs.CV cs.LG
\\
  Search and rescue operations require unmanned aerial vehicles to both
traverse unknown unstructured environments at high speed and track targets once
detected. Achieving both capabilities under degraded sensing and without global
localization remains an open challenge. Recent works on relative navigation
have shown robust tracking by anchoring planning and control to a visible
detected object, but cannot address navigation when no target is in the field
of view. We present HUNT (High-speed UAV Navigation and Tracking), a real-time
framework that unifies traversal, acquisition, and tracking within a single
relative formulation. HUNT defines navigation objectives directly from onboard
instantaneous observables such as attitude, altitude, and velocity, enabling
reactive high-speed flight during search. Once a target is detected, the same
perception-control pipeline transitions seamlessly to tracking. Outdoor
experiments in dense forests, container compounds, and search-and-rescue
operations with vehicles and mannequins demonstrate robust autonomy where
global methods fail.
\\ ( https://arxiv.org/abs/2509.19452 ,  17861kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19571 (*cross-listing*)
Date: Tue, 23 Sep 2025 20:56:00 GMT   (1653kb)

Title: Agentic Scene Policies: Unifying Space, Semantics, and Affordances for
  Robot Action
Authors: Sacha Morin, Kumaraditya Gupta, Mahtab Sandhu, Charlie Gauthier,
  Francesco Argenziano, Kirsty Ellis, Liam Paull
Categories: cs.RO cs.CV
Comments: Project page:
  https://montrealrobotics.ca/agentic-scene-policies.github.io/
\\
  Executing open-ended natural language queries is a core problem in robotics.
While recent advances in imitation learning and vision-language-actions models
(VLAs) have enabled promising end-to-end policies, these models struggle when
faced with complex instructions and new scenes. An alternative is to design an
explicit scene representation as a queryable interface between the robot and
the world, using query results to guide downstream motion planning. In this
work, we present Agentic Scene Policies (ASP), an agentic framework that
leverages the advanced semantic, spatial, and affordance-based querying
capabilities of modern scene representations to implement a capable
language-conditioned robot policy. ASP can execute open-vocabulary queries in a
zero-shot manner by explicitly reasoning about object affordances in the case
of more complex skills. Through extensive experiments, we compare ASP with VLAs
on tabletop manipulation problems and showcase how ASP can tackle room-level
queries through affordance-guided navigation, and a scaled-up scene
representation. (Project page:
https://montrealrobotics.ca/agentic-scene-policies.github.io/)
\\ ( https://arxiv.org/abs/2509.19571 ,  1653kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19626 (*cross-listing*)
Date: Tue, 23 Sep 2025 22:34:47 GMT   (28847kb)

Title: EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric
  Human Data
Authors: Ryan Punamiya, Dhruv Patel, Patcharapong Aphiwetsa, Pranav Kuppili,
  Lawrence Y. Zhu, Simar Kareer, Judy Hoffman, Danfei Xu
Categories: cs.RO cs.CV cs.LG
Comments: Accepted at 39th Conference on Neural Information Processing Systems
  (NeurIPS 2025) and Oral at Conference on Robot Learning (CoRL 2025)
\\
  Egocentric human experience data presents a vast resource for scaling up
end-to-end imitation learning for robotic manipulation. However, significant
domain gaps in visual appearance, sensor modalities, and kinematics between
human and robot impede knowledge transfer. This paper presents EgoBridge, a
unified co-training framework that explicitly aligns the policy latent spaces
between human and robot data using domain adaptation. Through a measure of
discrepancy on the joint policy latent features and actions based on Optimal
Transport (OT), we learn observation representations that not only align
between the human and robot domain but also preserve the action-relevant
information critical for policy learning. EgoBridge achieves a significant
absolute policy success rate improvement by 44% over human-augmented
cross-embodiment baselines in three real-world single-arm and bimanual
manipulation tasks. EgoBridge also generalizes to new objects, scenes, and
tasks seen only in human data, where baselines fail entirely. Videos and
additional information can be found at https://ego-bridge.github.io
\\ ( https://arxiv.org/abs/2509.19626 ,  28847kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19638 (*cross-listing*)
Date: Tue, 23 Sep 2025 23:05:40 GMT   (1618kb)

Title: TIMED: Adversarial and Autoregressive Refinement of Diffusion-Based Time
  Series Generation
Authors: MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali
  Boubrahimi
Categories: cs.LG cs.CV
Comments: Accepted to the IEEE International Conference on Data Mining (ICDM)
  2025
\\
  Generating high-quality synthetic time series is a fundamental yet
challenging task across domains such as forecasting and anomaly detection,
where real data can be scarce, noisy, or costly to collect. Unlike static data
generation, synthesizing time series requires modeling both the marginal
distribution of observations and the conditional temporal dependencies that
govern sequential dynamics. We propose TIMED, a unified generative framework
that integrates a denoising diffusion probabilistic model (DDPM) to capture
global structure via a forward-reverse diffusion process, a supervisor network
trained with teacher forcing to learn autoregressive dependencies through
next-step prediction, and a Wasserstein critic that provides adversarial
feedback to ensure temporal smoothness and fidelity. To further align the real
and synthetic distributions in feature space, TIMED incorporates a Maximum Mean
Discrepancy (MMD) loss, promoting both diversity and sample quality. All
components are built using masked attention architectures optimized for
sequence modeling and are trained jointly to effectively capture both
unconditional and conditional aspects of time series data. Experimental results
across diverse multivariate time series benchmarks demonstrate that TIMED
generates more realistic and temporally coherent sequences than
state-of-the-art generative models.
\\ ( https://arxiv.org/abs/2509.19638 ,  1618kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19674 (*cross-listing*)
Date: Wed, 24 Sep 2025 01:14:17 GMT   (1263kb)

Title: C${}^2$Prompt: Class-aware Client Knowledge Interaction for Federated
  Continual Learning
Authors: Kunlun Xu and Yibo Feng and Jiangmeng Li and Yongsheng Qi and Jiahuan
  Zhou
Categories: cs.LG cs.CV
Comments: Accepted by NeurIPS 2025
\\
  Federated continual learning (FCL) tackles scenarios of learning from
continuously emerging task data across distributed clients, where the key
challenge lies in addressing both temporal forgetting over time and spatial
forgetting simultaneously. Recently, prompt-based FCL methods have shown
advanced performance through task-wise prompt communication.In this study, we
underscore that the existing prompt-based FCL methods are prone to class-wise
knowledge coherence between prompts across clients. The class-wise knowledge
coherence includes two aspects: (1) intra-class distribution gap across
clients, which degrades the learned semantics across prompts, (2) inter-prompt
class-wise relevance, which highlights cross-class knowledge confusion. During
prompt communication, insufficient class-wise coherence exacerbates knowledge
conflicts among new prompts and induces interference with old prompts,
intensifying both spatial and temporal forgetting. To address these issues, we
propose a novel Class-aware Client Knowledge Interaction (C${}^2$Prompt) method
that explicitly enhances class-wise knowledge coherence during prompt
communication. Specifically, a local class distribution compensation mechanism
(LCDC) is introduced to reduce intra-class distribution disparities across
clients, thereby reinforcing intra-class knowledge consistency. Additionally, a
class-aware prompt aggregation scheme (CPA) is designed to alleviate
inter-class knowledge confusion by selectively strengthening class-relevant
knowledge aggregation. Extensive experiments on multiple FCL benchmarks
demonstrate that C${}^2$Prompt achieves state-of-the-art performance. Our
source code is available at
https://github.com/zhoujiahuan1991/NeurIPS2025-C2Prompt
\\ ( https://arxiv.org/abs/2509.19674 ,  1263kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19995 (*cross-listing*)
Date: Wed, 24 Sep 2025 11:02:03 GMT   (47060kb)

Title: MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly
Authors: Rui Xu, Tianyang Xue, Qiujie Dong, Le Wan, Zhe Zhu, Peng Li, Zhiyang
  Dou, Cheng Lin, Shiqing Xin, Yuan Liu, Wenping Wang, Taku Komura
Categories: cs.GR cs.CG cs.CV
Comments: Project is available at:
  https://xrvitd.github.io/MeshMosaic/index.html
\\
  Scaling artist-designed meshes to high triangle numbers remains challenging
for autoregressive generative models. Existing transformer-based methods suffer
from long-sequence bottlenecks and limited quantization resolution, primarily
due to the large number of tokens required and constrained quantization
granularity. These issues prevent faithful reproduction of fine geometric
details and structured density patterns. We introduce MeshMosaic, a novel
local-to-global framework for artist mesh generation that scales to over 100K
triangles--substantially surpassing prior methods, which typically handle only
around 8K faces. MeshMosaic first segments shapes into patches, generating each
patch autoregressively and leveraging shared boundary conditions to promote
coherence, symmetry, and seamless connectivity between neighboring regions.
This strategy enhances scalability to high-resolution meshes by quantizing
patches individually, resulting in more symmetrical and organized mesh density
and structure. Extensive experiments across multiple public datasets
demonstrate that MeshMosaic significantly outperforms state-of-the-art methods
in both geometric fidelity and user preference, supporting superior detail
representation and practical mesh generation for real-world applications.
\\ ( https://arxiv.org/abs/2509.19995 ,  47060kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19999 (*cross-listing*)
Date: Wed, 24 Sep 2025 11:04:34 GMT   (2615kb)

Title: MultiSoundGen: Video-to-Audio Generation for Multi-Event Scenarios via
  SlowFast Contrastive Audio-Visual Pretraining and Direct Preference
  Optimization
Authors: Jianxuan Yang, Xiaoran Yang, Lipan Zhang, Xinyue Guo, Zhao Wang,
  Gongping Huang
Categories: cs.MM cs.CV cs.SD
\\
  Current video-to-audio (V2A) methods struggle in complex multi-event
scenarios (video scenarios involving multiple sound sources, sound events, or
transitions) due to two critical limitations. First, existing methods face
challenges in precisely aligning intricate semantic information together with
rapid dynamic features. Second, foundational training lacks quantitative
preference optimization for semantic-temporal alignment and audio quality. As a
result, it fails to enhance integrated generation quality in cluttered
multi-event scenes. To address these core limitations, this study proposes a
novel V2A framework: MultiSoundGen. It introduces direct preference
optimization (DPO) into the V2A domain, leveraging audio-visual pretraining
(AVP) to enhance performance in complex multi-event scenarios. Our
contributions include two key innovations: the first is SlowFast Contrastive
AVP (SF-CAVP), a pioneering AVP model with a unified dual-stream architecture.
SF-CAVP explicitly aligns core semantic representations and rapid dynamic
features of audio-visual data to handle multi-event complexity; second, we
integrate the DPO method into V2A task and propose AVP-Ranked Preference
Optimization (AVP-RPO). It uses SF-CAVP as a reward model to quantify and
prioritize critical semantic-temporal matches while enhancing audio quality.
Experiments demonstrate that MultiSoundGen achieves state-of-the-art (SOTA)
performance in multi-event scenarios, delivering comprehensive gains across
distribution matching, audio quality, semantic alignment, and temporal
synchronization. The complete code and dataset will be released soon.
\\ ( https://arxiv.org/abs/2509.19999 ,  2615kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20001 (*cross-listing*)
Date: Wed, 24 Sep 2025 11:17:25 GMT   (1076kb)

Title: Ensuring Reliable Participation in Subjective Video Quality Tests Across
  Platforms
Authors: Babak Naderi, Ross Cutler
Categories: eess.IV cs.CV cs.MM
\\
  Subjective video quality assessment (VQA) is the gold standard for measuring
end-user experience across communication, streaming, and UGC pipelines. Beyond
high-validity lab studies, crowdsourcing offers accurate, reliable, faster, and
cheaper evaluation-but suffers from unreliable submissions by workers who
ignore instructions or game rewards. Recent tests reveal sophisticated exploits
of video metadata and rising use of remote-desktop (RD) connections, both of
which bias results. We propose objective and subjective detectors for RD users
and compare two mainstream crowdsourcing platforms on their susceptibility and
mitigation under realistic test conditions and task designs.
\\ ( https://arxiv.org/abs/2509.20001 ,  1076kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20077 (*cross-listing*)
Date: Wed, 24 Sep 2025 12:53:32 GMT   (30308kb)

Title: Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic
  Reasoning and Robotic Task Planning
Authors: Xun Li, Rodrigo Santa Cruz, Mingze Xi, Hu Zhang, Madhawa Perera, Ziwei
  Wang, Ahalya Ravendran, Brandon J. Matthews, Feng Xu, Matt Adcock, Dadong
  Wang, Jiajun Liu
Categories: cs.RO cs.CV cs.HC
\\
  To enable robots to comprehend high-level human instructions and perform
complex tasks, a key challenge lies in achieving comprehensive scene
understanding: interpreting and interacting with the 3D environment in a
meaningful way. This requires a smart map that fuses accurate geometric
structure with rich, human-understandable semantics. To address this, we
introduce the 3D Queryable Scene Representation (3D QSR), a novel framework
built on multimedia data that unifies three complementary 3D representations:
(1) 3D-consistent novel view rendering and segmentation from panoptic
reconstruction, (2) precise geometry from 3D point clouds, and (3) structured,
scalable organization via 3D scene graphs. Built on an object-centric design,
the framework integrates with large vision-language models to enable semantic
queryability by linking multimodal object embeddings, and supporting
object-level retrieval of geometric, visual, and semantic information. The
retrieved data are then loaded into a robotic task planner for downstream
execution. We evaluate our approach through simulated robotic task planning
scenarios in Unity, guided by abstract language instructions and using the
indoor public dataset Replica. Furthermore, we apply it in a digital duplicate
of a real wet lab environment to test QSR-supported robotic task planning for
emergency response. The results demonstrate the framework's ability to
facilitate scene understanding and integrate spatial and semantic reasoning,
effectively translating high-level human instructions into precise robotic task
planning in complex 3D environments.
\\ ( https://arxiv.org/abs/2509.20077 ,  30308kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20269 (*cross-listing*)
Date: Wed, 24 Sep 2025 16:03:27 GMT   (124kb)

Title: Predictive Coding-based Deep Neural Network Fine-tuning for
  Computationally Efficient Domain Adaptation
Authors: Matteo Cardoni, Sam Leroux
Categories: cs.LG cs.CV cs.NE
Comments: 20 pages, 4 figures
\\
  As deep neural networks are increasingly deployed in dynamic, real-world
environments, relying on a single static model is often insufficient. Changes
in input data distributions caused by sensor drift or lighting variations
necessitate continual model adaptation. In this paper, we propose a hybrid
training methodology that enables efficient on-device domain adaptation by
combining the strengths of Backpropagation and Predictive Coding. The method
begins with a deep neural network trained offline using Backpropagation to
achieve high initial performance. Subsequently, Predictive Coding is employed
for online adaptation, allowing the model to recover accuracy lost due to
shifts in the input data distribution. This approach leverages the robustness
of Backpropagation for initial representation learning and the computational
efficiency of Predictive Coding for continual learning, making it particularly
well-suited for resource-constrained edge devices or future neuromorphic
accelerators. Experimental results on the MNIST and CIFAR-10 datasets
demonstrate that this hybrid strategy enables effective adaptation with a
reduced computational overhead, offering a promising solution for maintaining
model performance in dynamic environments.
\\ ( https://arxiv.org/abs/2509.20269 ,  124kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20322 (*cross-listing*)
Date: Wed, 24 Sep 2025 17:10:02 GMT   (13808kb)

Title: VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and
  Generation
Authors: Shaofeng Yin, Yanjie Ze, Hong-Xing Yu, C. Karen Liu, Jiajun Wu
Categories: cs.RO cs.CV cs.LG
Comments: Website: https://visualmimic.github.io
\\
  Humanoid loco-manipulation in unstructured environments demands tight
integration of egocentric perception and whole-body control. However, existing
approaches either depend on external motion capture systems or fail to
generalize across diverse tasks. We introduce VisualMimic, a visual sim-to-real
framework that unifies egocentric vision with hierarchical whole-body control
for humanoid robots. VisualMimic combines a task-agnostic low-level keypoint
tracker -- trained from human motion data via a teacher-student scheme -- with
a task-specific high-level policy that generates keypoint commands from visual
and proprioceptive input. To ensure stable training, we inject noise into the
low-level policy and clip high-level actions using human motion statistics.
VisualMimic enables zero-shot transfer of visuomotor policies trained in
simulation to real humanoid robots, accomplishing a wide range of
loco-manipulation tasks such as box lifting, pushing, football dribbling, and
kicking. Beyond controlled laboratory settings, our policies also generalize
robustly to outdoor environments. Videos are available at:
https://visualmimic.github.io .
\\ ( https://arxiv.org/abs/2509.20322 ,  13808kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19486 (*cross-listing*)
Date: Tue, 23 Sep 2025 18:48:56 GMT   (309kb)

Title: Supercomputing for High-speed Avoidance and Reactive Planning in Robots
Authors: Kieran S. Lachmansingh, Jos\'e R. Gonz\'alez-Estrada, Ryan E. Grant,
  Matthew K. X. J. Pan
Categories: cs.RO cs.DC
Comments: 8 pages, 3 figures
\\
  This paper presents SHARP (Supercomputing for High-speed Avoidance and
Reactive Planning), a proof-of-concept study demonstrating how high-performance
computing (HPC) can enable millisecond-scale responsiveness in robotic control.
While modern robots face increasing demands for reactivity in human--robot
shared workspaces, onboard processors are constrained by size, power, and cost.
Offloading to HPC offers massive parallelism for trajectory planning, but its
feasibility for real-time robotics remains uncertain due to network latency and
jitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator
must dodge high-speed foam projectiles. Using a parallelized multi-goal A*
search implemented with MPI on both local and remote HPC clusters, the system
achieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300
km away), with avoidance success rates of 84% and 88%, respectively. These
results show that when round-trip latency remains within the
tens-of-milliseconds regime, HPC-side computation is no longer the bottleneck,
enabling avoidance well below human reaction times. The SHARP results motivate
hybrid control architectures: low-level reflexes remain onboard for safety,
while bursty, high-throughput planning tasks are offloaded to HPC for
scalability. By reporting per-stage timing and success rates, this study
provides a reproducible template for assessing real-time feasibility of
HPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable
pathway toward dependable, reactive robots in dynamic environments.
\\ ( https://arxiv.org/abs/2509.19486 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20241 (*cross-listing*)
Date: Wed, 24 Sep 2025 15:32:01 GMT   (1918kb)

Title: Energy Use of AI Inference: Efficiency Pathways and Test-Time Compute
Authors: Felipe Oviedo, Fiodar Kazhamiaka, Esha Choukse, Allen Kim, Amy Luers,
  Melanie Nakagawa, Ricardo Bianchini, Juan M. Lavista Ferres
Categories: cs.LG cs.DC
Comments: A preprint version with DOI is available at Zenodo:
  https://doi.org/10.5281/zenodo.17188770
\\
  As AI inference scales to billions of queries and emerging reasoning and
agentic workflows increase token demand, reliable estimates of per-query energy
use are increasingly important for capacity planning, emissions accounting, and
efficiency prioritization. Many public estimates are inconsistent and overstate
energy use, because they extrapolate from limited benchmarks and fail to
reflect efficiency gains achievable at scale. In this perspective, we introduce
a bottom-up methodology to estimate the per-query energy of large-scale LLM
systems based on token throughput. For models running on an H100 node under
realistic workloads, GPU utilization and PUE constraints, we estimate a median
energy per query of 0.34 Wh (IQR: 0.18-0.67) for frontier-scale models (>200
billion parameters). These results are consistent with measurements using
production-scale configurations and show that non-production estimates and
assumptions can overstate energy use by 4-20x. Extending to test-time scaling
scenarios with 15x more tokens per typical query, the median energy rises 13x
to 4.32 Wh, indicating that targeting efficiency in this regime will deliver
the largest fleet-wide savings. We quantify achievable efficiency gains at the
model, serving platform, and hardware levels, finding individual median
reductions of 1.5-3.5x in energy per query, while combined advances can
plausibly deliver 8-20x reductions. To illustrate the system-level impact, we
estimate the baseline daily energy use of a deployment serving 1 billion
queries to be 0.8 GWh/day. If 10% are long queries, demand could grow to 1.8
GWh/day. With targeted efficiency interventions, it falls to 0.9 GWh/day,
similar to the energy footprint of web search at that scale. This echoes how
data centers historically tempered energy growth through efficiency gains
during the internet and cloud build-up.
\\ ( https://arxiv.org/abs/2509.20241 ,  1918kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14295 (*cross-listing*)
Date: Wed, 17 Sep 2025 02:31:03 GMT   (4912kb)
Date (revised v2): Mon, 22 Sep 2025 06:46:39 GMT   (5807kb)

Title: AEGIS: Automated Error Generation and Identification for Multi-Agent
  Systems
Authors: Fanqi Kong, Ruijie Zhang, Huaxiao Yin, Guibin Zhang, Xiaofei Zhang,
  Ziang Chen, Zhaowei Zhang, Xiaoyuan Zhang, Song-Chun Zhu, and Xue Feng
Categories: cs.RO cs.MA
\\
  As Multi-Agent Systems (MAS) become increasingly autonomous and complex,
understanding their error modes is critical for ensuring their reliability and
safety. However, research in this area has been severely hampered by the lack
of large-scale, diverse datasets with precise, ground-truth error labels. To
address this bottleneck, we introduce \textbf{AEGIS}, a novel framework for
\textbf{A}utomated \textbf{E}rror \textbf{G}eneration and
\textbf{I}dentification for Multi-Agent \textbf{S}ystems. By systematically
injecting controllable and traceable errors into initially successful
trajectories, we create a rich dataset of realistic failures. This is achieved
using a context-aware, LLM-based adaptive manipulator that performs
sophisticated attacks like prompt injection and response corruption to induce
specific, predefined error modes. We demonstrate the value of our dataset by
exploring three distinct learning paradigms for the error identification task:
Supervised Fine-Tuning, Reinforcement Learning, and Contrastive Learning. Our
comprehensive experiments show that models trained on AEGIS data achieve
substantial improvements across all three learning paradigms. Notably, several
of our fine-tuned models demonstrate performance competitive with or superior
to proprietary systems an order of magnitude larger, validating our automated
data generation framework as a crucial resource for developing more robust and
interpretable multi-agent systems. Our project website is available at
https://kfq20.github.io/AEGIS-Website.
\\ ( https://arxiv.org/abs/2509.14295 ,  5807kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20147 (*cross-listing*)
Date: Wed, 24 Sep 2025 14:11:51 GMT   (559kb)

Title: Choose Your Battles: Distributed Learning Over Multiple Tug of War Games
Authors: Siddharth Chandak, Ilai Bistritz, Nicholas Bambos
Categories: cs.GT cs.LG cs.MA cs.SY eess.SY
Comments: Submitted to IEEE TAC
\\
  Consider N players and K games taking place simultaneously. Each of these
games is modeled as a Tug-of-War (ToW) game where increasing the action of one
player decreases the reward for all other players. Each player participates in
only one game at any given time. At each time step, a player decides the game
in which they wish to participate in and the action they take in that game.
Their reward depends on the actions of all players that are in the same game.
This system of K games is termed `Meta Tug-of-War' (Meta-ToW) game. These games
can model scenarios such as power control, distributed task allocation, and
activation in sensor networks. We propose the Meta Tug-of-Peace algorithm, a
distributed algorithm where the action updates are done using a simple
stochastic approximation algorithm, and the decision to switch games is made
using an infrequent 1-bit communication between the players. We prove that in
Meta-ToW games, our algorithm converges to an equilibrium that satisfies a
target Quality of Service reward vector for the players. We then demonstrate
the efficacy of our algorithm through simulations for the scenarios mentioned
above.
\\ ( https://arxiv.org/abs/2509.20147 ,  559kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20314 (*cross-listing*)
Date: Wed, 24 Sep 2025 16:51:24 GMT   (1552kb)

Title: On Robustness of Consensus over Pseudo-Undirected Path Graphs
Authors: Abhinav Sinha, Dwaipayan Mukherjee, and Shashi Ranjan Kumar
Categories: eess.SY cs.MA cs.RO cs.SY math.DS math.OC
\\
  Consensus over networked agents is typically studied using undirected or
directed communication graphs. Undirected graphs enforce symmetry in
information exchange, leading to convergence to the average of initial states,
while directed graphs permit asymmetry but make consensus dependent on root
nodes and their influence. Both paradigms impose inherent restrictions on
achievable consensus values and network robustness. This paper introduces a
theoretical framework for achieving consensus over a class of network
topologies, termed pseudo-undirected graphs, which retains bidirectional
connectivity between node pairs but allows the corresponding edge weights to
differ, including the possibility of negative values under bounded conditions.
The resulting Laplacian is generally non-symmetric, yet it guarantees consensus
under connectivity assumptions, to expand the solution space, which enables the
system to achieve a stable consensus value that can lie outside the convex hull
of the initial state set. We derive admissibility bounds for negative weights
for a pseudo-undirected path graph, and show an application in the simultaneous
interception of a moving target.
\\ ( https://arxiv.org/abs/2509.20314 ,  1552kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2407.01476
replaced with revised version Wed, 24 Sep 2025 05:46:23 GMT   (2501kb)

Title: Tree Search for Language Model Agents
Authors: Jing Yu Koh, Stephen McAleer, Daniel Fried, Ruslan Salakhutdinov
Categories: cs.AI cs.CL cs.LG
Comments: 13 pages. Models and code available at
  https://jykoh.com/search-agents
\\ ( https://arxiv.org/abs/2407.01476 ,  2501kb)
------------------------------------------------------------------------------
\\
arXiv:2407.02425
replaced with revised version Wed, 24 Sep 2025 12:44:47 GMT   (225kb)

Title: Reinforcement Learning and Machine ethics:a systematic review
Authors: Ajay Vishwanath and Louise A. Dennis and Marija Slavkovik
Categories: cs.AI
\\ ( https://arxiv.org/abs/2407.02425 ,  225kb)
------------------------------------------------------------------------------
\\
arXiv:2411.04578
replaced with revised version Wed, 24 Sep 2025 11:34:53 GMT   (8567kb)

Title: Multi-Agents are Social Groups: Investigating Social Influence of
  Multiple Agents in Human-Agent Interactions
Authors: Tianqi Song, Yugin Tan, Zicheng Zhu, Yibin Feng, Yi-Chieh Lee
Categories: cs.AI cs.HC
\\ ( https://arxiv.org/abs/2411.04578 ,  8567kb)
------------------------------------------------------------------------------
\\
arXiv:2501.10017
replaced with revised version Wed, 24 Sep 2025 07:54:44 GMT   (2251kb)

Title: Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by
  Hybrid VAE-Diffusion-Based Generative Neural Networks
Authors: Junlan Chen, Qijie He, Pei Liu, Wei Ma, Ziyuan Pu, Nan Zheng
Categories: cs.AI cs.DB
\\ ( https://arxiv.org/abs/2501.10017 ,  2251kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11959
replaced with revised version Wed, 24 Sep 2025 04:12:41 GMT   (259kb)

Title: STRIVE: Structured Reasoning for Self-Improvement in Claim Verification
Authors: Haisong Gong, Jing Li, Junfei Wu, Qiang Liu, Shu Wu, Liang Wang
Categories: cs.AI
Comments: Accepted by Machine Intelligence Research (MIR)
DOI: 10.1007/s11633-025-1598-5
\\ ( https://arxiv.org/abs/2502.11959 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19546
replaced with revised version Tue, 23 Sep 2025 21:03:10 GMT   (7744kb)

Title: CNS-Obsidian: A Neurosurgical Vision-Language Model Built From
  Scientific Publications
Authors: Anton Alyakin, Jaden Stryker, Daniel Alexander Alber, Karl L. Sangwon,
  Jin Vivian Lee, Brandon Duderstadt, Akshay Save, David Kurland, Spencer
  Frome, Shrutika Singh, Jeff Zhang, Eunice Yang, Ki Yun Park, Cordelia
  Orillac, Aly A. Valliani, Sean Neifert, Albert Liu, Aneek Patel, Christopher
  Livia, Darryl Lau, Ilya Laufer, Peter A. Rozman, Eveline Teresa Hidalgo,
  Howard Riina, Rui Feng, Todd Hollon, Yindalon Aphinyanaphongs, John G.
  Golfinos, Laura Snyder, Eric Leuthardt, Douglas Kondziolka, Eric Karl Oermann
Categories: cs.AI cs.CL cs.HC
\\ ( https://arxiv.org/abs/2502.19546 ,  7744kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02403
replaced with revised version Wed, 24 Sep 2025 05:11:34 GMT   (3971kb)

Title: AutoEval: A Practical Framework for Autonomous Evaluation of Mobile
  Agents
Authors: Jiahui Sun, Zhichao Hua and Yubin Xia
Categories: cs.AI
\\ ( https://arxiv.org/abs/2503.02403 ,  3971kb)
------------------------------------------------------------------------------
\\
arXiv:2503.08275
replaced with revised version Wed, 24 Sep 2025 02:56:18 GMT   (494kb)

Title: Beyond Outlining: Heterogeneous Recursive Planning for Adaptive
  Long-form Writing with Language Models
Authors: Ruibin Xiong, Yimeng Chen, Dmitrii Khizbullin, Mingchen Zhuge,
  J\"urgen Schmidhuber
Categories: cs.AI cs.CL
Comments: 37 pages, 3 figures
\\ ( https://arxiv.org/abs/2503.08275 ,  494kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09447
replaced with revised version Wed, 24 Sep 2025 02:17:15 GMT   (23645kb)

Title: Online Language Splatting
Authors: Saimouli Katragadda, Cho-Ying Wu, Yuliang Guo, Xinyu Huang, Guoquan
  Huang, Liu Ren
Categories: cs.AI cs.CV cs.RO
\\ ( https://arxiv.org/abs/2503.09447 ,  23645kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23326
replaced with revised version Wed, 24 Sep 2025 14:08:00 GMT   (17622kb)

Title: Exploring Explainable Multi-agent MCTS-minimax Hybrids in Board Game
  Using Process Mining
Authors: Yiyu Qian, Tim Miller, Zheng Qian, Liyuan Zhao
Categories: cs.AI
Comments: 38 pages, AAAI 2025 PRL
\\ ( https://arxiv.org/abs/2503.23326 ,  17622kb)
------------------------------------------------------------------------------
\\
arXiv:2505.02003
replaced with revised version Wed, 24 Sep 2025 10:08:10 GMT   (2481kb)

Title: Closed-loop control of seizure activity via real-time seizure
  forecasting by reservoir neuromorphic computing
Authors: Maryam Sadeghi, Dar\'io Fern\'andez Khatiboun, Yasser Rezaeiyan, Saima
  Rizwan, Alessandro Barcellona, Andrea Merello, Marco Crepaldi, Gabriella
  Panuccio and Farshad Moradi
Categories: cs.AI cs.ET cs.HC
\\ ( https://arxiv.org/abs/2505.02003 ,  2481kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18961
replaced with revised version Tue, 23 Sep 2025 18:02:45 GMT   (9666kb)

Title: Weaver: Interweaving SQL and LLM for Table Reasoning
Authors: Rohit Khoja, Devanshu Gupta, Yanjie Fu, Dan Roth, Vivek Gupta
Categories: cs.AI cs.IR
\\ ( https://arxiv.org/abs/2505.18961 ,  9666kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20306
replaced with revised version Wed, 24 Sep 2025 11:44:12 GMT   (1479kb)

Title: Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy
  Prediction in Assisted Reproductive Technology: A Review
Authors: Xueqiang Ouyang and Jia Wei
Categories: cs.AI eess.IV q-bio.QM
\\ ( https://arxiv.org/abs/2505.20306 ,  1479kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23436
replaced with revised version Wed, 24 Sep 2025 13:44:56 GMT   (346kb)

Title: Emergent Risk Awareness in Rational Agents under Resource Constraints
Authors: Daniel Jarne Ornia, Nicholas Bishop, Joel Dyer, Wei-Chen Lee, Ani
  Calinescu, Doyne Farmer, Michael Wooldridge
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.23436 ,  346kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21976
replaced with revised version Tue, 23 Sep 2025 19:50:14 GMT   (9874kb)

Title: Compression Strategies for Efficient Multimodal LLMs in Medical Contexts
Authors: Tanvir A. Khan, Aranya Saha, Ismam N. Swapnil and Mohammad A. Haque
Categories: cs.AI
Comments: 16 pages, 7 figures
\\ ( https://arxiv.org/abs/2507.21976 ,  9874kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15690
replaced with revised version Tue, 23 Sep 2025 18:41:49 GMT   (5402kb)

Title: GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark
  for Structured Instruction Following and Visual Reasoning
Authors: Abhigya Verma, Sriram Puttagunta, Seganrasan Subramanian, Sravan
  Ramachandran
Categories: cs.AI cs.LG cs.MM
Comments: 23 pages, 9 tables, 3 figures
\\ ( https://arxiv.org/abs/2508.15690 ,  5402kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02761
replaced with revised version Wed, 24 Sep 2025 03:01:43 GMT   (926kb)

Title: Plan Verification for LLM-Based Embodied Task Completion Agents
Authors: Ananth Hariharan, Vardhan Dongre, Dilek Hakkani-T\"ur, Gokhan Tur
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.02761 ,  926kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17318
replaced with revised version Wed, 24 Sep 2025 07:23:31 GMT   (3532kb)

Title: CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning
  in Large Language Models
Authors: Zhuofan Chen, Jiyuan He, Yichi Zhang, Xing Hu, Haoxing Wen, Jun Bai,
  Wenge Rong
Categories: cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.17318 ,  3532kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18218
replaced with revised version Wed, 24 Sep 2025 07:52:27 GMT   (31kb)

Title: Similarity Field Theory: A General Mathematical Framework for
  Intelligence
Authors: Kei-Sing Ng
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.18218 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18849
replaced with revised version Wed, 24 Sep 2025 03:41:49 GMT   (4106kb)

Title: MAPO: Mixed Advantage Policy Optimization
Authors: Wenke Huang and Quan Zhang and Yiyang Fang and Jian Liang and Xuankun
  Rong and Huanjin Yao and Guancheng Wan and Ke Liang and Wenwen He and Mingjun
  Li and Leszek Rutkowski and Mang Ye and Bo Du and Dacheng Tao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.18849 ,  4106kb)
------------------------------------------------------------------------------
\\
arXiv:2407.10999
replaced with revised version Wed, 24 Sep 2025 05:33:59 GMT   (2796kb)

Title: TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house
  Criteria by Criteria Division and Zero-shot Plus Few-shot
Authors: Kaiqi Zhang, Shuai Yuan, Honghan Zhao
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2407.10999 ,  2796kb)
------------------------------------------------------------------------------
\\
arXiv:2407.18920
replaced with revised version Wed, 24 Sep 2025 15:30:03 GMT   (1090kb)

Title: Context-Masked Meta-Prompting for Privacy-Preserving LLM Adaptation in
  Finance
Authors: Sayash Raaj Hiraou
Categories: cs.CL
\\ ( https://arxiv.org/abs/2407.18920 ,  1090kb)
------------------------------------------------------------------------------
\\
arXiv:2409.09324
replaced with revised version Wed, 24 Sep 2025 16:59:19 GMT   (477kb)

Title: Efficient Fine-Tuning of Large Language Models for Automated Medical
  Documentation
Authors: Hui Yi Leong, Yi Fan Gao, Ji Shuai, Yang Zhang, Uktu Pamuksuz
Categories: cs.CL cs.AI
Comments: 4 pages, 3 Figures, 3 Tables. The final version will be published in
  the proceedings of the IEEE conference
DOI: 10.13140/RG.2.2.26884.74881
\\ ( https://arxiv.org/abs/2409.09324 ,  477kb)
------------------------------------------------------------------------------
\\
arXiv:2409.18708
replaced with revised version Wed, 24 Sep 2025 08:50:44 GMT   (98kb)

Title: Evading Toxicity Detection with ASCII-art: A Benchmark of Spatial
  Attacks on Moderation Systems
Authors: Sergey Berezin, Reza Farahbakhsh, Noel Crespi
Categories: cs.CL cs.AI cs.CR
Journal-ref: https://aclanthology.org/2025.woah-1.13/
\\ ( https://arxiv.org/abs/2409.18708 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:2410.03090
replaced with revised version Wed, 24 Sep 2025 16:56:17 GMT   (1035kb)

Title: UNComp: Can Matrix Entropy Uncover Sparsity? -- A Compressor Design from
  an Uncertainty-Aware Perspective
Authors: Jing Xiong, Jianghan Shen, Fanghua Ye, Chaofan Tao, Zhongwei Wan,
  Jianqiao Lu, Xun Wu, Chuanyang Zheng, Zhijiang Guo, Min Yang, Lingpeng Kong,
  Ngai Wong
Categories: cs.CL cs.LG
Comments: Accepted at EMNLP 2025 (Main Conference)
\\ ( https://arxiv.org/abs/2410.03090 ,  1035kb)
------------------------------------------------------------------------------
\\
arXiv:2501.01168
replaced with revised version Wed, 24 Sep 2025 10:03:47 GMT   (129kb)

Title: Blind Men and the Elephant: Diverse Perspectives on Gender Stereotypes
  in Benchmark Datasets
Authors: Mahdi Zakizadeh and Mohammad Taher Pilehvar
Categories: cs.CL cs.AI
Comments: Accepted at EMNLP 2025
\\ ( https://arxiv.org/abs/2501.01168 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2501.04341
replaced with revised version Wed, 24 Sep 2025 12:56:29 GMT   (314kb)

Title: Understanding Before Reasoning: Enhancing Chain-of-Thought with
  Iterative Summarization Pre-Prompting
Authors: Dong-Hai Zhu, Yu-Jie Xiong, Jia-Chen Zhang, Xi-Jiong Xie and Chun-Ming
  Xia
Categories: cs.CL
\\ ( https://arxiv.org/abs/2501.04341 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2501.05926
replaced with revised version Wed, 24 Sep 2025 14:58:32 GMT   (600kb)

Title: LLMs Reproduce Stereotypes of Sexual and Gender Minorities
Authors: Ruby Ostrow and Adam Lopez
Categories: cs.CL
Comments: 13 pages, 5 figures, 9 tables (including bibliography and appendix).
  Accepted to Findings of EMNLP 2025
\\ ( https://arxiv.org/abs/2501.05926 ,  600kb)
------------------------------------------------------------------------------
\\
arXiv:2501.10836
replaced with revised version Tue, 23 Sep 2025 18:50:56 GMT   (6089kb)

Title: BAP v2: An Enhanced Task Framework for Instruction Following in
  Minecraft Dialogues
Authors: Prashant Jayannavar, Liliang Ren, Marisa Hudspeth, Risham Sidhu,
  Charlotte Lambert, Ariel Cordes, Elizabeth Kaplan, Anjali Narayan-Chen, Julia
  Hockenmaier
Categories: cs.CL cs.AI
Comments: major revision; few examples of changes: added contemporary LLMs and
  new SOTA model, improved readability, expanded related work, etc
\\ ( https://arxiv.org/abs/2501.10836 ,  6089kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11856
replaced with revised version Wed, 24 Sep 2025 11:06:37 GMT   (1023kb)

Title: LLMs as a synthesis between symbolic and distributed approaches to
  language
Authors: Gemma Boleda
Categories: cs.CL
Comments: Final version to appear in Findings of the ACL (significantly revised
  wrt v1). 15 pages, 4 figures
\\ ( https://arxiv.org/abs/2502.11856 ,  1023kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14359
replaced with revised version Wed, 24 Sep 2025 12:04:54 GMT   (2025kb)

Title: Triangulating LLM Progress through Benchmarks, Games, and Cognitive
  Tests
Authors: Filippo Moment\`e, Alessandro Suglia, Mario Giulianelli, Ambra
  Ferrari, Alexander Koller, Oliver Lemon, David Schlangen, Raquel Fern\'andez,
  Raffaella Bernardi
Categories: cs.CL
Comments: Accepted at EMNLP 2025 (Findings)
\\ ( https://arxiv.org/abs/2502.14359 ,  2025kb)
------------------------------------------------------------------------------
\\
arXiv:2502.17715
replaced with revised version Tue, 23 Sep 2025 23:47:37 GMT   (1290kb)

Title: Bridging Information Gaps with Comprehensive Answers: Improving the
  Diversity and Informativeness of Follow-Up Questions
Authors: Zhe Liu, Taekyu Kang, Haoyu Wang, Seyed Hossein Alavi, Vered Shwartz
Categories: cs.CL cs.AI cs.HC
Comments: 9 pages, 3 figures, 8 tables, submitted to StarSEM 2025
\\ ( https://arxiv.org/abs/2502.17715 ,  1290kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18583
replaced with revised version Tue, 23 Sep 2025 18:05:55 GMT   (10203kb)

Title: What are Foundation Models Cooking in the Post-Soviet World?
Authors: Anton Lavrouk, Tarek Naous, Alan Ritter, Wei Xu
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2502.18583 ,  10203kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18993
replaced with revised version Wed, 24 Sep 2025 09:28:43 GMT   (2706kb)

Title: MEBench: Benchmarking Large Language Models for Cross-Document
  Multi-Entity Question Answering
Authors: Teng Lin, Yuyu Luo, Honglin Zhang, Jicheng Zhang, Chunlin Liu, Kaishun
  Wu, Nan Tang
Categories: cs.CL cs.DB
Comments: EMNLP2025 Main
\\ ( https://arxiv.org/abs/2502.18993 ,  2706kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02003
replaced with revised version Wed, 24 Sep 2025 14:26:13 GMT   (1933kb)

Title: HoT: Highlighted Chain of Thought for Referencing Supporting Facts from
  Inputs
Authors: Tin Nguyen, Logan Bolton, Mohammad Reza Taesiri, Trung Bui, Anh Totti
  Nguyen
Categories: cs.CL cs.HC
\\ ( https://arxiv.org/abs/2503.02003 ,  1933kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02737
replaced with revised version Wed, 24 Sep 2025 06:17:32 GMT   (1820kb)

Title: Large Language Models for Multilingual Previously Fact-Checked Claim
  Detection
Authors: Ivan Vykopal, Mat\'u\v{s} Pikuliak, Simon Ostermann, Tatiana Anikina,
  Michal Gregor, Mari\'an \v{S}imko
Categories: cs.CL
Comments: Accepted for the EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2503.02737 ,  1820kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07513
replaced with revised version Tue, 23 Sep 2025 18:42:02 GMT   (5377kb)

Title: Language Models Fail to Introspect About Their Knowledge of Language
Authors: Siyuan Song, Jennifer Hu, Kyle Mahowald
Categories: cs.CL cs.AI
Comments: 23 pages, 10 figures, COLM 2025 camera ready
\\ ( https://arxiv.org/abs/2503.07513 ,  5377kb)
------------------------------------------------------------------------------
\\
arXiv:2503.11381
replaced with revised version Tue, 23 Sep 2025 21:25:17 GMT   (4022kb)

Title: Modeling Subjectivity in Cognitive Appraisal with Language Models
Authors: Yuxiang Zhou, Hainiu Xu, Desmond C. Ong, Maria Liakata, Petr Slovak,
  Yulan He
Categories: cs.CL
Comments: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2503.11381 ,  4022kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13390
replaced with revised version Tue, 23 Sep 2025 19:15:23 GMT   (9604kb)

Title: Aligned Probing: Relating Toxic Behavior and Model Internals
Authors: Andreas Waldis, Vagrant Gautam, Anne Lauscher, Dietrich Klakow, Iryna
  Gurevych
Categories: cs.CL
\\ ( https://arxiv.org/abs/2503.13390 ,  9604kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14411
replaced with revised version Wed, 24 Sep 2025 02:41:11 GMT   (2755kb)

Title: Unifying Text Semantics and Graph Structures for Temporal
  Text-attributed Graphs with Large Language Models
Authors: Siwei Zhang, Yun Xiong, Yateng Tang, Jiarong Xu, Xi Chen, Zehao Gu,
  Xuezheng Hao, Zian Jia, Jiawei Zhang
Categories: cs.CL cs.AI
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2503.14411 ,  2755kb)
------------------------------------------------------------------------------
\\
arXiv:2503.18991
replaced with revised version Wed, 24 Sep 2025 14:11:50 GMT   (1862kb)

Title: Inverse Reinforcement Learning with Dynamic Reward Scaling for LLM
  Alignment
Authors: Ruoxi Cheng, Haoxuan Ma, Weixin Wang, Ranjie Duan, Jiexi Liu,
  Xiaoshuang Jia, Simeng Qin, Xiaochun Cao, Yang Liu, Xiaojun Jia
Categories: cs.CL cs.AI cs.LG
Comments: The first three authors contributed equally to this work
\\ ( https://arxiv.org/abs/2503.18991 ,  1862kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08590
replaced with revised version Wed, 24 Sep 2025 12:06:14 GMT   (382kb)

Title: Playpen: An Environment for Exploring Learning Through Conversational
  Interaction
Authors: Nicola Horst, Davide Mazzaccara, Antonia Schmidt, Michael Sullivan,
  Filippo Moment\`e, Luca Franceschetti, Philipp Sadler, Sherzod Hakimov,
  Alberto Testoni, Raffaella Bernardi, Raquel Fern\'andez, Alexander Koller,
  Oliver Lemon, David Schlangen, Mario Giulianelli, Alessandro Suglia
Categories: cs.CL
Comments: Accepted at EMNLP 2025 (Main) Source code:
  https://github.com/lm-playpen/playpen Please send correspodence to:
  lm-playschool@googlegroups.com
\\ ( https://arxiv.org/abs/2504.08590 ,  382kb)
------------------------------------------------------------------------------
\\
arXiv:2504.21191
replaced with revised version Wed, 24 Sep 2025 01:15:31 GMT   (17kb)

Title: Small or Large? Zero-Shot or Finetuned? Guiding Language Model Choice
  for Specialized Applications in Healthcare
Authors: Lovedeep Gondara, Jonathan Simkin, Graham Sayle, Shebnum Devji,
  Gregory Arbour, Raymond Ng
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2504.21191 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2504.21625
replaced with revised version Wed, 24 Sep 2025 11:52:17 GMT   (4467kb)

Title: Meeseeks: A Feedback-Driven, Iterative Self-Correction Benchmark
  evaluating LLMs' Instruction Following Capability
Authors: Jiaming wang, Yunke Zhao, Peng Ding, Jun Kuang, Yibin Shen, Zhe Tang,
  Yilin Jin, ZongYu Wang, Xiaoyu Li, Xuezhi Cao, Xunliang Cai
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.21625 ,  4467kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09316
replaced with revised version Wed, 24 Sep 2025 03:54:58 GMT   (857kb)

Title: Scent of Knowledge: Optimizing Search-Enhanced Reasoning with
  Information Foraging
Authors: Hongjin Qian, Zheng Liu
Categories: cs.CL cs.IR
Comments: Neurips 25, Spotlight
\\ ( https://arxiv.org/abs/2505.09316 ,  857kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12621
replaced with revised version Wed, 24 Sep 2025 09:22:11 GMT   (319kb)

Title: SAFE: Improving LLM Systems using Sentence-Level In-generation
  Attribution
Authors: Jo\~ao Eduardo Batista, Emil Vatai, Mohamed Wahib
Categories: cs.CL cs.IR
Comments: 30 pages (9 pages of content, 5 pages of references, 16 pages of
  supplementary material), 7 figures, 13 tables
\\ ( https://arxiv.org/abs/2505.12621 ,  319kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14045
replaced with revised version Wed, 24 Sep 2025 01:32:55 GMT   (358kb)

Title: From Unaligned to Aligned: Scaling Multilingual LLMs with Multi-Way
  Parallel Corpora
Authors: Yingli Shen, Wen Lai, Shuo Wang, Ge Gao, Kangyang Luo, Alexander
  Fraser, Maosong Sun
Categories: cs.CL cs.AI
Journal-ref: EMNLP 2025 Main (Oral)
\\ ( https://arxiv.org/abs/2505.14045 ,  358kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15074
replaced with revised version Wed, 24 Sep 2025 17:25:12 GMT   (9726kb)

Title: DISCO Balances the Scales: Adaptive Domain- and Difficulty-Aware
  Reinforcement Learning on Imbalanced Data
Authors: Yuhang Zhou, Jing Zhu, Shengyi Qian, Zhuokai Zhao, Xiyao Wang, Xiaoyu
  Liu, Ming Li, Paiheng Xu, Wei Ai, Furong Huang
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2505.15074 ,  9726kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16088
replaced with revised version Wed, 24 Sep 2025 10:35:24 GMT   (854kb)

Title: Date Fragments: A Hidden Bottleneck of Tokenization for Temporal
  Reasoning
Authors: Gagan Bhatia, Maxime Peyrard, Wei Zhao
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2505.16088 ,  854kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22061
replaced with revised version Wed, 24 Sep 2025 07:57:31 GMT   (284kb)

Title: Safeguarding Privacy of Retrieval Data against Membership Inference
  Attacks: Is This Query Too Close to Home?
Authors: Yujin Choi, Youngjoo Park, Junyoung Byun, Jaewook Lee, and Jinseong
  Park
Categories: cs.CL
Comments: Accepted for EMNLP findings
\\ ( https://arxiv.org/abs/2505.22061 ,  284kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22157
replaced with revised version Wed, 24 Sep 2025 10:42:38 GMT   (864kb)

Title: LASER: Stratified Selective Sampling for Instruction Tuning with
  Dedicated Scoring Strategy
Authors: Paramita Mirza, Lucas Weber, Fabian K\"uch
Categories: cs.CL
Comments: Accepted at Findings of the Association for Computational
  Linguistics: EMNLP 2025
\\ ( https://arxiv.org/abs/2505.22157 ,  864kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22323
replaced with revised version Wed, 24 Sep 2025 16:48:33 GMT   (4045kb)

Title: Advancing Expert Specialization for Better MoE
Authors: Hongcan Guo, Haolang Lu, Guoshun Nan, Bolun Chu, Jialin Zhuang, Yuan
  Yang, Wenhao Che, Sicong Leng, Qimei Cui, and Xudong Jiang
Categories: cs.CL cs.SE
Comments: 33pages, 6figures(Accepted by Neurips 2026 Oral)
MSC-class: 68T07
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2505.22323 ,  4045kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23001
replaced with revised version Tue, 23 Sep 2025 21:07:44 GMT   (243kb)

Title: DyePack: Provably Flagging Test Set Contamination in LLMs Using
  Backdoors
Authors: Yize Cheng, Wenxiao Wang, Mazda Moayeri, Soheil Feizi
Categories: cs.CL
Comments: EMNLP2025 main, Camera-ready
\\ ( https://arxiv.org/abs/2505.23001 ,  243kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23368
replaced with revised version Wed, 24 Sep 2025 12:01:02 GMT   (556kb)

Title: Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain
  Human Label Variation
Authors: Beiduo Chen, Yang Janet Liu, Anna Korhonen, Barbara Plank
Categories: cs.CL
Comments: Accepted by EMNLP 2025 Main (Oral), 25 pages, 7 figures
\\ ( https://arxiv.org/abs/2505.23368 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23832
replaced with revised version Wed, 24 Sep 2025 09:47:04 GMT   (2174kb)

Title: LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements
  Generation
Authors: Chaeeun Kim, Jinu Lee, Wonseok Hwang
Categories: cs.CL cs.IR
Comments: EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2505.23832 ,  2174kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03880
replaced with revised version Wed, 24 Sep 2025 06:02:55 GMT   (400kb)

Title: RadialRouter: Structured Representation for Efficient and Robust Large
  Language Models Routing
Authors: Ruihan Jin, Pengpeng Shao, Zhengqi Wen, Jinyang Wu, Mingkuan Feng,
  Shuai Zhang, Jianhua Tao
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2506.03880 ,  400kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10979
replaced with revised version Wed, 24 Sep 2025 09:39:44 GMT   (1420kb)

Title: How Well Can Reasoning Models Identify and Recover from Unhelpful
  Thoughts?
Authors: Sohee Yang, Sang-Woo Lee, Nora Kassner, Daniela Gottesman, Sebastian
  Riedel, Mor Geva
Categories: cs.CL
Comments: Findings of EMNLP 2025
\\ ( https://arxiv.org/abs/2506.10979 ,  1420kb)
------------------------------------------------------------------------------
\\
arXiv:2506.19209
replaced with revised version Wed, 24 Sep 2025 02:27:14 GMT   (288kb)

Title: Augmenting Multi-Agent Communication with State Delta Trajectory
Authors: Yichen Tang, Weihang Su, Yujia Zhou, Yiqun Liu, Min Zhang, Shaoping
  Ma, Qingyao Ai
Categories: cs.CL
Comments: 22 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.19209 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2507.01234
replaced with revised version Wed, 24 Sep 2025 07:40:38 GMT   (945kb)

Title: The Medium Is Not the Message: Deconfounding Document Embeddings via
  Linear Concept Erasure
Authors: Yu Fan, Yang Tian, Shauli Ravfogel, Mrinmaya Sachan, Elliott Ash,
  Alexander Hoyle
Categories: cs.CL
Comments: Accepted to EMNLP 2025 (Main)
\\ ( https://arxiv.org/abs/2507.01234 ,  945kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04137
replaced with revised version Wed, 24 Sep 2025 14:48:30 GMT   (1344kb)

Title: Detecting Token-Level Hallucinations Using Variance Signals: A
  Reference-Free Approach
Authors: Keshav Kumar
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2507.04137 ,  1344kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06899
replaced with revised version Wed, 24 Sep 2025 14:33:17 GMT   (836kb)

Title: VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual
  Grounding Manipulation
Authors: Ziang Ye, Yang Zhang, Wentao Shi, Xiaoyu You, Fuli Feng, Tat-Seng Chua
Categories: cs.CL cs.AI
Comments: Accepted in COLM2025
\\ ( https://arxiv.org/abs/2507.06899 ,  836kb)
------------------------------------------------------------------------------
\\
arXiv:2507.09076
replaced with revised version Wed, 24 Sep 2025 07:56:12 GMT   (729kb)

Title: Dynamic Parameter Memory: Temporary LoRA-Enhanced LLM for Long-Sequence
  Emotion Recognition in Conversation
Authors: Jialong Mai, Xiaofen Xing, Yawei Li, Weidong Chen, Zhipeng Li,
  Jingyuan Xing, Xiangmin Xu
Categories: cs.CL cs.AI
Comments: submitted to ICLR 2026
MSC-class: 68T50
ACM-class: I.2.7; H.5.2
\\ ( https://arxiv.org/abs/2507.09076 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22729
replaced with revised version Wed, 24 Sep 2025 11:55:48 GMT   (2728kb)

Title: Resource-Efficient Adaptation of Large Language Models for Text
  Embeddings via Prompt Engineering and Contrastive Fine-tuning
Authors: Benedikt Roth, Stephan Rappensperger, Tianming Qiu, Hamza Imamovi\'c,
  Julian W\"ormann, Hao Shen
Categories: cs.CL
\\ ( https://arxiv.org/abs/2507.22729 ,  2728kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22931
replaced with revised version Wed, 24 Sep 2025 16:41:40 GMT   (943kb)

Title: Enhancing RAG Efficiency with Adaptive Context Compression
Authors: Shuyu Guo, Shuo Zhang, Zhaochun Ren
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2507.22931 ,  943kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01424
replaced with revised version Wed, 24 Sep 2025 05:11:07 GMT   (544kb)

Title: From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs
Authors: Haonan Bian, Yutao Qi, Rui Yang, Yuanxi Che, Jiaqian Wang, Heming Xia,
  Ranran Zhen
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.01424 ,  544kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08742
replaced with revised version Wed, 24 Sep 2025 07:37:00 GMT   (766kb)

Title: SciRerankBench: Benchmarking Rerankers Towards Scientific
  Retrieval-Augmented Generated LLMs
Authors: Haotian Chen, Qingqing Long, Meng Xiao, Xiao Luo, Wei Ju, Chengrui
  Wang, Xuezhi Wang, Yuanchun Zhou, Hengshu Zhu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.08742 ,  766kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01301
replaced with revised version Wed, 24 Sep 2025 14:02:11 GMT   (75kb)

Title: Culture is Everywhere: A Call for Intentionally Cultural Evaluation
Authors: Juhyun Oh, Inha Cha, Michael Saxon, Hyunseung Lim, Shaily Bhatt, Alice
  Oh
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.01301 ,  75kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03148
replaced with revised version Wed, 24 Sep 2025 16:07:19 GMT   (754kb)

Title: Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan,
  Sutsilvan, Surmiran, Puter, and Vallader
Authors: Jannis Vamvas, Ignacio P\'erez Prat, Not Battesta Soliva, Sandra
  Baltermia-Guetg, Andrina Beeli, Simona Beeli, Madlaina Capeder, Laura
  Decurtins, Gian Peder Gregori, Flavia Hobi, Gabriela Holderegger, Arina
  Lazzarini, Viviana Lazzarini, Walter Rosselli, Bettina Vital, Anna
  Rutkiewicz, Rico Sennrich
Categories: cs.CL
Comments: WMT25 (Open Language Data Initiative Shared Task)
\\ ( https://arxiv.org/abs/2509.03148 ,  754kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06277
replaced with revised version Wed, 24 Sep 2025 00:07:25 GMT   (196kb)

Title: No Encore: Unlearning as Opt-Out in Music Generation
Authors: Jinju Kim, Taehan Kim, Abdul Waheed, Jong Hwan, Rita Singh
Categories: cs.CL
Comments: NeurIPS 2025 Workshop on AI for Music
\\ ( https://arxiv.org/abs/2509.06277 ,  196kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10644
replaced with revised version Wed, 24 Sep 2025 16:59:55 GMT   (6914kb)

Title: Interdisciplinary Research in Conversation: A Case Study in
  Computational Morphology for Language Documentation
Authors: Enora Rice, Katharina von der Wense and Alexis Palmer
Categories: cs.CL
Comments: Accepted to EMNLP 2025
\\ ( https://arxiv.org/abs/2509.10644 ,  6914kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15248
replaced with revised version Wed, 24 Sep 2025 06:04:40 GMT   (235kb)

Title: Synthetic bootstrapped pretraining
Authors: Zitong Yang, Aonan Zhang, Hong Liu, Tatsunori Hashimoto, Emmanuel
  Cand\`es, Chong Wang, Ruoming Pang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.15248 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15373
replaced with revised version Tue, 23 Sep 2025 18:14:37 GMT   (46kb)

Title: Frustratingly Easy Data Augmentation for Low-Resource ASR
Authors: Katsumi Ibaraki, David Chiang
Categories: cs.CL
Comments: 5 pages, 2 figures, 2 tables, submitted to ICASSP 2026
\\ ( https://arxiv.org/abs/2509.15373 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16589
replaced with revised version Wed, 24 Sep 2025 05:32:29 GMT   (1129kb)

Title: Benchmarking Contextual and Paralinguistic Reasoning in Speech-LLMs: A
  Case Study with In-the-Wild Data
Authors: Qiongqiong Wang, Hardik Bhupendra Sailor, Tianchi Liu, Wenyu Zhang,
  Muhammad Huzaifah, Nattadaporn Lertcheva, Shuo Sun, Nancy F. Chen, Jinyang
  Wu, AiTi Aw
Categories: cs.CL cs.AI
Comments: Accepted in EMNLP Findings 2025
\\ ( https://arxiv.org/abs/2509.16589 ,  1129kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17552
replaced with revised version Wed, 24 Sep 2025 05:24:09 GMT   (2593kb)

Title: Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A
  Case Study with In-Context Representation Learning
Authors: Tianle Zhang, Wanlong Fang, Jonathan Woo, Paridhi Latawa, Deepak
  A.Subramanian, Alvin Chan
Categories: cs.CL cs.AI
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.17552 ,  2593kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18762
replaced with revised version Wed, 24 Sep 2025 05:47:31 GMT   (0kb,I)

Title: When Long Helps Short: How Context Length in Supervised Fine-tuning
  Affects Behavior of Large Language Models
Authors: Yingming Zheng, Hanqi Li, Kai Yu and Lu Chen
Categories: cs.CL cs.AI
Comments: There are some problems with the institute requirements so we have to
  withdraw now and submit after all procedures have been done
\\ ( https://arxiv.org/abs/2509.18762 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18813
replaced with revised version Wed, 24 Sep 2025 02:21:15 GMT   (291kb)

Title: MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction
Authors: Liting Zhang, Shiwan Zhao, Aobo Kong and Qicheng Li
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.18813 ,  291kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19033
replaced with revised version Wed, 24 Sep 2025 07:17:32 GMT   (1048kb)

Title: Charting a Decade of Computational Linguistics in Italy: The CLiC-it
  Corpus
Authors: Chiara Alzetta, Serena Auriemma, Alessandro Bondielli, Luca Dini,
  Chiara Fazzone, Alessio Miaschi, Martina Miliani, Marta Sartor
Categories: cs.CL
Comments: Submitted to IJCoL
MSC-class: 68T50
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2509.19033 ,  1048kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19170
replaced with revised version Wed, 24 Sep 2025 11:28:42 GMT   (1843kb)

Title: Soft Tokens, Hard Truths
Authors: Natasha Butt, Ariel Kwiatkowski, Ismail Labiad, Julia Kempe, Yann
  Ollivier
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.19170 ,  1843kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19199
replaced with revised version Wed, 24 Sep 2025 01:27:23 GMT   (2139kb)

Title: Online Process Reward Leanring for Agentic Reinforcement Learning
Authors: Xiaoqian Liu, Ke Wang, Yuchuan Wu, Fei Huang, Yongbin Li, Junge Zhang,
  Jianbin Jiao
Categories: cs.CL
Comments: 16 pages, 5 figures
\\ ( https://arxiv.org/abs/2509.19199 ,  2139kb)
------------------------------------------------------------------------------
\\
arXiv:1903.07165
replaced with revised version Wed, 24 Sep 2025 12:38:18 GMT   (8725kb)

Title: An Optimized PatchMatch for Multi-scale and Multi-feature Label Fusion
Authors: R\'emi Giraud, Vinh-Thong Ta, Nicolas Papadakis, Jos\'e V. Manj\'on,
  D. Louis Collins, Pierrick Coup\'e, Alzheimer's Disease Neuroimaging
  Initiative
Categories: cs.CV
Comments: Neuroimage 2016
\\ ( https://arxiv.org/abs/1903.07165 ,  8725kb)
------------------------------------------------------------------------------
\\
arXiv:1903.07193
replaced with revised version Wed, 24 Sep 2025 12:35:19 GMT   (9686kb)

Title: Robust superpixels using color and contour features along linear path
Authors: R\'emi Giraud, Vinh-Thong Ta, Nicolas Papadakis
Categories: cs.CV
Comments: Computer Vision and Image Understanding (CVIU), 2018
\\ ( https://arxiv.org/abs/1903.07193 ,  9686kb)
------------------------------------------------------------------------------
\\
arXiv:2003.04414
replaced with revised version Wed, 24 Sep 2025 12:26:03 GMT   (5885kb)

Title: Texture Superpixel Clustering from Patch-based Nearest Neighbor Matching
Authors: R\'emi Giraud, Yannick Berthoumieu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2003.04414 ,  5885kb)
------------------------------------------------------------------------------
\\
arXiv:2003.04428
replaced with revised version Wed, 24 Sep 2025 08:53:51 GMT   (5186kb)

Title: Multi-Scale Superpatch Matching using Dual Superpixel Descriptors
Authors: R\'emi Giraud, Merlin Boyer, Micha\"el Cl\'ement
Categories: cs.CV
Journal-ref: Pattern Recognition Letters 2020
\\ ( https://arxiv.org/abs/2003.04428 ,  5186kb)
------------------------------------------------------------------------------
\\
arXiv:2310.03602
replaced with revised version Wed, 24 Sep 2025 03:53:21 GMT   (22998kb)

Title: Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout
  Constraints
Authors: Chuan Fang, Yuan Dong, Kunming Luo, Xiaotao Hu, Rakesh Shrestha, Ping
  Tan
Categories: cs.CV
\\ ( https://arxiv.org/abs/2310.03602 ,  22998kb)
------------------------------------------------------------------------------
\\
arXiv:2312.04931
replaced with revised version Wed, 24 Sep 2025 15:24:43 GMT   (1721kb)

Title: Long Video Understanding with Learnable Retrieval in Video-Language
  Models
Authors: Jiaqi Xu, Cuiling Lan, Wenxuan Xie, Xuejin Chen, Yan Lu
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Multimedia (TMM)
\\ ( https://arxiv.org/abs/2312.04931 ,  1721kb)
------------------------------------------------------------------------------
\\
arXiv:2402.03251
replaced with revised version Wed, 24 Sep 2025 14:59:39 GMT   (5334kb)

Title: CLIP Can Understand Depth
Authors: Sohee Kim, Jisu Kang, Dunam Kim, Seokju Lee
Categories: cs.CV cs.AI cs.LG
Comments: Accepted in Pattern Recognition, 2025
\\ ( https://arxiv.org/abs/2402.03251 ,  5334kb)
------------------------------------------------------------------------------
\\
arXiv:2408.01653
replaced with revised version Tue, 23 Sep 2025 19:12:03 GMT   (10999kb)

Title: MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from
  Multi-Cylindrical Panoramas
Authors: Feng Qiao, Zhexiao Xiong, Xinge Zhu, Yuexin Ma, Qiumeng He, Nathan
  Jacobs
Categories: cs.CV
Comments: Accepted by WACV 2026
\\ ( https://arxiv.org/abs/2408.01653 ,  10999kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11567
replaced with revised version Wed, 24 Sep 2025 00:39:45 GMT   (1345kb)

Title: Positional Prompt Tuning for Efficient 3D Representation Learning
Authors: Shaochen Zhang, Zekun Qi, Runpei Dong, Xiuxiu Bai, Xing Wei
Categories: cs.CV
Comments: Accepted at ACMMM 2025 Oral
\\ ( https://arxiv.org/abs/2408.11567 ,  1345kb)
------------------------------------------------------------------------------
\\
arXiv:2409.01522
replaced with revised version Wed, 24 Sep 2025 06:44:20 GMT   (12927kb)

Title: Lagrangian Motion Fields for Long-term Motion Generation
Authors: Yifei Yang, Zikai Huang, Chenshu Xu and Shengfeng He
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI), 2025
\\ ( https://arxiv.org/abs/2409.01522 ,  12927kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13674
replaced with revised version Wed, 24 Sep 2025 14:58:32 GMT   (18028kb)

Title: Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning
  via Image-Guided Diffusion
Authors: Yijun Liang, Shweta Bhardwaj, Tianyi Zhou
Categories: cs.CV cs.AI
Comments: Accepted in ICCV2025. 22 pages, including references and appendix.
  Code is available at http://github.com/tianyi-lab/DisCL
\\ ( https://arxiv.org/abs/2410.13674 ,  18028kb)
------------------------------------------------------------------------------
\\
arXiv:2411.00623
replaced with revised version Wed, 24 Sep 2025 03:51:09 GMT   (356kb)

Title: Replay-Free Continual Low-Rank Adaptation with Dynamic Memory
Authors: Huancheng Chen and Jingtao Li and Weiming Zhuang and Chen Chen and
  Lingjuan Lyu
Categories: cs.CV cs.LG
Comments: Latest reversion
\\ ( https://arxiv.org/abs/2411.00623 ,  356kb)
------------------------------------------------------------------------------
\\
arXiv:2411.10679
replaced with revised version Wed, 24 Sep 2025 12:41:58 GMT   (15288kb)

Title: SMLNet: A SPD Manifold Learning Network for Infrared and Visible Image
  Fusion
Authors: Huan Kang, Hui Li, Tianyang Xu, Xiao-Jun Wu, Rui Wang, Chunyang Cheng,
  Josef Kittler
Categories: cs.CV
Comments: 23 pages, 17 figures
ACM-class: I.4
\\ ( https://arxiv.org/abs/2411.10679 ,  15288kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17223
replaced with revised version Wed, 24 Sep 2025 15:39:02 GMT   (41920kb)

Title: DreamMix: Decoupling Object Attributes for Enhanced Editability in
  Customized Image Inpainting
Authors: Yicheng Yang, Pengxiang Li, Lu Zhang, Liqian Ma, Ping Hu, Siyu Du,
  Yunzhi Zhuge, Xu Jia, Huchuan Lu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.17223 ,  41920kb)
------------------------------------------------------------------------------
\\
arXiv:2411.19860
replaced with revised version Wed, 24 Sep 2025 13:01:20 GMT   (22996kb)

Title: SpaRC: Sparse Radar-Camera Fusion for 3D Object Detection
Authors: Philipp Wolters, Johannes Gilg, Torben Teepe, Fabian Herzog, Felix
  Fent, Gerhard Rigoll
Categories: cs.CV cs.LG
Comments: 18 pages, 11 figures
\\ ( https://arxiv.org/abs/2411.19860 ,  22996kb)
------------------------------------------------------------------------------
\\
arXiv:2412.07772
replaced with revised version Tue, 23 Sep 2025 21:08:03 GMT   (12751kb)

Title: From Slow Bidirectional to Fast Autoregressive Video Diffusion Models
Authors: Tianwei Yin, Qiang Zhang, Richard Zhang, William T. Freeman, Fredo
  Durand, Eli Shechtman, Xun Huang
Categories: cs.CV
Comments: CVPR 2025. Project Page: https://causvid.github.io/
\\ ( https://arxiv.org/abs/2412.07772 ,  12751kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12520
replaced with revised version Wed, 24 Sep 2025 07:44:35 GMT   (5140kb)

Title: SafeEraser: Enhancing Safety in Multimodal Large Language Models through
  Multimodal Machine Unlearning
Authors: Junkai Chen, Zhijie Deng, Kening Zheng, Yibo Yan, Shuliang Liu, PeiJun
  Wu, Peijie Jiang, Jia Liu, Xuming Hu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.12520 ,  5140kb)
------------------------------------------------------------------------------
\\
arXiv:2503.00531
replaced with revised version Wed, 24 Sep 2025 11:02:27 GMT   (5359kb)

Title: GaussianSeal: Rooting Adaptive Watermarks for 3D Gaussian Generation
  Model
Authors: Runyi Li, Xuanyu Zhang, Chuhan Tong, Zhipei Xu, Jian Zhang
Categories: cs.CV eess.IV
Comments: To be appeared in Machine Intelligence Research
DOI: 10.1007/s11633-025-1588-7
\\ ( https://arxiv.org/abs/2503.00531 ,  5359kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04139
replaced with revised version Tue, 23 Sep 2025 20:28:45 GMT   (6854kb)

Title: Robust Computer-Vision based Construction Site Detection for
  Assistive-Technology Applications
Authors: Junchi Feng, Giles Hamilton-Fletcher, Nikhil Ballem, Michael Batavia,
  Yifei Wang, Jiuling Zhong, Maurizio Porfiri, John-Ross Rizzo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.04139 ,  6854kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04344
replaced with revised version Wed, 24 Sep 2025 17:48:25 GMT   (19515kb)

Title: LEDiT: Your Length-Extrapolatable Diffusion Transformer without
  Positional Encoding
Authors: Shen Zhang, Siyuan Liang, Yaning Tan, Zhaowei Chen, Linze Li, Ge Wu,
  Yuhao Chen, Shuheng Li, Zhenyu Zhao, Caihua Chen, Jiajun Liang, Yao Tang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.04344 ,  19515kb)
------------------------------------------------------------------------------
\\
arXiv:2503.06361
replaced with revised version Wed, 24 Sep 2025 13:05:49 GMT   (23998kb)

Title: Adversarial Robustness of Discriminative Self-Supervised Learning in
  Vision
Authors: \"Omer Veysel \c{C}a\u{g}atan, \"Omer Faruk Tal, M. Emre G\"ursoy
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2503.06361 ,  23998kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15275
replaced with revised version Wed, 24 Sep 2025 07:38:29 GMT   (1736kb)

Title: Challenges and Trends in Egocentric Vision: A Survey
Authors: Xiang Li, Heqian Qiu, Lanxiao Wang, Hanwen Zhang, Chenghao Qi, Linfeng
  Han, Huiyu Xiong, Hongliang Li
Categories: cs.CV cs.AI
Comments: This article was accepted by Machine Intelligence Research
DOI: 10.1007/s11633-025-1599-4
\\ ( https://arxiv.org/abs/2503.15275 ,  1736kb)
------------------------------------------------------------------------------
\\
arXiv:2503.17937
replaced with revised version Wed, 24 Sep 2025 06:35:05 GMT   (15935kb)

Title: Cross-Domain Underwater Image Enhancement Guided by No-Reference Image
  Quality Assessment: A Transfer Learning Approach
Authors: Zhi Zhang, Minfu Li, Lu Li, Daoyi Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.17937 ,  15935kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02876
replaced with revised version Wed, 24 Sep 2025 17:23:48 GMT   (9424kb)

Title: Multimodal Reference Visual Grounding
Authors: Yangxiao Lu, Ruosen Li, Liqiang Jing, Jikai Wang, Xinya Du, Yunhui
  Guo, Nicholas Ruozzi, Yu Xiang
Categories: cs.CV cs.LG
Comments: Project page with our code and dataset:
  https://irvlutd.github.io/MultiGrounding
\\ ( https://arxiv.org/abs/2504.02876 ,  9424kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04974
replaced with revised version Tue, 23 Sep 2025 21:43:47 GMT   (30038kb)

Title: Towards Visual Text Grounding of Multimodal Large Language Model
Authors: Ming Li, Ruiyi Zhang, Jian Chen, Chenguang Wang, Jiuxiang Gu, Yufan
  Zhou, Franck Dernoncourt, Wanrong Zhu, Tianyi Zhou, Tong Sun
Categories: cs.CV cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2504.04974 ,  30038kb)
------------------------------------------------------------------------------
\\
arXiv:2504.12699
replaced with revised version Tue, 23 Sep 2025 20:42:06 GMT   (2102kb)

Title: Unsupervised Cross-Domain 3D Human Pose Estimation via
  Pseudo-Label-Guided Global Transforms
Authors: Jingjing Liu, Zhiyong Wang, Xinyu Fan, Amirhossein Dadashzadeh,
  Honghai Liu and Majid Mirmehdi
Categories: cs.CV
Comments: accepted to IEEE Transactions on Circuits and Systems for Video
  Technology
DOI: 10.1109/TCSVT.2025.3610066
\\ ( https://arxiv.org/abs/2504.12699 ,  2102kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13275
replaced with revised version Wed, 24 Sep 2025 05:52:12 GMT   (3735kb)

Title: ChartQA-X: Generating Explanations for Visual Chart Reasoning
Authors: Shamanthak Hegde, Pooyan Fazli, Hasti Seifi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2504.13275 ,  3735kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11881
replaced with revised version Wed, 24 Sep 2025 07:40:31 GMT   (4389kb)

Title: Revisiting Residual Connections: Orthogonal Updates for Stable and
  Efficient Deep Networks
Authors: Giyeong Oh, Woohyun Cho, Siyeol Kim, Suhwan Choi, Younjae Yu
Categories: cs.CV cs.AI
Comments: 27 pages, minor typo fix, not final version, Accepted at the 39th
  Conference on Neural Information Processing Systems (NeurIPS 2025)
\\ ( https://arxiv.org/abs/2505.11881 ,  4389kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12753
replaced with revised version Wed, 24 Sep 2025 11:44:49 GMT   (1892kb)

Title: LiDAR MOT-DETR: A LiDAR-based Two-Stage Transformer for 3D Multiple
  Object Tracking
Authors: Martha Teiko Teye, Ori Maoz, Matthias Rottmann
Categories: cs.CV
Comments: Camera-ready copy
\\ ( https://arxiv.org/abs/2505.12753 ,  1892kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16180
replaced with revised version Wed, 24 Sep 2025 03:01:31 GMT   (10970kb)

Title: Redemption Score: A Multi-Modal Evaluation Framework for Image
  Captioning via Distributional, Perceptual, and Linguistic Signal
  Triangulation
Authors: Ashim Dahal, Ankit Ghimire, Saydul Akbar Murad, Nick Rahimi
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2505.16180 ,  10970kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18875
replaced with revised version Tue, 23 Sep 2025 20:06:40 GMT   (18543kb)

Title: Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via
  Semantic-Aware Permutation
Authors: Shuo Yang, Haocheng Xi, Yilong Zhao, Muyang Li, Jintao Zhang, Han Cai,
  Yujun Lin, Xiuyu Li, Chenfeng Xu, Kelly Peng, Jianfei Chen, Song Han, Kurt
  Keutzer, Ion Stoica
Categories: cs.CV
\\ ( https://arxiv.org/abs/2505.18875 ,  18543kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23601
replaced with revised version Wed, 24 Sep 2025 14:44:36 GMT   (5853kb)

Title: EndoBench: A Comprehensive Evaluation of Multi-Modal Large Language
  Models for Endoscopy Analysis
Authors: Shengyuan Liu, Boyun Zheng, Wenting Chen, Zhihao Peng, Zhenfei Yin,
  Jing Shao, Jiancong Hu, Yixuan Yuan
Categories: cs.CV
Comments: 40 pages, 22 figures; Accepted by NeurIPS 2025 Dataset and Benchmark
  Track
\\ ( https://arxiv.org/abs/2505.23601 ,  5853kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23745
replaced with revised version Wed, 24 Sep 2025 11:40:31 GMT   (4678kb)

Title: To Trust Or Not To Trust Your Vision-Language Model's Prediction
Authors: Hao Dong, Moru Liu, Jian Liang, Eleni Chatzi, Olga Fink
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.23745 ,  4678kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00433
replaced with revised version Wed, 24 Sep 2025 15:22:22 GMT   (31265kb)

Title: Latent Wavelet Diffusion For Ultra-High-Resolution Image Synthesis
Authors: Luigi Sigillo, Shengfeng He, Danilo Comminiello
Categories: cs.CV cs.LG eess.IV
\\ ( https://arxiv.org/abs/2506.00433 ,  31265kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02547
replaced with revised version Wed, 24 Sep 2025 03:39:47 GMT   (3676kb)

Title: Probabilistic Online Event Downsampling
Authors: Andreu Girbau-Xalabarder, Jun Nagata, Shinichi Sumiyoshi, Ricard
  Marsal, Shin'ichi Satoh
Categories: cs.CV cs.ET
Comments: Best paper award finalist at CVPR 2025 Event-Vision workshop
\\ ( https://arxiv.org/abs/2506.02547 ,  3676kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03135
replaced with revised version Wed, 24 Sep 2025 00:47:35 GMT   (12800kb)

Title: OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for
  Vision Language Models
Authors: Mengdi Jia, Zekun Qi, Shaochen Zhang, Wenyao Zhang, Xinqiang Yu,
  Jiawei He, He Wang, Li Yi
Categories: cs.CV cs.AI cs.CL
Comments: Project Page: https://qizekun.github.io/omnispatial/
\\ ( https://arxiv.org/abs/2506.03135 ,  12800kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10302
replaced with revised version Wed, 24 Sep 2025 12:41:38 GMT   (1086kb)

Title: A Quad-Step Approach to Uncertainty-Aware Deep Learning for Skin Cancer
  Classification
Authors: Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah
  Alizadehsani, U. Rajendra Acharya
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2506.10302 ,  1086kb)
------------------------------------------------------------------------------
\\
arXiv:2506.15404
replaced with revised version Wed, 24 Sep 2025 03:46:15 GMT   (3498kb)

Title: NERO: Explainable Out-of-Distribution Detection with Neuron-level
  Relevance
Authors: Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2506.15404 ,  3498kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17873
replaced with revised version Wed, 24 Sep 2025 03:26:52 GMT   (2764kb)

Title: SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large
  Language Model
Authors: Guankun Wang, Junyi Wang, Wenjin Mo, Long Bai, Kun Yuan, Ming Hu,
  Jinlin Wu, Junjun He, Yiming Huang, Nicolas Padoy, Zhen Lei, Hongbin Liu,
  Nassir Navab, and Hongliang Ren
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2506.17873 ,  2764kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22803
replaced with revised version Wed, 24 Sep 2025 08:29:38 GMT   (10760kb)

Title: Intervening in Black Box: Concept Bottleneck Model for Enhancing Human
  Neural Network Mutual Understanding
Authors: Nuoye Xiong, Anqi Dong, Ning Wang, Cong Hua, Guangming Zhu, Lin Mei,
  Peiyi Shen, Liang Zhang
Categories: cs.CV cs.HC cs.LG
Comments: Accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2506.22803 ,  10760kb)
------------------------------------------------------------------------------
\\
arXiv:2507.10403
replaced with revised version Wed, 24 Sep 2025 14:10:23 GMT   (9468kb)

Title: CLOSP: A Unified Semantic Space for SAR, MSI, and Text in Remote Sensing
Authors: Daniele Rege Cambrin, Lorenzo Vaiani, Giuseppe Gallipoli, Luca
  Cagliero, Paolo Garza
Categories: cs.CV cs.CL cs.IR cs.MM
\\ ( https://arxiv.org/abs/2507.10403 ,  9468kb)
------------------------------------------------------------------------------
\\
arXiv:2507.15809
replaced with revised version Wed, 24 Sep 2025 12:42:48 GMT   (6969kb)

Title: Diffusion models for multivariate subsurface generation and efficient
  probabilistic inversion
Authors: Roberto Miele, Niklas Linde
Categories: cs.CV cs.LG physics.geo-ph stat.AP
Comments: 35 pages, 16 figures, reviewed version. Changes include the
  following. General revision of the text to improve the language clarity and
  correct minor errors; Ip values are now reported in SI (Pa.s/m); addition of
  three bibliographic references and correction of one reference wrongly
  reported (Yismaw et al., 2024); standardization of the figures' labels
\\ ( https://arxiv.org/abs/2507.15809 ,  6969kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04852
replaced with revised version Tue, 23 Sep 2025 19:48:56 GMT   (3994kb)

Title: VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual
  Evidence
Authors: Chenhui Qiang, Zhaoyang Wei, Xumeng Han, Zipeng Wang, Siyao Li,
  Xiangyuan Lan, Jianbin Jiao, Zhenjun Han
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.04852 ,  3994kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10931
replaced with revised version Wed, 24 Sep 2025 06:43:29 GMT   (24496kb)

Title: VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step
  Image Generation Models By Value Sign Flip
Authors: Wenqi Guo, Shan Du
Categories: cs.CV cs.GR
\\ ( https://arxiv.org/abs/2508.10931 ,  24496kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12587
replaced with revised version Tue, 23 Sep 2025 19:29:35 GMT   (750kb)

Title: Multimodal Chain of Continuous Thought for Latent-Space Reasoning in
  Vision-Language Models
Authors: Tan-Hanh Pham and Chris Ngo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.12587 ,  750kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13739
replaced with revised version Wed, 24 Sep 2025 17:02:50 GMT   (11549kb)

Title: Enhancing Targeted Adversarial Attacks on Large Vision-Language Models
  via Intermediate Projector
Authors: Yiming Cao, Yanjie Li, Kaisheng Liang, Bin Xiao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.13739 ,  11549kb)
------------------------------------------------------------------------------
\\
arXiv:2508.14370
replaced with revised version Wed, 24 Sep 2025 00:55:49 GMT   (1603kb)

Title: FastTracker: Real-Time and Accurate Visual Tracking
Authors: Hamidreza Hashempoor, Yu Dong Hwang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.14370 ,  1603kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08502
replaced with revised version Tue, 23 Sep 2025 19:04:53 GMT   (9040kb)

Title: Chirality in Action: Time-Aware Video Representation Learning by Latent
  Straightening
Authors: Piyush Bagad, Andrew Zisserman
Categories: cs.CV
Comments: Project page: https://bpiyush.github.io/lift-website/
\\ ( https://arxiv.org/abs/2509.08502 ,  9040kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10887
replaced with revised version Wed, 24 Sep 2025 09:29:40 GMT   (1930kb)

Title: AutoOEP -- A Multi-modal Framework for Online Exam Proctoring
Authors: Aryan Kashyap Naveen, Bhuvanesh Singla, Raajan Wankhade, Shreesha M,
  Ramu S, Ram Mohana Reddy Guddeti
Categories: cs.CV
Comments: 8 pages, 6 figures
\\ ( https://arxiv.org/abs/2509.10887 ,  1930kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12201
replaced with revised version Wed, 24 Sep 2025 13:15:38 GMT   (20959kb)

Title: OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling
Authors: Yang Zhou, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Haoyu Guo, Zizun
  Li, Kaijing Ma, Xinyue Li, Yating Wang, Haoyi Zhu, Mingyu Liu, Dingning Liu,
  Jiange Yang, Zhoujie Fu, Junyi Chen, Chunhua Shen, Jiangmiao Pang, Kaipeng
  Zhang, Tong He
Categories: cs.CV
Comments: https://yangzhou24.github.io/OmniWorld/
\\ ( https://arxiv.org/abs/2509.12201 ,  20959kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15225
replaced with revised version Wed, 24 Sep 2025 08:54:20 GMT   (3818kb)

Title: Lost in Translation? Vocabulary Alignment for Source-Free Domain
  Adaptation in Open-Vocabulary Semantic Segmentation
Authors: Silvio Mazzucco, Carl Persson, Mattia Segu, Pier Luigi Dovesi,
  Federico Tombari, Luc Van Gool, Matteo Poggi
Categories: cs.CV
Comments: BMVC 2025 - Project Page: https://thegoodailab.org/blog/vocalign -
  Code: https://github.com/Sisso16/VocAlign
\\ ( https://arxiv.org/abs/2509.15225 ,  3818kb)
------------------------------------------------------------------------------
\\
arXiv:2509.15791
replaced with revised version Wed, 24 Sep 2025 08:25:54 GMT   (2763kb)

Title: Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization
Authors: Tan Pan, Kaiyu Guo, Dongli Xu, Zhaorui Tan, Chen Jiang, Deshu Chen,
  Xin Guo, Brian C. Lovell, Limei Han, Yuan Cheng, Mahsa Baktashmotlagh
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.15791 ,  2763kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16549
replaced with revised version Wed, 24 Sep 2025 08:10:42 GMT   (2580kb)

Title: Efficient Rectified Flow for Image Fusion
Authors: Zirui Wang, Jiayi Zhang, Tianwei Guan, Yuhan Zhou, Xingyuan Li,
  Minjing Dong, Jinyuan Liu
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.16549 ,  2580kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16738
replaced with revised version Wed, 24 Sep 2025 11:22:58 GMT   (2879kb)

Title: Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning
Authors: Kai Jiang, Zhengyan Shi, Dell Zhang, Hongyuan Zhang and Xuelong Li
Categories: cs.CV cs.LG
Comments: Accepted by NeurIPS 2025. Code is available at
  https://github.com/ASCIIJK/MiN-NeurIPS2025
\\ ( https://arxiv.org/abs/2509.16738 ,  2879kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18159
replaced with revised version Wed, 24 Sep 2025 13:32:31 GMT   (877kb)

Title: PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal
  Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization
  on the Kvasir Dataset
Authors: Akwasi Asare, Ulas Bagci
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2509.18159 ,  877kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18160
replaced with revised version Wed, 24 Sep 2025 13:09:54 GMT   (1778kb)

Title: PerceptronCARE: A Deep Learning-Based Intelligent Teleophthalmology
  Application for Diabetic Retinopathy Diagnosis
Authors: Akwasi Asare, Isaac Baffour Senkyire, Emmanuel Freeman, Mary Sagoe,
  Simon Hilary Ayinedenaba Aluze-Ele, and Kelvin Kwao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.18160 ,  1778kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18308
replaced with revised version Wed, 24 Sep 2025 01:07:54 GMT   (4503kb)

Title: Rethinking Pulmonary Embolism Segmentation: A Study of Current
  Approaches and Challenges with an Open Weight Model
Authors: Yixin Zhang, Ryan Chamberlain, Lawrence Ngo, Kevin Kramer, Maciej A.
  Mazurowski
Categories: cs.CV
Comments: submitted to WACV 2026 application track, model weights available at:
  https://github.com/mazurowski-lab/PulmonaryEmbolismSegmentation
\\ ( https://arxiv.org/abs/2509.18308 ,  4503kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18639
replaced with revised version Wed, 24 Sep 2025 13:22:07 GMT   (9400kb)

Title: Understanding-in-Generation: Reinforcing Generative Capability of
  Unified Model via Infusing Understanding into Generation
Authors: Yuanhuiyi Lyu, Chi Kit Wong, Chenfei Liao, Lutao Jiang, Xu Zheng,
  Zexin Lu, Linfeng Zhang, Xuming Hu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.18639 ,  9400kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18754
replaced with revised version Wed, 24 Sep 2025 07:53:56 GMT   (23387kb)

Title: COLT: Enhancing Video Large Language Models with Continual Tool Usage
Authors: Yuyang Liu, Xinyuan Shi, Xiaondan Liang
Categories: cs.CV cs.AI
Comments: 16 pages
\\ ( https://arxiv.org/abs/2509.18754 ,  23387kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19090
replaced with revised version Wed, 24 Sep 2025 08:19:50 GMT   (21941kb)

Title: Citrus-V: Advancing Medical Foundation Models with Unified Medical Image
  Grounding for Clinical Reasoning
Authors: Guoxin Wang, Jun Zhao, Xinyi Liu, Yanbo Liu, Xuyang Cao, Chao Li,
  Zhuoyun Liu, Qintian Sun, Fangru Zhou, Haoqiang Xing, Zhenhong Yang
Categories: cs.CV cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.19090 ,  21941kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19096
replaced with revised version Wed, 24 Sep 2025 08:42:59 GMT   (12247kb)

Title: Investigating Traffic Accident Detection Using Multimodal Large Language
  Models
Authors: Ilhan Skender, Kailin Tong, Selim Solmaz, Daniel Watzenig
Categories: cs.CV cs.SE
Comments: Accepted for presentation at the 2025 IEEE International Automated
  Vehicle Validation Conference (IAVVC 2025). Final version to appear in IEEE
  Xplore
\\ ( https://arxiv.org/abs/2509.19096 ,  12247kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19244
replaced with revised version Wed, 24 Sep 2025 09:38:15 GMT   (7721kb)

Title: Lavida-O: Elastic Large Masked Diffusion Models for Unified Multimodal
  Understanding and Generation
Authors: Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya
  Grover, Jason Kuen
Categories: cs.CV
Comments: 31 pages, 15 figures
\\ ( https://arxiv.org/abs/2509.19244 ,  7721kb)
------------------------------------------------------------------------------
\\
arXiv:2504.19516
replaced with revised version Wed, 24 Sep 2025 05:39:00 GMT   (2401kb)

Title: Bullet: Boosting GPU Utilization for LLM Serving via Dynamic
  Spatial-Temporal Orchestration
Authors: Zejia Lin, Hongxin Xu, Guanyi Chen, Zhiguang Chen, Yutong Lu, Xianwei
  Zhang
Categories: cs.DC
\\ ( https://arxiv.org/abs/2504.19516 ,  2401kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13523
replaced with revised version Wed, 24 Sep 2025 01:32:55 GMT   (2597kb)

Title: LAMMPS-KOKKOS: Performance Portable Molecular Dynamics Across Exascale
  Architectures
Authors: Anders Johansson, Evan Weinberg, Christian R. Trott, Megan J.
  McCarthy, Stan G. Moore
Categories: cs.DC cs.PF physics.comp-ph
Comments: 16 pages, 7 figures
ACM-class: C.1.4; C.2.4; C.4; D.1.3; D.3.4; E.1; I.6; I.6.8; J.2
DOI: 10.1145/3731599.3767498
\\ ( https://arxiv.org/abs/2508.13523 ,  2597kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16410
replaced with revised version Wed, 24 Sep 2025 14:30:27 GMT   (4006kb)

Title: Optimal Multi-agent Path Finding in Continuous Time
Authors: Alvin Combrink, Sabino Francesco Roselli, Martin Fabian
Categories: cs.MA cs.DM cs.RO
Comments: 35 pages
\\ ( https://arxiv.org/abs/2508.16410 ,  4006kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12446
replaced with revised version Wed, 24 Sep 2025 03:51:42 GMT   (1511kb)

Title: PromptSculptor: Multi-Agent Based Text-to-Image Prompt Optimization
Authors: Dawei Xiang, Wenyan Xu, Kexin Chu, Tianqi Ding, Zixu Shen, Yiming
  Zeng, Jianchang Su, Wei Zhang
Categories: cs.MA cs.AI
Comments: Accepted to EMNLP 2025 System Demonstration Track
\\ ( https://arxiv.org/abs/2509.12446 ,  1511kb)
------------------------------------------------------------------------------
\\
arXiv:2305.16056
replaced with revised version Wed, 24 Sep 2025 10:44:26 GMT   (370kb)

Title: Markov Decision Processes under External Temporal Processes
Authors: Ranga Shaarad Ayyagari, Revanth Raj Eega, Ambedkar Dukkipati
Categories: cs.LG cs.AI
Comments: 45 pages
\\ ( https://arxiv.org/abs/2305.16056 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2308.00177
replaced with revised version Tue, 23 Sep 2025 23:35:02 GMT   (11624kb)

Title: Pretrained deep models outperform GBDTs in Learning-To-Rank under label
  scarcity
Authors: Charlie Hou, Kiran Koshy Thekumparampil, Michael Shavlovsky, Giulia
  Fanti, Yesh Dattatreya, Sujay Sanghavi
Categories: cs.LG cs.AI
Comments: Published in TMLR, ICML-MFPL 2023 Workshop Oral, SPIGM@ICML2024
\\ ( https://arxiv.org/abs/2308.00177 ,  11624kb)
------------------------------------------------------------------------------
\\
arXiv:2311.11073
replaced with revised version Tue, 23 Sep 2025 19:49:17 GMT   (3322kb)

Title: CueGCL: Cluster-aware Personalized Self-Training for Unsupervised Graph
  Contrastive Learning
Authors: Yuecheng Li, Lele Fu, Sheng Huang, Chuan Chen, Lei Yang, Zibin Zheng
Categories: cs.SI cs.AI cs.LG
Comments: 13 pages, 7 figures
\\ ( https://arxiv.org/abs/2311.11073 ,  3322kb)
------------------------------------------------------------------------------
\\
arXiv:2405.18620
replaced with revised version Tue, 23 Sep 2025 18:21:29 GMT   (5203kb)

Title: RealitySummary: Exploring On-Demand Mixed Reality Text Summarization and
  Question Answering using Large Language Models
Authors: Aditya Gunturu, Shivesh Jadon, Nandi Zhang, Morteza Faraji, Jarin
  Thundathil, Wesley Willett, Ryo Suzuki
Categories: cs.HC cs.AI cs.CL
Comments: SUI 2025
DOI: 10.1145/3694907.3765933
\\ ( https://arxiv.org/abs/2405.18620 ,  5203kb)
------------------------------------------------------------------------------
\\
arXiv:2408.08055
replaced with revised version Wed, 24 Sep 2025 07:10:35 GMT   (199kb)

Title: DeNOTS: Stable Deep Neural ODEs for Time Series
Authors: Ilya Kuleshov, Evgenia Romanenkova, Vladislav Zhuzhel, Galina Boeva,
  Evgeni Vorsin, Alexey Zaytsev
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2408.08055 ,  199kb)
------------------------------------------------------------------------------
\\
arXiv:2408.09695
replaced with revised version Wed, 24 Sep 2025 03:41:57 GMT   (8695kb)

Title: On the Integration of Spatial-Temporal Knowledge: A Lightweight Approach
  to Atmospheric Time Series Forecasting
Authors: Yisong Fu, Fei Wang, Zezhi Shao, Boyu Diao, Lin Wu, Zhulin An,
  Chengqing Yu, Yujie Li, Yongjun Xu
Categories: cs.LG cs.AI physics.ao-ph
\\ ( https://arxiv.org/abs/2408.09695 ,  8695kb)
------------------------------------------------------------------------------
\\
arXiv:2409.09245
replaced with revised version Wed, 24 Sep 2025 02:53:58 GMT   (406kb)

Title: Robust Training of Neural Networks at Arbitrary Precision and Sparsity
Authors: Chengxi Ye, Grace Chu, Yanfeng Liu, Yichi Zhang, Lukasz Lew, Li Zhang,
  Mark Sandler, Andrew Howard
Categories: cs.LG cs.AI cs.CL cs.CV cs.NA math.NA
\\ ( https://arxiv.org/abs/2409.09245 ,  406kb)
------------------------------------------------------------------------------
\\
arXiv:2410.01841 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 17:00:37 GMT   (820kb)

Title: A GEN AI Framework for Medical Note Generation
Authors: Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz
Categories: eess.AS cs.AI cs.CL cs.IR cs.SD
Comments: 8 Figures, 7 page, IEEE standard research paper
\\ ( https://arxiv.org/abs/2410.01841 ,  820kb)
------------------------------------------------------------------------------
\\
arXiv:2410.08792
replaced with revised version Wed, 24 Sep 2025 03:44:46 GMT   (4302kb)

Title: VLM See, Robot Do: Human Demo Video to Robot Action Plan via Vision
  Language Model
Authors: Beichen Wang, Juexiao Zhang, Shuwen Dong, Irving Fang, Chen Feng
Categories: cs.RO cs.AI cs.CV cs.LG
\\ ( https://arxiv.org/abs/2410.08792 ,  4302kb)
------------------------------------------------------------------------------
\\
arXiv:2411.15913
replaced with revised version Wed, 24 Sep 2025 06:37:35 GMT   (24785kb)

Title: Stylus: Repurposing Stable Diffusion for Training-Free Music Style
  Transfer on Mel-Spectrograms
Authors: Heehwan Wang, Joonwoo Kwon, Sooyoung Kim, Jungwoo Seo, Shinjae Yoo,
  Yuewei Lin, Jiook Cha
Categories: cs.SD cs.AI cs.LG eess.AS
Comments: Codes will be released upon acceptance
\\ ( https://arxiv.org/abs/2411.15913 ,  24785kb)
------------------------------------------------------------------------------
\\
arXiv:2501.02481
replaced with revised version Wed, 24 Sep 2025 09:52:43 GMT   (8947kb)

Title: Representation Convergence: Mutual Distillation is Secretly a Form of
  Regularization
Authors: Zhengpeng Xie, Jiahang Cao, Changwei Wang, Fan Yang, Marco Hutter,
  Qiang Zhang, Jianxiong Zhang, Renjing Xu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2501.02481 ,  8947kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01375
replaced with revised version Wed, 24 Sep 2025 09:43:29 GMT   (449kb)

Title: Compact Rule-Based Classifier Learning via Gradient Descent
Authors: Javier Fumanal-Idocin, Raquel Fernandez-Peralta, Javier Andreu-Perez
Categories: cs.LG cs.AI cs.LO
\\ ( https://arxiv.org/abs/2502.01375 ,  449kb)
------------------------------------------------------------------------------
\\
arXiv:2502.13143
replaced with revised version Wed, 24 Sep 2025 00:19:51 GMT   (16248kb)

Title: SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and
  Object Manipulation
Authors: Zekun Qi, Wenyao Zhang, Yufei Ding, Runpei Dong, Xinqiang Yu, Jingwen
  Li, Lingyun Xu, Baoyu Li, Xialin He, Guofan Fan, Jiazhao Zhang, Jiawei He,
  Jiayuan Gu, Xin Jin, Kaisheng Ma, Zhizheng Zhang, He Wang, Li Yi
Categories: cs.RO cs.AI cs.CV
Comments: Accepted at NeurIPS 2025 Spotlight
\\ ( https://arxiv.org/abs/2502.13143 ,  16248kb)
------------------------------------------------------------------------------
\\
arXiv:2502.13465
replaced with revised version Wed, 24 Sep 2025 03:30:12 GMT   (930kb)

Title: HawkBench: Investigating Resilience of RAG Methods on Stratified
  Information-Seeking Tasks
Authors: Hongjin Qian, Zheng Liu, Chao Gao, Yankai Wang, Defu Lian and Zhicheng
  Dou
Categories: cs.IR cs.AI cs.CL
Comments: Neurips 25 DB Track, Spotlight
\\ ( https://arxiv.org/abs/2502.13465 ,  930kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19307
replaced with revised version Wed, 24 Sep 2025 07:27:12 GMT   (3035kb)

Title: Anomaly Detection in Complex Dynamical Systems: A Systematic Framework
  Using Embedding Theory and Physics-Inspired Consistency
Authors: Michael Somma, Thomas Gallien, Branka Stojanovic
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2502.19307 ,  3035kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05810
replaced with revised version Wed, 24 Sep 2025 10:24:14 GMT   (121kb)

Title: A Transformer Model for Predicting Chemical Products from Generic SMARTS
  Templates with Data Augmentation
Authors: Derin Ozer, Sylvain Lamprier, Thomas Cauchy, Nicolas Gutowski, Benoit
  Da Mota
Categories: cs.LG cs.AI physics.chem-ph
Comments: ICTAI 2025
\\ ( https://arxiv.org/abs/2503.05810 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05997
replaced with revised version Tue, 23 Sep 2025 21:48:04 GMT   (4937kb)

Title: Learning to Drive by Imitating Surrounding Vehicles
Authors: Yasin Sonmez, Hanna Krasowski, Murat Arcak
Categories: cs.RO cs.AI cs.LG
\\ ( https://arxiv.org/abs/2503.05997 ,  4937kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03792
replaced with revised version Wed, 24 Sep 2025 00:49:22 GMT   (138kb)

Title: DP-LET: An Efficient Spatio-Temporal Network Traffic Prediction
  Framework
Authors: Xintong Wang, Haihan Nan, Ruidong Li and Huaming Wu
Categories: cs.LG cs.AI
Comments: Accepted for presentation to the 2025 IEEE Global Communications
  Conference (IEEE GLOBECOM)
Journal-ref: GLOBECOM 2025 - 2025 IEEE Global Communications Conference
\\ ( https://arxiv.org/abs/2504.03792 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04751 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 09:51:38 GMT   (154kb)

Title: Unsupervised Estimation of Nonlinear Audio Effects: Comparing
  Diffusion-Based and Adversarial approaches
Authors: Eloi Moliner, Michal \v{S}vento, Alec Wright, Lauri Juvela, Pavel
  Rajmic, Vesa V\"alim\"aki
Categories: eess.AS cs.AI
Comments: Accepted to the 28th International Conference on Digital Audio
  Effects (DAFx25)
\\ ( https://arxiv.org/abs/2504.04751 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2504.10552
replaced with revised version Wed, 24 Sep 2025 10:29:39 GMT   (6029kb)

Title: LEMUR Neural Network Dataset: Towards Seamless AutoML
Authors: Arash Torabi Goodarzi, Roman Kochnev, Waleed Khalid, Hojjat Torabi
  Goudarzi, Furui Qin, Tolgay Atinc Uzun, Yashkumar Sanjaybhai Dhameliya, Yash
  Kanubhai Kathiriya, Zofia Antonina Bentyn, Dmitry Ignatov, Radu Timofte
Categories: cs.LG cs.AI cs.CV cs.DL
\\ ( https://arxiv.org/abs/2504.10552 ,  6029kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09262 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 05:45:47 GMT   (8532kb)

Title: EDBench: Large-Scale Electron Density Data for Molecular Modeling
Authors: Hongxin Xiang, Ke Li, Mingquan Liu, Zhixiang Cheng, Bin Yao, Wenjie
  Du, Jun Xia, Li Zeng, Xin Jin, Xiangxiang Zeng
Categories: physics.chem-ph cs.AI cs.CV cs.LG
Comments: accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.09262 ,  8532kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11552
replaced with revised version Wed, 24 Sep 2025 04:09:49 GMT   (1942kb)

Title: GSPRec: Temporal-Aware Graph Spectral Filtering for Recommendation
Authors: Ahmad Bin Rabiah, Julian McAuley
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2505.11552 ,  1942kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11595
replaced with revised version Wed, 24 Sep 2025 03:10:33 GMT   (119kb)

Title: Stepwise Guided Policy Optimization: Coloring your Incorrect Reasoning
  in GRPO
Authors: Peter Chen, Xiaopeng Li, Ziniu Li, Xi Chen, Tianyi Lin
Categories: cs.LG cs.AI cs.CL
Comments: 42 pages
\\ ( https://arxiv.org/abs/2505.11595 ,  119kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16196
replaced with revised version Wed, 24 Sep 2025 09:34:19 GMT   (6626kb)

Title: SEM: Enhancing Spatial Understanding for Robust Robot Manipulation
Authors: Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Yiwei Jin, Keyu Li,
  Zhizhong Su
Categories: cs.RO cs.AI cs.CV
\\ ( https://arxiv.org/abs/2505.16196 ,  6626kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00096 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 14:16:30 GMT   (0kb,I)

Title: PathGene: Benchmarking Driver Gene Mutations and Exon Prediction Using
  Multicenter Lung Cancer Histopathology Image Dataset
Authors: Liangrui Pan, Qingchun Liang, Shen Zhao, Songqing Fan, Shaoliang Peng
Categories: q-bio.GN cs.AI
Comments: This submission is being withdrawn because we identified issues in
  the analysis that may affect the results. A corrected version will be
  submitted in the future. The manuscript is withdrawn as it requires
  substantial revision. An improved version will be submitted in the future
\\ ( https://arxiv.org/abs/2506.00096 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00236
replaced with revised version Tue, 23 Sep 2025 18:56:10 GMT   (276kb)

Title: Localized LoRA: A Structured Low-Rank Approximation for Efficient
  Fine-Tuning
Authors: Babak Barazandeh, Subhabrata Majumdar, Om Rajyaguru, George
  Michailidis
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2506.00236 ,  276kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04681
replaced with revised version Tue, 23 Sep 2025 23:45:44 GMT   (459kb)

Title: Urania: Differentially Private Insights into AI Use
Authors: Daogao Liu, Edith Cohen, Badih Ghazi, Peter Kairouz, Pritish Kamath,
  Alexander Knop, Ravi Kumar, Pasin Manurangsi, Adam Sealfon, Da Yu, Chiyuan
  Zhang
Categories: cs.LG cs.AI cs.CL cs.CR cs.CY
Comments: To appear at COLM 2025
\\ ( https://arxiv.org/abs/2506.04681 ,  459kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06290
replaced with revised version Tue, 23 Sep 2025 19:44:10 GMT   (3041kb)

Title: CellCLIP -- Learning Perturbation Effects in Cell Painting via
  Text-Guided Contrastive Learning
Authors: Mingyu Lu, Ethan Weinberger, Chanwoo Kim, Su-In Lee
Categories: cs.LG cs.AI cs.CV
\\ ( https://arxiv.org/abs/2506.06290 ,  3041kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12044
replaced with revised version Wed, 24 Sep 2025 12:57:03 GMT   (2284kb)

Title: Why Do Some Inputs Break Low-Bit LLM Quantization?
Authors: Ting-Yun Chang, Muru Zhang, Jesse Thomason, Robin Jia
Categories: cs.LG cs.AI
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2506.12044 ,  2284kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18240
replaced with revised version Wed, 24 Sep 2025 05:11:08 GMT   (4655kb)

Title: Quantum-Classical Hybrid Quantized Neural Network
Authors: Wenxin Li, Chuan Wang, Hongdong Zhu, Qi Gao, Yin Ma, Hai Wei, Kai Wen
Categories: cs.LG cs.AI physics.optics
\\ ( https://arxiv.org/abs/2506.18240 ,  4655kb)
------------------------------------------------------------------------------
\\
arXiv:2506.19121
replaced with revised version Tue, 23 Sep 2025 19:35:35 GMT   (11496kb)

Title: CUPID: Curating Data your Robot Loves with Influence Functions
Authors: Christopher Agia, Rohan Sinha, Jingyun Yang, Rika Antonova, Marco
  Pavone, Haruki Nishimura, Masha Itkina, Jeannette Bohg
Categories: cs.RO cs.AI cs.LG
Comments: Project page: https://cupid-curation.github.io. 27 pages, 15 figures.
  Accepted to the Conference on Robot Learning (CoRL) 2025
ACM-class: I.2.6; I.2.9
\\ ( https://arxiv.org/abs/2506.19121 ,  11496kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20869
replaced with revised version Wed, 24 Sep 2025 07:46:21 GMT   (2423kb)

Title: Engineering RAG Systems for Real-World Applications: Design,
  Development, and Evaluation
Authors: Md Toufique Hasan, Muhammad Waseem, Kai-Kristian Kemell, Ayman Asad
  Khan, Mika Saari and Pekka Abrahamsson
Categories: cs.SE cs.AI cs.IR
Comments: Published in the Proceedings of the 51st Euromicro Conference on
  Software Engineering and Advanced Applications, SEAA 2025. Lecture Notes in
  Computer Science, volume 16082, pages 143-158. Springer, 2026
ACM-class: D.2.11; I.2.6; H.3.3
Journal-ref: LNCS 16082, 143-158, 2026
DOI: 10.1007/978-3-032-04200-2_10
\\ ( https://arxiv.org/abs/2506.20869 ,  2423kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22095
replaced with revised version Wed, 24 Sep 2025 15:51:44 GMT   (112kb)

Title: Beyond Simple Graphs: Neural Multi-Objective Routing on Multigraphs
Authors: Filip Rydin, Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani,
  Bal\'azs Kulcs\'ar
Categories: cs.LG cs.AI
Comments: 29 pages, 6 Figures
\\ ( https://arxiv.org/abs/2506.22095 ,  112kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22397 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 14:42:00 GMT   (28955kb)

Title: HAZEMATCHING: Dehazing Light Microscopy Images with Guided Conditional
  Flow Matching
Authors: Anirban Ray, Ashesh, Florian Jug
Categories: eess.IV cs.AI cs.CV
Comments: 4 figures, 9 pages + refs, 38 pages total (including supplement), 23
  supplementary figures
\\ ( https://arxiv.org/abs/2506.22397 ,  28955kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04164
replaced with revised version Wed, 24 Sep 2025 16:36:27 GMT   (2893kb)

Title: Structure As Search: Unsupervised Permutation Learning for Combinatorial
  Optimization
Authors: Yimeng Min, Carla P. Gomes
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2507.04164 ,  2893kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04487
replaced with revised version Wed, 24 Sep 2025 08:26:00 GMT   (4384kb)

Title: LoSiA: Efficient High-Rank Fine-Tuning via Subnet Localization and
  Optimization
Authors: Xujia Wang, Yunjia Qi, Bin Xu
Categories: cs.LG cs.AI
Comments: Accepted to EMNLP 2025 (Oral); 20 pages, 12 figures
\\ ( https://arxiv.org/abs/2507.04487 ,  4384kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08011 (*cross-listing*)
replaced with revised version Tue, 23 Sep 2025 21:31:36 GMT   (194kb)

Title: Energy Management for Renewable-Colocated Artificial Intelligence Data
  Centers
Authors: Siying Li and Lang Tong and Timothy D. Mount
Categories: math.OC cs.AI cs.SY eess.SY
\\ ( https://arxiv.org/abs/2507.08011 ,  194kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08540
replaced with revised version Wed, 24 Sep 2025 16:51:16 GMT   (87kb)

Title: White-Basilisk: A Hybrid Model for Code Vulnerability Detection
Authors: Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris
  Ioannidis
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2507.08540 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2507.12574
replaced with revised version Wed, 24 Sep 2025 16:03:34 GMT   (3387kb)

Title: Assay2Mol: large language model-based drug design using BioAssay context
Authors: Yifan Deng, Spencer S. Ericksen, Anthony Gitter
Categories: cs.LG cs.AI q-bio.QM
Comments: 26 pages, 10 figures
\\ ( https://arxiv.org/abs/2507.12574 ,  3387kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21179
replaced with revised version Wed, 24 Sep 2025 15:38:14 GMT   (5628kb)

Title: CANDLE: A Cross-Modal Agentic Knowledge Distillation Framework for
  Interpretable Sarcopenia Diagnosis
Authors: Yuqi Jin, Zhenhao Shuai, Zihan Hu, Weiteng Zhang, Weihao Xie, Jianwei
  Shuai, Xian Shen, Zhen Feng
Categories: cs.LG cs.AI
Comments: 11 pages, 4 figures, 5 tables
\\ ( https://arxiv.org/abs/2507.21179 ,  5628kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00935
replaced with revised version Wed, 24 Sep 2025 06:08:42 GMT   (817kb)

Title: Measuring Harmfulness of Computer-Using Agents
Authors: Aaron Xuxiang Tian, Ruofan Zhang, Janet Tang, Ji Wang, Tianyu Shi,
  Jiaxin Wen
Categories: cs.CR cs.AI
Comments: 17 pages, 9 figures
ACM-class: I.2.7; K.6.5
\\ ( https://arxiv.org/abs/2508.00935 ,  817kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01961
replaced with revised version Wed, 24 Sep 2025 10:03:27 GMT   (207kb)

Title: Kron-LoRA: Hybrid Kronecker-LoRA Adapters for Scalable, Sustainable
  Fine-tuning
Authors: Yixin Shen
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2508.01961 ,  207kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05473
replaced with revised version Tue, 23 Sep 2025 18:29:44 GMT   (287kb)

Title: Embedding Alignment in Code Generation for Audio
Authors: Sam Kouteili, Hiren Madhu, George Typaldos, Mark Santolucito
Categories: cs.MM cs.AI cs.SD eess.AS
Comments: Accepted to NeurIPS 2025 AI4Music Workshop
\\ ( https://arxiv.org/abs/2508.05473 ,  287kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08345
replaced with revised version Wed, 24 Sep 2025 06:30:04 GMT   (1775kb)

Title: Do AI Companies Make Good on Voluntary Commitments to the White House?
Authors: Jennifer Wang, Kayla Huang, Kevin Klyman, Rishi Bommasani
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2508.08345 ,  1775kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18337 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 06:28:07 GMT   (0kb,I)

Title: EAI-Avatar: Emotion-Aware Interactive Talking Head Generation
Authors: Haijie Yang, Zhenyu Zhang, Hao Tang, Jianjun Qian, Jian Yang
Categories: eess.AS cs.AI cs.SD
Comments: The submission is withdrawn at the request of the authors due to
  internal reasons within the research team
\\ ( https://arxiv.org/abs/2508.18337 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04303
replaced with revised version Wed, 24 Sep 2025 04:51:50 GMT   (454kb)

Title: HumAIne-Chatbot: Real-Time Personalized Conversational AI via
  Reinforcement Learning
Authors: Georgios Makridis, George Fragiadakis, Jorge Oliveira, Tomaz Saraiva,
  Philip Mavrepis, Georgios Fatouros, Dimosthenis Kyriazis
Categories: cs.HC cs.AI
Comments: 11 pages, 4 figures, IEEE conference format
\\ ( https://arxiv.org/abs/2509.04303 ,  454kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06385
replaced with revised version Wed, 24 Sep 2025 16:25:58 GMT   (1060kb)

Title: Beyond the Pre-Service Horizon: Infusing In-Service Behavior for
  Improved Financial Risk Forecasting
Authors: Senhao Liu, Zhiyu Guo, Zhiyuan Ji, Yueguo Chen, Yateng Tang, Yunhai
  Wang, Xuehao Zheng, and Xiang Ao
Categories: cs.LG cs.AI
Comments: Accepted to IEEE ICDM 2025
\\ ( https://arxiv.org/abs/2509.06385 ,  1060kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09744
replaced with revised version Wed, 24 Sep 2025 06:55:13 GMT   (4312kb)

Title: Structure Matters: Brain Graph Augmentation via Learnable Edge Masking
  for Data-efficient Psychiatric Diagnosis
Authors: Mujie Liu, Chenze Wang, Liping Chen, Nguyen Linh Dan Le, Niharika
  Tewari, Ting Dang, Jiangang Ma, and Feng Xia
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.09744 ,  4312kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11543
replaced with revised version Wed, 24 Sep 2025 15:05:34 GMT   (5441kb)

Title: UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning
Authors: Zhengxi Lu, Jiabo Ye, Fei Tang, Yongliang Shen, Haiyang Xu, Ziwei
  Zheng, Weiming Lu, Ming Yan, Fei Huang, Jun Xiao, Yueting Zhuang
Categories: cs.LG cs.AI
Comments: 22 pages, 17 figures
\\ ( https://arxiv.org/abs/2509.11543 ,  5441kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11686
replaced with revised version Wed, 24 Sep 2025 07:06:41 GMT   (264kb)

Title: Do Code Semantics Help? A Comprehensive Study on Execution Trace-Based
  Information for Code Large Language Models
Authors: Jian Wang, Xiaofei Xie, Qiang Hu, Shangqing Liu, Yi Li
Categories: cs.SE cs.AI
Comments: EMNLP2025-findings https://openreview.net/forum?id=d4ICISW2T4
\\ ( https://arxiv.org/abs/2509.11686 ,  264kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16295
replaced with revised version Tue, 23 Sep 2025 18:30:24 GMT   (1496kb)

Title: Patterns in the Transition From Founder-Leadership to Community
  Governance of Open Source
Authors: Mobina Noori, Mahasweta Chakraborti, Amy X Zhang, Seth Frey
Categories: cs.CY cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.16295 ,  1496kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16931
replaced with revised version Wed, 24 Sep 2025 09:26:28 GMT   (240kb)

Title: Equip Pre-ranking with Target Attention by Residual Quantization
Authors: Yutong Li, Yu Zhu, Yichen Qiao, Ziyu Guan, Lv Shao, Tong Liu and Bo
  Zheng
Categories: cs.IR cs.AI cs.LG
Comments: 5 pages, 2 figures, submitted to WSDM 2026 Short Paper Track
ACM-class: I.2.0; I.5.0; I.7.0
\\ ( https://arxiv.org/abs/2509.16931 ,  240kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18127
replaced with revised version Wed, 24 Sep 2025 03:58:59 GMT   (8064kb)

Title: Safe-SAIL: Towards a Fine-grained Safety Landscape of Large Language
  Models via Sparse Autoencoder Interpretation Framework
Authors: Jiaqi Weng, Han Zheng, Hanyu Zhang, Qinqin He, Jialing Tao, Hui Xue,
  Zhixuan Chu, Xiting Wang
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.18127 ,  8064kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18133
replaced with revised version Wed, 24 Sep 2025 08:15:17 GMT   (313kb)

Title: Self-Evolving LLMs via Continual Instruction Tuning
Authors: Jiazheng Kang, Le Huang, Cheng Hou, Zhe Zhao, Zhenxiang Yan, Chuan
  Shi, and Ting Bai
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.18133 ,  313kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18562
replaced with revised version Wed, 24 Sep 2025 03:29:46 GMT   (305kb)

Title: CPCLDETECTOR: Knowledge Enhancement and Alignment Selection for Chinese
  Patronizing and Condescending Language Detection
Authors: Jiaxun Yang, Yifei Han, Long Zhang, Yujie Liu, Bin Li, Bo Gao, Yangfan
  He, Kejia Zhan
Categories: cs.MM cs.AI
Comments: Submitted to ICASSP 2025
\\ ( https://arxiv.org/abs/2509.18562 ,  305kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18644
replaced with revised version Wed, 24 Sep 2025 07:38:56 GMT   (2028kb)

Title: Do You Need Proprioceptive States in Visuomotor Policies?
Authors: Juntu Zhao, Wenbo Lu, Di Zhang, Yufeng Liu, Yushen Liang, Tianluo
  Zhang, Yifeng Cao, Junyuan Xie, Yingdong Hu, Shengjie Wang, Junliang Guo,
  Dequan Wang, Yang Gao
Categories: cs.RO cs.AI
Comments: Project page: https://statefreepolicy.github.io
\\ ( https://arxiv.org/abs/2509.18644 ,  2028kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19277 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 08:17:37 GMT   (4390kb)

Title: MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion
  interactive segmentation of neurofibromas in whole-body MRI
Authors: Georgii Kolokolnikov, Marie-Lena Schmalhofer, Sophie Goetz, Lennart
  Well, Said Farschtschi, Victor-Felix Mautner, Inka Ristow, Rene Werner
Categories: eess.IV cs.AI cs.CV cs.LG
\\ ( https://arxiv.org/abs/2509.19277 ,  4390kb)
------------------------------------------------------------------------------
\\
arXiv:2407.00890 (*cross-listing*)
replaced with revised version Tue, 23 Sep 2025 18:27:49 GMT   (828kb)

Title: Macroeconomic Forecasting with Large Language Models
Authors: Andrea Carriero and Davide Pettenuzzo and Shubhranshu Shekhar
Categories: econ.EM cs.CL cs.LG
\\ ( https://arxiv.org/abs/2407.00890 ,  828kb)
------------------------------------------------------------------------------
\\
arXiv:2408.15176
replaced with revised version Wed, 24 Sep 2025 09:18:09 GMT   (1947kb)

Title: Unifying Symbolic Music Arrangement: Track-Aware Reconstruction and
  Structured Tokenization
Authors: Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Qihao Liang, Torin
  Hopkins Ye Wang
Categories: cs.SD cs.CL eess.AS
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2408.15176 ,  1947kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14480
replaced with revised version Wed, 24 Sep 2025 13:49:49 GMT   (25994kb)

Title: GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question
  Answering
Authors: Saumya Saxena, Blake Buchanan, Chris Paxton, Peiqi Liu, Bingqing Chen,
  Narunas Vaskevicius, Luigi Palmieri, Jonathan Francis, Oliver Kroemer
Categories: cs.RO cs.CL cs.CV cs.LG
Comments: Project website: https://saumyasaxena.github.io/grapheqa
\\ ( https://arxiv.org/abs/2412.14480 ,  25994kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14264
replaced with revised version Wed, 24 Sep 2025 15:47:49 GMT   (1296kb)

Title: AAPO: Enhancing the Reasoning Capabilities of LLMs with Advantage
  Momentum
Authors: Jian Xiong, Jingbo Zhou, Jingyong Ye, Qiang Huang, Dejing Dou
Categories: cs.LG cs.CL
Comments: 18 pages, 4 figures
\\ ( https://arxiv.org/abs/2505.14264 ,  1296kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24195
replaced with revised version Tue, 23 Sep 2025 19:39:08 GMT   (2448kb)

Title: WikiGap: Promoting Epistemic Equity by Surfacing Knowledge Gaps Between
  English Wikipedia and other Language Editions
Authors: Zining Wang, Yuxuan Zhang, Dongwook Yoon, Nicholas Vincent, Farhan
  Samir, Vered Shwartz
Categories: cs.HC cs.CL
\\ ( https://arxiv.org/abs/2505.24195 ,  2448kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16893
replaced with revised version Wed, 24 Sep 2025 02:18:08 GMT   (4027kb)

Title: DRES: Fake news detection by dynamic representation and ensemble
  selection
Authors: Faramarz Farhangian, Leandro A. Ensina, George D. C. Cavalcanti,
  Rafael M. O. Cruz
Categories: cs.LG cs.CL
Comments: Accepted as oral presentation at EMNLP 2025
\\ ( https://arxiv.org/abs/2509.16893 ,  4027kb)
------------------------------------------------------------------------------
\\
arXiv:2212.12322 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 07:26:13 GMT   (13229kb)

Title: Infrared Image Super-Resolution: Systematic Review, and Future Trends
Authors: Yongsong Huang, Tomo Miyazaki, Xiaofeng Liu, Shinichiro Omachi
Categories: eess.IV cs.CV cs.LG
Comments: This work has been submitted to the IEEE JSTARS for possible
  publication
\\ ( https://arxiv.org/abs/2212.12322 ,  13229kb)
------------------------------------------------------------------------------
\\
arXiv:2306.11123 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 15:57:10 GMT   (18814kb)

Title: To Fold or Not to Fold: Graph Regularized Tensor Train for Visual Data
  Completion
Authors: Le Xu, Lei Cheng, Ngai Wong, and Yik-Chung Wu
Categories: eess.SP cs.CV
\\ ( https://arxiv.org/abs/2306.11123 ,  18814kb)
------------------------------------------------------------------------------
\\
arXiv:2409.02529
replaced with revised version Wed, 24 Sep 2025 02:56:48 GMT   (5017kb)

Title: Sample what you cant compress
Authors: Vighnesh Birodkar, Gabriel Barcik, James Lyon, Sergey Ioffe, David
  Minnen, Joshua V. Dillon
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2409.02529 ,  5017kb)
------------------------------------------------------------------------------
\\
arXiv:2501.16803
replaced with revised version Wed, 24 Sep 2025 07:11:50 GMT   (6472kb)

Title: RG-Attn: Radian Glue Attention for Multi-modality Multi-agent
  Cooperative Perception
Authors: Lantao Li, Kang Yang, Wenqi Zhang, Xiaoxue Wang and Chen Sun
Categories: cs.RO cs.CV cs.NI eess.IV
Comments: Accepted by ICCV 2025 DriveX workshop (Final Version)
\\ ( https://arxiv.org/abs/2501.16803 ,  6472kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18485 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 16:14:54 GMT   (3309kb)

Title: Deciphering Functions of Neurons in Vision-Language Models
Authors: Jiaqi Xu, Cuiling Lan, Yan Lu
Categories: q-bio.NC cs.CV
Comments: Accepted by the 31st ACM International Conference on Multimedia (ACM
  MM 2025)
\\ ( https://arxiv.org/abs/2502.18485 ,  3309kb)
------------------------------------------------------------------------------
\\
arXiv:2504.02045
replaced with revised version Tue, 23 Sep 2025 20:29:33 GMT   (28991kb)

Title: Generating 360{\deg} Video is What You Need For a 3D Scene
Authors: Zhaoyang Zhang, Yannick Hold-Geoffroy, Milo\v{s} Ha\v{s}an, Ziwen
  Chen, Fujun Luan, Julie Dorsey and Yiwei Hu
Categories: cs.GR cs.CV
Comments: SIGGRAPH Asia 2025. Project Page:
  \url{https://zhaoyangzh.github.io/projects/worldprompter/}
\\ ( https://arxiv.org/abs/2504.02045 ,  28991kb)
------------------------------------------------------------------------------
\\
arXiv:2504.18442 (*cross-listing*)
replaced with revised version Wed, 24 Sep 2025 15:59:22 GMT   (5419kb)

Title: Imaging Biomarkers for Neurodegenerative Diseases from Detailed
  Segmentation of Medial Temporal Lobe Subregions on in vivo Brain MRI Using
  Upsampling Strategy Guided by High-resolution ex vivo MRI
Authors: Yue Li, Pulkit Khandelwal, Long Xie, Laura E. M. Wisse, Amanda E.
  Denning, Christopher A. Brown, Emily McGrew, Sydney A. Lim, Niyousha
  Sadeghpour, Sadhana Ravikumar, Ranjit Ittyerah, Eunice Chung, Daniel T. Ohm,
  Nidhi S. Mundada, Mar\'ia Mercedes \'I\~niguez de Onzo\~no Mart\'in, Mar\'ia
  del Mar Arroyo Jim\'enez, Monica M\~unoz, Maria del Pilar Marcos Rabal, David
  J. Irwin, Edward B. Lee, Ricardo Insausti, Sandhitsu R. Das, David A. Wolk,
  Paul A. Yushkevich
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2504.18442 ,  5419kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08643
replaced with revised version Wed, 24 Sep 2025 02:57:21 GMT   (14291kb)

Title: X-Part: high fidelity and structure coherent shape decomposition
Authors: Xinhao Yan, Jiachen Xu, Yang Li, Changfeng Ma, Yunhan Yang, Chunshi
  Wang, Zibo Zhao, Zeqiang Lai, Yunfei Zhao, Zhuo Chen, Chunchao Guo
Categories: cs.GR cs.CV
Comments: Tech Report, Project Page:
  https://yanxinhao.github.io/Projects/X-Part/
\\ ( https://arxiv.org/abs/2509.08643 ,  14291kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18786
replaced with revised version Wed, 24 Sep 2025 13:40:17 GMT   (4835kb)

Title: Human-Interpretable Uncertainty Explanations for Point Cloud
  Registration
Authors: Johannes A. Gaus, Loris Schneider, Yitian Shi, Jongseok Lee, Rania
  Rayyes, Rudolph Triebel
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/2509.18786 ,  4835kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12144
replaced with revised version Tue, 23 Sep 2025 20:06:35 GMT   (446kb)

Title: Proof-of-Social-Capital: A Consensus Protocol Replacing Stake for Social
  Capital
Authors: Juraj Mariani, Ivan Homoliak
Categories: cs.CR cs.DC
\\ ( https://arxiv.org/abs/2505.12144 ,  446kb)
------------------------------------------------------------------------------
\\
arXiv:2506.23906
replaced with revised version Wed, 24 Sep 2025 15:52:13 GMT   (523kb)

Title: Segmented Operations using Matrix Multiplications
Authors: Aleksandros Sobczyk, Giuseppe Sorrentino, Anastasios Zouzias
Categories: cs.DS cs.CC cs.DC
\\ ( https://arxiv.org/abs/2506.23906 ,  523kb)
------------------------------------------------------------------------------
\\
arXiv:2505.08060
replaced with revised version Mon, 22 Sep 2025 18:14:09 GMT   (3873kb)

Title: Coverage Path Planning for Holonomic UAVs via Uniaxial-Feasible,
  Gap-Severity Guided Decomposition
Authors: Pedro Antonio Alarcon Granadeno, Jane Cleland-Huang
Categories: cs.RO cs.MA
Comments: 8 pages, 4 figures,
\\ ( https://arxiv.org/abs/2505.08060 ,  3873kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
	