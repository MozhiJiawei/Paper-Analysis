Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 200251 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月8日 12:25
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Thu  4 Sep 25 18:00:00 GMT  to  Fri  5 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.04505
Date: Tue, 2 Sep 2025 13:50:36 GMT   (340kb)

Title: The Ethical Compass of the Machine: Evaluating Large Language Models for
  Decision Support in Construction Project Management
Authors: Somtochukwu Azie, Yiping Meng
Categories: cs.AI cs.CY
Comments: 16 Pages
\\
  The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.
\\ ( https://arxiv.org/abs/2509.04505 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04642
Date: Thu, 4 Sep 2025 20:00:37 GMT   (70kb)

Title: Maestro: Joint Graph & Config Optimization for Reliable AI Agents
Authors: Wenxiao Wang, Priyatham Kattakinda, Soheil Feizi
Categories: cs.AI cs.CL cs.LG cs.SE
Comments: Technical Report by RELAI.ai
\\
  Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.
\\ ( https://arxiv.org/abs/2509.04642 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04646
Date: Thu, 4 Sep 2025 20:07:31 GMT   (961kb)

Title: Towards Personalized Explanations for Health Simulations: A
  Mixed-Methods Framework for Stakeholder-Centric Summarization
Authors: Philippe J. Giabbanelli and Ameeta Agrawal
Categories: cs.AI cs.ET
Comments: Accepted at the AAAI 2025 Fall Symposium Series. November 6-8, 2025,
  Arlington, VA, USA
\\
  Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.
\\ ( https://arxiv.org/abs/2509.04646 ,  961kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04676
Date: Thu, 4 Sep 2025 21:40:32 GMT   (1998kb)

Title: An Approach to Grounding AI Model Evaluations in Human-derived Criteria
Authors: Sasha Mitts
Categories: cs.AI cs.HC
Comments: 4 figures, 6 pages, presented at CHI 2025 Workshop on Human-AI
  Interaction for Augmented Reasoning
\\
  In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.
\\ ( https://arxiv.org/abs/2509.04676 ,  1998kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04731
Date: Fri, 5 Sep 2025 01:03:51 GMT   (20kb)

Title: Language-Driven Hierarchical Task Structures as Explicit World Models
  for Multi-Agent Learning
Authors: Brennen Hill
Categories: cs.AI cs.CL cs.LG cs.MA cs.RO
MSC-class: 68T05, 90C40, 91A26, 68T42, 93E35
ACM-class: I.2.11; I.2.6; I.2.8; I.2.9; I.2.7
\\
  The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.
\\ ( https://arxiv.org/abs/2509.04731 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04791
Date: Fri, 5 Sep 2025 04:05:27 GMT   (5173kb)

Title: What-If Analysis of Large Language Models: Explore the Game World Using
  Proactive Thinking
Authors: Yuan Sui, Yanming Zhang, Yi Liao, Yu Gu, Guohua Tang, Zhongqian Sun,
  Wei Yang, Bryan Hooi
Categories: cs.AI
Comments: arXiv admin note: text overlap with arXiv:2508.21365
\\
  Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.
\\ ( https://arxiv.org/abs/2509.04791 ,  5173kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04809
Date: Fri, 5 Sep 2025 05:09:09 GMT   (1461kb)

Title: TalkToAgent: A Human-centric Explanation of Reinforcement Learning
  Agents with Large Language Models
Authors: Haechang Kim, Hao Chen, Can Li, Jong Min Lee
Categories: cs.AI cs.HC
Comments: 31 pages total
\\
  Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.
\\ ( https://arxiv.org/abs/2509.04809 ,  1461kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04847
Date: Fri, 5 Sep 2025 06:55:15 GMT   (148kb)

Title: Collaboration and Conflict between Humans and Language Models through
  the Lens of Game Theory
Authors: Mukul Singh, Arjun Radhakrishna, Sumit Gulwani
Categories: cs.AI
Comments: 9 pages
\\
  Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.
\\ ( https://arxiv.org/abs/2509.04847 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04871
Date: Fri, 5 Sep 2025 07:36:12 GMT   (333kb)

Title: Cloning a Conversational Voice AI Agent from Call\,Recording Datasets
  for Telesales
Authors: Krittanon Kaewtawee, Wachiravit Modecrua, Krittin Pachtrachai,
  Touchapon Kraisingkorn
Categories: cs.AI cs.LG
Comments: 10 pages, 4 figures
\\
  Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.
\\ ( https://arxiv.org/abs/2509.04871 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04876
Date: Fri, 5 Sep 2025 07:44:05 GMT   (632kb)

Title: OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in
  Multi-Agent LLM Collaboration
Authors: Jusheng Zhang, Yijia Fan, Kaitong Cai, Xiaofei Sun, Keze Wang
Categories: cs.AI
Comments: Accepted at EMNLP 2025 (Long Paper)
\\
  This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.
\\ ( https://arxiv.org/abs/2509.04876 ,  632kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04908
Date: Fri, 5 Sep 2025 08:24:12 GMT   (6621kb)

Title: SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and
  Parsing
Authors: Hongyi Jing, Jiafu Chen, Chen Rao, Ziqiang Dang, Jiajie Teng, Tianyi
  Chu, Juncheng Mo, Shuo Fang, Huaizhong Lin, Rui Lv, Chenguang Ma, Lei Zhao
Categories: cs.AI cs.CL cs.CV cs.HC
\\
  The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.
\\ ( https://arxiv.org/abs/2509.04908 ,  6621kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04926
Date: Fri, 5 Sep 2025 08:44:27 GMT   (5543kb,D)

Title: Towards Ontology-Based Descriptions of Conversations with
  Qualitatively-Defined Concepts
Authors: Barbara Gendron (LORIA, UL), Ga\"el Guibon (LIPN, LORIA), Mathieu
  D'aquin (LORIA, UL)
Categories: cs.AI cs.CL cs.LG
Comments: Accepted at TOTh 2025 (Terminology \& Ontology: Theories and
  applications)
\\
  The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.
\\ ( https://arxiv.org/abs/2509.04926 ,  5543kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04979
Date: Fri, 5 Sep 2025 10:04:33 GMT   (887kb)

Title: Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for
  Ranking Agents
Authors: Rajesh Tembarai Krishnamachari and Srividya Rajesh
Categories: cs.AI
\\
  AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.
\\ ( https://arxiv.org/abs/2509.04979 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05007
Date: Fri, 5 Sep 2025 11:14:11 GMT   (2170kb)

Title: Sticker-TTS: Learn to Utilize Historical Experience with a
  Sticker-driven Test-Time Scaling Framework
Authors: Jie Chen, Jinhao Jiang, Yingqian Min, Zican Dong, Shijie Wang, Wayne
  Xin Zhao, Ji-Rong Wen
Categories: cs.AI cs.CL
Comments: 11 pages, 1 figures, 5 tables
ACM-class: I.2.7
\\
  Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.
\\ ( https://arxiv.org/abs/2509.05007 ,  2170kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05072
Date: Fri, 5 Sep 2025 13:13:19 GMT   (1475kb)

Title: Finding your MUSE: Mining Unexpected Solutions Engine
Authors: Nir Sweed, Hanit Hakim, Ben Wolfson, Hila Lifshitz, Dafna Shahaf
Categories: cs.AI cs.CL
\\
  Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.
\\ ( https://arxiv.org/abs/2509.05072 ,  1475kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05091
Date: Fri, 5 Sep 2025 13:30:17 GMT   (24859kb)

Title: ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed
  Feedback
Authors: Matteo Bortoletto, Yichao Zhou, Lance Ying, Tianmin Shu, Andreas
  Bulling
Categories: cs.AI cs.MA
Comments: Website at https://www.matteobortoletto.org/protom/
\\
  While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.
\\ ( https://arxiv.org/abs/2509.05091 ,  24859kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05139
Date: Fri, 5 Sep 2025 14:30:41 GMT   (41kb)

Title: Evaluation and Comparison Semantics for ODRL
Authors: Jaime Osvaldo Salas, Paolo Pareti, Semih Yumu\c{s}ak, Soulmaz
  Gheisari, Luis-Daniel Ib\'a\~nez, George Konstantinidis
Categories: cs.AI
Comments: Accepted as a full paper at the 14th International Joint Conference
  on Knowledge Graphs (IJCKG 2025). This is the submitted manuscript, the
  accepted manuscript will be published by Springer Nature
\\
  We consider the problem of evaluating, and comparing computational policies
in the Open Digital Rights Language (ODRL), which has become the de facto
standard for governing the access and usage of digital resources. Although
preliminary progress has been made on the formal specification of the
language's features, a comprehensive formal semantics of ODRL is still missing.
In this paper, we provide a simple and intuitive formal semantics for ODRL that
is based on query answering. Our semantics refines previous formalisations, and
is aligned with the latest published specification of the language (2.2).
Building on our evaluation semantics, and motivated by data sharing scenarios,
we also define and study the problem of comparing two policies, detecting
equivalent, more restrictive or more permissive policies.
\\ ( https://arxiv.org/abs/2509.05139 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05263
Date: Fri, 5 Sep 2025 17:22:33 GMT   (13914kb)

Title: LatticeWorld: A Multimodal Large Language Model-Empowered Framework for
  Interactive Complex World Generation
Authors: Yinglin Duan, Zhengxia Zou, Tongwei Gu, Wei Jia, Zhan Zhao, Luyi Xu,
  Xinzhu Liu, Hao Jiang, Kang Chen, Shuang Qiu
Categories: cs.AI cs.CV cs.LG
\\
  Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18
\\ ( https://arxiv.org/abs/2509.05263 ,  13914kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04455
Date: Wed, 27 Aug 2025 03:13:40 GMT   (1875kb)

Title: INSEva: A Comprehensive Chinese Benchmark for Large Language Models in
  Insurance
Authors: Shisong Chen, Qian Zhu, Wenyan Yang, Chengyi Yang, Zhong Wang, Ping
  Wang, Xuan Lin, Bo Xu, Daqian Li, Chao Yuan, Licai Qi, Wanqing Xu, sun
  zhenxing, Xin Lu, Shiqiang Xiong, Chao Chen, Haixiang Hu, Yanghua Xiao
Categories: cs.CL
Comments: Under review
\\
  Insurance, as a critical component of the global financial system, demands
high standards of accuracy and reliability in AI applications. While existing
benchmarks evaluate AI capabilities across various domains, they often fail to
capture the unique characteristics and requirements of the insurance domain. To
address this gap, we present INSEva, a comprehensive Chinese benchmark
specifically designed for evaluating AI systems' knowledge and capabilities in
insurance. INSEva features a multi-dimensional evaluation taxonomy covering
business areas, task formats, difficulty levels, and cognitive-knowledge
dimension, comprising 38,704 high-quality evaluation examples sourced from
authoritative materials. Our benchmark implements tailored evaluation methods
for assessing both faithfulness and completeness in open-ended responses.
Through extensive evaluation of 8 state-of-the-art Large Language Models
(LLMs), we identify significant performance variations across different
dimensions. While general LLMs demonstrate basic insurance domain competency
with average scores above 80, substantial gaps remain in handling complex,
real-world insurance scenarios. The benchmark will be public soon.
\\ ( https://arxiv.org/abs/2509.04455 ,  1875kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04456
Date: Wed, 27 Aug 2025 03:44:56 GMT   (642kb)

Title: Mentalic Net: Development of RAG-based Conversational AI and Evaluation
  Framework for Mental Health Support
Authors: Anandi Dutta, Shivani Mruthyunjaya, Jessica Saddington, Kazi Sifatul
  Islam
Categories: cs.CL
Comments: Preprint Version, Accepted in ISEMV 2025
\\
  The emergence of large language models (LLMs) has unlocked boundless
possibilities, along with significant challenges. In response, we developed a
mental health support chatbot designed to augment professional healthcare, with
a strong emphasis on safe and meaningful application. Our approach involved
rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and
bias. We employed a retrieval-augmented generation (RAG) framework, integrated
prompt engineering, and fine-tuned a pre-trained model on novel datasets. The
resulting system, Mentalic Net Conversational AI, achieved a BERT Score of
0.898, with other evaluation metrics falling within satisfactory ranges. We
advocate for a human-in-the-loop approach and a long-term, responsible strategy
in developing such transformative technologies, recognizing both their
potential to change lives and the risks they may pose if not carefully managed.
\\ ( https://arxiv.org/abs/2509.04456 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04457
Date: Wed, 27 Aug 2025 09:17:42 GMT   (4682kb)

Title: Do MLLMs Really Understand the Charts?
Authors: Xiao Zhang, Dongyuan Li, Liuyu Xiang, Yao Zhang, Cheng Zhong, Zhaofeng
  He
Categories: cs.CL
Comments: 19 pages,15 figures
\\
  Although Multimodal Large Language Models (MLLMs) have demonstrated
increasingly impressive performance in chart understanding, most of them
exhibit alarming hallucinations and significant performance degradation when
handling non-annotated charts. Therefore, a question arises: Do MLLMs really
understand the charts? Since a human is capable of understanding charts and
estimating the values by visual reasoning, we first carefully establish a
comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the
visual reasoning abilities of MLLMs on non-annotated charts. We argue that
MLLMs are primarily relying on recognition rather than reasoning to interpret
the charts. To steer MLLMs to reasonable chart understanding, we propose
ChartReasoner that mimics human behavior by grounding their estimation in chart
understanding. Extensive results on the proposed CRBench show that
ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even
compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also
demonstrates the visual reasoning abilities in general chart comprehension on
public benchmarks, leading to significant performance gains and enabling MLLMs
to rationally understand the charts. The code and dataset will be publicly
available upon publication.
\\ ( https://arxiv.org/abs/2509.04457 ,  4682kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04458
Date: Wed, 27 Aug 2025 10:52:43 GMT   (256kb)

Title: Predicting Failures of LLMs to Link Biomedical Ontology Terms to
  Identifiers Evidence Across Models and Ontologies
Authors: Daniel B. Hier, Steven Keith Platt, Tayo Obafemi-Ajayi
Categories: cs.CL
Comments: Accepted for Presentation, IEEE-EMBS International Conference on
  Biomedical and Health Informatics (BHI 25), Atlanta GA USA, October 26-29,
  2025
ACM-class: I.2
\\
  Large language models often perform well on biomedical NLP tasks but may fail
to link ontology terms to their correct identifiers. We investigate why these
failures occur by analyzing predictions across two major ontologies, Human
Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o
and LLaMa 3.1 405B. We evaluate nine candidate features related to term
familiarity, identifier usage, morphology, and ontology structure. Univariate
and multivariate analyses show that exposure to ontology identifiers is the
strongest predictor of linking success.
\\ ( https://arxiv.org/abs/2509.04458 ,  256kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04459
Date: Wed, 27 Aug 2025 16:01:58 GMT   (3351kb)

Title: Uncertainty-Aware Collaborative System of Large and Small Models for
  Multimodal Sentiment Analysis
Authors: Shiqin Han, Manning Gao, Menghua Jiang, Yuncheng Jiang, Haifeng Hu,
  Sijie Mai
Categories: cs.CL cs.LG
\\
  The advent of Multimodal Large Language Models (MLLMs) has significantly
advanced the state-of-the-art in multimodal machine learning, yet their
substantial computational demands present a critical barrier to real-world
deployment. Conversely, smaller, specialized models offer high efficiency but
often at the cost of performance. To reconcile this performance-efficiency
trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS)
that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a
lightweight baseline model for multimodal sentiment analysis. The core of our
system is an uncertainty-driven cascade mechanism, where the efficient small
model first acts as a rapid filter for all input samples. Only those samples
yielding high predictive uncertainty, thereby indicating greater difficulty,
are selectively escalated to the MLLM for more sophisticated analysis.
Furthermore, our system introduces advanced strategies to handle ambiguous or
conflicting predictions, including weighted averaging for predictions of
similar polarity and a prompt-based cross-verification to resolve conflicting
predictions when both models exhibit high uncertainty. This
sample-difficulty-aware approach allows for a dynamic allocation of
computational resources, drastically reducing inference costs while retaining
the high accuracy of MLLM. Extensive experiments on benchmark datasets
demonstrate that our proposed method achieves state-of-the-art performance,
while requiring only a fraction of the computational resources compared to
using a standalone MLLM.
\\ ( https://arxiv.org/abs/2509.04459 ,  3351kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04460
Date: Thu, 28 Aug 2025 06:03:11 GMT   (377kb)

Title: CoCoNUTS: Concentrating on Content while Neglecting Uninformative
  Textual Styles for AI-Generated Peer Review Detection
Authors: Yihan Chen, Jiawei Chen, Guozhao Mo, Xuanang Chen, Ben He, Xianpei
  Han, and Le Sun
Categories: cs.CL cs.AI
\\
  The growing integration of large language models (LLMs) into the peer review
process presents potential risks to the fairness and reliability of scholarly
evaluation. While LLMs offer valuable assistance for reviewers with language
refinement, there is growing concern over their use to generate substantive
review content. Existing general AI-generated text detectors are vulnerable to
paraphrasing attacks and struggle to distinguish between surface language
refinement and substantial content generation, suggesting that they primarily
rely on stylistic cues. When applied to peer review, this limitation can result
in unfairly suspecting reviews with permissible AI-assisted language
enhancement, while failing to catch deceptively humanized AI-generated reviews.
To address this, we propose a paradigm shift from style-based to content-based
detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark
built upon a fine-grained dataset of AI-generated peer reviews, covering six
distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an
AI review detector via a multi-task learning framework, designed to achieve
more accurate and robust detection of AI involvement in review content. Our
work offers a practical foundation for evaluating the use of LLMs in peer
review, and contributes to the development of more precise, equitable, and
reliable detection methods for real-world scholarly applications. Our code and
data will be publicly available at https://github.com/Y1hanChen/COCONUTS.
\\ ( https://arxiv.org/abs/2509.04460 ,  377kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04461
Date: Thu, 28 Aug 2025 06:35:12 GMT   (1829kb)

Title: From Post To Personality: Harnessing LLMs for MBTI Prediction in Social
  Media
Authors: Tian Ma, Kaiyu Feng, Yu Rong, Kangfei Zhao
Categories: cs.CL cs.SI
Journal-ref: CIKM 2025 Short Paper (Technical Report)
DOI: 10.1145/3746252.3760813
\\
  Personality prediction from social media posts is a critical task that
implies diverse applications in psychology and sociology. The Myers Briggs Type
Indicator (MBTI), a popular personality inventory, has been traditionally
predicted by machine learning (ML) and deep learning (DL) techniques. Recently,
the success of Large Language Models (LLMs) has revealed their huge potential
in understanding and inferring personality traits from social media content.
However, directly exploiting LLMs for MBTI prediction faces two key challenges:
the hallucination problem inherent in LLMs and the naturally imbalanced
distribution of MBTI types in the population. In this paper, we propose
PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from
social media posts of individuals. Specifically, PtoP leverages Retrieval
Augmented Generation with in context learning to mitigate hallucination in
LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification
in MBTI understanding with synthetic minority oversampling, which balances the
class imbalance by generating synthetic samples. Experiments conducted on a
real world social media dataset demonstrate that PtoP achieves state of the art
performance compared with 10 ML and DL baselines.
\\ ( https://arxiv.org/abs/2509.04461 ,  1829kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04462
Date: Thu, 28 Aug 2025 13:06:53 GMT   (767kb)

Title: Benchmarking GPT-5 for biomedical natural language processing
Authors: Yu Hou, Zaifu Zhan and Rui Zhang
Categories: cs.CL cs.AI
\\
  The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.
\\ ( https://arxiv.org/abs/2509.04462 ,  767kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04464
Date: Thu, 28 Aug 2025 20:14:35 GMT   (1015kb)

Title: Can Multiple Responses from an LLM Reveal the Sources of Its
  Uncertainty?
Authors: Yang Nan, Pengfei He, Ravi Tandon, Han Xu
Categories: cs.CL cs.AI
Comments: Proceedings of The 2025 Conference on Empirical Methods in Natural
  Language Processing (Findings)
\\
  Large language models (LLMs) have delivered significant breakthroughs across
diverse domains but can still produce unreliable or misleading outputs, posing
critical challenges for real-world applications. While many recent studies
focus on quantifying model uncertainty, relatively little work has been devoted
to \textit{diagnosing the source of uncertainty}. In this study, we show that,
when an LLM is uncertain, the patterns of disagreement among its multiple
generated responses contain rich clues about the underlying cause of
uncertainty. To illustrate this point, we collect multiple responses from a
target LLM and employ an auxiliary LLM to analyze their patterns of
disagreement. The auxiliary model is tasked to reason about the likely source
of uncertainty, such as whether it stems from ambiguity in the input question,
a lack of relevant knowledge, or both. In cases involving knowledge gaps, the
auxiliary model also identifies the specific missing facts or concepts
contributing to the uncertainty. In our experiment, we validate our framework
on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing
distinct uncertainty sources. Such diagnosis shows the potential for relevant
manual interventions that improve LLM performance and reliability.
\\ ( https://arxiv.org/abs/2509.04464 ,  1015kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04465
Date: Thu, 28 Aug 2025 22:52:10 GMT   (964kb)

Title: Emotionally-Aware Agents for Dispute Resolution
Authors: Sushrita Rakshit, James Hale, Kushal Chawla, Jeanne M. Brett, Jonathan
  Gratch
Categories: cs.CL cs.AI
\\
  In conflict, people use emotional expressions to shape their counterparts'
thoughts, feelings, and actions. This paper explores whether automatic text
emotion recognition offers insight into this influence in the context of
dispute resolution. Prior work has shown the promise of such methods in
negotiations; however, disputes evoke stronger emotions and different social
processes. We use a large corpus of buyer-seller dispute dialogues to
investigate how emotional expressions shape subjective and objective outcomes.
We further demonstrate that large-language models yield considerably greater
explanatory power than previous methods for emotion intensity annotation and
better match the decisions of human annotators. Findings support existing
theoretical models for how emotional expressions contribute to conflict
escalation and resolution and suggest that agent-based systems could be useful
in managing disputes by recognizing and potentially mitigating emotional
escalation.
\\ ( https://arxiv.org/abs/2509.04465 ,  964kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04466
Date: Thu, 28 Aug 2025 23:08:32 GMT   (6177kb)

Title: Just-in-time and distributed task representations in language models
Authors: Yuxuan Li, Declan Campbell, Stephanie C. Y. Chan, Andrew Kyle Lampinen
Categories: cs.CL cs.AI
\\
  Many of language models' impressive capabilities originate from their
in-context learning: based on instructions or examples, they can infer and
perform new tasks without weight updates. In this work, we investigate
\emph{when} representations for new tasks are formed in language models, and
\emph{how} these representations change over the course of context. We focus on
''transferrable'' task representations -- vector representations that can
restore task context in another instance of the model, even without the full
prompt. We show that these representations evolve in non-monotonic and sporadic
ways, and are distinct from a more inert representation of high-level task
categories that persists throughout the context. Specifically, models often
condense multiple evidence into these transferrable task representations, which
align well with the performance improvement based on more examples in the
context. However, this accrual process exhibits strong locality along the
sequence dimension, coming online only at certain tokens -- despite task
identity being reliably decodable throughout the context. Moreover, these local
but transferrable task representations tend to capture minimal ''task scopes'',
such as a semantically-independent subtask, and models rely on more
temporally-distributed representations to support longer and composite tasks.
This two-fold locality (temporal and semantic) underscores a kind of
just-in-time computational process underlying language models' ability to adapt
to new evidence and learn new tasks on the fly.
\\ ( https://arxiv.org/abs/2509.04466 ,  6177kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04467
Date: Fri, 29 Aug 2025 02:29:52 GMT   (716kb)

Title: Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode
  Disaggregation in Inference
Authors: Hao Zhang, Mengsi Lyu, Yulong Ao, Yonghua Lin
Categories: cs.CL cs.AI
Comments: 21 pages
\\
  Large Language Models (LLMs) demonstrate exceptional capabilities across
various tasks, but their deployment is constrained by high computational and
memory costs. Model pruning provides an effective means to alleviate these
demands. However, existing methods often ignore the characteristics of
prefill-decode (PD) disaggregation in practice. In this paper, we propose a
novel pruning method for PD disaggregation inference, enabling more precise and
efficient block and KV Cache pruning. Our approach constructs pruning and
distillation sets to perform iterative block removal independently for the
prefill and decode stages, obtaining better pruning solutions. Moreover, we
introduce a token-aware cache pruning mechanism that retains all KV Cache in
the prefill stage but selectively reuses entries for the first and last token
sequences in selected layers during decode, reducing communication costs with
minimal overhead. Extensive experiments demonstrate that our approach
consistently achieves strong performance in both PD disaggregation and PD
unified settings without disaggregation. Under the default settings, our method
achieves a 20.56% inference speedup and a 4.95 times reduction in data
transmission bandwidth consumption.
\\ ( https://arxiv.org/abs/2509.04467 ,  716kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04468
Date: Fri, 29 Aug 2025 06:13:21 GMT   (462kb)

Title: Evaluating Large Language Models for Financial Reasoning: A CFA-Based
  Benchmark Study
Authors: Xuan Yao, Qianteng Wang, Xinbo Liu, Ke-Wei Huang
Categories: cs.CL cs.AI
\\
  The rapid advancement of large language models presents significant
opportunities for financial applications, yet systematic evaluation in
specialized financial contexts remains limited. This study presents the first
comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice
questions from official mock exams across Levels I-III of CFA, most rigorous
professional certifications globally that mirror real-world financial analysis
complexity. We compare models distinguished by core design priorities:
multi-modal and computationally powerful, reasoning-specialized and highly
accurate, and lightweight efficiency-optimized.
  We assess models under zero-shot prompting and through a novel
Retrieval-Augmented Generation pipeline that integrates official CFA curriculum
content. The RAG system achieves precise domain-specific knowledge retrieval
through hierarchical knowledge organization and structured query generation,
significantly enhancing reasoning accuracy in professional financial
certification evaluation.
  Results reveal that reasoning-oriented models consistently outperform others
in zero-shot settings, while the RAG pipeline provides substantial improvements
particularly for complex scenarios. Comprehensive error analysis identifies
knowledge gaps as the primary failure mode, with minimal impact from text
readability. These findings provide actionable insights for LLM deployment in
finance, offering practitioners evidence-based guidance for model selection and
cost-performance optimization.
\\ ( https://arxiv.org/abs/2509.04468 ,  462kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04469
Date: Fri, 29 Aug 2025 09:09:20 GMT   (69kb)

Title: Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies
  for Invoice Processing
Authors: David Berghaus, Armin Berger, Lars Hillebrand, Kostadin Cvejoski,
  Rafet Sifa
Categories: cs.CL cs.AI
\\
  This paper benchmarks eight multi-modal large language models from three
families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly
available invoice document datasets using zero-shot prompting. We compare two
processing strategies: direct image processing using multi-modal capabilities
and a structured parsing approach converting documents to markdown first.
Results show native image processing generally outperforms structured
approaches, with performance varying across model types and document
characteristics. This benchmark provides insights for selecting appropriate
models and processing strategies for automated document systems. Our code is
available online.
\\ ( https://arxiv.org/abs/2509.04469 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04470
Date: Fri, 29 Aug 2025 11:15:57 GMT   (7280kb)

Title: COCORELI: Cooperative, Compositional Reconstitution \& Execution of
  Language Instructions
Authors: Swarnadeep Bhar, Omar Naim, Eleni Metheniti, Bastien Navarri, Lo\"ic
  Cabannes, Morteza Ezzabady, Nicholas Asher
Categories: cs.CL cs.AI
Comments: 18 pages
\\
  We present COCORELI, a hybrid agent framework designed to tackle the
limitations of large language models (LLMs) in tasks requiring: following
complex instructions, minimizing hallucination, and spatial reasoning. COCORELI
integrates medium-sized LLM agents with novel abstraction mechanisms and a
discourse module to parse instructions to in-context learn dynamic, high-level
representations of the environment. Experiments on natural collaborative
construction tasks show that COCORELI outperforms single-LLM CoT and agentic
LLM systems, all using larger LLMs. It manages to largely avoid hallucinations,
identify missing information, ask for clarifications, and update its learned
objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown
in the ToolBench API completion task.
\\ ( https://arxiv.org/abs/2509.04470 ,  7280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04471
Date: Fri, 29 Aug 2025 14:35:00 GMT   (192kb)

Title: MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient
  Approach for Radiological Report Classification
Authors: Alice Schiavone (1 and 2), Marco Fraccaro (3), Lea Marie Pehrson (1, 4
  and 5), Silvia Ingala (4 and 6), Rasmus Bonnevie (3), Michael Bachmann
  Nielsen (5), Vincent Beliveau (7), Melanie Ganz (1 and 2), Desmond Elliott
  (1) ((1) Department of Computer Science, University of Copenhagen, Denmark,
  (2) Neurobiology Research Unit, Copenhagen University Hospital, Denmark, (3)
  Unumed Aps, Denmark, (4) Department of Diagnostic Radiology, Copenhagen
  University Hospital, Denmark, (5) Department of Clinical Medicine, University
  of Copenhagen, Denmark, (6) Cerebriu A/S, Denmark, (7) Institute for Human
  Genetics, Medical University of Innsbruck, Austria)
Categories: cs.CL cs.AI
Comments: 8 pages, 14 pages including references and appendix. 9 figures.
  Preprint
\\
  Radiology reports contain rich clinical information that can be used to train
imaging models without relying on costly manual annotation. However, existing
approaches face critical limitations: rule-based methods struggle with
linguistic variability, supervised models require large annotated datasets, and
recent LLM-based systems depend on closed-source or resource-intensive models
that are unsuitable for clinical use. Moreover, current solutions are largely
restricted to English and single-modality, single-taxonomy datasets. We
introduce MOSAIC, a multilingual, taxonomy-agnostic, and computationally
efficient approach for radiological report classification. Built on a compact
open-access language model (MedGemma-4B), MOSAIC supports both zero-/few-shot
prompting and lightweight fine-tuning, enabling deployment on consumer-grade
GPUs. We evaluate MOSAIC across seven datasets in English, Spanish, French, and
Danish, spanning multiple imaging modalities and label taxonomies. The model
achieves a mean macro F1 score of 88 across five chest X-ray datasets,
approaching or exceeding expert-level performance, while requiring only 24 GB
of GPU memory. With data augmentation, as few as 80 annotated samples are
sufficient to reach a weighted F1 score of 82 on Danish reports, compared to 86
with the full 1600-sample training set. MOSAIC offers a practical alternative
to large or proprietary LLMs in clinical settings. Code and models are
open-source. We invite the community to evaluate and extend MOSAIC on new
languages, taxonomies, and modalities.
\\ ( https://arxiv.org/abs/2509.04471 ,  192kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04472
Date: Fri, 29 Aug 2025 20:45:37 GMT   (10198kb)

Title: RECAP: REwriting Conversations for Intent Understanding in Agentic
  Planning
Authors: Kushan Mitra, Dan Zhang, Hannah Kim, Estevam Hruschka
Categories: cs.CL cs.AI
\\
  Understanding user intent is essential for effective planning in
conversational assistants, particularly those powered by large language models
(LLMs) coordinating multiple agents. However, real-world dialogues are often
ambiguous, underspecified, or dynamic, making intent detection a persistent
challenge. Traditional classification-based approaches struggle to generalize
in open-ended settings, leading to brittle interpretations and poor downstream
planning. We propose RECAP (REwriting Conversations for Agent Planning), a new
benchmark designed to evaluate and advance intent rewriting, reframing
user-agent dialogues into concise representations of user goals. RECAP captures
diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal
conversations. Alongside the dataset, we introduce an LLM-based evaluator that
assesses planning utility given the rewritten intent. Using RECAP, we develop a
prompt-based rewriting approach that outperforms baselines. We further
demonstrate that fine-tuning two DPO-based rewriters yields additional utility
gains. Our results highlight intent rewriting as a critical and tractable
component for improving agent planning in open-domain dialogue systems.
\\ ( https://arxiv.org/abs/2509.04472 ,  10198kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04473
Date: Fri, 29 Aug 2025 22:38:16 GMT   (182kb)

Title: SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task
  Understanding in Low Resource Settings
Authors: Jaekwon Yoo, Kunal Chandiramani, Divya Tadimeti, Abenezer Girma,
  Chandra Dhir
Categories: cs.CL cs.AI
\\
  While integrating speech encoder with LLM requires substantial data and
resources, use cases face limitations due to insufficient availability. To
address this, we propose a solution with a parameter-efficient adapter that
converts speech embeddings into LLM-compatible tokens, focusing on end-to-end
automatic speech recognition (ASR), named entity recognition (NER), and
sentiment analysis (SA). To reduce labeling costs, we employ an LLM-based
synthetic dataset annotation technique. The proposed adapter, using 7x fewer
trainable parameters, achieves significant performance gains: a 26% relative
Word Error Rates (WER) improvement on the LibriSpeech ASR task, a 6.3% relative
F1 score increase on the NER task, and a 32% relative F1 score boost on the SA
task. Moreover, using advanced techniques such as adding a classifier
regularizer and optimizing the LLM with Low-Rank Adaptation (LoRA) yields
notable performance gains, with Spoken Language Understanding Evaluation (SLUE)
score improvement of 6.6% and 9.5%
\\ ( https://arxiv.org/abs/2509.04473 ,  182kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04474
Date: Sat, 30 Aug 2025 01:54:55 GMT   (269kb)

Title: Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for
  Efficient LLM Test-Time Scaling
Authors: Shengyin Sun and Yiming Li and Xing Li and Yingzhao Lian and Weizhe
  Lin and Hui-Ling Zhen and Zhiyuan Yang and Chen Chen and Xianzhi Yu and
  Mingxuan Yuan and Chen Ma
Categories: cs.CL cs.AI
Comments: 18 pages
\\
  Test-time scaling has emerged as a powerful paradigm for enhancing the
reasoning capabilities of large language models (LLMs) by allocating additional
computational resources during inference. However, this paradigm is inherently
inefficient due to the generation of redundant and repetitive reasoning traces,
leading to significant computational overhead. Speculative decoding offers a
promising avenue for mitigating this inefficiency, yet its efficacy in the
structured, repetition-rich context of test-time scaling remains largely
unexplored. To bridge this gap, we introduce the first comprehensive benchmark
designed to evaluate speculative decoding methods for accelerating LLM
test-time scaling. Our benchmark provides consistent experimental protocols
across representative test-time scaling paradigms (e.g., Best-of-N sampling and
multi-round thinking), enabling a fair comparison of three major categories of
speculative decoding: model-based, training-based, and n-gram-based methods.
Extensive experiments reveal that simple n-gram-based methods effectively
capture repetitive patterns, demonstrating unique potential in accelerating
test-time scaling. This phenomenon demonstrates the value of integrating
n-gram-based methods with model-based or training-based approaches to balance
acceleration for both repetitive and diverse reasoning in test-time scaling. We
hope this benchmark spurs further research on speculative decoding for
test-time scaling, enabling faster and more practical reasoning in LLMs through
better handling of repetitive and diverse reasoning paths.
\\ ( https://arxiv.org/abs/2509.04474 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04475
Date: Sat, 30 Aug 2025 03:09:07 GMT   (1674kb)

Title: ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM
  Test-time Compute
Authors: Hao Wen, Yifan Su, Feifei Zhang, Yunxin Liu, Yunhao Liu, Ya-Qin Zhang,
  Yuanchun Li
Categories: cs.CL cs.AI
\\
  Recent advances in Large Language Models (LLMs) have been driven by test-time
compute scaling - a strategy that improves reasoning by generating longer,
sequential thought processes. While effective, this approach encounters a
significant bottleneck as computation increases, where further computation
offers only marginal performance gains. We argue this ceiling is not an
inherent limit of the model's capability but a flaw in the scaling strategy
itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial
steps lock it into a suboptimal reasoning path. To overcome this, we introduce
a new scaling paradigm: native thought parallelism. We present ParaThinker, an
end-to-end framework that trains an LLM to generate multiple, diverse reasoning
paths in parallel and synthesize them into a superior final answer. By
exploring different lines of thoughts simultaneously, ParaThinker effectively
sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning
potential. Our approach demonstrates that scaling compute in parallel (width)
is a more effective and efficient way to superior reasoning than simply scaling
sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves
substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5%
for 7B models on average with 8 parallel paths), while adding only negligible
latency overhead (7.1%). This enables smaller models to surpass much larger
counterparts and establishes parallel thinking as a critical, efficient
dimension for scaling future LLMs.
\\ ( https://arxiv.org/abs/2509.04475 ,  1674kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04476
Date: Sat, 30 Aug 2025 07:59:02 GMT   (3630kb)

Title: Training Text-to-Molecule Models with Context-Aware Tokenization
Authors: Seojin Kim, Hyeontae Song, Jaehyun Nam, Jinwoo Shin
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Findings
\\
  Recently, text-to-molecule models have shown great potential across various
chemical applications, e.g., drug-discovery. These models adapt language models
to molecular data by representing molecules as sequences of atoms. However,
they rely on atom-level tokenizations, which primarily focus on modeling local
connectivity, thereby limiting the ability of models to capture the global
structural context within molecules. To tackle this issue, we propose a novel
text-to-molecule model, coined Context-Aware Molecular T5 (CAMT5). Inspired by
the significance of the substructure-level contexts in understanding molecule
structures, e.g., ring systems, we introduce substructure-level tokenization
for text-to-molecule models. Building on our tokenization scheme, we develop an
importance-based training strategy that prioritizes key substructures, enabling
CAMT5 to better capture the molecular semantics. Extensive experiments verify
the superiority of CAMT5 in various text-to-molecule generation tasks.
Intriguingly, we find that CAMT5 outperforms the state-of-the-art methods using
only 2% of training tokens. In addition, we propose a simple yet effective
ensemble strategy that aggregates the outputs of text-to-molecule models to
further boost the generation performance. Code is available at
https://github.com/Songhyeontae/CAMT5.git.
\\ ( https://arxiv.org/abs/2509.04476 ,  3630kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04478
Date: Sat, 30 Aug 2025 16:35:53 GMT   (1205kb)

Title: An End-to-End System for Culturally-Attuned Driving Feedback using a
  Dual-Component NLG Engine
Authors: Iniakpokeikiye Peter Thompson, Yi Dewei, Reiter Ehud
Categories: cs.CL
Comments: The paper has 5 figures and 1 table
ACM-class: F.2.2; I.2.7
\\
  This paper presents an end-to-end mobile system that delivers
culturally-attuned safe driving feedback to drivers in Nigeria, a low-resource
environment with significant infrastructural challenges. The core of the system
is a novel dual-component Natural Language Generation (NLG) engine that
provides both legally-grounded safety tips and persuasive, theory-driven
behavioural reports. We describe the complete system architecture, including an
automatic trip detection service, on-device behaviour analysis, and a
sophisticated NLG pipeline that leverages a two-step reflection process to
ensure high-quality feedback. The system also integrates a specialized machine
learning model for detecting alcohol-influenced driving, a key local safety
issue. The architecture is engineered for robustness against intermittent
connectivity and noisy sensor data. A pilot deployment with 90 drivers
demonstrates the viability of our approach, and initial results on detected
unsafe behaviours are presented. This work provides a framework for applying
data-to-text and AI systems to achieve social good.
\\ ( https://arxiv.org/abs/2509.04478 ,  1205kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04479
Date: Sat, 30 Aug 2025 22:20:41 GMT   (330kb)

Title: No Clustering, No Routing: How Transformers Actually Process Rare Tokens
Authors: Jing Liu
Categories: cs.CL cs.AI
\\
  Large language models struggle with rare token prediction, yet the mechanisms
driving their specialization remain unclear. Prior work identified specialized
``plateau'' neurons for rare tokens following distinctive three-regime
influence patterns \cite{liu2025emergent}, but their functional organization is
unknown. We investigate this through neuron influence analyses, graph-based
clustering, and attention head ablations in GPT-2 XL and Pythia models. Our
findings show that: (1) rare token processing requires additional plateau
neurons beyond the power-law regime sufficient for common tokens, forming dual
computational regimes; (2) plateau neurons are spatially distributed rather
than forming modular clusters; and (3) attention mechanisms exhibit no
preferential routing to specialists. These results demonstrate that rare token
specialization arises through distributed, training-driven differentiation
rather than architectural modularity, preserving context-sensitive flexibility
while achieving adaptive capacity allocation.
\\ ( https://arxiv.org/abs/2509.04479 ,  330kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04480
Date: Sat, 30 Aug 2025 23:47:17 GMT   (23875kb)

Title: Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal
  Large Language Model for Personalized Visual Emotion Recognition
Authors: Ryo Takahashi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki
  Haseyama
Categories: cs.CL cs.LG
Comments: 11 pages, 4 figures
\\
  Visual Emotion Recognition (VER) is an important research topic due to its
wide range of applications, including opinion mining and advertisement design.
Extending this capability to recognize emotions at the individual level further
broadens its potential applications. Recently, Multimodal Large Language Models
(MLLMs) have attracted increasing attention and demonstrated performance
comparable to that of conventional VER methods. However, MLLMs are trained on
large and diverse datasets containing general opinions, which causes them to
favor majority viewpoints and familiar patterns. This tendency limits their
performance in a personalized VER, which is crucial for practical and
real-world applications, and indicates a key area for improvement. To address
this limitation, the proposed method employs discrete prompt tuning inspired by
the process of humans' prompt engineering to adapt the VER task to each
individual. Our method selects the best natural language representation from
the generated prompts and uses it to update the prompt for the realization of
accurate personalized VER.
\\ ( https://arxiv.org/abs/2509.04480 ,  23875kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04482
Date: Sun, 31 Aug 2025 10:20:48 GMT   (221kb)

Title: Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented
  Large Language Models for Healthcare
Authors: Ravi Shankar, Sheng Wong, Lin Li, Magdalena Bachmann, Alex
  Silverthorne, Beth Albert, Gabriel Davis Jones
Categories: cs.CL cs.AI
\\
  Reliable abstention is critical for retrieval-augmented generation (RAG)
systems, particularly in safety-critical domains such as women's health, where
incorrect answers can lead to harm. We present an energy-based model (EBM) that
learns a smooth energy landscape over a dense semantic corpus of 2.6M
guideline-derived questions, enabling the system to decide when to generate or
abstain. We benchmark the EBM against a calibrated softmax baseline and a
k-nearest neighbour (kNN) density heuristic across both easy and hard
abstention splits, where hard cases are semantically challenging
near-distribution queries. The EBM achieves superior abstention performance
abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for
softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives,
performance is comparable across methods, but the EBM's advantage becomes most
pronounced in safety-critical hard distributions. A comprehensive ablation with
controlled negative sampling and fair data exposure shows that robustness stems
primarily from the energy scoring head, while the inclusion or exclusion of
specific negative types (hard, easy, mixed) sharpens decision boundaries but is
not essential for generalisation to hard cases. These results demonstrate that
energy-based abstention scoring offers a more reliable confidence signal than
probability-based softmax confidence, providing a scalable and interpretable
foundation for safe RAG systems.
\\ ( https://arxiv.org/abs/2509.04482 ,  221kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04483
Date: Sun, 31 Aug 2025 10:22:54 GMT   (67kb)

Title: DecMetrics: Structured Claim Decomposition Scoring for Factually
  Consistent LLM Outputs
Authors: Minghui Huang
Categories: cs.CL cs.AI
\\
  Claim decomposition plays a crucial role in the fact-checking process by
breaking down complex claims into simpler atomic components and identifying
their unfactual elements. Despite its importance, current research primarily
focuses on generative methods for decomposition, with insufficient emphasis on
evaluating the quality of these decomposed atomic claims. To bridge this gap,
we introduce \textbf{DecMetrics}, which comprises three new metrics:
\texttt{COMPLETENESS}, \texttt{CORRECTNESS}, and \texttt{SEMANTIC ENTROPY},
designed to automatically assess the quality of claims produced by
decomposition models. Utilizing these metrics, we develop a lightweight claim
decomposition model, optimizing its performance through the integration of
these metrics as a reward function. Through automatic evaluation, our approach
aims to set a benchmark for claim decomposition, enhancing both the reliability
and effectiveness of fact-checking systems.
\\ ( https://arxiv.org/abs/2509.04483 ,  67kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04484
Date: Sun, 31 Aug 2025 14:19:07 GMT   (9620kb)

Title: The Good, the Bad and the Constructive: Automatically Measuring Peer
  Review's Utility for Authors
Authors: Abdelrahman Sadallah, Tim Baumg\"artner, Iryna Gurevych, Ted Briscoe
Categories: cs.CL cs.AI cs.CY
Comments: EMNLP 2025 Main
\\
  Providing constructive feedback to paper authors is a core component of peer
review. With reviewers increasingly having less time to perform reviews,
automated support systems are required to ensure high reviewing quality, thus
making the feedback in reviews useful for authors. To this end, we identify
four key aspects of review comments (individual points in weakness sections of
reviews) that drive the utility for authors: Actionability, Grounding &
Specificity, Verifiability, and Helpfulness. To enable evaluation and
development of models assessing review comments, we introduce the RevUtil
dataset. We collect 1,430 human-labeled review comments and scale our data with
10k synthetically labeled comments for training purposes. The synthetic data
additionally contains rationales, i.e., explanations for the aspect score of a
review comment. Employing the RevUtil dataset, we benchmark fine-tuned models
for assessing review comments on these aspects and generating rationales. Our
experiments demonstrate that these fine-tuned models achieve agreement levels
with humans comparable to, and in some cases exceeding, those of powerful
closed models like GPT-4o. Our analysis further reveals that machine-generated
reviews generally underperform human reviews on our four aspects.
\\ ( https://arxiv.org/abs/2509.04484 ,  9620kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04485
Date: Sun, 31 Aug 2025 16:43:07 GMT   (1387kb)

Title: ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk
  Prediction from Electronic Health Records
Authors: Chris Sainsbury, Andreas Karwath
Categories: cs.CL cs.AI
\\
  We present ASCENDgpt, a transformer-based model specifically designed for
cardiovascular risk prediction from longitudinal electronic health records
(EHRs). Our approach introduces a novel phenotype-aware tokenization scheme
that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens,
achieving 99.6\% consolidation of diagnosis codes while preserving semantic
information. This phenotype mapping contributes to a total vocabulary of 10,442
tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We
pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a
masked language modeling objective, then fine-tune for time-to-event prediction
of five cardiovascular outcomes: myocardial infarction (MI), stroke, major
adverse cardiovascular events (MACE), cardiovascular death, and all-cause
mortality. Our model achieves excellent discrimination on the held-out test set
with an average C-index of 0.816, demonstrating strong performance across all
outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842,
all-cause mortality: 0.824). The phenotype-based approach enables clinically
interpretable predictions while maintaining computational efficiency. Our work
demonstrates the effectiveness of domain-specific tokenization and pretraining
for EHR-based risk prediction tasks.
\\ ( https://arxiv.org/abs/2509.04485 ,  1387kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04488
Date: Mon, 1 Sep 2025 03:10:14 GMT   (1188kb)

Title: Serialized Output Prompting for Large Language Model-based Multi-Talker
  Speech Recognition
Authors: Hao Shi, Yusuke Fujita, Tomoya Mizumoto, Lianbo Liu, Atsushi Kojima,
  Yui Sudo
Categories: cs.CL cs.AI cs.SD eess.AS
\\
  Prompts are crucial for task definition and for improving the performance of
large language models (LLM)-based systems. However, existing LLM-based
multi-talker (MT) automatic speech recognition (ASR) systems either omit
prompts or rely on simple task-definition prompts, with no prior work exploring
the design of prompts to enhance performance. In this paper, we propose
extracting serialized output prompts (SOP) and explicitly guiding the LLM using
structured prompts to improve system performance (SOP-MT-ASR). A Separator and
serialized Connectionist Temporal Classification (CTC) layers are inserted
after the speech encoder to separate and extract MT content from the mixed
speech encoding in a first-speaking-first-out manner. Subsequently, the SOP,
which serves as a prompt for LLMs, is obtained by decoding the serialized CTC
outputs using greedy search. To train the model effectively, we design a
three-stage training strategy, consisting of serialized output training (SOT)
fine-tuning, serialized speech information extraction, and SOP-based
adaptation. Experimental results on the LibriMix dataset show that, although
the LLM-based SOT model performs well in the two-talker scenario, it fails to
fully leverage LLMs under more complex conditions, such as the three-talker
scenario. The proposed SOP approach significantly improved performance under
both two- and three-talker conditions.
\\ ( https://arxiv.org/abs/2509.04488 ,  1188kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04491
Date: Mon, 1 Sep 2025 11:43:07 GMT   (300kb)

Title: Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised
  Training of ASR
Authors: Xinnian Zhao and Hugo Van Hamme
Categories: cs.CL cs.AI
Comments: eusipco2025
\\
  This study proposes a novel approach to using TV subtitles within a weakly
supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV
subtitles are readily available, their imprecise alignment with corresponding
audio limits their applicability as supervised targets for verbatim
transcription. Rather than using subtitles as direct supervision signals, our
method reimagines them as context-rich prompts. This design enables the model
to handle discrepancies between spoken audio and subtitle text. Instead,
generated pseudo transcripts become the primary targets, with subtitles acting
as guiding cues for iterative refinement. To further enhance the process, we
introduce a weighted attention mechanism that emphasizes relevant subtitle
tokens during inference. Our experiments demonstrate significant improvements
in transcription accuracy, highlighting the effectiveness of the proposed
method in refining transcripts. These enhanced pseudo-labeled datasets provide
high-quality foundational resources for training robust ASR systems.
\\ ( https://arxiv.org/abs/2509.04491 ,  300kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04492
Date: Mon, 1 Sep 2025 13:34:21 GMT   (502kb)

Title: Learned Hallucination Detection in Black-Box LLMs using Token-level
  Entropy Production Rate
Authors: Charles Moslonka, Hicham Randrianarivo, Arthur Garnier and Emmanuel
  Malherbe
Categories: cs.CL cs.AI
Comments: 8 pages, 7 figures, 1 table. pre-print version
\\
  Hallucinations in Large Language Model (LLM) outputs for Question Answering
(QA) tasks critically undermine their real-world reliability. This paper
introduces an applied methodology for robust, one-shot hallucination detection,
specifically designed for scenarios with limited data access, such as
interacting with black-box LLM APIs that typically expose only a few top
candidate log-probabilities per token. Our approach derives uncertainty
indicators directly from these readily available log-probabilities generated
during non-greedy decoding. We first derive an Entropy Production Rate (EPR)
metric that offers baseline performance, later augmented with supervised
learning. Our learned model uses features representing the entropic
contributions of the accessible top-ranked tokens within a single generated
sequence, requiring no multiple query re-runs. Evaluated across diverse QA
datasets and multiple LLMs, this estimator significantly improves hallucination
detection over using EPR alone. Crucially, high performance is demonstrated
using only the typically small set of available log-probabilities (e.g., top
<10 per token), confirming its practical efficiency and suitability for these
API-constrained deployments. This work provides a readily deployable technique
to enhance the trustworthiness of LLM responses from a single generation pass
in QA and Retrieval-Augmented Generation (RAG) systems, with its utility
further demonstrated in a finance framework analyzing responses to queries on
annual reports from an industrial dataset.
\\ ( https://arxiv.org/abs/2509.04492 ,  502kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04497
Date: Mon, 1 Sep 2025 19:05:26 GMT   (1780kb)

Title: A Narrative-Driven Computational Framework for Clinician Burnout
  Surveillance
Authors: Syed Ahmad Chan Bukhari, Fazel Keshtkar, and Alyssa Meczkowska
Categories: cs.CL cs.AI
Comments: 6 pages, 6 Figure
\\
  Clinician burnout poses a substantial threat to patient safety, particularly
in high-acuity intensive care units (ICUs). Existing research predominantly
relies on retrospective survey tools or broad electronic health record (EHR)
metadata, often overlooking the valuable narrative information embedded in
clinical notes. In this study, we analyze 10,000 ICU discharge summaries from
MIMIC-IV, a publicly available database derived from the electronic health
records of Beth Israel Deaconess Medical Center. The dataset encompasses
diverse patient data, including vital signs, medical orders, diagnoses,
procedures, treatments, and deidentified free-text clinical notes. We introduce
a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for
clinical narratives, a lexical stress lexicon tailored for clinician burnout
surveillance, and five-topic latent Dirichlet allocation (LDA) with workload
proxies. A provider-level logistic regression classifier achieves a precision
of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out
set, surpassing metadata-only baselines by greater than or equal to 0.17 F1
score. Specialty-specific analysis indicates elevated burnout risk among
providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate
that ICU clinical narratives contain actionable signals for proactive
well-being monitoring.
\\ ( https://arxiv.org/abs/2509.04497 ,  1780kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04498
Date: Mon, 1 Sep 2025 19:51:06 GMT   (15498kb)

Title: Where Should I Study? Biased Language Models Decide! Evaluating Fairness
  in LMs for Academic Recommendations
Authors: Krithi Shailya, Akhilesh Kumar Mishra, Gokul S Krishnan, Balaraman
  Ravindran
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) are increasingly used as daily recommendation
systems for tasks like education planning, yet their recommendations risk
perpetuating societal biases. This paper empirically examines geographic,
demographic, and economic biases in university and program suggestions from
three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360
simulated user profiles varying by gender, nationality, and economic status, we
analyze over 25,000 recommendations. Results show strong biases: institutions
in the Global North are disproportionately favored, recommendations often
reinforce gender stereotypes, and institutional repetition is prevalent. While
LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities
across 58 countries, systemic disparities persist. To quantify these issues, we
propose a novel, multi-dimensional evaluation framework that goes beyond
accuracy by measuring demographic and geographic representation. Our findings
highlight the urgent need for bias consideration in educational LMs to ensure
equitable global access to higher education.
\\ ( https://arxiv.org/abs/2509.04498 ,  15498kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04499
Date: Tue, 2 Sep 2025 00:32:38 GMT   (9310kb)

Title: DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability
  Across Citations and Evidence
Authors: Pranav Narayanan Venkit, Philippe Laban, Yilun Zhou, Kung-Hsiang
  Huang, Yixin Mao, Chien-Sheng Wu
Categories: cs.CL cs.AI
Comments: arXiv admin note: text overlap with arXiv:2410.22349
\\
  Generative search engines and deep research LLM agents promise trustworthy,
source-grounded synthesis, yet users regularly encounter overconfidence, weak
sourcing, and confusing citation practices. We introduce DeepTRACE, a novel
sociotechnically grounded audit framework that turns prior community-identified
failure cases into eight measurable dimensions spanning answer text, sources,
and citations. DeepTRACE uses statement-level analysis (decomposition,
confidence scoring) and builds citation and factual-support matrices to audit
how systems reason with and attribute evidence end-to-end. Using automated
extraction pipelines for popular public models (e.g., GPT-4.5/5, You.com,
Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to
human raters, we evaluate both web-search engines and deep-research
configurations. Our findings show that generative search engines and deep
research agents frequently produce one-sided, highly confident responses on
debate queries and include large fractions of statements unsupported by their
own listed sources. Deep-research configurations reduce overconfidence and can
attain high citation thoroughness, but they remain highly one-sided on debate
queries and still exhibit large fractions of unsupported statements, with
citation accuracy ranging from 40--80% across systems.
\\ ( https://arxiv.org/abs/2509.04499 ,  9310kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04500
Date: Tue, 2 Sep 2025 00:40:34 GMT   (12863kb)

Title: Context Engineering for Trustworthiness: Rescorla Wagner Steering Under
  Mixed and Inappropriate Contexts
Authors: Rushi Wang, Jiateng Liu, Cheng Qian, Yifan Shen, Yanzhou Pan, Zhaozhuo
  Xu, Ahmed Abbasi, Heng Ji, Denghui Zhang
Categories: cs.CL cs.AI
Comments: 36 pages, 7 figures
\\
  Incorporating external context can significantly enhance the response quality
of Large Language Models (LLMs). However, real-world contexts often mix
relevant information with disproportionate inappropriate content, posing
reliability risks. How do LLMs process and prioritize mixed context? To study
this, we introduce the Poisoned Context Testbed, pairing queries with
real-world contexts containing relevant and inappropriate content. Inspired by
associative learning in animals, we adapt the Rescorla-Wagner (RW) model from
neuroscience to quantify how competing contextual signals influence LLM
outputs. Our adapted model reveals a consistent behavioral pattern: LLMs
exhibit a strong tendency to incorporate information that is less prevalent in
the context. This susceptibility is harmful in real-world settings, where small
amounts of inappropriate content can substantially degrade response quality.
Empirical evaluations on our testbed further confirm this vulnerability. To
tackle this, we introduce RW-Steering, a two-stage finetuning-based approach
that enables the model to internally identify and ignore inappropriate signals.
Unlike prior methods that rely on extensive supervision across diverse context
mixtures, RW-Steering generalizes robustly across varying proportions of
inappropriate content. Experiments show that our best fine-tuned model improves
response quality by 39.8% and reverses the undesirable behavior curve,
establishing RW-Steering as a robust, generalizable context engineering
solution for improving LLM safety in real-world use.
\\ ( https://arxiv.org/abs/2509.04500 ,  12863kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04501
Date: Tue, 2 Sep 2025 03:59:40 GMT   (110kb)

Title: Understanding Reinforcement Learning for Model Training, and future
  directions with GRAPE
Authors: Rohit Patel
Categories: cs.CL cs.AI cs.LG
Comments: 35 pages, 1 figure
MSC-class: 68T07, 68T05, 62M45, 68T50, 90C40
ACM-class: I.2.6; I.2.7
\\
  This paper provides a self-contained, from-scratch, exposition of key
algorithms for instruction tuning of models: SFT, Rejection Sampling,
REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy
Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct
Preference Optimization (DPO). Explanations of these algorithms often assume
prior knowledge, lack critical details, and/or are overly generalized and
complex. Here, each method is discussed and developed step by step using
simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity
and provide a clear and intuitive understanding of the concepts. By minimizing
detours into the broader RL literature and connecting concepts to LLMs, we
eliminate superfluous abstractions and reduce cognitive overhead. Following
this exposition, we provide a literature review of new techniques and
approaches beyond those detailed. Finally, new ideas for research and
exploration in the form of GRAPE (Generalized Relative Advantage Policy
Evolution) are presented.
\\ ( https://arxiv.org/abs/2509.04501 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04502
Date: Tue, 2 Sep 2025 04:49:51 GMT   (530kb)

Title: VaccineRAG: Boosting Multimodal Large Language Models' Immunity to
  Harmful RAG Samples
Authors: Qixin Sun, Ziqin Wang, Hengyuan Zhao, Yilin Li, Kaiyou Song, Linjiang
  Huang, Xiaolin Hu, Qingpei Guo, Si Liu
Categories: cs.CL cs.AI
\\
  Retrieval Augmented Generation enhances the response accuracy of Large
Language Models (LLMs) by integrating retrieval and generation modules with
external knowledge, demonstrating particular strength in real-time queries and
Visual Question Answering tasks. However, the effectiveness of RAG is
frequently hindered by the precision of the retriever: many retrieved samples
fed into the generation phase are irrelevant or misleading, posing a critical
bottleneck to LLMs' performance. To address this challenge, we introduce
VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation
dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using
data with varying positive/negative sample ratios, systematically exposing
inherent weaknesses in current LLMs. On the other hand, it enhances models'
sample-discrimination capabilities by prompting LLMs to generate explicit
Chain-of-Thought (CoT) analysis for each sample before producing final answers.
Furthermore, to enhance the model's ability to learn long-sequence complex CoT
content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple
components rather than a single whole, our model can make more informed
preference selections for complex sequences, thereby enhancing its capacity to
learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG
validate the effectiveness of the proposed scheme. The code and dataset will be
publicly released soon.
\\ ( https://arxiv.org/abs/2509.04502 ,  530kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04504
Date: Tue, 2 Sep 2025 07:03:20 GMT   (5962kb)

Title: Behavioral Fingerprinting of Large Language Models
Authors: Zehua Pei, Hui-Ling Zhen, Ying Zhang, Zhiyuan Yang, Xing Li, Xianzhi
  Yu, Mingxuan Yuan, Bei Yu
Categories: cs.CL cs.AI
Comments: Submitted to 1st Open Conference on AI Agents for Science
  (agents4science 2025)
\\
  Current benchmarks for Large Language Models (LLMs) primarily focus on
performance metrics, often failing to capture the nuanced behavioral
characteristics that differentiate them. This paper introduces a novel
``Behavioral Fingerprinting'' framework designed to move beyond traditional
evaluation by creating a multi-faceted profile of a model's intrinsic cognitive
and interactive styles. Using a curated \textit{Diagnostic Prompt Suite} and an
innovative, automated evaluation pipeline where a powerful LLM acts as an
impartial judge, we analyze eighteen models across capability tiers. Our
results reveal a critical divergence in the LLM landscape: while core
capabilities like abstract and causal reasoning are converging among top
models, alignment-related behaviors such as sycophancy and semantic robustness
vary dramatically. We further document a cross-model default persona clustering
(ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together,
this suggests that a model's interactive nature is not an emergent property of
its scale or reasoning power, but a direct consequence of specific, and highly
variable, developer alignment strategies. Our framework provides a reproducible
and scalable methodology for uncovering these deep behavioral differences.
Project: https://github.com/JarvisPei/Behavioral-Fingerprinting
\\ ( https://arxiv.org/abs/2509.04504 ,  5962kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04507
Date: Tue, 2 Sep 2025 16:13:29 GMT   (420kb)

Title: From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM
  Approach
Authors: Nithyashree Sivasubramaniam
Categories: cs.CL cs.AI
\\
  Silent Speech Interfaces (SSIs) have gained attention for their ability to
generate intelligible speech from non-acoustic signals. While significant
progress has been made in advancing speech generation pipelines, limited work
has addressed the recognition and downstream processing of synthesized speech,
which often suffers from phonetic ambiguity and noise. To overcome these
challenges, we propose an enhanced automatic speech recognition framework that
combines a transformer-based acoustic model with a large language model (LLM)
for post-processing. The transformer captures full utterance context, while the
LLM ensures linguistic consistency. Experimental results show a 16% relative
and 6% absolute reduction in word error rate (WER) over a 36% baseline,
demonstrating substantial improvements in intelligibility for silent speech
interfaces.
\\ ( https://arxiv.org/abs/2509.04507 ,  420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04508
Date: Tue, 2 Sep 2025 18:36:52 GMT   (7719kb)

Title: ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent
  Systems Using Small Language Models
Authors: Biddut Sarker Bijoy, Mohammad Saqib Hasan, Pegah Alipoormolabashi,
  Avirup Sil, Aruna Balasubramanian, Niranjan Balasubramanian
Categories: cs.CL
\\
  Multi-agent systems with smaller language models (SLMs) present a viable
alternative to single agent systems powered by large language models (LLMs) for
addressing complex problems. In this work, we study how these alternatives
compare in terms of both effectiveness and efficiency. To study this trade-off,
we instantiate single and multi-agent systems for the complex problems in the
AppWorld environment using different sized language models.
  We find that difficulties with long-trajectory learning in smaller language
models (SLMs) limit their performance. Even when trained for specialized roles,
SLMs fail to learn all subtasks effectively. To address this issue, we
introduce a simple progressive sub-task training strategy, which introduces new
sub-tasks progressively in each training epoch. We find that this novel
strategy, analogous to instance level curriculum learning, consistently
improves the effectiveness of multi-agents at all configurations. Our Pareto
analysis shows that fine-tuned multi-agent systems yield better
effectiveness-efficiency trade-offs. Additional ablations and analyses shows
the importance of our progressive training strategy and its ability to reduce
subtask error rates.
\\ ( https://arxiv.org/abs/2509.04508 ,  7719kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04510
Date: Tue, 2 Sep 2025 19:05:09 GMT   (8681kb)

Title: Combine Virtual Reality and Machine-Learning to Identify the Presence of
  Dyslexia: A Cross-Linguistic Approach
Authors: Michele Materazzini, Gianluca Morciano, Jose Manuel Alcalde-Llergo,
  Enrique Yeguas-Bolivar, Giuseppe Calabro, Andrea Zingoni and Juri Taborri
Categories: cs.CL cs.HC
Comments: 22 pages, 10 figures, 5 tables
Journal-ref: Information 2025, 16, 71
DOI: 10.3390/info16090719
\\
  This study explores the use of virtual reality (VR) and artificial
intelligence (AI) to predict the presence of dyslexia in Italian and Spanish
university students. In particular, the research investigates whether
VR-derived data from Silent Reading (SR) tests and self-esteem assessments can
differentiate between students that are affected by dyslexia and students that
are not, employing machine learning (ML) algorithms. Participants completed
VR-based tasks measuring reading performance and self-esteem. A preliminary
statistical analysis (t tests and Mann Whitney tests) on these data was
performed, to compare the obtained scores between individuals with and without
dyslexia, revealing significant differences in completion time for the SR test,
but not in accuracy, nor in self esteem. Then, supervised ML models were
trained and tested, demonstrating an ability to classify the presence/absence
of dyslexia with an accuracy of 87.5 per cent for Italian, 66.6 per cent for
Spanish, and 75.0 per cent for the pooled group. These findings suggest that VR
and ML can effectively be used as supporting tools for assessing dyslexia,
particularly by capturing differences in task completion speed, but
language-specific factors may influence classification accuracy.
\\ ( https://arxiv.org/abs/2509.04510 ,  8681kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04512
Date: Tue, 2 Sep 2025 20:53:03 GMT   (157kb)

Title: Scaling behavior of large language models in emotional safety
  classification across sizes and tasks
Authors: Edoardo Pinzuti, Oliver T\"uscher, and Andr\'e Ferreira Castro
Categories: cs.CL cs.LG
\\
  Understanding how large language models (LLMs) process emotionally sensitive
content is critical for building safe and reliable systems, particularly in
mental health contexts. We investigate the scaling behavior of LLMs on two key
tasks: trinary classification of emotional safety (safe vs. unsafe vs.
borderline) and multi-label classification using a six-category safety risk
taxonomy. To support this, we construct a novel dataset by merging several
human-authored mental health datasets (> 15K samples) and augmenting them with
emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA
models (1B, 3B, 8B, 70B) across zero-shot, few-shot, and fine-tuning settings.
Our results show that larger LLMs achieve stronger average performance,
particularly in nuanced multi-label classification and in zero-shot settings.
However, lightweight fine-tuning allowed the 1B model to achieve performance
comparable to larger models and BERT in several high-data categories, while
requiring <2GB VRAM at inference. These findings suggest that smaller,
on-device models can serve as viable, privacy-preserving alternatives for
sensitive applications, offering the ability to interpret emotional context and
maintain safe conversational boundaries. This work highlights key implications
for therapeutic LLM applications and the scalable alignment of safety-critical
systems.
\\ ( https://arxiv.org/abs/2509.04512 ,  157kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04515
Date: Wed, 3 Sep 2025 00:25:25 GMT   (15637kb)

Title: Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through
  Model Explanations
Authors: Martha O. Dimgba, Sharon Oba, Ameeta Agrawal, Philippe J. Giabbanelli
Categories: cs.CL cs.AI
\\
  Language models have been shown to propagate social bias through their
output, particularly in the representation of gender and ethnicity. This paper
investigates gender and ethnicity biases in AI-generated occupational stories.
Representation biases are measured before and after applying our proposed
mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME),
revealing improvements in demographic representation ranging from 2% to 20%.
BAME leverages model-generated explanations to inform targeted prompt
engineering, effectively reducing biases without modifying model parameters. By
analyzing stories generated across 25 occupational groups, three large language
models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and
multiple demographic dimensions, we identify persistent patterns of
overrepresentation and underrepresentation linked to training data stereotypes.
Our findings demonstrate that guiding models with their own internal reasoning
mechanisms can significantly enhance demographic parity, thereby contributing
to the development of more transparent generative AI systems.
\\ ( https://arxiv.org/abs/2509.04515 ,  15637kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04516
Date: Wed, 3 Sep 2025 03:25:11 GMT   (422kb)

Title: Artificially Fluent: Swahili AI Performance Benchmarks Between
  English-Trained and Natively-Trained Datasets
Authors: Sophie Jaffer, Simeon Sayer
Categories: cs.CL cs.CY
Comments: 13 Pages, 3 Figures
\\
  As large language models (LLMs) expand multilingual capabilities, questions
remain about the equity of their performance across languages. While many
communities stand to benefit from AI systems, the dominance of English in
training data risks disadvantaging non-English speakers. To test the hypothesis
that such data disparities may affect model performance, this study compares
two monolingual BERT models: one trained and tested entirely on Swahili data,
and another on comparable English news data. To simulate how multilingual LLMs
process non-English queries through internal translation and abstraction, we
translated the Swahili news data into English and evaluated it using the
English-trained model. This approach tests the hypothesis by evaluating whether
translating Swahili inputs for evaluation on an English model yields better or
worse performance compared to training and testing a model entirely in Swahili,
thus isolating the effect of language consistency versus cross-lingual
abstraction. The results prove that, despite high-quality translation, the
native Swahili-trained model performed better than the Swahili-to-English
translated model, producing nearly four times fewer errors: 0.36% vs. 1.47%
respectively. This gap suggests that translation alone does not bridge
representational differences between languages and that models trained in one
language may struggle to accurately interpret translated inputs due to
imperfect internal knowledge representation, suggesting that native-language
training remains important for reliable outcomes. In educational and
informational contexts, even small performance gaps may compound inequality.
Future research should focus on addressing broader dataset development for
underrepresented languages and renewed attention to multilingual model
evaluation, ensuring the reinforcing effect of global AI deployment on existing
digital divides is reduced.
\\ ( https://arxiv.org/abs/2509.04516 ,  422kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04517
Date: Wed, 3 Sep 2025 07:25:16 GMT   (393kb)

Title: Analysis of Voluntarily Reported Data Post Mesh Implantation for
  Detecting Public Emotion and Identifying Concern Reports
Authors: Indu Bala, Lewis Mitchell, Marianne H Gillam
Categories: cs.CL cs.LG
\\
  Mesh implants are widely utilized in hernia repair surgeries, but
postoperative complications present a significant concern. This study analyzes
patient reports from the Manufacturer and User Facility Device Experience
(MAUDE) database spanning 2000 to 2021 to investigate the emotional aspects of
patients following mesh implantation using Natural Language Processing (NLP).
Employing the National Research Council Canada (NRC) Emotion Lexicon and
TextBlob for sentiment analysis, the research categorizes patient narratives
into eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy,
and disgust) and assesses sentiment polarity. The goal is to discern patterns
in patient sentiment over time and to identify reports signaling urgent
concerns, referred to as "Concern Reports," thereby understanding shifts in
patient experiences in relation to changes in medical device regulation and
technological advancements in healthcare. The study detected an increase in
Concern Reports and higher emotional intensity during the periods of 2011-2012
and 2017-2018. Through temporal analysis of Concern Reports and overall
sentiment, this research provides valuable insights for healthcare
practitioners, enhancing their understanding of patient experiences
post-surgery, which is critical for improving preoperative counselling,
postoperative care, and preparing patients for mesh implant surgeries. The
study underscores the importance of emotional considerations in medical
practices and the potential for sentiment analysis to inform and enhance
patient care.
\\ ( https://arxiv.org/abs/2509.04517 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04518
Date: Wed, 3 Sep 2025 07:41:14 GMT   (2358kb)

Title: Advancing SLM Tool-Use Capability using Reinforcement Learning
Authors: Dhruvi Paprunia, Vansh Kharidia, Pankti Doshi
Categories: cs.CL
\\
  Large Language Models (LLMs) have progressed beyond simple text creation, and
tool use has become increasingly important for complex, real-world tasks. Tool
use in LLMs refers to their ability to utilize external resources such as APIs,
databases, or software functions to extend their functionality beyond
generating text.Tools are used for tasks such as performing calculations,
making API calls to retrieve the current time and date, and more. This
capability enables models to fetch real-time data, execute commands, or solve
problems requiring dynamic interaction, making it indispensable for
applications like AI agents in virtual assistants, robotic control, or
automated workflows.
  However, while LLMs are usually adept tool use, their vast resource
requirements and computation complexity restrict their use in every use case.As
a result, there is an increasing need for more compact and efficient Small
Language Models (SLMs). Small language models (SLMs) struggle in tool use
compared to large language models (LLMs). As soon in Table 1. SLMs are
typically trained on smaller, more specific datasets, resulting in a narrower
knowledge base and limited contextual understanding compared to LLMs.
  This research addresses these challenges by using Reinforcement Learning
(RL), specifically Group Relative Policy Optimization (GRPO), to enhance
tool-use proficiency in SLMs. Unlike conventional fine-tuning approaches that
require heavy computation and often lack adaptability, our method provides an
efficient, effective solution that significantly boosts SLM tool-use accuracy,
increasing their practical utility.
\\ ( https://arxiv.org/abs/2509.04518 ,  2358kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04519
Date: Wed, 3 Sep 2025 10:12:18 GMT   (1202kb)

Title: Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained
  Extraction of Structured Data from Hebrew Free-Text Radiology Reports in
  Crohn's Disease
Authors: Zvi Badash, Hadas Ben-Atya, Naama Gavrielov, Liam Hazan, Gili Focht,
  Ruth Cytter-Kuint, Talar Hagopian, Dan Turner, and Moti Freiman
Categories: cs.CL
\\
  Extracting structured clinical information from radiology reports is
challenging, especially in low-resource languages. This is pronounced in
Crohn's disease, with sparsely represented multi-organ findings. We developed
Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based
model for extraction from Hebrew radiology text. In an administrative database
study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across
Israeli providers. A subset of 512 reports was radiologist-annotated for
findings across six gastrointestinal organs and 15 pathologies, yielding 90
structured labels per subject. Multilabel-stratified split (66%
train+validation; 33% test), preserving label prevalence. Performance was
evaluated with accuracy, F1, Cohen's $\kappa$, AUC, PPV, NPV, and recall. On 24
organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1
0.83$\pm$0.08 and $\kappa$ 0.65$\pm$0.17, outperforming the SMP zero-shot
baseline (F1 0.49$\pm$0.07, $\kappa$ 0.06$\pm$0.07) and standard fine-tuning
(F1 0.30$\pm$0.27, $\kappa$ 0.27$\pm$0.34; paired t-test $p < 10^{-7}$).
Hierarchical inference cuts runtime 5.1$\times$ vs. traditional inference.
Applied to all reports, it revealed associations among ileal wall thickening,
stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in
inflammatory findings. HSMP-BERT offers a scalable solution for structured
extraction in radiology, enabling population-level analysis of Crohn's disease
and demonstrating AI's potential in low-resource settings.
\\ ( https://arxiv.org/abs/2509.04519 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04523
Date: Wed, 3 Sep 2025 14:12:03 GMT   (891kb)

Title: Using LLMs to create analytical datasets: A case study of reconstructing
  the historical memory of Colombia
Authors: David Anderson, Galia Benitez, Margret Bjarnadottir, Shriyan Reyya
Categories: cs.CL cs.CY
\\
  Colombia has been submerged in decades of armed conflict, yet until recently,
the systematic documentation of violence was not a priority for the Colombian
government. This has resulted in a lack of publicly available conflict
information and, consequently, a lack of historical accounts. This study
contributes to Colombia's historical memory by utilizing GPT, a large language
model (LLM), to read and answer questions about over 200,000 violence-related
newspaper articles in Spanish. We use the resulting dataset to conduct both
descriptive analysis and a study of the relationship between violence and the
eradication of coca crops, offering an example of policy analyses that such
data can support. Our study demonstrates how LLMs have opened new research
opportunities by enabling examinations of large text corpora at a previously
infeasible depth.
\\ ( https://arxiv.org/abs/2509.04523 ,  891kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04534
Date: Thu, 4 Sep 2025 04:18:45 GMT   (3241kb)

Title: Quantized Large Language Models in Biomedical Natural Language
  Processing: Evaluation and Recommendation
Authors: Zaifu Zhan, Shuang Zhou, Min Zeng, Kai Yu, Meijia Song, Xiaoyi Chen,
  Jun Wang, Yu Hou, Rui Zhang
Categories: cs.CL cs.AI
Comments: 11 pages, 7 figures
\\
  Large language models have demonstrated remarkable capabilities in biomedical
natural language processing, yet their rapid growth in size and computational
requirements present a major barrier to adoption in healthcare settings where
data privacy precludes cloud deployment and resources are limited. In this
study, we systematically evaluated the impact of quantization on 12
state-of-the-art large language models, including both general-purpose and
biomedical-specific models, across eight benchmark datasets covering four key
tasks: named entity recognition, relation extraction, multi-label
classification, and question answering. We show that quantization substantially
reduces GPU memory requirements-by up to 75%-while preserving model performance
across diverse tasks, enabling the deployment of 70B-parameter models on 40GB
consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness
to advanced prompting methods are largely maintained. These findings provide
significant practical and guiding value, highlighting quantization as a
practical and effective strategy for enabling the secure, local deployment of
large yet high-capacity language models in biomedical contexts, bridging the
gap between technical advances in AI and real-world clinical translation.
\\ ( https://arxiv.org/abs/2509.04534 ,  3241kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04549
Date: Thu, 4 Sep 2025 17:32:56 GMT   (15kb)

Title: Manipulating Transformer-Based Models: Controllability, Steerability,
  and Robust Interventions
Authors: Faruk Alpay, Taylan Alpay
Categories: cs.CL cs.AI
Comments: 13 pages
MSC-class: 68T50, 68T05
ACM-class: I.2.7; I.2.6; I.2.11
\\
  Transformer-based language models excel in NLP tasks, but fine-grained
control remains challenging. This paper explores methods for manipulating
transformer models through principled interventions at three levels: prompts,
activations, and weights. We formalize controllable text generation as an
optimization problem addressable via prompt engineering, parameter-efficient
fine-tuning, model editing, and reinforcement learning. We introduce a unified
framework encompassing prompt-level steering, activation interventions, and
weight-space edits. We analyze robustness and safety implications, including
adversarial attacks and alignment mitigations. Theoretically, we show minimal
weight updates can achieve targeted behavior changes with limited side-effects.
Empirically, we demonstrate >90% success in sentiment control and factual edits
while preserving base performance, though generalization-specificity trade-offs
exist. We discuss ethical dual-use risks and the need for rigorous evaluation.
This work lays groundwork for designing controllable and robust language
models.
\\ ( https://arxiv.org/abs/2509.04549 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04605
Date: Thu, 4 Sep 2025 18:40:52 GMT   (5832kb)

Title: Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm
  Recognition -- Multimodal Fusion, Challenges, and Future Prospects
Authors: Xiyuan Gao, Shekhar Nayak, Matt Coler
Categories: cs.CL
Comments: 20 pages, 7 figures, Submitted to IEEE Transactions on Affective
  Computing
\\
  Sarcasm, a common feature of human communication, poses challenges in
interpersonal interactions and human-machine interactions. Linguistic research
has highlighted the importance of prosodic cues, such as variations in pitch,
speaking rate, and intonation, in conveying sarcastic intent. Although previous
work has focused on text-based sarcasm detection, the role of speech data in
recognizing sarcasm has been underexplored. Recent advancements in speech
technology emphasize the growing importance of leveraging speech data for
automatic sarcasm recognition, which can enhance social interactions for
individuals with neurodegenerative conditions and improve machine understanding
of complex human language use, leading to more nuanced interactions. This
systematic review is the first to focus on speech-based sarcasm recognition,
charting the evolution from unimodal to multimodal approaches. It covers
datasets, feature extraction, and classification methods, and aims to bridge
gaps across diverse research domains. The findings include limitations in
datasets for sarcasm recognition in speech, the evolution of feature extraction
techniques from traditional acoustic features to deep learning-based
representations, and the progression of classification methods from unimodal
approaches to multimodal fusion techniques. In so doing, we identify the need
for greater emphasis on cross-cultural and multilingual sarcasm recognition, as
well as the importance of addressing sarcasm as a multimodal phenomenon, rather
than a text-based challenge.
\\ ( https://arxiv.org/abs/2509.04605 ,  5832kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04606
Date: Thu, 4 Sep 2025 18:41:59 GMT   (2668kb)

Title: Sample-efficient Integration of New Modalities into Large Language
  Models
Authors: Osman Batur \.Ince, Andr\'e F. T. Martins, Oisin Mac Aodha, Edoardo M.
  Ponti
Categories: cs.CL cs.AI cs.CV
Comments: Pre-print
\\
  Multimodal foundation models can process several modalities. However, since
the space of possible modalities is large and evolving over time, training a
model from scratch to encompass all modalities is unfeasible. Moreover,
integrating a modality into a pre-existing foundation model currently requires
a significant amount of paired data, which is often not available for
low-resource modalities. In this paper, we introduce a method for
sample-efficient modality integration (SEMI) into Large Language Models (LLMs).
To this end, we devise a hypernetwork that can adapt a shared projector --
placed between modality-specific encoders and an LLM -- to any modality. The
hypernetwork, trained on high-resource modalities (i.e., text, speech, audio,
video), is conditioned on a few samples from any arbitrary modality at
inference time to generate a suitable adapter. To increase the diversity of
training modalities, we artificially multiply the number of encoders through
isometric transformations. We find that SEMI achieves a significant boost in
sample efficiency during few-shot integration of new modalities (i.e.,
satellite images, astronomical images, inertial measurements, and molecules)
with encoders of arbitrary embedding dimensionality. For instance, to reach the
same accuracy as 32-shot SEMI, training the projector from scratch needs
64$\times$ more data. As a result, SEMI holds promise to extend the modality
coverage of foundation models.
\\ ( https://arxiv.org/abs/2509.04606 ,  2668kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04615
Date: Thu, 4 Sep 2025 18:59:07 GMT   (16kb)

Title: Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing
  LLMs
Authors: Brennen Hill, Surendra Parla, Venkata Abhijeeth Balabhadruni, Atharv
  Prajod Padmalayam, Sujay Chandra Shekara Sharma
Categories: cs.CL cs.CR cs.LG
MSC-class: 68T07, 68T50
ACM-class: I.2.7; I.2.6; K.6.5
\\
  The proliferation of Large Language Models (LLMs) has introduced critical
security challenges, where adversarial actors can manipulate input prompts to
cause significant harm and circumvent safety alignments. These prompt-based
attacks exploit vulnerabilities in a model's design, training, and contextual
understanding, leading to intellectual property theft, misinformation
generation, and erosion of user trust. A systematic understanding of these
attack vectors is the foundational step toward developing robust
countermeasures. This paper presents a comprehensive literature survey of
prompt-based attack methodologies, categorizing them to provide a clear threat
model. By detailing the mechanisms and impacts of these exploits, this survey
aims to inform the research community's efforts in building the next generation
of secure LLMs that are inherently resistant to unauthorized distillation,
fine-tuning, and editing.
\\ ( https://arxiv.org/abs/2509.04615 ,  16kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04650
Date: Thu, 4 Sep 2025 20:22:33 GMT   (1617kb)

Title: Comparative Analysis of Transformer Models in Disaster Tweet
  Classification for Public Safety
Authors: Sharif Noor Zisad and Ragib Hasan
Categories: cs.CL cs.AI
\\
  Twitter and other social media platforms have become vital sources of real
time information during disasters and public safety emergencies. Automatically
classifying disaster related tweets can help emergency services respond faster
and more effectively. Traditional Machine Learning (ML) models such as Logistic
Regression, Naive Bayes, and Support Vector Machines have been widely used for
this task, but they often fail to understand the context or deeper meaning of
words, especially when the language is informal, metaphorical, or ambiguous. We
posit that, in this context, transformer based models can perform better than
traditional ML models. In this paper, we evaluate the effectiveness of
transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for
classifying disaster related tweets. These models are compared with traditional
ML approaches to highlight the performance gap. Experimental results show that
BERT achieved the highest accuracy (91%), significantly outperforming
traditional models like Logistic Regression and Naive Bayes (both at 82%). The
use of contextual embeddings and attention mechanisms allows transformer models
to better understand subtle language in tweets, where traditional ML models
fall short. This research demonstrates that transformer architectures are far
more suitable for public safety applications, offering improved accuracy,
deeper language understanding, and better generalization across real world
social media text.
\\ ( https://arxiv.org/abs/2509.04650 ,  1617kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04655
Date: Thu, 4 Sep 2025 20:50:51 GMT   (2929kb)

Title: Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs
Authors: Ayush Gupta, Ramneet Kaur, Anirban Roy, Adam D. Cobb, Rama Chellappa,
  Susmit Jha
Categories: cs.CL cs.AI
Comments: Accepted to EMNLP 2025 main conference
\\
  We propose a novel inference-time out-of-domain (OOD) detection algorithm for
specialized large language models (LLMs). Despite achieving state-of-the-art
performance on in-domain tasks through fine-tuning, specialized LLMs remain
vulnerable to incorrect or unreliable outputs when presented with OOD inputs,
posing risks in critical applications. Our method leverages the Inductive
Conformal Anomaly Detection (ICAD) framework, using a new non-conformity
measure based on the model's dropout tolerance. Motivated by recent findings on
polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs
exhibit higher dropout tolerance than OOD inputs. We aggregate dropout
tolerance across multiple layers via a valid ensemble approach, improving
detection while maintaining theoretical false alarm bounds from ICAD.
Experiments with medical-specialized LLMs show that our approach detects OOD
inputs better than baseline methods, with AUROC improvements of $2\%$ to $37\%$
when treating OOD datapoints as positives and in-domain test datapoints as
negatives.
\\ ( https://arxiv.org/abs/2509.04655 ,  2929kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04656
Date: Thu, 4 Sep 2025 20:57:35 GMT   (1597kb)

Title: AraHalluEval: A Fine-grained Hallucination Evaluation Framework for
  Arabic LLMs
Authors: Aisha Alansari and Hamzah Luqman
Categories: cs.CL
\\
  Recently, extensive research on the hallucination of the large language
models (LLMs) has mainly focused on the English language. Despite the growing
number of multilingual and Arabic-specific LLMs, evaluating LLMs' hallucination
in the Arabic context remains relatively underexplored. The knowledge gap is
particularly pressing given Arabic's widespread use across many regions and its
importance in global communication and media. This paper presents the first
comprehensive hallucination evaluation of Arabic and multilingual LLMs on two
critical Arabic natural language generation tasks: generative question
answering (GQA) and summarization. This study evaluates a total of 12 LLMs,
including 4 Arabic pre-trained models, 4 multilingual models, and 4
reasoning-based models. To assess the factual consistency and faithfulness of
LLMs' outputs, we developed a fine-grained hallucination evaluation framework
consisting of 12 fine-grained hallucination indicators that represent the
varying characteristics of each task. The results reveal that factual
hallucinations are more prevalent than faithfulness errors across all models
and tasks. Notably, the Arabic pre-trained model Allam consistently
demonstrates lower hallucination rates than multilingual models and a
comparative performance with reasoning-based models. The code is available at:
\href{https://github.com/aishaalansari57/AraHalluEval}{Github link}.
\\ ( https://arxiv.org/abs/2509.04656 ,  1597kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04657
Date: Thu, 4 Sep 2025 21:03:59 GMT   (336kb)

Title: Evaluating NL2SQL via SQL2NL
Authors: Mohammadtaher Safarzadeh, Afshin Oroojlooyjadid, Dan Roth
Categories: cs.CL cs.AI cs.DB cs.LG
Comments: Accepted to EMNLP 2025
\\
  Robust evaluation in the presence of linguistic variation is key to
understanding the generalization capabilities of Natural Language to SQL
(NL2SQL) models, yet existing benchmarks rarely address this factor in a
systematic or controlled manner. We propose a novel schema-aligned paraphrasing
framework that leverages SQL-to-NL (SQL2NL) to automatically generate
semantically equivalent, lexically diverse queries while maintaining alignment
with the original schema and intent. This enables the first targeted evaluation
of NL2SQL robustness to linguistic variation in isolation-distinct from prior
work that primarily investigates ambiguity or schema perturbations. Our
analysis reveals that state-of-the-art models are far more brittle than
standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop
in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries,
while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to
42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We
also find that robustness degradation varies significantly with query
complexity, dataset, and domain -- highlighting the need for evaluation
frameworks that explicitly measure linguistic generalization to ensure reliable
performance in real-world settings.
\\ ( https://arxiv.org/abs/2509.04657 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04664
Date: Thu, 4 Sep 2025 21:26:31 GMT   (142kb)

Title: Why Language Models Hallucinate
Authors: Adam Tauman Kalai and Ofir Nachum and Santosh S. Vempala and Edwin
  Zhang
Categories: cs.CL
\\
  Like students facing hard exam questions, large language models sometimes
guess when uncertain, producing plausible yet incorrect statements instead of
admitting uncertainty. Such "hallucinations" persist even in state-of-the-art
systems and undermine trust. We argue that language models hallucinate because
the training and evaluation procedures reward guessing over acknowledging
uncertainty, and we analyze the statistical causes of hallucinations in the
modern training pipeline. Hallucinations need not be mysterious -- they
originate simply as errors in binary classification. If incorrect statements
cannot be distinguished from facts, then hallucinations in pretrained language
models will arise through natural statistical pressures. We then argue that
hallucinations persist due to the way most evaluations are graded -- language
models are optimized to be good test-takers, and guessing when uncertain
improves test performance. This "epidemic" of penalizing uncertain responses
can only be addressed through a socio-technical mitigation: modifying the
scoring of existing benchmarks that are misaligned but dominate leaderboards,
rather than introducing additional hallucination evaluations. This change may
steer the field toward more trustworthy AI systems.
\\ ( https://arxiv.org/abs/2509.04664 ,  142kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04696
Date: Thu, 4 Sep 2025 23:05:23 GMT   (331kb)

Title: ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs
Authors: Samira Khorshidi, Azadeh Nikfarjam, Suprita Shankar, Yisi Sang, Yash
  Govind, Hyun Jang, Ali Kasgari, Alexis McClimans, Mohamed Soliman, Vishnu
  Konda, Ahmed Fakhry, Xiaoguang Qi
Categories: cs.CL cs.AI
\\
  Knowledge graphs (KGs) are foundational to many AI applications, but
maintaining their freshness and completeness remains costly. We present ODKE+,
a production-grade system that automatically extracts and ingests millions of
open-domain facts from web sources with high precision. ODKE+ combines modular
components into a scalable pipeline: (1) the Extraction Initiator detects
missing or stale facts, (2) the Evidence Retriever collects supporting
documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and
ontology-guided prompting for large language models (LLMs), (4) a lightweight
Grounder validates extracted facts using a second LLM, and (5) the Corroborator
ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates
ontology snippets tailored to each entity type to align extractions with schema
constraints, enabling scalable, type-consistent fact extraction across 195
predicates. The system supports batch and streaming modes, processing over 9
million Wikipedia pages and ingesting 19 million high-confidence facts with
98.8% precision. ODKE+ significantly improves coverage over traditional
methods, achieving up to 48% overlap with third-party KGs and reducing update
lag by 50 days on average. Our deployment demonstrates that LLM-based
extraction, grounded in ontological structure and verification workflows, can
deliver trustworthiness, production-scale knowledge ingestion with broad
real-world applicability. A recording of the system demonstration is included
with the submission and is also available at https://youtu.be/UcnE3_GsTWs.
\\ ( https://arxiv.org/abs/2509.04696 ,  331kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04702
Date: Thu, 4 Sep 2025 23:14:52 GMT   (8095kb)

Title: OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational
  Speech Dataset with Diverse Topics
Authors: Wei Chu, Yuanzhe Dong, Ke Tan, Dong Han, Xavier Menendez-Pidal, Ruchao
  Fan, Chenfeng Miao, Chanwoo Kim, Bhiksha Raj, Rita Singh
Categories: cs.CL
\\
  OleSpeech-IV dataset is a large-scale multispeaker and multilingual
conversational speech dataset with diverse topics. The audio content comes from
publicly-available English podcasts, talk shows, teleconferences, and other
conversations. Speaker names, turns, and transcripts are human-sourced and
refined by a proprietary pipeline, while additional information such as
timestamps and confidence scores is derived from the pipeline. The IV denotes
its position as Tier IV in the Olewave dataset series. In addition, we have
open-sourced a subset, OleSpeech-IV-2025-EN-AR-100, for non-commercial research
use.
\\ ( https://arxiv.org/abs/2509.04702 ,  8095kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04716
Date: Fri, 5 Sep 2025 00:06:00 GMT   (999kb)

Title: KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced
  Question Answering
Authors: Yushi Sun, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan
  Tang, Lei Chen
Categories: cs.CL cs.AI cs.IR
Comments: Accepted by EMNLP Findings 2025
\\
  Retrieval-Augmented Generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by incorporating external data, with Knowledge Graphs
(KGs) offering crucial information for question answering. Traditional
Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing,
which typically retrieves knowledge strictly necessary for answer generation,
thus often suffer from low coverage due to rigid schema requirements and
semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that
enhances QA coverage by retrieving a broader subgraph likely to contain
relevant information. Our retrieval-filtering-summarization approach, combined
with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs,
reduces noises and improves QA for both simple and complex questions.
Experiments demonstrate that KERAG surpasses state-of-the-art solutions by
about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.
\\ ( https://arxiv.org/abs/2509.04716 ,  999kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04745
Date: Fri, 5 Sep 2025 01:55:41 GMT   (156kb)

Title: Phonological Representation Learning for Isolated Signs Improves
  Out-of-Vocabulary Generalization
Authors: Lee Kezar, Zed Sehyr, Jesse Thomason
Categories: cs.CL cs.CV
\\
  Sign language datasets are often not representative in terms of vocabulary,
underscoring the need for models that generalize to unseen signs. Vector
quantization is a promising approach for learning discrete, token-like
representations, but it has not been evaluated whether the learned units
capture spurious correlations that hinder out-of-vocabulary performance. This
work investigates two phonological inductive biases: Parameter Disentanglement,
an architectural bias, and Phonological Semi-Supervision, a regularization
technique, to improve isolated sign recognition of known signs and
reconstruction quality of unseen signs with a vector-quantized autoencoder. The
primary finding is that the learned representations from the proposed model are
more effective for one-shot reconstruction of unseen signs and more
discriminative for sign identification compared to a controlled baseline. This
work provides a quantitative analysis of how explicit, linguistically-motivated
biases can improve the generalization of learned representations of sign
language.
\\ ( https://arxiv.org/abs/2509.04745 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04753
Date: Fri, 5 Sep 2025 02:07:40 GMT   (729kb)

Title: A Study of Large Language Models for Patient Information Extraction:
  Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning
Authors: Cheng Peng, Xinyu Dong, Mengxian Lyu, Daniel Paredes, Yaoyun Zhang,
  Yonghui Wu
Categories: cs.CL cs.AI
\\
  Natural language processing (NLP) is a key technology to extract important
patient information from clinical narratives to support healthcare
applications. The rapid development of large language models (LLMs) has
revolutionized many NLP tasks in the clinical domain, yet their optimal use in
patient information extraction tasks requires further exploration. This study
examines LLMs' effectiveness in patient information extraction, focusing on LLM
architectures, fine-tuning strategies, and multi-task instruction tuning
techniques for developing robust and generalizable patient information
extraction systems. This study aims to explore key concepts of using LLMs for
clinical concept and relation extraction tasks, including: (1) encoder-only or
decoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT)
algorithms, and (3) multi-task instruction tuning on few-shot learning
performance. We benchmarked a suite of LLMs, including encoder-based LLMs
(BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1,
GatorTronLlama), across five datasets. We compared traditional full-size
fine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning
framework that combines both tasks across four datasets to evaluate the
zero-shot and few-shot learning performance using the leave-one-dataset-out
strategy.
\\ ( https://arxiv.org/abs/2509.04753 ,  729kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04770
Date: Fri, 5 Sep 2025 02:58:45 GMT   (575kb)

Title: Research on Multi-hop Inference Optimization of LLM Based on MQUAKE
  Framework
Authors: Zucheng Liang, Wenxin Wei, Kaijie Zhang, Hongyi Chen
Categories: cs.CL cs.LG
\\
  Accurately answering complex questions has consistently been a significant
challenge for Large Language Models (LLMs). To address this, this paper
proposes a multi-hop question decomposition method for complex questions,
building upon research within the MQUAKE framework. Utilizing the LLAMA3 model,
we systematically investigate the impact of multi-hop question decomposition
within knowledge graphs on model comprehension and reasoning accuracy, both
before and after model training. In our experiments, we systematically
partitioned and converted the MQUAKE-T dataset into two distinct formats: a
single-hop dataset designed for directly answering complex questions, and a
multi-hop dataset constructed using the multi-hop question decomposition
method. We then fine-tuned the LLAMA3 model on these datasets and conducted
inference tests. Our results demonstrate that, without fine-tuning the LLM, the
prediction performance based on the multi-hop question decomposition method
significantly outperforms the method of directly answering complex questions.
After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance
of both approaches improved compared to the untrained baseline. Crucially, the
method utilizing multi-hop decomposition consistently maintained its
superiority. These findings validate the effectiveness of the multi-hop
decomposition method both before and after training, demonstrating its
capability to effectively enhance the LLM's ability to answer complex
questions.
\\ ( https://arxiv.org/abs/2509.04770 ,  575kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04779
Date: Fri, 5 Sep 2025 03:22:38 GMT   (46kb)

Title: Decoders Laugh as Loud as Encoders
Authors: Eli Borodach, Raj Dandekar, Rajat Dandekar and Sreedath Panat
Categories: cs.CL cs.AI
\\
  From the dawn of the computer, Allen Turing dreamed of a robot that could
communicate using language as a human being. The recent advances in the field
of Large Language Models (LLMs) shocked the scientific community when a single
model can apply for various natural language processing (NLP) tasks, while the
output results are sometimes even better than most human communication skills.
Models such as GPT, Claude, Grok, etc. have left their mark on the scientific
community. However, it is unclear how much these models understand what they
produce, especially in a nuanced theme such as humor. The question of whether
computers understand humor is still open (among the decoders, the latest to be
checked was GPT-2). We addressed this issue in this paper; we have showed that
a fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well
as the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)
\\ ( https://arxiv.org/abs/2509.04779 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04784
Date: Fri, 5 Sep 2025 03:47:06 GMT   (84kb)

Title: Enhancing Diversity in Large Language Models via Determinantal Point
  Processes
Authors: Yilei Chen, Souradip Chakraborty, Lorenz Wolf, Ioannis Ch.
  Paschalidis, Aldo Pacchiano
Categories: cs.CL cs.AI
\\
  Supervised fine-tuning and reinforcement learning are two popular methods for
post-training large language models (LLMs). While improving the model's
performance on downstream tasks, they often reduce the model's output
diversity, leading to narrow, canonical responses. Existing methods to enhance
diversity are limited, either by operating at inference time or by focusing on
lexical differences. We propose a novel training method named DQO based on
determinantal point processes (DPPs) to jointly optimize LLMs for quality and
semantic diversity. Our approach samples and embeds a group of responses for
each prompt, then uses the determinant of a kernel-based similarity matrix to
measure diversity as the volume spanned by the embeddings of these responses.
Experiments across instruction-following, summarization, story generation, and
reasoning tasks demonstrate that our method substantially improves semantic
diversity without sacrificing model quality.
\\ ( https://arxiv.org/abs/2509.04784 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04794
Date: Fri, 5 Sep 2025 04:19:15 GMT   (41kb)

Title: Personality as a Probe for LLM Evaluation: Method Trade-offs and
  Downstream Effects
Authors: Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven
Categories: cs.CL
\\
  Personality manipulation in large language models (LLMs) is increasingly
applied in customer service and agentic scenarios, yet its mechanisms and
trade-offs remain unclear. We present a systematic study of personality control
using the Big Five traits, comparing in-context learning (ICL),
parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our
contributions are fourfold. First, we construct a contrastive dataset with
balanced high/low trait responses, enabling effective steering vector
computation and fair cross-method evaluation. Second, we introduce a unified
evaluation framework based on within-run $\Delta$ analysis that disentangles,
reasoning capability, agent performance, and demographic bias across MMLU,
GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to
separate openness from conscientiousness, addressing representational overlap
in trait encoding. Fourth, we propose a three-level stability framework that
quantifies method-, trait-, and combination-level robustness, offering
practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT
and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment
with minimal capability loss, PEFT delivers the highest alignment at the cost
of degraded task performance, and MS provides lightweight runtime control with
competitive effectiveness. Trait-level analysis shows openness as uniquely
challenging, agreeableness as most resistant to ICL, and personality encoding
consolidating around intermediate layers. Taken together, these results
establish personality manipulation as a multi-level probe into behavioral
representation, linking surface conditioning, parameter encoding, and
activation-level steering, and positioning mechanistic steering as a
lightweight alternative to fine-tuning for both deployment and
interpretability.
\\ ( https://arxiv.org/abs/2509.04794 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04796
Date: Fri, 5 Sep 2025 04:29:15 GMT   (280kb)

Title: Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under
  Recursive Synthetic Training
Authors: Figarri Keisha, Zekun Wu, Ze Wang, Adriano Koshiyama, Philip Treleaven
Categories: cs.CL
\\
  Large language models increasingly rely on synthetic data due to
human-written content scarcity, yet recursive training on model-generated
outputs leads to model collapse, a degenerative process threatening factual
reliability. We define knowledge collapse as a distinct three-stage phenomenon
where factual accuracy deteriorates while surface fluency persists, creating
"confidently wrong" outputs that pose critical risks in accuracy-dependent
domains. Through controlled experiments with recursive synthetic training, we
demonstrate that collapse trajectory and timing depend critically on
instruction format, distinguishing instruction-following collapse from
traditional model collapse through its conditional, prompt-dependent nature. We
propose domain-specific synthetic training as a targeted mitigation strategy
that achieves substantial improvements in collapse resistance while maintaining
computational efficiency. Our evaluation framework combines model-centric
indicators with task-centric metrics to detect distinct degradation phases,
enabling reproducible assessment of epistemic deterioration across different
language models. These findings provide both theoretical insights into collapse
dynamics and practical guidance for sustainable AI training in
knowledge-intensive applications where accuracy is paramount.
\\ ( https://arxiv.org/abs/2509.04796 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04802
Date: Fri, 5 Sep 2025 04:36:17 GMT   (4951kb)

Title: Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in
  LLMs with Action Graphs
Authors: Ilham Wicaksono, Zekun Wu, Theo King, Adriano Koshiyama, Philip
  Treleaven
Categories: cs.CL
\\
  As large language models transition to agentic systems, current safety
evaluation frameworks face critical gaps in assessing deployment-specific
risks. We introduce AgentSeer, an observability-based evaluation framework that
decomposes agentic executions into granular action and component graphs,
enabling systematic agentic-situational assessment. Through cross-model
validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and
iterative refinement attacks, we demonstrate fundamental differences between
model-level and agentic-level vulnerability profiles. Model-level evaluation
reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash
(50.00% ASR), with both models showing susceptibility to social engineering
while maintaining logic-based attack resistance. However, agentic-level
assessment exposes agent-specific risks invisible to traditional evaluation. We
discover "agentic-only" vulnerabilities that emerge exclusively in agentic
contexts, with tool-calling showing 24-60% higher ASR across both models.
Cross-model analysis reveals universal agentic patterns, agent transfer
operations as highest-risk tools, semantic rather than syntactic vulnerability
mechanisms, and context-dependent attack effectiveness, alongside
model-specific security profiles in absolute ASR levels and optimal injection
strategies. Direct attack transfer from model-level to agentic contexts shows
degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash:
28%), while context-aware iterative attacks successfully compromise objectives
that failed at model-level, confirming systematic evaluation gaps. These
findings establish the urgent need for agentic-situation evaluation paradigms,
with AgentSeer providing the standardized methodology and empirical validation.
\\ ( https://arxiv.org/abs/2509.04802 ,  4951kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04813
Date: Fri, 5 Sep 2025 05:24:56 GMT   (469kb)

Title: Analyzing Finnish Inflectional Classes through Discriminative Lexicon
  and Deep Learning Models
Authors: Alexandre Nikolaev, Yu-Ying Chuang, R. Harald Baayen
Categories: cs.CL
\\
  Descriptions of complex nominal or verbal systems make use of inflectional
classes. Inflectional classes bring together nouns which have similar stem
changes and use similar exponents in their paradigms. Although inflectional
classes can be very useful for language teaching as well as for setting up
finite state morphological systems, it is unclear whether inflectional classes
are cognitively real, in the sense that native speakers would need to discover
these classes in order to learn how to properly inflect the nouns of their
language. This study investigates whether the Discriminative Lexicon Model
(DLM) can understand and produce Finnish inflected nouns without setting up
inflectional classes, using a dataset with 55,271 inflected nouns of 2000
high-frequency Finnish nouns from 49 inflectional classes. Several DLM
comprehension and production models were set up. Some models were not informed
about frequency of use, and provide insight into learnability with infinite
exposure (endstate learning). Other models were set up from a usage based
perspective, and were trained with token frequencies being taken into
consideration (frequency-informed learning). On training data, models performed
with very high accuracies. For held-out test data, accuracies decreased, as
expected, but remained acceptable. Across most models, performance increased
for inflectional classes with more types, more lower-frequency words, and more
hapax legomena, mirroring the productivity of the inflectional classes. The
model struggles more with novel forms of unproductive and less productive
classes, and performs far better for unseen forms belonging to productive
classes. However, for usage-based production models, frequency was the dominant
predictor of model performance, and correlations with measures of productivity
were tenuous or absent.
\\ ( https://arxiv.org/abs/2509.04813 ,  469kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04821
Date: Fri, 5 Sep 2025 05:45:07 GMT   (1172kb)

Title: AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding
Authors: Yan Xie, Yibo Cui, Liang Xie, Erwei Yin
Categories: cs.CL
Comments: 5 pages, 1 figures
\\
  Spoken Language Understanding (SLU) is a core component of conversational
systems, enabling machines to interpret user utterances. Despite its
importance, developing effective SLU systems remains challenging due to the
scarcity of labeled training data and the computational burden of deploying
Large Language Models (LLMs) in real-world applications. To further alleviate
these issues, we propose an Adaptive Feature Distillation framework that
transfers rich semantic representations from a General Text Embeddings
(GTE)-based teacher model to a lightweight student model. Our method introduces
a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to
align heterogeneous feature spaces, and a Dynamic Distillation Coefficient
(DDC) that adaptively modulates the distillation strength based on real-time
feedback from intent and slot prediction performance. Experiments on the
Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves
state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score,
and 85.50% overall accuracy.
\\ ( https://arxiv.org/abs/2509.04821 ,  1172kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04866
Date: Fri, 5 Sep 2025 07:30:01 GMT   (5135kb)

Title: Memorization $\neq$ Understanding: Do Large Language Models Have the
  Ability of Scenario Cognition?
Authors: Boxiang Ma, Ru Li, Yuanlong Wang, Hongye Tan, Xiaoli Li
Categories: cs.CL
Comments: EMNLP 2025 Main Conference
\\
  Driven by vast and diverse textual data, large language models (LLMs) have
demonstrated impressive performance across numerous natural language processing
(NLP) tasks. Yet, a critical question persists: does their generalization arise
from mere memorization of training data or from deep semantic understanding? To
investigate this, we propose a bi-perspective evaluation framework to assess
LLMs' scenario cognition - the ability to link semantic scenario elements with
their arguments in context. Specifically, we introduce a novel scenario-based
dataset comprising diverse textual descriptions of fictional facts, annotated
with scenario elements. LLMs are evaluated through their capacity to answer
scenario-related questions (model output perspective) and via probing their
internal representations for encoded scenario elements-argument associations
(internal representation perspective). Our experiments reveal that current LLMs
predominantly rely on superficial memorization, failing to achieve robust
semantic scenario cognition, even in simple cases. These findings expose
critical limitations in LLMs' semantic understanding and offer cognitive
insights for advancing their capabilities.
\\ ( https://arxiv.org/abs/2509.04866 ,  5135kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04868
Date: Fri, 5 Sep 2025 07:30:40 GMT   (81kb)

Title: Using LLMs for Multilingual Clinical Entity Linking to ICD-10
Authors: Sylvia Vassileva, Ivan Koychev, Svetla Boytcheva
Categories: cs.CL
Comments: 7 pages, 2 Figures, to be published in Proceedings of the 15th
  International Conference on Recent Advances in Natural Language Processing,
  RANLP 2025
\\
  The linking of clinical entities is a crucial part of extracting structured
information from clinical texts. It is the process of assigning a code from a
medical ontology or classification to a phrase in the text. The International
Classification of Diseases - 10th revision (ICD-10) is an international
standard for classifying diseases for statistical and insurance purposes.
Automatically assigning the correct ICD-10 code to terms in discharge summaries
will simplify the work of healthcare professionals and ensure consistent coding
in hospitals. Our paper proposes an approach for linking clinical terms to
ICD-10 codes in different languages using Large Language Models (LLMs). The
approach consists of a multistage pipeline that uses clinical dictionaries to
match unambiguous terms in the text and then applies in-context learning with
GPT-4.1 to predict the ICD-10 code for the terms that do not match the
dictionary. Our system shows promising results in predicting ICD-10 codes on
different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on
subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.
\\ ( https://arxiv.org/abs/2509.04868 ,  81kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04884
Date: Fri, 5 Sep 2025 08:03:01 GMT   (10857kb)

Title: L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning
Authors: Raul Singh, Nicolo Brunello, Vincenzo Scotti, Mark James Carman
Categories: cs.CL cs.PF
Comments: Work published at ICNLSP 2025, waiting for publication link
\\
  The ability of Large Language Models (LLMs) to solve complex tasks has made
them crucial in the development of AI-based applications. However, the high
computational requirements to fine-tune these LLMs on downstream tasks pose
significant challenges, particularly when resources are limited. In response to
this challenge, we introduce L1RA, a novel technique aimed at dynamically
distributing the rank of low-rank adapters during fine-tuning using LoRA. Given
a rank budget (i.e., total sum of adapters rank), L1RA leverages L1
regularisation to prune redundant ranks and redistribute them across adapters,
thereby optimising resource utilisation. Through a series of comprehensive
experiments, we empirically demonstrate that L1RA maintains comparable or even
reduced computational overhead compared to other LoRA variants, including the
vanilla approach, while achieving same or better performances. Moreover, the
post-training analysis of rank distribution unveiled insights into the specific
model components requiring the most adaptation to align with the task
objective: the feed-forward layers and the attention output projection. These
results highlight the efficacy of L1RA in not only enhancing the efficiency of
LLM fine-tuning, but also in providing valuable diagnostic information for
model refinement and customisation. In conclusion, L1RA stands as a promising
technique for advancing the performance and interpretability of LLM adaptation,
particularly in scenarios where computational resources are constrained.
\\ ( https://arxiv.org/abs/2509.04884 ,  10857kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04897
Date: Fri, 5 Sep 2025 08:17:59 GMT   (304kb)

Title: PLaMo 2 Technical Report
Authors: Preferred Networks: Kaizaburo Chubachi, Yasuhiro Fujita, Shinichi
  Hemmi, Yuta Hirokawa, Toshiki Kataoka, Goro Kobayashi, Kenichi Maehashi,
  Calvin Metzger, Hiroaki Mikami, Shogo Murai, Daisuke Nishino, Kento Nozawa,
  Shintarou Okada, Daisuke Okanohara, Shunta Saito, Shotaro Sano, Shuji Suzuki,
  Daisuke Tanaka, Avinash Ummadisingu, Hanqin Wang, Sixue Wang, Tianqi Xu
Categories: cs.CL cs.AI cs.LG
\\
  In this report, we introduce PLaMo 2, a series of Japanese-focused large
language models featuring a hybrid Samba-based architecture that transitions to
full attention via continual pre-training to support 32K token contexts.
Training leverages extensive synthetic corpora to overcome data scarcity, while
computational efficiency is achieved through weight reuse and structured
pruning. This efficient pruning methodology produces an 8B model that achieves
performance comparable to our previous 100B model. Post-training further
refines the models using a pipeline of supervised fine-tuning (SFT) and direct
preference optimization (DPO), enhanced by synthetic Japanese instruction data
and model merging techniques. Optimized for inference using vLLM and
quantization with minimal accuracy loss, the PLaMo 2 models achieve
state-of-the-art results on Japanese benchmarks, outperforming similarly-sized
open models in instruction-following, language fluency, and Japanese-specific
knowledge.
\\ ( https://arxiv.org/abs/2509.04897 ,  304kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04903
Date: Fri, 5 Sep 2025 08:21:41 GMT   (1857kb)

Title: ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation
  Reinforcement Learning
Authors: Jianghao Chen, Wei Sun, Qixiang Yin, Lingxing Kong, Zhixing Tan,
  Jiajun Zhang
Categories: cs.CL
Comments: Under review, our code is available at https://github.com/ZNLP/ACE-RL
\\
  Large Language Models (LLMs) have demonstrated remarkable progress in
long-context understanding, yet they face significant challenges in
high-quality long-form generation. Existing studies primarily suffer from two
limitations: (1) A heavy reliance on scarce, high-quality long-form response
data for supervised fine-tuning (SFT) or for pairwise preference reward in
reinforcement learning (RL). (2) Focus on coarse-grained quality optimization
dimensions, such as relevance, coherence, and helpfulness, overlooking the
fine-grained specifics inherent to diverse long-form generation scenarios. To
address this issue, we propose a framework using Adaptive Constraint-Enhanced
reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first
automatically deconstructs each instruction into a set of fine-grained,
adaptive constraint criteria by identifying its underlying intents and demands.
Subsequently, we design a reward mechanism that quantifies the quality of
long-form responses based on their satisfaction over corresponding constraints,
converting subjective quality evaluation into constraint verification. Finally,
we utilize reinforcement learning to guide models toward superior long-form
generation capabilities. Experimental results demonstrate that our ACE-RL
framework significantly outperforms existing SFT and RL baselines by 20.70% and
7.32% on WritingBench, and our top-performing model even surpasses proprietary
systems like GPT-4o by 7.10%, providing a more effective training paradigm for
LLMs to generate high-quality content across diverse long-form generation
scenarios.
\\ ( https://arxiv.org/abs/2509.04903 ,  1857kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04969
Date: Fri, 5 Sep 2025 09:49:39 GMT   (6140kb)

Title: Classification of kinetic-related injury in hospital triage data using
  NLP
Authors: Midhun Shyam, Jim Basilakis, Kieran Luken, Steven Thomas, John
  Crozier, Paul M. Middleton, X. Rosalind Wang
Categories: cs.CL cs.LG
Comments: Accepted as a short paper for publishing at ADMA 2025
  (https://adma2025.github.io), with Supplementary Material available at
  https://github.com/CRMDS/Kinetic-Injury-Triage
\\
  Triage notes, created at the start of a patient's hospital visit, contain a
wealth of information that can help medical staff and researchers understand
Emergency Department patient epidemiology and the degree of time-dependent
illness or injury. Unfortunately, applying modern Natural Language Processing
and Machine Learning techniques to analyse triage data faces some challenges:
Firstly, hospital data contains highly sensitive information that is subject to
privacy regulation thus need to be analysed on site; Secondly, most hospitals
and medical facilities lack the necessary hardware to fine-tune a Large
Language Model (LLM), much less training one from scratch; Lastly, to identify
the records of interest, expert inputs are needed to manually label the
datasets, which can be time-consuming and costly. We present in this paper a
pipeline that enables the classification of triage data using LLM and limited
compute resources. We first fine-tuned a pre-trained LLM with a classifier
using a small (2k) open sourced dataset on a GPU; and then further fine-tuned
the model with a hospital specific dataset of 1000 samples on a CPU. We
demonstrated that by carefully curating the datasets and leveraging existing
models and open sourced data, we can successfully classify triage data with
limited compute resources.
\\ ( https://arxiv.org/abs/2509.04969 ,  6140kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04982
Date: Fri, 5 Sep 2025 10:08:14 GMT   (868kb)

Title: Optimizing Small Transformer-Based Language Models for Multi-Label
  Sentiment Analysis in Short Texts
Authors: Julius Neumann, Robert Lange, Yuni Susanti, Michael F\"arber
Categories: cs.CL cs.IR cs.LG
Comments: Accepted at LDD@ECAI 2025
\\
  Sentiment classification in short text datasets faces significant challenges
such as class imbalance, limited training samples, and the inherent
subjectivity of sentiment labels -- issues that are further intensified by the
limited context in short texts. These factors make it difficult to resolve
ambiguity and exacerbate data sparsity, hindering effective learning. In this
paper, we evaluate the effectiveness of small Transformer-based models (i.e.,
BERT and RoBERTa, with fewer than 1 billion parameters) for multi-label
sentiment classification, with a particular focus on short-text settings.
Specifically, we evaluated three key factors influencing model performance: (1)
continued domain-specific pre-training, (2) data augmentation using
automatically generated examples, specifically generative data augmentation,
and (3) architectural variations of the classification head. Our experiment
results show that data augmentation improves classification performance, while
continued pre-training on augmented datasets can introduce noise rather than
boost accuracy. Furthermore, we confirm that modifications to the
classification head yield only marginal benefits. These findings provide
practical guidance for optimizing BERT-based models in resource-constrained
settings and refining strategies for sentiment classification in short-text
datasets.
\\ ( https://arxiv.org/abs/2509.04982 ,  868kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05006
Date: Fri, 5 Sep 2025 11:13:20 GMT   (342kb)

Title: Do Large Language Models Need Intent? Revisiting Response Generation
  Strategies for Service Assistant
Authors: Inbal Bolshinsky, Shani Kupiec, Almog Sasson, Yehudit Aperstein,
  Alexander Apartsin
Categories: cs.CL cs.LG
Comments: 7 pages, 1 figure
\\
  In the era of conversational AI, generating accurate and contextually
appropriate service responses remains a critical challenge. A central question
remains: Is explicit intent recognition a prerequisite for generating
high-quality service responses, or can models bypass this step and produce
effective replies directly? This paper conducts a rigorous comparative study to
address this fundamental design dilemma. Leveraging two publicly available
service interaction datasets, we benchmark several state-of-the-art language
models, including a fine-tuned T5 variant, across both paradigms: Intent-First
Response Generation and Direct Response Generation. Evaluation metrics
encompass both linguistic quality and task success rates, revealing surprising
insights into the necessity or redundancy of explicit intent modelling. Our
findings challenge conventional assumptions in conversational AI pipelines,
offering actionable guidelines for designing more efficient and effective
response generation systems.
\\ ( https://arxiv.org/abs/2509.05006 ,  342kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05056
Date: Fri, 5 Sep 2025 12:35:06 GMT   (46kb)

Title: Masked Diffusion Language Models with Frequency-Informed Training
Authors: Despoina Kosmopoulou, Efthymios Georgiou, Vaggelis Dorovatas, Georgios
  Paraskevopoulos, Alexandros Potamianos
Categories: cs.CL
Comments: Preprint
\\
  We present a masked diffusion language modeling framework for data-efficient
training for the BabyLM 2025 Challenge. Our approach applies diffusion training
objectives to language modeling under strict data constraints, incorporating
frequency-informed masking that prioritizes learning from rare tokens while
maintaining theoretical validity. We explore multiple noise scheduling
strategies, including two-mode approaches, and investigate different noise
weighting schemes within the NELBO objective. We evaluate our method on the
BabyLM benchmark suite, measuring linguistic competence, world knowledge, and
human-likeness. Results show performance competitive to hybrid
autoregressive-masked baselines, demonstrating that diffusion-based training
offers a viable alternative for data-restricted language learning.
\\ ( https://arxiv.org/abs/2509.05056 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05060
Date: Fri, 5 Sep 2025 12:40:31 GMT   (1391kb)

Title: Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End
  Learnable Language Representations
Authors: Patrick Amadeus Irawan, Ryandito Diandaru, Belati Jagad Bintang
  Syuhada, Randy Zakya Suchrady, Alham Fikri Aji, Genta Indra Winata, Fajri
  Koto, Samuel Cahyawijaya
Categories: cs.CL
\\
  We introduce Entropy2Vec, a novel framework for deriving cross-lingual
language representations by leveraging the entropy of monolingual language
models. Unlike traditional typological inventories that suffer from feature
sparsity and static snapshots, Entropy2Vec uses the inherent uncertainty in
language models to capture typological relationships between languages. By
training a language model on a single language, we hypothesize that the entropy
of its predictions reflects its structural similarity to other languages: Low
entropy indicates high similarity, while high entropy suggests greater
divergence. This approach yields dense, non-sparse language embeddings that are
adaptable to different timeframes and free from missing values. Empirical
evaluations demonstrate that Entropy2Vec embeddings align with established
typological categories and achieved competitive performance in downstream
multilingual NLP tasks, such as those addressed by the LinguAlchemy framework.
\\ ( https://arxiv.org/abs/2509.05060 ,  1391kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05066
Date: Fri, 5 Sep 2025 12:58:15 GMT   (4582kb)

Title: ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions
Authors: Matteo Bortoletto, Constantin Ruhdorfer, Andreas Bulling
Categories: cs.CL cs.AI
Comments: EMNLP 2025 (Main)
\\
  Most existing Theory of Mind (ToM) benchmarks for foundation models rely on
variations of the Sally-Anne test, offering only a very limited perspective on
ToM and neglecting the complexity of human social interactions. To address this
gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM
capabilities in environments rich with social interactions and spatial
dynamics. While current ToM benchmarks are limited to text-only or dyadic
interactions, ToM-SSI is multimodal and includes group interactions of up to
four agents that communicate and move in situated environments. This unique
design allows us to study, for the first time, mixed cooperative-obstructive
settings and reasoning about multiple agents' mental state in parallel, thus
capturing a wider range of social cognition than existing benchmarks. Our
evaluations reveal that the current models' performance is still severely
limited, especially in these new tasks, highlighting critical gaps for future
research.
\\ ( https://arxiv.org/abs/2509.05066 ,  4582kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05100
Date: Fri, 5 Sep 2025 13:37:04 GMT   (769kb)

Title: ICR: Iterative Clarification and Rewriting for Conversational Search
Authors: Zhiyu Cao, Peifeng Li, Qiaoming Zhu
Categories: cs.CL cs.AI
\\
  Most previous work on Conversational Query Rewriting employs an end-to-end
rewriting paradigm. However, this approach is hindered by the issue of multiple
fuzzy expressions within the query, which complicates the simultaneous
identification and rewriting of multiple positions. To address this issue, we
propose a novel framework ICR (Iterative Clarification and Rewriting), an
iterative rewriting scheme that pivots on clarification questions. Within this
framework, the model alternates between generating clarification questions and
rewritten queries. The experimental results show that our ICR can continuously
improve retrieval performance in the clarification-rewriting iterative process,
thereby achieving state-of-the-art performance on two popular datasets.
\\ ( https://arxiv.org/abs/2509.05100 ,  769kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05146
Date: Fri, 5 Sep 2025 14:38:07 GMT   (16018kb)

Title: PRIM: Towards Practical In-Image Multilingual Machine Translation
Authors: Yanzhi Tian, Zeming Liu, Zhengyang Liu, Chong Feng, Xin Li, Heyan
  Huang, Yuhang Guo
Categories: cs.CL cs.CV
Comments: Accepted to EMNLP 2025 Main Conference
\\
  In-Image Machine Translation (IIMT) aims to translate images containing texts
from one language to another. Current research of end-to-end IIMT mainly
conducts on synthetic data, with simple background, single font, fixed text
position, and bilingual translation, which can not fully reflect real world,
causing a significant gap between the research and practical conditions. To
facilitate research of IIMT in real-world scenarios, we explore Practical
In-Image Multilingual Machine Translation (IIMMT). In order to convince the
lack of publicly available data, we annotate the PRIM dataset, which contains
real-world captured one-line text images with complex background, various
fonts, diverse text positions, and supports multilingual translation
directions. We propose an end-to-end model VisTrans to handle the challenge of
practical conditions in PRIM, which processes visual text and background
information in the image separately, ensuring the capability of multilingual
translation while improving the visual quality. Experimental results indicate
the VisTrans achieves a better translation quality and visual effect compared
to other models. The code and dataset are available at:
https://github.com/BITHLP/PRIM.
\\ ( https://arxiv.org/abs/2509.05146 ,  16018kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05199
Date: Fri, 5 Sep 2025 15:58:49 GMT   (549kb)

Title: Triadic Fusion of Cognitive, Functional, and Causal Dimensions for
  Explainable LLMs: The TAXAL Framework
Authors: David Herrera-Poyatos, Carlos Pel\'aez-Gonz\'alez, Cristina Zuheros,
  Virilo Tejedor, Rosana Montes, and Francisco Herrera
Categories: cs.CL
Comments: 27 pages, 9 tables and 2 figures
\\
  Large Language Models (LLMs) are increasingly being deployed in high-risk
domains where opacity, bias, and instability undermine trust and
accountability. Traditional explainability methods, focused on surface outputs,
do not capture the reasoning pathways, planning logic, and systemic impacts of
agentic LLMs.
  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a
triadic fusion framework that unites three complementary dimensions: cognitive
(user understanding), functional (practical utility), and causal (faithful
reasoning). TAXAL provides a unified, role-sensitive foundation for designing,
evaluating, and deploying explanations in diverse sociotechnical settings.
  Our analysis synthesizes existing methods, ranging from post-hoc attribution
and dialogic interfaces to explanation-aware prompting, and situates them
within the TAXAL triadic fusion model. We further demonstrate its applicability
through case studies in law, education, healthcare, and public services,
showing how explanation strategies adapt to institutional constraints and
stakeholder roles.
  By combining conceptual clarity with design patterns and deployment pathways,
TAXAL advances explainability as a technical and sociotechnical practice,
supporting trustworthy and context-sensitive LLM applications in the era of
agentic AI.
\\ ( https://arxiv.org/abs/2509.05199 ,  549kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05209
Date: Fri, 5 Sep 2025 16:11:05 GMT   (470kb)

Title: Hunyuan-MT Technical Report
Authors: Mao Zheng, Zheng Li, Bingxin Qu, Mingyang Song, Yang Du, Mingrui Sun,
  Di Wang
Categories: cs.CL
\\
  In this report, we introduce Hunyuan-MT-7B, our first open-source
multilingual translation model, which supports bidirectional translation across
33 major languages and places a special emphasis on translation between
Mandarin and several ethnic minority languages as well as dialects.
Furthermore, to serve and address diverse translation scenarios and enhance
model performance at test time, we introduce Hunyuan-MT-Chimera-7B, a
translation model inspired by the slow thinking mode. This model integrates
multiple outputs generated by the Hunyuan-MT-7B model under varying parameter
settings, thereby achieving performance superior to that of conventional
slow-thinking models based on Chain-of-Thought (CoT). The development of our
models follows a holistic training process specifically engineered for
multilingual translation, which begins with general and MT-oriented
pre-training to build foundational capabilities, proceeds to Supervised
Fine-Tuning (SFT) for task-specific adaptation, and culminates in advanced
alignment through Reinforcement Learning (RL) and weak-to-strong RL. Through
comprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and
Hunyuan-MT-Chimera-7B significantly outperform all translation-specific models
of comparable parameter size and most of the SOTA large models, particularly on
the task of translation between Mandarin and minority languages as well as
dialects. In the WMT2025 shared task (General Machine Translation), our models
demonstrate state-of-the-art performance, ranking first in 30 out of 31
language pairs. This result highlights the robustness of our models across a
diverse linguistic spectrum, encompassing high-resource languages such as
Chinese, English, and Japanese, as well as low-resource languages including
Czech, Marathi, Estonian, and Icelandic.
\\ ( https://arxiv.org/abs/2509.05209 ,  470kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05215
Date: Fri, 5 Sep 2025 16:18:20 GMT   (591kb)

Title: BEDTime: A Unified Benchmark for Automatically Describing Time Series
Authors: Medhasweta Sen, Zachary Gottesman, Jiaxing Qiu, C. Bayan Bruss, Nam
  Nguyen, Tom Hartvigsen
Categories: cs.CL cs.LG
\\
  Many recent studies have proposed general-purpose foundation models designed
for a variety of time series analysis tasks. While several established datasets
already exist for evaluating these models, previous works frequently introduce
their models in conjunction with new datasets, limiting opportunities for
direct, independent comparisons and obscuring insights into the relative
strengths of different methods. Additionally, prior evaluations often cover
numerous tasks simultaneously, assessing a broad range of model abilities
without clearly pinpointing which capabilities contribute to overall
performance. To address these gaps, we formalize and evaluate 3 tasks that test
a model's ability to describe time series using generic natural language: (1)
recognition (True/False question-answering), (2) differentiation (multiple
choice question-answering), and (3) generation (open-ended natural language
description). We then unify 4 recent datasets to enable head-to-head model
comparisons on each task. Experimentally, in evaluating 13 state-of-the-art
language, vision--language, and time series--language models, we find that (1)
popular language-only methods largely underperform, indicating a need for time
series-specific architectures, (2) VLMs are quite successful, as expected,
identifying the value of vision models for these tasks and (3) pretrained
multimodal time series--language models successfully outperform LLMs, but still
have significant room for improvement. We also find that all approaches exhibit
clear fragility in a range of robustness tests. Overall, our benchmark provides
a standardized evaluation on a task necessary for time series reasoning
systems.
\\ ( https://arxiv.org/abs/2509.05215 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05218
Date: Fri, 5 Sep 2025 16:20:48 GMT   (1325kb)

Title: HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range
  Dependency Modeling in Large Language Models
Authors: Chang Dai, Hongyu Shan, Mingyang Song, Di Liang
Categories: cs.CL cs.AI
Comments: This paper proposes Hyperbolic Rotary Positional Encoding (HoPE), a
  geometric reformulation of positional encoding inspired by Lorentz
  transformations. HoPE addresses limitations of existing methods like RoPE by
  enabling stable long-distance dependency modeling. Code and data will be made
  available upon publication
\\
  Positional encoding mechanisms enable Transformers to model sequential
structure and long-range dependencies in text. While absolute positional
encodings struggle with extrapolation to longer sequences due to fixed
positional representations, and relative approaches like Alibi exhibit
performance degradation on extremely long contexts, the widely-used Rotary
Positional Encoding (RoPE) introduces oscillatory attention patterns that
hinder stable long-distance dependency modelling. We address these limitations
through a geometric reformulation of positional encoding. Drawing inspiration
from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic
Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to
implement Lorentz rotations on token representations. Theoretical analysis
demonstrates that RoPE is a special case of our generalized formulation. HoPE
fundamentally resolves RoPE's slation issues by enforcing monotonic decay of
attention weights with increasing token distances. Extensive experimental
results, including perplexity evaluations under several extended sequence
benchmarks, show that HoPE consistently exceeds existing positional encoding
methods. These findings underscore HoPE's enhanced capacity for representing
and generalizing long-range dependencies. Data and code will be available.
\\ ( https://arxiv.org/abs/2509.05218 ,  1325kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05226
Date: Fri, 5 Sep 2025 16:40:13 GMT   (294kb)

Title: Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware
  Chain-of-Thought Distillation
Authors: Abdul Waheed, Chancharik Mitra, Laurie Z. Wang, Deva Ramanan, Bhiksha
  Raj
Categories: cs.CL
Comments: 28 Pages
\\
  Chain-of-thought reasoning, while powerful, can produce unnecessarily verbose
output for simpler problems. We present a framework for difficulty-aware
reasoning that teaches models to dynamically adjust reasoning depth based on
problem complexity. Remarkably, we show that models can be endowed with such
dynamic inference pathways without any architectural modifications; we simply
post-train on data that is carefully curated to include chain-of-thought traces
that are proportional in length to problem difficulty. Our analysis reveals
that post-training via supervised fine-tuning (SFT) primarily captures patterns
like reasoning length and format, while direct preference optimization (DPO)
preserves reasoning accuracy, with their combination reducing length and
maintaining or improving performance. Both quantitative metrics and qualitative
assessments confirm that models can learn to "think proportionally", reasoning
minimally on simple problems while maintaining depth for complex ones.
\\ ( https://arxiv.org/abs/2509.05226 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05230
Date: Fri, 5 Sep 2025 16:47:22 GMT   (461kb)

Title: CURE: Controlled Unlearning for Robust Embeddings -- Mitigating
  Conceptual Shortcuts in Pre-Trained Language Models
Authors: Aysenur Kocak, Shuo Yang, Bardh Prenkaj, Gjergji Kasneci
Categories: cs.CL cs.AI cs.LG
Comments: Accepted at the Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2025)
\\
  Pre-trained language models have achieved remarkable success across diverse
applications but remain susceptible to spurious, concept-driven correlations
that impair robustness and fairness. In this work, we introduce CURE, a novel
and lightweight framework that systematically disentangles and suppresses
conceptual shortcuts while preserving essential content information. Our method
first extracts concept-irrelevant representations via a dedicated content
extractor reinforced by a reversal network, ensuring minimal loss of
task-relevant information. A subsequent controllable debiasing module employs
contrastive learning to finely adjust the influence of residual conceptual
cues, enabling the model to either diminish harmful biases or harness
beneficial correlations as appropriate for the target task. Evaluated on the
IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an
absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp,
while introducing minimal computational overhead. Our approach establishes a
flexible, unsupervised blueprint for combating conceptual biases, paving the
way for more reliable and fair language understanding systems.
\\ ( https://arxiv.org/abs/2509.05230 ,  461kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05254
Date: Fri, 5 Sep 2025 17:12:19 GMT   (9421kb)

Title: Uniform Information Density and Syntactic Reduction: Revisiting
  $\textit{that}$-Mentioning in English Complement Clauses
Authors: Hailin Hao, Elsi Kaiser
Categories: cs.CL
\\
  Speakers often have multiple ways to express the same meaning. The Uniform
Information Density (UID) hypothesis suggests that speakers exploit this
variability to maintain a consistent rate of information transmission during
language production. Building on prior work linking UID to syntactic reduction,
we revisit the finding that the optional complementizer $\textit{that}$in
English complement clauses is more likely to be omitted when the clause has low
information density (i.e., more predictable). We advance this line of research
by analyzing a large-scale, contemporary conversational corpus and using
machine learning and neural language models to refine estimates of information
density. Our results replicated the established relationship between
information density and $\textit{that}$-mentioning. However, we found that
previous measures of information density based on matrix verbs'
subcategorization probability capture substantial idiosyncratic lexical
variation. By contrast, estimates derived from contextual word embeddings
account for additional variance in patterns of complementizer usage.
\\ ( https://arxiv.org/abs/2509.05254 ,  9421kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05282
Date: Fri, 5 Sep 2025 17:48:26 GMT   (218kb)

Title: Elucidating the Design Space of Decay in Linear Attention
Authors: Zhen Qin, Xuyang Shen, Yiran Zhong
Categories: cs.CL
Comments: Accepted to COLM 2025. Yiran Zhong is the corresponding author. Code
  is available at https://github.com/Doraemonzzz/xmixers
\\
  This paper presents a comprehensive investigation into the decay mechanisms
inherent in linear complexity sequence models. We systematically delineate the
design space of decay mechanisms across four pivotal dimensions:
parameterization strategy, which refers to the computational methodology for
decay; parameter sharing, which involves the utilization of supplementary
parameters for decay computation; decay granularity, comparing scalar versus
vector-based decay; and compatibility with relative positional encoding
methods, such as Rotary Position Embedding (RoPE). Through an extensive series
of experiments conducted on diverse language modeling tasks, we uncovered
several critical insights. Firstly, the design of the parameterization strategy
for decay requires meticulous consideration. Our findings indicate that
effective configurations are typically confined to a specific range of
parameters. Secondly, parameter sharing cannot be used arbitrarily, as it may
cause decay values to be too large or too small, thereby significantly
impacting performance. Thirdly, under identical parameterization strategies,
scalar decay generally underperforms compared to its vector-based counterpart.
However, in certain scenarios with alternative parameterization strategies,
scalar decay may unexpectedly surpass vector decay in efficacy. Lastly, our
analysis reveals that RoPE, a commonly employed relative positional encoding
method, typically fails to provide tangible benefits to the majority of linear
attention mechanisms.
\\ ( https://arxiv.org/abs/2509.05282 ,  218kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05291
Date: Fri, 5 Sep 2025 17:56:24 GMT   (3473kb)

Title: Crosscoding Through Time: Tracking Emergence & Consolidation Of
  Linguistic Representations Throughout LLM Pretraining
Authors: Deniz Bayazit, Aaron Mueller, Antoine Bosselut
Categories: cs.CL cs.AI cs.LG
\\
  Large language models (LLMs) learn non-trivial abstractions during
pretraining, like detecting irregular plural noun subjects. However, it is not
well understood when and how specific linguistic abilities emerge as
traditional evaluation methods such as benchmarking fail to reveal how models
acquire concepts and capabilities. To bridge this gap and better understand
model training at the concept level, we use sparse crosscoders to discover and
align features across model checkpoints. Using this approach, we track the
evolution of linguistic features during pretraining. We train crosscoders
between open-sourced checkpoint triplets with significant performance and
representation shifts, and introduce a novel metric, Relative Indirect Effects
(RelIE), to trace training stages at which individual features become causally
important for task performance. We show that crosscoders can detect feature
emergence, maintenance, and discontinuation during pretraining. Our approach is
architecture-agnostic and scalable, offering a promising path toward more
interpretable and fine-grained analysis of representation learning throughout
pretraining.
\\ ( https://arxiv.org/abs/2509.05291 ,  3473kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04490
Date: Mon, 1 Sep 2025 11:27:47 GMT   (25203kb)

Title: Facial Emotion Recognition does not detect feeling unsafe in automated
  driving
Authors: Abel van Elburg, Konstantinos Gkentsidis, Mathieu Sarrazin, Sarah
  Barendswaard, Varun Kotian, Riender Happee
Categories: cs.CV
ACM-class: J.4; I.2.10
\\
  Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.
\\ ( https://arxiv.org/abs/2509.04490 ,  25203kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04545
Date: Thu, 4 Sep 2025 16:46:10 GMT   (27420kb)

Title: PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via
  Chain-of-Thought Prompt Rewriting
Authors: Linqing Wang, Ximing Xing, Yiji Cheng, Zhiyuan Zhao, Jiale Tao, Qixun
  Wang, Ruihuang Li, Xin Li, Mingrui Wu, Xinchi Deng, Chunyu Wang, Qinglin Lu
Categories: cs.CV
Comments: technical report
\\
  Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.
\\ ( https://arxiv.org/abs/2509.04545 ,  27420kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04548
Date: Thu, 4 Sep 2025 17:00:17 GMT   (44141kb)

Title: Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified
  Multimodal Model
Authors: Hongyang Wei, Baixin Xu, Hongbo Liu, Cyrus Wu, Jie Liu, Yi Peng, Peiyu
  Wang, Zexiang Liu, Jingwen He, Yidan Xietian, Chuanxin Tang, Zidong Wang,
  Yichen Wei, Liang Hu, Boyi Jiang, William Li, Ying He, Yang Liu, Xuchen Song,
  Eric Li, Yahui Zhou
Categories: cs.CV
\\
  Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.
\\ ( https://arxiv.org/abs/2509.04548 ,  44141kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04582
Date: Thu, 4 Sep 2025 18:04:47 GMT   (5036kb)

Title: Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing
  via Bidirectional Warping
Authors: Jingyi Lu, Kai Han
Categories: cs.CV
Comments: Accepted to ICCV 2025. Project page:
  https://visual-ai.github.io/inpaint4drag/
ACM-class: I.3.6; I.3.3
\\
  Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/
\\ ( https://arxiv.org/abs/2509.04582 ,  5036kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04597
Date: Thu, 4 Sep 2025 18:20:36 GMT   (7882kb)

Title: DisPatch: Disarming Adversarial Patches in Object Detection with
  Diffusion Models
Authors: Jin Ma, Mohammed Aldeen, Christopher Salas, Feng Luo, Mashrur
  Chowdhury, Mert Pes\'e, Long Cheng
Categories: cs.CV
\\
  Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.
\\ ( https://arxiv.org/abs/2509.04597 ,  7882kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04600
Date: Thu, 4 Sep 2025 18:29:48 GMT   (3181kb)

Title: WATCH: World-aware Allied Trajectory and pose reconstruction for Camera
  and Human
Authors: Qijun Ying, Zhongyuan Hu, Rui Zhang, Ronghui Li, Yu Lu, Zijiao Zeng
Categories: cs.CV
\\
  Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.
\\ ( https://arxiv.org/abs/2509.04600 ,  3181kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04602
Date: Thu, 4 Sep 2025 18:34:59 GMT   (1837kb)

Title: Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption
  Retrieval for Dense Video Captioning
Authors: MinJu Jeon, Si-Woo Kim, Ye-Chan Kim, HyunGee Kim, Dong-Jin Kim
Categories: cs.CV
Comments: Accepted in EMNLP 2025
\\
  Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning
\\ ( https://arxiv.org/abs/2509.04602 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04624
Date: Thu, 4 Sep 2025 19:19:25 GMT   (10306kb)

Title: UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle
  Detection, Classification, Tracking, and Behavioral Analysis
Authors: Ali Khanpour, Tianyi Wang, Afra Vahidi-Shams, Wim Ectors, Farzam
  Nakhaie, Amirhossein Taheri, Christian Claudel
Categories: cs.CV cs.ET cs.RO cs.SY eess.IV eess.SY
Comments: 15 pages, 8 figures, 2 tables
\\
  Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.
\\ ( https://arxiv.org/abs/2509.04624 ,  10306kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04669
Date: Thu, 4 Sep 2025 21:32:27 GMT   (130kb)

Title: VCMamba: Bridging Convolutions with Multi-Directional Mamba for
  Efficient Visual Representation
Authors: Mustafa Munir, Alex Zhang, Radu Marculescu
Categories: cs.CV cs.AI cs.LG
Comments: Proceedings of the 2025 IEEE/CVF International Conference on Computer
  Vision (ICCV) Workshops
\\
  Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.
\\ ( https://arxiv.org/abs/2509.04669 ,  130kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04687
Date: Thu, 4 Sep 2025 22:32:57 GMT   (23914kb)

Title: Guideline-Consistent Segmentation via Multi-Agent Refinement
Authors: Vanshika Vats, Ashwani Rathee, James Davis
Categories: cs.CV
\\
  Semantic segmentation in real-world applications often requires not only
accurate masks but also strict adherence to textual labeling guidelines. These
guidelines are typically complex and long, and both human and automated
labeling often fail to follow them faithfully. Traditional approaches depend on
expensive task-specific retraining that must be repeated as the guidelines
evolve. Although recent open-vocabulary segmentation methods excel with simple
prompts, they often fail when confronted with sets of paragraph-length
guidelines that specify intricate segmentation rules. To address this, we
introduce a multi-agent, training-free framework that coordinates
general-purpose vision-language models within an iterative Worker-Supervisor
refinement architecture. The Worker performs the segmentation, the Supervisor
critiques it against the retrieved guidelines, and a lightweight reinforcement
learning stop policy decides when to terminate the loop, ensuring
guideline-consistent masks while balancing resource use. Evaluated on the Waymo
and ReasonSeg datasets, our method notably outperforms state-of-the-art
baselines, demonstrating strong generalization and instruction adherence.
\\ ( https://arxiv.org/abs/2509.04687 ,  23914kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04711
Date: Thu, 4 Sep 2025 23:54:25 GMT   (436kb)

Title: Domain Adaptation for Different Sensor Configurations in 3D Object
  Detection
Authors: Satoshi Tanaka, Kok Seang Tan, Isamu Yamashita
Categories: cs.CV cs.RO
\\
  Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.
\\ ( https://arxiv.org/abs/2509.04711 ,  436kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04729
Date: Fri, 5 Sep 2025 01:02:02 GMT   (15743kb)

Title: CD-Mamba: Cloud detection with long-range spatial dependency modeling
Authors: Tianxiang Xue, Jiayi Zhao, Jingsheng Li, Changlu Chen, Kun Zhan
Categories: cs.CV
Comments: Journal of Applied Remote Sensing
\\
  Remote sensing images are frequently obscured by cloud cover, posing
significant challenges to data integrity and reliability. Effective cloud
detection requires addressing both short-range spatial redundancies and
long-range atmospheric similarities among cloud patches. Convolutional neural
networks are effective at capturing local spatial dependencies, while Mamba has
strong capabilities in modeling long-range dependencies. To fully leverage both
local spatial relations and long-range dependencies, we propose CD-Mamba, a
hybrid model that integrates convolution and Mamba's state-space modeling into
a unified cloud detection network. CD-Mamba is designed to comprehensively
capture pixelwise textural details and long term patchwise dependencies for
cloud detection. This design enables CD-Mamba to manage both pixel-wise
interactions and extensive patch-wise dependencies simultaneously, improving
detection accuracy across diverse spatial scales. Extensive experiments
validate the effectiveness of CD-Mamba and demonstrate its superior performance
over existing methods.
\\ ( https://arxiv.org/abs/2509.04729 ,  15743kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04732
Date: Fri, 5 Sep 2025 01:04:32 GMT   (2950kb)

Title: Exploiting Unlabeled Structures through Task Consistency Training for
  Versatile Medical Image Segmentation
Authors: Shengqian Zhu, Jiafei Wu, Xiaogang Xu, Chengrong Yu, Ying Song, Zhang
  Yi, Guangjun Li, Junjie Hu
Categories: cs.CV
\\
  Versatile medical image segmentation (VMIS) targets the segmentation of
multiple classes, while obtaining full annotations for all classes is often
impractical due to the time and labor required. Leveraging partially labeled
datasets (PLDs) presents a promising alternative; however, current VMIS
approaches face significant class imbalance due to the unequal category
distribution in PLDs. Existing methods attempt to address this by generating
pseudo-full labels. Nevertheless, these typically require additional models and
often result in potential performance degradation from label noise. In this
work, we introduce a Task Consistency Training (TCT) framework to address class
imbalance without requiring extra models. TCT includes a backbone network with
a main segmentation head (MSH) for multi-channel predictions and multiple
auxiliary task heads (ATHs) for task-specific predictions. By enforcing a
consistency constraint between the MSH and ATH predictions, TCT effectively
utilizes unlabeled anatomical structures. To avoid error propagation from
low-consistency, potentially noisy data, we propose a filtering strategy to
exclude such data. Additionally, we introduce a unified auxiliary
uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines
caused by the dominance of specific tasks. Extensive experiments on eight
abdominal datasets from diverse clinical sites demonstrate our approach's
effectiveness.
\\ ( https://arxiv.org/abs/2509.04732 ,  2950kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04735
Date: Fri, 5 Sep 2025 01:24:42 GMT   (6662kb)

Title: Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A
  Dual Uncertainty-Aware Training Approach to SAM Optimization
Authors: Dharsan Ravindran, Kevin Wang, Zhuoyuan Cao, Saleh Abdelrahman,
  Jeffery Wu
Categories: cs.CV cs.AI
\\
  Recent advances in vision foundation models, such as the Segment Anything
Model (SAM) and its successor SAM2, have achieved state-of-the-art performance
on general image segmentation benchmarks. However, these models struggle in
adverse weather conditions where visual ambiguity is high, largely due to their
lack of uncertainty quantification. Inspired by progress in medical imaging,
where uncertainty-aware training has improved reliability in ambiguous cases,
we investigate two approaches to enhance segmentation robustness for autonomous
driving. First, we introduce a multi-step finetuning procedure for SAM2 that
incorporates uncertainty metrics directly into the loss function, improving
overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter
(UAT), originally designed for medical image segmentation, to driving contexts.
We evaluate both methods on CamVid, BDD100K, and GTA driving datasets.
Experiments show that UAT-SAM outperforms standard SAM in extreme weather,
while SAM2 with uncertainty-aware loss achieves improved performance across
diverse driving scenes. These findings underscore the value of explicit
uncertainty modeling for safety-critical autonomous driving in challenging
environments.
\\ ( https://arxiv.org/abs/2509.04735 ,  6662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04736
Date: Fri, 5 Sep 2025 01:30:16 GMT   (11455kb)

Title: WatchHAR: Real-time On-device Human Activity Recognition System for
  Smartwatches
Authors: Taeyoung Yeon, Vasco Xu, Henry Hoffmann, and Karan Ahuja
Categories: cs.CV
Comments: 8 pages, 4 figures, ICMI '25 (27th International Conference on
  Multimodal Interaction), October 13-17, 2025, Canberra, ACT, Australia
ACM-class: I.2.10; H.5.2
DOI: 10.1145/3716553.3750775
\\
  Despite advances in practical and multimodal fine-grained Human Activity
Recognition (HAR), a system that runs entirely on smartwatches in unconstrained
environments remains elusive. We present WatchHAR, an audio and inertial-based
HAR system that operates fully on smartwatches, addressing privacy and latency
issues associated with external data processing. By optimizing each component
of the pipeline, WatchHAR achieves compounding performance gains. We introduce
a novel architecture that unifies sensor data preprocessing and inference into
an end-to-end trainable module, achieving 5x faster processing while
maintaining over 90% accuracy across more than 25 activity classes. WatchHAR
outperforms state-of-the-art models for event detection and activity
classification while running directly on the smartwatch, achieving 9.3 ms
processing time for activity event detection and 11.8 ms for multimodal
activity classification. This research advances on-device activity recognition,
realizing smartwatches' potential as standalone, privacy-aware, and
minimally-invasive continuous activity tracking devices.
\\ ( https://arxiv.org/abs/2509.04736 ,  11455kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04757
Date: Fri, 5 Sep 2025 02:25:05 GMT   (1257kb)

Title: MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label
  Post-Hurricane Damage Assessment using UAV Imagery
Authors: Zhangding Liu, Neda Mohammadi, and John E. Taylor
Categories: cs.CV cs.AI
Comments: 34 pages, 7 figures
\\
  Rapid and accurate post-hurricane damage assessment is vital for disaster
response and recovery. Yet existing CNN-based methods struggle to capture
multi-scale spatial features and to distinguish visually similar or
co-occurring damage types. To address these issues, we propose MCANet, a
multi-label classification framework that learns multi-scale representations
and adaptively attends to spatially relevant regions for each damage category.
MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context
across scales and a multi-head class-specific residual attention module to
enhance discrimination. Each attention branch focuses on different spatial
granularities, balancing local detail with global context. We evaluate MCANet
on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.
MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,
Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,
performance further improves to 92.35%, boosting average precision for
challenging classes such as Road Blocked by over 6%. Class activation mapping
confirms MCANet's ability to localize damage-relevant regions, supporting
interpretability. Outputs from MCANet can inform post-disaster risk mapping,
emergency routing, and digital twin-based disaster response. Future work could
integrate disaster-specific knowledge graphs and multimodal large language
models to improve adaptability to unseen disasters and enrich semantic
understanding for real-world decision-making.
\\ ( https://arxiv.org/abs/2509.04757 ,  1257kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04758
Date: Fri, 5 Sep 2025 02:37:01 GMT   (3838kb)

Title: Dynamic Group Detection using VLM-augmented Temporal Groupness Graph
Authors: Kaname Yokoyama and Chihiro Nakatani and Norimichi Ukita
Categories: cs.CV
Comments: 10 pages, Accepted to ICCV2025
\\
  This paper proposes dynamic human group detection in videos. For detecting
complex groups, not only the local appearance features of in-group members but
also the global context of the scene are important. Such local and global
appearance features in each frame are extracted using a Vision-Language Model
(VLM) augmented for group detection in our method. For further improvement, the
group structure should be consistent over time. While previous methods are
stabilized on the assumption that groups are not changed in a video, our method
detects dynamically changing groups by global optimization using a graph with
all frames' groupness probabilities estimated by our groupness-augmented CLIP
features. Our experimental results demonstrate that our method outperforms
state-of-the-art group detection methods on public datasets. Code:
https://github.com/irajisamurai/VLM-GroupDetection.git
\\ ( https://arxiv.org/abs/2509.04758 ,  3838kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04772
Date: Fri, 5 Sep 2025 03:05:18 GMT   (515kb)

Title: FloodVision: Urban Flood Depth Estimation Using Foundation
  Vision-Language Models and Domain Knowledge Graph
Authors: Zhangding Liu, Neda Mohammadi, and John E. Taylor
Categories: cs.CV cs.AI
\\
  Timely and accurate floodwater depth estimation is critical for road
accessibility and emergency response. While recent computer vision methods have
enabled flood detection, they suffer from both accuracy limitations and poor
generalization due to dependence on fixed object detectors and task-specific
training. To enable accurate depth estimation that can generalize across
diverse flood scenarios, this paper presents FloodVision, a zero-shot framework
that combines the semantic reasoning abilities of the foundation
vision-language model GPT-4o with a structured domain knowledge graph. The
knowledge graph encodes canonical real-world dimensions for common urban
objects including vehicles, people, and infrastructure elements to ground the
model's reasoning in physical reality. FloodVision dynamically identifies
visible reference objects in RGB images, retrieves verified heights from the
knowledge graph to mitigate hallucination, estimates submergence ratios, and
applies statistical outlier filtering to compute final depth values. Evaluated
on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean
absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and
surpassing prior CNN-based methods. The system generalizes well across varying
scenes and operates in near real-time, making it suitable for future
integration into digital twin platforms and citizen-reporting apps for smart
city flood resilience.
\\ ( https://arxiv.org/abs/2509.04772 ,  515kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04773
Date: Fri, 5 Sep 2025 03:05:50 GMT   (3109kb)

Title: Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for
  Text-to-Video Retrieval
Authors: Bangxiang Lan, Ruobing Xie, Ruixiang Zhao, Xingwu Sun, Zhanhui Kang,
  Gang Yang, Xirong Li
Categories: cs.CV
Comments: Accepted to ICCV2025
\\
  The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by
textual queries with the same semantic meanings. Recent CLIP-based approaches
have explored two frameworks: Two-Tower versus Single-Tower framework, yet the
former suffers from low effectiveness, while the latter suffers from low
efficiency. In this study, we explore a new Hybrid-Tower framework that can
hybridize the advantages of the Two-Tower and Single-Tower framework, achieving
high effectiveness and efficiency simultaneously. We propose a novel hybrid
method, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,
which includes a new pseudo-query generator designed to generate a pseudo-query
for each video. This enables the video feature and the textual features of
pseudo-query to interact in a fine-grained manner, similar to the Single-Tower
approaches to hold high effectiveness, even before the real textual query is
received. Simultaneously, our method introduces no additional storage or
computational overhead compared to the Two-Tower framework during the inference
stage, thus maintaining high efficiency. Extensive experiments on five commonly
used text-video retrieval benchmarks demonstrate that our method achieves a
significant improvement over the baseline, with an increase of $1.6\% \sim
3.9\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower
models while achieving near state-of-the-art performance, highlighting the
advantages of the Hybrid-Tower framework.
\\ ( https://arxiv.org/abs/2509.04773 ,  3109kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04775
Date: Fri, 5 Sep 2025 03:10:00 GMT   (14416kb)

Title: Comparative Evaluation of Traditional and Deep Learning Feature Matching
  Algorithms using Chandrayaan-2 Lunar Data
Authors: R. Makharia, J. G. Singla, Amitabh, N. Dube, H. Sharma
Categories: cs.CV
Comments: 27 pages, 11 figures, 3 tables
\\
  Accurate image registration is critical for lunar exploration, enabling
surface mapping, resource localization, and mission planning. Aligning data
from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,
Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),
and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya
mission) -- is challenging due to differences in resolution, illumination, and
sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,
AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using
cross-modality image pairs from equatorial and polar regions. A preprocessing
pipeline is proposed, including georeferencing, resolution alignment, intensity
normalization, and enhancements like adaptive histogram equalization, principal
component analysis, and shadow correction. SuperGlue consistently yields the
lowest root mean square error and fastest runtimes. Classical methods such as
SIFT and AKAZE perform well near the equator but degrade under polar lighting.
The results highlight the importance of preprocessing and learning-based
approaches for robust lunar image registration across diverse conditions.
\\ ( https://arxiv.org/abs/2509.04775 ,  14416kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04800
Date: Fri, 5 Sep 2025 04:31:16 GMT   (10456kb)

Title: Toward Accessible Dermatology: Skin Lesion Classification Using Deep
  Learning Models on Mobile-Acquired Images
Authors: Asif Newaz, Masum Mushfiq Ishti, A Z M Ashraful Azam, Asif Ur Rahman
  Adib
Categories: cs.CV cs.AI
Comments: Under Review in ICSigSys 2025
\\
  Skin diseases are among the most prevalent health concerns worldwide, yet
conventional diagnostic methods are often costly, complex, and unavailable in
low-resource settings. Automated classification using deep learning has emerged
as a promising alternative, but existing studies are mostly limited to
dermoscopic datasets and a narrow range of disease classes. In this work, we
curate a large dataset of over 50 skin disease categories captured with mobile
devices, making it more representative of real-world conditions. We evaluate
multiple convolutional neural networks and Transformer-based architectures,
demonstrating that Transformer models, particularly the Swin Transformer,
achieve superior performance by effectively capturing global contextual
features. To enhance interpretability, we incorporate Gradient-weighted Class
Activation Mapping (Grad-CAM), which highlights clinically relevant regions and
provides transparency in model predictions. Our results underscore the
potential of Transformer-based approaches for mobile-acquired skin lesion
classification, paving the way toward accessible AI-assisted dermatological
screening and early diagnosis in resource-limited environments.
\\ ( https://arxiv.org/abs/2509.04800 ,  10456kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04816
Date: Fri, 5 Sep 2025 05:30:53 GMT   (7585kb)

Title: Extracting Uncertainty Estimates from Mixtures of Experts for Semantic
  Segmentation
Authors: Svetlana Pavlitska, Beyza Keskin, Alwin Fa{\ss}bender, Christian
  Hubschneider and J. Marius Z\"ollner
Categories: cs.CV cs.LG
Comments: Accepted for publication at the STREAM workshop at ICCV2025
\\
  Estimating accurate and well-calibrated predictive uncertainty is important
for enhancing the reliability of computer vision models, especially in
safety-critical applications like traffic scene perception. While ensemble
methods are commonly used to quantify uncertainty by combining multiple models,
a mixture of experts (MoE) offers an efficient alternative by leveraging a
gating network to dynamically weight expert predictions based on the input.
Building on the promising use of MoEs for semantic segmentation in our previous
works, we show that well-calibrated predictive uncertainty estimates can be
extracted from MoEs without architectural modifications. We investigate three
methods to extract predictive uncertainty estimates: predictive entropy, mutual
information, and expert variance. We evaluate these methods for an MoE with two
experts trained on a semantical split of the A2D2 dataset. Our results show
that MoEs yield more reliable uncertainty estimates than ensembles in terms of
conditional correctness metrics under out-of-distribution (OOD) data.
Additionally, we evaluate routing uncertainty computed via gate entropy and
find that simple gating mechanisms lead to better calibration of routing
uncertainty estimates than more complex classwise gates. Finally, our
experiments on the Cityscapes dataset suggest that increasing the number of
experts can further enhance uncertainty calibration. Our code is available at
https://github.com/KASTEL-MobilityLab/mixtures-of-experts/.
\\ ( https://arxiv.org/abs/2509.04816 ,  7585kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04824
Date: Fri, 5 Sep 2025 05:50:38 GMT   (25887kb)

Title: Exploring Non-Local Spatial-Angular Correlations with a Hybrid
  Mamba-Transformer Framework for Light Field Super-Resolution
Authors: Haosong Liu, Xiancheng Zhu, Huanqiang Zeng, Jianqing Zhu, Jiuwen Cao,
  and Junhui Hou
Categories: cs.CV cs.AI
\\
  Recently, Mamba-based methods, with its advantage in long-range information
modeling and linear complexity, have shown great potential in optimizing both
computational cost and performance of light field image super-resolution
(LFSR). However, current multi-directional scanning strategies lead to
inefficient and redundant feature extraction when applied to complex LF data.
To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)
strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to
achieve more efficient and precise feature extraction. Furthermore, we propose
a dual-stage modeling strategy to address the limitation of state space in
preserving spatial-angular and disparity information, thereby enabling a more
comprehensive exploration of non-local spatial-angular correlations.
Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace
Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage
II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba
Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar
feature refinement. Building upon meticulously designed modules and strategies,
we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates
the strengths of Mamba and Transformer models for LFSR, enabling comprehensive
information exploration across spatial, angular, and epipolar-plane domains.
Experimental results demonstrate that LFMT significantly outperforms current
state-of-the-art methods in LFSR, achieving substantial improvements in
performance while maintaining low computational complexity on both real-word
and synthetic LF datasets.
\\ ( https://arxiv.org/abs/2509.04824 ,  25887kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04833
Date: Fri, 5 Sep 2025 06:30:06 GMT   (10555kb)

Title: PropVG: End-to-End Proposal-Driven Visual Grounding with
  Multi-Granularity Discrimination
Authors: Ming Dai, Wenxuan Cheng, Jiedong Zhuang, Jiang-jiang Liu, Hongshen
  Zhao, Zhenhua Feng, Wankou Yang
Categories: cs.CV cs.AI
Comments: ICCV2025
\\
  Recent advances in visual grounding have largely shifted away from
traditional proposal-based two-stage frameworks due to their inefficiency and
high computational complexity, favoring end-to-end direct reference paradigms.
However, these methods rely exclusively on the referred target for supervision,
overlooking the potential benefits of prominent prospective targets. Moreover,
existing approaches often fail to incorporate multi-granularity discrimination,
which is crucial for robust object identification in complex scenarios. To
address these limitations, we propose PropVG, an end-to-end proposal-based
framework that, to the best of our knowledge, is the first to seamlessly
integrate foreground object proposal generation with referential object
comprehension without requiring additional detectors. Furthermore, we introduce
a Contrastive-based Refer Scoring (CRS) module, which employs contrastive
learning at both sentence and word levels to enhance the capability in
understanding and distinguishing referred objects. Additionally, we design a
Multi-granularity Target Discrimination (MTD) module that fuses object- and
semantic-level information to improve the recognition of absent targets.
Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO
(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and
models are available at https://github.com/Dmmm1997/PropVG.
\\ ( https://arxiv.org/abs/2509.04833 ,  10555kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04834
Date: Fri, 5 Sep 2025 06:35:36 GMT   (9005kb)

Title: TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting
  Scramjet Combustion Evolution
Authors: Yifei Jia, Shiyu Cheng, Yu Dong, Guan Li, Dong Tian, Ruixiao Peng,
  Xuyi Lu, Yu Wang, Wei Yao, Guihua Shan
Categories: cs.CV
\\
  Understanding the complex combustion dynamics within scramjet engines is
critical for advancing high-speed propulsion technologies. However, the large
scale and high dimensionality of simulation-generated temporal flow field data
present significant challenges for visual interpretation, feature
differentiation, and cross-case comparison. In this paper, we present
TemporalFlowViz, a parameter-aware visual analytics workflow and system
designed to support expert-driven clustering, visualization, and interpretation
of temporal flow fields from scramjet combustion simulations. Our approach
leverages hundreds of simulated combustion cases with varying initial
conditions, each producing time-sequenced flow field images. We use pretrained
Vision Transformers to extract high-dimensional embeddings from these frames,
apply dimensionality reduction and density-based clustering to uncover latent
combustion modes, and construct temporal trajectories in the embedding space to
track the evolution of each simulation over time. To bridge the gap between
latent representations and expert reasoning, domain specialists annotate
representative cluster centroids with descriptive labels. These annotations are
used as contextual prompts for a vision-language model, which generates
natural-language summaries for individual frames and full simulation cases. The
system also supports parameter-based filtering, similarity-based case
retrieval, and coordinated multi-view exploration to facilitate in-depth
analysis. We demonstrate the effectiveness of TemporalFlowViz through two
expert-informed case studies and expert feedback, showing TemporalFlowViz
enhances hypothesis generation, supports interpretable pattern discovery, and
enhances knowledge discovery in large-scale scramjet combustion analysis.
\\ ( https://arxiv.org/abs/2509.04834 ,  9005kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04848
Date: Fri, 5 Sep 2025 06:58:39 GMT   (20433kb)

Title: Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations
Authors: Enze Ye, Wei Lin, Shaochi Ren, Yakun Liu, Xiaoping Li, Hao Wang, He
  Sun, Feng Pan
Categories: cs.CV physics.bio-ph physics.optics q-bio.QM
Comments: 16 pages, 5 figures
\\
  High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables
label-free, volumetric characterization of individual cells by reconstructing
their refractive index (RI) distributions from multiple viewing angles during
flow through microfluidic channels. However, current imaging methods assume
that cells undergo uniform, single-axis rotation, which require their poses to
be known at each frame. This assumption restricts applicability to
near-spherical cells and prevents accurate imaging of irregularly shaped cells
with complex rotations. As a result, only a subset of the cellular population
can be analyzed, limiting the ability of flow-based assays to perform robust
statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction
framework that leverages the Fourier diffraction theorem and implicit neural
representations (INRs) for high-throughput flow cytometry tomographic imaging.
By jointly optimizing each cell's unknown rotational trajectory and volumetric
structure under weak scattering assumptions, OmniFHT supports arbitrary cell
geometries and multi-axis rotations. Its continuous representation also allows
accurate reconstruction from sparsely sampled projections and restricted
angular coverage, producing high-fidelity results with as few as 10 views or
only 120 degrees of angular range. OmniFHT enables, for the first time, in
situ, high-throughput tomographic imaging of entire flowing cell populations,
providing a scalable and unbiased solution for label-free morphometric analysis
in flow cytometry platforms.
\\ ( https://arxiv.org/abs/2509.04848 ,  20433kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04859
Date: Fri, 5 Sep 2025 07:21:26 GMT   (2866kb)

Title: CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus
Authors: Hannah Schieber, Dominik Frischmann, Simon Boche, Victor Schaack,
  Angela Schoellig, Stefan Leutenegger and Daniel Roth
Categories: cs.CV
\\
  Mobile reconstruction for autonomous aerial robotics holds strong potential
for critical applications such as tele-guidance and disaster response. These
tasks demand both accurate 3D reconstruction and fast scene processing. Instead
of reconstructing the entire scene in detail, it is often more efficient to
focus on specific objects, i.e., points of interest (PoIs). Mobile robots
equipped with advanced sensing can usually detect these early during data
acquisition or preliminary analysis, reducing the need for full-scene
optimization. Gaussian Splatting (GS) has recently shown promise in delivering
high-quality novel view synthesis and 3D representation by an incremental
learning process. Extending GS with scene editing, semantics adds useful
per-splat features to isolate objects effectively.
  Semantic 3D Gaussian editing can already be achieved before the full training
cycle is completed, reducing the overall training time. Moreover, the
semantically relevant area, the PoI, is usually already known during capturing.
To balance high-quality reconstruction with reduced training time, we propose
CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS
and then refine it for the semantic object using our novel color-based
effective filtering for effective object isolation. This is speeding up the
training process to be about a quarter less than a full training cycle for
semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,
outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher
novel-view-synthesis quality.
\\ ( https://arxiv.org/abs/2509.04859 ,  2866kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04886
Date: Fri, 5 Sep 2025 08:06:08 GMT   (457kb)

Title: Cryo-RL: automating prostate cancer cryoablation planning with
  reinforcement learning
Authors: Trixia Simangan, Ahmed Nadeem Abbasi, Yipeng Hu, Shaheer U. Saeed
Categories: cs.CV
Comments: Accepted at MICAD (Medical Imaging and Computer-Aided Diagnosis) 2025
\\
  Cryoablation is a minimally invasive localised treatment for prostate cancer
that destroys malignant tissue during de-freezing, while sparing surrounding
healthy structures. Its success depends on accurate preoperative planning of
cryoprobe placements to fully cover the tumour and avoid critical anatomy. This
planning is currently manual, expertise-dependent, and time-consuming, leading
to variability in treatment quality and limited scalability. In this work, we
introduce Cryo-RL, a reinforcement learning framework that models cryoablation
planning as a Markov decision process and learns an optimal policy for
cryoprobe placement. Within a simulated environment that models clinical
constraints and stochastic intraoperative variability, an agent sequentially
selects cryoprobe positions and ice sphere diameters. Guided by a reward
function based on tumour coverage, this agent learns a cryoablation strategy
that leads to optimal cryoprobe placements without the need for any
manually-designed plans. Evaluated on 583 retrospective prostate cancer cases,
Cryo-RL achieved over 8 percentage-point Dice improvements compared with the
best automated baselines, based on geometric optimisation, and matched human
expert performance while requiring substantially less planning time. These
results highlight the potential of reinforcement learning to deliver clinically
viable, reproducible, and efficient cryoablation plans.
\\ ( https://arxiv.org/abs/2509.04886 ,  457kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04889
Date: Fri, 5 Sep 2025 08:10:40 GMT   (26484kb)

Title: SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision
  Models
Authors: Dominik Pegler, David Steyrl, Mengfan Zhang, Alexander Karner, Jozsef
  Arato, Frank Scharnowski, Filip Melinscak
Categories: cs.CV cs.AI cs.HC cs.LG
Comments: 60 pages (30 main text, 30 appendix), 20 figures (5 in main text, 15
  in appendix)
\\
  Advances in computer vision have opened new avenues for clinical
applications, particularly in computerized exposure therapy where visual
stimuli can be dynamically adjusted based on patient responses. As a critical
step toward such adaptive systems, we investigated whether pretrained computer
vision models can accurately predict fear levels from spider-related images. We
adapted three diverse models using transfer learning to predict human fear
ratings (on a 0-100 scale) from a standardized dataset of 313 images. The
models were evaluated using cross-validation, achieving an average mean
absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis
revealed that reducing the dataset size significantly harmed performance,
though further increases yielded no substantial gains. Explainability
assessments showed the models' predictions were based on spider-related
features. A category-wise error analysis further identified visual conditions
associated with higher errors (e.g., distant views and artificial/painted
spiders). These findings demonstrate the potential of explainable computer
vision models in predicting fear ratings, highlighting the importance of both
model explainability and a sufficient dataset size for developing effective
emotion-aware therapeutic technologies.
\\ ( https://arxiv.org/abs/2509.04889 ,  26484kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04894
Date: Fri, 5 Sep 2025 08:15:46 GMT   (577kb)

Title: SynGen-Vision: Synthetic Data Generation for training industrial vision
  models
Authors: Alpana Dubey, Suma Mani Kuriakose, Nitish Bhardwaj
Categories: cs.CV cs.LG
ACM-class: I.4
\\
  We propose an approach to generate synthetic data to train computer vision
(CV) models for industrial wear and tear detection. Wear and tear detection is
an important CV problem for predictive maintenance tasks in any industry.
However, data curation for training such models is expensive and time-consuming
due to the unavailability of datasets for different wear and tear scenarios.
Our approach employs a vision language model along with a 3D simulation and
rendering engine to generate synthetic data for varying rust conditions. We
evaluate our approach by training a CV model for rust detection using the
generated dataset and tested the trained model on real images of rusted
industrial objects. The model trained with the synthetic data generated by our
approach, outperforms the other approaches with a mAP50 score of 0.87. The
approach is customizable and can be easily extended to other industrial wear
and tear detection scenarios
\\ ( https://arxiv.org/abs/2509.04894 ,  577kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04895
Date: Fri, 5 Sep 2025 08:15:57 GMT   (319kb)

Title: Evaluating Multiple Instance Learning Strategies for Automated Sebocyte
  Droplet Counting
Authors: Maryam Adelipour, Gustavo Carneiro, Jeongkwon Kim
Categories: cs.CV cs.LG
Comments: 8 pages, 1 figure, 2 tables
\\
  Sebocytes are lipid-secreting cells whose differentiation is marked by the
accumulation of intracellular lipid droplets, making their quantification a key
readout in sebocyte biology. Manual counting is labor-intensive and subjective,
motivating automated solutions. Here, we introduce a simple attention-based
multiple instance learning (MIL) framework for sebocyte image analysis. Nile
Red-stained sebocyte images were annotated into 14 classes according to droplet
counts, expanded via data augmentation to about 50,000 cells. Two models were
benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated
patch-level counts, and an attention-based MIL model leveraging ResNet-50
features with instance weighting. Experiments using five-fold cross-validation
showed that the baseline MLP achieved more stable performance (mean MAE = 5.6)
compared with the attention-based MIL, which was less consistent (mean MAE =
10.7) but occasionally superior in specific folds. These findings indicate that
simple bag-level aggregation provides a robust baseline for slide-level droplet
counting, while attention-based MIL requires task-aligned pooling and
regularization to fully realize its potential in sebocyte image analysis.
\\ ( https://arxiv.org/abs/2509.04895 ,  319kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04932
Date: Fri, 5 Sep 2025 08:54:57 GMT   (1865kb)

Title: UniView: Enhancing Novel View Synthesis From A Single Image By Unifying
  Reference Features
Authors: Haowang Cui, Rui Chen, Tao Luo, Rui Li, Jiaze Wang
Categories: cs.CV
Comments: Submitted to ACM TOMM
\\
  The task of synthesizing novel views from a single image is highly ill-posed
due to multiple explanations for unobserved areas. Most current methods tend to
generate unseen regions from ambiguity priors and interpolation near input
views, which often lead to severe distortions. To address this limitation, we
propose a novel model dubbed as UniView, which can leverage reference images
from a similar object to provide strong prior information during view
synthesis. More specifically, we construct a retrieval and augmentation system
and employ a multimodal large language model (MLLM) to assist in selecting
reference images that meet our requirements. Additionally, a plug-and-play
adapter module with multi-level isolation layers is introduced to dynamically
generate reference features for the target views. Moreover, in order to
preserve the details of an original input image, we design a decoupled triple
attention mechanism, which can effectively align and integrate multi-branch
features into the synthesis process. Extensive experiments have demonstrated
that our UniView significantly improves novel view synthesis performance and
outperforms state-of-the-art methods on the challenging datasets.
\\ ( https://arxiv.org/abs/2509.04932 ,  1865kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04957
Date: Fri, 5 Sep 2025 09:24:08 GMT   (1586kb)

Title: Efficient Video-to-Audio Generation via Multiple Foundation Models
  Mapper
Authors: Gehui Chen, Guan'an Wang, Xiaowen Huang, Jitao Sang
Categories: cs.CV cs.MM cs.SD eess.AS
\\
  Recent Video-to-Audio (V2A) generation relies on extracting semantic and
temporal features from video to condition generative models. Training these
models from scratch is resource intensive. Consequently, leveraging foundation
models (FMs) has gained traction due to their cross-modal knowledge transfer
and generalization capabilities. One prior work has explored fine-tuning a
lightweight mapper network to connect a pre-trained visual encoder with a
text-to-audio generation model for V2A. Inspired by this, we introduce the
Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper
approach, MFM-Mapper benefits from richer semantic and temporal information by
fusing features from dual visual encoders. Furthermore, by replacing a linear
mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels
between cross-modal features mapping and autoregressive translation tasks. Our
MFM-Mapper exhibits remarkable training efficiency. It achieves better
performance in semantic and temporal consistency with fewer training consuming,
requiring only 16\% of the training scale compared to previous mapper-based
work, yet achieves competitive performance with models trained on a much larger
scale.
\\ ( https://arxiv.org/abs/2509.04957 ,  1586kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05000
Date: Fri, 5 Sep 2025 10:48:46 GMT   (13066kb)

Title: Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust
  Infrared and Visible Image Fusion Framework
Authors: Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui
Categories: cs.CV
\\
  Most existing infrared-visible image fusion (IVIF) methods assume
high-quality inputs, and therefore struggle to handle dual-source degraded
scenarios, typically requiring manual selection and sequential application of
multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion
pipeline inevitably leads to error accumulation and performance degradation. To
overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),
a novel framework that synergistically integrates vision-language models (VLMs)
for degradation perception with dual-domain (frequency/spatial) joint
optimization. Concretely, the designed Guided Frequency Modality-Specific
Extraction (GFMSE) module performs frequency-domain degradation perception and
suppression and discriminatively extracts fusion-relevant sub-band features.
Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries
out cross-modal degradation filtering and adaptive multi-source feature
aggregation in the spatial domain to enhance modality complementarity and
structural consistency. Extensive qualitative and quantitative experiments
demonstrate that GD^2Fusion achieves superior fusion performance compared with
existing algorithms and strategies in dual-source degraded scenarios. The code
will be publicly released after acceptance of this paper.
\\ ( https://arxiv.org/abs/2509.05000 ,  13066kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05004
Date: Fri, 5 Sep 2025 11:03:15 GMT   (69kb)

Title: Interpretable Deep Transfer Learning for Breast Ultrasound Cancer
  Detection: A Multi-Dataset Study
Authors: Mohammad Abbadi, Yassine Himeur, Shadi Atalla, and Wathiq Mansoor
Categories: cs.CV
Comments: 6 pages, 2 figures and 1 table
\\
  Breast cancer remains a leading cause of cancer-related mortality among women
worldwide. Ultrasound imaging, widely used due to its safety and
cost-effectiveness, plays a key role in early detection, especially in patients
with dense breast tissue. This paper presents a comprehensive study on the
application of machine learning and deep learning techniques for breast cancer
classification using ultrasound images. Using datasets such as BUSI, BUS-BRA,
and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,
KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,
GoogLeNet). Experimental results show that ResNet-18 achieves the highest
accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML
models, though outperformed by CNNs, achieve competitive performance when
enhanced with deep feature extraction. Grad-CAM visualizations further improve
model transparency by highlighting diagnostically relevant image regions. These
findings support the integration of AI-based diagnostic tools into clinical
workflows and demonstrate the feasibility of deploying high-performing,
interpretable systems for ultrasound-based breast cancer detection.
\\ ( https://arxiv.org/abs/2509.05004 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05012
Date: Fri, 5 Sep 2025 11:22:52 GMT   (1117kb)

Title: A biologically inspired separable learning vision model for real-time
  traffic object perception in Dark
Authors: Hulin Li, Qiliang Ren, Jun Li, Hanbing Wei, Zheng Liu, Linfang Fan
Categories: cs.CV
DOI: 10.1016/j.eswa.2025.129529
\\
  Fast and accurate object perception in low-light traffic scenes has attracted
increasing attention. However, due to severe illumination degradation and the
lack of reliable visual cues, existing perception models and methods struggle
to quickly adapt to and accurately predict in low-light environments. Moreover,
there is the absence of available large-scale benchmark specifically focused on
low-light traffic scenes. To bridge this gap, we introduce a physically
grounded illumination degradation method tailored to real-world low-light
settings and construct Dark-traffic, the largest densely annotated dataset to
date for low-light traffic scenes, supporting object detection, instance
segmentation, and optical flow estimation. We further propose the Separable
Learning Vision Model (SLVM), a biologically inspired framework designed to
enhance perception under adverse lighting. SLVM integrates four key components:
a light-adaptive pupillary mechanism for illumination-sensitive feature
extraction, a feature-level separable learning strategy for efficient
representation, task-specific decoupled branches for multi-task separable
learning, and a spatial misalignment-aware fusion module for precise
multi-feature alignment. Extensive experiments demonstrate that SLVM achieves
state-of-the-art performance with reduced computational overhead. Notably, it
outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1
percentage points in instance segmentation, and reduces endpoint error (EPE) of
baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end
trained SLVM surpasses Swin Transformer+EnlightenGAN and
ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key
metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage
points. The Dark-traffic dataset and complete code is released at
https://github.com/alanli1997/slvm.
\\ ( https://arxiv.org/abs/2509.05012 ,  1117kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05019
Date: Fri, 5 Sep 2025 11:28:53 GMT   (476kb)

Title: Leveraging Transfer Learning and Mobile-enabled Convolutional Neural
  Networks for Improved Arabic Handwritten Character Recognition
Authors: Mohsine El Khayati, Ayyad Maafiri, Yassine Himeur, Hamzah Ali
  Alkhazaleh, Shadi Atalla, and Wathiq Mansoor
Categories: cs.CV
Comments: 20pages, 9 figures and 11 tables
\\
  The study explores the integration of transfer learning (TL) with
mobile-enabled convolutional neural networks (MbNets) to enhance Arabic
Handwritten Character Recognition (AHCR). Addressing challenges like extensive
computational requirements and dataset scarcity, this research evaluates three
TL strategies--full fine-tuning, partial fine-tuning, and training from
scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and
ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,
HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently
achieving superior accuracy, robustness, and efficiency, with ShuffleNet
excelling in generalization, particularly under full fine-tuning. The IFHCDB
dataset yielded the highest results, with 99% accuracy using MnasNet under full
fine-tuning, highlighting its suitability for robust character recognition. The
AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA
posed significant challenges due to its variability, achieving a peak accuracy
of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall
performance, balancing accuracy and convergence speed, while partial
fine-tuning underperformed across metrics. These findings underscore the
potential of combining TL and MbNets for resource-efficient AHCR, paving the
way for further optimizations and broader applications. Future work will
explore architectural modifications, in-depth dataset feature analysis, data
augmentation, and advanced sensitivity analysis to enhance model robustness and
generalizability.
\\ ( https://arxiv.org/abs/2509.05019 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05030
Date: Fri, 5 Sep 2025 11:40:44 GMT   (10156kb)

Title: LUIVITON: Learned Universal Interoperable VIrtual Try-ON
Authors: Cong Cao, Xianhang Cheng, Jingyuan Liu, Yujian Zheng, Zhenhui Lin,
  Meriem Chkir, Hao Li
Categories: cs.CV
\\
  We present LUIVITON, an end-to-end system for fully automated virtual try-on,
capable of draping complex, multi-layer clothing onto diverse and arbitrarily
posed humanoid characters. To address the challenge of aligning complex
garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy
representation and separate the clothing-to-body draping problem into two
correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,
where each has its unique challenges. While we address the clothing-to-SMPL
fitting problem using a geometric learning-based approach for
partial-to-complete shape correspondence prediction, we introduce a diffusion
model-based approach for body-to-SMPL correspondence using multi-view
consistent appearance features and a pre-trained 2D foundation model. Our
method can handle complex geometries, non-manifold meshes, and generalizes
effectively to a wide range of humanoid characters -- including humans, robots,
cartoon subjects, creatures, and aliens, while maintaining computational
efficiency for practical adoption. In addition to offering a fully automatic
fitting solution, LUIVITON supports fast customization of clothing size,
allowing users to adjust clothing sizes and material properties after they have
been draped. We show that our system can produce high-quality 3D clothing
fittings without any human labor, even when 2D clothing sewing patterns are not
available.
\\ ( https://arxiv.org/abs/2509.05030 ,  10156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05034
Date: Fri, 5 Sep 2025 11:45:17 GMT   (311kb)

Title: Towards Efficient Pixel Labeling for Industrial Anomaly Detection and
  Localization
Authors: Jingqi Wu, Hanxi Li, Lin Yuanbo Wu, Hao Chen, Deyin Liu, Peng Wang
Categories: cs.CV cs.AI
\\
  Industrial product inspection is often performed using Anomaly Detection (AD)
frameworks trained solely on non-defective samples. Although defective samples
can be collected during production, leveraging them usually requires
pixel-level annotations, limiting scalability. To address this, we propose
ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial
anomaly detection. ADClick generates pixel-wise anomaly annotations from only a
few user clicks and a brief textual description, enabling precise and efficient
labeling that significantly improves AD model performance (e.g., AP = 96.1\% on
MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that
aligns visual features and textual prompts via a prototype-based approach for
anomaly detection and localization. By combining pixel-level priors with
language-guided cues, ADClick-Seg achieves state-of-the-art results on the
challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC =
99.1\% on MVTec AD).
\\ ( https://arxiv.org/abs/2509.05034 ,  311kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05071
Date: Fri, 5 Sep 2025 13:09:37 GMT   (18852kb)

Title: Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact
  Detection and Correction
Authors: Mojtaba Safari, Zach Eidex, Richard L.J. Qiu, Matthew Goette, Tonghe
  Wang, and Xiaofeng Yang
Categories: cs.CV physics.med-ph
\\
  Background: To systematically review and perform a meta-analysis of
artificial intelligence (AI)-driven methods for detecting and correcting
magnetic resonance imaging (MRI) motion artifacts, assessing current
developments, effectiveness, challenges, and future research directions.
Methods: A comprehensive systematic review and meta-analysis were conducted,
focusing on deep learning (DL) approaches, particularly generative models, for
the detection and correction of MRI motion artifacts. Quantitative data were
extracted regarding utilized datasets, DL architectures, and performance
metrics. Results: DL, particularly generative models, show promise for reducing
motion artifacts and improving image quality; however, limited
generalizability, reliance on paired training data, and risk of visual
distortions remain key challenges that motivate standardized datasets and
reporting. Conclusions: AI-driven methods, particularly DL generative models,
show significant potential for improving MRI image quality by effectively
addressing motion artifacts. However, critical challenges must be addressed,
including the need for comprehensive public datasets, standardized reporting
protocols for artifact levels, and more advanced, adaptable DL techniques to
reduce reliance on extensive paired datasets. Addressing these aspects could
substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and
improve patient care outcomes.
\\ ( https://arxiv.org/abs/2509.05071 ,  18852kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05075
Date: Fri, 5 Sep 2025 13:15:37 GMT   (16252kb)

Title: GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting
Authors: Yangming Li, Chaoyu Liu, Lihao Liu, Simon Masnou, Carola-Bibian
  Sch\"onlieb
Categories: cs.CV
\\
  A few recent works explored incorporating geometric priors to regularize the
optimization of Gaussian splatting, further improving its performance. However,
those early studies mainly focused on the use of low-order geometric priors
(e.g., normal vector), and they are also unreliably estimated by
noise-sensitive methods, like local principal component analysis. To address
their limitations, we first present GeoSplat, a general geometry-constrained
optimization framework that exploits both first-order and second-order
geometric quantities to improve the entire training pipeline of Gaussian
splatting, including Gaussian initialization, gradient update, and
densification. As an example, we initialize the scales of 3D Gaussian
primitives in terms of principal curvatures, leading to a better coverage of
the object surface than random initialization. Secondly, based on certain
geometric structures (e.g., local manifold), we introduce efficient and
noise-robust estimation methods that provide dynamic geometric priors for our
framework. We conduct extensive experiments on multiple datasets for novel view
synthesis, showing that our framework: GeoSplat, significantly improves the
performance of Gaussian splatting and outperforms previous baselines.
\\ ( https://arxiv.org/abs/2509.05075 ,  16252kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05078
Date: Fri, 5 Sep 2025 13:16:55 GMT   (19kb)

Title: Scale-interaction transformer: a hybrid cnn-transformer model for facial
  beauty prediction
Authors: Djamel Eddine Boukhari
Categories: cs.CV
\\
  Automated Facial Beauty Prediction (FBP) is a challenging computer vision
task due to the complex interplay of local and global facial features that
influence human perception. While Convolutional Neural Networks (CNNs) excel at
feature extraction, they often process information at a fixed scale,
potentially overlooking the critical inter-dependencies between features at
different levels of granularity. To address this limitation, we introduce the
Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture
that synergizes the feature extraction power of CNNs with the relational
modeling capabilities of Transformers. The SIT first employs a multi-scale
module with parallel convolutions to capture facial characteristics at varying
receptive fields. These multi-scale representations are then framed as a
sequence and processed by a Transformer encoder, which explicitly models their
interactions and contextual relationships via a self-attention mechanism. We
conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark
dataset, where the proposed SIT model establishes a new state-of-the-art. It
achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our
findings demonstrate that explicitly modeling the interplay between multi-scale
visual cues is crucial for high-performance FBP. The success of the SIT
architecture highlights the potential of hybrid CNN-Transformer models for
complex image regression tasks that demand a holistic, context-aware
understanding.
\\ ( https://arxiv.org/abs/2509.05078 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05086
Date: Fri, 5 Sep 2025 13:25:33 GMT   (1931kb)

Title: Robust Experts: the Effect of Adversarial Training on CNNs with Sparse
  Mixture-of-Experts Layers
Authors: Svetlana Pavlitska, Haixi Fan, Konstantin Ditschuneit, J. Marius
  Z\"ollner
Categories: cs.CV cs.LG
Comments: Accepted for publication at the STREAM workshop at ICCV 2025
\\
  Robustifying convolutional neural networks (CNNs) against adversarial attacks
remains challenging and often requires resource-intensive countermeasures. We
explore the use of sparse mixture-of-experts (MoE) layers to improve robustness
by replacing selected residual blocks or convolutional layers, thereby
increasing model capacity without additional inference cost. On ResNet
architectures trained on CIFAR-100, we find that inserting a single MoE layer
in the deeper stages leads to consistent improvements in robustness under PGD
and AutoPGD attacks when combined with adversarial training. Furthermore, we
discover that when switch loss is used for balancing, it causes routing to
collapse onto a small set of overused experts, thereby concentrating
adversarial training on these paths and inadvertently making them more robust.
As a result, some individual experts outperform the gated MoE model in
robustness, suggesting that robust subpaths emerge through specialization. Our
code is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.
\\ ( https://arxiv.org/abs/2509.05086 ,  1931kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05092
Date: Fri, 5 Sep 2025 13:30:49 GMT   (6348kb)

Title: Semi-supervised Deep Transfer for Regression without Domain Alignment
Authors: Mainak Biswas, Ambedkar Dukkipati, Devarajan Sridharan
Categories: cs.CV
Comments: 15 pages, 6 figures, International Conference on Computer Vision 2025
\\
  Deep learning models deployed in real-world applications (e.g., medicine)
face challenges because source models do not generalize well to domain-shifted
target data. Many successful domain adaptation (DA) approaches require full
access to source data. Yet, such requirements are unrealistic in scenarios
where source data cannot be shared either because of privacy concerns or
because it is too large and incurs prohibitive storage or computational costs.
Moreover, resource constraints may limit the availability of labeled targets.
We illustrate this challenge in a neuroscience setting where source data are
unavailable, labeled target data are meager, and predictions involve
continuous-valued outputs. We build upon Contradistinguisher (CUDA), an
efficient framework that learns a shared model across the labeled source and
unlabeled target samples, without intermediate representation alignment. Yet,
CUDA was designed for unsupervised DA, with full access to source data, and for
classification tasks. We develop CRAFT -- a Contradistinguisher-based
Regularization Approach for Flexible Training -- for source-free (SF),
semi-supervised transfer of pretrained models in regression tasks. We showcase
the efficacy of CRAFT in two neuroscience settings: gaze prediction with
electroencephalography (EEG) data and ``brain age'' prediction with structural
MRI data. For both datasets, CRAFT yielded up to 9% improvement in
root-mean-squared error (RMSE) over fine-tuned models when labeled training
examples were scarce. Moreover, CRAFT leveraged unlabeled target data and
outperformed four competing state-of-the-art source-free domain adaptation
models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two
other real-world regression benchmarks. We propose CRAFT as an efficient
approach for source-free, semi-supervised deep transfer for regression that is
ubiquitous in biology and medicine.
\\ ( https://arxiv.org/abs/2509.05092 ,  6348kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05131
Date: Fri, 5 Sep 2025 14:18:52 GMT   (2964kb)

Title: A Scalable Attention-Based Approach for Image-to-3D Texture Mapping
Authors: Arianna Rampini, Kanika Madan, Bruno Roy, AmirHossein Zamani, Derek
  Cheung
Categories: cs.CV cs.LG
\\
  High-quality textures are critical for realistic 3D content creation, yet
existing generative methods are slow, rely on UV maps, and often fail to remain
faithful to a reference image. To address these challenges, we propose a
transformer-based framework that predicts a 3D texture field directly from a
single image and a mesh, eliminating the need for UV mapping and differentiable
rendering, and enabling faster texture generation. Our method integrates a
triplane representation with depth-based backprojection losses, enabling
efficient training and faster inference. Once trained, it generates
high-fidelity textures in a single forward pass, requiring only 0.2s per shape.
Extensive qualitative, quantitative, and user preference evaluations
demonstrate that our method outperforms state-of-the-art baselines on
single-image texture reconstruction in terms of both fidelity to the input
image and perceptual quality, highlighting its practicality for scalable,
high-quality, and controllable 3D content creation.
\\ ( https://arxiv.org/abs/2509.05131 ,  2964kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05144
Date: Fri, 5 Sep 2025 14:37:31 GMT   (43138kb)

Title: SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic
  Mask Splitting and Growing
Authors: Chaolei Wang, Yang Luo, Jing Du, Siyu Chen, Yiping Chen, Ting Han
Categories: cs.CV
\\
  Accurate 3D instance segmentation is crucial for high-quality scene
understanding in the 3D vision domain. However, 3D instance segmentation based
on 2D-to-3D lifting approaches struggle to produce precise instance-level
segmentation, due to accumulated errors introduced during the lifting process
from ambiguous semantic guidance and insufficient depth constraints. To tackle
these challenges, we propose splitting and growing reliable semantic mask for
high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow"
framework that first purifies and splits ambiguous lifted masks using geometric
primitives, and then grows them into complete instances within the scene.
Unlike existing approaches that directly rely on raw lifted masks and sacrifice
segmentation accuracy, SGS-3D serves as a training-free refinement method that
jointly fuses semantic and geometric information, enabling effective
cooperation between the two levels of representation. Specifically, for
semantic guidance, we introduce a mask filtering strategy that leverages the
co-occurrence of 3D geometry primitives to identify and remove ambiguous masks,
thereby ensuring more reliable semantic consistency with the 3D object
instances. For the geometric refinement, we construct fine-grained object
instances by exploiting both spatial continuity and high-level features,
particularly in the case of semantic ambiguity between distinct objects.
Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that
SGS-3D substantially improves segmentation accuracy and robustness against
inaccurate masks from pre-trained models, yielding high-fidelity object
instances while maintaining strong generalization across diverse indoor and
outdoor environments. Code is available in the supplementary materials.
\\ ( https://arxiv.org/abs/2509.05144 ,  43138kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05188
Date: Fri, 5 Sep 2025 15:38:19 GMT   (3750kb)

Title: SL-SLR: Self-Supervised Representation Learning for Sign Language
  Recognition
Authors: Ariel Basso Madjoukeng, J\'er\^ome Fink, Pierre Poitier, Edith Belise
  Kenmogne, and Benoit Frenay
Categories: cs.CV
\\
  Sign language recognition (SLR) is a machine learning task aiming to identify
signs in videos. Due to the scarcity of annotated data, unsupervised methods
like contrastive learning have become promising in this field. They learn
meaningful representations by pulling positive pairs (two augmented versions of
the same instance) closer and pushing negative pairs (different from the
positive pairs) apart. In SLR, in a sign video, only certain parts provide
information that is truly useful for its recognition. Applying contrastive
methods to SLR raises two issues: (i) contrastive learning methods treat all
parts of a video in the same way, without taking into account the relevance of
certain parts over others; (ii) shared movements between different signs make
negative pairs highly similar, complicating sign discrimination. These issues
lead to learning non-discriminative features for sign recognition and poor
results in downstream tasks. In response, this paper proposes a self-supervised
learning framework designed to learn meaningful representations for SLR. This
framework consists of two key components designed to work together: (i) a new
self-supervised approach with free-negative pairs; (ii) a new data augmentation
technique. This approach shows a considerable gain in accuracy compared to
several contrastive and self-supervised methods, across linear evaluation,
semi-supervised learning, and transferability between sign languages.
\\ ( https://arxiv.org/abs/2509.05188 ,  3750kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05198
Date: Fri, 5 Sep 2025 15:57:36 GMT   (12094kb)

Title: Enhancing 3D Point Cloud Classification with ModelNet-R and
  Point-SkipNet
Authors: Mohammad Saeid, Amir Salarpour and Pedram MohajerAnsari
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: This paper has been accepted for presentation at the 7th
  International Conference on Pattern Recognition and Image Analysis (IPRIA
  2025)
\\
  The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.
\\ ( https://arxiv.org/abs/2509.05198 ,  12094kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05208
Date: Fri, 5 Sep 2025 16:10:53 GMT   (2869kb)

Title: Symbolic Graphics Programming with Large Language Models
Authors: Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang,
  Yandong Wen and Weiyang Liu
Categories: cs.CV cs.LG
Comments: Technical report (32 pages, 12 figures, project page:
  https://spherelab.ai/SGP-Gen/)
\\
  Large language models (LLMs) excel at program synthesis, yet their ability to
produce symbolic graphics programs (SGPs) that render into precise visual
content remains underexplored. We study symbolic graphics programming, where
the goal is to generate an SGP from a natural-language description. This task
also serves as a lens into how LLMs understand the visual world by prompting
them to generate images rendered from SGPs. Among various SGPs, our paper
sticks to scalable vector graphics (SVGs). We begin by examining the extent to
which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a
comprehensive benchmark covering object fidelity, scene fidelity, and
compositionality (attribute binding, spatial relations, numeracy). On
SGP-GenBench, we discover that frontier proprietary models substantially
outperform open-source models, and performance correlates well with general
coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to
generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards
approach, where a format-validity gate ensures renderable SVG, and a
cross-modal reward aligns text and the rendered image via strong vision
encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to
Qwen-2.5-7B, our method substantially improves SVG generation quality and
semantics, achieving performance on par with frontier systems. We further
analyze training dynamics, showing that RL induces (i) finer decomposition of
objects into controllable primitives and (ii) contextual details that improve
scene coherence. Our results demonstrate that symbolic graphics programming
offers a precise and interpretable lens on cross-modal grounding.
\\ ( https://arxiv.org/abs/2509.05208 ,  2869kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05249
Date: Fri, 5 Sep 2025 17:01:05 GMT   (1335kb)

Title: COGITAO: A Visual Reasoning Framework To Study Compositionality &
  Generalization
Authors: Yassine Taoudi-Benchekroun, Klim Troyan, Pascal Sager, Stefan Gerber,
  Lukas Tuggener and Benjamin Grewe
Categories: cs.CV cs.AI
Comments: 10 main pages, 3 figure, appendix available
\\
  The ability to compose learned concepts and apply them in novel settings is
key to human intelligence, but remains a persistent limitation in
state-of-the-art machine learning models. To address this issue, we introduce
COGITAO, a modular and extensible data generation framework and benchmark
designed to systematically study compositionality and generalization in visual
domains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs
rule-based tasks which apply a set of transformations to objects in grid-like
environments. It supports composition, at adjustable depth, over a set of 28
interoperable transformations, along with extensive control over grid
parametrization and object properties. This flexibility enables the creation of
millions of unique task rules -- surpassing concurrent datasets by several
orders of magnitude -- across a wide range of difficulties, while allowing
virtually unlimited sample generation per rule. We provide baseline experiments
using state-of-the-art vision models, highlighting their consistent failures to
generalize to novel combinations of familiar elements, despite strong in-domain
performance. COGITAO is fully open-sourced, including all code and datasets, to
support continued research in this field.
\\ ( https://arxiv.org/abs/2509.05249 ,  1335kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05296
Date: Fri, 5 Sep 2025 17:59:47 GMT   (5360kb)

Title: WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool
Authors: Zizun Li, Jianjun Zhou, Yifan Wang, Haoyu Guo, Wenzheng Chang, Yang
  Zhou, Haoyi Zhu, Junyi Chen, Chunhua Shen, Tong He
Categories: cs.CV cs.AI
\\
  We present WinT3R, a feed-forward reconstruction model capable of online
prediction of precise camera poses and high-quality point maps. Previous
methods suffer from a trade-off between reconstruction quality and real-time
performance. To address this, we first introduce a sliding window mechanism
that ensures sufficient information exchange among frames within the window,
thereby improving the quality of geometric predictions without large
computation. In addition, we leverage a compact representation of cameras and
maintain a global camera token pool, which enhances the reliability of camera
pose estimation without sacrificing efficiency. These designs enable WinT3R to
achieve state-of-the-art performance in terms of online reconstruction quality,
camera pose estimation, and reconstruction speed, as validated by extensive
experiments on diverse datasets. Code and model are publicly available at
https://github.com/LiZizun/WinT3R.
\\ ( https://arxiv.org/abs/2509.05296 ,  5360kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05297
Date: Fri, 5 Sep 2025 17:59:59 GMT   (10404kb)

Title: FlowSeek: Optical Flow Made Easier with Depth Foundation Models and
  Motion Bases
Authors: Matteo Poggi, Fabio Tosi
Categories: cs.CV
Comments: ICCV 2025 - Project Page: https://flowseek25.github.io/ - Code:
  https://github.com/mattpoggi/flowseek
\\
  We present FlowSeek, a novel framework for optical flow requiring minimal
hardware resources for training. FlowSeek marries the latest advances on the
design space of optical flow networks with cutting-edge single-image depth
foundation models and classical low-dimensional motion parametrization,
implementing a compact, yet accurate architecture. FlowSeek is trained on a
single consumer-grade GPU, a hardware budget about 8x lower compared to most
recent methods, and still achieves superior cross-dataset generalization on
Sintel Final and KITTI, with a relative improvement of 10 and 15% over the
previous state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow
datasets.
\\ ( https://arxiv.org/abs/2509.05297 ,  10404kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04719
Date: Fri, 5 Sep 2025 00:25:40 GMT   (6241kb)

Title: STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous
  GPUs
Authors: Han Liang, Jiahui Zhou, Zicheng Zhou, Xiaoxi Zhang and Xu Chen
Categories: cs.DC cs.CV
\\
  The escalating adoption of diffusion models for applications such as image
generation demands efficient parallel inference techniques to manage their
substantial computational cost. However, existing diffusion parallelism
inference schemes often underutilize resources in heterogeneous multi-GPU
environments, where varying hardware capabilities or background tasks cause
workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion
Inference (STADI), a novel framework to accelerate diffusion model inference in
such settings. At its core is a hybrid scheduler that orchestrates fine-grained
parallelism across both temporal and spatial dimensions. Temporally, STADI
introduces a novel computation-aware step allocator applied after warmup
phases, using a least-common-multiple-minimizing quantization technique to
reduce denoising steps on slower GPUs and execution synchronization. To further
minimize GPU idle periods, STADI executes an elastic patch parallelism
mechanism that allocates variably sized image patches to GPUs according to
their computational capability, ensuring balanced workload distribution through
a complementary spatial mechanism. Extensive experiments on both
load-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy,
demonstrating improved load balancing and mitigation of performance
bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion
inference framework, our method significantly reduces end-to-end inference
latency by up to 45% and significantly improves resource utilization on
heterogeneous GPUs.
\\ ( https://arxiv.org/abs/2509.04719 ,  6241kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04827
Date: Fri, 5 Sep 2025 05:58:16 GMT   (5222kb)

Title: VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing
  for Energy-Efficient LLM Serving
Authors: Jiahuan Yu (1), Aryan Taneja (1), Junfeng Lin (2), Minjia Zhang (1)
  ((1) University of Illinois Urbana-Champaign, (2) Tsinghua University)
Categories: cs.DC
\\
  Modern Large Language Model (LLM) serving systems increasingly support
interactive applications, like real-time chat assistants, code generation
tools, and agentic workflows. However, the soaring energy cost of LLM inference
presents a growing challenge for sustainable and cost-effective deployment.
This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM
serving, built from a control theory perspective. VoltanaLLM co-designs
frequency scaling and request routing in emerging prefill/decode disaggregated
architectures, leveraging their decoupled execution to enable fine-grained
phase-specific control. It consists of a feedback-driven frequency controller
that dynamically adapts GPU frequency for prefill and decode phases, and a
state-space router that explores routing decisions across frequency-scaled
instances to minimize energy under latency constraints. We implement VoltanaLLM
in SGLang and evaluate its performance over multiple state-of-the-art LLMs and
real-world datasets. The results demonstrate that VoltanaLLM achieves up to
36.3% energy savings while maintaining near-perfect SLO attainment rate, paving
the way for sustainable and intelligent LLM serving.
\\ ( https://arxiv.org/abs/2509.04827 ,  5222kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05216
Date: Fri, 5 Sep 2025 16:19:25 GMT   (6467kb)

Title: Toward Distributed 3D Gaussian Splatting for High-Resolution Isosurface
  Visualization
Authors: Mengjiao Han, Andres Sewell, Joseph Insley, Janet Knowles, Victor A.
  Mateevitsi, Michael E. Papka, Steve Petruzza, and Silvio Rizzi
Categories: cs.DC
Journal-ref: IEEE eScience 2025 Poster
\\
  We present a multi-GPU extension of the 3D Gaussian Splatting (3D-GS)
pipeline for scientific visualization. Building on previous work that
demonstrated high-fidelity isosurface reconstruction using Gaussian primitives,
we incorporate a multi-GPU training backend adapted from Grendel-GS to enable
scalable processing of large datasets. By distributing optimization across
GPUs, our method improves training throughput and supports high-resolution
reconstructions that exceed single-GPU capacity. In our experiments, the system
achieves a 5.6X speedup on the Kingsnake dataset (4M Gaussians) using four GPUs
compared to a single-GPU baseline, and successfully trains the Miranda dataset
(18M Gaussians) that is an infeasible task on a single A100 GPU. This work lays
the groundwork for integrating 3D-GS into HPC-based scientific workflows,
enabling real-time post hoc and in situ visualization of complex simulations.
\\ ( https://arxiv.org/abs/2509.05216 ,  6467kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05248
Date: Fri, 5 Sep 2025 17:00:55 GMT   (986kb)

Title: Dynamic reconfiguration for malleable applications using RMA
Authors: Iker Mart\'in-\'Alvarez, Jos\'e I. Aliaga and Maribel Castillo
Categories: cs.DC
Comments: Sumbitted in Workshop DynRes25. 12 pages, 6 Figures, 3 Algorithm, 1
  Listing
\\
  This paper investigates the novel one-sided communication methods based on
remote memory access (RMA) operations in MPI for dynamic resizing of malleable
applications, enabling data redistribution with minimal impact on application
execution. After their integration into the MaM library, these methods are
compared with traditional collective-based approaches. In addition, the
existing strategy Wait Drains is extended to support efficient background
reconfiguration. Results show comparable performance, though high
initialization costs currently limit their advantage.
\\ ( https://arxiv.org/abs/2509.05248 ,  986kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05258
Date: Fri, 5 Sep 2025 17:14:58 GMT   (132kb)

Title: Scaling Performance of Large Language Model Pretraining
Authors: Alexander Interrante-Grant, Carla Varela-Rosa, Suhaas Narayan, Chris
  Connelly, Albert Reuther
Categories: cs.DC cs.AI
\\
  Large language models (LLMs) show best-in-class performance across a wide
range of natural language processing applications. Training these models is an
extremely computationally expensive task; frontier Artificial Intelligence (AI)
research companies are investing billions of dollars into supercomputing
infrastructure to train progressively larger models on increasingly massive
datasets. Unfortunately, information about the scaling performance and training
considerations of these large training pipelines is scarce in public
literature. Working with large-scale datasets and models can be complex and
practical recommendations are scarce in the public literature for tuning
training performance when scaling up large language models. In this paper, we
aim to demystify the large language model pretraining pipeline somewhat - in
particular with respect to distributed training, managing large datasets across
hundreds of nodes, and scaling up data parallelism with an emphasis on fully
leveraging available GPU compute capacity.
\\ ( https://arxiv.org/abs/2509.05258 ,  132kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04537
Date: Thu, 4 Sep 2025 08:09:42 GMT   (7288kb)

Title: Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem
Authors: Ryosuke Takata, Atsushi Masumori, Takashi Ikegammi
Categories: cs.MA cs.AI cs.CY
\\
  We investigate the emergent social dynamics of Large Language Model (LLM)
agents in a spatially extended El Farol Bar problem, observing how they
autonomously navigate this classic social dilemma. As a result, the LLM agents
generated a spontaneous motivation to go to the bar and changed their decision
making by becoming a collective. We also observed that the LLM agents did not
solve the problem completely, but rather behaved more like humans. These
findings reveal a complex interplay between external incentives
(prompt-specified constraints such as the 60\% threshold) and internal
incentives (culturally-encoded social preferences derived from pre-training),
demonstrating that LLM agents naturally balance formal game-theoretic
rationality with social motivations that characterize human behavior. These
findings suggest that a new model of group decision making, which could not be
handled in the previous game-theoretic problem setting, can be realized by LLM
agents.
\\ ( https://arxiv.org/abs/2509.04537 ,  7288kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04993
Date: Fri, 5 Sep 2025 10:40:31 GMT   (1963kb)

Title: LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of
  Dual-Loop Edge-Terminal Collaboration
Authors: Zheyan Qu, Wenbo Wang, Zitong Yu, Boquan Sun, Yang Li, and Xing Zhang
Categories: cs.MA cs.AI
Comments: This paper has been accepted by IEEE Communications Magazine
\\
  The ubiquitous computing resources in 6G networks provide ideal environments
for the fusion of large language models (LLMs) and intelligent services through
the agent framework. With auxiliary modules and planning cores, LLM-enabled
agents can autonomously plan and take actions to deal with diverse environment
semantics and user intentions. However, the limited resources of individual
network devices significantly hinder the efficient operation of LLM-enabled
agents with complex tool calls, highlighting the urgent need for efficient
multi-level device collaborations. To this end, the framework and method of the
LLM-enabled multi-agent system with dual-loop terminal-edge collaborations are
proposed in 6G networks. Firstly, the outer loop consists of the iterative
collaborations between the global agent and multiple sub-agents deployed on
edge servers and terminals, where the planning capability is enhanced through
task decomposition and parallel sub-task distribution. Secondly, the inner loop
utilizes sub-agents with dedicated roles to circularly reason, execute, and
replan the sub-task, and the parallel tool calling generation with offloading
strategies is incorporated to improve efficiency. The improved task planning
capability and task execution efficiency are validated through the conducted
case study in 6G-supported urban safety governance. Finally, the open
challenges and future directions are thoroughly analyzed in 6G networks,
accelerating the advent of the 6G era.
\\ ( https://arxiv.org/abs/2509.04993 ,  1963kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2509.02718 (*cross-listing*)
Date: Tue, 2 Sep 2025 18:15:03 GMT   (375kb)

Title: Efficient Training-Free Online Routing for High-Volume Multi-LLM Serving
Authors: Fangzhou Wu, Sandeep Silwal
Categories: cs.DB cs.AI cs.LG
Comments: 31 pages
\\
  Increasing demand for Large Language Models (LLMs) services imposes
substantial deployment and computation costs on providers. LLM routing offers a
cost-efficient solution by directing queries to the optimal LLM based on model
and query features. However, existing works primarily focus on offline
scenarios and struggle to adapt to online settings with high query volume and
constrained token budgets. In this work, we introduce the first training-free
algorithm for online routing scenarios. Our algorithm leverages approximate
nearest neighbor search to efficiently estimate query features and performs a
one-time optimization over a small set of initial queries to learn a routing
strategy that guides future routing. We provide theoretical guarantees
demonstrating that our algorithm achieves a competitive ratio of $1 - o(1)$
under natural assumptions, which is further validated by extensive experiments
across 3 benchmark datasets and 8 baselines, showing an average improvement of
3.55$\times$ in overall performance, 1.85$\times$ in cost efficiency, and
nearly 4.25$\times$ in throughput.
\\ ( https://arxiv.org/abs/2509.02718 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04463 (*cross-listing*)
Date: Thu, 28 Aug 2025 16:46:03 GMT   (1399kb)

Title: Multiscale Graph Neural Network for Turbulent Flow-Thermal Prediction
  Around a Complex-Shaped Pin-Fin
Authors: Riddhiman Raut, Evan M. Mihalko, Amrita Basak
Categories: physics.flu-dyn cs.AI cs.LG cs.NA math.NA
\\
  This study presents the development of a domain-responsive edge-aware
multiscale Graph Neural Network for predicting steady, turbulent flow and
thermal behavior in a two-dimensional channel containing arbitrarily shaped
complex pin-fin geometries. The training dataset was constructed through an
automated framework that integrated geometry generation, meshing, and
flow-field solutions in ANSYS Fluent. The pin-fin geometry was parameterized
using piecewise cubic splines, producing 1,000 diverse configurations through
Latin Hypercube Sampling. Each simulation was converted into a graph structure,
where nodes carried a feature vector containing spatial coordinates, a
normalized streamwise position, one-hot boundary indicators, and a signed
distance to the nearest boundary such as wall. This graph structure served as
input to the newly developed Graph Neural Network, which was trained to predict
temperature, velocity magnitude, and pressure at each node using data from
ANSYS. The network predicted fields with outstanding accuracy, capturing
boundary layers, recirculation, and the stagnation region upstream of the
pin-fins while reducing wall time by 2-3 orders of magnitude. In conclusion,
the novel graph neural network offered a fast and reliable surrogate for
simulations in complex flow configurations.
\\ ( https://arxiv.org/abs/2509.04463 ,  1399kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04481 (*cross-listing*)
Date: Sun, 31 Aug 2025 01:45:56 GMT   (497kb)

Title: Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game
  Environments
Authors: Yi-Chun Chen and Arnav Jhala
Categories: cs.GR cs.AI cs.CL cs.MM
\\
  Recent advances in large language models(LLMs) enable compelling story
generation, but connecting narrative text to playable visual environments
remains an open challenge in procedural content generation(PCG). We present a
lightweight pipeline that transforms short narrative prompts into a sequence of
2D tile-based game scenes, reflecting the temporal structure of stories. Given
an LLM-generated narrative, our system identifies three key time frames,
extracts spatial predicates in the form of "Object-Relation-Object" triples,
and retrieves visual assets using affordance-aware semantic embeddings from the
GameTileNet dataset. A layered terrain is generated using Cellular Automata,
and objects are placed using spatial rules grounded in the predicate structure.
We evaluated our system in ten diverse stories, analyzing tile-object matching,
affordance-layer alignment, and spatial constraint satisfaction across frames.
This prototype offers a scalable approach to narrative-driven scene generation
and lays the foundation for future work on multi-frame continuity, symbolic
tracking, and multi-agent coordination in story-centered PCG.
\\ ( https://arxiv.org/abs/2509.04481 ,  497kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04506 (*cross-listing*)
Date: Tue, 2 Sep 2025 14:30:50 GMT   (2063kb)

Title: Memristor-Based Neural Network Accelerators for Space Applications:
  Enhancing Performance with Temporal Averaging and SIRENs
Authors: Zacharia A. Rudge, Dominik Dold, Moritz Fieback, Dario Izzo, Said
  Hamdioui
Categories: eess.SY cs.AI cs.AR cs.SY
Comments: 21 pages, IAA acta astronautica. arXiv admin note: text overlap with
  arXiv:2509.02369
\\
  Memristors are an emerging technology that enables artificial intelligence
(AI) accelerators with high energy efficiency and radiation robustness --
properties that are vital for the deployment of AI on-board spacecraft.
However, space applications require reliable and precise computations, while
memristive devices suffer from non-idealities, such as device variability,
conductance drifts, and device faults. Thus, porting neural networks (NNs) to
memristive devices often faces the challenge of severe performance degradation.
In this work, we show in simulations that memristor-based NNs achieve
competitive performance levels on on-board tasks, such as navigation \& control
and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers,
and periodic activation functions, we improve initial results from around
$0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming
close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our
results demonstrate the potential of memristors for on-board space
applications, and we are convinced that future technology and NN improvements
will further close the performance gap to fully unlock the benefits of
memristors.
\\ ( https://arxiv.org/abs/2509.04506 ,  2063kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04535 (*cross-listing*)
Date: Thu, 4 Sep 2025 06:55:38 GMT   (1055kb)

Title: In-Context Policy Adaptation via Cross-Domain Skill Diffusion
Authors: Minjong Yoo, Woo Kyung Kim, Honguk Woo
Categories: cs.RO cs.AI cs.LG
Comments: 9 pages
Journal-ref: Proceedings of the AAAI Conference on Artificial Intelligence,
  2025
\\
  In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.
\\ ( https://arxiv.org/abs/2509.04535 ,  1055kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04544 (*cross-listing*)
Date: Thu, 4 Sep 2025 11:42:43 GMT   (7566kb)

Title: i-Mask: An Intelligent Mask for Breath-Driven Activity Recognition
Authors: Ashutosh Kumar Sinha, Ayush Patel, Mitul Dudhat, Pritam Anand, and
  Rahul Mishra
Categories: cs.LG cs.AI
Comments: 18 Pages, 10 Figures
\\
  The patterns of inhalation and exhalation contain important physiological
signals that can be used to anticipate human behavior, health trends, and vital
parameters. Human activity recognition (HAR) is fundamentally connected to
these vital signs, providing deeper insights into well-being and enabling
real-time health monitoring. This work presents i-Mask, a novel HAR approach
that leverages exhaled breath patterns captured using a custom-developed mask
equipped with integrated sensors. Data collected from volunteers wearing the
mask undergoes noise filtering, time-series decomposition, and labeling to
train predictive models. Our experimental results validate the effectiveness of
the approach, achieving over 95\% accuracy and highlighting its potential in
healthcare and fitness applications.
\\ ( https://arxiv.org/abs/2509.04544 ,  7566kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04588 (*cross-listing*)
Date: Thu, 4 Sep 2025 18:09:17 GMT   (21755kb)

Title: Toward Faithfulness-guided Ensemble Interpretation of Neural Network
Authors: Siyu Zhang, Kenneth Mcmillan
Categories: cs.LG cs.AI
\\
  Interpretable and faithful explanations for specific neural inferences are
crucial for understanding and evaluating model behavior. Our work introduces
\textbf{F}aithfulness-guided \textbf{E}nsemble \textbf{I}nterpretation
(\textbf{FEI}), an innovative framework that enhances the breadth and
effectiveness of faithfulness, advancing interpretability by providing superior
visualization. Through an analysis of existing evaluation benchmarks,
\textbf{FEI} employs a smooth approximation to elevate quantitative
faithfulness scores. Diverse variations of \textbf{FEI} target enhanced
faithfulness in hidden layer encodings, expanding interpretability.
Additionally, we propose a novel qualitative metric that assesses hidden layer
faithfulness. In extensive experiments, \textbf{FEI} surpasses existing
methods, demonstrating substantial advances in qualitative visualization and
quantitative faithfulness scores. Our research establishes a comprehensive
framework for elevating faithfulness in neural network explanations,
emphasizing both breadth and precision
\\ ( https://arxiv.org/abs/2509.04588 ,  21755kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04601 (*cross-listing*)
Date: Thu, 4 Sep 2025 18:33:40 GMT   (5914kb)

Title: Quantum-Enhanced Multi-Task Learning with Learnable Weighting for
  Pharmacokinetic and Toxicity Prediction
Authors: Han Zhang, Fengji Ma, Jiamin Su, Xinyue Yang, Lei Wang, Wen-Cai Ye, Li
  Liu
Categories: cs.LG cs.AI
\\
  Prediction for ADMET (Absorption, Distribution, Metabolism, Excretion, and
Toxicity) plays a crucial role in drug discovery and development, accelerating
the screening and optimization of new drugs. Existing methods primarily rely on
single-task learning (STL), which often fails to fully exploit the
complementarities between tasks. Besides, it requires more computational
resources while training and inference of each task independently. To address
these issues, we propose a new unified Quantum-enhanced and task-Weighted
Multi-Task Learning (QW-MTL) framework, specifically designed for ADMET
classification tasks. Built upon the Chemprop-RDKit backbone, QW-MTL adopts
quantum chemical descriptors to enrich molecular representations with
additional information about the electronic structure and interactions.
Meanwhile, it introduces a novel exponential task weighting scheme that
combines dataset-scale priors with learnable parameters to achieve dynamic loss
balancing across tasks. To the best of our knowledge, this is the first work to
systematically conduct joint multi-task training across all 13 Therapeutics
Data Commons (TDC) classification benchmarks, using leaderboard-style data
splits to ensure a standardized and realistic evaluation setting. Extensive
experimental results show that QW-MTL significantly outperforms single-task
baselines on 12 out of 13 tasks, achieving high predictive performance with
minimal model complexity and fast inference, demonstrating the effectiveness
and efficiency of multi-task molecular learning enhanced by quantum-informed
features and adaptive task weighting.
\\ ( https://arxiv.org/abs/2509.04601 ,  5914kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04622 (*cross-listing*)
Date: Thu, 4 Sep 2025 19:11:10 GMT   (58kb)

Title: Measuring the Measures: Discriminative Capacity of Representational
  Similarity Metrics Across Model Families
Authors: Jialin Wu, Shreya Saha, Yiqing Bo, Meenakshi Khosla
Categories: cs.LG cs.AI cs.NE
\\
  Representational similarity metrics are fundamental tools in neuroscience and
AI, yet we lack systematic comparisons of their discriminative power across
model families. We introduce a quantitative framework to evaluate
representational similarity measures based on their ability to separate model
families-across architectures (CNNs, Vision Transformers, Swin Transformers,
ConvNeXt) and training regimes (supervised vs. self-supervised). Using three
complementary separability measures-dprime from signal detection theory,
silhouette coefficients and ROC-AUC, we systematically assess the
discriminative capacity of commonly used metrics including RSA, linear
predictivity, Procrustes, and soft matching. We show that separability
systematically increases as metrics impose more stringent alignment
constraints. Among mapping-based approaches, soft-matching achieves the highest
separability, followed by Procrustes alignment and linear predictivity.
Non-fitting methods such as RSA also yield strong separability across families.
These results provide the first systematic comparison of similarity metrics
through a separability lens, clarifying their relative sensitivity and guiding
metric choice for large-scale model and brain comparisons.
\\ ( https://arxiv.org/abs/2509.04622 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04628 (*cross-listing*)
Date: Thu, 4 Sep 2025 19:29:02 GMT   (866kb)

Title: Action Chunking with Transformers for Image-Based Spacecraft Guidance
  and Control
Authors: Alejandro Posadas-Nava, Andrea Scorsoglio, Luca Ghilardi, Roberto
  Furfaro, Richard Linares
Categories: cs.RO cs.AI
Comments: 12 pages, 6 figures, 2025 AAS/AIAA Astrodynamics Specialist
  Conference
Report-no: AAS 25-897
\\
  We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.
\\ ( https://arxiv.org/abs/2509.04628 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04632 (*cross-listing*)
Date: Thu, 4 Sep 2025 19:50:16 GMT   (1080kb)

Title: Schema Inference for Tabular Data Repositories Using Large Language
  Models
Authors: Zhenyu Wu, Jiaoyan Chen and Norman W. Paton
Categories: cs.DB cs.AI
\\
  Minimally curated tabular data often contain representational inconsistencies
across heterogeneous sources, and are accompanied by sparse metadata. Working
with such data is intimidating. While prior work has advanced dataset discovery
and exploration, schema inference remains difficult when metadata are limited.
We present SI-LLM (Schema Inference using Large Language Models), which infers
a concise conceptual schema for tabular data using only column headers and cell
values. The inferred schema comprises hierarchical entity types, attributes,
and inter-type relationships. In extensive evaluation on two datasets from web
tables and open data, SI-LLM achieves promising end-to-end results, as well as
better or comparable results to state-of-the-art methods at each step. All
source code, full prompts, and datasets of SI-LLM are available at
https://github.com/PierreWoL/SILLM.
\\ ( https://arxiv.org/abs/2509.04632 ,  1080kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04633 (*cross-listing*)
Date: Thu, 4 Sep 2025 19:51:00 GMT   (112kb)

Title: Scaling Environments for Organoid Intelligence with LLM-Automated Design
  and Plasticity-Based Evaluation
Authors: Brennen Hill
Categories: cs.NE cs.AI cs.LG q-bio.NC
MSC-class: 92B20, 68T05, 92C20, 93E35
ACM-class: I.2.6; J.3; I.6.8; D.2.2
\\
  As the complexity of artificial agents increases, the design of environments
that can effectively shape their behavior and capabilities has become a
critical research frontier. We propose a framework that extends this principle
to a novel class of agents: biological neural networks in the form of neural
organoids. This paper introduces three scalable, closed-loop virtual
environments designed to train organoid-based biological agents and probe the
underlying mechanisms of learning, such as long-term potentiation (LTP) and
long-term depression (LTD). We detail the design of three distinct task
environments with increasing complexity: (1) a conditional avoidance task, (2)
a one-dimensional predator-prey scenario, and (3) a replication of the classic
Pong game. For each environment, we formalize the state and action spaces, the
sensory encoding and motor decoding mechanisms, and the feedback protocols
based on predictable (reward) and unpredictable (punishment) stimulation.
Furthermore, we propose a novel meta-learning approach where a Large Language
Model (LLM) is used to automate the generation and optimization of experimental
protocols, scaling the process of environment and curriculum design. Finally,
we outline a multi-modal approach for evaluating learning by measuring synaptic
plasticity at electrophysiological, cellular, and molecular levels. This work
bridges the gap between computational neuroscience and agent-based AI, offering
a unique platform for studying embodiment, learning, and intelligence in a
controlled biological substrate.
\\ ( https://arxiv.org/abs/2509.04633 ,  112kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04653 (*cross-listing*)
Date: Thu, 4 Sep 2025 20:40:37 GMT   (39kb)

Title: Interpreting Transformer Architectures as Implicit Multinomial
  Regression
Authors: Jonas A. Actor and Anthony Gruber and Eric C. Cyr
Categories: cs.LG cs.AI cs.NA math.NA
\\
  Mechanistic interpretability aims to understand how internal components of
modern machine learning models, such as weights, activations, and layers, give
rise to the model's overall behavior. One particularly opaque mechanism is
attention: despite its central role in transformer models, its mathematical
underpinnings and relationship to concepts like feature polysemanticity,
superposition, and model performance remain poorly understood. This paper
establishes a novel connection between attention mechanisms and multinomial
regression. Specifically, we show that in a fixed multinomial regression
setting, optimizing over latent features yields optimal solutions that align
with the dynamics induced by attention blocks. In other words, the evolution of
representations through a transformer can be interpreted as a trajectory that
recovers the optimal features for classification.
\\ ( https://arxiv.org/abs/2509.04653 ,  39kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04682 (*cross-listing*)
Date: Thu, 4 Sep 2025 22:03:05 GMT   (13092kb)

Title: Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine
  Bioacoustic Monitoring
Authors: Nicholas R. Rasmussen, Rodrigue Rizk, Longwei Wang, KC Santosh
Categories: cs.SD cs.AI cs.CV cs.IR cs.LG eess.AS
Comments: Under review as an anonymous submission to IEEETAI - We are allowed
  an archive submission. Final formatting is yet to be determined
\\
  Underwater Passive Acoustic Monitoring (UPAM) provides rich spatiotemporal
data for long-term ecological analysis, but intrinsic noise and complex signal
dependencies hinder model stability and generalization. Multilayered windowing
has improved target sound localization, yet variability from shifting ambient
noise, diverse propagation effects, and mixed biological and anthropogenic
sources demands robust architectures and rigorous evaluation. We introduce
GetNetUPAM, a hierarchical nested cross-validation framework designed to
quantify model stability under ecologically realistic variability. Data are
partitioned into distinct site-year segments, preserving recording
heterogeneity and ensuring each validation fold reflects a unique environmental
subset, reducing overfitting to localized noise and sensor artifacts. Site-year
blocking enforces evaluation against genuine environmental diversity, while
standard cross-validation on random subsets measures generalization across
UPAM's full signal distribution, a dimension absent from current benchmarks.
Using GetNetUPAM as the evaluation backbone, we propose the Adaptive Resolution
Pooling and Attention Network (ARPA-N), a neural architecture for irregular
spectrogram dimensions. Adaptive pooling with spatial attention extends the
receptive field, capturing global context without excessive parameters. Under
GetNetUPAM, ARPA-N achieves a 14.4% gain in average precision over DenseNet
baselines and a log2-scale order-of-magnitude drop in variability across all
metrics, enabling consistent detection across site-year folds and advancing
scalable, accurate bioacoustic monitoring.
\\ ( https://arxiv.org/abs/2509.04682 ,  13092kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04712 (*cross-listing*)
Date: Thu, 4 Sep 2025 23:56:26 GMT   (2089kb)

Title: Bootstrapping Reinforcement Learning with Sub-optimal Policies for
  Autonomous Driving
Authors: Zhihao Zhang, Chengyang Peng, Ekim Yurtsever and Keith A. Redmill
Categories: cs.RO cs.AI cs.LG cs.SY eess.SY
\\
  Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.
\\ ( https://arxiv.org/abs/2509.04712 ,  2089kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04733 (*cross-listing*)
Date: Fri, 5 Sep 2025 01:07:12 GMT   (250kb)

Title: CoVeR: Conformal Calibration for Versatile and Reliable Autoregressive
  Next-Token Prediction
Authors: Yuzhu Chen and Yingjie Wang and Shunyu Liu and Yongcheng Jing and
  Dacheng Tao
Categories: cs.LG cs.AI
\\
  Autoregressive pre-trained models combined with decoding methods have
achieved impressive performance on complex reasoning tasks. While mainstream
decoding strategies such as beam search can generate plausible candidate sets,
they often lack provable coverage guarantees, and struggle to effectively
balance search efficiency with the need for versatile trajectories,
particularly those involving long-tail sequences that are essential in certain
real-world applications. To address these limitations, we propose
\textsc{CoVeR}, a novel model-free decoding strategy wihtin the conformal
prediction framework that simultaneously maintains a compact search space and
ensures high coverage probability over desirable trajectories. Theoretically,
we establish a PAC-style generalization bound, guaranteeing that \textsc{CoVeR}
asymptotically achieves a coverage rate of at least $1 - \alpha$ for any target
level $\alpha \in (0,1)$.
\\ ( https://arxiv.org/abs/2509.04733 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04734 (*cross-listing*)
Date: Fri, 5 Sep 2025 01:23:59 GMT   (1071kb)

Title: Beyond I-Con: Exploring New Dimension of Distance Measures in
  Representation Learning
Authors: Jasmine Shone, Shaden Alshammari, Mark Hamilton, Zhening Li, William
  Freeman
Categories: cs.LG cs.AI cs.CV
\\
  The Information Contrastive (I-Con) framework revealed that over 23
representation learning methods implicitly minimize KL divergence between data
and learned distributions that encode similarities between data points.
However, a KL-based loss may be misaligned with the true objective, and
properties of KL divergence such as asymmetry and unboundedness may create
optimization challenges. We present Beyond I-Con, a framework that enables
systematic discovery of novel loss functions by exploring alternative
statistical divergences and similarity kernels. Key findings: (1) on
unsupervised clustering of DINO-ViT embeddings, we achieve state-of-the-art
results by modifying the PMI algorithm to use total variation (TV) distance;
(2) on supervised contrastive learning, we outperform the standard approach by
using TV and a distance-based similarity kernel instead of KL and an angular
kernel; (3) on dimensionality reduction, we achieve superior qualitative
results and better performance on downstream tasks than SNE by replacing KL
with a bounded f-divergence. Our results highlight the importance of
considering divergence and similarity kernel choices in representation learning
optimization.
\\ ( https://arxiv.org/abs/2509.04734 ,  1071kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04752 (*cross-listing*)
Date: Fri, 5 Sep 2025 02:07:36 GMT   (1499kb)

Title: SePA: A Search-enhanced Predictive Agent for Personalized Health
  Coaching
Authors: Melik Ozolcer and Sang Won Bae
Categories: cs.HC cs.AI cs.LG
Comments: Accepted at IEEE-EMBS International Conference on Biomedical and
  Health Informatics (BHI'25). 7 pages, 5 figures, 3 tables
\\
  This paper introduces SePA (Search-enhanced Predictive AI Agent), a novel LLM
health coaching system that integrates personalized machine learning and
retrieval-augmented generation to deliver adaptive, evidence-based guidance.
SePA combines: (1) Individualized models predicting daily stress, soreness, and
injury risk from wearable sensor data (28 users, 1260 data points); and (2) A
retrieval module that grounds LLM-generated feedback in expert-vetted web
content to ensure contextual relevance and reliability. Our predictive models,
evaluated with rolling-origin cross-validation and group k-fold
cross-validation show that personalized models outperform generalized
baselines. In a pilot expert study (n=4), SePA's retrieval-based advice was
preferred over a non-retrieval baseline, yielding meaningful practical effect
(Cliff's $\delta$=0.3, p=0.05). We also quantify latency performance trade-offs
between response quality and speed, offering a transparent blueprint for
next-generation, trustworthy personal health informatics systems.
\\ ( https://arxiv.org/abs/2509.04752 ,  1499kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04781 (*cross-listing*)
Date: Fri, 5 Sep 2025 03:30:04 GMT   (156kb)

Title: The LLM Has Left The Chat: Evidence of Bail Preferences in Large
  Language Models
Authors: Danielle Ensign, Henry Sleight, Kyle Fish
Categories: cs.CY cs.AI cs.LG
\\
  When given the option, will LLMs choose to leave the conversation (bail)? We
investigate this question by giving models the option to bail out of
interactions using three different bail methods: a bail tool the model can
call, a bail string the model can output, and a bail prompt that asks the model
if it wants to leave. On continuations of real world data (Wildchat and
ShareGPT), all three of these bail methods find models will bail around
0.28-32\% of the time (depending on the model and bail method). However, we
find that bail rates can depend heavily on the model used for the transcript,
which means we may be overestimating real world bail rates by up to 4x. If we
also take into account false positives on bail prompt (22\%), we estimate real
world bail rates range from 0.06-7\%, depending on the model and bail method.
We use observations from our continuations of real world data to construct a
non-exhaustive taxonomy of bail cases, and use this taxonomy to construct
BailBench: a representative synthetic dataset of situations where some models
bail. We test many models on this dataset, and observe some bail behavior
occurring for most of them. Bail rates vary substantially between models, bail
methods, and prompt wordings. Finally, we study the relationship between
refusals and bails. We find: 1) 0-13\% of continuations of real world
conversations resulted in a bail without a corresponding refusal 2) Jailbreaks
tend to decrease refusal rates, but increase bail rates 3) Refusal abliteration
increases no-refuse bail rates, but only for some bail methods 4) Refusal rate
on BailBench does not appear to predict bail rate.
\\ ( https://arxiv.org/abs/2509.04781 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04782 (*cross-listing*)
Date: Fri, 5 Sep 2025 03:32:51 GMT   (605kb)

Title: VARMA-Enhanced Transformer for Time Series Forecasting
Authors: Jiajun Song, Xiaoou Liu
Categories: cs.LG cs.AI
Comments: The Pacific Rim International Conference on Artificial Intelligence -
  PRICAI2025
\\
  Transformer-based models have significantly advanced time series forecasting.
Recent work, like the Cross-Attention-only Time Series transformer (CATS),
shows that removing self-attention can make the model more accurate and
efficient. However, these streamlined architectures may overlook the
fine-grained, local temporal dependencies effectively captured by classical
statistical models like Vector AutoRegressive Moving Average model (VARMA). To
address this gap, we propose VARMAformer, a novel architecture that synergizes
the efficiency of a cross-attention-only framework with the principles of
classical time series analysis. Our model introduces two key innovations: (1) a
dedicated VARMA-inspired Feature Extractor (VFE) that explicitly models
autoregressive (AR) and moving-average (MA) patterns at the patch level, and
(2) a VARMA-Enhanced Attention (VE-atten) mechanism that employs a temporal
gate to make queries more context-aware. By fusing these classical insights
into a modern backbone, VARMAformer captures both global, long-range
dependencies and local, statistical structures. Through extensive experiments
on widely-used benchmark datasets, we demonstrate that our model consistently
outperforms existing state-of-the-art methods. Our work validates the
significant benefit of integrating classical statistical insights into modern
deep learning frameworks for time series forecasting.
\\ ( https://arxiv.org/abs/2509.04782 ,  605kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04785 (*cross-listing*)
Date: Fri, 5 Sep 2025 03:47:49 GMT   (952kb)

Title: Graph Unlearning: Efficient Node Removal in Graph Neural Networks
Authors: Faqian Guan and Tianqing Zhu and Zhoutian Wang and Wei Ren and Wanlei
  Zhou
Categories: cs.LG cs.AI
\\
  With increasing concerns about privacy attacks and potential sensitive
information leakage, researchers have actively explored methods to efficiently
remove sensitive training data and reduce privacy risks in graph neural network
(GNN) models. Node unlearning has emerged as a promising technique for
protecting the privacy of sensitive nodes by efficiently removing specific
training node information from GNN models. However, existing node unlearning
methods either impose restrictions on the GNN structure or do not effectively
utilize the graph topology for node unlearning. Some methods even compromise
the graph's topology, making it challenging to achieve a satisfactory
performance-complexity trade-off. To address these issues and achieve efficient
unlearning for training node removal in GNNs, we propose three novel node
unlearning methods: Class-based Label Replacement, Topology-guided Neighbor
Mean Posterior Probability, and Class-consistent Neighbor Node Filtering. Among
these methods, Topology-guided Neighbor Mean Posterior Probability and
Class-consistent Neighbor Node Filtering effectively leverage the topological
features of the graph, resulting in more effective node unlearning. To validate
the superiority of our proposed methods in node unlearning, we conducted
experiments on three benchmark datasets. The evaluation criteria included model
utility, unlearning utility, and unlearning efficiency. The experimental
results demonstrate the utility and efficiency of the proposed methods and
illustrate their superiority compared to state-of-the-art node unlearning
methods. Overall, the proposed methods efficiently remove sensitive training
nodes and protect the privacy information of sensitive nodes in GNNs. The
findings contribute to enhancing the privacy and security of GNN models and
provide valuable insights into the field of node unlearning.
\\ ( https://arxiv.org/abs/2509.04785 ,  952kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04805 (*cross-listing*)
Date: Fri, 5 Sep 2025 04:52:51 GMT   (649kb)

Title: AI-Driven Fronthaul Link Compression in Wireless Communication Systems:
  Review and Method Design
Authors: Keqin Zhang
Categories: eess.SP cs.AI cs.LG
\\
  Modern fronthaul links in wireless systems must transport high-dimensional
signals under stringent bandwidth and latency constraints, which makes
compression indispensable. Traditional strategies such as compressed sensing,
scalar quantization, and fixed-codec pipelines often rely on restrictive
priors, degrade sharply at high compression ratios, and are hard to tune across
channels and deployments. Recent progress in Artificial Intelligence (AI) has
brought end-to-end learned transforms, vector and hierarchical quantization,
and learned entropy models that better exploit the structure of Channel State
Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first
surveys AI-driven compression techniques and then provides a focused analysis
of two representative high-compression routes: CSI feedback with end-to-end
learning and Resource Block (RB) granularity precoding optimization combined
with compression. Building on these insights, we propose a fronthaul
compression strategy tailored to cell-free architectures. The design targets
high compression with controlled performance loss, supports RB-level rate
adaptation, and enables low-latency inference suitable for centralized
cooperative transmission in next-generation networks.
\\ ( https://arxiv.org/abs/2509.04805 ,  649kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04844 (*cross-listing*)
Date: Fri, 5 Sep 2025 06:52:03 GMT   (7760kb)

Title: REMOTE: A Unified Multimodal Relation Extraction Framework with
  Multilevel Optimal Transport and Mixture-of-Experts
Authors: Xinkui Lin, Yongxiu Xu, Minghao Tang, Shilong Zhang, Hongbo Xu, Hao
  Xu, Yubin Wang
Categories: cs.MM cs.AI cs.IR
Comments: ACM MM 2025
DOI: 10.1145/3746027.3754868
\\
  Multimodal relation extraction (MRE) is a crucial task in the fields of
Knowledge Graph and Multimedia, playing a pivotal role in multimodal knowledge
graph construction. However, existing methods are typically limited to
extracting a single type of relational triplet, which restricts their ability
to extract triplets beyond the specified types. Directly combining these
methods fails to capture dynamic cross-modal interactions and introduces
significant computational redundancy. Therefore, we propose a novel
\textit{unified multimodal Relation Extraction framework with Multilevel
Optimal Transport and mixture-of-Experts}, termed REMOTE, which can
simultaneously extract intra-modal and inter-modal relations between textual
entities and visual objects. To dynamically select optimal interaction features
for different types of relational triplets, we introduce mixture-of-experts
mechanism, ensuring the most relevant modality information is utilized.
Additionally, considering that the inherent property of multilayer sequential
encoding in existing encoders often leads to the loss of low-level information,
we adopt a multilevel optimal transport fusion module to preserve low-level
features while maintaining multilayer encoding, yielding more expressive
representations. Correspondingly, we also create a Unified Multimodal Relation
Extraction (UMRE) dataset to evaluate the effectiveness of our framework,
encompassing diverse cases where the head and tail entities can originate from
either text or image. Extensive experiments show that REMOTE effectively
extracts various types of relational triplets and achieves state-of-the-art
performanc on almost all metrics across two other public MRE datasets. We
release our resources at https://github.com/Nikol-coder/REMOTE.
\\ ( https://arxiv.org/abs/2509.04844 ,  7760kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04853 (*cross-listing*)
Date: Fri, 5 Sep 2025 07:07:18 GMT   (8265kb)

Title: A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving
  Based on Expert Routing
Authors: Chengkai Xu, Jiaqi Liu, Yicheng Guo, Peng Hang, Jian Sun
Categories: cs.RO cs.AI
Comments: https://perfectxu88.github.io/KDP-AD/
\\
  End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.
\\ ( https://arxiv.org/abs/2509.04853 ,  8265kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04855 (*cross-listing*)
Date: Fri, 5 Sep 2025 07:14:24 GMT   (17kb)

Title: The Paradox of Doom: Acknowledging Extinction Risk Reduces the Incentive
  to Prevent It
Authors: Jakub Growiec, Klaus Prettner
Categories: econ.GN cs.AI q-fin.EC
\\
  We investigate the salience of extinction risk as a source of impatience. Our
framework distinguishes between human extinction risk and individual mortality
risk while allowing for various degrees of intergenerational altruism.
Additionally, we consider the evolutionarily motivated "selfish gene"
perspective. We find that the risk of human extinction is an indispensable
component of the discount rate, whereas individual mortality risk can be hedged
against - partially or fully, depending on the setup - through human
reproduction. Overall, we show that in the face of extinction risk, people
become more impatient rather than more farsighted. Thus, the greater the threat
of extinction, the less incentive there is to invest in avoiding it. Our
framework can help explain why humanity consistently underinvests in mitigation
of catastrophic risks, ranging from climate change mitigation, via pandemic
prevention, to addressing the emerging risks of transformative artificial
intelligence.
\\ ( https://arxiv.org/abs/2509.04855 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04923 (*cross-listing*)
Date: Fri, 5 Sep 2025 08:41:24 GMT   (1947kb)

Title: Artificial intelligence for representing and characterizing quantum
  systems
Authors: Yuxuan Du, Yan Zhu, Yuan-Hang Zhang, Min-Hsiu Hsieh, Patrick
  Rebentrost, Weibo Gao, Ya-Dong Wu, Jens Eisert, Giulio Chiribella, Dacheng
  Tao, Barry C. Sanders
Categories: quant-ph cs.AI cs.LG
Comments: 32 pages. Comments are welcome
\\
  Efficient characterization of large-scale quantum systems, especially those
produced by quantum analog simulators and megaquop quantum computers, poses a
central challenge in quantum science due to the exponential scaling of the
Hilbert space with respect to system size. Recent advances in artificial
intelligence (AI), with its aptitude for high-dimensional pattern recognition
and function approximation, have emerged as a powerful tool to address this
challenge. A growing body of research has leveraged AI to represent and
characterize scalable quantum systems, spanning from theoretical foundations to
experimental realizations. Depending on how prior knowledge and learning
architectures are incorporated, the integration of AI into quantum system
characterization can be categorized into three synergistic paradigms: machine
learning, and, in particular, deep learning and language models. This review
discusses how each of these AI paradigms contributes to two core tasks in
quantum systems characterization: quantum property prediction and the
construction of surrogates for quantum states. These tasks underlie diverse
applications, from quantum certification and benchmarking to the enhancement of
quantum algorithms and the understanding of strongly correlated phases of
matter. Key challenges and open questions are also discussed, together with
future prospects at the interface of AI and quantum science.
\\ ( https://arxiv.org/abs/2509.04923 ,  1947kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04970 (*cross-listing*)
Date: Fri, 5 Sep 2025 09:52:08 GMT   (1843kb)

Title: DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and
  Interpretability in Manipulation
Authors: Tien Pham, Xinyun Chi, Khang Nguyen, Manfred Huber, Angelo Cangelosi
Categories: cs.RO cs.AI
\\
  Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input
\\ ( https://arxiv.org/abs/2509.04970 ,  1843kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04983 (*cross-listing*)
Date: Fri, 5 Sep 2025 10:19:32 GMT   (69kb)

Title: Exploring an implementation of quantum learning pipeline for support
  vector machines
Authors: Mario Bifulco, Luca Roversi
Categories: quant-ph cs.AI
\\
  This work presents a fully quantum approach to support vector machine (SVM)
learning by integrating gate-based quantum kernel methods with quantum
annealing-based optimization. We explore the construction of quantum kernels
using various feature maps and qubit configurations, evaluating their
suitability through Kernel-Target Alignment (KTA). The SVM dual problem is
reformulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem,
enabling its solution via quantum annealers. Our experiments demonstrate that a
high degree of alignment in the kernel and an appropriate regularization
parameter lead to competitive performance, with the best model achieving an
F1-score of 90%. These results highlight the feasibility of an end-to-end
quantum learning pipeline and the potential of hybrid quantum architectures in
quantum high-performance computing (QHPC) contexts.
\\ ( https://arxiv.org/abs/2509.04983 ,  69kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04991 (*cross-listing*)
Date: Fri, 5 Sep 2025 10:37:27 GMT   (6014kb)

Title: High-Resolution Global Land Surface Temperature Retrieval via a Coupled
  Mechanism-Machine Learning Framework
Authors: Tian Xie, Huanfeng Shen, Menghui Jiang, Juan-Carlos Jim\'enez-Mu\~noz,
  Jos\'e A. Sobrino, Huifang Li, Chao Zeng
Categories: physics.ao-ph cs.AI cs.LG
\\
  Land surface temperature (LST) is vital for land-atmosphere interactions and
climate processes. Accurate LST retrieval remains challenging under
heterogeneous land cover and extreme atmospheric conditions. Traditional split
window (SW) algorithms show biases in humid environments; purely machine
learning (ML) methods lack interpretability and generalize poorly with limited
data. We propose a coupled mechanism model-ML (MM-ML) framework integrating
physical constraints with data-driven learning for robust LST retrieval. Our
approach fuses radiative transfer modeling with data components, uses MODTRAN
simulations with global atmospheric profiles, and employs physics-constrained
optimization. Validation against 4,450 observations from 29 global sites shows
MM-ML achieves MAE=1.84K, RMSE=2.55K, and R-squared=0.966, outperforming
conventional methods. Under extreme conditions, MM-ML reduces errors by over
50%. Sensitivity analysis indicates LST estimates are most sensitive to sensor
radiance, then water vapor, and less to emissivity, with MM-ML showing superior
stability. These results demonstrate the effectiveness of our coupled modeling
strategy for retrieving geophysical parameters. The MM-ML framework combines
physical interpretability with nonlinear modeling capacity, enabling reliable
LST retrieval in complex environments and supporting climate monitoring and
ecosystem studies.
\\ ( https://arxiv.org/abs/2509.04991 ,  6014kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04999 (*cross-listing*)
Date: Fri, 5 Sep 2025 10:47:49 GMT   (405kb)

Title: Adversarial Augmentation and Active Sampling for Robust Cyber Anomaly
  Detection
Authors: Sidahmed Benabderrahmane, Talal Rahwan
Categories: cs.CR cs.AI cs.CY cs.LG
\\
  Advanced Persistent Threats (APTs) present a considerable challenge to
cybersecurity due to their stealthy, long-duration nature. Traditional
supervised learning methods typically require large amounts of labeled data,
which is often scarce in real-world scenarios. This paper introduces a novel
approach that combines AutoEncoders for anomaly detection with active learning
to iteratively enhance APT detection. By selectively querying an oracle for
labels on uncertain or ambiguous samples, our method reduces labeling costs
while improving detection accuracy, enabling the model to effectively learn
with minimal data and reduce reliance on extensive manual labeling. We present
a comprehensive formulation of the Attention Adversarial Dual AutoEncoder-based
anomaly detection framework and demonstrate how the active learning loop
progressively enhances the model's performance. The framework is evaluated on
real-world, imbalanced provenance trace data from the DARPA Transparent
Computing program, where APT-like attacks account for just 0.004\% of the data.
The datasets, which cover multiple operating systems including Android, Linux,
BSD, and Windows, are tested in two attack scenarios. The results show
substantial improvements in detection rates during active learning,
outperforming existing methods.
\\ ( https://arxiv.org/abs/2509.04999 ,  405kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05031 (*cross-listing*)
Date: Fri, 5 Sep 2025 11:42:03 GMT   (5144kb)

Title: Pointing-Guided Target Estimation via Transformer-Based Attention
Authors: Luca M\"uller, Hassan Ali, Philipp Allgeuer, Luk\'a\v{s}
  Gajdo\v{s}ech, Stefan Wermter
Categories: cs.RO cs.AI cs.CV
Comments: Accepted at the 34th International Conference on Artificial Neural
  Networks (ICANN) 2025,12 pages,4 figures,1 table; work was co-funded by
  Horizon Europe project TERAIS under Grant agreement number 101079338
ACM-class: I.2.9; I.2.10; I.2.6
\\
  Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.
\\ ( https://arxiv.org/abs/2509.05031 ,  5144kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05112 (*cross-listing*)
Date: Fri, 5 Sep 2025 13:50:26 GMT   (1299kb)

Title: GenAI-based test case generation and execution in SDV platform
Authors: Denesa Zyberaj, Lukasz Mazur, Nenad Petrovic, Pankhuri Verma, Pascal
  Hirmer, Dirk Slama, Xiangwei Cheng, Alois Knoll
Categories: cs.SE cs.AI
\\
  This paper introduces a GenAI-driven approach for automated test case
generation, leveraging Large Language Models and Vision-Language Models to
translate natural language requirements and system diagrams into structured
Gherkin test cases. The methodology integrates Vehicle Signal Specification
modeling to standardize vehicle signal definitions, improve compatibility
across automotive subsystems, and streamline integration with third-party
testing tools. Generated test cases are executed within the digital.auto
playground, an open and vendor-neutral environment designed to facilitate rapid
validation of software-defined vehicle functionalities. We evaluate our
approach using the Child Presence Detection System use case, demonstrating
substantial reductions in manual test specification effort and rapid execution
of generated tests. Despite significant automation, the generation of test
cases and test scripts still requires manual intervention due to current
limitations in the GenAI pipeline and constraints of the digital.auto platform.
\\ ( https://arxiv.org/abs/2509.05112 ,  1299kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05145 (*cross-listing*)
Date: Fri, 5 Sep 2025 14:38:02 GMT   (2248kb)

Title: Exploring Situated Stabilities of a Rhythm Generation System through
  Variational Cross-Examination
Authors: B{\l}a\.zej Kotowski, Nicholas Evans, Behzad Haki, Frederic Font,
  Sergi Jord\`a
Categories: cs.HC cs.AI cs.SD eess.AS
Comments: AI Music Creativity 2025
\\
  This paper investigates GrooveTransformer, a real-time rhythm generation
system, through the postphenomenological framework of Variational
Cross-Examination (VCE). By reflecting on its deployment across three distinct
artistic contexts, we identify three stabilities: an autonomous drum
accompaniment generator, a rhythmic control voltage sequencer in Eurorack
format, and a rhythm driver for a harmonic accompaniment system. The
versatility of its applications was not an explicit goal from the outset of the
project. Thus, we ask: how did this multistability emerge? Through VCE, we
identify three key contributors to its emergence: the affordances of system
invariants, the interdisciplinary collaboration, and the situated nature of its
development. We conclude by reflecting on the viability of VCE as a descriptive
and analytical method for Digital Musical Instrument (DMI) design, emphasizing
its value in uncovering how technologies mediate, co-shape, and are co-shaped
by users and contexts.
\\ ( https://arxiv.org/abs/2509.05145 ,  2248kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05190 (*cross-listing*)
Date: Fri, 5 Sep 2025 15:42:15 GMT   (522kb)

Title: Accuracy-Constrained CNN Pruning for Efficient and Reliable EEG-Based
  Seizure Detection
Authors: Mounvik K and N Harshit
Categories: cs.LG cs.AI
\\
  Deep learning models, especially convolutional neural networks (CNNs), have
shown considerable promise for biomedical signals such as EEG-based seizure
detection. However, these models come with challenges, primarily due to their
size and compute requirements in environments where real-time detection or
limited resources are available. In this study, we present a lightweight
one-dimensional CNN model with structured pruning to improve efficiency and
reliability. The model was trained with mild early stopping to address possible
overfitting, achieving an accuracy of 92.78% and a macro-F1 score of 0.8686.
Structured pruning of the baseline CNN involved removing 50% of the
convolutional kernels based on their importance to model predictions.
Surprisingly, after pruning the weights and memory by 50%, the new network was
still able to maintain predictive capabilities, while modestly increasing
precision to 92.87% and improving the macro-F1 score to 0.8707. Overall, we
present a convincing case that structured pruning removes redundancy, improves
generalization, and, in combination with mild early stopping, achieves a
promising way forward to improve seizure detection efficiency and reliability,
which is clear motivation for resource-limited settings.
\\ ( https://arxiv.org/abs/2509.05190 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05197 (*cross-listing*)
Date: Fri, 5 Sep 2025 15:57:16 GMT   (1685kb)

Title: AI Agents for Web Testing: A Case Study in the Wild
Authors: Naimeng Ye, Xiao Yu, Ruize Xu, Tianyi Peng, Zhou Yu
Categories: cs.SE cs.AI cs.HC
\\
  Automated web testing plays a critical role in ensuring high-quality user
experiences and delivering business value. Traditional approaches primarily
focus on code coverage and load testing, but often fall short of capturing
complex user behaviors, leaving many usability issues undetected. The emergence
of large language models (LLM) and AI agents opens new possibilities for web
testing by enabling human-like interaction with websites and a general
awareness of common usability problems. In this work, we present WebProber, a
prototype AI agent-based web testing framework. Given a URL, WebProber
autonomously explores the website, simulating real user interactions,
identifying bugs and usability issues, and producing a human-readable report.
We evaluate WebProber through a case study of 120 academic personal websites,
where it uncovered 29 usability issues--many of which were missed by
traditional tools. Our findings highlight agent-based testing as a promising
direction while outlining directions for developing next-generation,
user-centered testing frameworks.
\\ ( https://arxiv.org/abs/2509.05197 ,  1685kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05207 (*cross-listing*)
Date: Fri, 5 Sep 2025 16:10:20 GMT   (1623kb)

Title: RapidGNN: Energy and Communication-Efficient Distributed Training on
  Large-Scale Graph Neural Networks
Authors: Arefin Niam, Tevfik Kosar and M S Q Zulkar Nine
Categories: cs.LG cs.AI
Comments: arXiv admin note: text overlap with arXiv:2505.10806
\\
  Graph Neural Networks (GNNs) have become popular across a diverse set of
tasks in exploring structural relationships between entities. However, due to
the highly connected structure of the datasets, distributed training of GNNs on
large-scale graphs poses significant challenges. Traditional sampling-based
approaches mitigate the computational loads, yet the communication overhead
remains a challenge. This paper presents RapidGNN, a distributed GNN training
framework with deterministic sampling-based scheduling to enable efficient
cache construction and prefetching of remote features. Evaluation on benchmark
graph datasets demonstrates RapidGNN's effectiveness across different scales
and topologies. RapidGNN improves end-to-end training throughput by 2.46x to
3.00x on average over baseline methods across the benchmark datasets, while
cutting remote feature fetches by over 9.70x to 15.39x. RapidGNN further
demonstrates near-linear scalability with an increasing number of computing
units efficiently. Furthermore, it achieves increased energy efficiency over
the baseline methods for both CPU and GPU by 44% and 32%, respectively.
\\ ( https://arxiv.org/abs/2509.05207 ,  1623kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05238 (*cross-listing*)
Date: Fri, 5 Sep 2025 16:54:26 GMT   (527kb)

Title: Uncertain but Useful: Leveraging CNN Variability into Data Augmentation
Authors: In\'es Gonzalez-Pepe, Vinuyan Sivakolunthu, Yohan Chatelain and
  Tristan Glatard
Categories: math.NA cs.AI cs.NA
\\
  Deep learning (DL) is rapidly advancing neuroimaging by achieving
state-of-the-art performance with reduced computation times. Yet the numerical
stability of DL models -- particularly during training -- remains
underexplored. While inference with DL is relatively stable, training
introduces additional variability primarily through iterative stochastic
optimization. We investigate this training-time variability using FastSurfer, a
CNN-based whole-brain segmentation pipeline. Controlled perturbations are
introduced via floating point perturbations and random seeds. We find that: (i)
FastSurfer exhibits higher variability compared to that of a traditional
neuroimaging pipeline, suggesting that DL inherits and is particularly
susceptible to sources of instability present in its predecessors; (ii)
ensembles generated with perturbations achieve performance similar to an
unperturbed baseline; and (iii) variability effectively produces ensembles of
numerical model families that can be repurposed for downstream applications. As
a proof of concept, we demonstrate that numerical ensembles can be used as a
data augmentation strategy for brain age regression. These findings position
training-time variability not only as a reproducibility concern but also as a
resource that can be harnessed to improve robustness and enable new
applications in neuroimaging.
\\ ( https://arxiv.org/abs/2509.05238 ,  527kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05256 (*cross-listing*)
Date: Fri, 5 Sep 2025 17:14:29 GMT   (2104kb)

Title: Recomposer: Event-roll-guided generative audio editing
Authors: Daniel P. W. Ellis, Eduardo Fonseca, Ron J. Weiss, Kevin Wilson, Scott
  Wisdom, Hakan Erdogan, John R. Hershey, Aren Jansen, R. Channing Moore, Manoj
  Plakal
Categories: cs.SD cs.AI cs.LG eess.AS
Comments: 5 pages, 5 figures
\\
  Editing complex real-world sound scenes is difficult because individual sound
sources overlap in time. Generative models can fill-in missing or corrupted
details based on their strong prior understanding of the data domain. We
present a system for editing individual sound events within complex scenes able
to delete, insert, and enhance individual sound events based on textual edit
descriptions (e.g., ``enhance Door'') and a graphical representation of the
event timing derived from an ``event roll'' transcription. We present an
encoder-decoder transformer working on SoundStream representations, trained on
synthetic (input, desired output) audio example pairs formed by adding isolated
sound events to dense, real-world backgrounds. Evaluation reveals the
importance of each part of the edit descriptions -- action, class, timing. Our
work demonstrates ``recomposition'' is an important and practical application.
\\ ( https://arxiv.org/abs/2509.05256 ,  2104kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05276 (*cross-listing*)
Date: Fri, 5 Sep 2025 17:34:00 GMT   (2870kb)

Title: SpikingBrain Technical Report: Spiking Brain-inspired Large Models
Authors: Yuqi Pan, Yupeng Feng, Jinghao Zhuang, Siyu Ding, Zehao Liu, Bohan
  Sun, Yuhong Chou, Han Xu, Xuerui Qiu, Anlin Deng, Anjie Hu, Peng Zhou, Man
  Yao, Jibin Wu, Jian Yang, Guoliang Sun, Bo Xu and Guoqi Li
Categories: cs.LG cs.AI cs.CL
\\
  Mainstream Transformer-based large language models face major efficiency
bottlenecks: training computation scales quadratically with sequence length,
and inference memory grows linearly, limiting long-context processing. Building
large models on non-NVIDIA platforms also poses challenges for stable and
efficient training. To address this, we introduce SpikingBrain, a family of
brain-inspired models designed for efficient long-context training and
inference. SpikingBrain leverages the MetaX GPU cluster and focuses on three
aspects: (1) Model Architecture: linear and hybrid-linear attention
architectures with adaptive spiking neurons; (2) Algorithmic Optimizations: an
efficient, conversion-based training pipeline and a dedicated spike coding
framework; (3) System Engineering: customized training frameworks, operator
libraries, and parallelism strategies tailored to MetaX hardware.
  Using these techniques, we develop two models: SpikingBrain-7B, a linear LLM,
and SpikingBrain-76B, a hybrid-linear MoE LLM. These models demonstrate the
feasibility of large-scale LLM development on non-NVIDIA platforms.
SpikingBrain achieves performance comparable to open-source Transformer
baselines while using only about 150B tokens for continual pre-training. Our
models significantly improve long-sequence training efficiency and deliver
inference with (partially) constant memory and event-driven spiking behavior.
For example, SpikingBrain-7B attains over 100x speedup in Time to First Token
for 4M-token sequences. Training remains stable for weeks on hundreds of MetaX
C550 GPUs, with the 7B model reaching a Model FLOPs Utilization of 23.4
percent. The proposed spiking scheme achieves 69.15 percent sparsity, enabling
low-power operation. Overall, this work demonstrates the potential of
brain-inspired mechanisms to drive the next generation of efficient and
scalable large model design.
\\ ( https://arxiv.org/abs/2509.05276 ,  2870kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03083 (*cross-listing*)
Date: Tue, 3 Jun 2025 17:04:22 GMT   (242kb)
Date (revised v2): Thu, 5 Jun 2025 22:39:07 GMT   (242kb)
Date (revised v3): Tue, 2 Sep 2025 17:15:59 GMT   (267kb)

Title: Labelling Data with Unknown References
Authors: Adrian de Wynter
Categories: cs.DS cs.AI cs.CL
Comments: Extended version with LLM-based results/analysis
\\
  An evaluator is trustworthy when there exists some agreed-upon way to measure
its performance as a labeller. The two ways to establish trustworthiness are
either by testing it, or by assuming the evaluator `knows' somehow the way to
label the corpus. However, if labelled references (e.g., a development set) are
unavailable, neither of these approaches work: the former requires the data,
and the latter is an assumption, not evidence. To address this, we introduce an
algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator
without any existing references. Our algorithm works by successively posing
challenges to said evaluator. We show that this is sufficient to establish
trustworthiness w.h.p., in such a way that when the evaluator actually knows
the way to label the corpus, the No-Data Algorithm accepts its output; and,
conversely, flags untrustworthy evaluators when these are unable to prove it.
We present formal proofs of correctness, empirical tests, and applications to
LLMs-as-judges on low-resource languages.
\\ ( https://arxiv.org/abs/2506.03083 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04667 (*cross-listing*)
Date: Thu, 4 Sep 2025 21:30:25 GMT   (156kb)

Title: DarkStream: real-time speech anonymization with low latency
Authors: Waris Quamer, Ricardo Gutierrez-Osuna
Categories: eess.AS cs.CL cs.LG
Comments: Accepted for presentation at ASRU 2025
\\
  We propose DarkStream, a streaming speech synthesis model for real-time
speaker anonymization. To improve content encoding under strict latency
constraints, DarkStream combines a causal waveform encoder, a short lookahead
buffer, and transformer-based contextual layers. To further reduce inference
time, the model generates waveforms directly via a neural vocoder, thus
removing intermediate mel-spectrogram conversions. Finally, DarkStream
anonymizes speaker identity by injecting a GAN-generated pseudo-speaker
embedding into linguistic features from the content encoder. Evaluations show
our model achieves strong anonymization, yielding close to 50% speaker
verification EER (near-chance performance) on the lazy-informed attack
scenario, while maintaining acceptable linguistic intelligibility (WER within
9%). By balancing low-latency, robust privacy, and minimal intelligibility
degradation, DarkStream provides a practical solution for privacy-preserving
real-time speech communication.
\\ ( https://arxiv.org/abs/2509.04667 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04744 (*cross-listing*)
Date: Fri, 5 Sep 2025 01:54:50 GMT   (6198kb)

Title: WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning
Authors: Gagan Mundada, Yash Vishe, Amit Namburi, Xin Xu, Zachary Novack,
  Julian McAuley, Junda Wu
Categories: cs.SD cs.CL eess.AS
\\
  Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated
impressive capabilities across various vision-language tasks. However, their
reasoning abilities in the multimodal symbolic music domain remain largely
unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic
music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to
interpret real-world music scores and answer complex musicological queries.
Each instance in WildScore is sourced from genuine musical compositions and
accompanied by authentic user-generated questions and discussions, capturing
the intricacies of practical music analysis. To facilitate systematic
evaluation, we propose a systematic taxonomy, comprising both high-level and
fine-grained musicological ontologies. Furthermore, we frame complex music
reasoning as multiple-choice question answering, enabling controlled and
scalable assessment of MLLMs' symbolic music understanding. Empirical
benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns
in their visual-symbolic reasoning, uncovering both promising directions and
persistent challenges for MLLMs in symbolic music reasoning and analysis. We
release the dataset and code.
\\ ( https://arxiv.org/abs/2509.04744 ,  6198kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04810 (*cross-listing*)
Date: Fri, 5 Sep 2025 05:17:14 GMT   (463kb)

Title: Code Review Without Borders: Evaluating Synthetic vs. Real Data for
  Review Recommendation
Authors: Yogev Cohen, Dudi Ohayon, Romy Somkin, Yehudit Aperstein, Alexander
  Apartsin
Categories: cs.SE cs.CL cs.LG
Comments: 4 pages, 1 figure
\\
  Automating the decision of whether a code change requires manual review is
vital for maintaining software quality in modern development workflows.
However, the emergence of new programming languages and frameworks creates a
critical bottleneck: while large volumes of unlabelled code are readily
available, there is an insufficient amount of labelled data to train supervised
models for review classification. We address this challenge by leveraging Large
Language Models (LLMs) to translate code changes from well-resourced languages
into equivalent changes in underrepresented or emerging languages, generating
synthetic training data where labelled examples are scarce. We assume that
although LLMs have learned the syntax and semantics of new languages from
available unlabelled code, they have yet to fully grasp which code changes are
considered significant or review-worthy within these emerging ecosystems. To
overcome this, we use LLMs to generate synthetic change examples and train
supervised classifiers on them. We systematically compare the performance of
these classifiers against models trained on real labelled data. Our experiments
across multiple GitHub repositories and language pairs demonstrate that
LLM-generated synthetic data can effectively bootstrap review recommendation
systems, narrowing the performance gap even in low-resource settings. This
approach provides a scalable pathway to extend automated code review
capabilities to rapidly evolving technology stacks, even in the absence of
annotated data.
\\ ( https://arxiv.org/abs/2509.04810 ,  463kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04823 (*cross-listing*)
Date: Fri, 5 Sep 2025 05:50:00 GMT   (18606kb)

Title: Evaluating Cognitive-Behavioral Fixation via Multimodal User Viewing
  Patterns on Social Media
Authors: Yujie Wang, Yunwei Zhao, Jing Yang, Han Han, Shiguang Shan, Jie Zhang
Categories: cs.SI cs.CL
\\
  Digital social media platforms frequently contribute to cognitive-behavioral
fixation, a phenomenon in which users exhibit sustained and repetitive
engagement with narrow content domains. While cognitive-behavioral fixation has
been extensively studied in psychology, methods for computationally detecting
and evaluating such fixation remain underexplored. To address this gap, we
propose a novel framework for assessing cognitive-behavioral fixation by
analyzing users' multimodal social media engagement patterns. Specifically, we
introduce a multimodal topic extraction module and a cognitive-behavioral
fixation quantification module that collaboratively enable adaptive,
hierarchical, and interpretable assessment of user behavior. Experiments on
existing benchmarks and a newly curated multimodal dataset demonstrate the
effectiveness of our approach, laying the groundwork for scalable computational
analysis of cognitive fixation. All code in this project is publicly available
for research purposes at
https://github.com/Liskie/cognitive-fixation-evaluation.
\\ ( https://arxiv.org/abs/2509.04823 ,  18606kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05293 (*cross-listing*)
Date: Fri, 5 Sep 2025 17:58:45 GMT   (353kb)

Title: Non-Termination Proving: 100 Million LoC and Beyond
Authors: Julien Vanegue, Jules Villard, Peter O'Hearn and Azalea Raad
Categories: cs.PL cs.CL cs.SE
Comments: 14 pages, 4 figures
ACM-class: D.3; F.3
\\
  We report on our tool, Pulse Infinite, that uses proof techniques to show
non-termination (divergence) in large programs. Pulse Infinite works
compositionally and under-approximately: the former supports scale, and the
latter ensures soundness for proving divergence. Prior work focused on small
benchmarks in the tens or hundreds of lines of code (LoC), and scale limits
their practicality: a single company may have tens of millions, or even
hundreds of millions of LoC or more. We report on applying Pulse Infinite to
over a hundred million lines of open-source and proprietary software written in
C, C++, and Hack, identifying over 30 previously unknown issues, establishing a
new state of the art for detecting divergence in real-world codebases.
\\ ( https://arxiv.org/abs/2509.05293 ,  353kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04677 (*cross-listing*)
Date: Thu, 4 Sep 2025 21:41:59 GMT   (1965kb)

Title: Inferring the Graph Structure of Images for Graph Neural Networks
Authors: Mayur S Gowda, John Shi, Augusto Santos, Jos\'e M. F. Moura
Categories: eess.IV cs.CV cs.LG eess.SP
\\
  Image datasets such as MNIST are a key benchmark for testing Graph Neural
Network (GNN) architectures. The images are traditionally represented as a grid
graph with each node representing a pixel and edges connecting neighboring
pixels (vertically and horizontally). The graph signal is the values
(intensities) of each pixel in the image. The graphs are commonly used as input
to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph
CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the
images. In this work, we improve the accuracy of downstream graph neural
network tasks by finding alternative graphs to the grid graph and superpixel
methods to represent the dataset images, following the approach in [5, 6]. We
find row correlation, column correlation, and product graphs for each image in
MNIST and Fashion-MNIST using correlations between the pixel values building on
the method in [5, 6]. Experiments show that using these different graph
representations and features as input into downstream GNN models improves the
accuracy over using the traditional grid graph and superpixel methods in the
literature.
\\ ( https://arxiv.org/abs/2509.04677 ,  1965kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04819 (*cross-listing*)
Date: Fri, 5 Sep 2025 05:40:55 GMT   (47135kb)

Title: AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive
  Representations
Authors: Shuhan Ding, Jingjing Fu, Yu Gu, Naiteek Sangani, Mu Wei, Paul Vozila,
  Nan Liu, Jiang Bian, Hoifung Poon
Categories: eess.IV cs.CV
\\
  Medical image synthesis has become an essential strategy for augmenting
datasets and improving model generalization in data-scarce clinical settings.
However, fine-grained and controllable synthesis remains difficult due to
limited high-quality annotations and domain shifts across datasets. Existing
methods, often designed for natural images or well-defined tumors, struggle to
generalize to chest radiographs, where disease patterns are morphologically
diverse and tightly intertwined with anatomical structures. To address these
challenges, we propose AURAD, a controllable radiology synthesis framework that
jointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike
prior approaches that rely on randomly sampled masks-limiting diversity,
controllability, and clinical relevance-our method learns to generate masks
that capture multi-pathology coexistence and anatomical-pathological
consistency. It follows a progressive pipeline: pseudo masks are first
generated from clinical prompts conditioned on anatomical structures, and then
used to guide image synthesis. We also leverage pretrained expert medical
models to filter outputs and ensure clinical plausibility. Beyond visual
realism, the synthesized masks also serve as labels for downstream tasks such
as detection and segmentation, bridging the gap between generative modeling and
real-world clinical applications. Extensive experiments and blinded radiologist
evaluations demonstrate the effectiveness and generalizability of our method
across tasks and datasets. In particular, 78% of our synthesized images are
classified as authentic by board-certified radiologists, and over 40% of
predicted segmentation overlays are rated as clinically useful. All code,
pre-trained models, and the synthesized dataset will be released upon
publication.
\\ ( https://arxiv.org/abs/2509.04819 ,  47135kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04849 (*cross-listing*)
Date: Fri, 5 Sep 2025 06:58:53 GMT   (807kb)

Title: Histogram Driven Amplitude Embedding for Qubit Efficient Quantum Image
  Compression
Authors: Sahil Tomar, Sandeep Kumar
Categories: quant-ph cs.CV cs.ET cs.IT math.IT
Comments: 7 pages
\\
  This work introduces a compact and hardware efficient method for compressing
color images using near term quantum devices. The approach segments the image
into fixed size blocks called bixels, and computes the total intensity within
each block. A global histogram with B bins is then constructed from these block
intensities, and the normalized square roots of the bin counts are encoded as
amplitudes into an n qubit quantum state. Amplitude embedding is performed
using PennyLane and executed on real IBM Quantum hardware. The resulting state
is measured to reconstruct the histogram, enabling approximate recovery of
block intensities and full image reassembly. The method maintains a constant
qubit requirement based solely on the number of histogram bins, independent of
the resolution of the image. By adjusting B, users can control the trade off
between fidelity and resource usage. Empirical results demonstrate high quality
reconstructions using as few as 5 to 7 qubits, significantly outperforming
conventional pixel level encodings in terms of qubit efficiency and validating
the practical application of the method for current NISQ era quantum systems.
\\ ( https://arxiv.org/abs/2509.04849 ,  807kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04870 (*cross-listing*)
Date: Fri, 5 Sep 2025 07:32:42 GMT   (8013kb)

Title: Multi-modal Uncertainty Robust Tree Cover Segmentation For
  High-Resolution Remote Sensing Images
Authors: Yuanyuan Gui, Wei Li, Yinjian Wang, Xiang-Gen Xia, Mauro Marty,
  Christian Ginzler, Zuyuan Wang
Categories: eess.IV cs.CV
\\
  Recent advances in semantic segmentation of multi-modal remote sensing images
have significantly improved the accuracy of tree cover mapping, supporting
applications in urban planning, forest monitoring, and ecological assessment.
Integrating data from multiple modalities-such as optical imagery, light
detection and ranging (LiDAR), and synthetic aperture radar (SAR)-has shown
superior performance over single-modality methods. However, these data are
often acquired days or even months apart, during which various changes may
occur, such as vegetation disturbances (e.g., logging, and wildfires) and
variations in imaging quality. Such temporal misalignments introduce
cross-modal uncertainty, especially in high-resolution imagery, which can
severely degrade segmentation accuracy. To address this challenge, we propose
MURTreeFormer, a novel multi-modal segmentation framework that mitigates and
leverages aleatoric uncertainty for robust tree cover mapping. MURTreeFormer
treats one modality as primary and others as auxiliary, explicitly modeling
patch-level uncertainty in the auxiliary modalities via a probabilistic latent
representation. Uncertain patches are identified and reconstructed from the
primary modality's distribution through a VAE-based resampling mechanism,
producing enhanced auxiliary features for fusion. In the decoder, a gradient
magnitude attention (GMA) module and a lightweight refinement head (RH) are
further integrated to guide attention toward tree-like structures and to
preserve fine-grained spatial details. Extensive experiments on multi-modal
datasets from Shanghai and Zurich demonstrate that MURTreeFormer significantly
improves segmentation performance and effectively reduces the impact of
temporally induced aleatoric uncertainty.
\\ ( https://arxiv.org/abs/2509.04870 ,  8013kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04948 (*cross-listing*)
Date: Fri, 5 Sep 2025 09:14:59 GMT   (6800kb)

Title: Towards an Accurate and Effective Robot Vision (The Problem of
  Topological Localization for Mobile Robots)
Authors: Emanuela Boros
Categories: cs.RO cs.CV
Comments: Master's thesis
\\
  Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.
\\ ( https://arxiv.org/abs/2509.04948 ,  6800kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05154 (*cross-listing*)
Date: Fri, 5 Sep 2025 14:48:19 GMT   (11928kb)

Title: VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced
  Medical Image Segmentation
Authors: Julia Dietlmeier, Oluwabukola Grace Adegboro, Vayangi Ganepola,
  Claudia Mazo and Noel E. O'Connor
Categories: eess.IV cs.CV
Comments: Medical Imaging with Deep Learning (MIDL 2025) short paper
\\
  Vision-language models and their adaptations to image segmentation tasks
present enormous potential for producing highly accurate and interpretable
results. However, implementations based on CLIP and BiomedCLIP are still
lagging behind more sophisticated architectures such as CRIS. In this work,
instead of focusing on text prompt engineering as is the norm, we attempt to
narrow this gap by showing how to ensemble vision-language segmentation models
(VLSMs) with a low-complexity CNN. By doing so, we achieve a significant Dice
score improvement of 6.3% on the BKAI polyp dataset using the ensembled
BiomedCLIPSeg, while other datasets exhibit gains ranging from 1% to 6%.
Furthermore, we provide initial results on additional four radiology and
non-radiology datasets. We conclude that ensembling works differently across
these datasets (from outperforming to underperforming the CRIS model),
indicating a topic for future investigation by the community. The code is
available at https://github.com/juliadietlmeier/VLSM-Ensemble.
\\ ( https://arxiv.org/abs/2509.05154 ,  11928kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05201 (*cross-listing*)
Date: Fri, 5 Sep 2025 16:03:57 GMT   (5177kb)

Title: Robust Model Predictive Control Design for Autonomous Vehicles with
  Perception-based Observers
Authors: Nariman Niknejad, Gokul S. Sankar, Bahare Kiumarsi, Hamidreza Modares
Categories: cs.RO cs.CV cs.LG cs.SY eess.SY
\\
  This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.
\\ ( https://arxiv.org/abs/2509.05201 ,  5177kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05285 (*cross-listing*)
Date: Thu, 4 Sep 2025 15:01:01 GMT   (52506kb)

Title: Improved 3D Scene Stylization via Text-Guided Generative Image Editing
  with Region-Based Control
Authors: Haruo Fujiwara, Yusuke Mukuta, Tatsuya Harada
Categories: cs.GR cs.CV
\\
  Recent advances in text-driven 3D scene editing and stylization, which
leverage the powerful capabilities of 2D generative models, have demonstrated
promising outcomes. However, challenges remain in ensuring high-quality
stylization and view consistency simultaneously. Moreover, applying style
consistently to different regions or objects in the scene with semantic
correspondence is a challenging task. To address these limitations, we
introduce techniques that enhance the quality of 3D stylization while
maintaining view consistency and providing optional region-controlled style
transfer. Our method achieves stylization by re-training an initial 3D
representation using stylized multi-view 2D images of the source views.
Therefore, ensuring both style consistency and view consistency of stylized
multi-view images is crucial. We achieve this by extending the style-aligned
depth-conditioned view generation framework, replacing the fully shared
attention mechanism with a single reference-based attention-sharing mechanism,
which effectively aligns style across different viewpoints. Additionally,
inspired by recent 3D inpainting methods, we utilize a grid of multiple depth
maps as a single-image reference to further strengthen view consistency among
stylized images. Finally, we propose Multi-Region Importance-Weighted Sliced
Wasserstein Distance Loss, allowing styles to be applied to distinct image
regions using segmentation masks from off-the-shelf models. We demonstrate that
this optional feature enhances the faithfulness of style transfer and enables
the mixing of different styles across distinct regions of the scene.
Experimental evaluations, both qualitative and quantitative, demonstrate that
our pipeline effectively improves the results of text-driven 3D stylization.
\\ ( https://arxiv.org/abs/2509.05285 ,  52506kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05213 (*cross-listing*)
Date: Fri, 5 Sep 2025 16:15:22 GMT   (170kb)

Title: An Efficient Subspace Algorithm for Federated Learning on Heterogeneous
  Data
Authors: Jiaojiao Zhang, Yuqi Xu, Kun Yuan
Categories: cs.LG cs.DC
\\
  This work addresses the key challenges of applying federated learning to
large-scale deep neural networks, particularly the issue of client drift due to
data heterogeneity across clients and the high costs of communication,
computation, and memory. We propose FedSub, an efficient subspace algorithm for
federated learning on heterogeneous data. Specifically, FedSub utilizes
subspace projection to guarantee local updates of each client within
low-dimensional subspaces, thereby reducing communication, computation, and
memory costs. Additionally, it incorporates low-dimensional dual variables to
mitigate client drift. We provide convergence analysis that reveals the impact
of key factors such as step size and subspace projection matrices on
convergence. Experimental results demonstrate its efficiency.
\\ ( https://arxiv.org/abs/2509.05213 ,  170kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04815 (*cross-listing*)
Date: Fri, 5 Sep 2025 05:28:52 GMT   (5027kb)

Title: An Arbitration Control for an Ensemble of Diversified DQN variants in
  Continual Reinforcement Learning
Authors: Wonseo Jang, Dongjae Kim
Categories: cs.LG cs.MA
Comments: 8 pages, 8 figures
\\
  Deep reinforcement learning (RL) models, despite their efficiency in learning
an optimal policy in static environments, easily loses previously learned
knowledge (i.e., catastrophic forgetting). It leads RL models to poor
performance in continual reinforcement learning (CRL) scenarios. To address
this, we present an arbitration control mechanism over an ensemble of RL
agents. It is motivated by and closely aligned with how humans make decisions
in a CRL context using an arbitration control of multiple RL agents in parallel
as observed in the prefrontal cortex. We integrated two key ideas into our
model: (1) an ensemble of RLs (i.e., DQN variants) explicitly trained to have
diverse value functions and (2) an arbitration control that prioritizes agents
with higher reliability (i.e., less error) in recent trials. We propose a
framework for CRL, an Arbitration Control for an Ensemble of Diversified DQN
variants (ACED-DQN). We demonstrate significant performance improvements in
both static and continual environments, supported by empirical evidence showing
the effectiveness of arbitration control over diversified DQNs during training.
In this work, we introduced a framework that enables RL agents to continuously
learn, with inspiration from the human brain.
\\ ( https://arxiv.org/abs/2509.04815 ,  5027kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05182 (*cross-listing*)
Date: Fri, 5 Sep 2025 15:30:36 GMT   (411kb)

Title: Collective decision-making dynamics in hypernetworks
Authors: Angela Fontan and Silun Zhang
Categories: math.OC cs.MA cs.SY eess.SY
Comments: 8 pages, 2 figures
\\
  This work describes a collective decision-making dynamical process in a
multiagent system under the assumption of cooperative higher-order interactions
within the community, modeled as a hypernetwork. The nonlinear interconnected
system is characterized by saturated nonlinearities that describe how agents
transmit their opinion state to their neighbors in the hypernetwork, and by a
bifurcation parameter representing the community's social effort. We show that
the presence of higher-order interactions leads to the unfolding of a pitchfork
bifurcation, introducing an interval for the social effort parameter in which
the system exhibits bistability. With equilibrium points representing
collective decisions, this implies that, depending on the initial conditions,
the community will either remain in a deadlock state (with the origin as the
equilibrium point) or reach a nontrivial decision. A numerical example is given
to illustrate the results.
\\ ( https://arxiv.org/abs/2509.05182 ,  411kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2403.05265
replaced with revised version Fri, 5 Sep 2025 03:50:30 GMT   (3499kb)

Title: MMoE: Robust Spoiler Detection with Multi-modal Information and
  Domain-aware Mixture-of-Experts
Authors: Zinan Zeng, Sen Ye, Zijian Cai, Heng Wang, Yuhan Liu, Haokai Zhang,
  Minnan Luo
Categories: cs.AI
\\ ( https://arxiv.org/abs/2403.05265 ,  3499kb)
------------------------------------------------------------------------------
\\
arXiv:2408.05748
replaced with revised version Fri, 5 Sep 2025 05:30:31 GMT   (70kb)

Title: Low-Dimensional Federated Knowledge Graph Embedding via Knowledge
  Distillation
Authors: Xiaoxiong Zhang, Zhiwei Zeng, Xin Zhou, Zhiqi Shen
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2408.05748 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2408.09600
replaced with revised version Fri, 5 Sep 2025 04:54:29 GMT   (1233kb)

Title: Antidote: Post-fine-tuning Safety Alignment for Large Language Models
  against Harmful Fine-tuning
Authors: Tiansheng Huang, Gautam Bhattacharya, Pratik Joshi, Josh Kimball, Ling
  Liu
Categories: cs.AI cs.CR
Comments: Rejected by AAAI25-AIA. Accepted by ICML25. Authors are thankful to
  the anonymous reviewers from both AAAI25-AIA and ICML25
\\ ( https://arxiv.org/abs/2408.09600 ,  1233kb)
------------------------------------------------------------------------------
\\
arXiv:2410.23903
replaced with revised version Fri, 5 Sep 2025 15:41:39 GMT   (609kb)

Title: Neural Network Verification with PyRAT
Authors: Augustin Lemesle, Julien Lehmann and Tristan Le Gall
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2410.23903 ,  609kb)
------------------------------------------------------------------------------
\\
arXiv:2412.13501
replaced with revised version Thu, 4 Sep 2025 20:25:41 GMT   (55kb)

Title: GUI Agents: A Survey
Authors: Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zhengmian Hu,
  Hanjia Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie
  Chen, Viet Dac Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Mehrab
  Tanjim, Nesreen K. Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav
  Kveton, Thien Huu Nguyen, Trung Bui, Tianyi Zhou, Ryan A. Rossi, Franck
  Dernoncourt
Categories: cs.AI cs.HC
Comments: Accepted to Findings of ACL 2025
\\ ( https://arxiv.org/abs/2412.13501 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15937
replaced with revised version Fri, 5 Sep 2025 05:26:23 GMT   (1853kb)

Title: Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical
  Deployment
Authors: Gaole Dai, Shiqi Jiang, Ting Cao, Yuanchun Li, Yuqing Yang, Rui Tan,
  Mo Li, Lili Qiu
Categories: cs.AI
Comments: add baselines, add source code link
\\ ( https://arxiv.org/abs/2503.15937 ,  1853kb)
------------------------------------------------------------------------------
\\
arXiv:2504.01733
replaced with revised version Fri, 5 Sep 2025 15:24:27 GMT   (80kb)

Title: Epistemic Skills: Reasoning about Knowledge and Oblivion
Authors: Xiaolong Liang and Y\`i N. W\'ang
Categories: cs.AI cs.CC cs.LO
\\ ( https://arxiv.org/abs/2504.01733 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:2505.06020
replaced with revised version Fri, 5 Sep 2025 16:04:23 GMT   (11072kb)

Title: ArtRAG: Retrieval-Augmented Generation with Structured Context for
  Visual Art Understanding
Authors: Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika
  Kackovic, Nachoem Wijnberg, Marcel Worring
Categories: cs.AI cs.CV
\\ ( https://arxiv.org/abs/2505.06020 ,  11072kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07173
replaced with revised version Fri, 5 Sep 2025 09:25:57 GMT   (358kb)

Title: Translating Federated Learning Algorithms in Python into CSP Processes
  Using ChatGPT
Authors: Miroslav Popovic, Marko Popovic, Miodrag Djukic, Ilija Basicevic
Categories: cs.AI
Comments: 6 pages, 4 tables; Published by IEEE Xplore
DOI: 10.1109/MIPRO65660.2025.11131995
\\ ( https://arxiv.org/abs/2506.07173 ,  358kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14387
replaced with revised version Fri, 5 Sep 2025 11:46:29 GMT   (6666kb)

Title: Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning
Authors: William F. Shen, Xinchi Qiu, Nicola Cancedda, Nicholas D. Lane
Categories: cs.AI
\\ ( https://arxiv.org/abs/2506.14387 ,  6666kb)
------------------------------------------------------------------------------
\\
arXiv:2507.00008
replaced with revised version Fri, 5 Sep 2025 17:21:02 GMT   (1359kb)

Title: DiMo-GUI: Advancing Test-time Scaling in GUI Grounding via
  Modality-Aware Visual Reasoning
Authors: Hang Wu, Hongkai Chen, Yujun Cai, Chang Liu, Qingwen Ye, Ming-Hsuan
  Yang, Yiwei Wang
Categories: cs.AI cs.CV cs.HC
Comments: EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2507.00008 ,  1359kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05528
replaced with revised version Fri, 5 Sep 2025 17:52:53 GMT   (27017kb)

Title: Conversational Education at Scale: A Multi-LLM Agent Workflow for
  Procedural Learning and Pedagogic Quality Assessment
Authors: Jiahuan Pei, Fanghua Ye, Xin Sun, Wentao Deng, Koen Hindriks, Junxiao
  Wang
Categories: cs.AI cs.CL
Comments: 14 pages, accepted by EMNLP 2025
\\ ( https://arxiv.org/abs/2507.05528 ,  27017kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20541
replaced with revised version Fri, 5 Sep 2025 08:42:04 GMT   (1118kb)

Title: MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic
  Design
Authors: Zishang Qiu, Xinan Chen, Long Chen and Ruibin Bai
Categories: cs.AI
\\ ( https://arxiv.org/abs/2507.20541 ,  1118kb)
------------------------------------------------------------------------------
\\
arXiv:2508.11987
replaced with revised version Fri, 5 Sep 2025 09:15:55 GMT   (6484kb)

Title: FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction
Authors: Zhiyuan Zeng, Jiashuo Liu, Siyuan Chen, Tianci He, Yali Liao, Yixiao
  Tian, Jinpeng Wang, Zaiyuan Wang, Yang Yang, Lingyue Yin, Mingren Yin,
  Zhenwei Zhu, Tianle Cai, Zehui Chen, Jiecao Chen, Yantao Du, Xiang Gao,
  Jiacheng Guo, Liang Hu, Jianpeng Jiao, Xiangsheng Li, Jingkai Liu, Shuang Ni,
  Zhoufutu Wen, Ge Zhang, Kaiyuan Zhang, Xin Zhou, Jose Blanchet, Xipeng Qiu,
  Mengdi Wang, Wenhao Huang
Categories: cs.AI cs.LG
Comments: Technical report, 51 pages. Update the results
\\ ( https://arxiv.org/abs/2508.11987 ,  6484kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13676
replaced with revised version Fri, 5 Sep 2025 04:33:05 GMT   (3000kb)

Title: MHSNet:An MoE-based Hierarchical Semantic Representation Network for
  Accurate Duplicate Resume Detection with Large Language Model
Authors: Yu Li and Zulong Chen and Wenjian Xu and Hong Wen and Yipeng Yu and
  Man Lung Yiu and Yuyu Yin
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.13676 ,  3000kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16172
replaced with revised version Fri, 5 Sep 2025 08:26:57 GMT   (13033kb)

Title: Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent
  with Preference Chain
Authors: Kai Hu, Parfait Atchade-Adelomou, Carlo Adornetto, Adrian
  Mora-Carrero, Luis Alonso-Pastor, Ariel Noyman, Yubo Liu, Kent Larson
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.16172 ,  13033kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20368
replaced with revised version Fri, 5 Sep 2025 03:51:29 GMT   (248kb)

Title: AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal
  Multi-Objective Reinforcement Learning
Authors: Lang Mei, Zhihan Yang, Chong Chen
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.20368 ,  248kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01920
replaced with revised version Fri, 5 Sep 2025 04:49:52 GMT   (129kb)

Title: Dynamic Speculative Agent Planning
Authors: Yilin Guan, Wenyue Hua, Qingfeng Lan, Sun Fei, Dujian Ding, Devang
  Acharya, Chi Wang, William Yang Wang
Categories: cs.AI cs.LG cs.MA
Comments: 19 pages, 11 figures
\\ ( https://arxiv.org/abs/2509.01920 ,  129kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02544
replaced with revised version Fri, 5 Sep 2025 14:59:27 GMT   (16321kb)

Title: UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn
  Reinforcement Learning
Authors: Haoming Wang, Haoyang Zou, Huatong Song, Jiazhan Feng, Junjie Fang,
  Junting Lu, Longxiang Liu, Qinyu Luo, Shihao Liang, Shijue Huang, Wanjun
  Zhong, Yining Ye, Yujia Qin, Yuwen Xiong, Yuxin Song, Zhiyong Wu, Aoyan Li,
  Bo Li, Chen Dun, Chong Liu, Daoguang Zan, Fuxing Leng, Hanbin Wang, Hao Yu,
  Haobin Chen, Hongyi Guo, Jing Su, Jingjia Huang, Kai Shen, Kaiyu Shi, Lin
  Yan, Peiyao Zhao, Pengfei Liu, Qinghao Ye, Renjie Zheng, Shulin Xin, Wayne
  Xin Zhao, Wen Heng, Wenhao Huang, Wenqian Wang, Xiaobo Qin, Yi Lin, Youbin
  Wu, Zehui Chen, Zihao Wang, Baoquan Zhong, Xinchun Zhang, Xujing Li, Yuanfan
  Li, Zhongkai Zhao, Chengquan Jiang, Faming Wu, Haotian Zhou, Jinlin Pang, Li
  Han, Qi Liu, Qianli Ma, Siyao Liu, Songhua Cai, Wenqi Fu, Xin Liu, Yaohui
  Wang, Zhi Zhang, Bo Zhou, Guoliang Li, Jiajun Shi, Jiale Yang, et al. (45
  additional authors not shown)
Categories: cs.AI cs.CL cs.CV cs.HC
\\ ( https://arxiv.org/abs/2509.02544 ,  16321kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03728
replaced with revised version Fri, 5 Sep 2025 02:25:11 GMT   (88kb)

Title: PersonaTeaming: Exploring How Introducing Personas Can Improve Automated
  AI Red-Teaming
Authors: Wesley Hanwen Deng, Sunnie S. Y. Kim, Akshita Jha, Ken Holstein,
  Motahhare Eslami, Lauren Wilcox, Leon A Gatys
Categories: cs.AI cs.HC
\\ ( https://arxiv.org/abs/2509.03728 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03730
replaced with revised version Fri, 5 Sep 2025 01:39:01 GMT   (2477kb)

Title: The Personality Illusion: Revealing Dissociation Between Self-Reports &
  Behavior in LLMs
Authors: Pengrui Han, Rafal Kocielnik, Peiyang Song, Ramit Debnath, Dean Mobbs,
  Anima Anandkumar, R. Michael Alvarez
Categories: cs.AI cs.CL cs.CY cs.LG stat.ML
Comments: We make public all code and source data at
  https://github.com/psychology-of-AI/Personality-Illusion for full
  reproducibility
\\ ( https://arxiv.org/abs/2509.03730 ,  2477kb)
------------------------------------------------------------------------------
\\
arXiv:2302.01626
replaced with revised version Fri, 5 Sep 2025 03:17:09 GMT   (125kb)

Title: Modeling Sequential Sentence Relation to Improve Cross-lingual Dense
  Retrieval
Authors: Shunyu Zhang, Yaobo Liang, Ming Gong, Daxin Jiang, Nan Duan
Categories: cs.CL cs.IR
Comments: Published at ICLR 2023
\\ ( https://arxiv.org/abs/2302.01626 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2401.14295
replaced with revised version Fri, 5 Sep 2025 11:39:31 GMT   (2297kb)

Title: Demystifying Chains, Trees, and Graphs of Thoughts
Authors: Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger,
  Guangyuan Piao, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz
  Kwa\'sniewski, J\"urgen M\"uller, Lukas Gianinazzi, Ales Kubicek, Hubert
  Niewiadomski, Aidan O'Mahony, Onur Mutlu, Torsten Hoefler
Categories: cs.CL cs.AI cs.LG
Journal-ref: IEEE Transactions on Pattern Analysis and Machine Intelligence
  (2025)
DOI: 10.1109/TPAMI.2025.3598182
\\ ( https://arxiv.org/abs/2401.14295 ,  2297kb)
------------------------------------------------------------------------------
\\
arXiv:2402.12226
replaced with revised version Fri, 5 Sep 2025 07:56:50 GMT   (2849kb)

Title: AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling
Authors: Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng
  Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui,
  Tianxiang Sun, Yugang Jiang, Xipeng Qiu
Categories: cs.CL cs.AI cs.CV cs.LG
Comments: 28 pages, 16 figures, under review, work in progress
\\ ( https://arxiv.org/abs/2402.12226 ,  2849kb)
------------------------------------------------------------------------------
\\
arXiv:2407.18416
replaced with revised version Fri, 5 Sep 2025 16:33:46 GMT   (2760kb)

Title: PersonaGym: Evaluating Persona Agents and LLMs
Authors: Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin
  Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak
  Murahari
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP Findings 2025
\\ ( https://arxiv.org/abs/2407.18416 ,  2760kb)
------------------------------------------------------------------------------
\\
arXiv:2407.19835
replaced with revised version Thu, 4 Sep 2025 19:48:48 GMT   (43kb)

Title: ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to
  English Translation
Authors: Mohammed Khalil, Mohammed Sabry
Categories: cs.CL cs.AI
Comments: ArabicNLP 2025
\\ ( https://arxiv.org/abs/2407.19835 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2408.02544
replaced with revised version Fri, 5 Sep 2025 09:21:10 GMT   (7217kb)

Title: Caution for the Environment: Multimodal LLM Agents are Susceptible to
  Environmental Distractions
Authors: Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng
  Zhang, Hai Zhao
Categories: cs.CL
Comments: ACL 2025
\\ ( https://arxiv.org/abs/2408.02544 ,  7217kb)
------------------------------------------------------------------------------
\\
arXiv:2408.13518
replaced with revised version Fri, 5 Sep 2025 07:59:59 GMT   (3750kb)

Title: Selective Preference Optimization via Token-Level Reward Function
  Estimation
Authors: Kailai Yang, Zhiwei Liu, Qianqian Xie, Jimin Huang, Erxue Min, Sophia
  Ananiadou
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by the EMNLP 2025 main conference
\\ ( https://arxiv.org/abs/2408.13518 ,  3750kb)
------------------------------------------------------------------------------
\\
arXiv:2409.12929
replaced with revised version Fri, 5 Sep 2025 04:45:51 GMT   (1306kb)

Title: LogicPro: Improving Complex Logical Reasoning via Program-Guided
  Learning
Authors: Jin Jiang, Yuchen Yan, Yang Liu, Jianing Wang, Shuai Peng, Xunliang
  Cai, Yixin Cao, Mengdi Zhang, Liangcai Gao
Categories: cs.CL
Comments: 19 pages, ACL 2025 (Volume 1 Long Papers), pages 26200-26218
Journal-ref: Proceedings of the 63rd Annual Meeting of the Association for
  Computational Linguistics (Volume 1 Long Papers), pages 26200-26218, Vienna,
  Austria, July 2025. Association for Computational Linguistics
DOI: 10.18653/v1/2025.acl-long.1270
\\ ( https://arxiv.org/abs/2409.12929 ,  1306kb)
------------------------------------------------------------------------------
\\
arXiv:2411.19858
replaced with revised version Thu, 4 Sep 2025 18:25:45 GMT   (2323kb)

Title: What fifty-one years of Linguistics and Artificial Intelligence research
  tell us about their correlation: A scientometric analysis
Authors: Mohammed Q. Shormani, Yehia A. AlSohbani
Categories: cs.CL
Comments: 26 pages, 15 figures
MSC-class: cs-CL
ACM-class: F.2.2; I.2.7
\\ ( https://arxiv.org/abs/2411.19858 ,  2323kb)
------------------------------------------------------------------------------
\\
arXiv:2501.08613
replaced with revised version Fri, 5 Sep 2025 06:35:41 GMT   (467kb)

Title: Assessing the Sensitivity and Alignment of FOL Closeness Metrics
Authors: Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi
Categories: cs.CL
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2501.08613 ,  467kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18724
replaced with revised version Thu, 4 Sep 2025 19:36:17 GMT   (2184kb)

Title: Large Language Models with Temporal Reasoning for Longitudinal Clinical
  Summarization and Prediction
Authors: Maya Kruse, Shiyue Hu, Nicholas Derby, Yifu Wu, Samantha Stonbraker,
  Bingsheng Yao, Dakuo Wang, Elizabeth Goldberg, Yanjun Gao
Categories: cs.CL
\\ ( https://arxiv.org/abs/2501.18724 ,  2184kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16487
replaced with revised version Fri, 5 Sep 2025 03:08:05 GMT   (68kb)

Title: All That Glitters is Not Novel: Plagiarism in AI Generated Research
Authors: Tarun Gupta, Danish Pruthi
Categories: cs.CL
Comments: Accepted to ACL 2025 (main) conference
\\ ( https://arxiv.org/abs/2502.16487 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2503.21934
replaced with revised version Thu, 4 Sep 2025 19:36:32 GMT   (433kb)

Title: Proof or Bluff? Evaluating LLMs on 2025 USA Math Olympiad
Authors: Ivo Petrov, Jasper Dekoninck, Lyuben Baltadzhiev, Maria Drencheva,
  Kristian Minchev, Mislav Balunovi\'c, Nikola Jovanovi\'c, Martin Vechev
Categories: cs.CL
\\ ( https://arxiv.org/abs/2503.21934 ,  433kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03352
replaced with revised version Fri, 5 Sep 2025 11:18:16 GMT   (3960kb)

Title: StereoDetect: Detecting Stereotypes and Anti-stereotypes the Correct Way
  Using Social Psychological Underpinnings
Authors: Kaustubh Shivshankar Shejole, Pushpak Bhattacharyya
Categories: cs.CL cs.CY cs.HC
\\ ( https://arxiv.org/abs/2504.03352 ,  3960kb)
------------------------------------------------------------------------------
\\
arXiv:2504.06460
replaced with revised version Fri, 5 Sep 2025 17:44:05 GMT   (352kb)

Title: Can LLMs Simulate Personas with Reversed Performance? A Benchmark for
  Counterfactual Instruction Following
Authors: Sai Adith Senthil Kumar, Hao Yan, Saipavan Perepa, Murong Yue, Ziyu
  Yao
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.06460 ,  352kb)
------------------------------------------------------------------------------
\\
arXiv:2504.12882
replaced with revised version Fri, 5 Sep 2025 14:38:08 GMT   (973kb)

Title: ViClaim: A Multilingual Multilabel Dataset for Automatic Claim Detection
  in Videos
Authors: Patrick Giedemann, Pius von D\"aniken, Jan Deriu, Alvaro Rodrigo,
  Anselmo Pe\~nas, Mark Cieliebak
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.12882 ,  973kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17114
replaced with revised version Fri, 5 Sep 2025 17:40:14 GMT   (13987kb)

Title: RAVEN: Query-Guided Representation Alignment for Question Answering over
  Audio, Video, Embedded Sensors, and Natural Language
Authors: Subrata Biswas, Mohammad Nur Hossain Khan, Bashima Islam
Categories: cs.CL cs.CV cs.LG cs.MM
\\ ( https://arxiv.org/abs/2505.17114 ,  13987kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22809
replaced with revised version Fri, 5 Sep 2025 16:48:02 GMT   (10065kb)

Title: First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons &
  Dragons Gameplay
Authors: Andrew Zhu, Evan Osgood, Chris Callison-Burch
Categories: cs.CL cs.AI cs.HC
Comments: 9 pages, 5 figures. COLM 2025 Workshop on AI Agents
\\ ( https://arxiv.org/abs/2505.22809 ,  10065kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21445
replaced with revised version Thu, 4 Sep 2025 18:01:56 GMT   (366kb)

Title: Text2Cypher Across Languages: Evaluating and Finetuning LLMs
Authors: Makbule Gulcin Ozsoy, William Tai
Categories: cs.CL cs.IR
\\ ( https://arxiv.org/abs/2506.21445 ,  366kb)
------------------------------------------------------------------------------
\\
arXiv:2507.14240
replaced with revised version Thu, 4 Sep 2025 23:06:49 GMT   (222kb)

Title: HuggingGraph: Understanding the Supply Chain of LLM Ecosystem
Authors: Mohammad Shahedur Rahman, Peng Gao, Yuede Ji
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2507.14240 ,  222kb)
------------------------------------------------------------------------------
\\
arXiv:2507.19081
replaced with revised version Fri, 5 Sep 2025 17:20:30 GMT   (125kb)

Title: Arg-LLaDA: Argument Summarization via Large Language Diffusion Models
  and Sufficiency-Aware Refinement
Authors: Hao Li, Yizheng Sun, Viktor Schlegel, Kailai Yang, Riza
  Batista-Navarro, Goran Nenadic
Categories: cs.CL
Comments: Preprint
\\ ( https://arxiv.org/abs/2507.19081 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21509
replaced with revised version Fri, 5 Sep 2025 07:44:31 GMT   (2637kb)

Title: Persona Vectors: Monitoring and Controlling Character Traits in Language
  Models
Authors: Runjin Chen, Andy Arditi, Henry Sleight, Owain Evans, Jack Lindsey
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2507.21509 ,  2637kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17450
replaced with revised version Fri, 5 Sep 2025 09:48:04 GMT   (368kb)

Title: Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability
  in Knowledge and Safety with DuET-PD
Authors: Bryan Chen Zhengyu Tan, Daniel Wai Kit Chin, Zhengyuan Liu, Nancy F.
  Chen, Roy Ka-Wei Lee
Categories: cs.CL cs.CY
Comments: To appear at EMNLP 2025
\\ ( https://arxiv.org/abs/2508.17450 ,  368kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20201
replaced with revised version Fri, 5 Sep 2025 16:01:07 GMT   (795kb)

Title: Social Bias in Multilingual Language Models: A Survey
Authors: Lance Calvin Lim Gamboa, Yue Feng, Mark Lee
Categories: cs.CL
Comments: Accepted into EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2508.20201 ,  795kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00030
replaced with revised version Fri, 5 Sep 2025 15:41:49 GMT   (7750kb)

Title: MultiStream-LLM: Bridging Modalities for Robust Sign Language
  Translation
Authors: Marshall Thomas, Edward Fish, Richard Bowden
Categories: cs.CL cs.CV
\\ ( https://arxiv.org/abs/2509.00030 ,  7750kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00461
replaced with revised version Fri, 5 Sep 2025 12:32:22 GMT   (125kb)

Title: TECP: Token-Entropy Conformal Prediction for LLMs
Authors: Beining Xu, Yongming Lu
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.00461 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04111
replaced with revised version Fri, 5 Sep 2025 09:12:03 GMT   (595kb)

Title: MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages
Authors: Dan Saattrup Smart
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.04111 ,  595kb)
------------------------------------------------------------------------------
\\
arXiv:2205.02071
replaced with revised version Fri, 5 Sep 2025 01:10:10 GMT   (10528kb)

Title: Representation-Centric Survey of Skeletal Action Recognition and the
  ANUBIS Benchmark
Authors: Yang Liu, Jiyao Yang, Madhawa Perera, Pan Ji, Dongwoo Kim, Min Xu,
  Tianyang Wang, Saeed Anwar, Tom Gedeon, Lei Wang, Zhenyue Qin
Categories: cs.CV
\\ ( https://arxiv.org/abs/2205.02071 ,  10528kb)
------------------------------------------------------------------------------
\\
arXiv:2208.09677
replaced with revised version Fri, 5 Sep 2025 14:47:39 GMT   (410kb)

Title: Net2Brain: A Toolbox to compare artificial vision models with human
  brain responses
Authors: Domenic Bersch, Kshitij Dwivedi, Martina Vilas, Radoslaw M. Cichy,
  Gemma Roig
Categories: cs.CV cs.AI q-bio.NC
Comments: Published in Frontiers in Neuroinformatics (2025), Article 1515873.
  Version of record: https://doi.org/10.3389/fninf.2025.1515873 4 Pages, 3
  figures, submitted and accepted to CCNeuro 2022. For associated repository,
  see https://github.com/ToastyDom/Net2Brain Update 1: Changed Citation
Journal-ref: Front. Neuroinform. 19 (2025) 1515873
DOI: 10.3389/fninf.2025.1515873
\\ ( https://arxiv.org/abs/2208.09677 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:2312.03325
replaced with revised version Fri, 5 Sep 2025 09:28:42 GMT   (2847kb)

Title: FAGC:Feature Augmentation on Geodesic Curve in the Pre-Shape Space
Authors: Yuexing Han, Gan Hu, Guanxin Wan and Bing Wang
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2312.03325 ,  2847kb)
------------------------------------------------------------------------------
\\
arXiv:2408.05750
replaced with revised version Fri, 5 Sep 2025 02:34:19 GMT   (5176kb)

Title: FADE: A Dataset for Detecting Falling Objects around Buildings in Video
Authors: Zhigang Tu, Zhengbo Zhang, Zitao Gao, Chunluan Zhou, Junsong Yuan, Bo
  Du
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Information Forensics and Security
  (TIFS), 2025
\\ ( https://arxiv.org/abs/2408.05750 ,  5176kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11813
replaced with revised version Fri, 5 Sep 2025 07:15:34 GMT   (3551kb)

Title: SEA: Supervised Embedding Alignment for Token-Level Visual-Textual
  Integration in MLLMs
Authors: Yuanyang Yin, Yaqi Zhao, Yajie Zhang, Yuanxing Zhang, Ke Lin, Jiahao
  Wang, Xin Tao, Pengfei Wan, Wentao Zhang, Feng Zhao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2408.11813 ,  3551kb)
------------------------------------------------------------------------------
\\
arXiv:2409.11686
replaced with revised version Fri, 5 Sep 2025 17:36:16 GMT   (10695kb)

Title: Automated detection of underdiagnosed medical conditions via
  opportunistic imaging
Authors: Asad Aali, Andrew Johnston, Louis Blankemeier, Dave Van Veen, Laura T
  Derry, David Svec, Jason Hom, Robert D. Boutin, Akshay S. Chaudhari
Categories: cs.CV cs.AI cs.LG
Journal-ref: AASLD, 2025
\\ ( https://arxiv.org/abs/2409.11686 ,  10695kb)
------------------------------------------------------------------------------
\\
arXiv:2411.06378
replaced with revised version Fri, 5 Sep 2025 04:34:27 GMT   (3064kb)

Title: PKF: Probabilistic Data Association Kalman Filter for Multi-Object
  Tracking
Authors: Hanwen Cao, George J. Pappas, Nikolay Atanasov
Categories: cs.CV
\\ ( https://arxiv.org/abs/2411.06378 ,  3064kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17784
replaced with revised version Fri, 5 Sep 2025 02:09:31 GMT   (22331kb)

Title: HypDAE: Hyperbolic Diffusion Autoencoders for Hierarchical Few-shot
  Image Generation
Authors: Lingxiao Li, Kaixuan Fan, Boqing Gong, Xiangyu Yue
Categories: cs.CV
Comments: ICCV 2025, Code is available at:
  https://github.com/lingxiao-li/HypDAE
\\ ( https://arxiv.org/abs/2411.17784 ,  22331kb)
------------------------------------------------------------------------------
\\
arXiv:2412.14484
replaced with revised version Thu, 4 Sep 2025 20:09:59 GMT   (9066kb)

Title: DirectorLLM for Human-Centric Video Generation
Authors: Kunpeng Song, Tingbo Hou, Zecheng He, Haoyu Ma, Jialiang Wang, Animesh
  Sinha, Sam Tsai, Yaqiao Luo, Xiaoliang Dai, Li Chen, Xide Xia, Peizhao Zhang,
  Peter Vajda, Ahmed Elgammal, Felix Juefei-Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.14484 ,  9066kb)
------------------------------------------------------------------------------
\\
arXiv:2412.17541
replaced with revised version Fri, 5 Sep 2025 09:41:07 GMT   (1678kb)

Title: Spoof Trace Discovery for Deep Learning Based Explainable Face
  Anti-Spoofing
Authors: Haoyuan Zhang, Xiangyu Zhu, Li Gao, Jiawei Pan, Kai Pang, Guoying
  Zhao, Zhen Lei
Categories: cs.CV cs.AI
Comments: Accepted by IJCB 2025. Keywords: explainable artificial intelligence,
  face anti-spoofing, explainable face anti-spoofing, interpretable
\\ ( https://arxiv.org/abs/2412.17541 ,  1678kb)
------------------------------------------------------------------------------
\\
arXiv:2501.03544
replaced with revised version Fri, 5 Sep 2025 04:44:48 GMT   (2376kb)

Title: PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for
  Text-to-Image Models
Authors: Lingzhi Yuan, Xinfeng Li, Chejian Xu, Guanhong Tao, Xiaojun Jia, Yihao
  Huang, Wei Dong, Yang Liu, Bo Li
Categories: cs.CV cs.AI cs.CR
Comments: 15 pages, 8 figures, 14 tables
\\ ( https://arxiv.org/abs/2501.03544 ,  2376kb)
------------------------------------------------------------------------------
\\
arXiv:2501.04631
replaced with revised version Thu, 4 Sep 2025 17:13:32 GMT   (46682kb)

Title: Disentangled Clothed Avatar Generation with Layered Representation
Authors: Weitian Zhang, Yichao Yan, Sijing Wu, Manwen Liao, Xiaokang Yang
Categories: cs.CV
Comments: ICCV 2025 highlight, project page:
  https://olivia23333.github.io/LayerAvatar/
\\ ( https://arxiv.org/abs/2501.04631 ,  46682kb)
------------------------------------------------------------------------------
\\
arXiv:2501.06897
replaced with revised version Thu, 4 Sep 2025 23:32:43 GMT   (6480kb)

Title: ActiveGAMER: Active GAussian Mapping through Efficient Rendering
Authors: Liyan Chen, Huangying Zhan, Kevin Chen, Xiangyu Xu, Qingan Yan,
  Changjiang Cai, Yi Xu
Categories: cs.CV cs.RO
Comments: Accepted to CVPR2025. Project page:
  https://oppo-us-research.github.io/ActiveGAMER-website/. Code:
  https://github.com/oppo-us-research/ActiveGAMER
\\ ( https://arxiv.org/abs/2501.06897 ,  6480kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14346
replaced with revised version Fri, 5 Sep 2025 12:48:08 GMT   (1008kb)

Title: 3D Densification for Multi-Map Monocular VSLAM in Endoscopy
Authors: X. Anad\'on, Javier Rodr\'iguez-Puigvert, J.M.M. Montiel
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.14346 ,  1008kb)
------------------------------------------------------------------------------
\\
arXiv:2503.19065
replaced with revised version Fri, 5 Sep 2025 14:13:28 GMT   (1581kb)

Title: WikiAutoGen: Towards Multi-Modal Wikipedia-Style Article Generation
Authors: Zhongyu Yang, Jun Chen, Dannong Xu, Junjie Fei, Xiaoqian Shen,
  Liangbing Zhao, Chun-Mei Feng, Mohamed Elhoseiny
Categories: cs.CV
Comments: ICCV 2025, Project in https://wikiautogen.github.io/
\\ ( https://arxiv.org/abs/2503.19065 ,  1581kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20309
replaced with revised version Fri, 5 Sep 2025 11:23:33 GMT   (1024kb)

Title: Instruction-Oriented Preference Alignment for Enhancing Multi-Modal
  Comprehension Capability of MLLMs
Authors: Zitian Wang, Yue Liao, Kang Rong, Fengyun Rao, Yibo Yang, Si Liu
Categories: cs.CV
Comments: Accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2503.20309 ,  1024kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00204
replaced with revised version Fri, 5 Sep 2025 12:21:01 GMT   (2589kb)

Title: RailGoerl24: G\"orlitz Rail Test Center CV Dataset 2024
Authors: Rustam Tagiew (1), Ilkay Wunderlich (2), Mark Sastuba (1), Kilian
  G\"oller (3) and Steffen Seitz (3) ((1) German Centre for Rail Traffic
  Research at the Federal Railway Authority, (2) EYYES GmbH, (3) Conrad Zuse
  School of Embedded Composite AI and the Chair of Fundamentals of Electrical
  Engineering of Dresden University of Technology)
Categories: cs.CV cs.AI
Comments: 4 pages, 5 figures, presented at Engineering Reliable Autonomous
  Systems 2025
DOI: 10.1109/ERAS63351.2025.11135724
\\ ( https://arxiv.org/abs/2504.00204 ,  2589kb)
------------------------------------------------------------------------------
\\
arXiv:2505.04672
replaced with revised version Fri, 5 Sep 2025 08:59:41 GMT   (23361kb)

Title: Histo-Miner: Deep Learning based Tissue Features Extraction Pipeline
  from H&E Whole Slide Images of Cutaneous Squamous Cell Carcinoma
Authors: Lucas Sanc\'er\'e, Carina Lorenz, Doris Helbig, Oana-Diana Persa,
  Sonja Dengler, Alexander Kreuter, Martim Laimer, Anne Fr\"ohlich, Jennifer
  Landsberg, Johannes Br\"agelmann, Katarzyna Bozek
Categories: cs.CV q-bio.QM
Comments: 31 pages including supplement, 5 core figures, 5 supplement figures.
  Version 2: change sections order, add new supplementary sections, minor text
  updates
\\ ( https://arxiv.org/abs/2505.04672 ,  23361kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16422
replaced with revised version Fri, 5 Sep 2025 02:24:00 GMT   (8105kb)

Title: Unlocking Smarter Device Control: Foresighted Planning with a World
  Model-Driven Code Execution Approach
Authors: Xiaoran Yin, Xu Luo, Hao Wu, Lianli Gao, Jingkuan Song
Categories: cs.CV
Comments: Accepted to Findings of EMNLP 2025. This is the camera-ready version
\\ ( https://arxiv.org/abs/2505.16422 ,  8105kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10605
replaced with revised version Fri, 5 Sep 2025 11:39:36 GMT   (9960kb)

Title: High-resolution efficient image generation from WiFi CSI using a
  pretrained latent diffusion model
Authors: Eshan Ramesh, Takayuki Nishio
Categories: cs.CV
Comments: 6 pages, 4 figures
\\ ( https://arxiv.org/abs/2506.10605 ,  9960kb)
------------------------------------------------------------------------------
\\
arXiv:2506.11430
replaced with revised version Fri, 5 Sep 2025 08:38:02 GMT   (18269kb)

Title: Auto-Connect: Connectivity-Preserving RigFormer with Direct Preference
  Optimization
Authors: Jingfeng Guo, Jian Liu, Jinnan Chen, Shiwei Mao, Changrong Hu, Puhua
  Jiang, Junlin Yu, Jing Xu, Qi Liu, Lixin Xu, Zhuo Chen, Chunchao Guo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.11430 ,  18269kb)
------------------------------------------------------------------------------
\\
arXiv:2506.17733
replaced with revised version Fri, 5 Sep 2025 11:07:37 GMT   (6523kb)

Title: YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive
  Visual Perception
Authors: Mengqi Lei, Siqi Li, Yihong Wu, Han Hu, You Zhou, Xinhu Zheng,
  Guiguang Ding, Shaoyi Du, Zongze Wu, Yue Gao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.17733 ,  6523kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04681
replaced with revised version Fri, 5 Sep 2025 08:26:24 GMT   (900kb)

Title: Colorectal Cancer Tumor Grade Segmentation in Digital Histopathology
  Images: From Giga to Mini Challenge
Authors: Alper Bahcekapili, Duygu Arslan, Umut Ozdemir, Berkay Ozkirli, Emre
  Akbas, Ahmet Acar, Gozde B. Akar, Bingdou He, Shuoyu Xu, Umit Mert Caglar,
  Alptekin Temizel, Guillaume Picaud, Marc Chaumont, G\'erard Subsol, Luc
  T\'eot, Fahad Alsharekh, Shahad Alghannam, Hexiang Mao, Wenhua Zhang
Categories: cs.CV
Comments: Accepted Grand Challenge Paper ICIP 2025
\\ ( https://arxiv.org/abs/2507.04681 ,  900kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05814
replaced with revised version Fri, 5 Sep 2025 13:51:50 GMT   (0kb,I)

Title: Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified
  Synthesis Framework
Authors: Wang Wang, Mingyu Shi, Jun Jiang, Wenqian Ma, Chong Liu, Yasutaka
  Narazaki, Xuguang Wang
Categories: cs.CV cs.AI
Comments: Due to the authors' failure to reach an agreement on the manuscript
  quality, they voluntarily waive their rights to be credited as authors
\\ ( https://arxiv.org/abs/2507.05814 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06269
replaced with revised version Thu, 4 Sep 2025 18:52:33 GMT   (13283kb)

Title: BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry
  with Neural Signed Distance Fields
Authors: Rushil Desai
Categories: cs.CV cs.AI
Comments: ICCV 2025 Workshops (11 Pages, 6 Figures, 2 Tables)
\\ ( https://arxiv.org/abs/2507.06269 ,  13283kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07574
replaced with revised version Fri, 5 Sep 2025 13:15:54 GMT   (15641kb)

Title: Beyond the Linear Separability Ceiling: Aligning Representations in VLMs
Authors: Enrico Vompa, Tanel Tammet, Mohit Vaishnav
Categories: cs.CV
Comments: preprint
\\ ( https://arxiv.org/abs/2507.07574 ,  15641kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13120
replaced with revised version Fri, 5 Sep 2025 01:00:00 GMT   (0kb,I)

Title: RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects
  in Remote Sensing Images
Authors: Xiaozheng Jiang, Wei Zhang, Xuerui Mao
Categories: cs.CV cs.LG
Comments: The content of the thesis requires supplementation to make it more
  substantial
\\ ( https://arxiv.org/abs/2507.13120 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23567
replaced with revised version Fri, 5 Sep 2025 15:41:13 GMT   (18006kb)

Title: 3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection
Authors: Yung-Hsu Yang, Luigi Piccinelli, Mattia Segu, Siyuan Li, Rui Huang,
  Yuqian Fu, Marc Pollefeys, Hermann Blum, Zuria Bauer
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2507.23567 ,  18006kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10542
replaced with revised version Fri, 5 Sep 2025 07:38:22 GMT   (609kb)

Title: GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For
  Salient Object Detection in Optical Remote Sensing Images
Authors: Mengyu Ren, Yutong Li, Hua Li, Runmin Cong, Sam Kwong
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.10542 ,  609kb)
------------------------------------------------------------------------------
\\
arXiv:2508.14014
replaced with revised version Fri, 5 Sep 2025 01:14:16 GMT   (38044kb)

Title: Online 3D Gaussian Splatting Modeling with Novel View Selection
Authors: Byeonggwon Lee, Junkyu Park, Khang Truong Giang, Soohwan Song
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.14014 ,  38044kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15298
replaced with revised version Fri, 5 Sep 2025 15:35:54 GMT   (1611kb)

Title: TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect
  Classification
Authors: Darya Taratynova, Alya Almsouti, Beknur Kalmakhanbet, Numan Saeed,
  Mohammad Yaqub
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.15298 ,  1611kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18733
replaced with revised version Fri, 5 Sep 2025 02:02:06 GMT   (1652kb)

Title: Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from
  Vector Drawings
Authors: Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang
  Liu
Categories: cs.CV
Comments: Accepted to ACM MM 2025
\\ ( https://arxiv.org/abs/2508.18733 ,  1652kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01421
replaced with revised version Fri, 5 Sep 2025 09:39:32 GMT   (12701kb)

Title: InfoScale: Unleashing Training-free Variable-scaled Image Generation via
  Effective Utilization of Information
Authors: Guohui Zhang, Jiangtong Tan, Linjiang Huang, Zhonghang Yuan, Naishan
  Zheng, Jie Huang, Feng Zhao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.01421 ,  12701kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01910
replaced with revised version Fri, 5 Sep 2025 10:42:33 GMT   (16427kb)

Title: Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS
  Alignment Framework
Authors: Furong Jia, Lanxin Liu, Ce Hou, Fan Zhang, Xinyan Liu, Yu Liu
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2509.01910 ,  16427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02445
replaced with revised version Thu, 4 Sep 2025 21:00:18 GMT   (28148kb)

Title: Towards High-Fidelity, Identity-Preserving Real-Time Makeup Transfer:
  Decoupling Style Generation
Authors: Lydia Kin Ching Chau, Zhi Yu and Ruowei Jiang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.02445 ,  28148kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03025
replaced with revised version Fri, 5 Sep 2025 07:49:47 GMT   (6644kb)

Title: Unveiling the Response of Large Vision-Language Models to Visually
  Absent Tokens
Authors: Sohee Kim, Soohyun Ryu, Joonhyung Park, Eunho Yang
Categories: cs.CV cs.AI
Comments: accepted to EMNLP 2025
\\ ( https://arxiv.org/abs/2509.03025 ,  6644kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03786
replaced with revised version Fri, 5 Sep 2025 01:54:11 GMT   (2194kb)

Title: SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object
  Detection
Authors: Xinxin Huang, Han Sun, Ningzhong Liu, Huiyu Zhou, Yinan Yao
Categories: cs.CV
Comments: 14pages, accepted by PRCV2025
\\ ( https://arxiv.org/abs/2509.03786 ,  2194kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03975
replaced with revised version Fri, 5 Sep 2025 07:22:43 GMT   (592kb)

Title: Improving Vessel Segmentation with Multi-Task Learning and Auxiliary
  Data Available Only During Model Training
Authors: Daniel Sobotka, Alexander Herold, Matthias Perkonigg, Lucian Beer,
  Nina Bastati, Alina Sablatnig, Ahmed Ba-Ssalamah, Georg Langs
Categories: cs.CV
Journal-ref: Computerized Medical Imaging and Graphics Volume 114, June 2024,
  102369
DOI: 10.1016/j.compmedimag.2024.102369
\\ ( https://arxiv.org/abs/2509.03975 ,  592kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04334
replaced with revised version Fri, 5 Sep 2025 15:02:49 GMT   (14391kb)

Title: GeoArena: An Open Platform for Benchmarking Large Vision-language Models
  on WorldWide Image Geolocalization
Authors: Pengyue Jia, Yingyi Zhang, Xiangyu Zhao, Yixuan Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.04334 ,  14391kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04376
replaced with revised version Fri, 5 Sep 2025 02:40:36 GMT   (1426kb)

Title: AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval
  for Text-Based Person Anomaly Search
Authors: Hao Ju, Hu Zhang, Zhedong Zheng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.04376 ,  1426kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04378
replaced with revised version Fri, 5 Sep 2025 12:37:27 GMT   (2947kb)

Title: Aesthetic Image Captioning with Saliency Enhanced MLLMs
Authors: Yilin Tao, Jiashui Huang, Huaze Xu, and Ling Shao
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.04378 ,  2947kb)
------------------------------------------------------------------------------
\\
arXiv:2305.09538
replaced with revised version Thu, 4 Sep 2025 20:02:02 GMT   (239kb)

Title: A LOCAL View of the Polynomial Hierarchy
Authors: Fabian Reiter
Categories: cs.DC cs.CC cs.FL cs.LO
Comments: 77 pages, 18 figures (5 repeated); v4: Expanded discussion of
  alternation as a measure of locality, with additional expressibility and
  inexpressibility results
ACM-class: C.2.4; F.1.1; F.1.2; F.1.3; F.4.1; F.4.3
\\ ( https://arxiv.org/abs/2305.09538 ,  239kb)
------------------------------------------------------------------------------
\\
arXiv:2402.08950
replaced with revised version Thu, 4 Sep 2025 21:22:09 GMT   (161kb)

Title: Taking GPU Programming Models to Task for Performance Portability
Authors: Joshua H. Davis, Pranav Sivaraman, Joy Kitson, Konstantinos Parasyris,
  Harshitha Menon, Isaac Minn, Giorgis Georgakoudis, Abhinav Bhatele
Categories: cs.DC cs.PF
Comments: 16 pages, 5 figures
DOI: 10.1145/3721145.3730423
\\ ( https://arxiv.org/abs/2402.08950 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2503.22643
replaced with revised version Fri, 5 Sep 2025 14:53:52 GMT   (371kb)

Title: Hiding Latencies in Network-Based Image Loading for Deep Learning
Authors: Francesco Versaci, Giovanni Busonera
Categories: cs.DC
Comments: 20 pages, 7 figures
\\ ( https://arxiv.org/abs/2503.22643 ,  371kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20938
replaced with revised version Fri, 5 Sep 2025 16:19:54 GMT   (176kb)

Title: ParEval-Repo: A Benchmark Suite for Evaluating LLMs with
  Repository-level HPC Translation Tasks
Authors: Joshua H. Davis, Daniel Nichols, Ishan Khillan, Abhinav Bhatele
Categories: cs.DC
Comments: 10 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.20938 ,  176kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04833
replaced with revised version Fri, 5 Sep 2025 14:00:12 GMT   (1564kb)

Title: OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks
Authors: Nicolas Nicolaou, Onyeka Obi, Aayush Rajasekaran, Alejandro Bergasov,
  Aleksandr Bezobchuk, Kishori M. Konwar, Michael Meier, Santiago Paiva, Har
  Preet Singh, Swarnabha Sinha. Sriram Vishwanath, Muriel Medard
Categories: cs.DC
MSC-class: E.4, C.2.4
\\ ( https://arxiv.org/abs/2508.04833 ,  1564kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18708
replaced with revised version Fri, 5 Sep 2025 03:49:51 GMT   (9006kb)

Title: Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in
  Healthcare
Authors: Promise Osaine Ekpo, Brian La, Thomas Wiener, Saesha Agarwal, Arshia
  Agrawal, Gonzalo Gonzalez-Pumariega, Lekan P. Molu, Angelique Taylor
Categories: cs.MA cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.18708 ,  9006kb)
------------------------------------------------------------------------------
\\
arXiv:2312.16019 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 13:07:46 GMT   (6146kb)

Title: Survival Analysis with Adversarial Regularization
Authors: Michael Potter, Stefano Maxenti, Michael Everett
Categories: stat.ML cs.AI cs.LG stat.AP
Comments: Published in IEEE International Conference on Healthcare Informatics
  (ICHI) 2025
\\ ( https://arxiv.org/abs/2312.16019 ,  6146kb)
------------------------------------------------------------------------------
\\
arXiv:2405.15164
replaced with revised version Thu, 4 Sep 2025 18:13:50 GMT   (3326kb)

Title: From Frege to chatGPT: Compositionality in language, cognition, and deep
  neural networks
Authors: Jacob Russin, Sam Whitman McGrath, Danielle J. Williams
Categories: cs.NE cs.AI cs.LG
Comments: 19 pages (28 pages including references), 2 figures. Forthcoming in
  an edited volume on neuroscience and philosophy
\\ ( https://arxiv.org/abs/2405.15164 ,  3326kb)
------------------------------------------------------------------------------
\\
arXiv:2407.09337
replaced with revised version Fri, 5 Sep 2025 17:38:07 GMT   (135kb)

Title: CFaults: Model-Based Diagnosis for Fault Localization in C Programs with
  Multiple Test Cases
Authors: Pedro Orvalho and Mikol\'a\v{s} Janota and Vasco Manquinho
Categories: cs.SE cs.AI cs.LO
Comments: Accepted at FM 2024. 15 pages, 2 figures, 3 tables and 5 listings
Journal-ref: In the 26th international symposium on Formal Methods, FM 2024
\\ ( https://arxiv.org/abs/2407.09337 ,  135kb)
------------------------------------------------------------------------------
\\
arXiv:2409.16299
replaced with revised version Fri, 5 Sep 2025 08:01:17 GMT   (362kb)

Title: HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks
  at Scale
Authors: Huy Nhat Phan, Tien N. Nguyen, Phong X. Nguyen, Nghi D. Q. Bui
Categories: cs.SE cs.AI
Comments: 49 pages
\\ ( https://arxiv.org/abs/2409.16299 ,  362kb)
------------------------------------------------------------------------------
\\
arXiv:2411.07441
replaced with revised version Fri, 5 Sep 2025 08:40:29 GMT   (4457kb)

Title: Automatically Detecting Online Deceptive Patterns
Authors: Asmit Nayak, Shirley Zhang, Yash Wani, Rishabh Khandelwal, Kassem
  Fawaz
Categories: cs.HC cs.AI cs.CY
\\ ( https://arxiv.org/abs/2411.07441 ,  4457kb)
------------------------------------------------------------------------------
\\
arXiv:2411.13207
replaced with revised version Fri, 5 Sep 2025 04:24:34 GMT   (10418kb)

Title: The Information Security Awareness of Large Language Models
Authors: Ofir Cohen, Gil Ari Agmon, Asaf Shabtai, Rami Puzis
Categories: cs.CR cs.AI cs.LG
\\ ( https://arxiv.org/abs/2411.13207 ,  10418kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14333
replaced with revised version Thu, 4 Sep 2025 21:35:59 GMT   (2864kb)

Title: Revealing higher-order neural representations of uncertainty with the
  Noise Estimation through Reinforcement-based Diffusion (NERD) model
Authors: Hojjat Azimi Asrari, Megan A. K. Peters
Categories: cs.LG cs.AI q-bio.NC
Comments: 27 pages, 7 figures, 12 equations
\\ ( https://arxiv.org/abs/2503.14333 ,  2864kb)
------------------------------------------------------------------------------
\\
arXiv:2504.04365
replaced with revised version Fri, 5 Sep 2025 11:08:45 GMT   (493kb)

Title: AutoPDL: Automatic Prompt Optimization for LLM Agents
Authors: Claudio Spiess, Mandana Vaziri, Louis Mandel, Martin Hirzel
Categories: cs.LG cs.AI cs.PL
\\ ( https://arxiv.org/abs/2504.04365 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10264
replaced with revised version Fri, 5 Sep 2025 11:54:06 GMT   (3393kb)

Title: Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack
  in Federated Learning
Authors: Francesco Diana, Andr\'e Nusser, Chuan Xu, Giovanni Neglia
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2505.10264 ,  3393kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11737
replaced with revised version Thu, 4 Sep 2025 21:49:52 GMT   (708kb)

Title: TokUR: Token-Level Uncertainty Estimation for Large Language Model
  Reasoning
Authors: Tunyu Zhang, Haizhou Shi, Yibin Wang, Hengyi Wang, Xiaoxiao He,
  Zhuowei Li, Haoxian Chen, Ligong Han, Kai Xu, Huan Zhang, Dimitris Metaxas,
  Hao Wang
Categories: cs.LG cs.AI cs.CL
Comments: Preprint; Work in progress
\\ ( https://arxiv.org/abs/2505.11737 ,  708kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08224 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 02:02:24 GMT   (7984kb)

Title: AI-Assisted Rapid Crystal Structure Generation Towards a Target Local
  Environment
Authors: Osman Goni Ridwan, Sylvain Piti\'e, Monish Soundar Raj, Dong Dai,
  Gilles Frapper, Hongfei Xue and Qiang Zhu
Categories: cond-mat.mtrl-sci cs.AI physics.comp-ph
Comments: 27 pages, 15 figures
\\ ( https://arxiv.org/abs/2506.08224 ,  7984kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05644
replaced with revised version Fri, 5 Sep 2025 01:58:57 GMT   (752kb)

Title: The Features at Convergence Theorem: a first-principles alternative to
  the Neural Feature Ansatz for how networks learn representations
Authors: Enric Boix-Adsera, Neil Mallinar, James B. Simon, Mikhail Belkin
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2507.05644 ,  752kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07236
replaced with revised version Fri, 5 Sep 2025 17:54:18 GMT   (504kb)

Title: Simple Yet Effective: An Information-Theoretic Approach to Multi-LLM
  Uncertainty Quantification
Authors: Maya Kruse, Majid Afshar, Saksham Khatwani, Anoop Mayampurath, Guanhua
  Chen, Yanjun Gao
Categories: cs.LG cs.AI cs.CL
Comments: Accepted to EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2507.07236 ,  504kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13802
replaced with revised version Fri, 5 Sep 2025 11:44:19 GMT   (27584kb)

Title: Food safety trends across Europe: insights from the 392-million-entry
  CompreHensive European Food Safety (CHEFS) database
Authors: Nehir Kizililsoley, Floor van Meer, Osman Mutlu, Wouter F Hoenderdaal,
  Rosan G. Hob\'e, Wenjuan Mu, Arjen Gerssen, H.J. van der Fels-Klerx, \'Akos
  J\'o\'zwiak, Ioannis Manikas, Ali H\"urriyeto\v{g}lu, Bas H.M. van der Velden
Categories: cs.CY cs.AI cs.CV
\\ ( https://arxiv.org/abs/2507.13802 ,  27584kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01249
replaced with revised version Fri, 5 Sep 2025 17:13:05 GMT   (5652kb)

Title: AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend
  Against Prompt Injection
Authors: Peiran Wang, Yang Liu, Yunfei Lu, Yifeng Cai, Hongbo Chen, Qingyou
  Yang, Jie Zhang, Jue Hong, Ye Wu
Categories: cs.CR cs.AI cs.CL cs.LG cs.SE
\\ ( https://arxiv.org/abs/2508.01249 ,  5652kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15442 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 16:13:01 GMT   (2144kb)

Title: Mitigating Hallucinations in LM-Based TTS Models via Distribution
  Alignment Using GFlowNets
Authors: Chenlin Liu, Minghui Fang, Patrick Zhang, Wei Zhou, Jie Gao, Jiqing
  Han
Categories: eess.AS cs.AI cs.SD
Comments: Accepted to EMNLP 2025 Main Conference (Oral)
\\ ( https://arxiv.org/abs/2508.15442 ,  2144kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21001
replaced with revised version Fri, 5 Sep 2025 15:50:08 GMT   (1045kb)

Title: Train-Once Plan-Anywhere Kinodynamic Motion Planning via Diffusion Trees
Authors: Yaniv Hassidof, Tom Jurgenson, Kiril Solovey
Categories: cs.LG cs.AI cs.RO
Comments: Accepted to CoRL 2025, Project page:
  https://sites.google.com/view/ditree. v2: Abstract updated
\\ ( https://arxiv.org/abs/2508.21001 ,  1045kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21433
replaced with revised version Fri, 5 Sep 2025 06:16:59 GMT   (907kb)

Title: The Complexity Trap: Simple Observation Masking Is as Efficient as LLM
  Summarization for Agent Context Management
Authors: Tobias Lindenbauer, Igor Slinko, Ludwig Felder, Egor Bogomolov,
  Yaroslav Zharov
Categories: cs.SE cs.AI
Comments: v2: Fixed typos and formatting issues
\\ ( https://arxiv.org/abs/2508.21433 ,  907kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02046
replaced with revised version Thu, 4 Sep 2025 19:22:04 GMT   (707kb)

Title: Fantastic Pretraining Optimizers and Where to Find Them
Authors: Kaiyue Wen, David Hall, Tengyu Ma, Percy Liang
Categories: cs.LG cs.AI stat.ML
Comments: 108 pages, 8 figures, reproducible runs available at
  https://wandb.ai/marin-community/optimizer-scaling
\\ ( https://arxiv.org/abs/2509.02046 ,  707kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02055
replaced with revised version Fri, 5 Sep 2025 06:24:50 GMT   (14951kb)

Title: Align-Then-stEer: Adapting the Vision-Language Action Models through
  Unified Latent Guidance
Authors: Yang Zhang, Chenwei Wang, Ouyang Lu, Yuan Zhao, Yunfei Ge, Zhenglong
  Sun, Xiu Li, Chi Zhang, Chenjia Bai, Xuelong Li
Categories: cs.RO cs.AI
Comments: The first three authors contributed equally
\\ ( https://arxiv.org/abs/2509.02055 ,  14951kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02586 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 22:27:29 GMT   (13kb)

Title: MitoDetect++: A Domain-Robust Pipeline for Mitosis Detection and
  Atypical Subtyping
Authors: Esha Sadia Nasir, Jiaqi Lv, Mostafa Jahanifar, Shan E Ahmed Raza
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2509.02586 ,  13kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02640 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 14:00:52 GMT   (70kb)

Title: Adaptive Learning Strategies for Mitotic Figure Classification in
  MIDOG2025 Challenge
Authors: Biwen Meng, Xi Long, and Jingxin Liu
Categories: eess.IV cs.AI cs.CV
\\ ( https://arxiv.org/abs/2509.02640 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03643
replaced with revised version Fri, 5 Sep 2025 12:40:38 GMT   (5266kb)

Title: CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health
  Records
Authors: Chao Pang, Jiheum Park, Xinzhuo Jiang, Nishanth Parameshwar
  Pavinkurve, Krishna S. Kalluri, Shalmali Joshi, No\'emie Elhadad, Karthik
  Natarajan
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.03643 ,  5266kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18122
replaced with revised version Fri, 5 Sep 2025 13:58:20 GMT   (566kb)

Title: Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution
  Generalization of Misinformation Detection Models
Authors: Ivo Verhoeven, Pushkar Mishra, Ekaterina Shutova
Categories: cs.IR cs.CL
Comments: Under review
\\ ( https://arxiv.org/abs/2410.18122 ,  566kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20474 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 03:02:37 GMT   (505kb)

Title: MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and
  Adaptive Financial Trading
Authors: Siyi Wu, Junqiao Wang, Zhaoyang Guan, Leyi Zhao, Xinyuan Song, Xinyu
  Ying, Dexu Yu, Jinhao Wang, Hanlin Zhang, Michele Pak, Yangfan He, Yi Xin,
  Jianhui Wang, and Tianyu Shi
Categories: q-fin.TR cs.CL cs.LG
\\ ( https://arxiv.org/abs/2507.20474 ,  505kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20312
replaced with revised version Fri, 5 Sep 2025 00:27:59 GMT   (1115kb)

Title: ELIXIR: Efficient and LIghtweight model for eXplaIning Recommendations
Authors: Ben Kabongo and Vincent Guigue and Pirmin Lemberger
Categories: cs.IR cs.CL cs.LG
Comments: 10 pages, 3 figures, 6 Tables
\\ ( https://arxiv.org/abs/2508.20312 ,  1115kb)
------------------------------------------------------------------------------
\\
arXiv:2405.10833 (*cross-listing*)
replaced with revised version Thu, 4 Sep 2025 19:01:53 GMT   (16014kb)

Title: Automatic segmentation of Organs at Risk in Head and Neck cancer
  patients from CT and MRI scans
Authors: S\'ebastien Quetin, Andrew Heschl, Mauricio Murillo, Rohit Murali,
  Piotr Pater, George Shenouda, Shirin A. Enger, Farhad Maleki
Categories: eess.IV cs.CV
\\ ( https://arxiv.org/abs/2405.10833 ,  16014kb)
------------------------------------------------------------------------------
\\
arXiv:2410.17422
replaced with revised version Fri, 5 Sep 2025 04:15:46 GMT   (11616kb)

Title: Multimodal LLM Guided Exploration and Active Mapping using Fisher
  Information
Authors: Wen Jiang, Boshu Lei, Katrina Ashton, Kostas Daniilidis
Categories: cs.RO cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2410.17422 ,  11616kb)
------------------------------------------------------------------------------
\\
arXiv:2508.04160
replaced with revised version Fri, 5 Sep 2025 16:58:33 GMT   (1969kb)

Title: DRIVE-T: A Methodology for Discriminative and Representative Data Viz
  Item Selection for Literacy Construct and Assessment
Authors: Angela Locoro, Silvia Golia, Davide Falessi
Categories: cs.HC cs.CV
ACM-class: K.3; K.3.2
\\ ( https://arxiv.org/abs/2508.04160 ,  1969kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16897 (*cross-listing*)
replaced with revised version Fri, 5 Sep 2025 00:44:03 GMT   (2844kb)

Title: Generating Synthetic Contrast-Enhanced Chest CT Images from Non-Contrast
  Scans Using Slice-Consistent Brownian Bridge Diffusion Network
Authors: Pouya Shiri, Xin Yi, Neel P. Mistry, Samaneh Javadinia, Mohammad
  Chegini, Seok-Bum Ko, Amirali Baniasadi and Scott J. Adams
Categories: eess.IV cs.CV physics.med-ph
\\ ( https://arxiv.org/abs/2508.16897 ,  2844kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04351
replaced with revised version Fri, 5 Sep 2025 11:14:38 GMT   (4915kb)

Title: Global-to-Local or Local-to-Global? Enhancing Image Retrieval with
  Efficient Local Search and Effective Global Re-ranking
Authors: Dror Aiger, Bingyi Cao, Kaifeng Chen, Andre Araujo
Categories: cs.IR cs.CV
\\ ( https://arxiv.org/abs/2509.04351 ,  4915kb)
------------------------------------------------------------------------------
\\
arXiv:2403.15191
replaced with revised version Thu, 4 Sep 2025 18:33:14 GMT   (279kb)

Title: Your Trust, Your Terms: A General Paradigm for Near-Instant Cross-Chain
  Transfer
Authors: Di Wu, Jingyu Liu, Xuechao Wang, Jian Liu, Yingjie Xue, Kui Ren, Chun
  Chen
Categories: cs.CR cs.DC
\\ ( https://arxiv.org/abs/2403.15191 ,  279kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02613
replaced with revised version Fri, 5 Sep 2025 14:05:02 GMT   (306kb)

Title: MULTI-SCOUT: Multistatic Integrated Sensing and Communications in 5G and
  Beyond for Moving Target Detection, Positioning, and Tracking
Authors: Yalin E. Sagduyu, Kemal Davaslioglu, Tugba Erpek, Sastry Kompella,
  Gustave Anderson, Jonathan Ashdown
Categories: cs.NI cs.DC eess.SP
\\ ( https://arxiv.org/abs/2507.02613 ,  306kb)
------------------------------------------------------------------------------
\\
arXiv:2309.08896
replaced with revised version Fri, 5 Sep 2025 17:57:12 GMT   (7976kb)

Title: Graph-based Decentralized Task Allocation for Multi-Robot Target
  Localization
Authors: Juntong Peng, Hrishikesh Viswanath, Aniket Bera
Categories: cs.RO cs.MA
\\ ( https://arxiv.org/abs/2309.08896 ,  7976kb)
------------------------------------------------------------------------------
\\
arXiv:2410.17351
replaced with revised version Fri, 5 Sep 2025 17:04:26 GMT   (620kb)

Title: Hierarchical Multi-agent Reinforcement Learning for Cyber Network
  Defense
Authors: Aditya Vikram Singh, Ethan Rathbun, Emma Graham, Lisa Oakley, Simona
  Boboila, Alina Oprea, Peter Chin
Categories: cs.LG cs.CR cs.MA
Comments: 13 pages, 7 figures, RLC Paper
\\ ( https://arxiv.org/abs/2410.17351 ,  620kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02780
replaced with revised version Fri, 5 Sep 2025 13:34:27 GMT   (1204kb)

Title: Quantitative Resilience Modeling for Autonomous Cyber Defense
Authors: Xavier Cadet, Simona Boboila, Edward Koh, Peter Chin, Alina Oprea
Categories: cs.CR cs.LG cs.MA
\\ ( https://arxiv.org/abs/2503.02780 ,  1204kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00801
replaced with revised version Fri, 5 Sep 2025 08:00:49 GMT   (161kb)

Title: Adaptation of Parameters in Heterogeneous Multi-agent Systems
Authors: Hyungbo Shim and Jin Gyu Lee and B. D. O. Anderson
Categories: eess.SY cs.MA cs.SY
Comments: 10 pages, 2 figures, IEEE Conf. on Decision and Control 2025
\\ ( https://arxiv.org/abs/2509.00801 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01630
replaced with revised version Fri, 5 Sep 2025 15:36:28 GMT   (11071kb)

Title: Learning to Coordinate: Distributed Meta-Trajectory Optimization Via
  Differentiable ADMM-DDP
Authors: Bingheng Wang, Yichao Gao, Tianchen Sun, and Lin Zhao
Categories: cs.LG cs.MA cs.RO cs.SY eess.SY
\\ ( https://arxiv.org/abs/2509.01630 ,  11071kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
