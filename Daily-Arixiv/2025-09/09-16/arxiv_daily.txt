Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 4004a1 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年9月18日 11:48
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Tue 16 Sep 25 18:00:00 GMT  to  Wed 17 Sep 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2509.13332
Date: Tue, 9 Sep 2025 18:36:02 GMT   (619kb)

Title: Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy,
  Efficiency, and Robustness
Authors: Pratik Jayarao and Himanshu Gupta and Neeraj Varshney and Chaitanya
  Dwivedi
Categories: cs.AI cs.CL
\\
  As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.
\\ ( https://arxiv.org/abs/2509.13332 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13333
Date: Wed, 10 Sep 2025 06:36:38 GMT   (671kb)

Title: Evaluation Awareness Scales Predictably in Open-Weights Large Language
  Models
Authors: Maheep Chaudhary, Ian Su, Nikhil Hooda, Nishith Shankar, Julia Tan,
  Kevin Zhu, Ashwinee Panda, Ryan Lagasse, Vasu Sharma
Categories: cs.AI
\\
  Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.
\\ ( https://arxiv.org/abs/2509.13333 ,  671kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13334
Date: Wed, 10 Sep 2025 07:07:17 GMT   (22530kb)

Title: FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness
Authors: Anand Swaroop, Akshat Nallani, Saksham Uboweja, Adiliia Uzdenova,
  Michael Nguyen, Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Vasu Sharma,
  Maheep Chaudhary
Categories: cs.AI cs.LG
\\
  Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.
\\ ( https://arxiv.org/abs/2509.13334 ,  22530kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13339
Date: Thu, 11 Sep 2025 14:01:43 GMT   (294kb)

Title: Position: AI Safety Must Embrace an Antifragile Perspective
Authors: Ming Jin, Hyunin Lee
Categories: cs.AI
Journal-ref: Proceedings of the 42nd International Conference on Machine
  Learning, Vancouver, Canada. 2025
\\
  This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.
\\ ( https://arxiv.org/abs/2509.13339 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13341
Date: Thu, 11 Sep 2025 23:55:39 GMT   (1583kb)

Title: Imagined Autocurricula
Authors: Ahmet H. G\"uzel, Matthew Thomas Jackson, Jarek Luca Liesen, Tim
  Rockt\"aschel, Jakob Nicolaus Foerster, Ilija Bogunovic, Jack Parker-Holder
Categories: cs.AI cs.LG
\\
  Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.
\\ ( https://arxiv.org/abs/2509.13341 ,  1583kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13347
Date: Sat, 13 Sep 2025 03:12:02 GMT   (369kb)

Title: OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft
Authors: Zihao Wang, Muyao Li, Kaichen He, Xiangyu Wang, Zhancun Mu, Anji Liu,
  Yitao Liang
Categories: cs.AI
\\
  The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA
\\ ( https://arxiv.org/abs/2509.13347 ,  369kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13351
Date: Sun, 14 Sep 2025 02:42:34 GMT   (200kb)

Title: Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for
  Symbolic Planning
Authors: Pulkit Verma, Ngoc La, Anthony Favier, Swaroop Mishra, Julie A. Shah
Categories: cs.AI cs.CL
\\
  Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.
\\ ( https://arxiv.org/abs/2509.13351 ,  200kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13352
Date: Sun, 14 Sep 2025 08:46:40 GMT   (477kb)

Title: Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and
  Cognitive Reasoning
Authors: Anis Koubaa and Khaled Gabr
Categories: cs.AI cs.RO
Comments: 14 pages, 1 figure
MSC-class: 68T07, 68T40, 68T42
ACM-class: I.2.9; I.2.11; I.2.8; I.2.10
\\
  Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.
\\ ( https://arxiv.org/abs/2509.13352 ,  477kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13357
Date: Sun, 14 Sep 2025 22:11:09 GMT   (29kb)

Title: Semantic Fusion with Fuzzy-Membership Features for Controllable Language
  Modelling
Authors: Yongchao Huang and Hassan Raza
Categories: cs.AI
Comments: 16 pages
\\
  We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.
\\ ( https://arxiv.org/abs/2509.13357 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13364
Date: Mon, 15 Sep 2025 16:11:03 GMT   (54kb)

Title: Asterisk Operator
Authors: Zixi Li
Categories: cs.AI
Comments: Code available at: https://github.com/lizixi-0x2F/Asterisk-Games
\\
  We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation
\\ ( https://arxiv.org/abs/2509.13364 ,  54kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13368
Date: Tue, 16 Sep 2025 02:14:39 GMT   (7052kb)

Title: $Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning
  Automation
Authors: Yuan Wei, Xiaohan Shan, Ran Miao, Jianmin Li
Categories: cs.AI cs.LG
Comments: 9 pages, 7 figures
\\
  Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.
\\ ( https://arxiv.org/abs/2509.13368 ,  7052kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13379
Date: Tue, 16 Sep 2025 08:17:39 GMT   (10891kb)

Title: The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking
  in VLMs
Authors: Asif Azad, Mohammad Sadat Hossain, MD Sadik Hossain Shanto, M Saifur
  Rahman, Md Rizwan Pervez
Categories: cs.AI cs.CV
\\
  Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.
\\ ( https://arxiv.org/abs/2509.13379 ,  10891kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13389
Date: Tue, 16 Sep 2025 14:03:58 GMT   (45kb)

Title: From Next Token Prediction to (STRIPS) World Models -- Preliminary
  Results
Authors: Carlos N\'u\~nez-Molina, Vicen\c{c} G\'omez, Hector Geffner
Categories: cs.AI
Comments: 10 pages, 3 figures
ACM-class: I.2.4; I.2.6; I.2.8
\\
  We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.
\\ ( https://arxiv.org/abs/2509.13389 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13450
Date: Tue, 16 Sep 2025 18:36:22 GMT   (12749kb)

Title: SteeringControl: Holistic Evaluation of Alignment Steering in LLMs
Authors: Vincent Siu, Nicholas Crispino, David Park, Nathan W. Henry, Zhun
  Wang, Yang Liu, Dawn Song, Chenguang Wang
Categories: cs.AI cs.CL cs.LG
\\
  We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.
\\ ( https://arxiv.org/abs/2509.13450 ,  12749kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13547
Date: Tue, 16 Sep 2025 21:29:34 GMT   (33kb)

Title: AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for
  Enhanced Problem-Solving
Authors: Harper Reed, Michael Sugimura, Angelo Zangari
Categories: cs.AI cs.HC
Comments: 16 pages, 5 tables
\\
  We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.
\\ ( https://arxiv.org/abs/2509.13547 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13570
Date: Tue, 16 Sep 2025 22:18:12 GMT   (660kb)

Title: Gen AI in Proof-based Math Courses: A Pilot Study
Authors: Hannah Klawa, Shraddha Rajpal, and Cigole Thomas
Categories: cs.AI math.HO
Comments: 35 pages, 6 figures, Comments welcome!
MSC-class: Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40
\\
  With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.
\\ ( https://arxiv.org/abs/2509.13570 ,  660kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13588
Date: Tue, 16 Sep 2025 23:03:02 GMT   (2899kb)

Title: Programmable Cognitive Bias in Social Agents
Authors: Xuan Liu, Haoyang Shang, Haojian Jin
Categories: cs.AI cs.CE cs.CY
\\
  This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.
\\ ( https://arxiv.org/abs/2509.13588 ,  2899kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13615
Date: Wed, 17 Sep 2025 01:14:14 GMT   (2229kb)

Title: See, Think, Act: Teaching Multimodal Agents to Effectively Interact with
  GUI by Identifying Toggles
Authors: Zongru Wu, Rui Mao, Zhiyuan Tian, Pengzhou Cheng, Tianjie Ju, Zheng
  Wu, Lingzhong Dong, Haiyue Sheng, Zhuosheng Zhang, Gongshen Liu
Categories: cs.AI cs.CL cs.HC
\\
  The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.
\\ ( https://arxiv.org/abs/2509.13615 ,  2229kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13704
Date: Wed, 17 Sep 2025 05:14:11 GMT   (1111kb)

Title: InfraMind: A Novel Exploration-based GUI Agentic Framework for
  Mission-critical Industrial Management
Authors: Liangtao Lin, Zhaomeng Zhu, Tianwei Zhang and Yonggang Wen
Categories: cs.AI cs.SE
\\
  Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.
\\ ( https://arxiv.org/abs/2509.13704 ,  1111kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13761
Date: Wed, 17 Sep 2025 07:16:12 GMT   (3638kb)

Title: THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical
  Reasoning
Authors: Qikai Chang, Zhenrong Zhang, Pengfei Hu, Jiefeng Ma, Yicheng Pan,
  Jianshu Zhang, Jun Du, Quan Liu, Jianqing Gao
Categories: cs.AI cs.CL
Comments: 22 pages, 13 figures
\\
  Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.
\\ ( https://arxiv.org/abs/2509.13761 ,  3638kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13773
Date: Wed, 17 Sep 2025 07:43:14 GMT   (1715kb)

Title: MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based
  Instruction Recommendation
Authors: Zhipeng Bian, Jieming Zhu, Xuyang Xie, Quanyu Dai, Zhou Zhao, Zhenhua
  Dong
Categories: cs.AI cs.IR
Comments: Published in Proceedings of the 63rd Annual Meeting of the
  Association for Computational Linguistics (Volume 6: Industry Track), ACL
  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103
ACM-class: I.2.7; I.2.10
Journal-ref: Proceedings of the 63rd Annual Meeting of the Association for
  Computational Linguistics (Volume 6: Industry Track) ACL 2025 1457-1465
DOI: 10.18653/v1/2025.acl-industry.103
\\
  The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.
\\ ( https://arxiv.org/abs/2509.13773 ,  1715kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13880
Date: Wed, 17 Sep 2025 10:19:06 GMT   (181kb)

Title: An Exhaustive DPLL Approach to Model Counting over Integer Linear
  Constraints with Simplification Techniques
Authors: Mingwei Zhang, Zhenhao Gu, Liangda Fang, Cunjing Ge, Ziliang Chen,
  Zhao-Rong Lai, Quanlong Guan
Categories: cs.AI
\\
  Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.
\\ ( https://arxiv.org/abs/2509.13880 ,  181kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13968
Date: Wed, 17 Sep 2025 13:38:40 GMT   (468kb)

Title: Exploring Major Transitions in the Evolution of Biological Cognition
  With Artificial Neural Networks
Authors: Konstantinos Voudouris, Andrew Barron, Marta Halina, Colin Klein,
  Matishalin Patel
Categories: cs.AI cs.CL cs.FL cs.LG
\\
  Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.
\\ ( https://arxiv.org/abs/2509.13968 ,  468kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14030
Date: Wed, 17 Sep 2025 14:31:18 GMT   (6549kb)

Title: CrowdAgent: Multi-Agent Managed Multi-Source Annotation System
Authors: Maosheng Qin, Renyu Zhu, Mingxuan Xia, Chenkai Chen, Zhen Zhu, Minmin
  Lin, Junbo Zhao, Lu Xu, Changjie Fan, Runze Wu, Haobo Wang
Categories: cs.AI
\\
  High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.
\\ ( https://arxiv.org/abs/2509.14030 ,  6549kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14195
Date: Wed, 17 Sep 2025 17:30:58 GMT   (581kb)

Title: Hierarchical Learning for Maze Navigation: Emergence of Mental
  Representations via Second-Order Learning
Authors: Shalima Binta Manir, Tim Oates
Categories: cs.AI cs.LG
Comments: 8 pages, 3 figures
\\
  Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.
\\ ( https://arxiv.org/abs/2509.14195 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13480
Date: Tue, 16 Sep 2025 19:25:13 GMT   (2173kb)

Title: Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs
Authors: Andrea Piergentili, Beatrice Savoldi, Matteo Negri, Luisa Bentivogli
Categories: cs.CL
Comments: Accepted at CLiC-it 2025
\\
  Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.
\\ ( https://arxiv.org/abs/2509.13480 ,  2173kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13539
Date: Tue, 16 Sep 2025 21:07:17 GMT   (4547kb)

Title: Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC
  Transcripts Using Active Learning
Authors: Alisa Kanganis and Katherine A. Keith
Categories: cs.CL
\\
  The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.
\\ ( https://arxiv.org/abs/2509.13539 ,  4547kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13569
Date: Tue, 16 Sep 2025 22:13:45 GMT   (8947kb)

Title: Overview of Dialog System Evaluation Track: Dimensionality, Language,
  Culture and Safety at DSTC 12
Authors: John Mendon\c{c}a and Lining Zhang and Rahul Mallidi and Alon Lavie
  and Isabel Trancoso and Luis Fernando D'Haro and Jo\~ao Sedoc
Categories: cs.CL
Comments: DSTC12 Track 1 Overview Paper. https://chateval.org/dstc12
\\
  The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.
\\ ( https://arxiv.org/abs/2509.13569 ,  8947kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13624
Date: Wed, 17 Sep 2025 01:45:42 GMT   (26844kb)

Title: Latent Traits and Cross-Task Transfer: Deconstructing Dataset
  Interactions in LLM Fine-tuning
Authors: Shambhavi Krishna, Atharva Naik, Chaitali Agarwal, Sudharshan
  Govindan, Taesung Lee, Haw-Shiuan Chang
Categories: cs.CL cs.LG
Comments: Camera-ready version. Accepted to appear in the proceedings of the
  14th Joint Conference on Lexical and Computational Semantics (*SEM 2025)
\\
  Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.
\\ ( https://arxiv.org/abs/2509.13624 ,  26844kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13664
Date: Wed, 17 Sep 2025 03:34:35 GMT   (691kb)

Title: Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs
Authors: Zhuoxuan Zhang, Jinhao Duan, Edward Kim, Kaidi Xu
Categories: cs.CL cs.AI
Comments: To be appeared in EMNLP 2025 (main)
\\
  Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.
\\ ( https://arxiv.org/abs/2509.13664 ,  691kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13672
Date: Wed, 17 Sep 2025 03:54:52 GMT   (174kb)

Title: CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in
  Chinese Literature Grammatical Error Correction
Authors: Shang Qin, Jingheng Ye, Yinghui Li, Hai-Tao Zheng, Qi Li, Jinxiao
  Shan, Zhixing Li, Hong-Gee Kim
Categories: cs.CL cs.AI
\\
  The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.
\\ ( https://arxiv.org/abs/2509.13672 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13677
Date: Wed, 17 Sep 2025 04:07:22 GMT   (488kb)

Title: AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise
  Control in Text Generation
Authors: Xinxu Zhou, Jiaqi Bai, Zhenqi Sun, Fanxiang Zeng and Yue Liu
Categories: cs.CL cs.AI cs.HC
\\
  Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.
\\ ( https://arxiv.org/abs/2509.13677 ,  488kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13683
Date: Wed, 17 Sep 2025 04:28:07 GMT   (3459kb)

Title: Improving Context Fidelity via Native Retrieval-Augmented Reasoning
Authors: Suyuchen Wang, Jinlin Wang, Xinyu Wang, Shiqi Li, Xiangru Tang, Sirui
  Hong, Xiao-Wen Chang, Chenglin Wu, Bang Liu
Categories: cs.CL cs.AI
Comments: Accepted as a main conference paper at EMNLP 2025
\\
  Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.
\\ ( https://arxiv.org/abs/2509.13683 ,  3459kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13695
Date: Wed, 17 Sep 2025 04:56:51 GMT   (492kb)

Title: Can Large Language Models Robustly Perform Natural Language Inference
  for Japanese Comparatives?
Authors: Yosuke Mikami, Daiki Matsuoka and Hitomi Yanaka
Categories: cs.CL
Comments: To appear in Proceedings of the 16th International Conference on
  Computational Semantics (IWCS 2025)
\\
  Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.
\\ ( https://arxiv.org/abs/2509.13695 ,  492kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13696
Date: Wed, 17 Sep 2025 05:02:14 GMT   (53kb)

Title: Integrating Text and Time-Series into (Large) Language Models to Predict
  Medical Outcomes
Authors: Iyadh Ben Cheikh Larbi, Ajay Madhavan Ravichandran, Aljoscha
  Burchardt, Roland Roller
Categories: cs.CL
Comments: Presented and published at BioCreative IX
\\
  Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.
\\ ( https://arxiv.org/abs/2509.13696 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13702
Date: Wed, 17 Sep 2025 05:09:22 GMT   (2260kb)

Title: DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination
  Suppression in Large Language Models
Authors: Xiao Zheng
Categories: cs.CL cs.AI
\\
  Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.
\\ ( https://arxiv.org/abs/2509.13702 ,  2260kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13706
Date: Wed, 17 Sep 2025 05:29:23 GMT   (718kb)

Title: Automated Triaging and Transfer Learning of Incident Learning Safety
  Reports Using Large Language Representational Models
Authors: Peter Beidler, Mark Nguyen, Kevin Lybarger, Ola Holmberg, Eric Ford,
  John Kang
Categories: cs.CL cs.AI
\\
  PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.
\\ ( https://arxiv.org/abs/2509.13706 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13723
Date: Wed, 17 Sep 2025 06:18:46 GMT   (333kb)

Title: DSPC: Dual-Stage Progressive Compression Framework for Efficient
  Long-Context Reasoning
Authors: Yaxin Gao, Yao Lu, Zongfei Zhang, Jiaqi Nie, Shanqing Yu, Qi Xuan
Categories: cs.CL
\\
  Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.
\\ ( https://arxiv.org/abs/2509.13723 ,  333kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13734
Date: Wed, 17 Sep 2025 06:37:10 GMT   (344kb)

Title: Implementing a Logical Inference System for Japanese Comparatives
Authors: Yosuke Mikami, Daiki Matsuoka and Hitomi Yanaka
Categories: cs.CL
Comments: In Proceedings of the 5th Workshop on Natural Logic Meets Machine
  Learning (NALOMA)
Journal-ref: Proceedings of the 5th Workshop on Natural Logic Meets Machine
  Learning (NALOMA), pages 18-32, 2025
\\
  Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.
\\ ( https://arxiv.org/abs/2509.13734 ,  344kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13775
Date: Wed, 17 Sep 2025 07:45:09 GMT   (357kb)

Title: Exploring Data and Parameter Efficient Strategies for Arabic Dialect
  Identifications
Authors: Vani Kanjirangat, Ljiljana Dolamic, Fabio Rinaldi
Categories: cs.CL cs.AI
Comments: 4 main pages, 4 additional, 5 figures
\\
  This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.
\\ ( https://arxiv.org/abs/2509.13775 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13790
Date: Wed, 17 Sep 2025 07:58:59 GMT   (312kb)

Title: Teaching According to Talents! Instruction Tuning LLMs with
  Competence-Aware Curriculum Learning
Authors: Yangning Li, Tingwei Lu, Yinghui Li, Yankai Chen, Wei-Chieh Huang,
  Wenhao Jiang, Hui Wang, Hai-Tao Zheng, Philip S.Yu
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Findings
\\
  Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.
\\ ( https://arxiv.org/abs/2509.13790 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13803
Date: Wed, 17 Sep 2025 08:17:28 GMT   (55kb)

Title: Measuring Gender Bias in Job Title Matching for Grammatical Gender
  Languages
Authors: Laura Garc\'ia-Sardi\~na, Hermenegildo Fabregat, Daniel Deniz and
  Rabih Zbib
Categories: cs.CL
\\
  This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.
\\ ( https://arxiv.org/abs/2509.13803 ,  55kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13813
Date: Wed, 17 Sep 2025 08:28:07 GMT   (11353kb)

Title: Geometric Uncertainty for Detecting and Correcting Hallucinations in
  LLMs
Authors: Edward Phillips, Sean Wu, Soheila Molaei, Danielle Belgrave, Anshul
  Thakur, David Clifton
Categories: cs.CL
\\
  Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.
\\ ( https://arxiv.org/abs/2509.13813 ,  11353kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13814
Date: Wed, 17 Sep 2025 08:29:57 GMT   (182kb)

Title: Findings of the Third Automatic Minuting (AutoMin) Challenge
Authors: Kartik Shinde, Laurent Besacier, Ondrej Bojar, Thibaut Thonet, and
  Tirthankar Ghosal
Categories: cs.CL
Comments: Automin 2025 Website: https://ufal.github.io/automin-2025/
\\
  This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.
\\ ( https://arxiv.org/abs/2509.13814 ,  182kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13835
Date: Wed, 17 Sep 2025 09:05:37 GMT   (1433kb)

Title: Large Language Models Discriminate Against Speakers of German Dialects
Authors: Minh Duc Bui, Carolin Holtermann, Valentin Hofmann, Anne Lauscher,
  Katharina von der Wense
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Main
\\
  Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.
\\ ( https://arxiv.org/abs/2509.13835 ,  1433kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13869
Date: Wed, 17 Sep 2025 09:58:28 GMT   (619kb)

Title: Do LLMs Align Human Values Regarding Social Biases? Judging and
  Explaining Social Biases with LLMs
Authors: Yang Liu, Chenhui Chu
Categories: cs.CL
Comments: 38 pages, 31 figures
\\
  Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.
\\ ( https://arxiv.org/abs/2509.13869 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13879
Date: Wed, 17 Sep 2025 10:14:56 GMT   (385kb)

Title: Combining Evidence and Reasoning for Biomedical Fact-Checking
Authors: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione,
  Vincenzo Moscato
Categories: cs.CL cs.AI cs.IR
Journal-ref: Proceedings of the 48th International ACM SIGIR Conference on
  Research and Development in Information Retrieval, 2025
DOI: 10.1145/3726302.3729931
\\
  Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical sys- tems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminol- ogy, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combin- ing Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language mod- els with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of halluci-
nations, ensuring that generated outputs are grounded in veri- fiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the- art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.
\\ ( https://arxiv.org/abs/2509.13879 ,  385kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13888
Date: Wed, 17 Sep 2025 10:31:09 GMT   (1428kb)

Title: Combating Biomedical Misinformation through Multi-modal Claim Detection
  and Evidence-based Verification
Authors: Mariano Barone, Antonio Romano, Giuseppe Riccio, Marco Postiglione,
  Vincenzo Moscato
Categories: cs.CL cs.AI cs.IR
Journal-ref: SIGIR '25: Proceedings of the 48th International ACM SIGIR
  Conference on Research and Development in Information Retrieval, 2025
DOI: 10.1145/3726302.373015
\\
  Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER
\\ ( https://arxiv.org/abs/2509.13888 ,  1428kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13905
Date: Wed, 17 Sep 2025 11:11:27 GMT   (88kb)

Title: Do Large Language Models Understand Word Senses?
Authors: Domenico Meconi, Simone Stirpe, Federico Martelli, Leonardo Lavalle,
  Roberto Navigli
Categories: cs.CL cs.AI
Comments: 20 pages, to be published in EMNLP2025
\\
  Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.
\\ ( https://arxiv.org/abs/2509.13905 ,  88kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13930
Date: Wed, 17 Sep 2025 12:58:18 GMT   (6238kb)

Title: Linguistic Nepotism: Trading-off Quality for Language Preference in
  Multilingual RAG
Authors: Dayeon Ki, Marine Carpuat, Paul McNamee, Daniel Khashabi, Eugene Yang,
  Dawn Lawrie, Kevin Duh
Categories: cs.CL
Comments: 33 pages, 20 figures
\\
  Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.
\\ ( https://arxiv.org/abs/2509.13930 ,  6238kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13980
Date: Wed, 17 Sep 2025 13:52:45 GMT   (102kb)

Title: Long-context Reference-based MT Quality Estimation
Authors: Sami Ul Haq, Chinonso Cynthia Osuji, Sheila Castilho, Brian Davis
Categories: cs.CL cs.LG
\\
  In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.
\\ ( https://arxiv.org/abs/2509.13980 ,  102kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13990
Date: Wed, 17 Sep 2025 14:00:51 GMT   (1156kb)

Title: Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency
Authors: Colin Hong, Xu Guo, Anand Chaanan Singh, Esha Choukse, Dmitrii
  Ustiugov
Categories: cs.CL cs.AI cs.LG
Comments: Accepted by EMNLP 2025 (Oral), 9 pages
ACM-class: I.2.7
\\
  Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.
\\ ( https://arxiv.org/abs/2509.13990 ,  1156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14004
Date: Wed, 17 Sep 2025 14:14:05 GMT   (1532kb)

Title: Early Stopping Chain-of-thoughts in Large Language Models
Authors: Minjia Mao, Bowen Yin, Yu Zhu, Xiao Fang
Categories: cs.CL
\\
  Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.
\\ ( https://arxiv.org/abs/2509.14004 ,  1532kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14008
Date: Wed, 17 Sep 2025 14:19:28 GMT   (3192kb)

Title: Hala Technical Report: Building Arabic-Centric Instruction & Translation
  Models at Scale
Authors: Hasan Abed Al Kader Hammoud, Mohammad Zbeeb, Bernard Ghanem
Categories: cs.CL cs.AI cs.LG
Comments: Technical Report
\\
  We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.
\\ ( https://arxiv.org/abs/2509.14008 ,  3192kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14023
Date: Wed, 17 Sep 2025 14:27:17 GMT   (1027kb)

Title: Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality
Authors: Sami Ul Haq, Sheila Castilho, Yvette Graham
Categories: cs.CL cs.HC
Comments: Accepted at WMT2025 (ENNLP) for oral presented
\\
  Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.
\\ ( https://arxiv.org/abs/2509.14023 ,  1027kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14031
Date: Wed, 17 Sep 2025 14:33:17 GMT   (2904kb)

Title: You Are What You Train: Effects of Data Composition on Training
  Context-aware Machine Translation Models
Authors: Pawe{\l} M\k{a}ka, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP 2025 main conference
\\
  Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.
\\ ( https://arxiv.org/abs/2509.14031 ,  2904kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14034
Date: Wed, 17 Sep 2025 14:34:27 GMT   (1280kb)

Title: Enhancing Multi-Agent Debate System Performance via Confidence
  Expression
Authors: Zijie Lin and Bryan Hooi
Categories: cs.CL
Comments: EMNLP'25 Findings
\\
  Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.
\\ ( https://arxiv.org/abs/2509.14034 ,  1280kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14036
Date: Wed, 17 Sep 2025 14:37:59 GMT   (1933kb)

Title: SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting
  for Question-Based Sign Language Translation
Authors: Zekang Liu, Wei Feng, Fanhua Shang, Lianyu Hu, Jichao Feng, Liqing Gao
Categories: cs.CL cs.AI
\\
  Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.
\\ ( https://arxiv.org/abs/2509.14036 ,  1933kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14128
Date: Wed, 17 Sep 2025 16:08:46 GMT   (1655kb)

Title: Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance
  Models for Multilingual ASR and AST
Authors: Monica Sekoyan, Nithin Rao Koluguri, Nune Tadevosyan, Piotr Zelasko,
  Travis Bartley, Nick Karpov, Jagadeesh Balam, Boris Ginsburg
Categories: cs.CL eess.AS
Comments: Mini Version of it Submitted to ICASSP 2026
\\
  This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.
\\ ( https://arxiv.org/abs/2509.14128 ,  1655kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14161
Date: Wed, 17 Sep 2025 16:45:22 GMT   (357kb)

Title: CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset
Authors: Brian Yan, Injy Hamed, Shuichiro Shimizu, Vasista Lodagala, William
  Chen, Olga Iakovenko, Bashar Talafha, Amir Hussein, Alexander Polok, Kalvin
  Chang, Dominik Klement, Sara Althubaiti, Puyuan Peng, Matthew Wiesner, Thamar
  Solorio, Ahmed Ali, Sanjeev Khudanpur, Shinji Watanabe, Chih-Chen Chen, Zhen
  Wu, Karim Benharrak, Anuj Diwan, Samuele Cornell, Eunjung Yeo, Kwanghee Choi,
  Carlos Carvalho, Karen Rosero
Categories: cs.CL cs.SD eess.AS
\\
  We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.
\\ ( https://arxiv.org/abs/2509.14161 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14171
Date: Wed, 17 Sep 2025 16:56:27 GMT   (2167kb)

Title: AssoCiAm: A Benchmark for Evaluating Association Thinking while
  Circumventing Ambiguity
Authors: Yifan Liu, Wenkuan Zhao, Shanshan Zhong, Jinghui Qin, Mingfu Liang,
  Zhongzhan Huang, Wushao Wen
Categories: cs.CL
\\
  Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.
\\ ( https://arxiv.org/abs/2509.14171 ,  2167kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14180
Date: Wed, 17 Sep 2025 17:12:38 GMT   (1024kb)

Title: Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation
  Framework for Personal Finance LLMs
Authors: Akhil Theerthala
Categories: cs.CL cs.AI cs.LG
Comments: 24 pages, 11 figures. The paper presents a novel framework for
  generating a personal finance dataset. The resulting fine-tuned model and
  dataset are publicly available
MSC-class: 68T50
ACM-class: I.2.7; J.4
\\
  Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.
\\ ( https://arxiv.org/abs/2509.14180 ,  1024kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14197
Date: Wed, 17 Sep 2025 17:31:57 GMT   (11550kb)

Title: Framing Migration: A Computational Analysis of UK Parliamentary
  Discourse
Authors: Vahid Ghafouri, Robert McNeil, Teodor Yankov, Madeleine Sumption, Luc
  Rocher, Scott A. Hale, Adam Mahdi
Categories: cs.CL cs.CY
\\
  We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.
\\ ( https://arxiv.org/abs/2509.14197 ,  11550kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14233
Date: Wed, 17 Sep 2025 17:59:21 GMT   (3694kb)

Title: Apertus: Democratizing Open and Compliant LLMs for Global Language
  Environments
Authors: Alejandro Hern\'andez-Cano, Alexander H\"agele, Allen Hao Huang,
  Angelika Romanou, Antoni-Joan Solergibert, Barna Pasztor, Bettina Messmer,
  Dhia Garbaya, Eduard Frank \v{D}urech, Ido Hakimi, Juan Garc\'ia Giraldo,
  Mete Ismayilzada, Negar Foroutan, Skander Moalla, Tiancheng Chen, Vinko
  Sabol\v{c}ec, Yixuan Xu, Michael Aerni, Badr AlKhamissi, Ines Altemir
  Marinas, Mohammad Hossein Amani, Matin Ansaripour, Ilia Badanin, Harold
  Benoit, Emanuela Boros, Nicholas Browning, Fabian B\"osch, Maximilian
  B\"other, Niklas Canova, Camille Challier, Clement Charmillot, Jonathan
  Coles, Jan Deriu, Arnout Devos, Lukas Drescher, Daniil Dzenhaliou, Maud
  Ehrmann, Dongyang Fan, Simin Fan, Silin Gao, Miguel Gila, Mar\'ia Grandury,
  Diba Hashemi, Alexander Hoyle, Jiaming Jiang, Mark Klein, Andrei Kucharavy,
  Anastasiia Kucherenko, et al. (53 additional authors not shown)
Categories: cs.CL cs.AI cs.LG
\\
  We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.
\\ ( https://arxiv.org/abs/2509.14233 ,  3694kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13338
Date: Thu, 11 Sep 2025 13:12:22 GMT   (10498kb)

Title: Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks
Authors: Hassan Gharoun, Mohammad Sadegh Khorshidi, Kasra Ranjbarigderi, Fang
  Chen, and Amir H. Gandomi
Categories: cs.CV cs.AI cs.LG cs.NE
Comments: 15 pages, 4 figures, 3 tables
MSC-class: 68T07, 68T09
\\
  This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.
\\ ( https://arxiv.org/abs/2509.13338 ,  10498kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13353
Date: Sun, 14 Sep 2025 09:55:00 GMT   (25992kb)

Title: Hybrid Quantum-Classical Model for Image Classification
Authors: Muhammad Adnan Shahzad
Categories: cs.CV cs.AI cs.LG
\\
  This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.
\\ ( https://arxiv.org/abs/2509.13353 ,  25992kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13361
Date: Mon, 15 Sep 2025 13:35:43 GMT   (2856kb)

Title: Research on Expressway Congestion Warning Technology Based on
  YOLOv11-DIoU and GRU-Attention
Authors: Tong Yulin, Liang Xuechen
Categories: cs.CV
\\
  Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.
\\ ( https://arxiv.org/abs/2509.13361 ,  2856kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13366
Date: Mon, 15 Sep 2025 18:53:22 GMT   (765kb)

Title: Parking Space Ground Truth Test Automation by Artificial Intelligence
  Using Convolutional Neural Networks
Authors: Tony Rohe, Martin Margreiter and Markus Moertl
Categories: cs.CV
Comments: 10 pages, 5 figures
MSC-class: 68U99
ACM-class: J.2
\\
  This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.
\\ ( https://arxiv.org/abs/2509.13366 ,  765kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13375
Date: Tue, 16 Sep 2025 06:11:02 GMT   (8627kb)

Title: An Empirical Analysis of VLM-based OOD Detection: Mechanisms,
  Advantages, and Sensitivity
Authors: Yuxiao Lee, Xiaofeng Cao, Wei Ye, Jiangchao Yao, Jingkuan Song, Heng
  Tao Shen
Categories: cs.CV cs.AI
\\
  Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.
\\ ( https://arxiv.org/abs/2509.13375 ,  8627kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13385
Date: Tue, 16 Sep 2025 10:14:47 GMT   (8888kb)

Title: Curvature as a tool for evaluating dimensionality reduction and
  estimating intrinsic dimension
Authors: Charlotte Beylier, Parvaneh Joharinad, J\"urgen Jost, Nahid Torbati
Categories: cs.CV cs.DM cs.LG
Comments: 31 pages, 14 figures
MSC-class: 51K05 (primary) 57-08, 53Z50, 55U10 (secondary)
ACM-class: G.2.2
\\
  Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.
\\ ( https://arxiv.org/abs/2509.13385 ,  8888kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13388
Date: Tue, 16 Sep 2025 13:58:07 GMT   (18190kb)

Title: Landcover classification and change detection using remote sensing and
  machine learning: a case study of Western Fiji
Authors: Yadvendra Gurjar, Ruoni Wan, Ehsan Farahbakhsh, Rohitash Chandra
Categories: cs.CV cs.AI stat.AP
\\
  As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.
\\ ( https://arxiv.org/abs/2509.13388 ,  18190kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13396
Date: Tue, 16 Sep 2025 17:17:03 GMT   (1216kb)

Title: Real-Time Detection and Tracking of Foreign Object Intrusions in Power
  Systems via Feature-Based Edge Intelligence
Authors: Xinan Wang, Di Shi, Fengyu Wang
Categories: cs.CV cs.SY eess.SY
Comments: 12 page Journal paper, accepted by IEEE Open Access Journal of Power
  and Energy
\\
  This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.
\\ ( https://arxiv.org/abs/2509.13396 ,  1216kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13399
Date: Tue, 16 Sep 2025 17:45:39 GMT   (45428kb)

Title: EdiVal-Agent: An Object-Centric Framework for Automated, Scalable,
  Fine-Grained Evaluation of Multi-Turn Editing
Authors: Tianyu Chen, Yasi Zhang, Zhi Zhang, Peiyu Yu, Shu Wang, Zhendong Wang,
  Kevin Lin, Xiaofei Wang, Zhengyuan Yang, Linjie Li, Chung-Ching Lin, Jianwen
  Xie, Oscar Leong, Lijuan Wang, Ying Nian Wu, Mingyuan Zhou
Categories: cs.CV cs.AI cs.LG
Comments: Tianyu Chen and Yasi Zhang contributed equally; Oscar Leong, Lijuan
  Wang, Ying Nian Wu, and Mingyuan Zhou advised equally
\\
  Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision--language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.
\\ ( https://arxiv.org/abs/2509.13399 ,  45428kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13414
Date: Tue, 16 Sep 2025 18:00:14 GMT   (9782kb)

Title: MapAnything: Universal Feed-Forward Metric 3D Reconstruction
Authors: Nikhil Keetha, Norman M\"uller, Johannes Sch\"onberger, Lorenzo Porzi,
  Yuchen Zhang, Tobias Fischer, Arno Knapitsch, Duncan Zauss, Ethan Weber,
  Nelson Antunes, Jonathon Luiten, Manuel Lopez-Antequera, Samuel Rota Bul\`o,
  Christian Richardt, Deva Ramanan, Sebastian Scherer, Peter Kontschieder
Categories: cs.CV cs.AI cs.LG cs.RO
Comments: Project Page: https://map-anything.github.io/
\\
  We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.
\\ ( https://arxiv.org/abs/2509.13414 ,  9782kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13474
Date: Tue, 16 Sep 2025 19:17:54 GMT   (694kb)

Title: Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot
  Localization
Authors: Yujia Lin, Nicholas Evans
Categories: cs.CV
\\
  Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.
\\ ( https://arxiv.org/abs/2509.13474 ,  694kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13482
Date: Tue, 16 Sep 2025 19:27:58 GMT   (13602kb)

Title: Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice
  Vector Quantization
Authors: Hao Xu, Xiaolin Wu, Xi Zhang
Categories: cs.CV
Comments: Code available at https://github.com/hxu160/SALVQ
\\
  3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.
\\ ( https://arxiv.org/abs/2509.13482 ,  13602kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13484
Date: Tue, 16 Sep 2025 19:31:40 GMT   (11486kb)

Title: MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes
Authors: Liu Liu, Alexandra Kudaeva, Marco Cipriano, Fatimeh Al Ghannam, Freya
  Tan, Gerard de Melo, and Andres Sevtsuk
Categories: cs.CV cs.CY
Comments: 13 pages, 4 figures, under review at AAAI 2026
\\
  Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.
\\ ( https://arxiv.org/abs/2509.13484 ,  11486kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13496
Date: Tue, 16 Sep 2025 19:52:12 GMT   (7424kb)

Title: BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden
  Social Biases in Text-to-Image Generation
Authors: Rajatsubhra Chakraborty, Xujun Che, Depeng Xu, Cori Faklaris, Xi Niu,
  Shuhan Yuan
Categories: cs.CV cs.LG
\\
  Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not neces- sarily guarantee concept
representations to be disentangled post- mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable dif- fusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribu- tion maps of
these concepts, we quantify the spatial demographics- semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness dis- covery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU dur- ing the denoising process. Our findings show that existing
fairness interventions may reduce the output distributional gap but often fail
to disentangle concept-level coupling, whereas our mitigation method can
mitigate concept entanglement in image generation while complementing
distributional bias mitigation.
\\ ( https://arxiv.org/abs/2509.13496 ,  7424kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13504
Date: Tue, 16 Sep 2025 20:06:46 GMT   (12390kb)

Title: LivePyxel: Accelerating image annotations with a Python-integrated
  webcam live streaming
Authors: Uriel Garcilazo-Cruz, Joseph O. Okeme, Rodrigo A. Vargas--Hern\'andez
Categories: cs.CV
Comments: 8 pages, 10 figures, SM, 5 pages, 4 figures
\\
  The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel
\\ ( https://arxiv.org/abs/2509.13504 ,  12390kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13506
Date: Tue, 16 Sep 2025 20:11:48 GMT   (43410kb)

Title: DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised
  H-Transform
Authors: Xingzi Xu, Qi Li, Shuwen Qiu, Julien Han, Karim Bouyarmane
Categories: cs.CV
Comments: Published in 2025 CVPR Workshop
\\
  Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.
\\ ( https://arxiv.org/abs/2509.13506 ,  43410kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13507
Date: Tue, 16 Sep 2025 20:12:33 GMT   (4567kb)

Title: Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian
  Recognition in Autonomous Driving
Authors: Artem Savkin and Thomas Lapotre and Kevin Strauss and Uzair Akbar and
  Federico Tombari
Categories: cs.CV
DOI: 10.1109/ICRA40945.2020.9197024
\\
  In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.
\\ ( https://arxiv.org/abs/2509.13507 ,  4567kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13508
Date: Tue, 16 Sep 2025 20:13:48 GMT   (709kb)

Title: FunKAN: Functional Kolmogorov-Arnold Network for Medical Image
  Enhancement and Segmentation
Authors: Maksim Penkin, Andrey Krylov (Lomonosov Moscow State University)
Categories: cs.CV
Comments: 9 pages, 5 figures, submitted to the Fortieth AAAI Conference on
  Artificial Intelligence (AAAI-26)
ACM-class: I.4.3; I.4.6
\\
  Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.
\\ ( https://arxiv.org/abs/2509.13508 ,  709kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13515
Date: Tue, 16 Sep 2025 20:20:05 GMT   (1154kb)

Title: Multimodal Hate Detection Using Dual-Stream Graph Neural Networks
Authors: Jiangbei Yue, Shuonan Yang, Tailin Chen, Jianbo Jiao and Zeyu Fu
Categories: cs.CV
\\
  Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.
\\ ( https://arxiv.org/abs/2509.13515 ,  1154kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13525
Date: Tue, 16 Sep 2025 20:40:22 GMT   (7481kb)

Title: ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using
  Diffusion Priors
Authors: Romain Hardy, Tyler Berzin, Pranav Rajpurkar
Categories: cs.CV cs.AI cs.LG
Comments: 12 pages, 8 figures
\\
  Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.
\\ ( https://arxiv.org/abs/2509.13525 ,  7481kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13536
Date: Tue, 16 Sep 2025 21:03:55 GMT   (6108kb)

Title: MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM
Authors: Yinlong Bai, Hongxin Zhang, Sheng Zhong, Junkai Niu, Hai Li, Yijia He,
  Yi Zhou
Categories: cs.CV
\\
  Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.
\\ ( https://arxiv.org/abs/2509.13536 ,  6108kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13577
Date: Tue, 16 Sep 2025 22:37:21 GMT   (5646kb)

Title: Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for
  Trajectory Prediction in Autonomous Vehicles
Authors: Tongfei Guo and Lili Su
Categories: cs.CV cs.LG cs.RO
Comments: 8 pages, 7 figures
\\
  Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors--even on in-distribution samples--exhibit mode-dependent
distributions that evolve over time with dataset-specific dynamics. By
explicitly modeling these error modes, our method achieves substantial
improvements in both detection delay and false alarm rates. Comprehensive
experiments on established trajectory prediction benchmarks show that our
framework significantly outperforms prior UQ- and vision-based OOD approaches
in both accuracy and computational efficiency, offering a practical path toward
reliable, driving-aware autonomy.
\\ ( https://arxiv.org/abs/2509.13577 ,  5646kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13586
Date: Tue, 16 Sep 2025 23:00:16 GMT   (551kb)

Title: Annotating Satellite Images of Forests with Keywords from a Specialized
  Corpus in the Context of Change Detection
Authors: Nathalie Neptune, Josiane Mothe
Categories: cs.CV cs.CL cs.IR cs.MM
ACM-class: I.2; I.4; I.7; H.3
Journal-ref: Proceedings of the 20th International Conference on Content-based
  Multimedia Indexing 2023 Sep 20 (pp. 14-20)
DOI: 10.1145/3617233.3617242
\\
  The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.
\\ ( https://arxiv.org/abs/2509.13586 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13590
Date: Tue, 16 Sep 2025 23:15:44 GMT   (1696kb)

Title: Intelligent Healthcare Imaging Platform An VLM-Based Framework for
  Automated Medical Image Analysis and Clinical Report Generation
Authors: Samer Al-Hamadani
Categories: cs.CV cs.AI
Comments: 32 pages, 14 figures, 6 tables
\\
  The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.
\\ ( https://arxiv.org/abs/2509.13590 ,  1696kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13605
Date: Wed, 17 Sep 2025 00:29:27 GMT   (22969kb)

Title: A Generalization of CLAP from 3D Localization to Image Processing, A
  Connection With RANSAC & Hough Transforms
Authors: Ruochen Hou, Gabriel I. Fernandez, Alex Xu, and Dennis W. Hong
Categories: cs.CV cs.RO
\\
  In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.
\\ ( https://arxiv.org/abs/2509.13605 ,  22969kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13629
Date: Wed, 17 Sep 2025 01:56:35 GMT   (1078kb)

Title: SAMIR, an efficient registration framework via robust feature learning
  from SAM
Authors: Yue He, Min Liu, Qinghao Liu, Jiazheng Wang, Yaonan Wang, Hang Zhang,
  Xiang Chen
Categories: cs.CV
\\
  Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.
\\ ( https://arxiv.org/abs/2509.13629 ,  1078kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13631
Date: Wed, 17 Sep 2025 01:57:13 GMT   (1005kb)

Title: Federated Learning for Deforestation Detection: A Distributed Approach
  with Satellite Imagery
Authors: Yuvraj Dutta, Aaditya Sikder, and Basabdatta Palit
Categories: cs.CV cs.DC
Comments: 6 pages, 7 figures, accepted at IEEE INDISCON 2025
MSC-class: 14J60
ACM-class: F.2.2; I.2.7
\\
  Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.
\\ ( https://arxiv.org/abs/2509.13631 ,  1005kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13652
Date: Wed, 17 Sep 2025 02:57:34 GMT   (3840kb)

Title: Gaussian Alignment for Relative Camera Pose Estimation via Single-View
  Reconstruction
Authors: Yumin Li and Dylan Campbell
Categories: cs.CV
Comments: 12 pages, 4 figures, accepted by AJCAI 2025
ACM-class: I.4.8; I.4.5
\\
  Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.
\\ ( https://arxiv.org/abs/2509.13652 ,  3840kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13662
Date: Wed, 17 Sep 2025 03:31:41 GMT   (6156kb)

Title: Deep Lookup Network
Authors: Yulan Guo, Longguang Wang, Wendong Mao, Xiaoyu Dong, Yingqian Wang, Li
  Liu, Wei An
Categories: cs.CV cs.AI
\\
  Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).
\\ ( https://arxiv.org/abs/2509.13662 ,  6156kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13676
Date: Wed, 17 Sep 2025 04:04:08 GMT   (4773kb)

Title: Re-purposing SAM into Efficient Visual Projectors for MLLM-Based
  Referring Image Segmentation
Authors: Xiaobo Yang and Xiaojin Gong
Categories: cs.CV cs.AI
\\
  Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.
\\ ( https://arxiv.org/abs/2509.13676 ,  4773kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13681
Date: Wed, 17 Sep 2025 04:26:36 GMT   (3071kb)

Title: FishBEV: Distortion-Resilient Bird's Eye View Segmentation with
  Surround-View Fisheye Cameras
Authors: Hang Li, Dianmo Sheng, Qiankun Dong, Zichun Wang, Zhiwei Xu, Tao Li
Categories: cs.CV
Comments: 8 pages, 4 figures
\\
  As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.
\\ ( https://arxiv.org/abs/2509.13681 ,  3071kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13687
Date: Wed, 17 Sep 2025 04:33:54 GMT   (79460kb)

Title: Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging
  Classification
Authors: Kaniz Fatema, Emad A. Mohammed, and Sukhjit Singh Sehra
Categories: cs.CV
\\
  Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.
\\ ( https://arxiv.org/abs/2509.13687 ,  79460kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13711
Date: Wed, 17 Sep 2025 05:39:34 GMT   (6512kb)

Title: StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion
  Models
Authors: Qiuyu Tang and Joshua Krinsky and Aparna Bharati
Categories: cs.CV
\\
  The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.
\\ ( https://arxiv.org/abs/2509.13711 ,  6512kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13713
Date: Wed, 17 Sep 2025 05:51:07 GMT   (18611kb)

Title: UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation
  with Visual Odometry
Authors: Tae-Wook Um, Ki-Hyeon Kim, Hyun-Duck Choi and Hyo-Sung Ahn
Categories: cs.CV
\\
  Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.
\\ ( https://arxiv.org/abs/2509.13713 ,  18611kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13722
Date: Wed, 17 Sep 2025 06:17:23 GMT   (5124kb)

Title: Mitigating Query Selection Bias in Referring Video Object Segmentation
Authors: Dingwei Zhang, Dong Zhang, Jinhui Tang
Categories: cs.CV cs.AI
\\
  Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.
\\ ( https://arxiv.org/abs/2509.13722 ,  5124kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13747
Date: Wed, 17 Sep 2025 07:00:51 GMT   (6064kb)

Title: Improving Generalized Visual Grounding with Instance-aware Joint
  Learning
Authors: Ming Dai, Wenxuan Cheng, Jiang-Jiang Liu, Lingfeng Yang, Zhenhua Feng,
  Wankou Yang, and Jingdong Wang
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI) in September 2025
Journal-ref: IEEE Transactions on Pattern Analysis and Machine Intelligence
  (TPAMI2025)
DOI: 10.1109/TPAMI.2025.3607387
\\
  Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.
\\ ( https://arxiv.org/abs/2509.13747 ,  6064kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13754
Date: Wed, 17 Sep 2025 07:12:05 GMT   (1310kb)

Title: Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person
  Retrieval
Authors: Hao Yin, Xin Man, Feiyu Chen, Jie Shao, Heng Tao Shen
Categories: cs.CV
\\
  Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.
\\ ( https://arxiv.org/abs/2509.13754 ,  1310kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13756
Date: Wed, 17 Sep 2025 07:12:51 GMT   (1602kb)

Title: Controllable-Continuous Color Editing in Diffusion Model via Color
  Mapping
Authors: Yuqi Yang, Dongliang Chang, Yuanchen Fang, Yi-Zhe SonG, Zhanyu Ma, and
  Jun Guo
Categories: cs.CV
\\
  In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.
\\ ( https://arxiv.org/abs/2509.13756 ,  1602kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13760
Date: Wed, 17 Sep 2025 07:16:06 GMT   (4826kb)

Title: Iterative Prompt Refinement for Safer Text-to-Image Generation
Authors: Jinwoo Jeon, JunHyeok Oh, Hayeong Lee, Byung-Jun Lee
Categories: cs.CV
\\
  Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.
\\ ( https://arxiv.org/abs/2509.13760 ,  4826kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13762
Date: Wed, 17 Sep 2025 07:16:51 GMT   (8941kb)

Title: Task-Aware Image Signal Processor for Advanced Visual Perception
Authors: Kai Chen, Jin Xiao, Leheng Zhang, Kexuan Shi, Shuhang Gu
Categories: cs.CV
\\
  In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.
\\ ( https://arxiv.org/abs/2509.13762 ,  8941kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13766
Date: Wed, 17 Sep 2025 07:24:47 GMT   (16214kb)

Title: NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World
  Benchmark Dataset
Authors: Huichun Liu and Xiaosong Li and Yang Liu and Xiaoqi Cheng and Haishu
  Tan
Categories: cs.CV
\\
  Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.
\\ ( https://arxiv.org/abs/2509.13766 ,  16214kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13767
Date: Wed, 17 Sep 2025 07:32:00 GMT   (5706kb)

Title: VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in
  Real-time MRI
Authors: Daiqi Liu, Tom\'as Arias-Vergara, Johannes Enk, Fangxu Xing, Maureen
  Stone, Jerry L. Prince, Jana Hutter, Andreas Maier, Jonghye Woo, Paula Andrea
  P\'erez-Toro
Categories: cs.CV
Comments: Preprint submitted to ICASSP
\\
  Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.
\\ ( https://arxiv.org/abs/2509.13767 ,  5706kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13768
Date: Wed, 17 Sep 2025 07:32:15 GMT   (1572kb)

Title: Generative Image Coding with Diffusion Prior
Authors: Jianhui Chang
Categories: cs.CV
\\
  As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.
\\ ( https://arxiv.org/abs/2509.13768 ,  1572kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13769
Date: Wed, 17 Sep 2025 07:35:39 GMT   (5440kb)

Title: AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for
  Autonomous Driving
Authors: Yuechen Luo, Fang Li, Shaoqing Xu, Zhiyi Lai, Lei Yang, Qimao Chen,
  Ziang Luo, Zixun Xie, Shengyin Jiang, Jiaxin Liu, Long Chen, Bing Wang,
  Zhi-xin Yang
Categories: cs.CV
\\
  While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.
\\ ( https://arxiv.org/abs/2509.13769 ,  5440kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13776
Date: Wed, 17 Sep 2025 07:46:07 GMT   (2115kb)

Title: Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and
  Mesoscopic Semantics for Deepfake Detection and Localization
Authors: Chao Shuai, Gaojian Wang, Kun Pan, Tong Wu, Fanli Jin, Haohan Tan,
  Mengxiang Li, Zhenguang Liu, Feng Lin, Kui Ren
Categories: cs.CV
Comments: The 3rd Place, IJCAI 2025 Workshop on Deepfake Detection,
  Localization, and Interpretability
\\
  While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.
\\ ( https://arxiv.org/abs/2509.13776 ,  2115kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13784
Date: Wed, 17 Sep 2025 07:55:37 GMT   (5312kb)

Title: CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate
  Scheduling
Authors: Hanfang Liang, Bing Wang, Shizhen Zhang, Wen Jiang, Yizhuo Yang,
  Weixiang Guo, Shenghai Yuan
Categories: cs.CV
Comments: 8 pages, 6 figures
\\
  Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.
\\ ( https://arxiv.org/abs/2509.13784 ,  5312kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13789
Date: Wed, 17 Sep 2025 07:58:36 GMT   (27225kb)

Title: BWCache: Accelerating Video Diffusion Transformers through Block-Wise
  Caching
Authors: Hanshuai Cui and Zhiqing Tang and Zhifei Xu and Zhi Yao and Wenyi Zeng
  and Weijia Jia
Categories: cs.CV cs.AI
\\
  Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.
\\ ( https://arxiv.org/abs/2509.13789 ,  27225kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13792
Date: Wed, 17 Sep 2025 08:03:05 GMT   (9138kb)

Title: Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust
  Spacecraft 6-DoF Pose Estimation
Authors: Inder Pal Singh, Nidhal Eddine Chenni, Abd El Rahman Shabayek,
  Arunkumar Rathinam, Djamila Aouada
Categories: cs.CV cs.AI
\\
  Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.
\\ ( https://arxiv.org/abs/2509.13792 ,  9138kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13795
Date: Wed, 17 Sep 2025 08:05:36 GMT   (43024kb)

Title: SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient
  4-DoF UAV Localization in GNSS-Denied Environments
Authors: Jiayu Yuan, Ming Dai, Enhui Zheng, Chao Su, Nanxing Chen, Qiming Hu,
  Shibo Zhu and Yibin Cao
Categories: cs.CV
\\
  Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.
\\ ( https://arxiv.org/abs/2509.13795 ,  43024kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13801
Date: Wed, 17 Sep 2025 08:16:05 GMT   (531kb)

Title: Masked Feature Modeling Enhances Adaptive Segmentation
Authors: Wenlve Zhou, Zhiheng Zhou, Tiantao Xian, Yikui Zhai, Weibin Wu, Biyun
  Ma
Categories: cs.CV
\\
  Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.
\\ ( https://arxiv.org/abs/2509.13801 ,  531kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13809
Date: Wed, 17 Sep 2025 08:22:23 GMT   (581kb)

Title: Data-Efficient Spectral Classification of Hyperspectral Data Using
  MiniROCKET and HDC-MiniROCKET
Authors: Nick Theisen, Kenny Schlegel, Dietrich Paulus, Peer Neubert
Categories: cs.CV
Comments: Accepted for publication at IEEE CASE 2025
\\
  The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case
\\ ( https://arxiv.org/abs/2509.13809 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13834
Date: Wed, 17 Sep 2025 09:03:04 GMT   (22180kb)

Title: Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology
  Segmentation
Authors: Nguyen Lan Vi Vu, Thanh-Huy Nguyen, Thien Nguyen, Daisuke Kihara,
  Tianyang Wang, Xingjian Li, Min Xu
Categories: cs.CV
Comments: Accepted to BMVC 2025
\\
  Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.
\\ ( https://arxiv.org/abs/2509.13834 ,  22180kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13836
Date: Wed, 17 Sep 2025 09:08:05 GMT   (356kb)

Title: Diving into Mitigating Hallucinations from a Vision Perspective for
  Large Vision-Language Models
Authors: Weihang Wang, Xinhao Li, Ziyue Wang, Yan Pang, Jielei Zhang, Peiyi Li,
  Qiang Zhang, Longwen Gao
Categories: cs.CV cs.CL
Comments: Accepted by EMNLP2025 Finding
\\
  Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.
\\ ( https://arxiv.org/abs/2509.13836 ,  356kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13846
Date: Wed, 17 Sep 2025 09:23:52 GMT   (2103kb)

Title: Consistent View Alignment Improves Foundation Models for 3D Medical
  Image Segmentation
Authors: Puru Vaish, Felix Meister, Tobias Heimann, Christoph Brune, Jelmer M.
  Wolterink
Categories: cs.CV cs.LG
Comments: MICCAI 2025: 1st Place in Transformer track and 2nd Place in
  Convolution track of SSL3D-OpenMind challenge
\\
  Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.
\\ ( https://arxiv.org/abs/2509.13846 ,  2103kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13848
Date: Wed, 17 Sep 2025 09:24:40 GMT   (7586kb)

Title: SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation
Authors: Jiayi Pan, Jiaming Xu, Yongkang Zhou, Guohao Dai
Categories: cs.CV cs.LG
\\
  Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.
\\ ( https://arxiv.org/abs/2509.13848 ,  7586kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13858
Date: Wed, 17 Sep 2025 09:48:39 GMT   (4823kb)

Title: EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics
Authors: Qianxin Xia, Jiawei Du, Guoming Lu, Zhiyong Shu, Jielei Wang
Categories: cs.CV
\\
  Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.
\\ ( https://arxiv.org/abs/2509.13858 ,  4823kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13863
Date: Wed, 17 Sep 2025 09:53:47 GMT   (7203kb)

Title: LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray
  Laminography Reconstruction
Authors: Chu Chen, Ander Biguri, Jean-Michel Morel, Raymond H. Chan,
  Carola-Bibiane Sch\"onlieb and Jizhou Li
Categories: cs.CV cs.LG
\\
  X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.
\\ ( https://arxiv.org/abs/2509.13863 ,  7203kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13864
Date: Wed, 17 Sep 2025 09:54:27 GMT   (10987kb)

Title: Distractor-Aware Memory-Based Visual Object Tracking
Authors: Jovana Videnovic, Matej Kristan, Alan Lukezic
Categories: cs.CV
Comments: Code available on Github: https://github.com/jovanavidenovic/DAM4SAM
\\
  Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.
\\ ( https://arxiv.org/abs/2509.13864 ,  10987kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13873
Date: Wed, 17 Sep 2025 10:06:08 GMT   (403kb)

Title: Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion
  for Pelvic Fracture Diagnosis
Authors: Siam Tahsin Bhuiyan, Rashedur Rahman, Sefatul Wasi, Naomi Yagi, Syoji
  Kobashi, Ashraful Islam, Saadia Binte Alam
Categories: cs.CV
Comments: Accepted at MICCAI EMERGE 2025
\\
  Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.
\\ ( https://arxiv.org/abs/2509.13873 ,  403kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13883
Date: Wed, 17 Sep 2025 10:23:30 GMT   (3194kb)

Title: EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person
  View
Authors: Zhen Xu, Guorui Lu, Chang Gao, Qinyu Chen
Categories: cs.CV
Comments: 8 pages
\\
  Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.
\\ ( https://arxiv.org/abs/2509.13883 ,  3194kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13907
Date: Wed, 17 Sep 2025 11:13:16 GMT   (588kb)

Title: White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic
  Segmentation
Authors: Jiyun Im, SuBeen Lee, Miso Lee, Jae-Pil Heo
Categories: cs.CV
Comments: 9 pages, 5 figures
\\
  Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.
\\ ( https://arxiv.org/abs/2509.13907 ,  588kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13919
Date: Wed, 17 Sep 2025 11:27:33 GMT   (4792kb)

Title: Towards Rationale-Answer Alignment of LVLMs via Self-Rationale
  Calibration
Authors: Yuanchen Wu, Ke Yan, Shouhong Ding, Ziyin Zhou, Xiaoqiang Li
Categories: cs.CV
Comments: Accepted by ICML 2025
\\
  Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.
\\ ( https://arxiv.org/abs/2509.13919 ,  4792kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13922
Date: Wed, 17 Sep 2025 11:30:13 GMT   (20096kb)

Title: Towards Robust Defense against Customization via Protective Perturbation
  Resistant to Diffusion-based Purification
Authors: Wenkui Yang, Jie Cao, Junxian Duan, Ran He
Categories: cs.CV
Comments: Accepted to ICCV 2025
\\
  Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.
\\ ( https://arxiv.org/abs/2509.13922 ,  20096kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13936
Date: Wed, 17 Sep 2025 13:05:59 GMT   (35246kb)

Title: Noise-Level Diffusion Guidance: Well Begun is Half Done
Authors: Harvey Mannering, Zhiwu Huang, and Adam Prugel-Bennett
Categories: cs.CV
\\
  Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.
\\ ( https://arxiv.org/abs/2509.13936 ,  35246kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13939
Date: Wed, 17 Sep 2025 13:06:58 GMT   (7452kb)

Title: Can Current AI Models Count What We Mean, Not What They See? A Benchmark
  and Systematic Evaluation
Authors: Gia Khanh Nguyen, Yifeng Huang, Minh Hoai
Categories: cs.CV
\\
  Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.
\\ ( https://arxiv.org/abs/2509.13939 ,  7452kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14001
Date: Wed, 17 Sep 2025 14:13:20 GMT   (9534kb)

Title: MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment
Authors: Elena Camuffo, Francesco Barbato, Mete Ozay, Simone Milani, Umberto
  Michieli
Categories: cs.CV cs.AI cs.LG
\\
  We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.
\\ ( https://arxiv.org/abs/2509.14001 ,  9534kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14012
Date: Wed, 17 Sep 2025 14:21:00 GMT   (4910kb)

Title: Performance Optimization of YOLO-FEDER FusionNet for Robust Drone
  Detection in Visually Complex Environments
Authors: Tamara R. Lenhard, Andreas Weinmann, Tobias Koch
Categories: cs.CV
\\
  Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.
\\ ( https://arxiv.org/abs/2509.14012 ,  4910kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14033
Date: Wed, 17 Sep 2025 14:34:02 GMT   (3673kb)

Title: SAIL-VL2 Technical Report
Authors: Weijie Yin, Yongjie Ye, Fangxun Shu, Yue Liao, Zijian Kang, Hongyuan
  Dong, Haiyang Yu, Dingkang Yang, Jiacong Wang, Han Wang, Wenzhuo Liu, Xiao
  Liang, Shuicheng Yan, Chao Feng
Categories: cs.CV
Comments: Technical Report
\\
  We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.
\\ ( https://arxiv.org/abs/2509.14033 ,  3673kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14051
Date: Wed, 17 Sep 2025 14:54:29 GMT   (1359kb)

Title: PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd
  Multi-modal Embeddings
Authors: Suhang You, Carla Pitarch-Abaigar, Sanket Kachole, Sumedh Sonawane,
  Juhyung Ha, Anish Sudarshan Gada, David Crandall, Rakesh Shiradkar and
  Spyridon Bakas
Categories: cs.CV
Comments: 11 pages, 1 figure, method paper for CHIMERA 2025 Challenge
\\
  Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.
\\ ( https://arxiv.org/abs/2509.14051 ,  1359kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14055
Date: Wed, 17 Sep 2025 15:00:57 GMT   (7427kb)

Title: Wan-Animate: Unified Character Animation and Replacement with Holistic
  Replication
Authors: Gang Cheng, Xin Gao, Li Hu, Siqi Hu, Mingyang Huang, Chaonan Ji, Ju
  Li, Dechao Meng, Jinwei Qi, Penchong Qiao, Zhen Shen, Yafei Song, Ke Sun,
  Linrui Tian, Feng Wang, Guangyuan Wang, Qi Wang, Zhongjian Wang, Jiayu Xiao,
  Sheng Xu, Bang Zhang, Peng Zhang, Xindi Zhang, Zhe Zhang, Jingren Zhou, Lian
  Zhuo
Categories: cs.CV
Comments: Project Page: https://humanaigc.github.io/wan-animate/
\\
  We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.
\\ ( https://arxiv.org/abs/2509.14055 ,  7427kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14060
Date: Wed, 17 Sep 2025 15:04:45 GMT   (3472kb)

Title: VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by
  Visual Semantic Enhancement
Authors: Jun Du, Weiwei Xing, Ming Li, Fei Richard Yu
Categories: cs.CV
\\
  Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.
\\ ( https://arxiv.org/abs/2509.14060 ,  3472kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14084
Date: Wed, 17 Sep 2025 15:29:25 GMT   (8936kb)

Title: AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with
  Anomaly-Aware Calibration
Authors: Jingyi Yuan, Jianxiong Ye, Wenkang Chen, Chenqiang Gao
Categories: cs.CV
\\
  Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.
\\ ( https://arxiv.org/abs/2509.14084 ,  8936kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14097
Date: Wed, 17 Sep 2025 15:38:05 GMT   (5014kb)

Title: Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for
  Audio-Visual Video Parsing
Authors: Yaru Chen, Ruohao Guo, Liting Gao, Yang Xiang, Qingyu Luo, Zhenbo Li,
  Wenwu Wang
Categories: cs.CV cs.MM
\\
  Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.
\\ ( https://arxiv.org/abs/2509.14097 ,  5014kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14104
Date: Wed, 17 Sep 2025 15:47:18 GMT   (7318kb)

Title: CSMoE: An Efficient Remote Sensing Foundation Model with Soft
  Mixture-of-Experts
Authors: Leonard Hackel and Tom Burgert and Beg\"um Demir
Categories: cs.CV
\\
  Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.
\\ ( https://arxiv.org/abs/2509.14104 ,  7318kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14119
Date: Wed, 17 Sep 2025 15:58:59 GMT   (18589kb)

Title: Generative AI for Misalignment-Resistant Virtual Staining to Accelerate
  Histopathology Workflows
Authors: Jiabo MA, Wenqiang Li, Jinbang Li, Ziyi Liu, Linshan Wu, Fengtao Zhou,
  Li Liang, Ronald Cheong Kin Chan, Terence T.W. Wong, Hao Chen
Categories: cs.CV
Comments: the arxiv version of the under review journal paper
\\
  Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.
\\ ( https://arxiv.org/abs/2509.14119 ,  18589kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14120
Date: Wed, 17 Sep 2025 15:59:44 GMT   (1864kb)

Title: Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake
  and Morphing Attack Detection
Authors: Sara Concas, Simone Maurizio La Cava, Andrea Panzino, Ester Masala,
  Giulia Orr\`u, Gian Luca Marcialis
Categories: cs.CV
Comments: Accepted at the 2025 IEEE INTERNATIONAL CONFERENCE ON Metrology for
  eXtended Reality, Artificial Intelligence and Neural Engineering
\\
  Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.
\\ ( https://arxiv.org/abs/2509.14120 ,  1864kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14142
Date: Wed, 17 Sep 2025 16:21:34 GMT   (6592kb)

Title: MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods,
  Results, Discussion, and Outlook
Authors: Peng Xu, Shengwu Xiong, Jiajun Zhang, Yaxiong Chen, Bowen Zhou, Chen
  Change Loy, David A. Clifton, Kyoung Mu Lee, Luc Van Gool, Ruiming He, Ruilin
  Yao, Xinwei Long, Jirui Huang, Kai Tian, Sa Yang, Yihua Shao, Jin Feng, Yue
  Zhong, Jiakai Zhou, Cheng Tang, Tianyu Zou, Yifang Zhang, Junming Liang,
  Guoyou Li, Zhaoxiang Wang, Qiang Zhou, Yichen Zhao, Shili Xiong, Hyeongjin
  Nam, Jaerin Lee, Jaeyoung Chung, JoonKyu Park, Junghun Oh, Kanggeon Lee,
  Wooseok Lee, Juneyoung Ro, Turghun Osman, Can Hu, Chaoyang Liao, Cheng Chen,
  Chengcheng Han, Chenhao Qiu, Chong Peng, Cong Xu, Dailin Li, Feiyu Wang, Feng
  Gao, Guibo Zhu, Guopeng Tang, Haibo Lu, Han Fang, Han Qi, Hanxiao Wu, Haobo
  Cheng, Hongbo Sun, Hongyao Chen, Huayong Hu, Hui Li, Jiaheng Ma, Jiang Yu,
  Jianing Wang, Jie Yang, Jing He, Jinglin Zhou, Jingxuan Li, et al. (63
  additional authors not shown)
Categories: cs.CV
Comments: ICCV 2025 MARS2 Workshop and Challenge "Multimodal Reasoning and Slow
  Thinking in the Large Model Era: Towards System 2 and Beyond''
\\
  This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.
\\ ( https://arxiv.org/abs/2509.14142 ,  6592kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14149
Date: Wed, 17 Sep 2025 16:30:34 GMT   (9527kb)

Title: An Exploratory Study on Abstract Images and Visual Representations
  Learned from Them
Authors: Haotian Li and Jianbo Jiao
Categories: cs.CV
Comments: Accepted to BMVC 2025
\\
  Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.
\\ ( https://arxiv.org/abs/2509.14149 ,  9527kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14151
Date: Wed, 17 Sep 2025 16:31:40 GMT   (7241kb)

Title: BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View
  3D Object Detection
Authors: Rongyu Zhang, Jiaming Liu, Xiaoqi Li, Xiaowei Chi, Dan Wang, Li Du,
  Yuan Du, Shanghang Zhang
Categories: cs.CV
Comments: Accepted by IEEE TCSVT
\\
  Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.
\\ ( https://arxiv.org/abs/2509.14151 ,  7241kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14165
Date: Wed, 17 Sep 2025 16:48:00 GMT   (9893kb)

Title: Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High
  Resolutions
Authors: Michal Szczepanski, Martyna Poreba and Karim Haroun
Categories: cs.CV cs.AI
\\
  Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.
\\ ( https://arxiv.org/abs/2509.14165 ,  9893kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14199
Date: Wed, 17 Sep 2025 17:34:40 GMT   (767kb)

Title: Dense Video Understanding with Gated Residual Tokenization
Authors: Haichao Zhang, Wenhao Chai, Shwai He, Ang Li, Yun Fu
Categories: cs.CV cs.AI cs.CL cs.LG
\\
  High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.
\\ ( https://arxiv.org/abs/2509.14199 ,  767kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14227
Date: Wed, 17 Sep 2025 17:58:06 GMT   (744kb)

Title: Cin\'{e}aste: A Fine-grained Contextual Movie Question Answering
  Benchmark
Authors: Nisarg A. Shah, Amir Ziai, Chaitanya Ekanadham, Vishal M. Patel
Categories: cs.CV
Comments: 11 pages, 5 figures, 5 tables
ACM-class: I.2.10; I.2.7
\\
  While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.
\\ ( https://arxiv.org/abs/2509.14227 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14232
Date: Wed, 17 Sep 2025 17:59:14 GMT   (13733kb)

Title: GenExam: A Multidisciplinary Text-to-Image Exam
Authors: Zhaokai Wang, Penghao Yin, Xiangyu Zhao, Changyao Tian, Yu Qiao,
  Wenhai Wang, Jifeng Dai, Gen Luo
Categories: cs.CV
\\
  Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.
\\ ( https://arxiv.org/abs/2509.14232 ,  13733kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13325
Date: Fri, 22 Aug 2025 22:02:41 GMT   (2107kb)

Title: A User-centric Kubernetes-based Architecture for Green Cloud Computing
Authors: Matteo Zanotto, Leonardo Vicentini, Redi Vreto, Francesco Lumpp, Diego
  Braga, Sandro Fiore
Categories: cs.DC
\\
  To meet the increasing demand for cloud computing services, the scale and
number of data centers keeps increasing worldwide. This growth comes at the
cost of increased electricity consumption, which directly correlates to CO2
emissions, the main driver of climate change. As such, researching ways to
reduce cloud computing emissions is more relevant than ever. However, although
cloud providers are reportedly already working near optimal power efficiency,
they fail in providing precise sustainability reporting. This calls for further
improvements on the cloud computing consumer's side. To this end, in this paper
we propose a user-centric, Kubernetes-based architecture for green cloud
computing. We implement a carbon intensity forecaster and we use it to schedule
workloads based on the availability of green energy, exploiting both regional
and temporal variations to minimize emissions. We evaluate our system using
real-world traces of cloud workloads execution comparing the achieved carbon
emission savings against a baseline round-robin scheduler. Our findings
indicate that our system can achieve up to a 13% reduction in emissions in a
strict scenario with heavy limitations on the available resources.
\\ ( https://arxiv.org/abs/2509.13325 ,  2107kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13575
Date: Tue, 16 Sep 2025 22:32:48 GMT   (336kb)

Title: Testing and benchmarking emerging supercomputers via the MFC flow solver
Authors: Benjamin Wilfong and Anand Radhakrishnan and Henry A. Le Berre and
  Tanush Prathi and Stephen Abbott and Spencer H. Bryngelson
Categories: cs.DC
Comments: 9 pages, 3 figures
\\
  Deploying new supercomputers requires testing and evaluation via application
codes. Portable, user-friendly tools enable evaluation, and the Multicomponent
Flow Code (MFC), a computational fluid dynamics (CFD) code, addresses this
need. MFC is adorned with a toolchain that automates input generation,
compilation, batch job submission, regression testing, and benchmarking. The
toolchain design enables users to evaluate compiler-hardware combinations for
correctness and performance with limited software engineering experience. As
with other PDE solvers, wall time per spatially discretized grid point serves
as a figure of merit. We present MFC benchmarking results for five generations
of NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,
utilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have
revealed compiler bugs and regressions on recent machines such as Frontier and
El Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship
supercomputers.
\\ ( https://arxiv.org/abs/2509.13575 ,  336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13583
Date: Tue, 16 Sep 2025 22:54:03 GMT   (315kb)

Title: Modeling the Carbon Footprint of HPC: The Top 500 and EasyC
Authors: Varsha Rao, Andrew A. Chien
Categories: cs.DC
Comments: 15 pages, 11 figures
Journal-ref: Workshops of the International Conference for High Performance
  Computing, Networking, Storage and Analysis (SC Workshops 2025)
DOI: 10.1145/3731599.3767567
\\
  Climate change is a critical concern for HPC systems, but GHG protocol
carbon-emission accounting methodologies are difficult for a single system, and
effectively infeasible for a collection of systems. As a result, there is no
HPC-wide carbon reporting, and even the largest HPC sites do not do GHG
protocol reporting.
  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The
key challenge lies in modeling the carbon footprint with limited data
availability.
  With the disclosed Top500.org data, and using a new tool, EasyC, we were able
to model the operational carbon of 391 HPC systems and the embodied carbon of
283 HPC systems. We further show how this coverage can be enhanced by
exploiting additional public information. With improved coverage, then
interpolation is used to produce the first carbon footprint estimates of the
Top 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1
Year) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top
500's carbon footprint will increase through 2030.
  A key enabler is the EasyC tool which models carbon footprint with only a few
data metrics. We explore availability of data and enhancement, showing that
coverage can be increased to 98% of Top 500 systems for operational and 80.8%
of the systems for embodied emissions.
\\ ( https://arxiv.org/abs/2509.13583 ,  315kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13703
Date: Wed, 17 Sep 2025 05:11:05 GMT   (670kb)

Title: GPU Programming for AI Workflow Development on AWS SageMaker: An
  Instructional Approach
Authors: Sriram Srinivasan, Hamdan Alabsi, Rand Obeidat, Nithisha Ponnala,
  Azene Zenebe
Categories: cs.DC
\\
  We present the design, implementation, and comprehensive evaluation of a
specialized course on GPU architecture, GPU programming, and how these are used
for developing AI agents. This course is offered to undergraduate and graduate
students during Fall 2024 and Spring 2025. The course began with foundational
concepts in GPU/CPU hardware and parallel computing and progressed to develop
RAG and optimizing them using GPUs. Students gained experience provisioning and
configuring cloud-based GPU instances, implementing parallel algorithms, and
deploying scalable AI solutions. We evaluated learning outcomes through
assessments, course evaluations, and anonymous surveys. The results reveal that
(1) AWS served as an effective and economical platform for practical GPU
programming, (2) experiential learning significantly enhanced technical
proficiency and engagement, and (3) the course strengthened students'
problem-solving and critical thinking skills through tools such as TensorBoard
and HPC profilers, which exposed performance bottlenecks and scaling issues.
Our findings underscore the pedagogical value of integrating parallel computing
into STEM education. We advocate for broader adoption of similar electives
across STEM curricula to prepare students for the demands of modern,
compute-intensive fields.
\\ ( https://arxiv.org/abs/2509.13703 ,  670kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13978
Date: Wed, 17 Sep 2025 13:51:29 GMT   (860kb)

Title: LLM Agents for Interactive Workflow Provenance: Reference Architecture
  and Evaluation Methodology
Authors: Renan Souza, Timothy Poteet, Brian Etz, Daniel Rosendo, Amal
  Gueroudji, Woong Shin, Prasanna Balaprakash, Rafael Ferreira da Silva
Categories: cs.DC cs.AI cs.DB
Comments: Paper accepted in the proceedings of the ACM/IEEE Supercomputing
  Conference (SC). Cite it as Renan Souza, Timothy Poteet, Brian Etz, Daniel
  Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, and Rafael
  Ferreira da Silva. 2025. LLM Agents for Interactive Workflow Provenance:
  Reference Architecture and Evaluation Methodology. In SC Workshops (WORKS)
MSC-class: 68M14, 68M20, 68T07
ACM-class: C.2.4; D.1.3; I.2.0
DOI: 10.1145/3731599.3767582
\\
  Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.
\\ ( https://arxiv.org/abs/2509.13978 ,  860kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13346
Date: Fri, 12 Sep 2025 21:16:50 GMT   (1108kb)

Title: All Models Are Wrong, But Can They Be Useful? Lessons from COVID-19
  Agent-Based Models: A Systematic Review
Authors: Emma Von Hoene, Sara Von Hoene, Szandra Peter, Ethan Hopson, Emily
  Csizmadia, Faith Fenyk, Kai Barner, Timothy Leslie, Hamdi Kavak, Andreas
  Zufle, Amira Roess, Taylor Anderson
Categories: cs.MA cs.CY
Comments: 20 pages, 5 figures, 3 tables, 8 supplemental files
\\
  The COVID-19 pandemic prompted a surge in computational models to simulate
disease dynamics and guide interventions. Agent-based models (ABMs) are
well-suited to capture population and environmental heterogeneity, but their
rapid deployment raised questions about utility for health policy. We
systematically reviewed 536 COVID-19 ABM studies published from January 2020 to
December 2023, retrieved from Web of Science, PubMed, and Wiley on January 30,
2024. Studies were included if they used ABMs to simulate COVID-19
transmission, where reviews were excluded. Studies were assessed against nine
criteria of model usefulness, including transparency and re-use,
interdisciplinary collaboration and stakeholder engagement, and evaluation
practices. Publications peaked in late 2021 and were concentrated in a few
countries. Most models explored behavioral or policy interventions (n = 294,
54.85%) rather than real-time forecasting (n = 9, 1.68%). While most described
model assumptions (n = 491, 91.60%), fewer disclosed limitations (n = 349,
65.11%), shared code (n = 219, 40.86%), or built on existing models (n = 195,
36.38%). Standardized reporting protocols (n = 36, 6.72%) and stakeholder
engagement were rare (13.62%, n = 73). Only 2.24% (n = 12) described a
comprehensive validation framework, though uncertainty was often quantified (n
= 407, 75.93%). Limitations of this review include underrepresentation of
non-English studies, subjective data extraction, variability in study quality,
and limited generalizability. Overall, COVID-19 ABMs advanced quickly, but
lacked transparency, accessibility, and participatory engagement. Stronger
standards are needed for ABMs to serve as reliable decision-support tools in
future public health crises.
\\ ( https://arxiv.org/abs/2509.13346 ,  1108kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13712
Date: Wed, 17 Sep 2025 05:42:36 GMT   (983kb)

Title: Inject, Fork, Compare: Defining an Interaction Vocabulary for
  Multi-Agent Simulation Platforms
Authors: HwiJoon Lee, Martina Di Paola, Yoo Jin Hong, Quang-Huy Nguyen, Joseph
  Seering
Categories: cs.MA cs.HC
\\
  LLM-based multi-agent simulations are a rapidly growing field of research,
but current simulations often lack clear modes for interaction and analysis,
limiting the "what if" scenarios researchers are able to investigate. In this
demo, we define three core operations for interacting with multi-agent
simulations: inject, fork, and compare. Inject allows researchers to introduce
external events at any point during simulation execution. Fork creates
independent timeline branches from any timestamp, preserving complete state
while allowing divergent exploration. Compare facilitates parallel observation
of multiple branches, revealing how different interventions lead to distinct
emergent behaviors. Together, these operations establish a vocabulary that
transforms linear simulation workflows into interactive, explorable spaces. We
demonstrate this vocabulary through a commodity market simulation with fourteen
AI agents, where researchers can inject contrasting events and observe
divergent outcomes across parallel timelines. By defining these fundamental
operations, we provide a starting point for systematic causal investigation in
LLM-based agent simulations, moving beyond passive observation toward active
experimentation.
\\ ( https://arxiv.org/abs/2509.13712 ,  983kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2010.01052 (*cross-listing*)
Date: Fri, 2 Oct 2020 15:31:36 GMT   (1422kb)
Date (revised v2): Tue, 6 Oct 2020 09:24:02 GMT   (5631kb)
Date (revised v3): Thu, 8 Oct 2020 12:36:31 GMT   (5631kb)

Title: Joint data imputation and mechanistic modelling for simulating
  heart-brain interactions in incomplete datasets
Authors: Jaume Banus and Maxime Sermesant and Oscar Camara and Marco Lorenzi
Categories: cs.LG cs.AI stat.ML
DOI: 10.1007/978-3-030-59725-2_46
\\
  The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.
\\ ( https://arxiv.org/abs/2010.01052 ,  5631kb)
------------------------------------------------------------------------------
\\
arXiv:2408.00208 (*cross-listing*)
Date: Thu, 1 Aug 2024 00:33:32 GMT   (1832kb)

Title: Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review
  and Meta-analysis
Authors: SaeedReza Motamedian, Sadra Mohaghegh, Elham Babadi Oregani, Mahrsa
  Amjadi, Parnian Shobeiri, Negin Cheraghi, Niusha Solouki, Nikoo Ahmadi,
  Hossein Mohammad-Rahimi, Yassine Bouchareb, Arman Rahmim
Categories: physics.med-ph cs.AI cs.LG
\\
  Purpose: Artificial intelligence (AI) techniques have been extensively
utilized for diagnosing and prognosis of several diseases in recent years. This
study identifies, appraises and synthesizes published studies on the use of AI
for the prognosis of COVID-19. Method: Electronic search was performed using
Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that
examined machine learning or deep learning methods to determine the prognosis
of COVID-19 using CT or chest X-ray images were included. Polled sensitivity,
specificity area under the curve and diagnostic odds ratio were calculated.
Result: A total of 36 articles were included; various prognosis-related issues,
including disease severity, mechanical ventilation or admission to the
intensive care unit and mortality, were investigated. Several AI models and
architectures were employed, such as the Siamense model, support vector
machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural
networks. The models achieved 71%, 88% and 67% sensitivity for mortality,
severity assessment and need for ventilation, respectively. The specificity of
69%, 89% and 89% were reported for the aforementioned variables. Conclusion:
Based on the included articles, machine learning and deep learning methods used
for the prognosis of COVID-19 patients using radiomic features from CT or CXR
images can help clinicians manage patients and allocate resources more
effectively. These studies also demonstrate that combining patient demographic,
clinical data, laboratory tests and radiomic features improves model
performances.
\\ ( https://arxiv.org/abs/2408.00208 ,  1832kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13328 (*cross-listing*)
Date: Sat, 30 Aug 2025 20:10:15 GMT   (1048kb)

Title: Dual Actor DDPG for Airborne STAR-RIS Assisted Communications
Authors: Danish Rizvi, David Boyle
Categories: eess.SP cs.AI cs.IT cs.NI math.IT
\\
  This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.
\\ ( https://arxiv.org/abs/2509.13328 ,  1048kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13331 (*cross-listing*)
Date: Tue, 9 Sep 2025 04:41:18 GMT   (3138kb)

Title: Explainable AI-Enhanced Supervisory Control for High-Precision
  Spacecraft Formation
Authors: Reza Pirayeshshirazinezhad
Categories: astro-ph.IM cs.AI cs.RO cs.SY eess.SY
\\
  We use artificial intelligence (AI) and supervisory adaptive control systems
to plan and optimize the mission of precise spacecraft formation. Machine
learning and robust control enhance the efficiency of spacecraft precision
formation of the Virtual Telescope for X-ray Observation (VTXO) space mission.
VTXO is a precise formation of two separate spacecraft making a virtual
telescope with a one-kilometer focal length. One spacecraft carries the lens
and the other spacecraft holds the camera to observe high-energy space objects
in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed
automata for supervisory control, Monte Carlo simulations for stability and
robustness evaluation, and integration of deep neural networks for optimal
estimation of mission parameters, satisfy the high precision mission criteria.
We integrate deep neural networks with a constrained, non-convex dynamic
optimization pipeline to predict optimal mission parameters, ensuring precision
mission criteria are met. AI framework provides explainability by predicting
the resulting energy consumption and mission error for a given set of mission
parameters. It allows for transparent, justifiable, and real-time trade-offs, a
capability not present in traditional adaptive controllers. The results show
reductions in energy consumption and improved mission accuracy, demonstrating
the capability of the system to address dynamic uncertainties and disturbances.
\\ ( https://arxiv.org/abs/2509.13331 ,  3138kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13342 (*cross-listing*)
Date: Fri, 12 Sep 2025 00:03:04 GMT   (38801kb)

Title: Real World Robotic Exploration using Deep Neural Networks Trained in
  Photorealistic Reconstructed Environments
Authors: Isaac Ronald Ward
Categories: cs.RO cs.AI
Comments: This report is submitted as partial fulfilment of the requirements
  for the Honours Programme of the Department of Computer Science and Software
  Engineering, The University of Western Australia, 2019
\\
  In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of
\\ ( https://arxiv.org/abs/2509.13342 ,  38801kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13345 (*cross-listing*)
Date: Fri, 12 Sep 2025 19:41:10 GMT   (1734kb)

Title: Accuracy Paradox in Large Language Models: Regulating Hallucination
  Risks in Generative AI
Authors: Zihao Li, Weiwei Yi, Jiahong Chen
Categories: cs.CY cs.AI cs.CL cs.HC cs.LG
\\
  As Large Language Models (LLMs) permeate everyday decision-making, their
epistemic and societal risks demand urgent scrutiny. Hallucinations, the
generation of fabricated, misleading, oversimplified or untrustworthy outputs,
has emerged as imperative challenges. While regulatory, academic, and technical
discourse position accuracy as the principal benchmark for mitigating such
harms, this article contends that overreliance on accuracy misdiagnoses the
problem and has counterproductive effect: the accuracy paradox. Drawing on
interdisciplinary literatures, this article develops a taxonomy of
hallucination types and shows the paradox along three intertwining dimensions:
outputs, individuals and society. First, accuracy functions as a superficial
proxy for reliability, incentivising the optimisation of rhetorical fluency and
surface-level correctness over epistemic trustworthiness. This encourages
passive user trust in outputs that appear accurate but epistemically untenable.
Second, accuracy as a singular metric fails to detect harms that are not
factually false but are nonetheless misleading, value-laden, or socially
distorting, including consensus illusions, sycophantic alignment, and subtle
manipulation. Third, regulatory overemphasis on accuracy obscures the wider
societal consequences of hallucination, including social sorting, privacy
violations, equity harms, epistemic convergence that marginalises dissent,
reduces pluralism, and causes social deskilling. By examining the EU AI Act,
GDPR, and DSA, the article argues that current regulations are not yet
structurally equipped to address these epistemic, relational, and systemic
harms and exacerbated by the overreliance on accuracy. By exposing such
conceptual and practical challenges, this article calls for a fundamental shift
towards pluralistic, context-aware, and manipulation-resilient approaches to AI
trustworthy governance.
\\ ( https://arxiv.org/abs/2509.13345 ,  1734kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13349 (*cross-listing*)
Date: Sat, 13 Sep 2025 21:00:03 GMT   (2174kb)

Title: Label-Efficient Grasp Joint Prediction with Point-JEPA
Authors: Jed Guzelkabaagac, Boris Petrovi\'c
Categories: cs.RO cs.AI cs.LG
Comments: 4 pages, 5 figures. Submitted to IROS 2025 Workshop
\\
  We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.
\\ ( https://arxiv.org/abs/2509.13349 ,  2174kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13355 (*cross-listing*)
Date: Sun, 14 Sep 2025 14:35:11 GMT   (5403kb)

Title: Synthetic Data and the Shifting Ground of Truth
Authors: Dietmar Offenhuber
Categories: cs.CY cs.AI cs.LG
Comments: Talk presented at the Society for the Social Studies of Science (4S)
  2025 meeting in Seattle, Sept. 3, 2025
\\
  The emergence of synthetic data for privacy protection, training data
generation, or simply convenient access to quasi-realistic data in any shape or
volume complicates the concept of ground truth. Synthetic data mimic real-world
observations, but do not refer to external features. This lack of a
representational relationship, however, not prevent researchers from using
synthetic data as training data for AI models and ground truth repositories. It
is claimed that the lack of data realism is not merely an acceptable tradeoff,
but often leads to better model performance than realistic data: compensate for
known biases, prevent overfitting and support generalization, and make the
models more robust in dealing with unexpected outliers. Indeed, injecting noisy
and outright implausible data into training sets can be beneficial for the
model. This greatly complicates usual assumptions based on which
representational accuracy determines data fidelity (garbage in - garbage out).
Furthermore, ground truth becomes a self-referential affair, in which the
labels used as a ground truth repository are themselves synthetic products of a
generative model and as such not connected to real-world observations. My paper
examines how ML researchers and practitioners bootstrap ground truth under such
paradoxical circumstances without relying on the stable ground of
representation and real-world reference. It will also reflect on the broader
implications of a shift from a representational to what could be described as a
mimetic or iconic concept of data.
\\ ( https://arxiv.org/abs/2509.13355 ,  5403kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13359 (*cross-listing*)
Date: Mon, 15 Sep 2025 10:34:31 GMT   (141kb)

Title: Evaluating undergraduate mathematics examinations in the era of
  generative AI: a curriculum-level case study
Authors: Benjamin J. Walker, Beatriz Navarro Lameda, Ruth A. Reynolds
Categories: cs.CY cs.AI
\\
  Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are
transforming the educational landscape, prompting reconsideration of
traditional assessment practices. In parallel, universities are exploring
alternatives to in-person, closed-book examinations, raising concerns about
academic integrity and pedagogical alignment in uninvigilated settings. This
study investigates whether traditional closed-book mathematics examinations
retain their pedagogical relevance when hypothetically administered in
uninvigilated, open-book settings with GenAI access. Adopting an empirical
approach, we generate, transcribe, and blind-mark GenAI submissions to eight
undergraduate mathematics examinations at a Russel Group university, spanning
the entirety of the first-year curriculum. By combining independent GenAI
responses to individual questions, we enable a meaningful evaluation of GenAI
performance, both at the level of modules and across the first-year curriculum.
We find that GenAI attainment is at the level of a first-class degree, though
current performance can vary between modules. Further, we find that GenAI
performance is remarkably consistent when viewed across the entire curriculum,
significantly more so than that of students in invigilated examinations. Our
findings evidence the need for redesigning assessments in mathematics for
unsupervised settings, and highlight the potential reduction in pedagogical
value of current standards in the era of generative artificial intelligence.
\\ ( https://arxiv.org/abs/2509.13359 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13365 (*cross-listing*)
Date: Mon, 15 Sep 2025 18:01:03 GMT   (245kb)

Title: The Provenance Problem: LLMs and the Breakdown of Citation Norms
Authors: Brian D. Earp, Haotian Yuan, Julian Koplin, Sebastian Porsdam Mann
Categories: cs.CY cs.AI
Comments: 9 pages
\\
  The increasing use of generative AI in scientific writing raises urgent
questions about attribution and intellectual credit. When a researcher employs
ChatGPT to draft a manuscript, the resulting text may echo ideas from sources
the author has never encountered. If an AI system reproduces insights from, for
example, an obscure 1975 paper without citation, does this constitute
plagiarism? We argue that such cases exemplify the 'provenance problem': a
systematic breakdown in the chain of scholarly credit. Unlike conventional
plagiarism, this phenomenon does not involve intent to deceive (researchers may
disclose AI use and act in good faith) yet still benefit from the uncredited
intellectual contributions of others. This dynamic creates a novel category of
attributional harm that current ethical and professional frameworks fail to
address. As generative AI becomes embedded across disciplines, the risk that
significant ideas will circulate without recognition threatens both the
reputational economy of science and the demands of epistemic justice. This
Perspective analyzes how AI challenges established norms of authorship,
introduces conceptual tools for understanding the provenance problem, and
proposes strategies to preserve integrity and fairness in scholarly
communication.
\\ ( https://arxiv.org/abs/2509.13365 ,  245kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13372 (*cross-listing*)
Date: Tue, 16 Sep 2025 04:47:25 GMT   (6760kb)

Title: Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular
  Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy
  Imaging
Authors: Prahlad G Menon
Categories: eess.IV cs.AI cs.CV cs.ET q-bio.QM
MSC-class: 92C50, 68T07, 76D05, 65D18, 92C55
ACM-class: I.4.6; I.4.8; J.3; I.2.10; I.4.9
\\
  Fontan palliation for univentricular congenital heart disease progresses to
hemodynamic failure with complex flow patterns poorly characterized by
conventional 2D imaging. Current assessment relies on fluoroscopic angiography,
providing limited 3D geometric information essential for computational fluid
dynamics (CFD) analysis and surgical planning.
  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash
(2.5B parameters) for systematic, iterative processing of fluoroscopic
angiograms through transformer-based neural architecture. The pipeline
encompasses medical image preprocessing, vascular segmentation, contrast
enhancement, artifact removal, and virtual hemodynamic flow visualization
within 2D projections. Final views were processed through Tencent's
Hunyuan3D-2mini (384M parameters) for stereolithography file generation.
  The pipeline successfully generated geometrically optimized 2D projections
from single-view angiograms after 16 processing steps using a custom web
interface. Initial iterations contained hallucinated vascular features
requiring iterative refinement to achieve anatomically faithful
representations. Final projections demonstrated accurate preservation of
complex Fontan geometry with enhanced contrast suitable for 3D conversion.
AI-generated virtual flow visualization identified stagnation zones in central
connections and flow patterns in branch arteries. Complete processing required
under 15 minutes with second-level API response times.
  This approach demonstrates clinical feasibility of generating CFD-suitable
geometries from routine angiographic data, enabling 3D generation and rapid
virtual flow visualization for cursory insights prior to full CFD simulation.
While requiring refinement cycles for accuracy, this establishes foundation for
democratizing advanced geometric and hemodynamic analysis using readily
available imaging data.
\\ ( https://arxiv.org/abs/2509.13372 ,  6760kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13380 (*cross-listing*)
Date: Tue, 16 Sep 2025 08:52:13 GMT   (1223kb)

Title: ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy
Authors: Alejandro D. Mousist
Categories: cs.RO cs.AI cs.LG cs.MA cs.SY eess.SY
Comments: This preprint presents ASTREA, a multi-agent architecture combining
  LLM-guided semantic modulation with reinforcement learning for autonomous
  satellite operations. The system is validated in hardware orbital
  environments
\\
  This paper presents ASTREA, the first agentic system deployed on
flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using
thermal control as a representative use case, we integrate a
resource-constrained Large Language Model (LLM) agent with a reinforcement
learning controller in an asynchronous architecture tailored for
space-qualified platforms. Ground experiments show that LLM-guided supervision
improves thermal stability and reduces violations, confirming the feasibility
of combining semantic reasoning with adaptive control under hardware
constraints. However, on-orbit validation aboard the International Space
Station (ISS) reveals performance degradation caused by inference latency
mismatched with the rapid thermal cycles characteristic of Low Earth Orbit
(LEO) satellites. These results highlight both the opportunities and current
limitations of agentic LLM-based systems in real flight environments, providing
practical design guidelines for future space autonomy.
\\ ( https://arxiv.org/abs/2509.13380 ,  1223kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13387 (*cross-listing*)
Date: Tue, 16 Sep 2025 12:20:07 GMT   (1654kb)

Title: Uncovering AI Governance Themes in EU Policies using BERTopic and
  Thematic Analysis
Authors: Delaram Golpayegani, Marta Lasek-Markey, Arjumand Younus, Aphra Kerr,
  Dave Lewis
Categories: cs.CY cs.AI
\\
  The upsurge of policies and guidelines that aim to ensure Artificial
Intelligence (AI) systems are safe and trustworthy has led to a fragmented
landscape of AI governance. The European Union (EU) is a key actor in the
development of such policies and guidelines. Its High-Level Expert Group (HLEG)
issued an influential set of guidelines for trustworthy AI, followed in 2024 by
the adoption of the EU AI Act. While the EU policies and guidelines are
expected to be aligned, they may differ in their scope, areas of emphasis,
degrees of normativity, and priorities in relation to AI. To gain a broad
understanding of AI governance from the EU perspective, we leverage qualitative
thematic analysis approaches to uncover prevalent themes in key EU documents,
including the AI Act and the HLEG Ethics Guidelines. We further employ
quantitative topic modelling approaches, specifically through the use of the
BERTopic model, to enhance the results and increase the document sample to
include EU AI policy documents published post-2018. We present a novel
perspective on EU policies, tracking the evolution of its approach to
addressing AI governance.
\\ ( https://arxiv.org/abs/2509.13387 ,  1654kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13390 (*cross-listing*)
Date: Tue, 16 Sep 2025 14:04:22 GMT   (12513kb)

Title: A Domain Knowledge Informed Approach for Anomaly Detection of Electric
  Vehicle Interior Sounds
Authors: Deepti Kunte, Bram Cornelis, Claudio Colangeli, Karl Janssens, Brecht
  Van Baelen, Konstantinos Gryllias
Categories: cs.SD cs.AI cs.CV cs.LG eess.AS
Comments: Submitted to: Mechanical Systems and Signal Processing
ACM-class: I.2.1; I.2.6; I.2.10; I.5.1; I.5.2; J.2; J.7
\\
  The detection of anomalies in automotive cabin sounds is critical for
ensuring vehicle quality and maintaining passenger comfort. In many real-world
settings, this task is more appropriately framed as an unsupervised learning
problem rather than the supervised case due to the scarcity or complete absence
of labeled faulty data. In such an unsupervised setting, the model is trained
exclusively on healthy samples and detects anomalies as deviations from normal
behavior. However, in the absence of labeled faulty samples for validation and
the limited reliability of commonly used metrics, such as validation
reconstruction error, effective model selection remains a significant
challenge. To overcome these limitations, a domain-knowledge-informed approach
for model selection is proposed, in which proxy-anomalies engineered through
structured perturbations of healthy spectrograms are used in the validation set
to support model selection. The proposed methodology is evaluated on a
high-fidelity electric vehicle dataset comprising healthy and faulty cabin
sounds across five representative fault types viz., Imbalance, Modulation,
Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced
sound synthesis techniques, and validated via expert jury assessments, has been
made publicly available to facilitate further research. Experimental
evaluations on the five fault cases demonstrate the selection of optimal models
using proxy-anomalies, significantly outperform conventional model selection
strategies.
\\ ( https://arxiv.org/abs/2509.13390 ,  12513kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13391 (*cross-listing*)
Date: Tue, 16 Sep 2025 14:07:39 GMT   (43kb)

Title: The Intercepted Self: How Generative AI Challenges the Dynamics of the
  Relational Self
Authors: Sandrine R. Schiller, Camilo Miguel Signorelli and Filippos Stamatiou
Categories: cs.CY cs.AI
Comments: 8 pages, accepted at the 8th AAAI/ACM Conference on AI, Ethics, and
  Society
\\
  Generative AI is changing our way of interacting with technology, others, and
ourselves. Systems such as Microsoft copilot, Gemini and the expected Apple
intelligence still awaits our prompt for action. Yet, it is likely that AI
assistant systems will only become better at predicting our behaviour and
acting on our behalf. Imagine new generations of generative and predictive AI
deciding what you might like best at a new restaurant, picking an outfit that
increases your chances on your date with a partner also chosen by the same or a
similar system. Far from a science fiction scenario, the goal of several
research programs is to build systems capable of assisting us in exactly this
manner. The prospect urges us to rethink human-technology relations, but it
also invites us to question how such systems might change the way we relate to
ourselves. Building on our conception of the relational self, we question the
possible effects of generative AI with respect to what we call the sphere of
externalised output, the contextual sphere and the sphere of self-relating. In
this paper, we attempt to deepen the existential considerations accompanying
the AI revolution by outlining how generative AI enables the fulfilment of
tasks and also increasingly anticipates, i.e. intercepts, our initiatives in
these different spheres.
\\ ( https://arxiv.org/abs/2509.13391 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13395 (*cross-listing*)
Date: Tue, 16 Sep 2025 17:07:23 GMT   (233kb)

Title: TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech
  Recognition Abilities of Large Multimodal Models
Authors: Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson
Categories: eess.AS cs.AI cs.CL cs.LG cs.MM
\\
  Speech foundation models have recently demonstrated the ability to perform
Speech In-Context Learning (SICL). Selecting effective in-context examples is
crucial for SICL performance, yet selection methodologies remain underexplored.
In this work, we propose Text-Embedding KNN for SICL (TICL), a simple pipeline
that uses semantic context to enhance off-the-shelf large multimodal models'
speech recognition ability without fine-tuning. Across challenging automatic
speech recognition tasks, including accented English, multilingual speech, and
children's speech, our method enables models to surpass zero-shot performance
with up to 84.7% relative WER reduction. We conduct ablation studies to show
the robustness and efficiency of our method.
\\ ( https://arxiv.org/abs/2509.13395 ,  233kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13397 (*cross-listing*)
Date: Tue, 16 Sep 2025 17:29:47 GMT   (1334kb)

Title: The threat of analytic flexibility in using large language models to
  simulate human data: A call to attention
Authors: Jamie Cummins
Categories: cs.CY cs.AI
Comments: 11 pages, 3 figures
\\
  Social scientists are now using large language models to create "silicon
samples" - synthetic datasets intended to stand in for human respondents, aimed
at revolutionising human subjects research. However, there are many analytic
choices which must be made to produce these samples. Though many of these
choices are defensible, their impact on sample quality is poorly understood. I
map out these analytic choices and demonstrate how a very small number of
decisions can dramatically change the correspondence between silicon samples
and human data. Configurations (N = 252) varied substantially in their capacity
to estimate (i) rank ordering of participants, (ii) response distributions, and
(iii) between-scale correlations. Most critically, configurations were not
consistent in quality: those that performed well on one dimension often
performed poorly on another, implying that there is no "one-size-fits-all"
configuration that optimises the accuracy of these samples. I call for greater
attention to the threat of analytic flexibility in using silicon samples.
\\ ( https://arxiv.org/abs/2509.13397 ,  1334kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13400 (*cross-listing*)
Date: Tue, 16 Sep 2025 17:55:56 GMT   (100kb)

Title: Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer
  Reviews
Authors: Sai Suresh Marchala Vasu, Ivaxi Sheth, Hui-Po Wang, Ruta Binkyte,
  Mario Fritz
Categories: cs.CY cs.AI
\\
  The adoption of large language models (LLMs) is transforming the peer review
process, from assisting reviewers in writing more detailed evaluations to
generating entire reviews automatically. While these capabilities offer
exciting opportunities, they also raise critical concerns about fairness and
reliability. In this paper, we investigate bias in LLM-generated peer reviews
by conducting controlled experiments on sensitive metadata, including author
affiliation and gender. Our analysis consistently shows affiliation bias
favoring institutions highly ranked on common academic rankings. Additionally,
we find some gender preferences, which, even though subtle in magnitude, have
the potential to compound over time. Notably, we uncover implicit biases that
become more evident with token-based soft ratings.
\\ ( https://arxiv.org/abs/2509.13400 ,  100kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13471 (*cross-listing*)
Date: Tue, 16 Sep 2025 19:13:26 GMT   (2153kb)

Title: An LLM Agentic Approach for Legal-Critical Software: A Case Study for
  Tax Prep Software
Authors: Sina Gogani-Khiabani (University of Illinois Chicago), Ashutosh
  Trivedi (University of Colorado Boulder), Diptikalyan Saha (IBM Research),
  Saeid Tizpaz-Niari (University of Illinois Chicago)
Categories: cs.SE cs.AI
Comments: To appear at ICSE 26. 12 pages
DOI: 10.1145/3744916.3764575
\\
  Large language models (LLMs) show promise for translating natural-language
statutes into executable logic, but reliability in legally critical settings
remains challenging due to ambiguity and hallucinations. We present an agentic
approach for developing legal-critical software, using U.S. federal tax
preparation as a case study. The key challenge is test-case generation under
the oracle problem, where correct outputs require interpreting law. Building on
metamorphic testing, we introduce higher-order metamorphic relations that
compare system outputs across structured shifts among similar individuals.
Because authoring such relations is tedious and error-prone, we use an
LLM-driven, role-based framework to automate test generation and code
synthesis. We implement a multi-agent system that translates tax code into
executable software and incorporates a metamorphic-testing agent that searches
for counterexamples. In experiments, our framework using a smaller model
(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier
models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results
support agentic LLM methodologies as a path to robust, trustworthy
legal-critical software from natural-language specifications.
\\ ( https://arxiv.org/abs/2509.13471 ,  2153kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13487 (*cross-listing*)
Date: Tue, 16 Sep 2025 19:40:21 GMT   (1770kb)

Title: Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline
  Generation
Authors: Abubakari Alidu, Michele Ciavotta, Flavio DePaoli
Categories: cs.SE cs.AI
\\
  Developing reliable data enrichment pipelines demands significant engineering
expertise. We present Prompt2DAG, a methodology that transforms natural
language descriptions into executable Apache Airflow DAGs. We evaluate four
generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across
260 experiments using thirteen LLMs and five case studies to identify optimal
strategies for production-grade automation. Performance is measured using a
penalized scoring framework that combines reliability with code quality (SAT),
structural integrity (DST), and executability (PCT). The Hybrid approach
emerges as the optimal generative method, achieving a 78.5% success rate with
robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly
outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.
Our findings show that reliability, not intrinsic code quality, is the primary
differentiator. Cost-effectiveness analysis reveals the Hybrid method is over
twice as efficient as Direct prompting per successful DAG. We conclude that a
structured, hybrid approach is essential for balancing flexibility and
reliability in automated workflow generation, offering a viable path to
democratize data pipeline development.
\\ ( https://arxiv.org/abs/2509.13487 ,  1770kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13499 (*cross-listing*)
Date: Tue, 16 Sep 2025 19:55:25 GMT   (774kb)

Title: Reproducible workflow for online AI in digital health
Authors: Susobhan Ghosh, Bhanu T. Gulapalli, Daiqi Gao, Asim Gazi, Anna Trella,
  Ziping Xu, Kelly Zhang, Susan A. Murphy
Categories: cs.CY cs.AI
\\
  Online artificial intelligence (AI) algorithms are an important component of
digital health interventions. These online algorithms are designed to
continually learn and improve their performance as streaming data is collected
on individuals. Deploying online AI presents a key challenge: balancing
adaptability of online AI with reproducibility. Online AI in digital
interventions is a rapidly evolving area, driven by advances in algorithms,
sensors, software, and devices. Digital health intervention development and
deployment is a continuous process, where implementation - including the AI
decision-making algorithm - is interspersed with cycles of re-development and
optimization. Each deployment informs the next, making iterative deployment a
defining characteristic of this field. This iterative nature underscores the
importance of reproducibility: data collected across deployments must be
accurately stored to have scientific utility, algorithm behavior must be
auditable, and results must be comparable over time to facilitate scientific
discovery and trustworthy refinement. This paper proposes a reproducible
scientific workflow for developing, deploying, and analyzing online AI
decision-making algorithms in digital health interventions. Grounded in
practical experience from multiple real-world deployments, this workflow
addresses key challenges to reproducibility across all phases of the online AI
algorithm development life-cycle.
\\ ( https://arxiv.org/abs/2509.13499 ,  774kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13550 (*cross-listing*)
Date: Tue, 16 Sep 2025 21:33:11 GMT   (24kb)

Title: Complexity Bounds for Smooth Convex Multiobjective Optimization
Authors: Phillipe R. Sampaio
Categories: math.OC cs.AI
Comments: 16 pages
\\
  We study the oracle complexity of finding $\varepsilon$-Pareto stationary
points in smooth multiobjective optimization with $m$ objectives. The progress
metric is the Pareto stationarity gap $\mathcal{G}(x)$ (the norm of an optimal
convex combination of gradients). Our contributions are fourfold. (i) For
strongly convex objectives, any span first-order method (iterates lie in the
span of past gradients) exhibits linear convergence no faster than
$\exp(-\Theta(T/\sqrt{\kappa}))$ after $T$ oracle calls, where $\kappa$ is the
condition number, implying $\Theta(\sqrt{\kappa}\log(1/\varepsilon))$
iterations; this matches classical accelerated upper bounds. (ii) For convex
problems and oblivious one-step methods (a fixed scalarization with
pre-scheduled step sizes), we prove a lower bound of order $1/T$ on the best
gradient norm among the first $T$ iterates. (iii) Although accelerated gradient
descent is outside this restricted class, it is an oblivious span method and
attains the same $1/T$ upper rate on a fixed scalarization. (iv) For convex
problems and general span methods with adaptive scalarizations, we establish a
universal lower bound of order $1/T^{2}$ on the gradient norm of the final
iterate after $T$ steps, highlighting a gap between known upper bounds and
worst-case guarantees. All bounds hold on non-degenerate instances with
distinct objectives and non-singleton Pareto fronts; rates are stated up to
universal constants and natural problem scaling.
\\ ( https://arxiv.org/abs/2509.13550 ,  24kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13574 (*cross-listing*)
Date: Tue, 16 Sep 2025 22:28:27 GMT   (5829kb)

Title: Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic
  Policies: Mitigating Multi-Step Inference Degradation
Authors: Zidong Chen, Zihao Guo, Peng Wang, ThankGod Itua Egbe, Yan Lyu,
  Chenghao Qian
Categories: cs.RO cs.AI
\\
  Flow matching has emerged as a competitive framework for learning
high-quality generative policies in robotics; however, we find that
generalisation arises and saturates early along the flow trajectory, in
accordance with recent findings in the literature. We further observe that
increasing the number of Euler integration steps during inference
counter-intuitively and universally degrades policy performance. We attribute
this to (i) additional, uniformly spaced integration steps oversample the
late-time region, thereby constraining actions towards the training
trajectories and reducing generalisation; and (ii) the learned velocity field
becoming non-Lipschitz as integration time approaches 1, causing instability.
To address these issues, we propose a novel policy that utilises non-uniform
time scheduling (e.g., U-shaped) during training, which emphasises both early
and late temporal stages to regularise policy training, and a dense-jump
integration schedule at inference, which uses a single-step integration to
replace the multi-step integration beyond a jump point, to avoid unstable areas
around 1. Essentially, our policy is an efficient one-step learner that still
pushes forward performance through multi-step integration, yielding up to 23.7%
performance gains over state-of-the-art baselines across diverse robotic tasks.
\\ ( https://arxiv.org/abs/2509.13574 ,  5829kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13579 (*cross-listing*)
Date: Tue, 16 Sep 2025 22:37:37 GMT   (3727kb)

Title: TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement
  Learning
Authors: Momchil S. Tomov, Sang Uk Lee, Hansford Hendrago, Jinwook Huh, Teawon
  Han, Forbes Howington, Rafael da Silva, Gianmarco Bernasconi, Marc Heim,
  Samuel Findler, Xiaonan Ji, Alexander Boule, Michael Napoli, Kuo Chen, Jesse
  Miller, Boaz Floor, Yunqing Hu
Categories: cs.RO cs.AI cs.LG
\\
  We present TreeIRL, a novel planner for autonomous driving that combines
Monte Carlo tree search (MCTS) and inverse reinforcement learning (IRL) to
achieve state-of-the-art performance in simulation and in real-world driving.
The core idea is to use MCTS to find a promising set of safe candidate
trajectories and a deep IRL scoring function to select the most human-like
among them. We evaluate TreeIRL against both classical and state-of-the-art
planners in large-scale simulations and on 500+ miles of real-world autonomous
driving in the Las Vegas metropolitan area. Test scenarios include dense urban
traffic, adaptive cruise control, cut-ins, and traffic lights. TreeIRL achieves
the best overall performance, striking a balance between safety, progress,
comfort, and human-likeness. To our knowledge, our work is the first
demonstration of MCTS-based planning on public roads and underscores the
importance of evaluating planners across a diverse set of metrics and in
real-world environments. TreeIRL is highly extensible and could be further
improved with reinforcement learning and imitation learning, providing a
framework for exploring different combinations of classical and learning-based
approaches to solve the planning bottleneck in autonomous driving.
\\ ( https://arxiv.org/abs/2509.13579 ,  3727kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13597 (*cross-listing*)
Date: Tue, 16 Sep 2025 23:43:24 GMT   (866kb)

Title: Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents
Authors: Abhishek Goswami
Categories: cs.CR cs.AI
Comments: 17 pages, 6 figures, 2 Tables
\\
  Autonomous LLM agents can issue thousands of API calls per hour without human
oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings
stochastic reasoning, prompt injection, or multi-agent orchestration can
silently expand privileges.
  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each
agent's action to verifiable user intent and, optionally, to a specific
workflow step. A-JWT carries an agent's identity as a one-way checksum hash
derived from its prompt, tools and configuration, and a chained delegation
assertion to prove which downstream agent may execute a given task, and
per-agent proof-of-possession keys to prevent replay and in-process
impersonation. We define a new authorization mechanism and add a lightweight
client shim library that self-verifies code at run time, mints intent tokens,
tracks workflow steps and derives keys, thus enabling secure agent identity and
separation even within a single process.
  We illustrate a comprehensive threat model for agentic applications,
implement a Python proof-of-concept and show functional blocking of
scope-violating requests, replay, impersonation, and prompt-injection pathways
with sub-millisecond overhead on commodity hardware. The design aligns with
ongoing OAuth agent discussions and offers a drop-in path toward zero-trust
guarantees for agentic applications. A comprehensive performance and security
evaluation with experimental results will appear in our forthcoming journal
publication
\\ ( https://arxiv.org/abs/2509.13597 ,  866kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13603 (*cross-listing*)
Date: Wed, 17 Sep 2025 00:22:08 GMT   (51kb)

Title: Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid
  Retrieval with LLM Evaluation
Authors: Yongye Su, Zeya Zhang, Jane Kou, Cheng Ju, Shubhojeet Sarkar, Yamin
  Wang, Ji Liu, Shengbo Guo
Categories: cs.IR cs.AI
Comments: 5 Pages, work done as Yongye Su's internship project at Meta
\\
  Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.
\\ ( https://arxiv.org/abs/2509.13603 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13620 (*cross-listing*)
Date: Wed, 17 Sep 2025 01:30:44 GMT   (992kb)

Title: A reduced-order derivative-informed neural operator for subsurface
  fluid-flow
Authors: Jeongjin (Jayjay) Park, Grant Bruer, Huseyin Tuna Erdinc, Abhinav
  Prakash Gahlot, and Felix J. Herrmann
Categories: physics.comp-ph cs.AI cs.LG
\\
  Neural operators have emerged as cost-effective surrogates for expensive
fluid-flow simulators, particularly in computationally intensive tasks such as
permeability inversion from time-lapse seismic data, and uncertainty
quantification. In these applications, the fidelity of the surrogate's
gradients with respect to system parameters is crucial, as the accuracy of
downstream tasks, such as optimization and Bayesian inference, relies directly
on the quality of the derivative information. Recent advances in
physics-informed methods have leveraged derivative information to improve
surrogate accuracy. However, incorporating explicit Jacobians can become
computationally prohibitive, as the complexity typically scales quadratically
with the number of input parameters. To address this limitation, we propose
DeFINO (Derivative-based Fisher-score Informed Neural Operator), a
reduced-order, derivative-informed training framework. DeFINO integrates
Fourier neural operators (FNOs) with a novel derivative-based training strategy
guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto
dominant eigen-directions identified by the FIM, DeFINO captures critical
sensitivity information directly informed by observational data, significantly
reducing computational expense. We validate DeFINO through synthetic
experiments in the context of subsurface multi-phase fluid-flow, demonstrating
improvements in gradient accuracy while maintaining robust forward predictions
of underlying fluid dynamics. These results highlight DeFINO's potential to
offer practical, scalable solutions for inversion problems in complex
real-world scenarios, all at substantially reduced computational cost.
\\ ( https://arxiv.org/abs/2509.13620 ,  992kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13626 (*cross-listing*)
Date: Wed, 17 Sep 2025 01:54:11 GMT   (1363kb)

Title: Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental
  Health Retrieval
Authors: Amanda Chan, James Jiayu Liu, He Kai, Onno P. Kampman
Categories: cs.IR cs.AI
Comments: 25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health
ACM-class: H.3.3; J.3; I.2.7
\\
  Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.
\\ ( https://arxiv.org/abs/2509.13626 ,  1363kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13627 (*cross-listing*)
Date: Wed, 17 Sep 2025 01:56:07 GMT   (759kb)

Title: Secure, Scalable and Privacy Aware Data Strategy in Cloud
Authors: Vijay Kumar Butte, Sujata Butte
Categories: cs.CR cs.AI cs.DC
Journal-ref: Butte, Vijay Kumar, and Sujata Butte. "Secure, scalable and
  privacy aware data strategy in cloud." 2022 International Conference on
  Augmented Intelligence and Sustainable Systems (ICAISS). IEEE, 2022
DOI: 10.1109/ICAISS55157.2022.10011063
\\
  The enterprises today are faced with the tough challenge of processing,
storing large amounts of data in a secure, scalable manner and enabling
decision makers to make quick, informed data driven decisions. This paper
addresses this challenge and develops an effective enterprise data strategy in
the cloud. Various components of an effective data strategy are discussed and
architectures addressing security, scalability and privacy aspects are
provided.
\\ ( https://arxiv.org/abs/2509.13627 ,  759kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13633 (*cross-listing*)
Date: Wed, 17 Sep 2025 02:08:34 GMT   (1238kb)

Title: DeepLogit: A sequentially constrained explainable deep learning modeling
  approach for transport policy analysis
Authors: Jeremy Oon, Rakhi Manohar Mepparambath and Ling Feng
Categories: cs.LG cs.AI
\\
  Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .
\\ ( https://arxiv.org/abs/2509.13633 ,  1238kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13650 (*cross-listing*)
Date: Wed, 17 Sep 2025 02:56:21 GMT   (3335kb)

Title: GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You
  Commit?
Authors: Amena Amro and Manar H. Alalfi
Categories: cs.SE cs.AI
\\
  As software development practices increasingly adopt AI-powered tools,
ensuring that such tools can support secure coding has become critical. This
study evaluates the effectiveness of GitHub Copilot's recently introduced code
review feature in detecting security vulnerabilities. Using a curated set of
labeled vulnerable code samples drawn from diverse open-source projects
spanning multiple programming languages and application domains, we
systematically assessed Copilot's ability to identify and provide feedback on
common security flaws. Contrary to expectations, our results reveal that
Copilot's code review frequently fails to detect critical vulnerabilities such
as SQL injection, cross-site scripting (XSS), and insecure deserialization.
Instead, its feedback primarily addresses low-severity issues, such as coding
style and typographical errors. These findings expose a significant gap between
the perceived capabilities of AI-assisted code review and its actual
effectiveness in supporting secure development practices. Our results highlight
the continued necessity of dedicated security tools and manual code audits to
ensure robust software security.
\\ ( https://arxiv.org/abs/2509.13650 ,  3335kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13666 (*cross-listing*)
Date: Wed, 17 Sep 2025 03:35:52 GMT   (5522kb)

Title: DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater
  Monitoring
Authors: Zhenqi Wu, Abhinav Modi, Angelos Mavrogiannis, Kaustubh Joshi, Nikhil
  Chopra, Yiannis Aloimonos, Nare Karapetyan, Ioannis Rekleitis, Xiaomin Lin
Categories: cs.RO cs.AI
Comments: submitted to ICRA 2026
\\
  The ocean is warming and acidifying, increasing the risk of mass mortality
events for temperature-sensitive shellfish such as oysters. This motivates the
development of long-term monitoring systems. However, human labor is costly and
long-duration underwater work is highly hazardous, thus favoring robotic
solutions as a safer and more efficient option. To enable underwater robots to
make real-time, environment-aware decisions without human intervention, we must
equip them with an intelligent "brain." This highlights the need for
persistent,wide-area, and low-cost benthic monitoring. To this end, we present
DREAM, a Vision Language Model (VLM)-guided autonomy framework for long-term
underwater exploration and habitat monitoring. The results show that our
framework is highly efficient in finding and exploring target objects (e.g.,
oysters, shipwrecks) without prior location information. In the
oyster-monitoring task, our framework takes 31.5% less time than the previous
baseline with the same amount of oysters. Compared to the vanilla VLM, it uses
23% fewer steps while covering 8.88% more oysters. In shipwreck scenes, our
framework successfully explores and maps the wreck without collisions,
requiring 27.5% fewer steps than the vanilla model and achieving 100% coverage,
while the vanilla model achieves 60.23% average coverage in our shipwreck
environments.
\\ ( https://arxiv.org/abs/2509.13666 ,  5522kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13680 (*cross-listing*)
Date: Wed, 17 Sep 2025 04:17:42 GMT   (151kb)

Title: Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and
  Personality-Driven Variations
Authors: Wei Ma, Yixiao Yang, Jingquan Ge, Xiaofei Xie, Lingxiao Jiang
Categories: cs.SE cs.AI
\\
  Code generation models are widely used in software development, yet their
sensitivity to prompt phrasing remains under-examined. Identical requirements
expressed with different emotions or communication styles can yield divergent
outputs, while most benchmarks emphasize only peak performance. We present
PromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically
equivalent prompt variants with emotion and personality templates, and that
evaluates stability using probability aware continuous scoring or using binary
pass rates when logits are unavailable. The results are aggregated into a
proposed area under curve metric (AUC-E) for cross model comparison. Across 14
models from three families (Llama, Qwen, and DeepSeek), our study shows that
performance and stability behave as largely decoupled optimization objectives,
and it reveals architectural and scale related patterns that challenge common
assumptions about model robustness. The framework supports rapid screening for
closed-source models as well as detailed stability analysis in research
settings. PromptSE enables practitioners to quantify performance stability
trade offs for deployment and model selection, positioning prompt stability as
a complementary evaluation dimension alongside performance and fairness, and
contributing to more trustworthy AI-assisted software development tools.
\\ ( https://arxiv.org/abs/2509.13680 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13688 (*cross-listing*)
Date: Wed, 17 Sep 2025 04:35:48 GMT   (7886kb)

Title: CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson
  Seamless Fusion
Authors: James Jincheng, Youcheng Cai, Ligang Liu
Categories: cs.GR cs.AI
\\
  Controllable, high-fidelity mesh editing remains a significant challenge in
3D content creation. Existing generative methods often struggle with complex
geometries and fail to produce detailed results. We propose CraftMesh, a novel
framework for high-fidelity generative mesh manipulation via Poisson Seamless
Fusion. Our key insight is to decompose mesh editing into a pipeline that
leverages the strengths of 2D and 3D generative models: we edit a 2D reference
image, then generate a region-specific 3D mesh, and seamlessly fuse it into the
original model. We introduce two core techniques: Poisson Geometric Fusion,
which utilizes a hybrid SDF/Mesh representation with normal blending to achieve
harmonious geometric integration, and Poisson Texture Harmonization for
visually consistent texture blending. Experimental results demonstrate that
CraftMesh outperforms state-of-the-art methods, delivering superior global
consistency and local detail in complex editing tasks.
\\ ( https://arxiv.org/abs/2509.13688 ,  7886kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13735 (*cross-listing*)
Date: Wed, 17 Sep 2025 06:39:18 GMT   (991kb)

Title: State Space Models over Directed Graphs
Authors: Junzhi She, Xunkai Li, Rong-Hua Li, Guoren Wang
Categories: cs.LG cs.AI
Comments: currently undergoing review by IEEE Transactions on Big Data
\\
  Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.
\\ ( https://arxiv.org/abs/2509.13735 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13755 (*cross-listing*)
Date: Wed, 17 Sep 2025 07:12:35 GMT   (830kb)

Title: Scrub It Out! Erasing Sensitive Memorization in Code Language Models via
  Machine Unlearning
Authors: Zhaoyang Chu, Yao Wan, Zhikun Zhang, Di Wang, Zhou Yang, Hongyu Zhang,
  Pan Zhou, Xuanhua Shi, Hai Jin, David Lo
Categories: cs.SE cs.AI cs.CR
Comments: Accepted at the 48th IEEE/ACM International Conference on Software
  Engineering (ICSE 2026)
DOI: 10.1145/3744916.3764573
\\
  While Code Language Models (CLMs) have demonstrated superior performance in
software engineering tasks such as code generation and summarization, recent
empirical studies reveal a critical privacy vulnerability: these models exhibit
unintended memorization of sensitive training data, enabling verbatim
reproduction of confidential information when specifically prompted. To address
this issue, several approaches, including training data de-duplication and
differential privacy augmentation, have been proposed. However, these methods
require full-model retraining for deployed CLMs, which incurs substantial
computational costs. In this paper, we aim to answer the following research
question: Can sensitive information memorized by CLMs be erased effectively and
efficiently?
  We conduct a pioneering investigation into erasing sensitive memorization in
CLMs through machine unlearning - a post-hoc modification method that removes
specific information from trained models without requiring full retraining.
Specifically, we first quantify the memorization risks of sensitive data within
CLM training datasets and curate a high-risk dataset of 50,000 sensitive
memorized samples as unlearning targets. We study two widely used gradient
ascent-based unlearning approaches: the vanilla and constraint-based methods,
and introduce CodeEraser, an advanced variant that selectively unlearns
sensitive memorized segments in code while preserving the structural integrity
and functional correctness of the surrounding code. Extensive experiments on
three families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,
validate the effectiveness and efficiency of CodeEraser in erasing targeted
sensitive memorization while maintaining model utility.
\\ ( https://arxiv.org/abs/2509.13755 ,  830kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13782 (*cross-listing*)
Date: Wed, 17 Sep 2025 07:50:44 GMT   (524kb)

Title: Who is Introducing the Failure? Automatically Attributing Failures of
  Multi-Agent Systems via Spectrum Analysis
Authors: Yu Ge (1), Linna Xie (1), Zhong Li (1), Yu Pei (2), Tian Zhang (1)
  ((1) Nanjing University, (2) The Hong Kong Polytechnic University)
Categories: cs.SE cs.AI cs.MA
Comments: 20 pages, 6 figures
ACM-class: D.2.2; I.2.1
\\
  Large Language Model Powered Multi-Agent Systems (MASs) are increasingly
employed to automate complex real-world problems, such as programming and
scientific discovery. Despite their promising, MASs are not without their
flaws. However, failure attribution in MASs - pinpointing the specific agent
actions responsible for failures - remains underexplored and labor-intensive,
posing significant challenges for debugging and system improvement. To bridge
this gap, we propose FAMAS, the first spectrum-based failure attribution
approach for MASs, which operates through systematic trajectory replay and
abstraction, followed by spectrum analysis.The core idea of FAMAS is to
estimate, from variations across repeated MAS executions, the likelihood that
each agent action is responsible for the failure. In particular, we propose a
novel suspiciousness formula tailored to MASs, which integrates two key factor
groups, namely the agent behavior group and the action behavior group, to
account for the agent activation patterns and the action activation patterns
within the execution trajectories of MASs. Through expensive evaluations
against 12 baselines on the Who and When benchmark, FAMAS demonstrates superior
performance by outperforming all the methods in comparison.
\\ ( https://arxiv.org/abs/2509.13782 ,  524kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13805 (*cross-listing*)
Date: Wed, 17 Sep 2025 08:19:57 GMT   (5623kb)

Title: Towards a Physics Foundation Model
Authors: Florian Wiesner, Matthias Wessling, Stephen Baek
Categories: cs.LG cs.AI stat.ML
\\
  Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.
\\ ( https://arxiv.org/abs/2509.13805 ,  5623kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13854 (*cross-listing*)
Date: Wed, 17 Sep 2025 09:39:38 GMT   (578kb)

Title: Understanding the Process of Human-AI Value Alignment
Authors: Jack McKinlay, Marina De Vos, Janina A. Hoffmann, Andreas Theodorou
Categories: cs.CY cs.AI
Comments: 39 pages, 7 figures
\\
  Background: Value alignment in computer science research is often used to
refer to the process of aligning artificial intelligence with humans, but the
way the phrase is used often lacks precision. Objectives: In this paper, we
conduct a systematic literature review to advance the understanding of value
alignment in artificial intelligence by characterising the topic in the context
of its research literature. We use this to suggest a more precise definition of
the term. Methods: We analyse 172 value alignment research articles that have
been published in recent years and synthesise their content using thematic
analyses. Results: Our analysis leads to six themes: value alignment drivers &
approaches; challenges in value alignment; values in value alignment; cognitive
processes in humans and AI; human-agent teaming; and designing and developing
value-aligned systems. Conclusions: By analysing these themes in the context of
the literature we define value alignment as an ongoing process between humans
and autonomous agents that aims to express and implement abstract values in
diverse contexts, while managing the cognitive limits of both humans and AI
agents and also balancing the conflicting ethical and political demands
generated by the values in different groups. Our analysis gives rise to a set
of research challenges and opportunities in the field of value alignment for
future work.
\\ ( https://arxiv.org/abs/2509.13854 ,  578kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13866 (*cross-listing*)
Date: Wed, 17 Sep 2025 09:57:31 GMT   (4416kb)

Title: Masked Diffusion Models as Energy Minimization
Authors: Sitong Chen, Shen Nie, Jiacheng Sun, Zijin Feng, Zhenguo Li, Ji-Rong
  Wen, Chongxuan Li
Categories: cs.LG cs.AI
\\
  We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.
\\ ( https://arxiv.org/abs/2509.13866 ,  4416kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13892 (*cross-listing*)
Date: Wed, 17 Sep 2025 10:42:06 GMT   (59kb)

Title: Synthetic Data Generation for Screen Time and App Usage
Authors: Gustavo Kruger, Nikhil Sachdeva, Michael Sobolev
Categories: cs.HC cs.AI
Comments: 14 pages
ACM-class: I.2; J.4
Journal-ref: International Conference on Computer-Human Interaction Research
  and Applications (CHIRA) 2025
\\
  Smartphone usage data can provide valuable insights for understanding
interaction with technology and human behavior. However, collecting
large-scale, in-the-wild smartphone usage logs is challenging due to high
costs, privacy concerns, under representative user samples and biases like
non-response that can skew results. These challenges call for exploring
alternative approaches to obtain smartphone usage datasets. In this context,
large language models (LLMs) such as Open AI's ChatGPT present a novel approach
for synthetic smartphone usage data generation, addressing limitations of
real-world data collection. We describe a case study on how four prompt
strategies influenced the quality of generated smartphone usage data. We
contribute with insights on prompt design and measures of data quality,
reporting a prompting strategy comparison combining two factors, prompt level
of detail (describing a user persona, describing the expected results
characteristics) and seed data inclusion (with versus without an initial real
usage example). Our findings suggest that using LLMs to generate structured and
behaviorally plausible smartphone use datasets is feasible for some use cases,
especially when using detailed prompts. Challenges remain in capturing diverse
nuances of human behavioral patterns in a single synthetic dataset, and
evaluating tradeoffs between data fidelity and diversity, suggesting the need
for use-case-specific evaluation metrics and future research with more diverse
seed data and different LLM models.
\\ ( https://arxiv.org/abs/2509.13892 ,  59kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13895 (*cross-listing*)
Date: Wed, 17 Sep 2025 10:43:05 GMT   (2806kb)

Title: FedSSG: Expectation-Gated and History-Aware Drift Alignment for
  Federated Learning
Authors: Zhanting Zhou and Jinshan Lai and Fengchun Zhang and Zeqin Wu and
  Fengli Zhang
Categories: cs.LG cs.AI
Comments: 4 page main text for conference
\\
  Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.
\\ ( https://arxiv.org/abs/2509.13895 ,  2806kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13914 (*cross-listing*)
Date: Wed, 17 Sep 2025 11:18:16 GMT   (3253kb)

Title: Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction
Authors: Divya Thuremella, Yi Yang, Simon Wanna, Lars Kunze, and Daniele De
  Martini
Categories: cs.LG cs.AI
Comments: Accepted 2025 IEEE International Conference on Intelligent
  Transportation Systems (ITSC 2025)
\\
  This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.
\\ ( https://arxiv.org/abs/2509.13914 ,  3253kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13926 (*cross-listing*)
Date: Wed, 17 Sep 2025 11:40:46 GMT   (267kb)

Title: MAP: End-to-End Autonomous Driving with Map-Assisted Planning
Authors: Huilin Yin, Yiming Kan, Daniel Watzenig
Categories: cs.RO cs.AI cs.CV
Comments: 8 pages, 2 figures, accepted by ICCVW Author list updated to match
  the camera-ready version, in compliance with conference policy
ACM-class: I.2.9; I.2.10
\\
  In recent years, end-to-end autonomous driving has attracted increasing
attention for its ability to jointly model perception, prediction, and planning
within a unified framework. However, most existing approaches underutilize the
online mapping module, leaving its potential to enhance trajectory planning
largely untapped. This paper proposes MAP (Map-Assisted Planning), a novel
map-assisted end-to-end trajectory planning framework. MAP explicitly
integrates segmentation-based map features and the current ego status through a
Plan-enhancing Online Mapping module, an Ego-status-guided Planning module, and
a Weight Adapter based on current ego status. Experiments conducted on the
DAIR-V2X-seq-SPD dataset demonstrate that the proposed method achieves a 16.6%
reduction in L2 displacement error, a 56.2% reduction in off-road rate, and a
44.5% improvement in overall score compared to the UniV2X baseline, even
without post-processing. Furthermore, it achieves top ranking in Track 2 of the
End-to-End Autonomous Driving through V2X Cooperation Challenge of MEIS
Workshop @CVPR2025, outperforming the second-best model by 39.5% in terms of
overall score. These results highlight the effectiveness of explicitly
leveraging semantic map features in planning and suggest new directions for
improving structure design in end-to-end autonomous driving systems. Our code
is available at https://gitee.com/kymkym/map.git
\\ ( https://arxiv.org/abs/2509.13926 ,  267kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13927 (*cross-listing*)
Date: Wed, 17 Sep 2025 12:51:51 GMT   (58kb)

Title: DSpAST: Disentangled Representations for Spatial Audio Reasoning with
  Large Language Models
Authors: Kevin Wilkinghoff and Zheng-Hua Tan
Categories: eess.AS cs.AI cs.SD
\\
  Reasoning about spatial audio with large language models requires a spatial
audio encoder as an acoustic front-end to obtain audio embeddings for further
processing. Such an encoder needs to capture all information required to detect
the type of sound events, as well as the direction and distance of their
corresponding sources. Accomplishing this with a single audio encoder is
demanding as the information required for each of these tasks is mostly
independent of each other. As a result, the performance obtained with a single
encoder is often worse than when using task-specific audio encoders. In this
work, we present DSpAST, a novel audio encoder based on SpatialAST that learns
disentangled representations of spatial audio while having only 0.2% additional
parameters. Experiments on SpatialSoundQA with the spatial audio reasoning
system BAT demonstrate that DSpAST significantly outperforms SpatialAST.
\\ ( https://arxiv.org/abs/2509.13927 ,  58kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13941 (*cross-listing*)
Date: Wed, 17 Sep 2025 13:07:52 GMT   (1439kb)

Title: An Empirical Study on Failures in Automated Issue Solving
Authors: Simiao Liu, Fang Liu, Liehao Li, Xin Tan, Yinghao Zhu, Xiaoli Lian, Li
  Zhang
Categories: cs.SE cs.AI cs.CL
\\
  Automated issue solving seeks to autonomously identify and repair defective
code snippets across an entire codebase. SWE-Bench has emerged as the most
widely adopted benchmark for evaluating progress in this area. While LLM-based
agentic tools show great promise, they still fail on a substantial portion of
tasks. Moreover, current evaluations primarily report aggregate issue-solving
rates, which obscure the underlying causes of success and failure, making it
challenging to diagnose model weaknesses or guide targeted improvements. To
bridge this gap, we first analyze the performance and efficiency of three SOTA
tools, spanning both pipeline-based and agentic architectures, in automated
issue solving tasks of SWE-Bench-Verified under varying task characteristics.
Furthermore, to move from high-level performance metrics to underlying cause
analysis, we conducted a systematic manual analysis of 150 failed instances.
From this analysis, we developed a comprehensive taxonomy of failure modes
comprising 3 primary phases, 9 main categories, and 25 fine-grained
subcategories. Then we systematically analyze the distribution of the
identified failure modes, the results reveal distinct failure fingerprints
between the two architectural paradigms, with the majority of agentic failures
stemming from flawed reasoning and cognitive deadlocks. Motivated by these
insights, we propose a collaborative Expert-Executor framework. It introduces a
supervisory Expert agent tasked with providing strategic oversight and
course-correction for a primary Executor agent. This architecture is designed
to correct flawed reasoning and break the cognitive deadlocks that frequently
lead to failure. Experiments show that our framework solves 22.2% of previously
intractable issues for a leading single agent. These findings pave the way for
building more robust agents through diagnostic evaluation and collaborative
design.
\\ ( https://arxiv.org/abs/2509.13941 ,  1439kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13987 (*cross-listing*)
Date: Wed, 17 Sep 2025 13:59:38 GMT   (460kb)

Title: Differential Privacy in Federated Learning: Mitigating Inference Attacks
  with Randomized Response
Authors: Ozer Ozturk, Busra Buyuktanir, Gozde Karatas Baydogmus, Kazim Yildiz
Categories: cs.CR cs.AI
\\
  Machine learning models used for distributed architectures consisting of
servers and clients require large amounts of data to achieve high accuracy.
Data obtained from clients are collected on a central server for model
training. However, storing data on a central server raises concerns about
security and privacy. To address this issue, a federated learning architecture
has been proposed. In federated learning, each client trains a local model
using its own data. The trained models are periodically transmitted to the
central server. The server then combines the received models using federated
aggregation algorithms to obtain a global model. This global model is
distributed back to the clients, and the process continues in a cyclical
manner. Although preventing data from leaving the clients enhances security,
certain concerns still remain. Attackers can perform inference attacks on the
obtained models to approximate the training dataset, potentially causing data
leakage. In this study, differential privacy was applied to address the
aforementioned security vulnerability, and a performance analysis was
conducted. The Data-Unaware Classification Based on Association (duCBA)
algorithm was used as the federated aggregation method. Differential privacy
was implemented on the data using the Randomized Response technique, and the
trade-off between security and performance was examined under different epsilon
values. As the epsilon value decreased, the model accuracy declined, and class
prediction imbalances were observed. This indicates that higher levels of
privacy do not always lead to practical outcomes and that the balance between
security and performance must be carefully considered.
\\ ( https://arxiv.org/abs/2509.13987 ,  460kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14003 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:13:40 GMT   (6824kb)

Title: RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing
Authors: Liting Gao, Yi Yuan, Yaru Chen, Yuelan Cheng, Zhenbo Li, Juan Wen,
  Shubin Zhang, Wenwu Wang
Categories: cs.SD cs.AI
\\
  Diffusion models have shown remarkable progress in text-to-audio generation.
However, text-guided audio editing remains in its early stages. This task
focuses on modifying the target content within an audio signal while preserving
the rest, thus demanding precise localization and faithful editing according to
the text prompt. Existing training-based and zero-shot methods that rely on
full-caption or costly optimization often struggle with complex editing or lack
practicality. In this work, we propose a novel end-to-end efficient rectified
flow matching-based diffusion framework for audio editing, and construct a
dataset featuring overlapping multi-event audio to support training and
benchmarking in complex scenarios. Experiments show that our model achieves
faithful semantic alignment without requiring auxiliary captions or masks,
while maintaining competitive editing quality across metrics.
\\ ( https://arxiv.org/abs/2509.14003 ,  6824kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14037 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:38:52 GMT   (1216kb)

Title: PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease
  Similarity Prediction
Authors: Ranga Baminiwatte, Kazi Jewel Rana, Aaron J. Masino
Categories: q-bio.GN cs.AI cs.LG
\\
  Understanding disease similarity is critical for advancing diagnostics, drug
discovery, and personalized treatment strategies. We present PhenoGnet, a novel
graph-based contrastive learning framework designed to predict disease
similarity by integrating gene functional interaction networks with the Human
Phenotype Ontology (HPO). PhenoGnet comprises two key components: an intra-view
model that separately encodes gene and phenotype graphs using Graph
Convolutional Networks (GCNs) and Graph Attention Networks (GATs), and a cross
view model implemented as a shared weight multilayer perceptron (MLP) that
aligns gene and phenotype embeddings through contrastive learning. The model is
trained using known gene phenotype associations as positive pairs and randomly
sampled unrelated pairs as negatives. Diseases are represented by the mean
embeddings of their associated genes and/or phenotypes, and pairwise similarity
is computed via cosine similarity. Evaluation on a curated benchmark of 1,100
similar and 866 dissimilar disease pairs demonstrates strong performance, with
gene based embeddings achieving an AUCPR of 0.9012 and AUROC of 0.8764,
outperforming existing state of the art methods. Notably, PhenoGnet captures
latent biological relationships beyond direct overlap, offering a scalable and
interpretable solution for disease similarity prediction. These results
underscore its potential for enabling downstream applications in rare disease
research and precision medicine.
\\ ( https://arxiv.org/abs/2509.14037 ,  1216kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14040 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:42:18 GMT   (4573kb)

Title: Prompt2Auto: From Motion Prompt to Automated Control via
  Geometry-Invariant One-Shot Gaussian Process Learning
Authors: Zewen Yang, Xiaobing Dai, Dongfa Zhang, Yu Li, Ziyang Meng, Bingkun
  Huang, Hamid Sadeghian, Sami Haddadin
Categories: cs.RO cs.AI cs.SY eess.SY
\\
  Learning from demonstration allows robots to acquire complex skills from
human demonstrations, but conventional approaches often require large datasets
and fail to generalize across coordinate transformations. In this paper, we
propose Prompt2Auto, a geometry-invariant one-shot Gaussian process (GeoGP)
learning framework that enables robots to perform human-guided automated
control from a single motion prompt. A dataset-construction strategy based on
coordinate transformations is introduced that enforces invariance to
translation, rotation, and scaling, while supporting multi-step predictions.
Moreover, GeoGP is robust to variations in the user's motion prompt and
supports multi-skill autonomy. We validate the proposed approach through
numerical simulations with the designed user graphical interface and two
real-world robotic experiments, which demonstrate that the proposed method is
effective, generalizes across tasks, and significantly reduces the
demonstration burden. Project page is available at:
https://prompt2auto.github.io
\\ ( https://arxiv.org/abs/2509.14040 ,  4573kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14049 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:53:56 GMT   (9812kb)

Title: Comprehensive Evaluation of CNN-Based Audio Tagging Models on
  Resource-Constrained Devices
Authors: Jordi Grau-Haro, Ruben Ribes-Serrano, Javier Naranjo-Alcazar, Marta
  Garcia-Ballesteros and Pedro Zuccarello
Categories: cs.SD cs.AI
Comments: Accepted at Computing Conference 2026, London, UK
\\
  Convolutional Neural Networks (CNNs) have demonstrated exceptional
performance in audio tagging tasks. However, deploying these models on
resource-constrained devices like the Raspberry Pi poses challenges related to
computational efficiency and thermal management. In this paper, a comprehensive
evaluation of multiple convolutional neural network (CNN) architectures for
audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D
models from the Pretrained Audio Neural Networks (PANNs) framework, a
ConvNeXt-based model adapted for audio classification, as well as MobileNetV3
architectures. In addition, two PANNs-derived networks, CNN9 and CNN13,
recently proposed, are also evaluated. To enhance deployment efficiency and
portability across diverse hardware platforms, all models are converted to the
Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on
a single model, our analysis encompasses a broader range of architectures and
involves continuous 24-hour inference sessions to assess performance stability.
Our experiments reveal that, with appropriate model selection and optimization,
it is possible to maintain consistent inference latency and manage thermal
behavior effectively over extended periods. These findings provide valuable
insights for deploying audio tagging models in real-world edge computing
scenarios.
\\ ( https://arxiv.org/abs/2509.14049 ,  9812kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14057 (*cross-listing*)
Date: Wed, 17 Sep 2025 15:03:39 GMT   (18109kb)

Title: Machines are more productive than humans until they aren't, and vice
  versa
Authors: Riccardo Zanardelli
Categories: econ.GN cs.AI q-fin.EC
\\
  With the growth of artificial skills, organizations may increasingly confront
with the problem of optimizing skill policy decisions guided by economic
principles. This paper addresses the underlying complexity of this challenge by
developing an in-silico framework based on Monte Carlo simulations grounded in
empirical realism to analyze the economic impact of human and machine skills,
individually or jointly deployed, in the execution of tasks presenting varying
levels of complexity. Our results provide quantitative support for the
established notions that automation tends to be the most economically-effective
strategy for tasks characterized by low-to-medium generalization difficulty,
while automation struggles to match the economic utility of human skills in
more complex scenarios. Critically, our simulations highlight that combining
human and machine skills can be the most effective strategy when a high level
of generalization is required, but only if genuine augmentation is achieved. In
contrast, when failing to realize this synergy, the human-machine policy is
severely penalized by the inherent costs of its dual skill structure, causing
it to destroy value and becoming the worst choice from an economic perspective.
The takeaway for decision-makers is unambiguous: simply allocating human and
machine skills to a task is insufficient, and a human-machine skill policy is
neither a silver-bullet solution nor a low-risk compromise. Rather, it is a
critical opportunity to boost competitiveness that demands a strong
organizational commitment to enabling augmentation. Also, our findings show
that improving the cost-effectiveness of machine skills over time, while
useful, does not replace the fundamental need to focus on achieving
augmentation.
\\ ( https://arxiv.org/abs/2509.14057 ,  18109kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14061 (*cross-listing*)
Date: Wed, 17 Sep 2025 15:05:15 GMT   (1540kb)

Title: Queen Detection in Beehives via Environmental Sensor Fusion for
  Low-Power Edge Computing
Authors: Chiara De Luca and Elisa Donati
Categories: cs.LG cs.AI
\\
  Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.
\\ ( https://arxiv.org/abs/2509.14061 ,  1540kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14093 (*cross-listing*)
Date: Wed, 17 Sep 2025 15:33:44 GMT   (261kb)

Title: Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A
  Self-Optimizing Framework
Authors: Kerui Huang, Shuhan Liu, Xing Hu, Tongtong Xu, Lingfeng Bao, Xin Xia
Categories: cs.SE cs.AI cs.CL
\\
  Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.
\\ ( https://arxiv.org/abs/2509.14093 ,  261kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14172 (*cross-listing*)
Date: Wed, 17 Sep 2025 16:58:44 GMT   (1194kb)

Title: TGPO: Tree-Guided Preference Optimization for Robust Web Agent
  Reinforcement Learning
Authors: Ziyuan Chen, Zhenghui Zhao, Zhangye Han, Miancan Liu, Xianhang Ye,
  Yiqing Li, Hongbo Min, Jinkui Ren, Xiantao Zhang, Guitao Cao
Categories: cs.LG cs.AI
\\
  With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.
\\ ( https://arxiv.org/abs/2509.14172 ,  1194kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14181 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:12:39 GMT   (7336kb)

Title: Bridging Past and Future: Distribution-Aware Alignment for Time Series
  Forecasting
Authors: Yifan Hu, Jie Yang, Tian Zhou, Peiyuan Liu, Yujin Tang, Rong Jin,
  Liang Sun
Categories: cs.LG cs.AI
\\
  Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.
\\ ( https://arxiv.org/abs/2509.14181 ,  7336kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14216 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:50:59 GMT   (6682kb)

Title: A Universal Banach--Bregman Framework for Stochastic Iterations:
  Unifying Stochastic Mirror Descent, Learning and LLM Training
Authors: Johnny R. Zhang (Independent Researcher), Xiaomei Mi (University of
  Manchester), Gaoyuan Du (Amazon), Qianyi Sun (Microsoft), Shiqi Wang (Meta),
  Jiaxuan Li (Amazon), Wenhua Zhou (Independent Researcher)
Categories: cs.LG cs.AI
Comments: 69 pages, 10 figures. Preprint
\\
  Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.
\\ ( https://arxiv.org/abs/2509.14216 ,  6682kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14223 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:54:22 GMT   (1375kb)

Title: Language models' activations linearly encode training-order recency
Authors: Dmitrii Krasheninnikov, Richard E. Turner, David Krueger
Categories: cs.LG cs.AI cs.CL
\\
  We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.
\\ ( https://arxiv.org/abs/2509.14223 ,  1375kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12577 (*cross-listing*)
Date: Tue, 16 Sep 2025 02:08:11 GMT   (1618kb)

Title: An AI-Powered Framework for Analyzing Collective Idea Evolution in
  Deliberative Assemblies
Authors: Elinor Poole-Dayan, Deb Roy, Jad Kabbara
Categories: cs.CY cs.CL
\\
  In an era of increasing societal fragmentation, political polarization, and
erosion of public trust in institutions, representative deliberative assemblies
are emerging as a promising democratic forum for developing effective policy
outcomes on complex global issues. Despite theoretical attention, there remains
limited empirical work that systematically traces how specific ideas evolve,
are prioritized, or are discarded during deliberation to form policy
recommendations. Addressing these gaps, this work poses two central questions:
(1) How might we trace the evolution and distillation of ideas into concrete
recommendations within deliberative assemblies? (2) How does the deliberative
process shape delegate perspectives and influence voting dynamics over the
course of the assembly? To address these questions, we develop LLM-based
methodologies for empirically analyzing transcripts from a tech-enhanced
in-person deliberative assembly. The framework identifies and visualizes the
space of expressed suggestions. We also empirically reconstruct each delegate's
evolving perspective throughout the assembly. Our methods contribute novel
empirical insights into deliberative processes and demonstrate how LLMs can
surface high-resolution dynamics otherwise invisible in traditional assembly
outputs.
\\ ( https://arxiv.org/abs/2509.12577 ,  1618kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13356 (*cross-listing*)
Date: Sun, 14 Sep 2025 18:19:55 GMT   (1300kb)

Title: CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe
  and Transparent AI
Authors: Hasin Jawad Ali, Ilhamul Azam, Ajwad Abrar, Md. Kamrul Hasan, Hasan
  Mahmud
Categories: cs.CY cs.CL
\\
  The challenge of aligning artificial intelligence (AI) with human values
persists due to the abstract and often conflicting nature of moral principles
and the opacity of existing approaches. This paper introduces CogniAlign, a
multi-agent deliberation framework based on naturalistic moral realism, that
grounds moral reasoning in survivability, defined across individual and
collective dimensions, and operationalizes it through structured deliberations
among discipline-specific scientist agents. Each agent, representing
neuroscience, psychology, sociology, and evolutionary biology, provides
arguments and rebuttals that are synthesized by an arbiter into transparent and
empirically anchored judgments. We evaluate CogniAlign on classic and novel
moral questions and compare its outputs against GPT-4o using a five-part
ethical audit framework. Results show that CogniAlign consistently outperforms
the baseline across more than sixty moral questions, with average performance
gains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4
points in depth of explanation. In the Heinz dilemma, for example, CogniAlign
achieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a
decisive advantage in handling moral reasoning. By reducing black-box reasoning
and avoiding deceptive alignment, CogniAlign highlights the potential of
interdisciplinary deliberation as a scalable pathway for safe and transparent
AI alignment.
\\ ( https://arxiv.org/abs/2509.13356 ,  1300kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13625 (*cross-listing*)
Date: Wed, 17 Sep 2025 01:50:32 GMT   (164kb)

Title: Privacy-Aware In-Context Learning for Large Language Models
Authors: Bishnu Bhusal, Manoj Acharya, Ramneet Kaur, Colin Samplawski, Anirban
  Roy, Adam D. Cobb, Rohit Chadha, Susmit Jha
Categories: cs.LG cs.CL cs.CR
\\
  Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.
\\ ( https://arxiv.org/abs/2509.13625 ,  164kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13853 (*cross-listing*)
Date: Wed, 17 Sep 2025 09:38:47 GMT   (346kb)

Title: Noise Supervised Contrastive Learning and Feature-Perturbed for
  Anomalous Sound Detection
Authors: Shun Huang, Zhihua Fang, Liang He
Categories: cs.SD cs.CL
Comments: Accept ICASSP 2025
\\
  Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.
\\ ( https://arxiv.org/abs/2509.13853 ,  346kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13957 (*cross-listing*)
Date: Wed, 17 Sep 2025 13:28:46 GMT   (11368kb)

Title: Enhancing Time Awareness in Generative Recommendation
Authors: Sunkyung Lee, Seongmin Park, Jonghyo Kim, Mincheol Yoon, Jongwuk Lee
Categories: cs.IR cs.CL
Comments: EMNLP 2025 (Findings)
\\
  Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.
\\ ( https://arxiv.org/abs/2509.13957 ,  11368kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14041 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:42:38 GMT   (183kb)

Title: A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval
  Prediction For Instruction Caching
Authors: Henry Kao, Nikhil Sreekumar, Prabhdeep Singh Soni, Ali Sedaghati, Fang
  Su, Bryan Chan, Maziar Goudarzi, Reza Azimi
Categories: cs.AR cs.CL cs.OS cs.PF
\\
  Modern mobile CPU software pose challenges for conventional instruction cache
replacement policies due to their complex runtime behavior causing high reuse
distance between executions of the same instruction. Mobile code commonly
suffers from large amounts of stalls in the CPU frontend and thus starvation of
the rest of the CPU resources. Complexity of these applications and their code
footprint are projected to grow at a rate faster than available on-chip memory
due to power and area constraints, making conventional hardware-centric methods
for managing instruction caches to be inadequate. We present a novel
software-hardware co-design approach called TRRIP (Temperature-based
Re-Reference Interval Prediction) that enables the compiler to analyze,
classify, and transform code based on "temperature" (hot/cold), and to provide
the hardware with a summary of code temperature information through a
well-defined OS interface based on using code page attributes. TRRIP's
lightweight hardware extension employs code temperature attributes to optimize
the instruction cache replacement policy resulting in the eviction rate
reduction of hot code. TRRIP is designed to be practical and adoptable in real
mobile systems that have strict feature requirements on both the software and
hardware components. TRRIP can reduce the L2 MPKI for instructions by 26.5%
resulting in geomean speedup of 3.9%, on top of RRIP cache replacement running
mobile code already optimized using PGO.
\\ ( https://arxiv.org/abs/2509.14041 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14132 (*cross-listing*)
Date: Wed, 17 Sep 2025 16:13:37 GMT   (662kb)

Title: When Avatars Have Personality: Effects on Engagement and Communication
  in Immersive Medical Training
Authors: Julia S. Dollis, Iago A. Brito, Fernanda B. F\"arber, Pedro S. F. B.
  Ribeiro, Rafael T. Sousa, Arlindo R. Galv\~ao Filho
Categories: cs.HC cs.CL
Comments: 8 pages, 2 figures
\\
  While virtual reality (VR) excels at simulating physical environments, its
effectiveness for training complex interpersonal skills is limited by a lack of
psychologically plausible virtual humans. This is a critical gap in high-stakes
domains like medical education, where communication is a core competency. This
paper introduces a framework that integrates large language models (LLMs) into
immersive VR to create medically coherent virtual patients with distinct,
consistent personalities, built on a modular architecture that decouples
personality from clinical data. We evaluated our system in a mixed-method,
within-subjects study with licensed physicians who engaged in simulated
consultations. Results demonstrate that the approach is not only feasible but
is also perceived by physicians as a highly rewarding and effective training
enhancement. Furthermore, our analysis uncovers critical design principles,
including a ``realism-verbosity paradox" where less communicative agents can
seem more artificial, and the need for challenges to be perceived as authentic
to be instructive. This work provides a validated framework and key insights
for developing the next generation of socially intelligent VR training
environments.
\\ ( https://arxiv.org/abs/2509.14132 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14221 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:53:43 GMT   (2129kb)

Title: GEM-Bench: A Benchmark for Ad-Injected Response Generation within
  Generative Engine Marketing
Authors: Silan Hu, Shiqi Zhang, Yimin Shi, Xiaokui Xiao
Categories: cs.IR cs.CL
\\
  Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.
\\ ( https://arxiv.org/abs/2509.14221 ,  2129kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13358 (*cross-listing*)
Date: Mon, 15 Sep 2025 08:23:01 GMT   (442kb)

Title: 3D Reconstruction of Coronary Vessel Trees from Biplanar X-Ray Images
  Using a Geometric Approach
Authors: Ethan Koland, Lin Xi, Nadeev Wijesuriya, YingLiang Ma
Categories: eess.IV cs.CV
\\
  X-ray angiography is widely used in cardiac interventions to visualize
coronary vessels, assess integrity, detect stenoses and guide treatment. We
propose a framework for reconstructing 3D vessel trees from biplanar X-ray
images which are extracted from two X-ray videos captured at different C-arm
angles. The proposed framework consists of three main components: image
segmentation, motion phase matching, and 3D reconstruction. An automatic video
segmentation method for X-ray angiography to enable semantic segmentation for
image segmentation and motion phase matching. The goal of the motion phase
matching is to identify a pair of X-ray images that correspond to a similar
respiratory and cardiac motion phase to reduce errors in 3D reconstruction.
This is achieved by tracking a stationary object such as a catheter or lead
within the X-ray video. The semantic segmentation approach assigns different
labels to different object classes enabling accurate differentiation between
blood vessels, balloons, and catheters. Once a suitable image pair is selected,
key anatomical landmarks (vessel branching points and endpoints) are matched
between the two views using a heuristic method that minimizes reconstruction
errors. This is followed by a novel geometric reconstruction algorithm to
generate the 3D vessel tree. The algorithm computes the 3D vessel centrelines
by determining the intersection of two 3D surfaces. Compared to traditional
methods based on epipolar constraints, the proposed approach simplifies there
construction workflow and improves overall accuracy. We trained and validated
our segmentation method on 62 X-ray angiography video sequences. On the test
set, our method achieved a segmentation accuracy of 0.703. The 3D
reconstruction framework was validated by measuring the reconstruction error of
key anatomical landmarks, achieving a reprojection errors of 0.62mm +/- 0.38mm.
\\ ( https://arxiv.org/abs/2509.13358 ,  442kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13360 (*cross-listing*)
Date: Mon, 15 Sep 2025 13:23:23 GMT   (3800kb)

Title: PREDICT-GBM: Platform for Robust Evaluation and Development of
  Individualized Computational Tumor Models in Glioblastoma
Authors: L. Zimmer, J. Weidner, M. Balcerak, F. Kofler, I. Ezhov, B. Menze, B.
  Wiestler
Categories: eess.IV cs.CV cs.LG q-bio.QM
\\
  Glioblastoma is the most prevalent primary brain malignancy, distinguished by
its highly invasive behavior and exceptionally high rates of recurrence.
Conventional radiation therapy, which employs uniform treatment margins, fails
to account for patient-specific anatomical and biological factors that
critically influence tumor cell migration. To address this limitation, numerous
computational models of glioblastoma growth have been developed, enabling
generation of tumor cell distribution maps extending beyond radiographically
visible regions and thus informing more precise treatment strategies. However,
despite encouraging preliminary findings, the clinical adoption of these growth
models remains limited. To bridge this translational gap and accelerate both
model development and clinical validation, we introduce PREDICT-GBM, a
comprehensive integrated pipeline and dataset for modeling and evaluation. This
platform enables systematic benchmarking of state-of-the-art tumor growth
models using an expert-curated clinical dataset comprising 255 subjects with
complete tumor segmentations and tissue characterization maps. Our analysis
demonstrates that personalized radiation treatment plans derived from tumor
growth predictions achieved superior recurrence coverage compared to
conventional uniform margin approaches for two of the evaluated models. This
work establishes a robust platform for advancing and systematically evaluating
cutting-edge tumor growth modeling approaches, with the ultimate goal of
facilitating clinical translation and improving patient outcomes.
\\ ( https://arxiv.org/abs/2509.13360 ,  3800kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13428 (*cross-listing*)
Date: Tue, 16 Sep 2025 18:07:00 GMT   (1476kb)

Title: Autonomous Reporting of Normal Chest X-rays by Artificial Intelligence
  in the United Kingdom. Can We Take the Human Out of the Loop?
Authors: Katrina Nash, James Vaz, Ahmed Maiter, Christopher Johns, Nicholas
  Woznitza, Aditya Kale, Abdala Espinosa Morgado, Rhidian Bramley, Mark Hall,
  David Lowe, Alex Novak, Sarim Ather
Categories: q-bio.PE cs.CV
\\
  Chest X-rays (CXRs) are the most commonly performed imaging investigation. In
the UK, many centres experience reporting delays due to radiologist workforce
shortages. Artificial intelligence (AI) tools capable of distinguishing normal
from abnormal CXRs have emerged as a potential solution. If normal CXRs could
be safely identified and reported without human input, a substantial portion of
radiology workload could be reduced.
  This article examines the feasibility and implications of autonomous AI
reporting of normal CXRs. Key issues include defining normal, ensuring
generalisability across populations, and managing the sensitivity-specificity
trade-off. It also addresses legal and regulatory challenges, such as
compliance with IR(ME)R and GDPR, and the lack accountability frameworks for
errors. Further considerations include the impact on radiologists practice, the
need for robust post-market surveillance, and incorporation of patient
perspectives. While the benefits are clear, adoption must be cautious.
\\ ( https://arxiv.org/abs/2509.13428 ,  1476kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13541 (*cross-listing*)
Date: Tue, 16 Sep 2025 21:14:16 GMT   (1038kb)

Title: Semantic 3D Reconstructions with SLAM for Central Airway Obstruction
Authors: Ayberk Acar, Fangjie Li, Hao Li, Lidia Al-Zogbi, Kanyifeechukwu Jane
  Oguine, Susheela Sharma Stern, Jesse F. d'Almeida, Robert J. Webster III,
  Ipek Oguz, Jie Ying Wu
Categories: cs.RO cs.CV
Comments: 5 pages, 2 figures, 1 table
\\
  Central airway obstruction (CAO) is a life-threatening condition with
increasing incidence, caused by tumors in and outside of the airway.
Traditional treatment methods such as bronchoscopy and electrocautery can be
used to remove the tumor completely; however, these methods carry a high risk
of complications. Recent advances allow robotic interventions with lesser risk.
The combination of robot interventions with scene understanding and mapping
also opens up the possibilities for automation. We present a novel pipeline
that enables real-time, semantically informed 3D reconstructions of the central
airway using monocular endoscopic video.
  Our approach combines DROID-SLAM with a segmentation model trained to
identify obstructive tissues. The SLAM module reconstructs the 3D geometry of
the airway in real time, while the segmentation masks guide the annotation of
obstruction regions within the reconstructed point cloud. To validate our
pipeline, we evaluate the reconstruction quality using ex vivo models.
  Qualitative and quantitative results show high similarity between ground
truth CT scans and the 3D reconstructions (0.62 mm Chamfer distance). By
integrating segmentation directly into the SLAM workflow, our system produces
annotated 3D maps that highlight clinically relevant regions in real time.
High-speed capabilities of the pipeline allows quicker reconstructions compared
to previous work, reflecting the surgical scene more accurately.
  To the best of our knowledge, this is the first work to integrate semantic
segmentation with real-time monocular SLAM for endoscopic CAO scenarios. Our
framework is modular and can generalize to other anatomies or procedures with
minimal changes, offering a promising step toward autonomous robotic
interventions.
\\ ( https://arxiv.org/abs/2509.13541 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13576 (*cross-listing*)
Date: Tue, 16 Sep 2025 22:35:13 GMT   (18209kb)

Title: Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for
  Sparse-View CT
Authors: Haodong Li, Shuo Han, Haiyang Mao, Yu Shi, Changsheng Fang, Jianjia
  Zhang, Weiwen Wu, Hengyong Yu
Categories: eess.IV cs.CV
Comments: 11 pages, 8 figures, under reviewing of IEEE TMI
MSC-class: 65R32
\\
  Sparse-View CT (SVCT) reconstruction enhances temporal resolution and reduces
radiation dose, yet its clinical use is hindered by artifacts due to view
reduction and domain shifts from scanner, protocol, or anatomical variations,
leading to performance degradation in out-of-distribution (OOD) scenarios. In
this work, we propose a Cross-Distribution Diffusion Priors-Driven Iterative
Reconstruction (CDPIR) framework to tackle the OOD problem in SVCT. CDPIR
integrates cross-distribution diffusion priors, derived from a Scalable
Interpolant Transformer (SiT), with model-based iterative reconstruction
methods. Specifically, we train a SiT backbone, an extension of the Diffusion
Transformer (DiT) architecture, to establish a unified stochastic interpolant
framework, leveraging Classifier-Free Guidance (CFG) across multiple datasets.
By randomly dropping the conditioning with a null embedding during training,
the model learns both domain-specific and domain-invariant priors, enhancing
generalizability. During sampling, the globally sensitive transformer-based
diffusion model exploits the cross-distribution prior within the unified
stochastic interpolant framework, enabling flexible and stable control over
multi-distribution-to-noise interpolation paths and decoupled sampling
strategies, thereby improving adaptation to OOD reconstruction. By alternating
between data fidelity and sampling updates, our model achieves state-of-the-art
performance with superior detail preservation in SVCT reconstructions.
Extensive experiments demonstrate that CDPIR significantly outperforms existing
approaches, particularly under OOD conditions, highlighting its robustness and
potential clinical value in challenging imaging scenarios.
\\ ( https://arxiv.org/abs/2509.13576 ,  18209kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13591 (*cross-listing*)
Date: Tue, 16 Sep 2025 23:25:05 GMT   (7678kb)

Title: Object Pose Estimation through Dexterous Touch
Authors: Amir-Hossein Shahidzadeh, Jiyue Zhu, Kezhou Chen, Sha Yi, Cornelia
  Ferm\"uller, Yiannis Aloimonos and Xiaolong Wang
Categories: cs.RO cs.CV
\\
  Robust object pose estimation is essential for manipulation and interaction
tasks in robotics, particularly in scenarios where visual data is limited or
sensitive to lighting, occlusions, and appearances. Tactile sensors often offer
limited and local contact information, making it challenging to reconstruct the
pose from partial data. Our approach uses sensorimotor exploration to actively
control a robot hand to interact with the object. We train with Reinforcement
Learning (RL) to explore and collect tactile data. The collected 3D point
clouds are used to iteratively refine the object's shape and pose. In our
setup, one hand holds the object steady while the other performs active
exploration. We show that our method can actively explore an object's surface
to identify critical pose features without prior knowledge of the object's
geometry. Supplementary material and more demonstrations will be provided at
https://amirshahid.github.io/BimanualTactilePose .
\\ ( https://arxiv.org/abs/2509.13591 ,  7678kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13612 (*cross-listing*)
Date: Wed, 17 Sep 2025 01:08:03 GMT   (12602kb)

Title: Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans
Authors: Chuyang Zhou, Ziao Ji, Daochang Liu, Dongang Wang, Chenyu Wang, Chang
  Xu
Categories: q-bio.NC cs.CV
\\
  Understanding how spontaneous brain activity relates to stimulus-driven
neural responses is a fundamental challenge in cognitive neuroscience. While
task-based functional magnetic resonance imaging (fMRI) captures localized
stimulus-evoked brain activation, its acquisition is costly, time-consuming,
and difficult to scale across populations. In contrast, resting-state fMRI
(rs-fMRI) is task-free and abundant, but lacks direct interpretability. We
introduce Rest2Visual, a conditional generative model that predicts visually
evoked fMRI (ve-fMRI) from resting-state input and 2D visual stimuli. It
follows a volumetric encoder--decoder design, where multiscale 3D features from
rs-fMRI are modulated by image embeddings via adaptive normalization, enabling
spatially accurate, stimulus-specific activation synthesis. To enable model
training, we construct a large-scale triplet dataset from the Natural Scenes
Dataset (NSD), aligning each rs-fMRI volume with stimulus images and their
corresponding ve-fMRI activation maps. Quantitative evaluation shows that the
predicted activations closely match ground truth across standard similarity and
representational metrics, and support successful image reconstruction in
downstream decoding. Notably, the predicted maps preserve subject-specific
structure, demonstrating the model's capacity to generate individualized
functional surrogates. Our results provide compelling evidence that
individualized spontaneous neural activity can be transformed into
stimulus-aligned representations, opening new avenues for scalable, task-free
functional brain modeling.
\\ ( https://arxiv.org/abs/2509.13612 ,  12602kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13642 (*cross-listing*)
Date: Wed, 17 Sep 2025 02:33:29 GMT   (18305kb)

Title: LLM-I: LLMs are Naturally Interleaved Multimodal Creators
Authors: Zirun Guo, Feng Zhang, Kai Jia, Tao Jin
Categories: cs.LG cs.CV
\\
  We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.
\\ ( https://arxiv.org/abs/2509.13642 ,  18305kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13857 (*cross-listing*)
Date: Wed, 17 Sep 2025 09:46:57 GMT   (3929kb)

Title: InterKey: Cross-modal Intersection Keypoints for Global Localization on
  OpenStreetMap
Authors: Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Stewart
  Worrall
Categories: cs.RO cs.CV
Comments: 8 pages, 5 figures
\\
  Reliable global localization is critical for autonomous vehicles, especially
in environments where GNSS is degraded or unavailable, such as urban canyons
and tunnels. Although high-definition (HD) maps provide accurate priors, the
cost of data collection, map construction, and maintenance limits scalability.
OpenStreetMap (OSM) offers a free and globally available alternative, but its
coarse abstraction poses challenges for matching with sensor data. We propose
InterKey, a cross-modal framework that leverages road intersections as
distinctive landmarks for global localization. Our method constructs compact
binary descriptors by jointly encoding road and building imprints from point
clouds and OSM. To bridge modality gaps, we introduce discrepancy mitigation,
orientation determination, and area-equalized sampling strategies, enabling
robust cross-modal matching. Experiments on the KITTI dataset demonstrate that
InterKey achieves state-of-the-art accuracy, outperforming recent baselines by
a large margin. The framework generalizes to sensors that can produce dense
structural point clouds, offering a scalable and cost-effective solution for
robust vehicle localization.
\\ ( https://arxiv.org/abs/2509.13857 ,  3929kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13965 (*cross-listing*)
Date: Wed, 17 Sep 2025 13:37:13 GMT   (1385kb)

Title: MetricNet: Recovering Metric Scale in Generative Navigation Policies
Authors: Abhijeet Nayak, D\'ebora N.P. Oliveira, Samiran Gode, Cordelia Schmid,
  Wolfram Burgard
Categories: cs.RO cs.CV
\\
  Generative navigation policies have made rapid progress in improving
end-to-end learned navigation. Despite their promising results, this paradigm
has two structural problems. First, the sampled trajectories exist in an
abstract, unscaled space without metric grounding. Second, the control strategy
discards the full path, instead moving directly towards a single waypoint. This
leads to short-sighted and unsafe actions, moving the robot towards obstacles
that a complete and correctly scaled path would circumvent. To address these
issues, we propose MetricNet, an effective add-on for generative navigation
that predicts the metric distance between waypoints, grounding policy outputs
in real-world coordinates. We evaluate our method in simulation with a new
benchmarking framework and show that executing MetricNet-scaled waypoints
significantly improves both navigation and exploration performance. Beyond
simulation, we further validate our approach in real-world experiments.
Finally, we propose MetricNav, which integrates MetricNet into a navigation
policy to guide the robot away from obstacles while still moving towards the
goal.
\\ ( https://arxiv.org/abs/2509.13965 ,  1385kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14191 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:27:53 GMT   (28840kb)

Title: MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for
  High-Fidelity Mapping
Authors: Zhihao Cao, Hanyu Wu, Li Wa Tang, Zizhou Luo, Zihan Zhu, Wei Zhang,
  Marc Pollefeys, Martin R. Oswald
Categories: cs.RO cs.CV
\\
  Recent progress in dense SLAM has primarily targeted monocular setups, often
at the expense of robustness and geometric coverage. We present MCGS-SLAM, the
first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting
(3DGS). Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM
fuses dense RGB inputs from multiple viewpoints into a unified, continuously
optimized Gaussian map. A multi-camera bundle adjustment (MCBA) jointly refines
poses and depths via dense photometric and geometric residuals, while a scale
consistency module enforces metric alignment across views using low-rank
priors. The system supports RGB input and maintains real-time performance at
large scale. Experiments on synthetic and real-world datasets show that
MCGS-SLAM consistently yields accurate trajectories and photorealistic
reconstructions, usually outperforming monocular baselines. Notably, the wide
field of view from multi-camera input enables reconstruction of side-view
regions that monocular setups miss, critical for safe autonomous operation.
These results highlight the promise of multi-camera Gaussian Splatting SLAM for
high-fidelity mapping in robotics and autonomous driving.
\\ ( https://arxiv.org/abs/2509.14191 ,  28840kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13523 (*cross-listing*)
Date: Tue, 16 Sep 2025 20:38:29 GMT   (11727kb)

Title: AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions
Authors: V\"ain\"o Hatanp\"a\"a, Eugene Ku, Jason Stock, Murali Emani, Sam
  Foreman, Chunyong Jung, Sandeep Madireddy, Tung Nguyen, Varuni Sastry, Ray A.
  O. Sinurat, Sam Wheeler, Huihuo Zheng, Troy Arcomano, Venkatram Vishwanath,
  Rao Kotamarthi
Categories: cs.LG cs.DC
Comments: 14 pages, 7 figures
\\
  Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.
\\ ( https://arxiv.org/abs/2509.13523 ,  11727kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13739 (*cross-listing*)
Date: Wed, 17 Sep 2025 06:45:13 GMT   (74kb)

Title: ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated
  Learning
Authors: Zihou Wu (1), Yuecheng Li (1), Tianchi Liao (2), Jian Lou (2), Chuan
  Chen (1) ((1) School of Computer Science and Engineering, Sun Yat-sen
  University, Guangzhou, China (2) School of Software Engineering, Sun Yat-sen
  University, Zhuhai, China)
Categories: cs.LG cs.DC
Comments: 8 pages, 1 figure
\\
  Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.
\\ ( https://arxiv.org/abs/2509.13739 ,  74kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13855 (*cross-listing*)
Date: Wed, 17 Sep 2025 09:41:26 GMT   (151kb)

Title: Graph-Regularized Learning of Gaussian Mixture Models
Authors: Shamsiiat Abdurakhmanova, Alex Jung
Categories: cs.LG cs.DC
\\
  We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.
\\ ( https://arxiv.org/abs/2509.13855 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13933 (*cross-listing*)
Date: Wed, 17 Sep 2025 13:04:14 GMT   (145kb)

Title: Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless
  Federated Learning
Authors: Qiyue Li, Yingxin Liu, Hang Qi, Jieping Luo, Zhizhang Liu, Jingjin Wu
Categories: cs.LG cs.DC
\\
  We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.
\\ ( https://arxiv.org/abs/2509.13933 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14098 (*cross-listing*)
Date: Wed, 17 Sep 2025 15:38:25 GMT   (787kb)

Title: A Closeness Centrality-based Circuit Partitioner for Quantum Simulations
Authors: Doru Thom Popovici, Harlin Lee, Mauro Del Ben, Naoki Yoshioka,
  Nobuyasu Ito, Katherine Klymko, Daan Camps, Anastasiia Butko
Categories: quant-ph cs.DC
Comments: 14 pages, 10 figures
\\
  Simulating quantum circuits (QC) on high-performance computing (HPC) systems
has become an essential method to benchmark algorithms and probe the potential
of large-scale quantum computation despite the limitations of current quantum
hardware. However, these simulations often require large amounts of resources,
necessitating the use of large clusters with thousands of compute nodes and
large memory footprints. In this work, we introduce an end-to-end framework
that provides an efficient partitioning scheme for large-scale QCs alongside a
flexible code generator to offer a portable solution that minimizes data
movement between compute nodes. By formulating the distribution of quantum
states and circuits as a graph problem, we apply closeness centrality to assess
gate importance and design a fast, scalable partitioning method. The resulting
partitions are compiled into highly optimized codes that run seamlessly on a
wide range of supercomputers, providing critical insights into the performance
and scalability of quantum algorithm simulations.
\\ ( https://arxiv.org/abs/2509.14098 ,  787kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14211 (*cross-listing*)
Date: Wed, 17 Sep 2025 17:41:17 GMT   (314kb)

Title: Julia GraphBLAS with Nonblocking Execution
Authors: Pascal Costanza, Timothy G. Mattson, Raye Kimmerer, Benjamin Brock
Categories: cs.MS cs.DC cs.PL
\\
  From the beginning, the GraphBLAS were designed for ``nonblocking
execution''; i.e., calls to GraphBLAS methods return as soon as the arguments
to the methods are validated and define a directed acyclic graph (DAG) of
GraphBLAS operations. This lets GraphBLAS implementations fuse functions, elide
unneeded objects, exploit parallelism, plus any additional DAG-preserving
transformations. GraphBLAS implementations exist that utilize nonblocking
execution but with limited scope. In this paper, we describe our work to
implement GraphBLAS with support for aggressive nonblocking execution. We show
how features of the Julia programming language greatly simplify implementation
of nonblocking execution. This is \emph{work-in-progress} sufficient to show
the potential for nonblocking execution and is limited to GraphBLAS methods
required to support PageRank.
\\ ( https://arxiv.org/abs/2509.14211 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13381 (*cross-listing*)
Date: Tue, 16 Sep 2025 09:31:32 GMT   (657kb)

Title: Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical
  MARDL Approach
Authors: Zhang Xueyao, Yang Bo, Yu Zhiwen, Cao Xuelin, George C.
  Alexandropoulos, Merouane Debbah, Chau Yuen
Categories: cs.RO cs.LG cs.MA
Comments: 6 pages
\\
  Autonomous Underwater Vehicles (AUVs) have shown great potential for
cooperative detection and reconnaissance. However, collaborative AUV
communications introduce risks of exposure. In adversarial environments,
achieving efficient collaboration while ensuring covert operations becomes a
key challenge for underwater cooperative missions. In this paper, we propose a
novel dual time-scale Hierarchical Multi-Agent Proximal Policy Optimization
(H-MAPPO) framework. The high-level component determines the individuals
participating in the task based on a central AUV, while the low-level component
reduces exposure probabilities through power and trajectory control by the
participating AUVs. Simulation results show that the proposed framework
achieves rapid convergence, outperforms benchmark algorithms in terms of
performance, and maximizes long-term cooperative efficiency while ensuring
covert operations.
\\ ( https://arxiv.org/abs/2509.13381 ,  657kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13882 (*cross-listing*)
Date: Wed, 17 Sep 2025 10:20:19 GMT   (4757kb)

Title: Repulsive Trajectory Modification and Conflict Resolution for Efficient
  Multi-Manipulator Motion Planning
Authors: Junhwa Hong, Beomjoon Lee, Woojin Lee, Changjoo Nam
Categories: cs.RO cs.MA
Comments: 7 pages
\\
  We propose an efficient motion planning method designed to efficiently find
collision-free trajectories for multiple manipulators. While multi-manipulator
systems offer significant advantages, coordinating their motions is
computationally challenging owing to the high dimensionality of their composite
configuration space. Conflict-Based Search (CBS) addresses this by decoupling
motion planning, but suffers from subsequent conflicts incurred by resolving
existing conflicts, leading to an exponentially growing constraint tree of CBS.
Our proposed method is based on repulsive trajectory modification within the
two-level structure of CBS. Unlike conventional CBS variants, the low-level
planner applies a gradient descent approach using an Artificial Potential
Field. This field generates repulsive forces that guide the trajectory of the
conflicting manipulator away from those of other robots. As a result,
subsequent conflicts are less likely to occur. Additionally, we develop a
strategy that, under a specific condition, directly attempts to find a
conflict-free solution in a single step without growing the constraint tree.
Through extensive tests including physical robot experiments, we demonstrate
that our method consistently reduces the number of expanded nodes in the
constraint tree, achieves a higher success rate, and finds a solution faster
compared to Enhanced CBS and other state-of-the-art algorithms.
\\ ( https://arxiv.org/abs/2509.13882 ,  4757kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14025 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:28:23 GMT   (5523kb)

Title: TransforMARS: Fault-Tolerant Self-Reconfiguration for Arbitrarily Shaped
  Modular Aerial Robot Systems
Authors: Rui Huang, Zhiyu Gao, Siyu Tang, Jialin Zhang, Lei He, Ziqian Zhang,
  Lin Zhao
Categories: cs.RO cs.MA
\\
  Modular Aerial Robot Systems (MARS) consist of multiple drone modules that
are physically bound together to form a single structure for flight. Exploiting
structural redundancy, MARS can be reconfigured into different formations to
mitigate unit or rotor failures and maintain stable flight. Prior work on MARS
self-reconfiguration has solely focused on maximizing controllability margins
to tolerate a single rotor or unit fault for rectangular-shaped MARS. We
propose TransforMARS, a general fault-tolerant reconfiguration framework that
transforms arbitrarily shaped MARS under multiple rotor and unit faults while
ensuring continuous in-air stability. Specifically, we develop algorithms to
first identify and construct minimum controllable assemblies containing faulty
units. We then plan feasible disassembly-assembly sequences to transport MARS
units or subassemblies to form target configuration. Our approach enables more
flexible and practical feasible reconfiguration. We validate TransforMARS in
challenging arbitrarily shaped MARS configurations, demonstrating substantial
improvements over prior works in both the capacity of handling diverse
configurations and the number of faults tolerated. The videos and source code
of this work are available at the anonymous repository:
https://anonymous.4open.science/r/TransforMARS-1030/
\\ ( https://arxiv.org/abs/2509.14025 ,  5523kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14032 (*cross-listing*)
Date: Wed, 17 Sep 2025 14:33:49 GMT   (3983kb)

Title: Nash Equilibria in Games with Playerwise Concave Coupling Constraints:
  Existence and Computation
Authors: Philip Jordan, Maryam Kamgarpour
Categories: cs.GT cs.LG cs.MA
\\
  We study the existence and computation of Nash equilibria in continuous
static games where the players' admissible strategies are subject to shared
coupling constraints, i.e., constraints that depend on their \emph{joint}
strategies. Specifically, we focus on a class of games characterized by
playerwise concave utilities and playerwise concave constraints. Prior results
on the existence of Nash equilibria are not applicable to this class, as they
rely on strong assumptions such as joint convexity of the feasible set. By
leveraging topological fixed point theory and novel structural insights into
the contractibility of feasible sets under playerwise concave constraints, we
give an existence proof for Nash equilibria under weaker conditions. Having
established existence, we then focus on the computation of Nash equilibria via
independent gradient methods under the additional assumption that the utilities
admit a potential function. To account for the possibly nonconvex feasible
region, we employ a log barrier regularized gradient ascent with adaptive
stepsizes. Starting from an initial feasible strategy profile and under exact
gradient feedback, the proposed method converges to an $\epsilon$-approximate
constrained Nash equilibrium within $\mathcal{O}(\epsilon^{-3})$ iterations.
\\ ( https://arxiv.org/abs/2509.14032 ,  3983kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14112 (*cross-listing*)
Date: Wed, 17 Sep 2025 15:55:08 GMT   (53kb,D)

Title: Sound Value Iteration for Simple Stochastic Games
Authors: Muqsit Azeem (Technical University of Munich), Jan Kretinsky (Masaryk
  University), Maximilian Weininger (Ruhr-University Bochum)
Categories: cs.GT cs.MA
Comments: In Proceedings GandALF 2025, arXiv:2509.13258. A full version of this
  paper appears at arXiv:2411.11549
Report-no: EPTCS 428-4
Journal-ref: EPTCS 428, 2025, pp. 29-44
DOI: 10.4204/EPTCS.428.4
\\
  Algorithmic analysis of Markov decision processes (MDP) and stochastic games
(SG) in practice relies on value-iteration (VI) algorithms. Since basic VI does
not provide guarantees on the precision of the result, variants of VI have been
proposed that offer such guarantees. In particular, sound value iteration (SVI)
not only provides precise lower and upper bounds on the result, but also
converges faster in the presence of probabilistic cycles. Unfortunately, it is
neither applicable to SG, nor to MDP with end components. In this paper, we
extend SVI and cover both cases. The technical challenge consists mainly in
proper treatment of end components, which require different handling than in
the literature. Moreover, we provide several optimizations of SVI. Finally, we
evaluate our prototype implementation experimentally to demonstrate its
potential on systems with probabilistic cycles.
\\ ( https://arxiv.org/abs/2509.14112 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14126 (*cross-listing*)
Date: Wed, 17 Sep 2025 16:06:59 GMT   (5662kb)

Title: CrazyMARL: Decentralized Direct Motor Control Policies for Cooperative
  Aerial Transport of Cable-Suspended Payloads
Authors: Viktor Lorentz, Khaled Wahba, Sayantan Auddy, Marc Toussaint and
  Wolfgang H\"onig
Categories: cs.RO cs.MA
Comments: This work has been submitted to IEEE for possible publication
\\
  Collaborative transportation of cable-suspended payloads by teams of Unmanned
Aerial Vehicles (UAVs) has the potential to enhance payload capacity, adapt to
different payload shapes, and provide built-in compliance, making it attractive
for applications ranging from disaster relief to precision logistics. However,
multi-UAV coordination under disturbances, nonlinear payload dynamics, and
slack--taut cable modes remains a challenging control problem. To our
knowledge, no prior work has addressed these cable mode transitions in the
multi-UAV context, instead relying on simplifying rigid-link assumptions. We
propose CrazyMARL, a decentralized Reinforcement Learning (RL) framework for
multi-UAV cable-suspended payload transport. Simulation results demonstrate
that the learned policies can outperform classical decentralized controllers in
terms of disturbance rejection and tracking precision, achieving an 80%
recovery rate from harsh conditions compared to 44% for the baseline method. We
also achieve successful zero-shot sim-to-real transfer and demonstrate that our
policies are highly robust under harsh conditions, including wind, random
external disturbances, and transitions between slack and taut cable dynamics.
This work paves the way for autonomous, resilient UAV teams capable of
executing complex payload missions in unstructured environments.
\\ ( https://arxiv.org/abs/2509.14126 ,  5662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14127 (*cross-listing*)
Date: Wed, 17 Sep 2025 16:08:42 GMT   (1296kb)

Title: Energy Efficient Multi Robot Package Delivery under Capacity-Constraints
  via Voronoi-Constrained Networks
Authors: Alkesh K. Srivastava, Jared Michael Levin, Philip Dames
Categories: cs.RO cs.MA
\\
  We consider the problem of delivering multiple packages from a single pickup
depot to distinct goal locations using a homogeneous fleet of robots with
limited carrying capacity. We propose VCST-RCP, a Voronoi-Constrained Steiner
Tree Relay Coordination Planning framework that constructs sparse relay trunks
using Steiner tree optimization and then synthesizes robot-level pickup, relay,
and delivery schedules. This framework reframes relays from incidental
byproducts into central elements of coordination, offering a contrast with
traditional delivery methods that rely on direct source-to-destination
transport. Extensive experiments show consistent improvements of up to 34%
compared to conventional baselines, underscoring the benefits of incorporating
relays into the delivery process. These improvements translate directly to
enhanced energy efficiency in multi-robot delivery under capacity constraints,
providing a scalable framework for real-world logistics.
\\ ( https://arxiv.org/abs/2509.14127 ,  1296kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2410.19238
replaced with revised version Wed, 17 Sep 2025 04:46:12 GMT   (949kb)

Title: Designing AI-Agents with Personalities: A Psychometric Approach
Authors: Muhua Huang, Xijuan Zhang, Christopher Soto, James Evans
Categories: cs.AI cs.CY
\\ ( https://arxiv.org/abs/2410.19238 ,  949kb)
------------------------------------------------------------------------------
\\
arXiv:2505.08364
replaced with revised version Wed, 17 Sep 2025 13:35:33 GMT   (7594kb)

Title: Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive
  Difficulty Curriculum Learning and Expert-Guided Self-Reformulation
Authors: Enci Zhang, Xingang Yan, Wei Lin, Tianxiang Zhang, Qianchun Lu
Categories: cs.AI
Comments: 14 pages, 3 figs
\\ ( https://arxiv.org/abs/2505.08364 ,  7594kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13668
replaced with revised version Wed, 17 Sep 2025 14:47:17 GMT   (517kb)

Title: MAFA: A multi-agent framework for annotation
Authors: Mahmood Hegazy, Aaron Rodrigues, Azzam Naeem
Categories: cs.AI cs.LG
Journal-ref: ECAI 2025 Workshop on AI in Finance
\\ ( https://arxiv.org/abs/2505.13668 ,  517kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18325
replaced with revised version Wed, 17 Sep 2025 16:44:58 GMT   (1734kb)

Title: Understanding and Mitigating Overrefusal in LLMs from an Unveiling
  Perspective of Safety Decision Boundary
Authors: Licheng Pan, Yongqi Tong, Xin Zhang, Xiaolu Zhang, Jun Zhou, Zhixuan
  Chu
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.18325 ,  1734kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19676
replaced with revised version Wed, 17 Sep 2025 01:43:14 GMT   (721kb)

Title: Large Language Models' Reasoning Stalls: An Investigation into the
  Capabilities of Frontier Models
Authors: Lachlan McGinness, Peter Baumgartner
Categories: cs.AI
Comments: The original version of this article was withdrawn because there were
  errors in the evaluation of model faithfulness to reasoning strategies and
  completeness of reasoning. The analysis was re-conducted correctly and
  version two contains the corrections
\\ ( https://arxiv.org/abs/2505.19676 ,  721kb)
------------------------------------------------------------------------------
\\
arXiv:2507.17514
replaced with revised version Wed, 17 Sep 2025 11:19:18 GMT   (749kb)

Title: TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy
  AI Self-Assessment
Authors: Athanasios Davvetas, Xenia Ziouvelou, Ypatia Dami, Alexios Kaponis,
  Konstantina Giouvanopoulou, Michael Papademas
Categories: cs.AI
Comments: 9 pages, 1 figure, 4 tables
\\ ( https://arxiv.org/abs/2507.17514 ,  749kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22149
replaced with revised version Tue, 16 Sep 2025 19:35:19 GMT   (4222kb)

Title: When Truthful Representations Flip Under Deceptive Instructions?
Authors: Xianxuan Long, Yao Fu, Runchao Li, Mu Sheng, Haotian Yu, Xiaotian Han,
  Pan Li
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2507.22149 ,  4222kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19505
replaced with revised version Tue, 16 Sep 2025 20:22:56 GMT   (893kb)

Title: Caught in the Act: a mechanistic approach to detecting deception
Authors: Gerard Boxo, Ryan Socha, Daniel Yoo, Shivam Raval
Categories: cs.AI
Comments: 15 pages, 10 figures
\\ ( https://arxiv.org/abs/2508.19505 ,  893kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08380
replaced with revised version Wed, 17 Sep 2025 04:43:46 GMT   (684kb)

Title: Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML
  Compliance Narratives
Authors: Prathamesh Vasudeo Naik, Naresh Kumar Dintakurthi, Zhanghao Hu, Yue
  Wang, Robby Qiu
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.08380 ,  684kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12643
replaced with revised version Wed, 17 Sep 2025 06:58:41 GMT   (0kb,I)

Title: Learn to Relax with Large Language Models: Solving Nonlinear
  Combinatorial Optimization Problems via Bidirectional Coevolution
Authors: Beidan Liu, Zhengqiu Zhu, Chen Gao, Yong Zhao, Wei Qi, Quanjun Yin
Categories: cs.AI
Comments: We wish to withdraw this manuscript as we have identified several
  technical details that require further optimization and refinement. We plan
  to resubmit an updated version at a later date
\\ ( https://arxiv.org/abs/2509.12643 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2308.07107
replaced with revised version Wed, 17 Sep 2025 07:52:25 GMT   (1526kb)

Title: Large Language Models for Information Retrieval: A Survey
Authors: Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu,
  Chenlong Deng, Haonan Chen, Zheng Liu, Zhicheng Dou, and Ji-Rong Wen
Categories: cs.CL cs.IR
Comments: Updated to version 4; Accepted by ACM TOIS
DOI: 10.1145/3748304
\\ ( https://arxiv.org/abs/2308.07107 ,  1526kb)
------------------------------------------------------------------------------
\\
arXiv:2405.13541
replaced with revised version Wed, 17 Sep 2025 09:36:57 GMT   (393kb)

Title: Annotation-Efficient Language Model Alignment via Diverse and
  Representative Response Texts
Authors: Yuu Jinnai, Ukyo Honda
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP Findings, 2025
\\ ( https://arxiv.org/abs/2405.13541 ,  393kb)
------------------------------------------------------------------------------
\\
arXiv:2406.16013
replaced with revised version Tue, 16 Sep 2025 21:49:43 GMT   (2069kb)

Title: Database-Augmented Query Representation for Information Retrieval
Authors: Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong C. Park
Categories: cs.CL cs.AI cs.IR
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2406.16013 ,  2069kb)
------------------------------------------------------------------------------
\\
arXiv:2407.11963
replaced with revised version Wed, 17 Sep 2025 01:19:58 GMT   (628kb)

Title: NeedleBench: Evaluating LLM Retrieval and Reasoning Across Varying
  Information Densities
Authors: Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, Kai
  Chen
Categories: cs.CL
Comments: v3: Revisions with added experiments, clarifications, and related
  work updates
\\ ( https://arxiv.org/abs/2407.11963 ,  628kb)
------------------------------------------------------------------------------
\\
arXiv:2407.14701
replaced with revised version Tue, 16 Sep 2025 21:39:05 GMT   (10014kb)

Title: Contextual modulation of language comprehension in a dynamic neural
  model of lexical meaning
Authors: Michael C. Stern and Maria M. Pi\~nango
Categories: cs.CL
\\ ( https://arxiv.org/abs/2407.14701 ,  10014kb)
------------------------------------------------------------------------------
\\
arXiv:2409.12147
replaced with revised version Wed, 17 Sep 2025 00:19:20 GMT   (9587kb)

Title: MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for
  Reasoning
Authors: Justin Chih-Yao Chen, Archiki Prasad, Swarnadeep Saha, Elias
  Stengel-Eskin, Mohit Bansal
Categories: cs.CL
Comments: EMNLP 2025 (Camera-Ready)
\\ ( https://arxiv.org/abs/2409.12147 ,  9587kb)
------------------------------------------------------------------------------
\\
arXiv:2410.09252
replaced with revised version Wed, 17 Sep 2025 03:28:14 GMT   (1438kb)

Title: DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue
Authors: Minh Pham Dinh, Munira Syed, Michael G Yankoski, Trenton W. Ford
Categories: cs.CL cs.AI cs.HC
Comments: Accepted to EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2410.09252 ,  1438kb)
------------------------------------------------------------------------------
\\
arXiv:2410.10857
replaced with revised version Wed, 17 Sep 2025 05:32:19 GMT   (349kb)

Title: Mirror-Consistency: Harnessing Inconsistency in Majority Voting
Authors: Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang,
  Zhouhan Lin
Categories: cs.CL cs.AI
Comments: EMNLP 2024 Findings
\\ ( https://arxiv.org/abs/2410.10857 ,  349kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13456
replaced with revised version Wed, 17 Sep 2025 07:35:25 GMT   (4288kb)

Title: Unlocking Legal Knowledge: A Multilingual Dataset for Judicial
  Summarization in Switzerland
Authors: Luca Rolshoven, Vishvaksenan Rasiah, Srinanda Br\"ugger Bose, Sarah
  Hostettler, Lara Burkhalter, Matthias St\"urmer, Joel Niklaus
Categories: cs.CL cs.AI cs.LG
Comments: Accepted to EMNLP 2025 Findings
MSC-class: 68T50
ACM-class: I.2; I.7
\\ ( https://arxiv.org/abs/2410.13456 ,  4288kb)
------------------------------------------------------------------------------
\\
arXiv:2411.06207
replaced with revised version Wed, 17 Sep 2025 17:21:24 GMT   (922kb)

Title: KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large
  Language Models
Authors: Zhen Zhang, Xinyu Wang, Yong Jiang, Zile Qiao, Zhuo Chen, Guangyu Li,
  Feiteng Mu, Mengting Hu, Pengjun Xie, Fei Huang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2411.06207 ,  922kb)
------------------------------------------------------------------------------
\\
arXiv:2412.12478
replaced with revised version Wed, 17 Sep 2025 05:42:00 GMT   (2205kb)

Title: Human-in-the-Loop Generation of Adversarial Texts: A Case Study on
  Tibetan Script
Authors: Xi Cao, Yuan Sun, Jiajun Li, Quzong Gesang, Nuo Qun, Tashi Nyima
Categories: cs.CL cs.CR cs.HC
\\ ( https://arxiv.org/abs/2412.12478 ,  2205kb)
------------------------------------------------------------------------------
\\
arXiv:2501.01872
replaced with revised version Tue, 16 Sep 2025 22:58:02 GMT   (219kb)

Title: Turning Logic Against Itself : Probing Model Defenses Through
  Contrastive Questions
Authors: Rachneet Sachdeva and Rima Hazra and Iryna Gurevych
Categories: cs.CL
Comments: Accepted at EMNLP 2025 (Main)
\\ ( https://arxiv.org/abs/2501.01872 ,  219kb)
------------------------------------------------------------------------------
\\
arXiv:2501.09765
replaced with revised version Tue, 16 Sep 2025 19:06:07 GMT   (991kb)

Title: Enhancing the De-identification of Personally Identifiable Information
  in Educational Data
Authors: Zilyu Ji, Yuntian Shen, Jionghao Lin, Kenneth R. Koedinger
Categories: cs.CL cs.AI
Journal-ref: Journal of Educational Data Mining 17(2) (2025) 55-85
DOI: 10.5281/zenodo.17114271
\\ ( https://arxiv.org/abs/2501.09765 ,  991kb)
------------------------------------------------------------------------------
\\
arXiv:2501.19301
replaced with revised version Tue, 16 Sep 2025 19:06:51 GMT   (1248kb)

Title: Beyond checkmate: exploring the creative chokepoints in AI text
Authors: Nafis Irtiza Tripto, Saranya Venkatraman, Mahjabin Nahar, Dongwon Lee
Categories: cs.CL cs.AI
Comments: Accepted at 30th Conference on Empirical Methods in Natural Language
  Processing (EMNLP'25 Main conference). 9 pages
\\ ( https://arxiv.org/abs/2501.19301 ,  1248kb)
------------------------------------------------------------------------------
\\
arXiv:2502.07445
replaced with revised version Wed, 17 Sep 2025 05:30:26 GMT   (2357kb)

Title: Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon
Authors: Nurit Cohen-Inger, Yehonatan Elisha, Bracha Shapira, Lior Rokach,
  Seffi Cohen
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2502.07445 ,  2357kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11176
replaced with revised version Wed, 17 Sep 2025 09:13:23 GMT   (1126kb)

Title: LogiDynamics: Unraveling the Dynamics of Inductive, Abductive and
  Deductive Logical Inferences in LLM Reasoning
Authors: Tianshi Zheng, Jiayang Cheng, Chunyang Li, Haochen Shi, Zihao Wang,
  Jiaxin Bai, Yangqiu Song, Ginny Y. Wong, Simon See
Categories: cs.CL
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2502.11176 ,  1126kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15022
replaced with revised version Wed, 17 Sep 2025 07:52:58 GMT   (9310kb)

Title: Mind the Style Gap: Meta-Evaluation of Style and Attribute Transfer
  Metrics
Authors: Amalie Brogaard Pauli, Isabelle Augenstein, Ira Assent
Categories: cs.CL
Comments: Accepted at EMNLP Findings 2025
\\ ( https://arxiv.org/abs/2502.15022 ,  9310kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19749
replaced with revised version Tue, 16 Sep 2025 15:43:55 GMT   (10974kb)

Title: What's Not Said Still Hurts: A Description-Based Evaluation Framework
  for Measuring Social Bias in LLMs
Authors: Jinhao Pan, Chahat Raj, Ziyu Yao, Ziwei Zhu
Categories: cs.CL
Comments: EMNLP Findings 2025
\\ ( https://arxiv.org/abs/2502.19749 ,  10974kb)
------------------------------------------------------------------------------
\\
arXiv:2503.21670
replaced with revised version Wed, 17 Sep 2025 13:25:13 GMT   (924kb)

Title: COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in
  Hindi-English Code-Mixing
Authors: Rajvee Sheth, Himanshu Beniwal, Mayank Singh
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2503.21670 ,  924kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00132
replaced with revised version Wed, 17 Sep 2025 08:32:45 GMT   (4431kb)

Title: Contextualize-then-Aggregate: Circuits for In-Context Learning in
  Gemma-2 2B
Authors: Aleksandra Bakalova, Yana Veitsman, Xinting Huang, Michael Hahn
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2504.00132 ,  4431kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05262
replaced with revised version Wed, 17 Sep 2025 07:14:56 GMT   (241kb)

Title: Do Large Language Models Truly Grasp Addition? A Rule-Focused Diagnostic
  Using Two-Integer Arithmetic
Authors: Yang Yan, Yu Lu, Renjun Xu, Zhenzhong Lan
Categories: cs.CL
Comments: Accepted by EMNLP'25 Main
\\ ( https://arxiv.org/abs/2504.05262 ,  241kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20581
replaced with revised version Wed, 17 Sep 2025 07:43:22 GMT   (51kb)

Title: ClonEval: An Open Voice Cloning Benchmark
Authors: Iwona Christop, Tomasz Kuczy\'nski, Marek Kubis
Categories: cs.CL
Comments: Under review at ICASSP
\\ ( https://arxiv.org/abs/2504.20581 ,  51kb)
------------------------------------------------------------------------------
\\
arXiv:2505.11051
replaced with revised version Wed, 17 Sep 2025 07:46:11 GMT   (72kb)

Title: CAMEO: Collection of Multilingual Emotional Speech Corpora
Authors: Iwona Christop, Maciej Czajka
Categories: cs.CL cs.SD eess.AS
Comments: Under review at ICASSP
\\ ( https://arxiv.org/abs/2505.11051 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12381
replaced with revised version Wed, 17 Sep 2025 15:00:36 GMT   (1021kb)

Title: From n-gram to Attention: How Model Architectures Learn and Propagate
  Bias in Language Modeling
Authors: Mohsinul Kabir, Tasfia Tahsin, Sophia Ananiadou
Categories: cs.CL cs.AI
Comments: Accepted at EMNLP 2025 (Findings)
\\ ( https://arxiv.org/abs/2505.12381 ,  1021kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13259
replaced with revised version Wed, 17 Sep 2025 09:06:42 GMT   (265kb)

Title: From Automation to Autonomy: A Survey on Large Language Models in
  Scientific Discovery
Authors: Tianshi Zheng, Zheye Deng, Hong Ting Tsang, Weiqi Wang, Jiaxin Bai,
  Zihao Wang, Yangqiu Song
Categories: cs.CL
Comments: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2505.13259 ,  265kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16252
replaced with revised version Wed, 17 Sep 2025 07:16:41 GMT   (1125kb)

Title: Does Localization Inform Unlearning? A Rigorous Examination of Local
  Parameter Attribution for Knowledge Unlearning in Language Models
Authors: Hwiyeong Lee, Uiji Hwang, Hyelim Lim, Taeuk Kim
Categories: cs.CL
Comments: The 2025 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2025)
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2505.16252 ,  1125kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18614
replaced with revised version Wed, 17 Sep 2025 17:56:31 GMT   (8232kb)

Title: MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song
  Translation
Authors: Woohyun Cho and Youngmin Kim and Sunghyun Lee and Youngjae Yu
Categories: cs.CL cs.LG cs.MM cs.SD eess.AS
Comments: Accepted to EMNLP 2025, Project Page:
  https://k1064190.github.io/papers/paper1.html, our codes and datasets are
  available at https://github.com/k1064190/MAVL
\\ ( https://arxiv.org/abs/2505.18614 ,  8232kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18916
replaced with revised version Wed, 17 Sep 2025 14:42:02 GMT   (1632kb)

Title: SCRum-9: Multilingual Stance Classification over Rumours on Social Media
Authors: Yue Li, Jake Vasilakes, Zhixue Zhao, Carolina Scarton
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.18916 ,  1632kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23759
replaced with revised version Tue, 16 Sep 2025 18:13:16 GMT   (3246kb)

Title: Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint
Authors: Heekyung Lee, Jiaxin Ge, Tsung-Han Wu, Minwoo Kang, Trevor Darrell,
  David M. Chan
Categories: cs.CL cs.AI cs.CV cs.LG
Comments: EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2505.23759 ,  3246kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23804
replaced with revised version Wed, 17 Sep 2025 17:39:16 GMT   (1141kb)

Title: Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause
  Frequencies
Authors: Terrance Liu, Shuyi Wang, Daniel Preotiuc-Pietro, Yash Chandarana,
  Chirag Gupta
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP 2025 main conference
\\ ( https://arxiv.org/abs/2505.23804 ,  1141kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24621
replaced with revised version Wed, 17 Sep 2025 15:53:19 GMT   (1302kb)

Title: Benchmarking Large Language Models for Cryptanalysis and Side-Channel
  Vulnerabilities
Authors: Utsav Maskey, Chencheng Zhu, Usman Naseem
Categories: cs.CL
Comments: EMNLP'25 Findings
\\ ( https://arxiv.org/abs/2505.24621 ,  1302kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00658
replaced with revised version Wed, 17 Sep 2025 01:09:52 GMT   (2680kb)

Title: Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and
  Emotion-Informed Techniques
Authors: Lang Xiong, Raina Gao, Alyssa Jeong, Yicheng Fu, Sean O'Brien, Vasu
  Sharma, Kevin Zhu
Categories: cs.CL cs.AI
Comments: Accepted to EMNLP WiNLP and COLM Melt, Solar, PragLM, and Origen
\\ ( https://arxiv.org/abs/2506.00658 ,  2680kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02478
replaced with revised version Wed, 17 Sep 2025 05:53:30 GMT   (250kb)

Title: FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging
Authors: Zijian Li, Xiaocheng Feng, Huixin Liu, Yichong Huang, Ting Liu, Bing
  Qin
Categories: cs.CL
Comments: 12 pages, 11 figures
\\ ( https://arxiv.org/abs/2506.02478 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07032
replaced with revised version Wed, 17 Sep 2025 02:30:32 GMT   (8589kb)

Title: A Culturally-diverse Multilingual Multimodal Video Benchmark & Model
Authors: Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul
  Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue,
  Jean Lahoud, Md. Safirur Rashid, Shadid Intisar Quasem, Maheen Fatima, Franco
  Vidal, Mykola Maslych, Ketan Pravin More, Sanoojan Baliah, Hasindri Watawana,
  Yuhao Li, Fabian Farestam, Leon Schaller, Roman Tymtsiv, Simon Weber, Hisham
  Cholakkal, Ivan Laptev, Shin'ichi Satoh, Michael Felsberg, Mubarak Shah,
  Salman Khan, Fahad Shahbaz Khan
Categories: cs.CL cs.CV
\\ ( https://arxiv.org/abs/2506.07032 ,  8589kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10486
replaced with revised version Wed, 17 Sep 2025 02:02:04 GMT   (63kb)

Title: Table-Text Alignment: Explaining Claim Verification Against Tables in
  Scientific Papers
Authors: Xanh Ho, Sunisth Kumar, Yun-Ang Wu, Florian Boudin, Atsuhiro Takasu,
  Akiko Aizawa
Categories: cs.CL
Comments: EMNLP 2025 Findings; 9 pages; code and data are available at
  https://github.com/Alab-NII/SciTabAlign
\\ ( https://arxiv.org/abs/2506.10486 ,  63kb)
------------------------------------------------------------------------------
\\
arXiv:2506.16123
replaced with revised version Wed, 17 Sep 2025 04:57:12 GMT   (1265kb)

Title: FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning
Authors: Natapong Nitarach, Warit Sirichotedumrong, Panop Pitchayarthorn,
  Pittawat Taveekitworachai, Potsawee Manakul, Kunat Pipatanakul
Categories: cs.CL
Comments: Accepted at FinNLP-2025, EMNLP
\\ ( https://arxiv.org/abs/2506.16123 ,  1265kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02013
replaced with revised version Wed, 17 Sep 2025 08:55:42 GMT   (4335kb)

Title: SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech
  Role-Playing Agents
Authors: Changhao Jiang, Jiajun Sun, Yifei Cao, Jiabao Zhuang, Hui Li, Xiaoran
  Fan, Ming Zhang, Junjie Ye, Shihan Dou, Zhiheng Xi, Jingqi Tong, Yilong Wu,
  Baoyu Fan, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Tao Ji,
  Tao Gui, Qi Zhang, Xuanjing Huang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.02013 ,  4335kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02618
replaced with revised version Wed, 17 Sep 2025 03:12:50 GMT   (0kb,I)

Title: Mitigating Attention Hacking in Preference-Based Reward Modeling via
  Interaction Distillation
Authors: Jianxiang Zang, Meiling Ning, Shihan Dou, Jiazheng Zhang, Tao Gui, Qi
  Zhang, Xuanjing Huang
Categories: cs.CL
Comments: This paper is not suitable for this topic, we need to adjust the
  context
\\ ( https://arxiv.org/abs/2508.02618 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15214
replaced with revised version Wed, 17 Sep 2025 09:34:53 GMT   (1321kb)

Title: Self-Guided Function Calling in Large Language Models via Stepwise
  Experience Recall
Authors: Sijia Cui, Aiyao He, Shuai Xu, Hongming Zhang, Yanna Wang, Qingyang
  Zhang, Yajing Wang, Bo Xu
Categories: cs.CL
Comments: Accepted to EMNLP 2025
\\ ( https://arxiv.org/abs/2508.15214 ,  1321kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15709
replaced with revised version Wed, 17 Sep 2025 05:47:29 GMT   (929kb)

Title: Position Bias Mitigates Position Bias:Mitigate Position Bias Through
  Inter-Position Knowledge Distillation
Authors: Yifei Wang, Feng Xiong, Yong Wang, Linjing Li, Xiangxiang Chu, Daniel
  Dajun Zeng
Categories: cs.CL
Comments: EMNLP 2025 Oral
\\ ( https://arxiv.org/abs/2508.15709 ,  929kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18655
replaced with revised version Wed, 17 Sep 2025 13:01:21 GMT   (569kb)

Title: Empathy Omni: Enabling Empathetic Speech Response Generation through
  Large Language Models
Authors: Haoyu Wang, Guangyan Zhang, Jiale Chen, Jingyu Li, Yuehai Wang, Yiwen
  Guo
Categories: cs.CL cs.SD eess.AS
Comments: 5 pages, 1 figure, submitted to ICASSP 2026
MSC-class: I.2.7
\\ ( https://arxiv.org/abs/2508.18655 ,  569kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19546
replaced with revised version Tue, 16 Sep 2025 21:37:05 GMT   (551kb)

Title: Language Models Identify Ambiguities and Exploit Loopholes
Authors: Jio Choi, Mohit Bansal, Elias Stengel-Eskin
Categories: cs.CL cs.AI
Comments: EMNLP 2025 camera-ready; Code:
  https://github.com/esteng/ambiguous-loophole-exploitation
\\ ( https://arxiv.org/abs/2508.19546 ,  551kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19813
replaced with revised version Wed, 17 Sep 2025 02:30:40 GMT   (3930kb)

Title: T2R-bench: A Benchmark for Generating Article-Level Reports from Real
  World Industrial Tables
Authors: Jie Zhang, Changzai Pan, Kaiwen Wei, Sishi Xiong, Yu Zhao, Xiangyu Li,
  Jiaxin Peng, Xiaoyan Gu, Jian Yang, Wenhan Chang, Zhenhe Wu, Jiang Zhong,
  Shuangyong Song, Yongxiang Li, Xuelong Li
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.19813 ,  3930kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21137
replaced with revised version Wed, 17 Sep 2025 02:08:56 GMT   (476kb)

Title: How Does Cognitive Bias Affect Large Language Models? A Case Study on
  the Anchoring Effect in Price Negotiation Simulations
Authors: Yoshiki Takenami, Yin Jou Huang, Yugo Murawaki, Chenhui Chu
Categories: cs.CL
Comments: 18 pages, 2 figures. Accepted to EMNLP 2025 findings
\\ ( https://arxiv.org/abs/2508.21137 ,  476kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01081
replaced with revised version Wed, 17 Sep 2025 06:42:45 GMT   (41kb)

Title: Assessing Large Language Models on Islamic Legal Reasoning: Evidence
  from Inheritance Law Evaluation
Authors: Abdessalam Bouchekif, Samer Rashwani, Heba Sbahi, Shahd Gaben, Mutaz
  Al-Khatib, and Mohammed Ghaly
Categories: cs.CL cs.AI
Comments: 10 pages, 7 Tables, Code:
  https://github.com/bouchekif/inheritance_evaluation
ACM-class: I.2.6; I.2.7
\\ ( https://arxiv.org/abs/2509.01081 ,  41kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04476
replaced with revised version Wed, 17 Sep 2025 10:53:53 GMT   (3631kb)

Title: Training Text-to-Molecule Models with Context-Aware Tokenization
Authors: Seojin Kim, Hyeontae Song, Jaehyun Nam, Jinwoo Shin
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2509.04476 ,  3631kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06652
replaced with revised version Wed, 17 Sep 2025 12:55:31 GMT   (2723kb)

Title: IntrEx: A Dataset for Modeling Engagement in Educational Conversations
Authors: Xingwei Tan and Mahathi Parvatham and Chiara Gambi and Gabriele
  Pergola
Categories: cs.CL
Comments: EMNLP 2025 Findings camera-ready, 9+7 pages
\\ ( https://arxiv.org/abs/2509.06652 ,  2723kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07553
replaced with revised version Wed, 17 Sep 2025 03:25:42 GMT   (3323kb)

Title: VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for
  Trustworthy OS Agents
Authors: Zheng Wu and Heyuan Huang and Xingyu Lou and Xiangmou Qu and Pengzhou
  Cheng and Zongru Wu and Weiwen Liu and Weinan Zhang and Jun Wang and
  Zhaoxiang Wang and Zhuosheng Zhang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.07553 ,  3323kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10199
replaced with revised version Tue, 16 Sep 2025 22:00:53 GMT   (1973kb)

Title: Beyond Token Limits: Assessing Language Model Performance on Long Text
  Classification
Authors: Mikl\'os Seb\H{o}k, Viktor Kov\'acs, Martin B\'an\'oczy, Daniel
  M{\o}ller Eriksen, Nathalie Neptune, Philippe Roussille
Categories: cs.CL
ACM-class: I.7; I.2; J.4
\\ ( https://arxiv.org/abs/2509.10199 ,  1973kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10663
replaced with revised version Wed, 17 Sep 2025 11:21:33 GMT   (1490kb)

Title: Context Copying Modulation: The Role of Entropy Neurons in Managing
  Parametric and Contextual Knowledge Conflicts
Authors: Zineddine Tighidet, Andrea Mogini, Hedi Ben-younes, Jiali Mei, Patrick
  Gallinari, Benjamin Piwowarski
Categories: cs.CL
Comments: Accepted at EMNLP 2025
Journal-ref: EMNLP 2025
\\ ( https://arxiv.org/abs/2509.10663 ,  1490kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11498
replaced with revised version Tue, 16 Sep 2025 19:58:30 GMT   (1546kb)

Title: DeDisCo at the DISRPT 2025 Shared Task: A System for Discourse Relation
  Classification
Authors: Zhuoxuan Ju, Jingni Wu, Abhishek Purushothama, Amir Zeldes
Categories: cs.CL
Comments: System submission for the DISRPT 2025 - Shared Task on Discourse
  Relation Parsing and Treebanking In conjunction with CODI-CRAC & EMNLP 2025.
  1st place in Task 3: relation classification
\\ ( https://arxiv.org/abs/2509.11498 ,  1546kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11860
replaced with revised version Wed, 17 Sep 2025 07:36:35 GMT   (2278kb)

Title: MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long
  Role-Playing Dialogues
Authors: Weishu Chen, Jinyi Tang, Zhouhui Hou, Shihao Han, Mingjie Zhan,
  Zhiyuan Huang, Delong Liu, Jiawei Guo, Zhicheng Zhao, Fei Su
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.11860 ,  2278kb)
------------------------------------------------------------------------------
\\
arXiv:1901.11111
replaced with revised version Wed, 17 Sep 2025 13:34:59 GMT   (3148kb)

Title: Texture-Aware Superpixel Segmentation
Authors: Remi Giraud, Vinh-Thong Ta, Nicolas Papadakis, Yannick Berthoumieu
Categories: cs.CV
\\ ( https://arxiv.org/abs/1901.11111 ,  3148kb)
------------------------------------------------------------------------------
\\
arXiv:1903.06010
replaced with revised version Wed, 17 Sep 2025 13:56:23 GMT   (3891kb)

Title: Superpixel-based Color Transfer
Authors: R\'emi Giraud, Vinh-Thong Ta, Nicolas Papadakis
Categories: cs.CV
\\ ( https://arxiv.org/abs/1903.06010 ,  3891kb)
------------------------------------------------------------------------------
\\
arXiv:1903.07146
replaced with revised version Wed, 17 Sep 2025 14:11:02 GMT   (2265kb)

Title: Robust Shape Regularity Criteria for Superpixel Evaluation
Authors: R\'emi Giraud, Vinh-Thong Ta, Nicolas Papadakis
Categories: cs.CV
Comments: International Conference on Image Processing 2017
\\ ( https://arxiv.org/abs/1903.07146 ,  2265kb)
------------------------------------------------------------------------------
\\
arXiv:1903.07149
replaced with revised version Wed, 17 Sep 2025 15:19:54 GMT   (3419kb)

Title: SCALP: Superpixels with Contour Adherence using Linear Path
Authors: R\'emi Giraud, Vinh-Thong Ta, Nicolas Papadakis
Categories: cs.CV
Comments: International Conference on Pattern Recognition (ICPR) 2016
\\ ( https://arxiv.org/abs/1903.07149 ,  3419kb)
------------------------------------------------------------------------------
\\
arXiv:2307.13756
replaced with revised version Wed, 17 Sep 2025 03:36:05 GMT   (40959kb)

Title: PlaneRecTR++: Unified Query Learning for Joint 3D Planar Reconstruction
  and Pose Estimation
Authors: Jingjia Shi, Shuaifeng Zhi, Kai Xu
Categories: cs.CV
Comments: To be published in IEEE T-PAMI 2025. This is the journal extension of
  our ICCV 2023 paper "PlaneRecTR", which expands from single view
  reconstruction to simultaneous multi-view reconstruction and camera pose
  estimation. Note that the ICCV2023 PlaneRecTR paper could be found in the
  previous arxiv version [v2](arXiv:2307.13756v2)
\\ ( https://arxiv.org/abs/2307.13756 ,  40959kb)
------------------------------------------------------------------------------
\\
arXiv:2312.14427
replaced with revised version Tue, 16 Sep 2025 23:04:13 GMT   (1293kb)

Title: GROOD: GRadient-Aware Out-of-Distribution Detection
Authors: Mostafa ElAraby, Sabyasachi Sahoo, Yann Pequignot, Paul Novello, Liam
  Paull
Categories: cs.CV
Comments: Accepted to Transactions on Machine Learning Research (TMLR) 2025. 12
  pages, 5 figures, 7 tables
\\ ( https://arxiv.org/abs/2312.14427 ,  1293kb)
------------------------------------------------------------------------------
\\
arXiv:2408.07243
replaced with revised version Wed, 17 Sep 2025 08:54:25 GMT   (1214kb)

Title: Leveraging Perceptual Scores for Dataset Pruning in Computer Vision
  Tasks
Authors: Raghavendra Singh
Categories: cs.CV cs.IT math.IT
Comments: NON ARCHIVAL PRESENTATION 1st workshop on Dataset Distillation CVPR
  2024
\\ ( https://arxiv.org/abs/2408.07243 ,  1214kb)
------------------------------------------------------------------------------
\\
arXiv:2408.08872
replaced with revised version Tue, 16 Sep 2025 22:25:14 GMT   (2681kb)

Title: xGen-MM (BLIP-3): A Family of Open Large Multimodal Models
Authors: Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil
  Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, Shrikant
  Kendre, Jieyu Zhang, Shaoyen Tseng, Gustavo A Lujan-Moreno, Matthew L Olson,
  Musashi Hinck, David Cobbley, Vasudev Lal, Can Qin, Shu Zhang, Chia-Chih
  Chen, Ning Yu, Juntao Tan, Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan
  Wang, Yejin Choi, Ludwig Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos
  Niebles, Caiming Xiong, Ran Xu
Categories: cs.CV cs.AI cs.CL
\\ ( https://arxiv.org/abs/2408.08872 ,  2681kb)
------------------------------------------------------------------------------
\\
arXiv:2409.01086
replaced with revised version Wed, 17 Sep 2025 03:21:17 GMT   (14628kb)

Title: DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image
  Editing
Authors: Xiaolong Wang, Zhi-Qi Cheng, Jue Wang, Xiaojiang Peng
Categories: cs.CV cs.AI
Comments: 13 pages,12 figures
\\ ( https://arxiv.org/abs/2409.01086 ,  14628kb)
------------------------------------------------------------------------------
\\
arXiv:2410.19794
replaced with revised version Wed, 17 Sep 2025 01:36:10 GMT   (3323kb)

Title: DiffGAN: A Test Generation Approach for Differential Testing of Deep
  Neural Networks for Image Analysis
Authors: Zohreh Aghababaeyan, Manel Abdellatif, Lionel Briand, and Ramesh S
Categories: cs.CV cs.LG cs.SE
Comments: Accepted into IEEE Transactions on Software Engineering
DOI: 10.1109/TSE.2025.3611329
\\ ( https://arxiv.org/abs/2410.19794 ,  3323kb)
------------------------------------------------------------------------------
\\
arXiv:2410.22454
replaced with revised version Tue, 16 Sep 2025 18:43:24 GMT   (14178kb)

Title: Brain age identification from diffusion MRI synergistically predicts
  neurodegenerative disease
Authors: Chenyu Gao, Michael E. Kim, Karthik Ramadass, Praitayini Kanakaraj,
  Aravind R. Krishnan, Adam M. Saunders, Nancy R. Newlin, Ho Hin Lee, Qi Yang,
  Warren D. Taylor, Brian D. Boyd, Lori L. Beason-Held, Susan M. Resnick, Lisa
  L. Barnes, David A. Bennett, Marilyn S. Albert, Katherine D. Van Schaik,
  Derek B. Archer, Timothy J. Hohman, Angela L. Jefferson, Ivana I\v{s}gum,
  Daniel Moyer, Yuankai Huo, Kurt G. Schilling, Lianrui Zuo, Shunxing Bao,
  Nazirah Mohd Khairi, Zhiyuan Li, Christos Davatzikos, Bennett A. Landman
Categories: cs.CV
Comments: Accepted to Imaging Neuroscience
DOI: 10.1162/imag_a_00552
\\ ( https://arxiv.org/abs/2410.22454 ,  14178kb)
------------------------------------------------------------------------------
\\
arXiv:2411.14053
replaced with revised version Wed, 17 Sep 2025 09:28:44 GMT   (3108kb)

Title: Stereo Anything: Unifying Zero-shot Stereo Matching with Large-Scale
  Mixed Data
Authors: Xianda Guo and Chenming Zhang and Youmin Zhang and Ruilin Wang and
  Dujun Nie and Wenzhao Zheng and Matteo Poggi and Hao Zhao and Mang Ye and Qin
  Zou and Long Chen
Categories: cs.CV
Comments: Code will be available at
  \url{https://github.com/XiandaGuo/OpenStereo}
\\ ( https://arxiv.org/abs/2411.14053 ,  3108kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18131
replaced with revised version Wed, 17 Sep 2025 14:37:32 GMT   (2978kb)

Title: UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by
  Regional Visual Language Supervision
Authors: Yuru Wang, Pei Liu, Songtao Wang, Zehan Zhang, Xinyan Lu, Changwei
  Cai, Hao Li, Fu Liu, Peng Jia, and Xianpeng Lang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2412.18131 ,  2978kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06607
replaced with revised version Wed, 17 Sep 2025 16:12:12 GMT   (2407kb)

Title: A Deep Learning Pipeline for Solid Waste Detection in Remote Sensing
  Images
Authors: Federico Gibellini, Piero Fraternali, Giacomo Boracchi, Luca
  Morandini, Thomas Martinoli, Andrea Diecidue and Simona Malegori
Categories: cs.CV cs.AI
Journal-ref: Waste Management Bulletin 3 (2025) 100246
DOI: 10.1016/j.wmb.2025.100246
\\ ( https://arxiv.org/abs/2502.06607 ,  2407kb)
------------------------------------------------------------------------------
\\
arXiv:2502.20742
replaced with revised version Wed, 17 Sep 2025 11:23:52 GMT   (12970kb)

Title: Structured Preference Optimization for Vision-Language Long-Horizon Task
  Planning
Authors: Xiwen Liang, Min Lin, Weiqi Ruan, Rongtao Xu, Yuecheng Liu, Jiaqi
  Chen, Bingqian Lin, Yuzheng Zhuang, Xiaodan Liang
Categories: cs.CV cs.AI cs.CL
Comments: 18 pages
\\ ( https://arxiv.org/abs/2502.20742 ,  12970kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14171
replaced with revised version Wed, 17 Sep 2025 13:55:34 GMT   (13689kb)

Title: Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images
Authors: Simon Niedermayr, Christoph Neuhauser R\"udiger Westermann
Categories: cs.CV eess.IV
\\ ( https://arxiv.org/abs/2503.14171 ,  13689kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08531
replaced with revised version Tue, 16 Sep 2025 18:19:08 GMT   (7763kb)

Title: Embodied Image Captioning: Self-supervised Learning Agents for Spatially
  Coherent Image Descriptions
Authors: Tommaso Galliena, Tommaso Apicella, Stefano Rosa, Pietro Morerio,
  Alessio Del Bue, Lorenzo Natale
Categories: cs.CV cs.RO
Comments: 11 pages, 8 figures, 6 tables, code and test set annotations
  available at https://hsp-iit.github.io/embodied-captioning/
\\ ( https://arxiv.org/abs/2504.08531 ,  7763kb)
------------------------------------------------------------------------------
\\
arXiv:2504.10288
replaced with revised version Wed, 17 Sep 2025 15:13:24 GMT   (1947kb)

Title: Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost
  imaging
Authors: Mathieu Manni, Dmitry Karpov, K. Joost Batenburg, Sharon Shwartz,
  Nicola Vigan\`o
Categories: cs.CV cs.LG physics.data-an
\\ ( https://arxiv.org/abs/2504.10288 ,  1947kb)
------------------------------------------------------------------------------
\\
arXiv:2504.16404
replaced with revised version Wed, 17 Sep 2025 07:01:23 GMT   (5419kb)

Title: Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness
  Detection
Authors: Md Fahimuzzman Sohan, Raid Alzubi, Hadeel Alzoubi, Eid Albalawi, and
  A. H. Abdul Hafez
Categories: cs.CV cs.AI cs.LG eess.IV
\\ ( https://arxiv.org/abs/2504.16404 ,  5419kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21233
replaced with revised version Wed, 17 Sep 2025 08:06:44 GMT   (4213kb)

Title: CROP: Contextual Region-Oriented Visual Token Pruning
Authors: Jiawei Guo, Feifei Zhai, Pu Jian, Qianrun Wei, Yu Zhou
Categories: cs.CV
Comments: EMNLP2025 Main
\\ ( https://arxiv.org/abs/2505.21233 ,  4213kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04705
replaced with revised version Wed, 17 Sep 2025 14:41:23 GMT   (7847kb)

Title: Identity-Preserving Text-to-Video Generation Guided by Simple yet
  Effective Spatial-Temporal Decoupled Representations
Authors: Yuji Wang, Moran Li, Xiaobin Hu, Ran Yi, Jiangning Zhang, Han Feng,
  Weijian Cao, Yabiao Wang, Chengjie Wang, Lizhuang Ma
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.04705 ,  7847kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04990
replaced with revised version Wed, 17 Sep 2025 17:06:24 GMT   (1597kb)

Title: Effort-Optimized, Accuracy-Driven Labelling and Validation of Test
  Inputs for DL Systems: A Mixed-Integer Linear Programming Approach
Authors: Mohammad Hossein Amini, Mehrdad Sabetzadeh, Shiva Nejati
Categories: cs.CV cs.SE
\\ ( https://arxiv.org/abs/2507.04990 ,  1597kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00552
replaced with revised version Tue, 16 Sep 2025 23:34:56 GMT   (718kb)

Title: DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable
  Adversarial Purification
Authors: Chihan Huang, Belal Alsinglawi, Islam Al-qudah
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.00552 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05606
replaced with revised version Wed, 17 Sep 2025 16:44:11 GMT   (10475kb)

Title: Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and
  Vision
Authors: Luozheng Qin and Jia Gong and Yuqing Sun and Tianjiao Li and Mengping
  Yang and Xiaomeng Yang and Chao Qu and Zhiyu Tan and Hao Li
Categories: cs.CV cs.CL
Comments: Project Page: https://sais-fuxi.github.io/projects/uni-cot/
\\ ( https://arxiv.org/abs/2508.05606 ,  10475kb)
------------------------------------------------------------------------------
\\
arXiv:2508.06082
replaced with revised version Tue, 16 Sep 2025 18:37:37 GMT   (17453kb)

Title: SwiftVideo: A Unified Framework for Few-Step Video Generation through
  Trajectory-Distribution Alignment
Authors: Yanxiao Sun, Jiafu Wu, Yun Cao, Chengming Xu, Yabiao Wang, Weijian
  Cao, Donghao Luo, Chengjie Wang, Yanwei Fu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.06082 ,  17453kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09397
replaced with revised version Wed, 17 Sep 2025 02:06:05 GMT   (3566kb)

Title: Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone
  Flight Safety
Authors: Zhengli Zhang and Xinyu Luo and Yucheng Sun and Wenhua Ding and
  Dongyue Huang and Xinlei Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.09397 ,  3566kb)
------------------------------------------------------------------------------
\\
arXiv:2508.10256
replaced with revised version Wed, 17 Sep 2025 02:05:54 GMT   (12834kb)

Title: Deep Learning for Crack Detection: A Review of Learning Paradigms,
  Generalizability, and Datasets
Authors: Xinan Zhang, Haolin Wang, Yung-An Hsieh, Zhongyu Yang, Anthony Yezzi,
  Yi-Chang Tsai
Categories: cs.CV
Comments: under review
\\ ( https://arxiv.org/abs/2508.10256 ,  12834kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03740
replaced with revised version Tue, 16 Sep 2025 23:58:52 GMT   (1806kb)

Title: Singular Value Few-shot Adaptation of Vision-Language Models
Authors: Taha Koleilat, Hassan Rivaz, Yiming Xiao
Categories: cs.CV cs.CL
Comments: 10 pages, 2 figures, 8 tables
\\ ( https://arxiv.org/abs/2509.03740 ,  1806kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05582
replaced with revised version Wed, 17 Sep 2025 14:08:26 GMT   (26364kb)

Title: Reconstruction and Reenactment Separated Method for Realistic Gaussian
  Head
Authors: Zhiling Ye, Cong Zhou, Xiubao Zhang, Haifeng Shen, Weihong Deng, Quan
  Lu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.05582 ,  26364kb)
------------------------------------------------------------------------------
\\
arXiv:2509.06996
replaced with revised version Wed, 17 Sep 2025 13:47:40 GMT   (2624kb)

Title: Visible Yet Unreadable: A Systematic Blind Spot of Vision Language
  Models Across Writing Systems
Authors: Jie Zhang, Ting Xu, Gelei Deng, Runyi Hu, Han Qiu, Tianwei Zhang, Qing
  Guo, Ivor Tsang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2509.06996 ,  2624kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07613
replaced with revised version Wed, 17 Sep 2025 07:27:33 GMT   (572kb)

Title: Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of
  Alzheimer's Disease
Authors: Fangqi Cheng, Surajit Ray, Xiaochen Yang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.07613 ,  572kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09067
replaced with revised version Tue, 16 Sep 2025 23:59:45 GMT   (887kb)

Title: Improvement of Human-Object Interaction Action Recognition Using Scene
  Information and Multi-Task Learning Approach
Authors: Hesham M. Shehata and Mohammad Abdolrahmani
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.09067 ,  887kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09595
replaced with revised version Wed, 17 Sep 2025 04:08:08 GMT   (13071kb)

Title: Kling-Avatar: Grounding Multimodal Instructions for Cascaded
  Long-Duration Avatar Animation Synthesis
Authors: Yikang Ding, Jiwen Liu, Wenyuan Zhang, Zekun Wang, Wentao Hu, Liyuan
  Cui, Mingming Lao, Yingchao Shao, Hui Liu, Xiaohan Li, Ming Chen, Xiaoqiang
  Liu, Yu-Shen Liu, Pengfei Wan
Categories: cs.CV
Comments: Technical Report. Project Page: https://klingavatar.github.io/
\\ ( https://arxiv.org/abs/2509.09595 ,  13071kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10815
replaced with revised version Wed, 17 Sep 2025 17:01:54 GMT   (1801kb)

Title: Well-Conditioned Polynomial Representations for Mathematical Handwriting
  Recognition
Authors: Robert M. Corless, Deepak Singh Kalhan, Stephen M. Watt
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.10815 ,  1801kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12248
replaced with revised version Wed, 17 Sep 2025 05:30:43 GMT   (999kb)

Title: Humor in Pixels: Benchmarking Large Multimodal Models Understanding of
  Online Comics
Authors: Yuriel Ryan, Rui Yang Tan, Kenny Tsu Wei Choo, Roy Ka-Wei Lee
Categories: cs.CV cs.AI cs.CL
Comments: 27 pages, 8 figures, EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2509.12248 ,  999kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12918
replaced with revised version Wed, 17 Sep 2025 12:59:25 GMT   (1354kb)

Title: A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial
  Object Detection on Edge Devices via Structured Pruning and Channel-Wise
  Distillation
Authors: Melika Sabaghian, Mohammad Ali Keyvanrad, Seyyedeh Mahila Moghadami
Categories: cs.CV
Comments: 28 pages, 11 figures
MSC-class: 68T07
ACM-class: I.4.8
\\ ( https://arxiv.org/abs/2509.12918 ,  1354kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13301
replaced with revised version Wed, 17 Sep 2025 15:58:50 GMT   (19879kb)

Title: StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with
  Texture-Geometry Dual Guidance
Authors: Zefan Qu, Zhenwei Wang, Haoyuan Wang, Ke Xu, Gerhard Hancke, Rynson
  W.H. Lau
Categories: cs.CV
Comments: SIGGRAPH Asia 2025, Project page:https://stylesculptor.github.io
\\ ( https://arxiv.org/abs/2509.13301 ,  19879kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09061
replaced with revised version Wed, 17 Sep 2025 04:31:20 GMT   (788kb)

Title: EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge
  Using Analytical Model
Authors: Alyssa Pinnock, Shakya Jayakody, Kawsher A Roxy, Md Rubel Ahmed
Categories: cs.DC cs.AI cs.PF
Comments: 4 figures, 7 pages, IEEE conference template
\\ ( https://arxiv.org/abs/2506.09061 ,  788kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21492
replaced with revised version Tue, 16 Sep 2025 23:56:55 GMT   (2201kb)

Title: Bridging Cache-Friendliness and Concurrency: A Locality-Optimized
  In-Memory B-Skiplist
Authors: Yicong Luo, Senhe Hao, Brian Wheatman, Prashant Pandey and Helen Xu
Categories: cs.DC
Comments: Original paper was accepted into ICPP 2025
DOI: 10.1145/3754598.3754655
\\ ( https://arxiv.org/abs/2507.21492 ,  2201kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16592
replaced with revised version Wed, 17 Sep 2025 11:10:48 GMT   (40kb)

Title: Performance measurements of modern Fortran MPI applications with Score-P
Authors: Gregor Corbin
Categories: cs.DC cs.MS cs.PF
\\ ( https://arxiv.org/abs/2508.16592 ,  40kb)
------------------------------------------------------------------------------
\\
arXiv:2503.17671
replaced with revised version Wed, 17 Sep 2025 06:29:41 GMT   (7294kb)

Title: ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI
  Workflow Generation
Authors: Oucheng Huang, Yuhang Ma, Zeng Zhao, Mingrui Wu, Jiayi Ji, Rongsheng
  Zhang, Zhipeng Hu, Xiaoshuai Sun and Rongrong Ji
Categories: cs.MA cs.AI
\\ ( https://arxiv.org/abs/2503.17671 ,  7294kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04537
replaced with revised version Wed, 17 Sep 2025 13:45:52 GMT   (7498kb)

Title: Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem
Authors: Ryosuke Takata, Atsushi Masumori, Takashi Ikegami
Categories: cs.MA cs.AI cs.CY
\\ ( https://arxiv.org/abs/2509.04537 ,  7498kb)
------------------------------------------------------------------------------
\\
arXiv:2309.10092
replaced with revised version Wed, 17 Sep 2025 02:14:25 GMT   (21763kb)

Title: Conformal Temporal Logic Planning using Large Language Models
Authors: Jun Wang, Jiaming Tong, Kaiyuan Tan, Yevgeniy Vorobeychik, Yiannis
  Kantaros
Categories: cs.RO cs.AI
Comments: accepted by ACM Transactions on Cyber-Physical Systems
\\ ( https://arxiv.org/abs/2309.10092 ,  21763kb)
------------------------------------------------------------------------------
\\
arXiv:2404.17916
replaced with revised version Wed, 17 Sep 2025 09:53:11 GMT   (7556kb)

Title: FedCoSR: Personalized Federated Learning with Contrastive Shareable
  Representations for Label Heterogeneity in Non-IID Data
Authors: Chenghao Huang, Xiaolu Chen, Yanru Zhang, and Hao Wang
Categories: cs.LG cs.AI
Comments: 20 pages
Journal-ref: IEEE Transactions on Cybernetics, 2025
DOI: 10.1109/TCYB.2025.3599370
\\ ( https://arxiv.org/abs/2404.17916 ,  7556kb)
------------------------------------------------------------------------------
\\
arXiv:2405.02358
replaced with revised version Wed, 17 Sep 2025 09:01:42 GMT   (1568kb)

Title: Empowering Time Series Analysis with Foundation Models: A Comprehensive
  Survey
Authors: Jiexia Ye, Yongzi Yu, Weiqi Zhang, Le Wang, Jia Li, Fugee Tsung
Categories: cs.LG cs.AI
Comments: 10 figures, 5 tables, 20 pages
\\ ( https://arxiv.org/abs/2405.02358 ,  1568kb)
------------------------------------------------------------------------------
\\
arXiv:2405.19988
replaced with revised version Wed, 17 Sep 2025 01:05:56 GMT   (4341kb)

Title: Video-Language Critic: Transferable Reward Functions for
  Language-Conditioned Robotics
Authors: Minttu Alakuijala, Reginald McLean, Isaac Woungang, Nariman Farsad,
  Samuel Kaski, Pekka Marttinen, Kai Yuan
Categories: cs.RO cs.AI cs.CL cs.CV cs.LG
Comments: 14 pages in the main text, 22 pages including references and
  supplementary materials. 3 figures and 3 tables in the main text, 6 figures
  and 3 tables in supplementary materials
Journal-ref: Transactions on Machine Learning Research (TMLR) (02/2025)
\\ ( https://arxiv.org/abs/2405.19988 ,  4341kb)
------------------------------------------------------------------------------
\\
arXiv:2407.01613
replaced with revised version Tue, 16 Sep 2025 23:31:58 GMT   (5277kb)

Title: Self-adaptive weights based on balanced residual decay rate for
  physics-informed neural networks and deep operator networks
Authors: Wenqian Chen, Amanda A. Howard, Panos Stinis
Categories: cs.LG cs.AI stat.ML
Comments: 13 figures, 4 tables
Report-no: PNNL-SA-199965
Journal-ref: J. Comput. Phys., 542 (2025) 114226
DOI: 10.1016/j.jcp.2025.114226
\\ ( https://arxiv.org/abs/2407.01613 ,  5277kb)
------------------------------------------------------------------------------
\\
arXiv:2407.12374
replaced with revised version Wed, 17 Sep 2025 14:32:48 GMT   (355kb)

Title: Towards Unified and Adaptive Cross-Domain Collaborative Filtering via
  Graph Signal Processing
Authors: Jeongeun Lee, Seongku Kang, Won-Yong Shin, Jeongwhan Choi, Noseong
  Park, Dongha Lee
Categories: cs.IR cs.AI
\\ ( https://arxiv.org/abs/2407.12374 ,  355kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11824
replaced with revised version Wed, 17 Sep 2025 09:06:58 GMT   (4323kb)

Title: AppAgent v2: Advanced Agent for Flexible Mobile Interactions
Authors: Yanda Li, Chi Zhang, Wenjia Jiang, Wanqi Yang, Bin Fu, Pei Cheng, Xin
  Chen, Ling Chen, Yunchao Wei
Categories: cs.HC cs.AI
\\ ( https://arxiv.org/abs/2408.11824 ,  4323kb)
------------------------------------------------------------------------------
\\
arXiv:2409.19894
replaced with revised version Wed, 17 Sep 2025 05:54:41 GMT   (1690kb)

Title: Semantic Alignment-Enhanced Code Translation via an LLM-Based
  Multi-Agent System
Authors: Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou
Categories: cs.SE cs.AI
\\ ( https://arxiv.org/abs/2409.19894 ,  1690kb)
------------------------------------------------------------------------------
\\
arXiv:2411.18506
replaced with revised version Wed, 17 Sep 2025 14:32:24 GMT   (4291kb)

Title: LLM-ABBA: Understanding time series via symbolic approximation
Authors: Erin Carson, Xinye Chen, Cheng Kang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2411.18506 ,  4291kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05098
replaced with revised version Wed, 17 Sep 2025 03:12:35 GMT   (1114kb)

Title: Learning Temporal Invariance in Android Malware Detectors
Authors: Xinran Zheng, Shuo Yang, Edith C.H. Ngai, Suman Jana, Lorenzo
  Cavallaro
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2502.05098 ,  1114kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06857
replaced with revised version Tue, 16 Sep 2025 19:37:50 GMT   (802kb)

Title: Gemstones: A Model Suite for Multi-Faceted Scaling Laws
Authors: Sean McLeish, John Kirchenbauer, David Yu Miller, Siddharth Singh,
  Abhinav Bhatele, Micah Goldblum, Ashwinee Panda, Tom Goldstein
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2502.06857 ,  802kb)
------------------------------------------------------------------------------
\\
arXiv:2502.12484
replaced with revised version Wed, 17 Sep 2025 14:28:10 GMT   (140kb)

Title: LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction
  for Scalable Neural TSP Solvers
Authors: Junrui Wen, Yifei Li, Bart Selman, Kun He
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2502.12484 ,  140kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15871
replaced with revised version Wed, 17 Sep 2025 01:04:55 GMT   (104kb)

Title: A Comprehensive Survey on the Trustworthiness of Large Language Models
  in Healthcare
Authors: Manar Aljohani, Jun Hou, Sindhura Kommu and Xuan Wang
Categories: cs.CY cs.AI cs.CL
\\ ( https://arxiv.org/abs/2502.15871 ,  104kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01658
replaced with revised version Wed, 17 Sep 2025 14:29:01 GMT   (7871kb)

Title: CoPL: Collaborative Preference Learning for Personalizing LLMs
Authors: Youngbin Choi, Seunghyuk Cho, Minjong Lee, MoonJeong Park, Yesong Ko,
  Jungseul Ok, Dongwoo Kim
Categories: cs.LG cs.AI cs.IR
Comments: 19pages, 13 figures, 11 tables
\\ ( https://arxiv.org/abs/2503.01658 ,  7871kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09334
replaced with revised version Wed, 17 Sep 2025 13:19:14 GMT   (1190kb)

Title: CyberLLMInstruct: A Pseudo-malicious Dataset Revealing
  Safety-performance Trade-offs in Cyber Security LLM Fine-tuning
Authors: Adel ElZemity, Budi Arief and Shujun Li
Categories: cs.CR cs.AI
DOI: 10.1145/3733799.3762968
\\ ( https://arxiv.org/abs/2503.09334 ,  1190kb)
------------------------------------------------------------------------------
\\
arXiv:2504.01153
replaced with revised version Wed, 17 Sep 2025 17:16:11 GMT   (1026kb)

Title: Catch Me if You Search: When Contextual Web Search Results Affect the
  Detection of Hallucinations
Authors: Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee
Categories: cs.HC cs.AI cs.LG
Comments: Accepted to Computers in Human Behavior
\\ ( https://arxiv.org/abs/2504.01153 ,  1026kb)
------------------------------------------------------------------------------
\\
arXiv:2504.09532
replaced with revised version Wed, 17 Sep 2025 09:49:04 GMT   (1719kb)

Title: Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal
  Foundation Models for Zero-Shot Loco-Manipulation
Authors: Congcong Wen, Geeta Chandra Raju Bethala, Yu Hao, Niraj Pudasaini, Hao
  Huang, Shuaihang Yuan, Baoru Huang, Anh Nguyen, Anthony Tzes, Yi Fang
Categories: cs.RO cs.AI
Comments: website link: https://humanoid-coa.github.io/
\\ ( https://arxiv.org/abs/2504.09532 ,  1719kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11216
replaced with revised version Tue, 16 Sep 2025 18:13:14 GMT   (2022kb)

Title: FedDiverse: Tackling Data Heterogeneity in Federated Learning with
  Diversity-Driven Client Selection
Authors: Gergely D. N\'emeth, Eros Fan\`i, Yeat Jeng Ng, Barbara Caputo, Miguel
  \'Angel Lozano, Nuria Oliver, Novi Quadrianto
Categories: cs.LG cs.AI
Comments: 3rd IEEE International Conference on Federated Learning Technologies
  and Applications (FLTA 2025)
\\ ( https://arxiv.org/abs/2504.11216 ,  2022kb)
------------------------------------------------------------------------------
\\
arXiv:2504.17827
replaced with revised version Wed, 17 Sep 2025 11:36:56 GMT   (976kb)

Title: Evolution Meets Diffusion: Efficient Neural Architecture Generation
Authors: Bingye Zhou, Caiyang Yu
Categories: cs.NE cs.AI cs.LG
\\ ( https://arxiv.org/abs/2504.17827 ,  976kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20781
replaced with revised version Wed, 17 Sep 2025 17:01:05 GMT   (2847kb)

Title: Using LLMs in Generating Design Rationale for Software Architecture
  Decisions
Authors: Xiyu Zhou, Ruiyin Li, Peng Liang, Beiqi Zhang, Mojtaba Shahin,
  Zengyang Li, Chen Yang
Categories: cs.SE cs.AI
Comments: 38 pages, 5 images, 9 tables, Manuscript revision submitted to a
  journal (2025)
\\ ( https://arxiv.org/abs/2504.20781 ,  2847kb)
------------------------------------------------------------------------------
\\
arXiv:2505.06311
replaced with revised version Wed, 17 Sep 2025 09:17:08 GMT   (512kb)

Title: Defending against Indirect Prompt Injection by Instruction Detection
Authors: Tongyu Wen, Chenglong Wang, Xiyuan Yang, Haoyu Tang, Yueqi Xie,
  Lingjuan Lyu, Zhicheng Dou, Fangzhao Wu
Categories: cs.CR cs.AI
Comments: 16 pages, 4 figures
\\ ( https://arxiv.org/abs/2505.06311 ,  512kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09974
replaced with revised version Wed, 17 Sep 2025 13:26:12 GMT   (165kb)

Title: Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber
  Security Data
Authors: Adel ElZemity, Budi Arief and Shujun Li
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2505.09974 ,  165kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21717
replaced with revised version Wed, 17 Sep 2025 16:29:44 GMT   (183kb)

Title: Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient
  Sequence Modeling
Authors: M\'onika Farsang, Ramin Hasani, Daniela Rus, Radu Grosu
Categories: cs.LG cs.AI cs.NE
\\ ( https://arxiv.org/abs/2505.21717 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00308
replaced with revised version Wed, 17 Sep 2025 08:35:13 GMT   (1832kb)

Title: MythTriage: Scalable Detection of Opioid Use Disorder Myths on a
  Video-Sharing Platform
Authors: Hayoung Jung, Shravika Mittal, Ananya Aatreya, Navreet Kaur, Munmun De
  Choudhury, Tanushree Mitra
Categories: cs.CY cs.AI cs.CL cs.HC
Comments: To appear at EMNLP 2025. Please cite EMNLP version when proceedings
  are available
\\ ( https://arxiv.org/abs/2506.00308 ,  1832kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13912
replaced with revised version Wed, 17 Sep 2025 13:26:34 GMT   (1417kb)

Title: Self-supervised learning on gene expression data
Authors: Kevin Dradjat and Massinissa Hamidi and Pierre Bartet and Blaise
  Hanczar
Categories: cs.LG cs.AI
Journal-ref: Bioinformatics 2025
\\ ( https://arxiv.org/abs/2507.13912 ,  1417kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20923
replaced with revised version Wed, 17 Sep 2025 09:33:21 GMT   (6852kb)

Title: Pareto-Grid-Guided Large Language Models for Fast and High-Quality
  Heuristics Design in Multi-Objective Combinatorial Optimization
Authors: Minh Hieu Ha, Hung Phan, Tung Duy Doan, Tung Dao, Dao Tran, and Huynh
  Thi Thanh Binh
Categories: cs.NE cs.AI
Comments: 36 pages, 20 figures
\\ ( https://arxiv.org/abs/2507.20923 ,  6852kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00827
replaced with revised version Wed, 17 Sep 2025 15:22:57 GMT   (179kb)

Title: Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract
  Works (LRMoo F1 to schema.org)
Authors: Hudson de Martim
Categories: cs.DL cs.AI cs.CY cs.IR
Comments: Major revision. The paper is now Part I of a series, mapping a formal
  LRMoo-based legal ontology to the web. This part details the mapping of the
  abstract F1 Work to schema.org, clarifying its foundational contribution by
  removing application-specific dependencies
\\ ( https://arxiv.org/abs/2508.00827 ,  179kb)
------------------------------------------------------------------------------
\\
arXiv:2508.05170
replaced with revised version Wed, 17 Sep 2025 10:56:50 GMT   (1053kb)

Title: Posterior-GRPO: Rewarding Reasoning Processes in Code Generation
Authors: Lishui Fan, Yu Zhang, Mouxiang Chen, Zhongxin Liu
Categories: cs.SE cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2508.05170 ,  1053kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13057
replaced with revised version Wed, 17 Sep 2025 16:08:16 GMT   (3008kb)

Title: Hierarchical Evaluation Function: A Multi-Metric Approach for Optimizing
  Demand Forecasting Models
Authors: Adolfo Gonz\'alez and V\'ictor Parada
Categories: cs.LG cs.AI cs.PF
Comments: 31 pages, 15 figures, 25 tables. Submitted as a preprint. The
  manuscript introduces the Hierarchical Evaluation Function, a multi-metric
  framework for optimizing demand forecasting models under high uncertainty.
  Includes extensive experimental validation using real-world datasets and a
  comparative analysis against classical and modern methods
MSC-class: 62M10, 90C59, 68T05
ACM-class: I.2.6; I.5.1; I.5.2; I.5.4; G.1.6
\\ ( https://arxiv.org/abs/2508.13057 ,  3008kb)
------------------------------------------------------------------------------
\\
arXiv:2508.14689
replaced with revised version Wed, 17 Sep 2025 14:57:08 GMT   (115kb)

Title: ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signals
Authors: Yucong Zhang, Juan Liu, Ming Li
Categories: cs.SD cs.AI cs.LG eess.AS
Comments: submitted to ICASSP 2026
\\ ( https://arxiv.org/abs/2508.14689 ,  115kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17600
replaced with revised version Wed, 17 Sep 2025 02:27:49 GMT   (1685kb)

Title: GWM: Towards Scalable Gaussian World Models for Robotic Manipulation
Authors: Guanxing Lu, Baoxiong Jia, Puhao Li, Yixin Chen, Ziwei Wang, Yansong
  Tang, Siyuan Huang
Categories: cs.RO cs.AI cs.CV cs.LG
Comments: Published at ICCV 2025. Project page:
  https://gaussian-world-model.github.io/
\\ ( https://arxiv.org/abs/2508.17600 ,  1685kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18397
replaced with revised version Tue, 16 Sep 2025 21:13:18 GMT   (2998kb)

Title: Mining the Long Tail: A Comparative Study of Data-Centric Criticality
  Metrics for Robust Offline Reinforcement Learning in Autonomous Motion
  Planning
Authors: Antonio Guillen-Perez
Categories: cs.RO cs.AI cs.LG
\\ ( https://arxiv.org/abs/2508.18397 ,  2998kb)
------------------------------------------------------------------------------
\\
arXiv:2509.01319
replaced with revised version Wed, 17 Sep 2025 03:05:36 GMT   (1747kb)

Title: Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for
  Prediction Intervals
Authors: Li Rong Wang, Thomas C. Henderson, Yew Soon Ong, Yih Yng Ng, Xiuyi Fan
Categories: cs.LG cs.AI
Comments: Accepted at the 25th IEEE International Conference on Data Mining
  (ICDM)
\\ ( https://arxiv.org/abs/2509.01319 ,  1747kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05326
replaced with revised version Wed, 17 Sep 2025 17:25:28 GMT   (26kb)

Title: Zero-Knowledge Proofs in Sublinear Space
Authors: Logan Nye
Categories: cs.CR cs.AI
Comments: 23 pages
\\ ( https://arxiv.org/abs/2509.05326 ,  26kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10432 (*cross-listing*)
replaced with revised version Tue, 16 Sep 2025 20:37:41 GMT   (753kb)

Title: Standards in the Preparation of Biomedical Research Metadata: A
  Bridge2AI Perspective
Authors: Harry Caufield, Satrajit Ghosh, Sek Wong Kong, Jillian Parker, Nathan
  Sheffield, Bhavesh Patel, Andrew Williams, Timothy Clark, Monica C.
  Munoz-Torres
Categories: q-bio.OT cs.AI
\\ ( https://arxiv.org/abs/2509.10432 ,  753kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10970
replaced with revised version Wed, 17 Sep 2025 01:44:03 GMT   (3905kb)

Title: The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement
  and Harm Enablement in Large Language Models
Authors: Joshua Au Yeung, Jacopo Dalmasso, Luca Foschini, Richard JB Dobson,
  Zeljko Kraljevic
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.10970 ,  3905kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11417
replaced with revised version Wed, 17 Sep 2025 02:41:34 GMT   (1344kb)

Title: Enhancing Generalization in Vision-Language-Action Models by Preserving
  Pretrained Representations
Authors: Shresth Grover, Akshay Gopalkrishnan, Bo Ai, Henrik I. Christensen,
  Hao Su, Xuanlin Li
Categories: cs.RO cs.AI cs.CV cs.LG
Comments: Project Page: https://gen-vla.github.io/
\\ ( https://arxiv.org/abs/2509.11417 ,  1344kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12275
replaced with revised version Wed, 17 Sep 2025 03:05:23 GMT   (123kb)

Title: Omni-CLST: Error-aware Curriculum Learning with guided Selective
  chain-of-Thought for audio question answering
Authors: Jinghua Zhao, Hang Su, Lichun Fan, Zhenbo Luo, Jian Luan, Hui Wang,
  Haoqin Sun, Yong Qin
Categories: cs.SD cs.AI eess.AS
Comments: 5 pages, 1 figure, 2 tables submitted to icassp, under prereview
\\ ( https://arxiv.org/abs/2509.12275 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13227 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 13:17:03 GMT   (1290kb)

Title: Rich Vehicle Routing Problem in Disaster Management enabling
  Temporally-causal Transhipments across Multi-Modal Transportation Network
Authors: Santanu Banerjee, Goutam Sen, Siddhartha Mukhopadhyay
Categories: math.OC cs.AI cs.SY eess.SY
Comments: Major changes in version II: 1) Supplementary is now a separate
  document, 2) Algorithm steps have been updated with pseudocode in the
  Heuristic, 3) Explanation of the MILP formulation construction is further
  detailed in a supplementary section
MSC-class: 90B06, 90B10, 90B80, 90C11, 90C06, 90C08, 90C35, 90C47, 90C59, 90C90
ACM-class: G.2.1; G.2.2; G.2.3; F.2.2; I.2.8
\\ ( https://arxiv.org/abs/2509.13227 ,  1290kb)
------------------------------------------------------------------------------
\\
arXiv:2311.09945
replaced with revised version Wed, 17 Sep 2025 07:20:16 GMT   (435kb)

Title: An Attention-Based Denoising Framework for Personality Detection in
  Social Media Texts
Authors: Lei Lin, Jizhao Zhu, Qirui Tang, Yihua Du
Categories: cs.CY cs.CL
\\ ( https://arxiv.org/abs/2311.09945 ,  435kb)
------------------------------------------------------------------------------
\\
arXiv:2410.08299
replaced with revised version Tue, 16 Sep 2025 18:52:07 GMT   (780kb)

Title: Privately Learning from Graphs with Applications in Fine-tuning Large
  Language Models
Authors: Haoteng Yin, Rongzhe Wei, Eli Chien, Pan Li
Categories: cs.LG cs.CL cs.CR
Comments: Accepted by COLM 2025
\\ ( https://arxiv.org/abs/2410.08299 ,  780kb)
------------------------------------------------------------------------------
\\
arXiv:2412.16846 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 16:01:26 GMT   (933kb)

Title: KALL-E:Autoregressive Speech Synthesis with Next-Distribution Prediction
Authors: Kangxiang Xia, Xinfa Zhu, Jixun Yao, Wenjie Tian, Wenhao Li, Lei Xie
Categories: eess.AS cs.CL cs.SD
Comments: 6 figures, 5 tables
\\ ( https://arxiv.org/abs/2412.16846 ,  933kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10408
replaced with revised version Wed, 17 Sep 2025 09:28:46 GMT   (2035kb)

Title: Out-of-Context Reasoning in Large Language Models
Authors: Jonathan Shaki, Emanuele La Malfa, Michael Wooldridge, Sarit Kraus
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2503.10408 ,  2035kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12574
replaced with revised version Wed, 17 Sep 2025 03:13:53 GMT   (388kb)

Title: Yet Another Watermark for Large Language Models
Authors: Siyuan Bao, Ying Shi, Zhiguang Yang, Hanzhou Wu and Xinpeng Zhang
Categories: cs.CR cs.CL
Comments: https://scholar.google.com/citations?hl=en&user=IdiF7M0AAAAJ
\\ ( https://arxiv.org/abs/2509.12574 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2408.11915
replaced with revised version Wed, 17 Sep 2025 14:45:41 GMT   (5614kb)

Title: Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event
  Condition For Foley Sound
Authors: Junwon Lee, Jaekwon Im, Dabin Kim, Juhan Nam
Categories: cs.SD cs.CV cs.LG cs.MM eess.AS
Comments: Accepted at IEEE/ACM Transactions on Audio, Speech and Language
  Processing (TASLP)
\\ ( https://arxiv.org/abs/2408.11915 ,  5614kb)
------------------------------------------------------------------------------
\\
arXiv:2410.13034 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 16:19:18 GMT   (35527kb)

Title: Synthesis and Perceptual Scaling of High Resolution Naturalistic Images
  Using Stable Diffusion
Authors: Leonardo Pettini, Carsten Bogler, Christian Doeller and John-Dylan
  Haynes
Categories: q-bio.NC cs.CV
Comments: 80 pages, 26 Figures, 6 tables
\\ ( https://arxiv.org/abs/2410.13034 ,  35527kb)
------------------------------------------------------------------------------
\\
arXiv:2501.18167 (*cross-listing*)
replaced with revised version Tue, 16 Sep 2025 18:03:11 GMT   (9612kb)

Title: Scattering approach to diffusion quantifies axonal damage in brain
  injury
Authors: Ali Abdollahzadeh, Ricardo Coronado-Leija, Hong-Hsi Lee, Alejandra
  Sierra, Els Fieremans, Dmitry S. Novikov
Categories: physics.med-ph cs.CV physics.bio-ph
\\ ( https://arxiv.org/abs/2501.18167 ,  9612kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05424
replaced with revised version Wed, 17 Sep 2025 14:56:24 GMT   (26811kb)

Title: Locally Explaining Prediction Behavior via Gradual Interventions and
  Measuring Property Gradients
Authors: Niklas Penzel and Joachim Denzler
Categories: cs.LG cs.CV
Comments: Accepted at WACV-2026, 45 pages, 39 figures, 15 tables
\\ ( https://arxiv.org/abs/2503.05424 ,  26811kb)
------------------------------------------------------------------------------
\\
arXiv:2505.05798
replaced with revised version Wed, 17 Sep 2025 05:44:40 GMT   (203kb)

Title: Improving Generalizability of Kolmogorov-Arnold Networks via
  Error-Correcting Output Codes
Authors: Youngjoon Lee, Jinu Gong, Joonhyuk Kang
Categories: cs.LG cs.CV eess.IV eess.SP
Comments: Accepted to IEEE BioCAS 2025
\\ ( https://arxiv.org/abs/2505.05798 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02668 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 14:03:37 GMT   (3547kb)

Title: MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak
  Boundary Polyp Detection
Authors: Zhe Yee Tan and Ashwaq Qasem
Categories: eess.IV cs.CV
Comments: This work has been submitted to the IEEE for possible publication
\\ ( https://arxiv.org/abs/2507.02668 ,  3547kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11839
replaced with revised version Wed, 17 Sep 2025 03:11:49 GMT   (4921kb)

Title: TrajBooster: Boosting Humanoid Whole-Body Manipulation via
  Trajectory-Centric Learning
Authors: Jiacheng Liu, Pengxiang Ding, Qihang Zhou, Yuxuan Wu, Da Huang, Zimian
  Peng, Wei Xiao, Weinan Zhang, Lixin Yang, Cewu Lu, Donglin Wang
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/2509.11839 ,  4921kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16298 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 16:12:28 GMT   (742kb)

Title: Scalable hybrid quantum Monte Carlo simulation of U(1) gauge field
  coupled to fermions on GPU
Authors: Kexin Feng, Chuang Chen, Zi Yang Meng
Categories: cond-mat.str-el cs.DC hep-th
Comments: 14+4 pages, 6+6 figures
\\ ( https://arxiv.org/abs/2508.16298 ,  742kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15236
replaced with revised version Wed, 17 Sep 2025 08:17:45 GMT   (183kb)

Title: Applicability of the Minimal Dominating Set for Influence Maximization
  in Multilayer Networks
Authors: Micha{\l} Czuba, Mingshan Jia, Piotr Br\'odka, Katarzyna Musial
Categories: cs.SI cs.MA
Comments: This is a pre-copyedited, author-produced version of an article
  accepted for publication in Journal of Complex Networks. The version of
  record following peer review is available online at:
  https://academic.oup.com/comnet
DOI: 10.1093/comnet/cnaf036
\\ ( https://arxiv.org/abs/2502.15236 ,  183kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20772 (*cross-listing*)
replaced with revised version Wed, 17 Sep 2025 14:15:44 GMT   (376kb)

Title: Welfare and Cost Aggregation for Multi-Agent Control: When to Choose
  Which Social Cost Function, and Why?
Authors: Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio
  Bolognani
Categories: math.OC cs.MA cs.SY eess.SY
\\ ( https://arxiv.org/abs/2503.20772 ,  376kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10426
replaced with revised version Wed, 17 Sep 2025 06:22:52 GMT   (2013kb)

Title: DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with
  Disentangled Context-Aware Pre-Training
Authors: Jianxin Shi, Zengqi Peng, Xiaolong Chen, Tianyu Wo, Jun Ma
Categories: cs.RO cs.MA
\\ ( https://arxiv.org/abs/2509.10426 ,  2013kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11062
replaced with revised version Wed, 17 Sep 2025 11:06:49 GMT   (4973kb)

Title: Auto-Slides: An Interactive Multi-Agent System for Creating and
  Customizing Research Presentations
Authors: Yuheng Yang, Wenjia Jiang, Yang Wang, Yiwei Wang, Chi Zhang
Categories: cs.HC cs.MA
Comments: Project Homepage: https://auto-slides.github.io/
\\ ( https://arxiv.org/abs/2509.11062 ,  4973kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
