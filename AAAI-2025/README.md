# AAAI 2025 论文下载器

一个用于自动下载AAAI 2025会议论文的Python工具。该工具可以从AAAI官方网站批量下载所有论文的PDF文件，并根据论文标题自动命名文件。

## 功能特性

### 🚀 核心功能
- **批量下载**: 自动获取并下载AAAI 2025会议的所有论文PDF
- **智能命名**: 根据论文标题自动生成规范的文件名
- **断点续传**: 支持跳过已下载的文件，避免重复下载
- **进度跟踪**: 实时显示下载进度和状态信息

### 🛡️ 稳定性保障
- **重试机制**: 网络请求失败时自动重试（最多5次）
- **错误处理**: 完善的异常处理和错误日志记录
- **超时控制**: 设置合理的请求超时时间，避免长时间等待
- **随机User-Agent**: 使用多个User-Agent轮换，避免被网站屏蔽

### 📁 文件管理
- **文件名清理**: 自动处理文件名中的非法字符
- **长度限制**: 限制文件名长度，避免系统兼容性问题
- **序号前缀**: 为文件添加序号前缀，便于排序和管理
- **统计报告**: 下载完成后提供详细的统计信息

## 项目结构

```
AAAI-2025/
├── config.py              # 配置文件
├── download_papers.py      # 主程序文件
├── pages.html             # 网页源码（用于测试）
└── README.md              # 说明文档
```

## 安装依赖

确保您的Python环境已安装以下依赖包：

```bash
pip install requests beautifulsoup4 pathlib
```

或者创建requirements.txt文件：

```bash
# requirements.txt
requests>=2.25.0
beautifulsoup4>=4.9.0
```

然后安装：
```bash
pip install -r requirements.txt
```

## 配置说明

### 主要配置项 (config.py)

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| `AAAI_ISSUE_URL` | AAAI官方链接 | 论文列表页面URL |
| `DEFAULT_SAVE_DIR` | "AAAI-2025-Papers" | 默认保存目录 |
| `DEFAULT_DELAY` | 1.5秒 | 下载间隔时间 |
| `MAX_DOWNLOADS` | None | 限制下载数量（None=全部） |
| `REQUEST_TIMEOUT` | 30秒 | 请求超时时间 |
| `MAX_RETRY_ATTEMPTS` | 5次 | 最大重试次数 |
| `MAX_FILENAME_LENGTH` | 150字符 | 最大文件名长度 |

### 网络配置
- **超时设置**: 页面获取10秒，文件下载30秒
- **重试策略**: 失败后等待2秒再重试，最多重试5次
- **User-Agent轮换**: 使用3个不同的浏览器标识

## 使用方法

### 基本使用

1. **直接运行**:
   ```bash
   python download_papers.py
   ```

2. **程序会自动执行以下步骤**:
   - 获取AAAI 2025论文列表页面
   - 解析所有论文的PDF链接和标题
   - 创建保存目录
   - 逐个下载PDF文件
   - 生成下载统计报告

### 自定义配置

如需修改配置，请编辑 `config.py` 文件：

```python
# 修改保存目录
DEFAULT_SAVE_DIR = "我的论文集合"

# 限制下载数量（仅下载前10篇）
MAX_DOWNLOADS = 10

# 调整下载间隔（更快下载，但可能被限制）
DEFAULT_DELAY = 0.5
```

## 输出示例

### 运行日志
```
2025-01-XX XX:XX:XX - __main__ - INFO - 开始AAAI 2025论文下载程序
2025-01-XX XX:XX:XX - __main__ - INFO - 步骤1: 获取页面内容
2025-01-XX XX:XX:XX - __main__ - INFO - 成功获取页面内容
2025-01-XX XX:XX:XX - __main__ - INFO - 步骤2: 解析PDF链接和标题
2025-01-XX XX:XX:XX - __main__ - INFO - 找到 XXX 个文章摘要容器
2025-01-XX XX:XX:XX - __main__ - INFO - 找到 XXX 个PDF文件
2025-01-XX XX:XX:XX - __main__ - INFO - 步骤4: 开始下载PDF文件
2025-01-XX XX:XX:XX - __main__ - INFO - 进度: 1/XXX - [PDF链接]
2025-01-XX XX:XX:XX - __main__ - INFO - 论文标题: [论文标题]
2025-01-XX XX:XX:XX - __main__ - INFO - 开始下载: 001_论文标题.pdf
2025-01-XX XX:XX:XX - __main__ - INFO - 下载完成: 001_论文标题.pdf
```

### 最终统计
```
==================================================
下载任务完成总结:
成功下载: XXX 个文件
下载失败: 0 个文件
文件总数: XXX 个
总大小: XXX.XX MB
==================================================
```

## 文件命名规则

下载的PDF文件按以下规则命名：
- 格式：`序号_清理后的标题.pdf`
- 示例：`001_Deep_Learning_for_Natural_Language_Processing.pdf`
- 特殊字符会被替换为下划线
- 文件名长度限制在150字符以内

## 错误处理

### 常见问题及解决方案

1. **网络连接失败**
   - 程序会自动重试5次
   - 检查网络连接和防火墙设置

2. **文件下载失败**
   - 不完整的文件会被自动删除
   - 重新运行程序会跳过已下载的文件

3. **解析失败**
   - 可能是网页结构发生变化
   - 检查 `config.py` 中的CSS选择器配置

4. **磁盘空间不足**
   - 确保有足够的存储空间
   - 可以设置 `MAX_DOWNLOADS` 限制下载数量

## 技术实现

### 核心模块

1. **网页解析** (`extract_pdf_links_with_titles`)
   - 使用BeautifulSoup解析HTML
   - 提取论文标题和PDF链接
   - 支持CSS选择器配置

2. **文件下载** (`download_pdf`)
   - 流式下载大文件
   - 支持断点续传
   - 完整的错误处理

3. **文件管理** (`sanitize_filename`)
   - 清理非法字符
   - 长度限制
   - 编码处理

### 依赖库
- `requests`: HTTP请求处理
- `beautifulsoup4`: HTML解析
- `pathlib`: 路径操作
- `logging`: 日志记录

## 注意事项

### 使用建议
- 🕐 建议在网络状况良好时运行
- 💾 确保有足够的磁盘空间（通常需要几GB）
- ⏱️ 完整下载可能需要较长时间，请耐心等待
- 🔄 如果中断，重新运行会自动跳过已下载的文件

### 法律声明
- 本工具仅用于学术研究目的
- 请遵守AAAI网站的使用条款
- 下载的论文版权归原作者所有
- 请勿用于商业用途

### 技术限制
- 依赖于AAAI网站的HTML结构
- 网站结构变化可能影响解析功能
- 受网络状况和服务器响应速度影响

## 更新日志

### v1.0.0
- 初始版本发布
- 支持AAAI 2025论文批量下载
- 完整的错误处理和重试机制
- 智能文件命名和管理功能

## 贡献

欢迎提交Issue和Pull Request来改进这个工具！

## 许可证

本项目采用MIT许可证，详见LICENSE文件。 