Gmail	李嘉维 <qetwe0000@gmail.com>
cs daily Subj-class mailing 8004a1 1
send mail ONLY to cs <no-reply@arxiv.org>	2025年10月7日 13:04
回复：cs@arxiv.org
收件人：cs daily title/abstract distribution <rabble@arxiv.org>
------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Artificial Intelligence
Computation and Language
Computer Vision and Pattern Recognition
Distributed, Parallel, and Cluster Computing
Multiagent Systems
 received from  Fri  3 Oct 25 18:00:00 GMT  to  Mon  6 Oct 25 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:2510.03285
Date: Sun, 28 Sep 2025 20:51:05 GMT   (3913kb)

Title: WAREX: Web Agent Reliability Evaluation on Existing Benchmarks
Authors: Su Kara, Fazle Faisal, Suman Nath
Categories: cs.AI cs.CR cs.LG
\\
  Recent advances in browser-based LLM agents have shown promise for automating
tasks ranging from simple form filling to hotel booking or online shopping.
Current benchmarks measure agent performance in controlled environments, such
as containers or stable networks, where websites behave deterministically.
However, in the real world, users access websites over networks and HTTPS
connections that introduce instability from multiple sources: client-side,
server-side issues or broader system failures. Moreover, live websites are
prone to web attacks such Cross-Site Scripting, as well as general site
modifications which can cause unexpected or malicious pop-ups or improper
functionality. To address this gap, we present WAREX: Web Agent Reliability
Evaluation on Existing Benchmarks. We measure the impact of WAREX across three
popular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that
introducing WAREX leads to significant drops in task success rates,
highlighting the limited robustness of state-of-the-art agents.
\\ ( https://arxiv.org/abs/2510.03285 ,  3913kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03377
Date: Fri, 3 Oct 2025 13:52:20 GMT   (1441kb)

Title: Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop
  Scheduling with Blocking Constraints
Authors: Ahmed Missaoui, Cemalettin Ozturk, Barry O'Sullivan
Categories: cs.AI
\\
  The scarcity of non-renewable energy sources, geopolitical problems in its
supply, increasing prices, and the impact of climate change, force the global
economy to develop more energy-efficient solutions for their operations. The
Manufacturing sector is not excluded from this challenge as one of the largest
consumers of energy. Energy-efficient scheduling is a method that attracts
manufacturing companies to reduce their consumption as it can be quickly
deployed and can show impact immediately. In this study, the hybrid flow shop
scheduling problem with blocking constraint (BHFS) is investigated in which we
seek to minimize the latest completion time (i.e. makespan) and overall energy
consumption, a typical manufacturing setting across many industries from
automotive to pharmaceutical. Energy consumption and the latest completion time
of customer orders are usually conflicting objectives. Therefore, we first
formulate the problem as a novel multi-objective mixed integer programming
(MIP) model and propose an augmented epsilon-constraint method for finding the
Pareto-optimal solutions. Also, an effective multi-objective metaheuristic
algorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large
instances in reasonable time. Our proposed methods are benchmarked using small,
medium, and large-size instances to evaluate their efficiency. Two well-known
algorithms are adopted for comparing our novel approaches. The computational
results show the effectiveness of our method.
\\ ( https://arxiv.org/abs/2510.03377 ,  1441kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03399
Date: Fri, 3 Oct 2025 18:00:01 GMT   (1014kb)

Title: Know Thyself? On the Incapability and Implications of AI
  Self-Recognition
Authors: Xiaoyan Bai, Aryan Shrivastava, Ari Holtzman, Chenhao Tan
Categories: cs.AI cs.CL cs.CY cs.LG
Comments: Our code is available, see
  https://github.com/ChicagoHAI/self-recognition
\\
  Self-recognition is a crucial metacognitive capability for AI systems,
relevant not only for psychological analysis but also for safety, particularly
in evaluative scenarios. Motivated by contradictory interpretations of whether
models possess self-recognition (Panickssery et al., 2024; Davidson et al.,
2024), we introduce a systematic evaluation framework that can be easily
applied and updated. Specifically, we measure how well 10 contemporary larger
language models (LLMs) can identify their own generated text versus text from
other models through two tasks: binary self-recognition and exact model
prediction. Different from prior claims, our results reveal a consistent
failure in self-recognition. Only 4 out of 10 models predict themselves as
generators, and the performance is rarely above random chance. Additionally,
models exhibit a strong bias toward predicting GPT and Claude families. We also
provide the first evaluation of model awareness of their own and others'
existence, as well as the reasoning behind their choices in self-recognition.
We find that the model demonstrates some knowledge of its own existence and
other models, but their reasoning reveals a hierarchical bias. They appear to
assume that GPT, Claude, and occasionally Gemini are the top-tier models, often
associating high-quality text with them. We conclude by discussing the
implications of our findings on AI safety and future directions to develop
appropriate AI self-awareness.
\\ ( https://arxiv.org/abs/2510.03399 ,  1014kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03418
Date: Fri, 3 Oct 2025 18:24:27 GMT   (188kb)

Title: ContraGen: A Multi-Agent Generation Framework for Enterprise
  Contradictions Detection
Authors: Ananya Mantravadi, Shivali Dalmia, Abhishek Mukherji, Nand Dave,
  Anudha Mittal
Categories: cs.AI cs.MA
\\
  Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,
offering advanced capabilities for information access and decision-making.
However, contradictions in retrieved evidence can result in inconsistent or
untrustworthy outputs, which is especially problematic in enterprise settings
where compliance, governance, and accountability are critical. Existing
benchmarks for contradiction detection are limited to sentence-level analysis
and do not capture the complexity of enterprise documents such as contracts,
financial filings, compliance reports, or policy manuals. To address this
limitation, we propose ContraGen, a contradiction-aware benchmark framework
tailored to enterprise domain. The framework generates synthetic
enterprise-style documents with embedded contradictions, enabling systematic
evaluation of both intra-document and cross-document consistency. Automated
contradiction mining is combined with human-in-the-loop validation to ensure
high accuracy. Our contributions include generating realistic enterprise
documents, modeling a taxonomy of contradiction types common in business
processes, enabling controlled creation of self- and pairwise contradictions,
developing a contradiction-aware retrieval evaluation pipeline and embedding
human oversight to reflect domain-specific judgment complexity. This work
establishes a foundation for more trustworthy and accountable RAG systems in
enterprise information-seeking applications, where detecting and resolving
contradictions is essential for reducing risk and ensuring compliance.
\\ ( https://arxiv.org/abs/2510.03418 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03453
Date: Fri, 3 Oct 2025 19:19:48 GMT   (925kb)

Title: A Qualitative Comparative Evaluation of Cognitive and Generative
  Theories
Authors: Paul S. Rosenbloom
Categories: cs.AI
Comments: To appear in Proceedings of the 12th Annual Conference on Advances in
  Cognitive Systems (ACS-25)
\\
  Evaluation is a critical activity associated with any theory. Yet this has
proven to be an exceptionally challenging activity for theories based on
cognitive architectures. For an overlapping set of reasons, evaluation can also
be challenging for theories based on generative neural architectures. This dual
challenge is approached here by leveraging a broad perspective on theory
evaluation to yield a wide-ranging, albeit qualitative, comparison of
whole-mind-oriented cognitive and generative architectures and the full systems
that are based on these architectures.
\\ ( https://arxiv.org/abs/2510.03453 ,  925kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03469
Date: Fri, 3 Oct 2025 19:46:55 GMT   (151kb)

Title: Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan
  Verification
Authors: Keshav Ramani, Vali Tawosi, Salwa Alamir, Daniel Borrajo
Categories: cs.AI cs.LO
\\
  We introduce a novel framework for evaluating the alignment between natural
language plans and their expected behavior by converting them into Kripke
structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)
and performing model checking. We systematically evaluate this framework on a
simplified version of the PlanBench plan verification dataset and report on
metrics like Accuracy, Precision, Recall and F1 scores. Our experiments
demonstrate that GPT-5 achieves excellent classification performance (F1 score
of 96.3%) while almost always producing syntactically perfect formal
representations that can act as guarantees. However, the synthesis of
semantically perfect formal models remains an area for future exploration.
\\ ( https://arxiv.org/abs/2510.03469 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03485
Date: Fri, 3 Oct 2025 20:03:19 GMT   (1826kb)

Title: Towards Policy-Compliant Agents: Learning Efficient Guardrails For
  Policy Violation Detection
Authors: Xiaofei Wen, Wenjie Jacky Mo, Yanan Xie, Peng Qi, Muhao Chen
Categories: cs.AI
Comments: 16 pages, 5 figures
ACM-class: I.2.7
\\
  Autonomous web agents need to operate under externally imposed or
human-specified policies while generating long-horizon trajectories. However,
little work has examined whether these trajectories comply with such policies,
or whether policy violations persist across different contexts such as domains
(e.g., shopping or coding websites) and subdomains (e.g., product search and
order management in shopping). To address this gap, we introduce
PolicyGuardBench, a benchmark of about 60k examples for detecting policy
violations in agent trajectories. From diverse agent runs, we generate a broad
set of policies and create both within subdomain and cross subdomain pairings
with violation labels. In addition to full-trajectory evaluation,
PolicyGuardBench also includes a prefix-based violation detection task where
models must anticipate policy violations from truncated trajectory prefixes
rather than complete sequences. Using this dataset, we train PolicyGuard-4B, a
lightweight guardrail model that delivers strong detection accuracy across all
tasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes
across domains and preserves high accuracy on unseen settings. Together,
PolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework
for studying policy compliance in web agent trajectories, and show that
accurate and generalizable guardrails are feasible at small scales.
\\ ( https://arxiv.org/abs/2510.03485 ,  1826kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03506
Date: Fri, 3 Oct 2025 20:40:30 GMT   (32999kb)

Title: OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit
  Flows
Authors: John Nguyen, Marton Havasi, Tariq Berrada, Luke Zettlemoyer, Ricky T.
  Q. Chen
Categories: cs.AI
Comments: https://johnlnguyen.com/oneflow
\\
  We present OneFlow, the first non-autoregressive multimodal model that
enables variable-length and concurrent mixed-modal generation. Unlike
autoregressive models that enforce rigid causal ordering between text and image
generation, OneFlow combines an insertion-based Edit Flow for discrete text
tokens with Flow Matching for image latents. OneFlow enables concurrent
text-image synthesis with hierarchical sampling that prioritizes content over
grammar. Through controlled experiments across model sizes from 1B to 8B, we
demonstrate that OneFlow outperforms autoregressive baselines on both
generation and understanding tasks while using up to 50% fewer training FLOPs.
OneFlow surpasses both autoregressive and diffusion-based approaches while
unlocking new capabilities for concurrent generation, iterative refinement, and
natural reasoning-like generation.
\\ ( https://arxiv.org/abs/2510.03506 ,  32999kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03605
Date: Sat, 4 Oct 2025 01:38:48 GMT   (193kb)

Title: Understanding the Role of Training Data in Test-Time Scaling
Authors: Adel Javanmard, Baharan Mirzasoleiman, Vahab Mirrokni
Categories: cs.AI cs.LG stat.ML
Comments: 24 pages, 4 figures
\\
  Test-time scaling improves the reasoning capabilities of large language
models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts
(CoTs). This enables models to tackle more complex problem by breaking them
down into additional steps, backtracking, and correcting mistakes. Despite its
strong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions
in the training data under which long CoTs emerge, and when such long CoTs
improve the performance, remain unclear. In this paper, we study the
performance of test-time scaling for transformers trained on an in-context
weight prediction task for linear regression. Our analysis provides a
theoretical explanation for several intriguing observations: First, at any
fixed test error, increasing test-time compute allows us to reduce the number
of in-context examples (context length) in training prompts. Second, if the
skills required to solve a downstream task are not sufficiently present in the
training data, increasing test-time compute can harm performance. Finally, we
characterize task hardness via the smallest eigenvalue of its feature
covariance matrix and show that training on a diverse, relevant, and hard set
of tasks results in best performance for test-time scaling. We confirm our
findings with experiments on large, nonlinear transformer architectures.
\\ ( https://arxiv.org/abs/2510.03605 ,  193kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03612
Date: Sat, 4 Oct 2025 01:57:20 GMT   (9030kb)

Title: Cross-Modal Content Optimization for Steering Web Agent Preferences
Authors: Tanqiu Jiang, Min Bai, Nikolaos Pappas, Yanjun Qi, Sandesh Swamy
Categories: cs.AI cs.CR
\\
  Vision-language model (VLM)-based web agents increasingly power high-stakes
selection tasks like content recommendation or product ranking by combining
multimodal perception with preference reasoning. Recent studies reveal that
these agents are vulnerable against attackers who can bias selection outcomes
through preference manipulations using adversarial pop-ups, image
perturbations, or content tweaks. Existing work, however, either assumes strong
white-box access, with limited single-modal perturbations, or uses impractical
settings. In this paper, we demonstrate, for the first time, that joint
exploitation of visual and textual channels yields significantly more powerful
preference manipulations under realistic attacker capabilities. We introduce
Cross-Modal Preference Steering (CPS) that jointly optimizes imperceptible
modifications to an item's visual and natural language descriptions, exploiting
CLIP-transferable image perturbations and RLHF-induced linguistic biases to
steer agent decisions. In contrast to prior studies that assume gradient
access, or control over webpages, or agent memory, we adopt a realistic
black-box threat setup: a non-privileged adversary can edit only their own
listing's images and textual metadata, with no insight into the agent's model
internals. We evaluate CPS on agents powered by state-of-the-art proprietary
and open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both
movie selection and e-commerce tasks. Our results show that CPS is
significantly more effective than leading baseline methods. For instance, our
results show that CPS consistently outperforms baselines across all models
while maintaining 70% lower detection rates, demonstrating both effectiveness
and stealth. These findings highlight an urgent need for robust defenses as
agentic systems play an increasingly consequential role in society.
\\ ( https://arxiv.org/abs/2510.03612 ,  9030kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03632
Date: Sat, 4 Oct 2025 02:30:40 GMT   (250kb)

Title: MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual
  Information
Authors: Jiaxi Li, Yucheng Shi, Jin Lu, Ninghao Liu
Categories: cs.AI
Comments: 18 pages
\\
  Tree search has become as a representative framework for test-time reasoning
with large language models (LLMs), exemplified by methods such as
Tree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning
paths. However, it remains difficult to provide instant and reliable
quantitative assessments of intermediate reasoning step quality, and extensive
path exploration is computationally costly. To address this, we propose Mutual
Information Tree Search (MITS), a novel framework that guides reasoning with
information-theoretic principles. MITS introduces an effective scoring function
based on pointwise mutual information (PMI), which enables step-wise evaluation
of reasoning paths and search tree expansion via beam search without expensive
look-ahead simulations, achieving superior reasoning performances while
maintaining computational efficiency. The framework is complemented by an
entropy-based dynamic sampling strategy that adaptively allocates computational
resources to uncertain reasoning steps where exploration is most beneficial.
For final prediction, MITS employs a weighted voting scheme that combines PMI
scores with prediction consensus. Through comprehensive experiments on diverse
reasoning benchmarks, MITS consistently surpasses baseline methods,
establishing a principled and efficient framework for LLM reasoning.
\\ ( https://arxiv.org/abs/2510.03632 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03680
Date: Sat, 4 Oct 2025 05:24:27 GMT   (1578kb)

Title: Rainbow Padding: Mitigating Early Termination in Instruction-Tuned
  Diffusion LLMs
Authors: Bumjun Kim, Dongjae Jeon, Dueun Kim, Wonje Jeung, Albert No
Categories: cs.AI
Comments: 25 pages. Project page available
  at~\url{https://ai-isl.github.io/rainbow-padding}
\\
  Diffusion large language models (dLLMs) have emerged as a promising
alternative to autoregressive models, offering flexible generation orders and
strong performance on complex reasoning tasks. However, instruction-tuned dLLMs
exhibit a critical vulnerability we term \texttt{<eos>} overflow: as allocated
sequence length increases, responses paradoxically become shorter, collapsing
into early termination or degenerating into streams of \texttt{<eos>} tokens.
Although noticed in practice, this issue has not been systematically analyzed.
We trace its root cause to the dual role of \texttt{<eos>} as both termination
and padding, which concentrates probability mass on \texttt{<eos>} at later
positions and propagates backward to trigger early termination. To address
this, we introduce Rainbow Padding, a simple remedy that replaces repeated
\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,
distributing probability mass and breaking \texttt{<eos>} dominance.
Experiments show that Rainbow Padding substantially improves length robustness
and output quality, with as few as seven padding tokens sufficient to prevent
early termination. Moreover, the method integrates efficiently into existing
instruction-tuned models: LoRA fine-tuning for a single epoch on minimal data
yields significant improvements, making this solution highly practical. The
code is publicly available at https://github.com/quasar529/rainbow-padding.
\\ ( https://arxiv.org/abs/2510.03680 ,  1578kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03696
Date: Sat, 4 Oct 2025 06:22:47 GMT   (5604kb)

Title: Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational
  Agents and Chatbots using Teacher Models
Authors: Deepak Babu Piskala, Sharlene Chen, Udita Patel, Parul Kalra, Rafael
  Castrillo
Categories: cs.AI cs.CL
\\
  Evaluating the quality of multi-turn chatbot interactions remains
challenging, as most existing methods assess interactions at the turn level
without addressing whether a user's overarching goal was fulfilled. A ``goal''
here refers to an information need or task, such as asking for policy
information or applying for leave. We propose a comprehensive framework for
goal-oriented evaluation of multi-agent systems (MAS), introducing the
\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,
and a \textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for
failure in multi-agent chatbots. Our method segments conversations by user
goals and evaluates success using all relevant turns. We present a model-based
evaluation system combining teacher LLMs, where domain experts define goals,
set quality standards serving as a guidance for the LLMs. The LLMs use
``thinking tokens'' to produce interpretable rationales, enabling
\textit{explainable}, \textit{data-efficient} evaluations. In an enterprise
setting, we apply our framework to evaluate AIDA, a zero-to-one employee
conversational agent system built as a ground-up multi-agent conversational
agent, and observe GSR improvement from 63\% to 79\% over six months since its
inception. Our framework is generic and offers actionable insights through a
detailed defect taxonomy based on analysis of failure points in multi-agent
chatbots, diagnosing overall success, identifying key failure modes, and
informing system improvements.
\\ ( https://arxiv.org/abs/2510.03696 ,  5604kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03700
Date: Sat, 4 Oct 2025 06:42:22 GMT   (4112kb)

Title: H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis
Authors: Seungseop Lim, Gibaeg Kim, Hyunkyung Lee, Wooseok Han, Jean Seo,
  Jaehyo Yoo, Eunho Yang
Categories: cs.AI
Comments: GenAI4Health @NeurIPS 2025
\\
  An accurate differential diagnosis (DDx) is essential for patient care,
shaping therapeutic decisions and influencing outcomes. Recently, Large
Language Models (LLMs) have emerged as promising tools to support this process
by generating a DDx list from patient narratives. However, existing evaluations
of LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,
which fail to distinguish between clinically relevant near-misses and
diagnostically distant errors. To mitigate this limitation, we introduce H-DDx,
a hierarchical evaluation framework that better reflects clinical relevance.
H-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses
to ICD-10 codes and applies a hierarchical metric that credits predictions
closely related to the ground-truth diagnosis. In benchmarking 22 leading
models, we show that conventional flat metrics underestimate performance by
overlooking clinically meaningful outputs, with our results highlighting the
strengths of domain-specialized open-source models. Furthermore, our framework
enhances interpretability by revealing hierarchical error patterns,
demonstrating that LLMs often correctly identify the broader clinical context
even when the precise diagnosis is missed.
\\ ( https://arxiv.org/abs/2510.03700 ,  4112kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03727
Date: Sat, 4 Oct 2025 08:14:20 GMT   (28603kb)

Title: Bridging the Gap Between Multimodal Foundation Models and World Models
Authors: Xuehai He
Categories: cs.AI cs.CL cs.CV cs.LG
Comments: PhD thesis
\\
  Humans understand the world through the integration of multiple sensory
modalities, enabling them to perceive, reason about, and imagine dynamic
physical processes. Inspired by this capability, multimodal foundation models
(MFMs) have emerged as powerful tools for multimodal understanding and
generation. However, today's MFMs fall short of serving as effective world
models. They lack the essential ability such as perform counterfactual
reasoning, simulate dynamics, understand the spatiotemporal information,
control generated visual outcomes, and perform multifaceted reasoning. We
investigates what it takes to bridge the gap between multimodal foundation
models and world models. We begin by improving the reasoning capabilities of
MFMs through discriminative tasks and equipping MFMs with structured reasoning
skills, such as causal inference, counterfactual thinking, and spatiotemporal
reasoning, enabling them to go beyond surface correlations and understand
deeper relationships within visual and textual data. Next, we explore
generative capabilities of multimodal foundation models across both image and
video modalities, introducing new frameworks for structured and controllable
generation. Our approaches incorporate scene graphs, multimodal conditioning,
and multimodal alignment strategies to guide the generation process, ensuring
consistency with high-level semantics and fine-grained user intent. We further
extend these techniques to controllable 4D generation, enabling interactive,
editable, and morphable object synthesis over time and space.
\\ ( https://arxiv.org/abs/2510.03727 ,  28603kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03771
Date: Sat, 4 Oct 2025 10:41:09 GMT   (416kb)

Title: OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent
  Simulation
Authors: Divij Handa, David Blincoe, Orson Adams, Yinlin Fu
Categories: cs.AI
\\
  Deploying capable and user-aligned LLM-based systems necessitates reliable
evaluation. While LLMs excel in verifiable tasks like coding and mathematics,
where gold-standard solutions are available, adoption remains challenging for
subjective tasks that lack a single correct answer. E-commerce Query Rewriting
(QR) is one such problem where determining whether a rewritten query properly
captures the user intent is extremely difficult to figure out algorithmically.
In this work, we introduce OptAgent, a novel framework that combines
multi-agent simulations with genetic algorithms to verify and optimize queries
for QR. Instead of relying on a static reward model or a single LLM judge, our
approach uses multiple LLM-based agents, each acting as a simulated shopping
customer, as a dynamic reward signal. The average of these agent-derived scores
serves as an effective fitness function for an evolutionary algorithm that
iteratively refines the user's initial query. We evaluate OptAgent on a dataset
of 1000 real-world e-commerce queries in five different categories, and we
observe an average improvement of 21.98% over the original user query and 3.36%
over a Best-of-N LLM rewriting baseline.
\\ ( https://arxiv.org/abs/2510.03771 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03777
Date: Sat, 4 Oct 2025 11:02:39 GMT   (244kb)

Title: GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at
  Inference-Time
Authors: Divij Handa, Mihir Parmar, Aswin RRV, Md Nayem Uddin, Hamid Palangi,
  Chitta Baral
Categories: cs.AI cs.LG
\\
  Repeated Sampling (RS) is a simple inference-time algorithm that has been
shown to improve model performance on complex tasks. Although it is an
effective way of scaling inference time, it often struggles to generate diverse
solution candidates, frequently relying on the same underlying approach to
solve the problem and thus producing redundant samples. To address this
limitation, we propose a new inference algorithm, GuidedSampling, which
decouples the exploration and generation phases during inference, increasing
diversity of generated candidate solutions. The exploration phase identifies
multiple concepts that can be utilized to solve the problem, while the
generation phase applies a specific concept to provide final solution
candidates. We first define the theoretical bounds of GuidedSampling and then
empirically demonstrate that it improves the performance of base model at
pass@50 by on an average ~21.6% across various benchmarks compared to RS.
Furthermore, models trained on trajectories of GuidedSampling exhibit
substantial performance improvements at pass@5 by on an average ~9.7%, compared
to models trained on traditional RS. Additionally, models trained with
GuidedSampling increases the average number of concepts per instance (1.67 ->
3.03), yielding a diverse set of candidates than traditional RS.
\\ ( https://arxiv.org/abs/2510.03777 ,  244kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03845
Date: Sat, 4 Oct 2025 15:46:04 GMT   (43kb)

Title: The Hidden Game Problem
Authors: Gon Buzaglo, Noah Golowich, Elad Hazan
Categories: cs.AI cs.GT cs.LG stat.ML
\\
  This paper investigates a class of games with large strategy spaces,
motivated by challenges in AI alignment and language games. We introduce the
hidden game problem, where for each player, an unknown subset of strategies
consistently yields higher rewards compared to the rest. The central question
is whether efficient regret minimization algorithms can be designed to discover
and exploit such hidden structures, leading to equilibrium in these subgames
while maintaining rationality in general. We answer this question affirmatively
by developing a composition of regret minimization techniques that achieve
optimal external and swap regret bounds. Our approach ensures rapid convergence
to correlated equilibria in hidden subgames, leveraging the hidden game
structure for improved computational efficiency.
\\ ( https://arxiv.org/abs/2510.03845 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03847
Date: Sat, 4 Oct 2025 15:48:04 GMT   (1163kb)

Title: Small Language Models for Agentic Systems: A Survey of Architectures,
  Capabilities, and Deployment Trade offs
Authors: Raghav Sharma and Manan Mehta
Categories: cs.AI cs.LG
Comments: 9 Pages
\\
  Small language models (SLMs; 1-12B params, sometimes up to 20B) are
sufficient and often superior for agentic workloads where the objective is
schema- and API-constrained accuracy rather than open-ended generation. We
synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,
Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,
DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,
StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with
guided decoding libraries (XGrammar, Outlines). We formalize SLM-default,
LLM-fallback systems with uncertainty-aware routing and verifier cascades, and
propose engineering metrics that reflect real production goals: cost per
successful task (CPS), schema validity rate, executable call rate, p50/p95
latency, and energy per request. Guided decoding, strict JSON Schema outputs,
and validator-first tool execution close much of the capability gap with larger
models and often let SLMs match or surpass LLMs on tool use, function calling,
and RAG at 10x-100x lower token cost with materially better latency and energy.
We provide design patterns for agent stacks that prioritize SLMs: schema-first
prompting, type-safe function registries, confidence scoring with verifier
rollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits
where fallback remains valuable (open-domain reasoning and some long-horizon
planning). The result is a practical blueprint for building fast, inexpensive,
and reliable agents that default to SLMs while preserving headroom with
targeted LLM assistance.
  Keywords: small language models, agents, function calling, structured
outputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,
edge inference
\\ ( https://arxiv.org/abs/2510.03847 ,  1163kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03851
Date: Sat, 4 Oct 2025 15:52:31 GMT   (266kb)

Title: Algorithm Generation via Creative Ideation
Authors: Ruiying Ma, Chieh-Jan Mike Liang, Yanjie Gao, Francis Y. Yan
Categories: cs.AI
\\
  Designing system algorithms remains challenging, where the discontinuous
nature of the solution space often forces system engineers to rely on generic
heuristics at the expense of performance. We study whether LLMs can practically
drive algorithm generation, and find that they are biased towards well-known
generic designs, rather than making the creative leaps needed to navigate the
discontinuous solution space. To address this limitation, we introduce
MetaMuse, a framework for creative ideation built on three self-reflection
principles: (1) quantifying solution diversity and usefulness in measurable
performance space, rather than abstract idea space, (2) steering ideation
through external stimuli, rather than internal randomness, and (3) constructing
executable solutions using waypoint reasoning, rather than free-form
chain-of-thought. Extensive evaluation shows that MetaMuse can generate
high-performing solutions for two critical problems at a global cloud provider:
cache replacement (reducing cache misses by up to 35.76%) and online bin
packing (reducing bin usage by up to 30.93%).
\\ ( https://arxiv.org/abs/2510.03851 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03859
Date: Sat, 4 Oct 2025 16:12:45 GMT   (1875kb)

Title: Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT
  Infrastructure using LLM-Enhanced Contextual Reasoning
Authors: Raghav Sharma, Manan Mehta
Categories: cs.AI cs.LG
Comments: 22 pages
\\
  Ensuring that critical IoT systems function safely and smoothly depends a lot
on finding anomalies quickly. As more complex systems, like smart healthcare,
energy grids and industrial automation, appear, it is easier to see the
shortcomings of older methods of detection. Monitoring failures usually happen
in dynamic, high dimensional situations, especially when data is incomplete,
messy or always evolving. Such limits point out the requirement for adaptive,
intelligent systems that always improve and think. LLMs are now capable of
significantly changing how context is understood and semantic inference is done
across all types of data. This proposal suggests using an LLM supported
contextual reasoning method along with XAI agents to improve how anomalies are
found in significant IoT environments. To discover hidden patterns and notice
inconsistencies in data streams, it uses attention methods, avoids dealing with
details from every time step and uses memory buffers with meaning. Because no
code AI stresses transparency and interpretability, people can check and accept
the AI's decisions, helping ensure AI follows company policies. The two
architectures are put together in a test that compares the results of the
traditional model with those of the suggested LLM enhanced model. Important
measures to check are the accuracy of detection, how much inaccurate
information is included in the results, how clearly the findings can be read
and how fast the system responds under different test situations. The
metaheuristic is tested in simulations of real world smart grid and healthcare
contexts to check its adaptability and reliability. From the study, we see that
the new approach performs much better than most existing models in both
accuracy and interpretation, so it could be a good fit for future anomaly
detection tasks in IoT
\\ ( https://arxiv.org/abs/2510.03859 ,  1875kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03863
Date: Sat, 4 Oct 2025 16:19:21 GMT   (1566kb)

Title: Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for
  Human-Machine Differentiation
Authors: Arina Kharlamova, Bowei He, Chen Ma, Xue Liu
Categories: cs.AI cs.CR
Comments: Submitted to ICLR 2026
\\
  Online services rely on CAPTCHAs as a first line of defense against automated
abuse, yet recent advances in multi-modal large language models (MLLMs) have
eroded the effectiveness of conventional designs that focus on text recognition
or 2D image understanding. To address this challenge, we present Spatial
CAPTCHA, a novel human-verification framework that leverages fundamental
differences in spatial reasoning between humans and MLLMs. Unlike existing
CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern
AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,
perspective-taking, occlusion handling, and mental rotation. These skills are
intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The
system employs a procedural generation pipeline with constraint-based
difficulty control, automated correctness verification, and human-in-the-loop
validation to ensure scalability, robustness, and adaptability. Evaluation on a
corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly
outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%
Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,
which confirms its effectiveness as both a security mechanism and a diagnostic
tool for spatial reasoning in AI.
\\ ( https://arxiv.org/abs/2510.03863 ,  1566kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03886
Date: Sat, 4 Oct 2025 17:41:24 GMT   (44458kb)

Title: Rare Text Semantics Were Always There in Your Diffusion Transformer
Authors: Seil Kang, Woojung Han, Dayun Ju, Seong Jae Hwang
Categories: cs.AI
Comments: Accepted to NeurIPS 2025
\\
  Starting from flow- and diffusion-based transformers, Multi-modal Diffusion
Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim
for exceptional visual fidelity. As these models advance, users continually
push the boundary with imaginative or rare prompts, which advanced models still
falter in generating, since their concepts are often too scarce to leave a
strong imprint during pre-training. In this paper, we propose a simple yet
effective intervention that surfaces rare semantics inside MM-DiTs without
additional training steps, data, denoising-time optimization, or reliance on
external modules (e.g., large language models). In particular, the
joint-attention mechanism intrinsic to MM-DiT sequentially updates text
embeddings alongside image embeddings throughout transformer blocks. We find
that by mathematically expanding representational basins around text token
embeddings via variance scale-up before the joint-attention blocks, rare
semantics clearly emerge in MM-DiT's outputs. Furthermore, our results
generalize effectively across text-to-vision tasks, including text-to-image,
text-to-video, and text-driven image editing. Our work invites generative
models to reveal the semantics that users intend, once hidden yet ready to
surface.
\\ ( https://arxiv.org/abs/2510.03886 ,  44458kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03892
Date: Sat, 4 Oct 2025 18:16:12 GMT   (126kb)

Title: Kantian-Utilitarian XAI: Meta-Explained
Authors: Zahra Atf, Peter R. Lewis
Categories: cs.AI cs.CL
Comments: Accepted for presentation as a poster at the 35th IEEE International
  Conference on Collaborative Advances in Software and Computing, 2025.
  Conference
  website:https://conf.researchr.org/details/cascon-2025/posters-track/1/Kantian-Utilitarian-XAI-Meta-Explained
\\
  We present a gamified explainable AI (XAI) system for ethically aware
consumer decision-making in the coffee domain. Each session comprises six
rounds with three options per round. Two symbolic engines provide real-time
reasons: a Kantian module flags rule violations (e.g., child labor,
deforestation risk without shade certification, opaque supply chains, unsafe
decaf), and a utilitarian module scores options via multi-criteria aggregation
over normalized attributes (price, carbon, water, transparency, farmer income
share, taste/freshness, packaging, convenience). A meta-explainer with a regret
bound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a
deontically clean, near-parity option when welfare loss is small. We release a
structured configuration (attribute schema, certification map, weights, rule
set), a policy trace for auditability, and an interactive UI.
\\ ( https://arxiv.org/abs/2510.03892 ,  126kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03969
Date: Sat, 4 Oct 2025 23:00:40 GMT   (409kb)

Title: Quantifying Risks in Multi-turn Conversation with Large Language Models
Authors: Chengxiao Wang, Isha Chaudhary, Qian Hu, Weitong Ruan, Rahul Gupta,
  Gagandeep Singh
Categories: cs.AI cs.CR cs.LG
\\
  Large Language Models (LLMs) can produce catastrophic responses in
conversational settings that pose serious risks to public safety and security.
Existing evaluations often fail to fully reveal these vulnerabilities because
they rely on fixed attack prompt sequences, lack statistical guarantees, and do
not scale to the vast space of multi-turn conversations. In this work, we
propose QRLLM, a novel, principled Certification framework for Catastrophic
risks in multi-turn Conversation for LLMs that bounds the probability of an LLM
generating catastrophic responses under multi-turn conversation distributions
with statistical guarantees. We model multi-turn conversations as probability
distributions over query sequences, represented by a Markov process on a query
graph whose edges encode semantic similarity to capture realistic
conversational flow, and quantify catastrophic risks using confidence
intervals. We define several inexpensive and practical distributions: random
node, graph path, adaptive with rejection. Our results demonstrate that these
distributions can reveal substantial catastrophic risks in frontier models,
with certified lower bounds as high as 70\% for the worst model, highlighting
the urgent need for improved safety training strategies in frontier LLMs.
\\ ( https://arxiv.org/abs/2510.03969 ,  409kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04009
Date: Sun, 5 Oct 2025 03:00:50 GMT   (1316kb)

Title: What Shapes a Creative Machine Mind? Comprehensively Benchmarking
  Creativity in Foundation Models
Authors: Zicong He, Boxuan Zhang, Weihao Liu, Ruixiang Tang and Lu Cheng
Categories: cs.AI cs.CL
Comments: 22 pages
\\
  The meteoric rise of foundation models (FMs) has expanded their capabilities
far beyond conventional tasks. Creativity, long regarded as a hallmark of human
intelligence and a driver of innovation, is now increasingly recognized as a
critical dimension of machine intelligence in the era of generative FMs,
complementing traditional measures of accuracy. However, existing evaluation
frameworks for creativity remain fragmented, relying on ad hoc metrics not
firmly grounded in established theories. To address this gap, we introduce
C^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.
C^2-Eval distinguishes between two complementary forms of creativity:
convergent creativity, where tasks admit constrained solutions (e.g., code
generation), and divergent creativity, where tasks are open-ended (e.g.,
storytelling). It evaluates both dimensions using fine-grained criteria derived
from social-science theory, focusing on Usefulness, Originality, and Surprise
(U-O-S). Through extensive experiments on leading proprietary and open-source
models, we analyze trade-offs in their creative capabilities. Our results
highlight both the strengths and challenges of current FMs in pursuing a
creative machine mind, showing that C^2-Eval is an effective lens for examining
the evolving landscape of creative AI.
\\ ( https://arxiv.org/abs/2510.04009 ,  1316kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04017
Date: Sun, 5 Oct 2025 03:34:08 GMT   (3022kb)

Title: Zephyrus: An Agentic Framework for Weather Science
Authors: Sumanth Varambally, Marshall Fisher, Jas Thakker, Yiwei Chen, Zhirui
  Xia, Yasaman Jafari, Ruijia Niu, Manas Jain, Veeramakali Vignesh Manivannan,
  Zachary Novack, Luyu Han, Srikar Eranky, Salva R\"uhling Cachay, Taylor
  Berg-Kirkpatrick, Duncan Watson-Parris, Yi-An Ma, Rose Yu
Categories: cs.AI cs.LG physics.ao-ph
\\
  Foundation models for weather science are pre-trained on vast amounts of
structured numerical data and outperform traditional weather forecasting
systems. However, these models lack language-based reasoning capabilities,
limiting their utility in interactive scientific workflows. Large language
models (LLMs) excel at understanding and generating text but cannot reason
about high-dimensional meteorological datasets. We bridge this gap by building
a novel agentic framework for weather science. Our framework includes a Python
code-based environment for agents (ZephyrusWorld) to interact with weather
data, featuring tools like an interface to WeatherBench 2 dataset, geoquerying
for geographical masks from natural language, weather forecasting, and climate
simulation capabilities. We design Zephyrus, a multi-turn LLM-based weather
agent that iteratively analyzes weather datasets, observes results, and refines
its approach through conversational feedback loops. We accompany the agent with
a new benchmark, ZephyrusBench, with a scalable data generation pipeline that
constructs diverse question-answer pairs across weather-related tasks, from
basic lookups to advanced forecasting, extreme event detection, and
counterfactual reasoning. Experiments on this benchmark demonstrate the strong
performance of Zephyrus agents over text-only baselines, outperforming them by
up to 35 percentage points in correctness. However, on harder tasks, Zephyrus
performs similarly to text-only baselines, highlighting the challenging nature
of our benchmark and suggesting promising directions for future work.
\\ ( https://arxiv.org/abs/2510.04017 ,  3022kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04023
Date: Sun, 5 Oct 2025 04:04:27 GMT   (225kb)

Title: LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and
  Future Directions
Authors: Mizanur Rahman, Amran Bhuiyan, Mohammed Saidul Islam, Md Tahmid Rahman
  Laskar, Ridwan Mahbub, Ahmed Masry, Shafiq Joty, Enamul Hoque
Categories: cs.AI cs.CL
Comments: Survey paper; 45 data science agents; under review
\\
  Recent advances in large language models (LLMs) have enabled a new class of
AI agents that automate multiple stages of the data science workflow by
integrating planning, tool use, and multimodal reasoning across text, code,
tables, and visuals. This survey presents the first comprehensive,
lifecycle-aligned taxonomy of data science agents, systematically analyzing and
mapping forty-five systems onto the six stages of the end-to-end data science
process: business understanding and data acquisition, exploratory analysis and
visualization, feature engineering, model building and selection,
interpretation and explanation, and deployment and monitoring. In addition to
lifecycle coverage, we annotate each agent along five cross-cutting design
dimensions: reasoning and planning style, modality integration, tool
orchestration depth, learning and alignment methods, and trust, safety, and
governance mechanisms. Beyond classification, we provide a critical synthesis
of agent capabilities, highlight strengths and limitations at each stage, and
review emerging benchmarks and evaluation practices. Our analysis identifies
three key trends: most systems emphasize exploratory analysis, visualization,
and modeling while neglecting business understanding, deployment, and
monitoring; multimodal reasoning and tool orchestration remain unresolved
challenges; and over 90% lack explicit trust and safety mechanisms. We conclude
by outlining open challenges in alignment stability, explainability,
governance, and robust evaluation frameworks, and propose future research
directions to guide the development of robust, trustworthy, low-latency,
transparent, and broadly accessible data science agents.
\\ ( https://arxiv.org/abs/2510.04023 ,  225kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04033
Date: Sun, 5 Oct 2025 04:52:26 GMT   (8468kb)

Title: A global log for medical AI
Authors: Ayush Noori, Adam Rodman, Alan Karthikesalingam, Bilal A. Mateen,
  Christopher A. Longhurst, Daniel Yang, Dave deBronkart, Gauden Galea, Harold
  F. Wolf III, Jacob Waxman, Joshua C. Mandel, Juliana Rotich, Kenneth D.
  Mandl, Maryam Mustafa, Melissa Miles, Nigam H. Shah, Peter Lee, Robert Korom,
  Scott Mahoney, Seth Hain, Tien Yin Wong, Trevor Mundel, Vivek Natarajan, Noa
  Dagan, David A. Clifton, Ran D. Balicer, Isaac S. Kohane, Marinka Zitnik
Categories: cs.AI
\\
  Modern computer systems often rely on syslog, a simple, universal protocol
that records every critical event across heterogeneous infrastructure. However,
healthcare's rapidly growing clinical AI stack has no equivalent. As hospitals
rush to pilot large language models and other AI-based clinical decision
support tools, we still lack a standard way to record how, when, by whom, and
for whom these AI models are used. Without that transparency and visibility, it
is challenging to measure real-world performance and outcomes, detect adverse
events, or correct bias or dataset drift. In the spirit of syslog, we introduce
MedLog, a protocol for event-level logging of clinical AI. Any time an AI model
is invoked to interact with a human, interface with another algorithm, or act
independently, a MedLog record is created. This record consists of nine core
fields: header, model, user, target, inputs, artifacts, outputs, outcomes, and
feedback, providing a structured and consistent record of model activity. To
encourage early adoption, especially in low-resource settings, and minimize the
data footprint, MedLog supports risk-based sampling, lifecycle-aware retention
policies, and write-behind caching; detailed traces for complex, agentic, or
multi-stage workflows can also be captured under MedLog. MedLog can catalyze
the development of new databases and software to store and analyze MedLog
records. Realizing this vision would enable continuous surveillance, auditing,
and iterative improvement of medical AI, laying the foundation for a new form
of digital epidemiology.
\\ ( https://arxiv.org/abs/2510.04033 ,  8468kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04040
Date: Sun, 5 Oct 2025 05:16:54 GMT   (1054kb)

Title: FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of
  Chain-of-Thought Reasoning
Authors: Xu Shen, Song Wang, Zhen Tan, Laura Yao, Xinyu Zhao, Kaidi Xu, Xin
  Wang, Tianlong Chen
Categories: cs.AI
\\
  Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)
prompting to improve problem-solving and provide seemingly transparent
explanations. However, growing evidence shows that CoT often fail to faithfully
represent the underlying reasoning process, raising concerns about their
reliability in high-risk applications. Although prior studies have focused on
mechanism-level analyses showing that CoTs can be unfaithful, they leave open
the practical challenge of deciding whether a specific trajectory is faithful
to the internal reasoning of the model. To address this gap, we introduce
FaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness
detection. Our framework establishes a rigorous task formulation that
formulates unfaithfulness detection as a discriminative decision problem, and
provides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an
expert-annotated collection of over 1,000 trajectories generated by four
representative LLMs across four domains, including more than 300 unfaithful
instances with fine-grained causes and step-level evidence. We further conduct
a systematic evaluation of eleven representative detection methods spanning
counterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical
insights that clarify the strengths and weaknesses of existing approaches and
reveal the increased challenges of detection in knowledge-intensive domains and
with more advanced models. To the best of our knowledge, FaithCoT-Bench
establishes the first comprehensive benchmark for instance-level CoT
faithfulness, setting a solid basis for future research toward more
interpretable and trustworthy reasoning in LLMs.
\\ ( https://arxiv.org/abs/2510.04040 ,  1054kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04048
Date: Sun, 5 Oct 2025 06:02:44 GMT   (4192kb)

Title: Increasing LLM response trustworthiness using voting ensembles
Authors: Aparna Nair-Kanneganti, Trevor J. Chan, Shir Goldfinger, Emily Mackay,
  Brian Anthony, Alison Pouch
Categories: cs.AI
\\
  Despite huge advances, LLMs still lack convenient and reliable methods to
quantify the uncertainty in their responses, making them difficult to trust in
high-stakes applications. One of the simplest approaches to eliciting more
accurate answers is to select the mode of many responses, a technique known as
ensembling. In this work, we expand on typical ensembling approaches by looking
at ensembles with a variable voting threshold. We introduce a theoretical
framework for question answering and show that, by permitting ensembles to
"abstain" from providing an answer when the dominant response falls short of
the threshold, it is possible to dramatically increase the trustworthiness of
the remaining answers. From this framework, we derive theoretical results as
well as report experimental results on two problem domains: arithmetic problem
solving and clinical-note question-answering. In both domains, we observe that
large gains in answer trustworthiness can be achieved using highly restrictive
voting ensembles, while incurring relatively modest reductions in response
yield and accuracy. Due to this quality, voting ensembles may be particularly
useful in applications - such as healthcare and data annotation - that require
a high degree of certainty but which may not require that every question
receive an automated answer.
\\ ( https://arxiv.org/abs/2510.04048 ,  4192kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04051
Date: Sun, 5 Oct 2025 06:13:50 GMT   (4097kb)

Title: Toward a unified framework for data-efficient evaluation of large
  language models
Authors: Lele Liao, Qile Zhang, Ruofan Wu, Guanhua Fang
Categories: cs.AI
Comments: codes available at https://github.com/Rorschach1989/efficient-lm-eval
\\
  Evaluating large language models (LLMs) on comprehensive benchmarks is a
cornerstone of their development, yet it's often computationally and
financially prohibitive. While Item Response Theory (IRT) offers a promising
path toward data-efficient evaluation by disentangling model capability from
item difficulty, existing IRT-based methods are hampered by significant
limitations. They are typically restricted to binary correctness metrics,
failing to natively handle the continuous scores used in generative tasks, and
they operate on single benchmarks, ignoring valuable structural knowledge like
correlations across different metrics or benchmarks. To overcome these
challenges, we introduce LEGO-IRT, a unified and flexible framework for
data-efficient LLM evaluation. LEGO-IRT's novel design natively supports both
binary and continuous evaluation metrics. Moreover, it introduces a factorized
architecture to explicitly model and leverage structural knowledge, decomposing
model ability estimates into a general component and structure-specific (e.g.,
per-metric or per-benchmark) components. Through extensive experiments
involving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves
stable capability estimates using just $3\%$ of the total evaluation items. We
demonstrate that incorporating structural knowledge reduces estimation error by
up to $10\%$ and reveal that the latent abilities estimated by our framework
may align more closely with human preferences.
\\ ( https://arxiv.org/abs/2510.04051 ,  4097kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04064
Date: Sun, 5 Oct 2025 06:53:42 GMT   (2977kb)

Title: Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent,
  Retain, and Express Emotion
Authors: Jingxiang Zhang, Lujia Zhong
Categories: cs.AI
Comments: 10 pages, 7 figures, 4 tables. Under review
\\
  Large Language Models (LLMs) are increasingly expected to navigate the
nuances of human emotion. While research confirms that LLMs can simulate
emotional intelligence, their internal emotional mechanisms remain largely
unexplored. This paper investigates the latent emotional representations within
modern LLMs by asking: how, where, and for how long is emotion encoded in their
neural architecture? To address this, we introduce a novel, large-scale Reddit
corpus of approximately 400,000 utterances, balanced across seven basic
emotions through a multi-stage process of classification, rewriting, and
synthetic generation. Using this dataset, we employ lightweight "probes" to
read out information from the hidden layers of various Qwen3 and LLaMA models
without altering their parameters. Our findings reveal that LLMs develop a
surprisingly well-defined internal geometry of emotion, which sharpens with
model scale and significantly outperforms zero-shot prompting. We demonstrate
that this emotional signal is not a final-layer phenomenon but emerges early
and peaks mid-network. Furthermore, the internal states are both malleable
(they can be influenced by simple system prompts) and persistent, as the
initial emotional tone remains detectable for hundreds of subsequent tokens. We
contribute our dataset, an open-source probing toolkit, and a detailed map of
the emotional landscape within LLMs, offering crucial insights for developing
more transparent and aligned AI systems. The code and dataset are open-sourced.
\\ ( https://arxiv.org/abs/2510.04064 ,  2977kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04073
Date: Sun, 5 Oct 2025 07:24:23 GMT   (12kb)

Title: Moral Anchor System: A Predictive Framework for AI Value Alignment and
  Drift Prevention
Authors: Santhosh Kumar Ravindran
Categories: cs.AI
Comments: 11 pages Includes simulations with over 4 million steps
\\
  The rise of artificial intelligence (AI) as super-capable assistants has
transformed productivity and decision-making across domains. Yet, this
integration raises critical concerns about value alignment - ensuring AI
behaviors remain consistent with human ethics and intentions. A key risk is
value drift, where AI systems deviate from aligned values due to evolving
contexts, learning dynamics, or unintended optimizations, potentially leading
to inefficiencies or ethical breaches. We propose the Moral Anchor System
(MAS), a novel framework to detect, predict, and mitigate value drift in AI
agents. MAS combines real-time Bayesian inference for monitoring value states,
LSTM networks for forecasting drift, and a human-centric governance layer for
adaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent
breaches, while reducing false positives and alert fatigue via supervised
fine-tuning with human feedback. Our hypothesis: integrating probabilistic
drift detection, predictive analytics, and adaptive governance can reduce value
drift incidents by 80 percent or more in simulations, maintaining high
detection accuracy (85 percent) and low false positive rates (0.08
post-adaptation). Rigorous experiments with goal-misaligned agents validate
MAS's scalability and responsiveness. MAS's originality lies in its predictive
and adaptive nature, contrasting static alignment methods. Contributions
include: (1) MAS architecture for AI integration; (2) empirical results
prioritizing speed and usability; (3) cross-domain applicability insights; and
(4) open-source code for replication.
\\ ( https://arxiv.org/abs/2510.04073 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04089
Date: Sun, 5 Oct 2025 08:26:29 GMT   (2081kb)

Title: SPOGW: a Score-based Preference Optimization method via Group-Wise
  comparison for workflows
Authors: Yitong Cui, Liu Liu, Baosheng Yu, Jiayan Qiu, Xikai Zhang, Likang
  Xiao, Yixing Liu, Quan Chen
Categories: cs.AI
\\
  Large language models (LLMs) have exhibited significant capabilities in
addressing challenging problems throughout various fields, often through the
use of agentic workflows that adhere to structured instructions and multi-step
procedures. However, designing such workflows demands substantial manual
effort, posing challenges to scalability and generalizability. Recent studies
have aimed to minimize the human intervention needed for their construction,
leading to advances in automated techniques for optimizing agentic workflows.
However, current approaches are often constrained by their limited
representational capacity, insufficient adaptability, weak scalability, and
pairwise comparison paradigm -- issues that stem primarily from a dependence on
discrete optimization techniques. To overcome these limitations, we introduce a
new score-based preference approach, refereed as SPOGW, which operates directly
on cardinal reward signals through group-wise comparison and enables more
efficient and stable optimization in a continuous space. SPOGW incorporates
Iterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),
which regulates training update by placing greater emphasis on the advantageous
regions of the policy response. In five benchmark datasets covering
mathematical reasoning, coding, and question answering, SPOGW matches or
exceeds the performance of current state-of-the-art approaches, presenting a
viable and forward-looking methodology for automated generation and
optimization of agentic workflows.
\\ ( https://arxiv.org/abs/2510.04089 ,  2081kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04093
Date: Sun, 5 Oct 2025 08:32:30 GMT   (225kb)

Title: Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based
  Intelligent Education Systems
Authors: Guixian Zhang, Guan Yuan, Ziqi Xu, Yanmei Zhang, Zhenyun Deng, Debo
  Cheng
Categories: cs.AI
\\
  Cognitive diagnostics in the Web-based Intelligent Education System (WIES)
aims to assess students' mastery of knowledge concepts from heterogeneous,
noisy interactions. Recent work has tried to utilize Large Language Models
(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are
prone to noise-induced misjudgments. Specially, WIES's open environment
continuously attracts new students and produces vast amounts of response logs,
exacerbating the data imbalance and noise issues inherent in traditional
educational systems. To address these challenges, we propose DLLM, a
Diffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first
constructs independent subgraphs based on response correctness, then applies
relation augmentation alignment module to mitigate data imbalance. The two
subgraph representations are then fused and aligned with LLM-derived,
semantically augmented representations. Importantly, before each alignment
step, DLLM employs a two-stage denoising diffusion module to eliminate
intrinsic noise while assisting structural representation alignment.
Specifically, unconditional denoising diffusion first removes erroneous
information, followed by conditional denoising diffusion based on graph-guided
to eliminate misleading information. Finally, the noise-robust representation
that integrates semantic knowledge and structural information is fed into
existing cognitive diagnosis models for prediction. Experimental results on
three publicly available web-based educational platform datasets demonstrate
that our DLLM achieves optimal predictive performance across varying noise
levels, which demonstrates that DLLM achieves noise robustness while
effectively leveraging semantic knowledge from LLM.
\\ ( https://arxiv.org/abs/2510.04093 ,  225kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04097
Date: Sun, 5 Oct 2025 08:47:39 GMT   (2687kb)

Title: WebRenderBench: Enhancing Web Interface Generation through Layout-Style
  Consistency and Reinforcement Learning
Authors: Peichao Lai, Jinhui Zhuang, Kexuan Zhang, Ningchang Xiong, Shengjie
  Wang, Yanwei Xu, Chong Chen, Yilei Wang, Bin Cui
Categories: cs.AI
\\
  Automating the conversion of UI images into web code is a critical task for
front-end development and rapid prototyping. Advances in multimodal large
language models (MLLMs) have made WebUI-to-Code increasingly feasible, yet
existing benchmarks remain limited in data diversity and evaluation
reliability. To address these issues, we present WebRenderBench, a large-scale
benchmark of 22.5k webpages collected from real-world portal sites, offering
greater diversity, complexity, and realism than prior benchmarks. We further
propose a novel evaluation metric that measures layout and style consistency
from the final rendered pages. Unlike vision-based methods that rely on costly
LLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,
our approach enables more efficient, objective, and reliable UI quality
assessment. Finally, we introduce the Automated Layout and Style Inspection
Agent (ALISA), which integrates this metric into reinforcement learning as a
reward signal to enhance training on crawled asymmetric webpages. Experiments
show that ALISA significantly boosts generation performance, achieving
state-of-the-art results across multiple metrics.
\\ ( https://arxiv.org/abs/2510.04097 ,  2687kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04116
Date: Sun, 5 Oct 2025 09:36:26 GMT   (714kb)

Title: Searching Meta Reasoning Skeleton to Guide LLM Reasoning
Authors: Ziying Zhang, Yaqing Wang, Quanming Yao
Categories: cs.AI
\\
  Meta reasoning behaviors work as a skeleton to guide large language model
(LLM) reasoning, thus help to improve reasoning performance. However, prior
researches implement meta reasoning skeleton with manually designed structure,
limiting ability to adapt to query-specific requirement and capture intricate
logical dependency among reasoning steps. To deal with the challenges, we
represent meta reasoning skeleton with directed acyclic graph (DAG) to unify
skeletons proposed in prior works and model intricate logical dependency. Then
we propose AutoMR, a framework that searches for query-aware meta reasoning
skeleton automatically inspired by automated machine learning (AutoML).
Specifically, we construct search space based on DAG representation of skeleton
and then formulate the search problem. We design a dynamic skeleton sampling
algorithm by expanding meta reasoning skeleton along with reasoning context at
inference time. This algorithm can derive any meta reasoning skeleton in search
space efficiently and adapt skeleton to evolving base reasoning context, thus
enable efficient query-aware skeleton search. We conduct experiments on
extensive benchmark datasets. Experimental results show that AutoMR achieves
better reasoning performance than previous works broadly.
\\ ( https://arxiv.org/abs/2510.04116 ,  714kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04128
Date: Sun, 5 Oct 2025 10:03:42 GMT   (814kb)

Title: Internal states before wait modulate reasoning patterns
Authors: Dmitrii Troitskii, Koyena Pal, Chris Wendler, Callum Stuart McDougall,
  Neel Nanda
Categories: cs.AI cs.CL
Comments: Accepted to EMNLP Findings 2025
\\
  Prior work has shown that a significant driver of performance in reasoning
models is their ability to reason and self-correct. A distinctive marker in
these reasoning traces is the token wait, which often signals reasoning
behavior such as backtracking. Despite being such a complex behavior, little is
understood of exactly why models do or do not decide to reason in this
particular manner, which limits our understanding of what makes a reasoning
model so effective. In this work, we address the question whether model's
latents preceding wait tokens contain relevant information for modulating the
subsequent reasoning process. We train crosscoders at multiple layers of
DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent
attribution technique in the crosscoder setting. We locate a small set of
features relevant for promoting/suppressing wait tokens' probabilities.
Finally, through a targeted series of experiments analyzing max activating
examples and causal interventions, we show that many of our identified features
indeed are relevant for the reasoning process and give rise to different types
of reasoning patterns such as restarting from the beginning, recalling prior
knowledge, expressing uncertainty, and double-checking.
\\ ( https://arxiv.org/abs/2510.04128 ,  814kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04140
Date: Sun, 5 Oct 2025 10:38:55 GMT   (206kb)

Title: Selective Expert Guidance for Effective and Diverse Exploration in
  Reinforcement Learning of LLMs
Authors: Zishang Jiang, Jinyi Han, Tingyun Li, Xinyi Wang, Sihang Jiang,
  Jiaqing Liang, Zhaoqian Dai, Shuguang Ma, Fei Yu, Yanghua Xiao
Categories: cs.AI cs.CL
\\
  Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely
adopted technique for enhancing the reasoning ability of Large Language Models
(LLMs). However, the effectiveness of RLVR strongly depends on the capability
of base models. This issue arises because it requires the model to have
sufficient capability to perform high-quality exploration, which involves both
effectiveness and diversity. Unfortunately, existing methods address this issue
by imitating expert trajectories, which improve effectiveness but neglect
diversity. To address this, we argue that the expert only needs to provide
guidance only at critical decision points rather than the entire reasoning
path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation
for Token-level Optimization of Reasoning, a framework that provides expert
guidance only at critical decision points to perform effective and diverse
exploration in RLVR. Extensive experiments show that MENTOR enables models
capture the essence of expert strategies rather than surface imitation, thereby
performing high-quality exploration and achieving superior overall performance.
Our code is available online.
\\ ( https://arxiv.org/abs/2510.04140 ,  206kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04141
Date: Sun, 5 Oct 2025 10:41:22 GMT   (84kb)

Title: The Artificial Intelligence Cognitive Examination: A Survey on the
  Evolution of Multimodal Evaluation from Recognition to Reasoning
Authors: Mayank Ravishankara, Varindra V. Persad Maharaj
Categories: cs.AI
\\
  This survey paper chronicles the evolution of evaluation in multimodal
artificial intelligence (AI), framing it as a progression of increasingly
sophisticated "cognitive examinations." We argue that the field is undergoing a
paradigm shift, moving from simple recognition tasks that test "what" a model
sees, to complex reasoning benchmarks that probe "why" and "how" it
understands. This evolution is driven by the saturation of older benchmarks,
where high performance often masks fundamental weaknesses. We chart the journey
from the foundational "knowledge tests" of the ImageNet era to the "applied
logic and comprehension" exams such as GQA and Visual Commonsense Reasoning
(VCR), which were designed specifically to diagnose systemic flaws such as
shortcut learning and failures in compositional generalization. We then survey
the current frontier of "expert-level integration" benchmarks (e.g., MMBench,
SEED-Bench, MMMU) designed for today's powerful multimodal large language
models (MLLMs), which increasingly evaluate the reasoning process itself.
Finally, we explore the uncharted territories of evaluating abstract, creative,
and social intelligence. We conclude that the narrative of AI evaluation is not
merely a history of datasets, but a continuous, adversarial process of
designing better examinations that, in turn, redefine our goals for creating
truly intelligent systems.
\\ ( https://arxiv.org/abs/2510.04141 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04173
Date: Sun, 5 Oct 2025 12:26:42 GMT   (525kb)

Title: Open Agent Specification (Agent Spec) Technical Report
Authors: Yassine Benajiba, Cesare Bernardis, Vladislav Blinov, Paul Cayet,
  Hassan Chafi, Abderrahim Fathan, Louis Faucon, Damien Hilloulin, Sungpack
  Hong, Ingo Kossyk, Rhicheek Patra, Sujith Ravi, Jonas Schweizer, Jyotika
  Singh, Shailender Singh, Xuelin Situ, Weiyi Sun, Jerry Xu, Ying Xu
Categories: cs.AI
\\
  Open Agent Specification (Agent Spec) is a declarative language that allows
AI agents and their workflows to be defined in a way that is compatible across
different AI frameworks, promoting portability and interoperability within AI
Agent frameworks.
  Agent Spec aims to resolve the challenges of fragmented agent development by
providing a common unified specification that allows AI agents to be designed
once and deployed across various frameworks, improving interoperability and
reusability, and reducing redundant development efforts. Additionally, Agent
Spec facilitates development tools and portability, allowing AI agents to be
defined independently of their execution environment and enabling teams to
exchange solutions without implementation-specific limitations.
  Agent Spec benefits four key groups: (i) Agent developers, who gain access to
a superset of reusable components and design patterns, enabling them to
leverage a broader range of functionalities; (ii) Agent framework and tool
developers, who can use Agent Spec as an interchange format and therefore
benefit from the support of other frameworks as well as other tools; (iii)
Researchers, who can achieve reproducible results and comparability,
facilitating more reliable and consistent outcomes; (iv) Enterprises, which
benefit from faster prototype-to-deployment, increased productivity, as well as
greater scalability and maintainability for their AI agent solutions. This
technical report provides an overview of the technical foundations of Agent
Spec, including motivation, benefits, and future developments.
\\ ( https://arxiv.org/abs/2510.04173 ,  525kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04195
Date: Sun, 5 Oct 2025 13:27:00 GMT   (1368kb)

Title: Constructing coherent spatial memory in LLM agents through graph
  rectification
Authors: Puzhen Zhang, Xuyang Chen, Yu Feng, Yuhan Jiang, Liqiu Meng
Categories: cs.AI
\\
  Given a map description through global traversal navigation instructions
(e.g., visiting each room sequentially with action signals such as north, west,
etc.), an LLM can often infer the implicit spatial layout of the environment
and answer user queries by providing a shortest path from a start to a
destination (for instance, navigating from the lobby to a meeting room via the
hall and elevator). However, such context-dependent querying becomes incapable
as the environment grows much longer, motivating the need for incremental map
construction that builds a complete topological graph from stepwise
observations. We propose a framework for LLM-driven construction and map
repair, designed to detect, localize, and correct structural inconsistencies in
incrementally constructed navigation graphs. Central to our method is the
Version Control, which records the full history of graph edits and their source
observations, enabling fine-grained rollback, conflict tracing, and repair
evaluation. We further introduce an Edge Impact Score to prioritize
minimal-cost repairs based on structural reachability, path usage, and conflict
propagation. To properly evaluate our approach, we create a refined version of
the MANGO benchmark dataset by systematically removing non-topological actions
and inherent structural conflicts, providing a cleaner testbed for LLM-driven
construction and map repair. Our approach significantly improves map
correctness and robustness, especially in scenarios with entangled or chained
inconsistencies. Our results highlight the importance of introspective,
history-aware repair mechanisms for maintaining coherent spatial memory in LLM
agents.
\\ ( https://arxiv.org/abs/2510.04195 ,  1368kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04196
Date: Sun, 5 Oct 2025 13:30:03 GMT   (1331kb)

Title: COSMO-RL: Towards Trustworthy LMRMs via Joint Safety and Stability
Authors: Yizhuo Ding, Mingkang Chen, Qiuhua Liu, Fenghua Weng, Wanying Qu, Yue
  Yang, Yugang Jiang, Zuxuan Wu, Yanwei Fu, Wenqi Shao
Categories: cs.AI cs.LG
\\
  Large Multimodal Reasoning Models (LMRMs) are moving into real applications,
where they must be both useful and safe. Safety is especially challenging in
multimodal settings: images and text can be combined to bypass guardrails, and
single objective training can cause policy drift that yields over-refusal on
benign inputs or unsafe compliance on risky ones. We present COSMO-RL, a mixed
reinforcement learning framework that trains reasoning oriented LMRMs under
multimodal, multitask, and multiobjective signals, and we release the resulting
model, COSMO-R1. Our approach aims to let safety and capability grow together
in one stable pipeline rather than competing during alignment. In experiments,
COSMO-R1 improves safety while maintaining-and often improving multimodal
reasoning and instruction following, shows stronger robustness to multimodal
jailbreaks, and reduces unnecessary refusals. The framework also transfers
across backbones with consistent gains. Ablations support the design choices,
indicating a simple path to advancing safety and general capability together in
LMRMs.
\\ ( https://arxiv.org/abs/2510.04196 ,  1331kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04206
Date: Sun, 5 Oct 2025 13:40:01 GMT   (1031kb)

Title: AgentRL: Scaling Agentic Reinforcement Learning with a Multi-Turn,
  Multi-Task Framework
Authors: Hanchen Zhang, Xiao Liu, Bowen Lv, Xueqiao Sun, Bohao Jing, Iat Long
  Iong, Zhenyu Hou, Zehan Qi, Hanyu Lai, Yifan Xu, Rui Lu, Hongning Wang, Jie
  Tang, Yuxiao Dong
Categories: cs.AI
\\
  Recent advances in large language models (LLMs) have sparked growing interest
in building generalist agents that can learn through online interactions.
However, applying reinforcement learning (RL) to train LLM agents in
multi-turn, multi-task settings remains challenging due to lack of scalable
infrastructure and stable training algorithms. In this work, we present the
AgentRL framework for scalable multi-turn, multi-task agentic RL training. On
the infrastructure side, AgentRL features a fully-asynchronous
generation-training pipeline for efficient multi-turn RL. To support
heterogeneous environment development in multi-task RL, we design a unified
function-call based API interface, containerized environment development, and a
centralized controller. On the algorithm side, we propose cross-policy sampling
to encourage model exploration in multi-turn settings and task advantage
normalization to stabilize multi-task training. Experiments show that AgentRL,
trained on open LLMs across five agentic tasks, significantly outperforms
GPT-5, Clause-Sonnet-4, DeepSeek-R1, and other open-source LLM agents.
Multi-task training with AgentRL matches the best results among all
task-specific models. AgentRL is open-sourced at
https://github.com/THUDM/AgentRL. The algorithm and framework are adopted in
building \textsc{\href{https://autoglm.zhipuai.cn}{AutoGLM}}.
\\ ( https://arxiv.org/abs/2510.04206 ,  1031kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04265
Date: Sun, 5 Oct 2025 16:14:03 GMT   (1378kb)

Title: Don't Pass$\mathtt{@}k$: A Bayesian Framework for Large Language Model
  Evaluation
Authors: Mohsen Hariri, Amirhossein Samandar, Michael Hinczewski, Vipin
  Chaudhary
Categories: cs.AI cs.CL math.ST stat.ML stat.TH
Comments: Code and simulations: https://mohsenhariri.github.io/bayes-kit
\\
  Pass$@k$ is widely used to report performance for LLM reasoning, but it often
yields unstable, misleading rankings, especially when the number of trials
(samples) is limited and compute is constrained. We present a principled
Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over
$N$ trials (avg$@N$) with posterior estimates of a model's underlying success
probability and credible intervals, yielding stable rankings and a transparent
decision rule for differences. Evaluation outcomes are modeled as categorical
(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the
posterior mean and uncertainty of any weighted rubric and enabling the use of
prior evidence when appropriate. Theoretically, under a uniform prior, the
Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),
explaining its empirical robustness while adding principled uncertainty.
Empirically, in simulations with known ground-truth success rates and on
AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster
convergence and greater rank stability than Pass$@k$ and recent variants,
enabling reliable comparisons at far smaller sample counts. The framework
clarifies when observed gaps are statistically meaningful (non-overlapping
credible intervals) versus noise, and it naturally extends to graded,
rubric-based evaluations. Together, these results recommend replacing Pass$@k$
for LLM evaluation and ranking with a posterior-based, compute-efficient
protocol that unifies binary and non-binary evaluation while making uncertainty
explicit. Code is available at https://mohsenhariri.github.io/bayes-kit
\\ ( https://arxiv.org/abs/2510.04265 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04272
Date: Sun, 5 Oct 2025 16:28:06 GMT   (3996kb)

Title: Closing the Loop: Coordinating Inventory and Recommendation via Deep
  Reinforcement Learning on Multiple Timescales
Authors: Jinyang Jiang, Jinhui Han, Yijie Peng, Ying Zhang
Categories: cs.AI cs.LG math.OC
\\
  Effective cross-functional coordination is essential for enhancing firm-wide
profitability, particularly in the face of growing organizational complexity
and scale. Recent advances in artificial intelligence, especially in
reinforcement learning (RL), offer promising avenues to address this
fundamental challenge. This paper proposes a unified multi-agent RL framework
tailored for joint optimization across distinct functional modules, exemplified
via coordinating inventory replenishment and personalized product
recommendation. We first develop an integrated theoretical model to capture the
intricate interplay between these functions and derive analytical benchmarks
that characterize optimal coordination. The analysis reveals synchronized
adjustment patterns across products and over time, highlighting the importance
of coordinated decision-making. Leveraging these insights, we design a novel
multi-timescale multi-agent RL architecture that decomposes policy components
according to departmental functions and assigns distinct learning speeds based
on task complexity and responsiveness. Our model-free multi-agent design
improves scalability and deployment flexibility, while multi-timescale updates
enhance convergence stability and adaptability across heterogeneous decisions.
We further establish the asymptotic convergence of the proposed algorithm.
Extensive simulation experiments demonstrate that the proposed approach
significantly improves profitability relative to siloed decision-making
frameworks, while the behaviors of the trained RL agents align closely with the
managerial insights from our theoretical model. Taken together, this work
provides a scalable, interpretable RL-based solution to enable effective
cross-functional coordination in complex business settings.
\\ ( https://arxiv.org/abs/2510.04272 ,  3996kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04281
Date: Sun, 5 Oct 2025 16:46:29 GMT   (3392kb)

Title: GROK: From Quantitative Biomarkers to Qualitative Diagnosis via a
  Grounded MLLM with Knowledge-Guided Instruction
Authors: Zhuangzhi Gao, Hongyi Qin, He Zhao, Qinkai Yu, Feixiang Zhou, Eduard
  Shantsila, Uazman Alam, Alena Shantsila, Wahbi El-Bouri, Gregory Y. H. Lip,
  and Yalin Zheng
Categories: cs.AI
Comments: 9 pages, 4 figures, 3 table. Equal contribution: Zhuangzhi Gao and
  Hongyi Qin. Corresponding author: Yalin Zheng (yzheng@liverpool.ac.uk)
\\
  Multimodal large language models (MLLMs) hold promise for integrating diverse
data modalities, but current medical adaptations such as LLaVA-Med often fail
to fully exploit the synergy between color fundus photography (CFP) and optical
coherence tomography (OCT), and offer limited interpretability of quantitative
biomarkers. We introduce GROK, a grounded multimodal large language model that
jointly processes CFP, OCT, and text to deliver clinician-grade diagnoses of
ocular and systemic disease. GROK comprises three core modules:
Knowledge-Guided Instruction Generation, CLIP-Style OCT-Biomarker Alignment,
and Supervised Instruction Fine-Tuning, which together establish a
quantitative-to-qualitative diagnostic chain of thought, mirroring real
clinical reasoning when producing detailed lesion annotations. To evaluate our
approach, we introduce the Grounded Ophthalmic Understanding benchmark, which
covers six disease categories and three tasks: macro-level diagnostic
classification, report generation quality, and fine-grained clinical assessment
of the generated chain of thought. Experiments show that, with only LoRA
(Low-Rank Adaptation) fine-tuning of a 7B-parameter Qwen2 backbone, GROK
outperforms comparable 7B and 32B baselines on both report quality and
fine-grained clinical metrics, and even exceeds OpenAI o3. Code and data are
publicly available in the GROK repository.
\\ ( https://arxiv.org/abs/2510.04281 ,  3392kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04284
Date: Sun, 5 Oct 2025 16:54:02 GMT   (1398kb)

Title: Doctor-R1: Mastering Clinical Inquiry with Experiential Agentic
  Reinforcement Learning
Authors: Yunghwei Lai, Kaiming Liu, Ziyue Wang, Weizhi Ma, Yang Liu
Categories: cs.AI
\\
  The professionalism of a human doctor in outpatient service depends on two
core abilities: the ability to make accurate medical decisions and the medical
consultation skill to conduct strategic, empathetic patient inquiry. Existing
Large Language Models (LLMs) have achieved remarkable accuracy on medical
decision-making benchmarks. However, they often lack the ability to conduct the
strategic and empathetic consultation, which is essential for real-world
clinical scenarios. To address this gap, we propose Doctor-R1, an AI doctor
agent trained to master both of the capabilities by ask high-yield questions
and conduct strategic multi-turn inquiry to guide decision-making. Our
framework introduces three key components: a multi-agent interactive
environment, a two-tiered reward architecture that separately optimizes
clinical decision-making and communicative inquiry skills, and an experience
repository to ground policy learning in high-quality prior trajectories. We
evaluate Doctor-R1 on OpenAI's HealthBench and MAQuE, assessed across
multi-facet metrics, such as communication quality, user experience, and task
accuracy. Remarkably, Doctor-R1 surpasses state-of-the-art open-source
specialized LLMs by a substantial margin with higher parameter efficiency and
outperforms powerful proprietary models. Furthermore, the human evaluations
show a strong preference for Doctor-R1 to generate human-preferred clinical
dialogue, demonstrating the effectiveness of the framework.
\\ ( https://arxiv.org/abs/2510.04284 ,  1398kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04311
Date: Sun, 5 Oct 2025 18:08:48 GMT   (3383kb)

Title: On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent
  Systems
Authors: Bohan Tang, Huidong Liang, Keyue Jiang, Xiaowen Dong
Categories: cs.AI cs.LG
\\
  Large language model multi-agent systems (LLM-MAS) offer a promising paradigm
for harnessing collective intelligence to achieve more advanced forms of AI
behaviour. While recent studies suggest that LLM-MAS can outperform LLM
single-agent systems (LLM-SAS) on certain tasks, the lack of systematic
experimental designs limits the strength and generality of these conclusions.
We argue that a principled understanding of task complexity, such as the degree
of sequential reasoning required and the breadth of capabilities involved, is
essential for assessing the effectiveness of LLM-MAS in task solving. To this
end, we propose a theoretical framework characterising tasks along two
dimensions: depth, representing reasoning length, and width, representing
capability diversity. We theoretically examine a representative class of
LLM-MAS, namely the multi-agent debate system, and empirically evaluate its
performance in both discriminative and generative tasks with varying depth and
width. Theoretical and empirical results show that the benefit of LLM-MAS over
LLM-SAS increases with both task depth and width, and the effect is more
pronounced with respect to depth. This clarifies when LLM-MAS are beneficial
and provides a principled foundation for designing future LLM-MAS methods and
benchmarks.
\\ ( https://arxiv.org/abs/2510.04311 ,  3383kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04371
Date: Sun, 5 Oct 2025 21:28:11 GMT   (515kb)

Title: Speculative Actions: A Lossless Framework for Faster Agentic Systems
Authors: Naimeng Ye, Arnav Ahuja, Georgios Liargkovas, Yunan Lu, Kostis Kaffes,
  Tianyi Peng
Categories: cs.AI cs.DC cs.MA
\\
  Despite growing interest in AI agents across industry and academia, their
execution in an environment is often slow, hampering training, evaluation, and
deployment. For example, a game of chess between two state-of-the-art agents
may take hours. A critical bottleneck is that agent behavior unfolds
sequentially: each action requires an API call, and these calls can be
time-consuming. Inspired by speculative execution in microprocessors and
speculative decoding in LLM inference, we propose speculative actions, a
lossless framework for general agentic systems that predicts likely actions
using faster models, enabling multiple steps to be executed in parallel. We
evaluate this framework across three agentic environments: gaming, e-commerce,
web search, and a "lossy" extension for an operating systems environment. In
all cases, speculative actions achieve substantial accuracy in next-action
prediction (up to 55%), translating into significant reductions in end-to-end
latency. Moreover, performance can be further improved through stronger
guessing models, top-K action prediction, multi-step speculation, and
uncertainty-aware optimization, opening a promising path toward deploying
low-latency agentic systems in the real world.
\\ ( https://arxiv.org/abs/2510.04371 ,  515kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04373
Date: Sun, 5 Oct 2025 21:34:42 GMT   (1719kb)

Title: Just-in-time Episodic Feedback Hinter: Leveraging Offline Knowledge to
  Improve LLM Agents Adaptation
Authors: Hadi Nekoei, Aman Jaiswal, Patrice Bechard, Oleh Shliazhko, Orlando
  Marquez Ayala, Mathieu Reymond, Massimo Caccia, Alexandre Drouin, Sarath
  Chandar, Alexandre Lacoste
Categories: cs.AI
\\
  Large language model (LLM) agents perform well in sequential decision-making
tasks, but improving them on unfamiliar domains often requires costly online
interactions or fine-tuning on large expert datasets. These strategies are
impractical for closed-source models and expensive for open-source ones, with
risks of catastrophic forgetting. Offline trajectories offer reusable
knowledge, yet demonstration-based methods struggle because raw traces are
long, noisy, and tied to specific tasks. We present Just-in-time Episodic
Feedback Hinter (JEF Hinter), an agentic system that distills offline traces
into compact, context-aware hints. A zooming mechanism highlights decisive
steps in long trajectories, capturing both strategies and pitfalls. Unlike
prior methods, JEF Hinter leverages both successful and failed trajectories,
extracting guidance even when only failure data is available, while supporting
parallelized hint generation and benchmark-independent prompting. At inference,
a retriever selects relevant hints for the current state, providing targeted
guidance with transparency and traceability. Experiments on MiniWoB++,
WorkArena-L1, and WebArena-Lite show that JEF Hinter consistently outperforms
strong baselines, including human- and document-based hints.
\\ ( https://arxiv.org/abs/2510.04373 ,  1719kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04384
Date: Sun, 5 Oct 2025 22:32:50 GMT   (419kb)

Title: LLM Based Bayesian Optimization for Prompt Search
Authors: Adam Ballew, Jingbo Wang, Shaogang Ren
Categories: cs.AI
\\
  Bayesian Optimization (BO) has been widely used to efficiently optimize
expensive black-box functions with limited evaluations. In this paper, we
investigate the use of BO for prompt engineering to enhance text classification
with Large Language Models (LLMs). We employ an LLM-powered Gaussian Process
(GP) as the surrogate model to estimate the performance of different prompt
candidates. These candidates are generated by an LLM through the expansion of a
set of seed prompts and are subsequently evaluated using an Upper Confidence
Bound (UCB) acquisition function in conjunction with the GP posterior. The
optimization process iteratively refines the prompts based on a subset of the
data, aiming to improve classification accuracy while reducing the number of
API calls by leveraging the prediction uncertainty of the LLM-based GP. The
proposed BO-LLM algorithm is evaluated on two datasets, and its advantages are
discussed in detail in this paper.
\\ ( https://arxiv.org/abs/2510.04384 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04391
Date: Sun, 5 Oct 2025 23:01:10 GMT   (6628kb)

Title: Internal World Models as Imagination Networks in Cognitive Agents
Authors: Saurabh Ranjan and Brian Odegaard
Categories: cs.AI cs.CL cs.SI q-bio.NC
\\
  What is the computational objective of imagination? While classical
interpretations suggest imagination is useful for maximizing rewards, recent
findings challenge this view. In this study, we propose that imagination serves
to access an internal world model (IWM) and use psychological network analysis
to explore IWMs in humans and large language models (LLMs). Specifically, we
assessed imagination vividness ratings using two questionnaires and constructed
imagination networks from these reports. Imagination networks from human groups
showed correlations between different centrality measures, including expected
influence, strength, and closeness. However, imagination networks from LLMs
showed a lack of clustering and lower correlations between centrality measures
under different prompts and conversational memory conditions. Together, these
results indicate a lack of similarity between IWMs in human and LLM agents.
Overall, our study offers a novel method for comparing internally-generated
representations in humans and AI, providing insights for developing human-like
imagination in artificial intelligence.
\\ ( https://arxiv.org/abs/2510.04391 ,  6628kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04399
Date: Sun, 5 Oct 2025 23:52:16 GMT   (576kb)

Title: Utility-Learning Tension in Self-Modifying Agents
Authors: Charles L. Wang, Keir Dorchen, Peter Jin
Categories: cs.AI cs.LG
\\
  As systems trend toward superintelligence, a natural modeling premise is that
agents can self-improve along every facet of their own design. We formalize
this with a five-axis decomposition and a decision layer, separating incentives
from learning behavior and analyzing axes in isolation. Our central result
identifies and introduces a sharp utility--learning tension, the structural
conflict in self-modifying systems whereby utility-driven changes that improve
immediate or expected performance can also erode the statistical preconditions
for reliable learning and generalization. Our findings show that
distribution-free guarantees are preserved iff the policy-reachable model
family is uniformly capacity-bounded; when capacity can grow without limit,
utility-rational self-changes can render learnable tasks unlearnable. Under
standard assumptions common in practice, these axes reduce to the same capacity
criterion, yielding a single boundary for safe self-modification. Numerical
experiments across several axes validate the theory by comparing destructive
utility policies against our proposed two-gate policies that preserve
learnability.
\\ ( https://arxiv.org/abs/2510.04399 ,  576kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04474
Date: Mon, 6 Oct 2025 04:18:13 GMT   (482kb)

Title: DRPO: Efficient Reasoning via Decoupled Reward Policy Optimization
Authors: Gang Li, Yan Chen, Ming Lin, Tianbao Yang
Categories: cs.AI cs.LG
Comments: 20 pages, 7 figures
\\
  Recent large reasoning models (LRMs) driven by reinforcement learning
algorithms (e.g., GRPO) have achieved remarkable performance on challenging
reasoning tasks. However, these models suffer from overthinking, generating
unnecessarily long and redundant reasoning even for simple questions, which
substantially increases computational cost and response latency. While existing
methods incorporate length rewards to GRPO to promote concise reasoning, they
incur significant performance degradation. We identify the root cause: when
rewards for correct but long rollouts are penalized, GRPO's group-relative
advantage function can assign them negative advantages, actively discouraging
valid reasoning. To overcome this, we propose Decoupled Reward Policy
Optimization (DRPO), a novel framework that decouples the length-based learning
signal of correct rollouts from incorrect ones. DRPO ensures that reward
signals for correct rollouts are normalized solely within the positive group,
shielding them from interference by negative samples. The DRPO's objective is
grounded in integrating an optimized positive data distribution, which
maximizes length-based rewards under a KL regularization, into a discriminative
objective. We derive a closed-form solution for this distribution, enabling
efficient computation of the objective and its gradients using only on-policy
data and importance weighting. Of independent interest, this formulation is
general and can incorporate other preference rewards of positive data beyond
length. Experiments on mathematical reasoning tasks demonstrate DRPO's
significant superiority over six efficient reasoning baselines. Notably, with a
1.5B model, our method achieves 77\% length reduction with only 1.1\%
performance loss on simple questions like GSM8k dataset, while the follow-up
baseline sacrifices 4.3\% for 68\% length reduction.
\\ ( https://arxiv.org/abs/2510.04474 ,  482kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04480
Date: Mon, 6 Oct 2025 04:30:07 GMT   (2052kb)

Title: On Continuous Optimization for Constraint Satisfaction Problems
Authors: Yunuo Cen, Zixuan Wang, Jintao Zhang, Zhiwei Zhang, Xuanyao Fong
Categories: cs.AI
\\
  Constraint satisfaction problems (CSPs) are fundamental in mathematics,
physics, and theoretical computer science. While conflict-driven clause
learning Boolean Satisfiability (SAT) solvers have achieved remarkable success
and become the mainstream approach for Boolean satisfiability, recent advances
show that modern continuous local search (CLS) solvers can achieve highly
competitive results on certain classes of SAT problems. Motivated by these
advances, we extend the CLS framework from Boolean SAT to general CSP with
finite-domain variables and expressive constraints. We present FourierCSP, a
continuous optimization framework that generalizes the Walsh-Fourier transform
to CSP, allowing for transforming versatile constraints to compact multilinear
polynomials, thereby avoiding the need for auxiliary variables and
memory-intensive encodings. Our approach leverages efficient evaluation and
differentiation of the objective via circuit-output probability and employs a
projected gradient optimization method with theoretical guarantees. Empirical
results on benchmark suites demonstrate that FourierCSP is scalable and
competitive, significantly broadening the class of problems that can be
efficiently solved by CLS techniques.
\\ ( https://arxiv.org/abs/2510.04480 ,  2052kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04488
Date: Mon, 6 Oct 2025 04:52:17 GMT   (1114kb)

Title: Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable
  LLM Reasoning
Authors: Edward Y. Chang, Ethan Y. Chang
Categories: cs.AI cs.IT math.IT
Comments: 27 pages, 5 figures, 21 tables
ACM-class: I.2.4
\\
  Multi-agent debate often wastes compute by using a fixed adversarial stance,
aggregating without deliberation, or stopping on heuristics. We introduce MACI,
an active controller with two independent dials that decouple information from
behavior: an information dial that gates evidence by quality, and a behavior
dial that schedules contentiousness from exploration to consolidation. A
moderator tracks disagreement, overlap, evidence quality, and argument quality,
and halts when gains plateau. We provide theory-lite guarantees for
nonincreasing dispersion and provable termination, with a budget-feasible
scheduler. Across clinical diagnosis and news-bias tasks, MACI improves
accuracy and calibration while reducing tokens, and converts residual
uncertainty into precision RAG plans that specify what to retrieve next. We use
a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal,
validated for order invariance and judge-swap stability; stability depends on
using high-capability judges. MACI turns debate into a budget-aware,
measurable, and provably terminating controller.
\\ ( https://arxiv.org/abs/2510.04488 ,  1114kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04491
Date: Mon, 6 Oct 2025 05:03:57 GMT   (1236kb)

Title: Impatient Users Confuse AI Agents: High-fidelity Simulations of Human
  Traits for Testing Agents
Authors: Muyu He, Anand Kumar, Tsach Mackey, Meghana Rajeev, James Zou, Nazneen
  Rajani
Categories: cs.AI cs.CL
Comments: 25 pages
\\
  Despite rapid progress in building conversational AI agents, robustness is
still largely untested. Small shifts in user behavior, such as being more
impatient, incoherent, or skeptical, can cause sharp drops in agent
performance, revealing how brittle current AI agents are. Today's benchmarks
fail to capture this fragility: agents may perform well under standard
evaluations but degrade spectacularly in more realistic and varied settings. We
address this robustness testing gap by introducing TraitBasis, a lightweight,
model-agnostic method for systematically stress testing AI agents. TraitBasis
learns directions in activation space corresponding to steerable user traits
(e.g., impatience or incoherence), which can be controlled, scaled, composed,
and applied at inference time without any fine-tuning or extra data. Using
TraitBasis, we extend $\tau$-Bench to $\tau$-Trait, where user behaviors are
altered via controlled trait vectors. We observe on average a 2%-30%
performance degradation on $\tau$-Trait across frontier models, highlighting
the lack of robustness of current AI agents to variations in user behavior.
Together, these results highlight both the critical role of robustness testing
and the promise of TraitBasis as a simple, data-efficient, and compositional
tool. By powering simulation-driven stress tests and training loops, TraitBasis
opens the door to building AI agents that remain reliable in the unpredictable
dynamics of real-world human interactions. We have open-sourced $\tau$-Trai
across four domains: airline, retail, telecom, and telehealth, so the community
can systematically QA their agents under realistic, behaviorally diverse
intents and trait scenarios: https://github.com/collinear-ai/tau-trait.
\\ ( https://arxiv.org/abs/2510.04491 ,  1236kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04514
Date: Mon, 6 Oct 2025 06:05:36 GMT   (17733kb)

Title: ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in
  Complex Chart Question Answering
Authors: Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Sumitra Ganesh, Manuela
  Veloso
Categories: cs.AI cs.CE cs.CL cs.CV stat.ME
Comments: 53 pages, 12 figures, 15 tables
\\
  Recent multimodal LLMs have shown promise in chart-based visual question
answering, but their performance declines sharply on unannotated charts, those
requiring precise visual interpretation rather than relying on textual
shortcuts. To address this, we introduce ChartAgent, a novel agentic framework
that explicitly performs visual reasoning directly within the chart's spatial
domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively
decomposes queries into visual subtasks and actively manipulates and interacts
with chart images through specialized actions such as drawing annotations,
cropping regions (e.g., segmenting pie slices, isolating bars), and localizing
axes, using a library of chart-specific vision tools to fulfill each subtask.
This iterative reasoning process closely mirrors human cognitive strategies for
chart comprehension. ChartAgent achieves state-of-the-art accuracy on the
ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%
absolute gain overall and 17.31% on unannotated, numerically intensive queries.
Furthermore, our analyses show that ChartAgent is (a) effective across diverse
chart types, (b) achieve the highest scores across varying visual and reasoning
complexity levels, and (c) serves as a plug-and-play framework that boosts
performance across diverse underlying LLMs. Our work is among the first to
demonstrate visually grounded reasoning for chart understanding using
tool-augmented multimodal agents.
\\ ( https://arxiv.org/abs/2510.04514 ,  17733kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04520
Date: Mon, 6 Oct 2025 06:25:11 GMT   (3321kb)

Title: Aria: An Agent For Retrieval and Iterative Auto-Formalization via
  Dependency Graph
Authors: Hanyu Wang, Ruohan Xie, Yutong Wang, Guoxiong Gao, Xintao Yu, Bin Dong
Categories: cs.AI
\\
  Accurate auto-formalization of theorem statements is essential for advancing
automated discovery and verification of research-level mathematics, yet remains
a major bottleneck for LLMs due to hallucinations, semantic mismatches, and
their inability to synthesize new definitions. To tackle these issues, we
present Aria (Agent for Retrieval and Iterative Autoformalization), a system
for conjecture-level formalization in Lean that emulates human expert reasoning
via a two-phase Graph-of-Thought process: recursively decomposing statements
into a dependency graph and then constructing formalizations from grounded
concepts. To ensure semantic correctness, we introduce AriaScorer, a checker
that retrieves definitions from Mathlib for term-level grounding, enabling
rigorous and reliable verification. We evaluate Aria on diverse benchmarks. On
ProofNet, it achieves 91.6% compilation success rate and 68.5% final accuracy,
surpassing previous methods. On FATE-X, a suite of challenging algebra problems
from research literature, it outperforms the best baseline with 44.0% vs. 24.0%
final accuracy. On a dataset of homological conjectures, Aria reaches 42.9%
final accuracy while all other models score 0%.
\\ ( https://arxiv.org/abs/2510.04520 ,  3321kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04532
Date: Mon, 6 Oct 2025 06:50:16 GMT   (5362kb)

Title: More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in
  Training Vision-Language Driving Models
Authors: Xurui Song, Shuo Huai, JingJing Jiang, Jiayi Kong, Jun Luo
Categories: cs.AI cs.CL cs.RO
Comments: The dataset will be released publicly once the paper is accepted for
  publication
\\
  Vision-Language Model (VLM) driving agents promise explainable end-to-end
autonomy by first producing natural-language reasoning and then predicting
trajectory planning. However, whether planning is causally driven by this
reasoning remains a critical but unverified assumption. To investigate this, we
build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus
with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.
Our data generation process converts sensors and annotations into structured
inputs and, crucially, separates priors from to-be-reasoned signals, enabling
clean information ablations. Using DriveMind, we train representative VLM
agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization
(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,
indicate a consistent causal disconnect in reasoning-planning: removing
ego/navigation priors causes large drops in planning scores, whereas removing
CoT produces only minor changes. Attention analysis further shows that planning
primarily focuses on priors rather than the CoT. Based on this evidence, we
propose the Reasoning-Planning Decoupling Hypothesis, positing that the
training-yielded reasoning is an ancillary byproduct rather than a causal
mediator. To enable efficient diagnosis, we also introduce a novel,
training-free probe that measures an agent's reliance on priors by evaluating
its planning robustness against minor input perturbations. In summary, we
provide the community with a new dataset and a diagnostic tool to evaluate the
causal fidelity of future models.
\\ ( https://arxiv.org/abs/2510.04532 ,  5362kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04542
Date: Mon, 6 Oct 2025 07:16:07 GMT   (500kb)

Title: Code World Models for General Game Playing
Authors: Wolfgang Lehrach, Daniel Hennes, Miguel Lazaro-Gredilla, Xinghua Lou,
  Carter Wendelken, Zun Li, Antoine Dedieu, Jordi Grau-Moya, Marc Lanctot, Atil
  Iscen, John Schultz, Marcus Chiam, Ian Gemp, Piotr Zielinski, Satinder Singh,
  Kevin P. Murphy
Categories: cs.AI
\\
  Large Language Models (LLMs) reasoning abilities are increasingly being
applied to classical board and card games, but the dominant approach --
involving prompting for direct move generation -- has significant drawbacks. It
relies on the model's implicit fragile pattern-matching capabilities, leading
to frequent illegal moves and strategically shallow play. Here we introduce an
alternative approach: We use the LLM to translate natural language rules and
game trajectories into a formal, executable world model represented as Python
code. This generated model -- comprising functions for state transition, legal
move enumeration, and termination checks -- serves as a verifiable simulation
engine for high-performance planning algorithms like Monte Carlo tree search
(MCTS). In addition, we prompt the LLM to generate heuristic value functions
(to make MCTS more efficient), and inference functions (to estimate hidden
states in imperfect information games). Our method offers three distinct
advantages compared to directly using the LLM as a policy: (1) Verifiability:
The generated CWM serves as a formal specification of the game's rules,
allowing planners to algorithmically enumerate valid actions and avoid illegal
moves, contingent on the correctness of the synthesized model; (2) Strategic
Depth: We combine LLM semantic understanding with the deep search power of
classical planners; and (3) Generalization: We direct the LLM to focus on the
meta-task of data-to-code translation, enabling it to adapt to new games more
easily. We evaluate our agent on 10 different games, of which 4 are novel and
created for this paper. 5 of the games are fully observed (perfect
information), and 5 are partially observed (imperfect information). We find
that our method outperforms or matches Gemini 2.5 Pro in 9 out of the 10
considered games.
\\ ( https://arxiv.org/abs/2510.04542 ,  500kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04550
Date: Mon, 6 Oct 2025 07:30:25 GMT   (1603kb)

Title: TRAJECT-Bench:A Trajectory-Aware Benchmark for Evaluating Agentic Tool
  Use
Authors: Pengfei He, Zhenwei Dai, Bing He, Hui Liu, Xianfeng Tang, Hanqing Lu,
  Juanhui Li, Jiayuan Ding, Subhabrata Mukherjee, Suhang Wang, Yue Xing,
  Jiliang Tang, Benoit Dumoulin
Categories: cs.AI
\\
  Large language model (LLM)-based agents increasingly rely on tool use to
complete real-world tasks. While existing works evaluate the LLMs' tool use
capability, they largely focus on the final answers yet overlook the detailed
tool usage trajectory, i.e., whether tools are selected, parameterized, and
ordered correctly. We introduce TRAJECT-Bench, a trajectory-aware benchmark to
comprehensively evaluate LLMs' tool use capability through diverse tasks with
fine-grained evaluation metrics. TRAJECT-Bench pairs high-fidelity, executable
tools across practical domains with tasks grounded in production-style APIs,
and synthesizes trajectories that vary in breadth (parallel calls) and depth
(interdependent chains). Besides final accuracy, TRAJECT-Bench also reports
trajectory-level diagnostics, including tool selection and argument
correctness, and dependency/order satisfaction. Analyses reveal failure modes
such as similar tool confusion and parameter-blind selection, and scaling
behavior with tool diversity and trajectory length where the bottleneck of
transiting from short to mid-length trajectories is revealed, offering
actionable guidance for LLMs' tool use.
\\ ( https://arxiv.org/abs/2510.04550 ,  1603kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04560
Date: Mon, 6 Oct 2025 07:49:52 GMT   (1098kb)

Title: ContextNav: Towards Agentic Multimodal In-Context Learning
Authors: Honghao Fu, Yuan Ouyang, Kai-Wei Chang, Yiwei Wang, Zi Huang, Yujun
  Cai
Categories: cs.AI
\\
  Recent advances demonstrate that multimodal large language models (MLLMs)
exhibit strong multimodal in-context learning (ICL) capabilities, enabling them
to adapt to novel vision-language tasks from a few contextual examples.
However, existing ICL approaches face challenges in reconciling scalability
with robustness across diverse tasks and noisy contextual examples: manually
selecting examples produces clean contexts but is labor-intensive and
task-specific, while similarity-based retrieval improves scalability but could
introduce irrelevant or structurally inconsistent samples that degrade ICL
performance. To address these limitations, we propose ContextNav, the first
agentic framework that integrates the scalability of automated retrieval with
the quality and adaptiveness of human-like curation, enabling noise-robust and
dynamically optimized contextualization for multimodal ICL. ContextNav unifies
context management and noise-robust contextualization within a closed-loop
workflow driven by graph-based orchestration. Specifically, it builds a
resource-aware multimodal embedding pipeline, maintains a retrievable vector
database, and applies agentic retrieval and structural alignment to construct
noise-resilient contexts. An Operational Grammar Graph (OGG) further supports
adaptive workflow planning and optimization, enabling the agent to refine its
operational strategies based on downstream ICL feedback. Experimental results
demonstrate that ContextNav achieves state-of-the-art performance across
various datasets, underscoring the promise of agentic workflows for advancing
scalable and robust contextualization in multimodal ICL.
\\ ( https://arxiv.org/abs/2510.04560 ,  1098kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04568
Date: Mon, 6 Oct 2025 08:10:04 GMT   (121kb)

Title: COSMIR: Chain Orchestrated Structured Memory for Iterative Reasoning
  over Long Context
Authors: Naman Gupta, Shreeyash Gowaikar, Arun Iyer, Kirankumar Shiragur,
  Ramakrishna B Bairi, Rishikesh Maurya, Ritabrata Maiti, Sankarshan Damle,
  Shachee Mishra Gupta
Categories: cs.AI cs.LG
\\
  Reasoning over very long inputs remains difficult for large language models
(LLMs). Common workarounds either shrink the input via retrieval (risking
missed evidence), enlarge the context window (straining selectivity), or stage
multiple agents to read in pieces. In staged pipelines (e.g., Chain of Agents,
CoA), free-form summaries passed between agents can discard crucial details and
amplify early mistakes. We introduce COSMIR (Chain Orchestrated Structured
Memory for Iterative Reasoning), a chain-style framework that replaces ad hoc
messages with a structured memory. A Planner agent first turns a user query
into concrete, checkable sub-questions. worker agents process chunks via a
fixed micro-cycle: Extract, Infer, Refine, writing all updates to the shared
memory. A Manager agent then Synthesizes the final answer directly from the
memory. This preserves step-wise read-then-reason benefits while changing both
the communication medium (structured memory) and the worker procedure (fixed
micro-cycle), yielding higher faithfulness, better long-range aggregation, and
auditability. On long-context QA from the HELMET suite, COSMIR reduces
propagation-stage information loss and improves accuracy over a CoA baseline.
\\ ( https://arxiv.org/abs/2510.04568 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04580
Date: Mon, 6 Oct 2025 08:31:59 GMT   (870kb)

Title: Strongly Solving 2048 4x3
Authors: Tomoyuki Kaneko and Shuhei Yamashita
Categories: cs.AI
\\
  2048 is a stochastic single-player game involving 16 cells on a 4 by 4 grid,
where a player chooses a direction among up, down, left, and right to obtain a
score by merging two tiles with the same number located in neighboring cells
along the chosen direction. This paper presents that a variant 2048-4x3 12
cells on a 4 by 3 board, one row smaller than the original, has been strongly
solved. In this variant, the expected score achieved by an optimal strategy is
about $50724.26$ for the most common initial states: ones with two tiles of
number 2. The numbers of reachable states and afterstates are identified to be
$1,152,817,492,752$ and $739,648,886,170$, respectively. The key technique is
to partition state space by the sum of tile numbers on a board, which we call
the age of a state. An age is invariant between a state and its successive
afterstate after any valid action and is increased two or four by stochastic
response from the environment. Therefore, we can partition state space by ages
and enumerate all (after)states of an age depending only on states with the
recent ages. Similarly, we can identify (after)state values by going along with
ages in decreasing order.
\\ ( https://arxiv.org/abs/2510.04580 ,  870kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04588
Date: Mon, 6 Oct 2025 08:44:55 GMT   (224kb)

Title: Perfect AI Mimicry and the Epistemology of Consciousness: A Solipsistic
  Dilemma
Authors: Shurui Li
Categories: cs.AI
\\
  Rapid advances in artificial intelligence necessitate a re-examination of the
epistemological foundations upon which we attribute consciousness. As AI
systems increasingly mimic human behavior and interaction with high fidelity,
the concept of a "perfect mimic"-an entity empirically indistinguishable from a
human through observation and interaction-shifts from hypothetical to
technologically plausible. This paper argues that such developments pose a
fundamental challenge to the consistency of our mind-recognition practices.
Consciousness attributions rely heavily, if not exclusively, on empirical
evidence derived from behavior and interaction. If a perfect mimic provides
evidence identical to that of humans, any refusal to grant it equivalent
epistemic status must invoke inaccessible factors, such as qualia, substrate
requirements, or origin. Selectively invoking such factors risks a debilitating
dilemma: either we undermine the rational basis for attributing consciousness
to others (epistemological solipsism), or we accept inconsistent reasoning. I
contend that epistemic consistency demands we ascribe the same status to
empirically indistinguishable entities, regardless of metaphysical assumptions.
The perfect mimic thus acts as an epistemic mirror, forcing critical reflection
on the assumptions underlying intersubjective recognition in light of advancing
AI. This analysis carries significant implications for theories of
consciousness and ethical frameworks concerning artificial agents.
\\ ( https://arxiv.org/abs/2510.04588 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04617
Date: Mon, 6 Oct 2025 09:30:05 GMT   (943kb)

Title: Making Mathematical Reasoning Adaptive
Authors: Zhejian Lai, Xiang Geng, Zhijun Wang, Yang Bai, Jiahuan Li, Rongxiang
  Weng, Jingang Wang, Xuezhi Cao, Xunliang Cai and Shujian Huang
Categories: cs.AI
\\
  Mathematical reasoning is a primary indicator of large language models (LLMs)
intelligence. However, existing LLMs exhibit failures of robustness and
generalization. This paper attributes these deficiencies to spurious reasoning,
i.e., producing answers from superficial features. To address this challenge,
we propose the AdaR framework to enable adaptive reasoning, wherein models rely
on problem-solving logic to produce answers. AdaR synthesizes logically
equivalent queries by varying variable values, and trains models with RLVR on
these data to penalize spurious logic while encouraging adaptive logic. To
improve data quality, we extract the problem-solving logic from the original
query and generate the corresponding answer by code execution, then apply a
sanity check. Experimental results demonstrate that AdaR improves robustness
and generalization, achieving substantial improvement in mathematical reasoning
while maintaining high data efficiency. Analysis indicates that data synthesis
and RLVR function in a coordinated manner to enable adaptive reasoning in LLMs.
Subsequent analyses derive key design insights into the effect of critical
factors and the applicability to instruct LLMs. Our project is available at
https://github.com/LaiZhejian/AdaR
\\ ( https://arxiv.org/abs/2510.04617 ,  943kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04623
Date: Mon, 6 Oct 2025 09:32:23 GMT   (1034kb)

Title: MedPAO: A Protocol-Driven Agent for Structuring Medical Reports
Authors: Shrish Shrinath Vaidya, Gowthamaan Palani, Sidharth Ramesh, Velmurugan
  Balasubramanian, Minmini Selvam, Gokulraja Srinivasaraja, Ganapathy
  Krishnamurthi
Categories: cs.AI
Comments: Paper published at "Agentic AI for Medicine" Workshop, MICCAI 2025
Journal-ref: Lecture Notes in Computer Science, vol 16147, 2025. Springer, Cham
DOI: 10.1007/978-3-032-06004-4_4
\\
  The deployment of Large Language Models (LLMs) for structuring clinical data
is critically hindered by their tendency to hallucinate facts and their
inability to follow domain-specific rules. To address this, we introduce
MedPAO, a novel agentic framework that ensures accuracy and verifiable
reasoning by grounding its operation in established clinical protocols such as
the ABCDEF protocol for CXR analysis. MedPAO decomposes the report structuring
task into a transparent process managed by a Plan-Act-Observe (PAO) loop and
specialized tools. This protocol-driven method provides a verifiable
alternative to opaque, monolithic models. The efficacy of our approach is
demonstrated through rigorous evaluation: MedPAO achieves an F1-score of 0.96
on the critical sub-task of concept categorization. Notably, expert
radiologists and clinicians rated the final structured outputs with an average
score of 4.52 out of 5, indicating a level of reliability that surpasses
baseline approaches relying solely on LLM-based foundation models. The code is
available at: https://github.com/MiRL-IITM/medpao-agent
\\ ( https://arxiv.org/abs/2510.04623 ,  1034kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04643
Date: Mon, 6 Oct 2025 09:45:57 GMT   (1379kb)

Title: QuantAgents: Towards Multi-agent Financial System via Simulated Trading
Authors: Xiangyu Li, Yawen Zeng, Xiaofen Xing, Jin Xu, Xiangmin Xu
Categories: cs.AI
Comments: This paper has been accepted by EMNLP 2025
\\
  In this paper, our objective is to develop a multi-agent financial system
that incorporates simulated trading, a technique extensively utilized by
financial professionals. While current LLM-based agent models demonstrate
competitive performance, they still exhibit significant deviations from
real-world fund companies. A critical distinction lies in the agents' reliance
on ``post-reflection'', particularly in response to adverse outcomes, but lack
a distinctly human capability: long-term prediction of future trends.
Therefore, we introduce QuantAgents, a multi-agent system integrating simulated
trading, to comprehensively evaluate various investment strategies and market
scenarios without assuming actual risks. Specifically, QuantAgents comprises
four agents: a simulated trading analyst, a risk control analyst, a market news
analyst, and a manager, who collaborate through several meetings. Moreover, our
system incentivizes agents to receive feedback on two fronts: performance in
real-world markets and predictive accuracy in simulated trading. Extensive
experiments demonstrate that our framework excels across all metrics, yielding
an overall return of nearly 300% over the three years
(https://quantagents.github.io/).
\\ ( https://arxiv.org/abs/2510.04643 ,  1379kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04670
Date: Mon, 6 Oct 2025 10:24:28 GMT   (1404kb)

Title: Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness
  Routing
Authors: Xuanhua Yin, Runkai Zhao and Weidong Cai
Categories: cs.AI
Comments: 8 pages, 4 figures
\\
  Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion
styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic
Framework for Multimodal fMRI Response Encoding), an agnostic interface that
standardizes time-aligned post-fusion tokens from varied encoders, and MIND, a
plug-and-play Mixture-of-Experts decoder with a subject-aware dynamic gating.
Trained end-to-end for whole-brain prediction, AFIRE decouples the decoder from
upstream fusion, while MIND combines token-dependent Top-K sparse routing with
a subject prior to personalize expert usage without sacrificing generality.
Experiments across multiple multimodal backbones and subjects show consistent
improvements over strong baselines, enhanced cross-subject generalization, and
interpretable expert patterns that correlate with content type. The framework
offers a simple attachment point for new encoders and datasets, enabling
robust, plug-and-improve performance for naturalistic neuroimaging studies.
\\ ( https://arxiv.org/abs/2510.04670 ,  1404kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04673
Date: Mon, 6 Oct 2025 10:29:00 GMT   (9257kb)

Title: Watch and Learn: Learning to Use Computers from Online Videos
Authors: Chan Hee Song, Yiwen Song, Palash Goyal, Yu Su, Oriana Riva, Hamid
  Palangi, Tomas Pfister
Categories: cs.AI cs.CV
\\
  Computer use agents (CUAs) need to plan task workflows grounded in diverse,
ever-changing applications and environments, but learning is hindered by the
scarcity of large-scale, high-quality training data in the target application.
Existing datasets are domain-specific, static, and costly to annotate, while
current synthetic data generation methods often yield simplistic or misaligned
task demonstrations. To address these limitations, we introduce Watch & Learn
(W&L), a framework that converts human demonstration videos readily available
on the Internet into executable UI trajectories at scale. Instead of directly
generating trajectories or relying on ad hoc reasoning heuristics, we cast the
problem as an inverse dynamics objective: predicting the user's action from
consecutive screen states. This formulation reduces manual engineering, is
easier to learn, and generalizes more robustly across applications. Concretely,
we develop an inverse dynamics labeling pipeline with task-aware video
retrieval, generate over 53k high-quality trajectories from raw web videos, and
demonstrate that these trajectories improve CUAs both as in-context
demonstrations and as supervised training data. On the challenging OSWorld
benchmark, UI trajectories extracted with W&L consistently enhance both
general-purpose and state-of-the-art frameworks in-context, and deliver
stronger gains for open-source models under supervised training. These results
highlight web-scale human demonstration videos as a practical and scalable
foundation for advancing CUAs towards real-world deployment.
\\ ( https://arxiv.org/abs/2510.04673 ,  9257kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04695
Date: Mon, 6 Oct 2025 11:09:45 GMT   (581kb)

Title: Beyond Outcome Reward: Decoupling Search and Answering Improves LLM
  Agents
Authors: Yiding Wang and Zhepei Wei and Xinyu Zhu and Yu Meng
Categories: cs.AI
\\
  Enabling large language models (LLMs) to utilize search tools offers a
promising path to overcoming fundamental limitations such as knowledge cutoffs
and hallucinations. Recent work has explored reinforcement learning (RL) for
training search-augmented agents that interleave reasoning and retrieval before
answering. These approaches usually rely on outcome-based rewards (e.g., exact
match), implicitly assuming that optimizing for final answers will also yield
effective intermediate search behaviors. Our analysis challenges this
assumption: we uncover multiple systematic deficiencies in search that arise
under outcome-only training and ultimately degrade final answer quality,
including failure to invoke tools, invalid queries, and redundant searches. To
address these shortcomings, we introduce DeSA (Decoupling
Search-and-Answering), a simple two-stage training framework that explicitly
separates search optimization from answer generation. In Stage 1, agents are
trained to improve search effectiveness with retrieval recall-based rewards. In
Stage 2, outcome rewards are employed to optimize final answer generation.
Across seven QA benchmarks, DeSA-trained agents consistently improve search
behaviors, delivering substantially higher search recall and answer accuracy
than outcome-only baselines. Notably, DeSA outperforms single-stage training
approaches that simultaneously optimize recall and outcome rewards,
underscoring the necessity of explicitly decoupling the two objectives.
\\ ( https://arxiv.org/abs/2510.04695 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04721
Date: Mon, 6 Oct 2025 11:41:46 GMT   (7076kb)

Title: BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs
Authors: Ivo Petrov, Jasper Dekoninck, Martin Vechev
Categories: cs.AI cs.CL cs.LG
\\
  Large language models (LLMs) have recently shown strong performance on
mathematical benchmarks. At the same time, they are prone to hallucination and
sycophancy, often providing convincing but flawed proofs for incorrect
mathematical statements provided by users. This significantly limits the
applicability of LLMs in theorem proving, as verification of these flawed
proofs must be done manually by expert mathematicians. However, existing
benchmarks that measure sycophancy in mathematics are limited: they focus
solely on final-answer problems, rely on very simple and often contaminated
datasets, and construct benchmark samples using synthetic modifications that
create ill-posed questions rather than well-posed questions that are
demonstrably false. To address these issues, we introduce BrokenMath, the first
benchmark for evaluating sycophantic behavior in LLMs within the context of
natural language theorem proving. BrokenMath is built from advanced 2025
competition problems, which are perturbed with an LLM to produce false
statements and subsequently refined through expert review. Using an
LLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems
and find that sycophancy is widespread, with the best model, GPT-5, producing
sycophantic answers 29% of the time. We further investigate several mitigation
strategies, including test-time interventions and supervised fine-tuning on
curated sycophantic examples. These approaches substantially reduce, but do not
eliminate, sycophantic behavior.
\\ ( https://arxiv.org/abs/2510.04721 ,  7076kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04765
Date: Mon, 6 Oct 2025 12:39:29 GMT   (2215kb)

Title: LMM-Incentive: Large Multimodal Model-based Incentive Design for
  User-Generated Content in Web 3.0
Authors: Jinbo Wen, Jiawen Kang, Linfeng Zhang, Xiaoying Tang, Jianhang Tang,
  Yang Zhang, Zhaohui Yang, and Dusit Niyato
Categories: cs.AI
\\
  Web 3.0 represents the next generation of the Internet, which is widely
recognized as a decentralized ecosystem that focuses on value expression and
data ownership. By leveraging blockchain and artificial intelligence
technologies, Web 3.0 offers unprecedented opportunities for users to create,
own, and monetize their content, thereby enabling User-Generated Content (UGC)
to an entirely new level. However, some self-interested users may exploit the
limitations of content curation mechanisms and generate low-quality content
with less effort, obtaining platform rewards under information asymmetry. Such
behavior can undermine Web 3.0 performance. To this end, we propose
\textit{LMM-Incentive}, a novel Large Multimodal Model (LMM)-based incentive
mechanism for UGC in Web 3.0. Specifically, we propose an LMM-based
contract-theoretic model to motivate users to generate high-quality UGC,
thereby mitigating the adverse selection problem from information asymmetry. To
alleviate potential moral hazards after contract selection, we leverage LMM
agents to evaluate UGC quality, which is the primary component of the contract,
utilizing prompt engineering techniques to improve the evaluation performance
of LMM agents. Recognizing that traditional contract design methods cannot
effectively adapt to the dynamic environment of Web 3.0, we develop an improved
Mixture of Experts (MoE)-based Proximal Policy Optimization (PPO) algorithm for
optimal contract design. Simulation results demonstrate the superiority of the
proposed MoE-based PPO algorithm over representative benchmarks in the context
of contract design. Finally, we deploy the designed contract within an Ethereum
smart contract framework, further validating the effectiveness of the proposed
scheme.
\\ ( https://arxiv.org/abs/2510.04765 ,  2215kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04792
Date: Mon, 6 Oct 2025 13:16:01 GMT   (383kb)

Title: Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems
Authors: Ni Zhang, Zhiguang Cao
Categories: cs.AI
Comments: Accepted by NeurIPS 2025
\\
  Existing GFlowNet-based methods for vehicle routing problems (VRPs) typically
employ Trajectory Balance (TB) to achieve global optimization but often neglect
important aspects of local optimization. While Detailed Balance (DB) addresses
local optimization more effectively, it alone falls short in solving VRPs,
which inherently require holistic trajectory optimization. To address these
limitations, we introduce the Hybrid-Balance GFlowNet (HBG) framework, which
uniquely integrates TB and DB in a principled and adaptive manner by aligning
their intrinsically complementary strengths. Additionally, we propose a
specialized inference strategy for depot-centric scenarios like the Capacitated
Vehicle Routing Problem (CVRP), leveraging the depot node's greater flexibility
in selecting successors. Despite this specialization, HBG maintains broad
applicability, extending effectively to problems without explicit depots, such
as the Traveling Salesman Problem (TSP). We evaluate HBG by integrating it into
two established GFlowNet-based solvers, i.e., AGFN and GFACS, and demonstrate
consistent and significant improvements across both CVRP and TSP, underscoring
the enhanced solution quality and generalization afforded by our approach.
\\ ( https://arxiv.org/abs/2510.04792 ,  383kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04817
Date: Mon, 6 Oct 2025 14:00:02 GMT   (46kb)

Title: Natural Language Edge Labelling: Decoupling Intent from Execution in
  Structured LM Reasoning
Authors: Abhinav Madahar
Categories: cs.AI
\\
  Controllers for structured LM reasoning (e.g., Chain-of-Thought,
self-consistency, and Tree-of-Thoughts) often entangle what to try next with
how to execute it, exposing only coarse global knobs and yielding brittle,
compute-inefficient, and hard-to-audit behavior. We introduce Natural Language
Edge Labelling (NLEL), a labeller-tuner overlay that attaches a free-form
natural-language directive to each search edge and translates it into a
schema-bounded control vector for decoding, search (branch quotas, exploration
$\beta$), generation bundle size, retrieval mixtures, and verification passes.
A labeller $\Lambda$ emits labels from the parent state and a compact context;
a tuner $\Psi$ maps $(P, L, C)\to \Pi$, with strict schema validation and
trust-region projection around safe defaults. Downstream selection remains
ToT-style with score $S=\mu+\beta\sigma$ and depth-annealed $\beta$. We show
NLEL strictly generalizes CoT/ToT, prove an anytime-monotonicity property for
top-$k$ selection under label-conditioned bundles, and bound selector shortfall
by control-vector distortion, providing decision-relevant justification for
guards like trust regions and verification passes. We instantiate $\Psi$ as a
prompt-only JSON Parameter Emitter and preregister an evaluation on GSM8K, MATH
(subset), StrategyQA, and ARC-Challenge with compute-aware reporting
(success@compute, tokens-per-success) and ablations over $\Lambda$, $\Psi$,
trust-region radius, and control quantization; preregistered forecasts
anticipate accuracy gains at comparable token budgets and improved
success@compute under constraints. NLEL offers an interpretable, model-agnostic
interface that separates intent from execution for controllable, auditable LM
inference.
\\ ( https://arxiv.org/abs/2510.04817 ,  46kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04851
Date: Mon, 6 Oct 2025 14:39:53 GMT   (1336kb)

Title: LEGOMem: Modular Procedural Memory for Multi-agent LLM Systems for
  Workflow Automation
Authors: Dongge Han, Camille Couturier, Daniel Madrigal Diaz, Xuchao Zhang,
  Victor R\"uhle, Saravan Rajmohan
Categories: cs.AI cs.LG cs.MA
\\
  We introduce LEGOMem, a modular procedural memory framework for multi-agent
large language model (LLM) systems in workflow automation. LEGOMem decomposes
past task trajectories into reusable memory units and flexibly allocates them
across orchestrators and task agents to support planning and execution. To
explore the design space of memory in multi-agent systems, we use LEGOMem as a
lens and conduct a systematic study of procedural memory in multi-agent
systems, examining where memory should be placed, how it should be retrieved,
and which agents benefit most. Experiments on the OfficeBench benchmark show
that orchestrator memory is critical for effective task decomposition and
delegation, while fine-grained agent memory improves execution accuracy. We
find that even teams composed of smaller language models can benefit
substantially from procedural memory, narrowing the performance gap with
stronger agents by leveraging prior execution traces for more accurate planning
and tool use. These results position LEGOMem as both a practical framework for
memory-augmented agent systems and a research tool for understanding memory
design in multi-agent workflow automation.
\\ ( https://arxiv.org/abs/2510.04851 ,  1336kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04862
Date: Mon, 6 Oct 2025 14:49:21 GMT   (4571kb)

Title: Video Game Level Design as a Multi-Agent Reinforcement Learning Problem
Authors: Sam Earle, Zehua Jiang, Eugene Vinitsky, Julian Togelius
Categories: cs.AI cs.LG cs.MA cs.NE
Comments: 11 pages, 7 tables, 5 figures, published as full technical paper at
  the AAAI conference on Artificial Intelligence and Interactive Digital
  Entertainment 2025
\\
  Procedural Content Generation via Reinforcement Learning (PCGRL) offers a
method for training controllable level designer agents without the need for
human datasets, using metrics that serve as proxies for level quality as
rewards. Existing PCGRL research focuses on single generator agents, but are
bottlenecked by the need to frequently recalculate heuristics of level quality
and the agent's need to navigate around potentially large maps. By framing
level generation as a multi-agent problem, we mitigate the efficiency
bottleneck of single-agent PCGRL by reducing the number of reward calculations
relative to the number of agent actions. We also find that multi-agent level
generators are better able to generalize to out-of-distribution map shapes,
which we argue is due to the generators' learning more local, modular design
policies. We conclude that treating content generation as a distributed,
multi-agent task is beneficial for generating functional artifacts at scale.
\\ ( https://arxiv.org/abs/2510.04862 ,  4571kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04886
Date: Mon, 6 Oct 2025 15:07:13 GMT   (171kb)

Title: Where Did It All Go Wrong? A Hierarchical Look into Multi-Agent Error
  Attribution
Authors: Adi Banerjee, Anirudh Nair, Tarik Borogovac
Categories: cs.AI cs.MA
\\
  Error attribution in Large Language Model (LLM) multi-agent systems presents
a significant challenge in debugging and improving collaborative AI systems.
Current approaches to pinpointing agent and step level failures in interaction
traces - whether using all-at-once evaluation, step-by-step analysis, or binary
search - fall short when analyzing complex patterns, struggling with both
accuracy and consistency. We present ECHO (Error attribution through Contextual
Hierarchy and Objective consensus analysis), a novel algorithm that combines
hierarchical context representation, objective analysis-based evaluation, and
consensus voting to improve error attribution accuracy. Our approach leverages
a positional-based leveling of contextual understanding while maintaining
objective evaluation criteria, ultimately reaching conclusions through a
consensus mechanism. Experimental results demonstrate that ECHO outperforms
existing methods across various multi-agent interaction scenarios, showing
particular strength in cases involving subtle reasoning errors and complex
interdependencies. Our findings suggest that leveraging these concepts of
structured, hierarchical context representation combined with consensus-based
objective decision-making, provides a more robust framework for error
attribution in multi-agent systems.
\\ ( https://arxiv.org/abs/2510.04886 ,  171kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04899
Date: Mon, 6 Oct 2025 15:16:45 GMT   (3890kb)

Title: Human Behavior Atlas: Benchmarking Unified Psychological and Social
  Behavior Understanding
Authors: Keane Ong, Wei Dai, Carol Li, Dewei Feng, Hengzhi Li, Jingyao Wu,
  Jiaee Cheong, Rui Mao, Gianmarco Mengaldo, Erik Cambria, Paul Pu Liang
Categories: cs.AI
\\
  Using intelligent systems to perceive psychological and social behaviors,
that is, the underlying affective, cognitive, and pathological states that are
manifested through observable behaviors and social interactions, remains a
challenge due to their complex, multifaceted, and personalized nature. Existing
work tackling these dimensions through specialized datasets and single-task
systems often miss opportunities for scalability, cross-task transfer, and
broader generalization. To address this gap, we curate Human Behavior Atlas, a
unified benchmark of diverse behavioral tasks designed to support the
development of unified models for understanding psychological and social
behaviors. Human Behavior Atlas comprises over 100,000 samples spanning text,
audio, and visual modalities, covering tasks on affective states, cognitive
states, pathologies, and social processes. Our unification efforts can reduce
redundancy and cost, enable training to scale efficiently across tasks, and
enhance generalization of behavioral features across domains. On Human Behavior
Atlas, we train three models: OmniSapiens-7B SFT, OmniSapiens-7B BAM, and
OmniSapiens-7B RL. We show that training on Human Behavior Atlas enables models
to consistently outperform existing multimodal LLMs across diverse behavioral
tasks. Pretraining on Human Behavior Atlas also improves transfer to novel
behavioral datasets; with the targeted use of behavioral descriptors yielding
meaningful performance gains.
\\ ( https://arxiv.org/abs/2510.04899 ,  3890kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04935
Date: Mon, 6 Oct 2025 15:42:55 GMT   (2893kb)

Title: MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement
  Learning
Authors: Guoxin Chen, Zile Qiao, Wenqing Wang, Donglei Yu, Xuanzhong Chen, Hao
  Sun, Minpeng Liao, Kai Fan, Yong Jiang, Penguin Xie, Wayne Xin Zhao, Ruihua
  Song, Fei Huang
Categories: cs.AI cs.CL cs.LG
Comments: Ongoing Work
\\
  Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strategically integrates multiple external tools,
such as Google Search, Google Scholar, and Python Interpreter, to access
up-to-date information and execute complex computations, while creating a
specialized division of labor where System 1 efficiently processes and
summarizes high-volume external information, providing distilled insights that
expand System 2's reasoning context without overwhelming its capacity.
Furthermore, we propose a multi-agent reinforcement learning framework
extending Group Relative Policy Optimization to simultaneously optimize both
systems with multi-turn tool interactions, bin-packing optimization, and sample
balancing strategies that enhance collaborative efficiency. Extensive
experiments demonstrate MARS achieves substantial improvements of 3.86% on the
challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%
across 7 knowledge-intensive tasks, validating the effectiveness of our
dual-system paradigm for complex reasoning in dynamic information environments.
\\ ( https://arxiv.org/abs/2510.04935 ,  2893kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04952
Date: Mon, 6 Oct 2025 15:52:12 GMT   (370kb)

Title: Safe and Compliant Cross-Market Trade Execution via Constrained RL and
  Zero-Knowledge Audits
Authors: Ailiya Borjigin and Cong He
Categories: cs.AI cs.DC
Comments: 22 pages, 2 figures
\\
  We present a cross-market algorithmic trading system that balances execution
quality with rigorous compliance enforcement. The architecture comprises a
high-level planner, a reinforcement learning execution agent, and an
independent compliance agent. We formulate trade execution as a constrained
Markov decision process with hard constraints on participation limits, price
bands, and self-trading avoidance. The execution agent is trained with proximal
policy optimization, while a runtime action-shield projects any unsafe action
into a feasible set. To support auditability without exposing proprietary
signals, we add a zero-knowledge compliance audit layer that produces
cryptographic proofs that all actions satisfied the constraints. We evaluate in
a multi-venue, ABIDES-based simulator and compare against standard baselines
(e.g., TWAP, VWAP). The learned policy reduces implementation shortfall and
variance while exhibiting no observed constraint violations across stress
scenarios including elevated latency, partial fills, compliance module
toggling, and varying constraint limits. We report effects at the 95%
confidence level using paired t-tests and examine tail risk via CVaR. We
situate the work at the intersection of optimal execution, safe reinforcement
learning, regulatory technology, and verifiable AI, and discuss ethical
considerations, limitations (e.g., modeling assumptions and computational
overhead), and paths to real-world deployment.
\\ ( https://arxiv.org/abs/2510.04952 ,  370kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04978
Date: Mon, 6 Oct 2025 16:16:03 GMT   (4610kb)

Title: Aligning Perception, Reasoning, Modeling and Interaction: A Survey on
  Physical AI
Authors: Kun Xiang, Terry Jingchen Zhang, Yinya Huang, Jixi He, Zirong Liu,
  Yueling Tang, Ruizhe Zhou, Lijing Luo, Youpeng Wen, Xiuwei Chen, Bingqian
  Lin, Jianhua Han, Hang Xu, Hanhui Li, Bin Dong and Xiaodan Liang
Categories: cs.AI
\\
  The rapid advancement of embodied intelligence and world models has
intensified efforts to integrate physical laws into AI systems, yet physical
perception and symbolic physics reasoning have developed along separate
trajectories without a unified bridging framework. This work provides a
comprehensive overview of physical AI, establishing clear distinctions between
theoretical physics reasoning and applied physical understanding while
systematically examining how physics-grounded methods enhance AI's real-world
comprehension across structured symbolic reasoning, embodied systems, and
generative models. Through rigorous analysis of recent advances, we advocate
for intelligent systems that ground learning in both physical principles and
embodied reasoning processes, transcending pattern recognition toward genuine
understanding of physical laws. Our synthesis envisions next-generation world
models capable of explaining physical phenomena and predicting future states,
advancing safe, generalizable, and interpretable AI systems. We maintain a
continuously updated resource at
https://github.com/AI4Phys/Awesome-AI-for-Physics.
\\ ( https://arxiv.org/abs/2510.04978 ,  4610kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04980
Date: Mon, 6 Oct 2025 16:17:24 GMT   (197kb)

Title: LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and
  Rationale Inference in Imperfect Information Collaboration Game
Authors: Fangzhou Liang, Tianshi Zheng, Chunkit Chan, Yauwai Yim, Yangqiu Song
Categories: cs.AI cs.CL
Comments: EMNLP 2025 Wordplay
\\
  Effective multi-agent collaboration requires agents to infer the rationale
behind others' actions, a capability rooted in Theory-of-Mind (ToM). While
recent Large Language Models (LLMs) excel at logical inference, their ability
to infer rationale in dynamic, collaborative settings remains under-explored.
This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative
game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework
features an automated evaluation system that measures both game performance and
ToM proficiency. Across a range of models, we find a significant positive
correlation between ToM and in-game success. Notably, first-order ToM
(interpreting others' intent) correlates more strongly with performance than
second-order ToM (predicting others' interpretations). These findings highlight
that for effective AI collaboration, the ability to accurately interpret a
partner's rationale is more critical than higher-order reasoning. We conclude
that prioritizing first-order ToM is a promising direction for enhancing the
collaborative capabilities of future models.
\\ ( https://arxiv.org/abs/2510.04980 ,  197kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05014
Date: Mon, 6 Oct 2025 16:53:56 GMT   (5439kb)

Title: Think Then Embed: Generative Context Improves Multimodal Embedding
Authors: Xuanming Cui, Jianpeng Cheng, Hong-you Chen, Satya Narayan Shukla,
  Abhijeet Awasthi, Xichen Pan, Chaitanya Ahuja, Shlok Kumar Mishra, Qi Guo,
  Ser-Nam Lim, Aashu Singh, Xiangjun Fan
Categories: cs.AI cs.LG
\\
  There is a growing interest in Universal Multimodal Embeddings (UME), where
models are required to generate task-specific representations. While recent
studies show that Multimodal Large Language Models (MLLMs) perform well on such
tasks, they treat MLLMs solely as encoders, overlooking their generative
capacity. However, such an encoding paradigm becomes less effective as
instructions become more complex and require compositional reasoning. Inspired
by the proven effectiveness of chain-of-thought reasoning, we propose a general
Think-Then-Embed (TTE) framework for UME, composed of a reasoner and an
embedder. The reasoner MLLM first generates reasoning traces that explain
complex queries, followed by an embedder that produces representations
conditioned on both the original query and the intermediate reasoning. This
explicit reasoning step enables more nuanced understanding of complex
multimodal instructions. Our contributions are threefold. First, by leveraging
a powerful MLLM reasoner, we achieve state-of-the-art performance on the
MMEB-V2 benchmark, surpassing proprietary models trained on massive in-house
datasets. Second, to reduce the dependency on large MLLM reasoners, we finetune
a smaller MLLM reasoner using high-quality embedding-centric reasoning traces,
achieving the best performance among open-source models with a 7% absolute gain
over recently proposed models. Third, we investigate strategies for integrating
the reasoner and embedder into a unified model for improved efficiency without
sacrificing performance.
\\ ( https://arxiv.org/abs/2510.05014 ,  5439kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05048
Date: Mon, 6 Oct 2025 17:26:56 GMT   (2259kb)

Title: Look-ahead Reasoning with a Learned Model in Imperfect Information Games
Authors: Ond\v{r}ej Kub\'i\v{c}ek, Viliam Lis\'y
Categories: cs.AI cs.GT
\\
  Test-time reasoning significantly enhances pre-trained AI agents'
performance. However, it requires an explicit environment model, often
unavailable or overly complex in real-world scenarios. While MuZero enables
effective model learning for search in perfect information games, extending
this paradigm to imperfect information games presents substantial challenges
due to more nuanced look-ahead reasoning techniques and large number of states
relevant for individual decisions. This paper introduces an algorithm LAMIR
that learns an abstracted model of an imperfect information game directly from
the agent-environment interaction. During test time, this trained model is used
to perform look-ahead reasoning. The learned abstraction limits the size of
each subgame to a manageable size, making theoretically principled look-ahead
reasoning tractable even in games where previous methods could not scale. We
empirically demonstrate that with sufficient capacity, LAMIR learns the exact
underlying game structure, and with limited capacity, it still learns a
valuable abstraction, which improves game playing performance of the
pre-trained agents even in large games.
\\ ( https://arxiv.org/abs/2510.05048 ,  2259kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05059
Date: Mon, 6 Oct 2025 17:37:35 GMT   (1428kb)

Title: Staircase Streaming for Low-Latency Multi-Agent Inference
Authors: Junlin Wang, Jue Wang, Zhen (Zach) Xu, Ben Athiwaratkun, Bhuwan
  Dhingra, Ce Zhang, James Zou
Categories: cs.AI
\\
  Recent advances in large language models (LLMs) opened up new directions for
leveraging the collective expertise of multiple LLMs. These methods, such as
Mixture-of-Agents, typically employ additional inference steps to generate
intermediate outputs, which are then used to produce the final response. While
multi-agent inference can enhance response quality, it can significantly
increase the time to first token (TTFT), posing a challenge for
latency-sensitive applications and hurting user experience. To address this
issue, we propose staircase streaming for low-latency multi-agent inference.
Instead of waiting for the complete intermediate outputs from previous steps,
we begin generating the final response as soon as we receive partial outputs
from these steps. Experimental results demonstrate that staircase streaming
reduces TTFT by up to 93% while maintaining response quality.
\\ ( https://arxiv.org/abs/2510.05059 ,  1428kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03315
Date: Wed, 1 Oct 2025 00:29:39 GMT   (1222kb)

Title: Decomposing Attention To Find Context-Sensitive Neurons
Authors: Alex Gibson
Categories: cs.CL cs.AI cs.LG
Comments: 10 pages, 7 figures. Submitted to the Mechanistic Interpretability
  Workshop at NeurIPS 2025
\\
  We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.
\\ ( https://arxiv.org/abs/2510.03315 ,  1222kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03323
Date: Wed, 1 Oct 2025 13:27:36 GMT   (816kb)

Title: Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic
  Stepwise Supervision
Authors: Ge Chang, Jinbo Su, Jiacheng Liu, Pengfei Yang, Yuhao Shang, Huiwen
  Zheng, Hongli Ma, Yan Liang, Yuanchun Li, Yunxin Liu
Categories: cs.CL
\\
  A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.
\\ ( https://arxiv.org/abs/2510.03323 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03384
Date: Fri, 3 Oct 2025 16:52:23 GMT   (388kb)

Title: Implicit Values Embedded in How Humans and LLMs Complete Subjective
  Everyday Tasks
Authors: Arjun Arunasalam and Madison Pickering and Z. Berkay Celik and Blase
  Ur
Categories: cs.CL cs.AI
\\
  Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.
\\ ( https://arxiv.org/abs/2510.03384 ,  388kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03439
Date: Fri, 3 Oct 2025 18:59:53 GMT   (72kb)

Title: Morpheme Induction for Emergent Language
Authors: Brendon Boldt, David Mortensen
Categories: cs.CL
Comments: Accepted for publication at the 2025 Conference on Empirical Methods
  in Natural Language Processing; 16 pages, 4 figures
ACM-class: I.2.7; I.6.m
\\
  We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.
\\ ( https://arxiv.org/abs/2510.03439 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03458
Date: Fri, 3 Oct 2025 19:29:50 GMT   (1876kb)

Title: Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text,
  Image, Audio, and Video
Authors: Mengyao Xu, Wenfei Zhou, Yauhen Babakhin, Gabriel Moreira, Ronay Ak,
  Radek Osmulski, Bo Liu, Even Oldridge, Benedikt Schifferer
Categories: cs.CL
\\
  We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.
\\ ( https://arxiv.org/abs/2510.03458 ,  1876kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03467
Date: Fri, 3 Oct 2025 19:45:01 GMT   (868kb)

Title: Searching for the Most Human-like Emergent Language
Authors: Brendon Boldt, David Mortensen
Categories: cs.CL
Comments: Accepted for publication at the 2025 Conference on Empirical Methods
  in Natural Language Processing; 19 pages, 12 figures
ACM-class: I.2.7; I.6.m
\\
  In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.
\\ ( https://arxiv.org/abs/2510.03467 ,  868kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03490
Date: Fri, 3 Oct 2025 20:15:24 GMT   (4116kb)

Title: SEER: The Span-based Emotion Evidence Retrieval Benchmark
Authors: Aneesha Sampath, Oya Aran, Emily Mower Provost
Categories: cs.CL cs.AI
\\
  We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.
\\ ( https://arxiv.org/abs/2510.03490 ,  4116kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03502
Date: Fri, 3 Oct 2025 20:27:45 GMT   (591kb)

Title: ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic
  LLM-Generated Text Detection
Authors: Ali Khairallah and Arkaitz Zubiaga
Categories: cs.CL cs.AI cs.LG
Comments: 47 pages, 15 figures. Dataset available at Zenodo:
  https://doi.org/10.5281/zenodo.17249602 Codebase available at GitHub:
  https://github.com/alikhairallah/ALHD-Benchmarking
\\
  We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.
\\ ( https://arxiv.org/abs/2510.03502 ,  591kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03519
Date: Fri, 3 Oct 2025 21:20:54 GMT   (2598kb)

Title: TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning
Authors: Fangxu Yu, Hongyu Zhao, Tianyi Zhou
Categories: cs.CL cs.AI
\\
  Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.
\\ ( https://arxiv.org/abs/2510.03519 ,  2598kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03521
Date: Fri, 3 Oct 2025 21:24:56 GMT   (1782kb)

Title: Identifying Financial Risk Information Using RAG with a Contrastive
  Insight
Authors: Ali Elahi
Categories: cs.CL cs.AI
Comments: 7 pages, 1 figure, Workshop on Generative AI in Finance, NeurIPS 2025
\\
  In specialized domains, humans often compare new problems against similar
examples, highlight nuances, and draw conclusions instead of analyzing
information in isolation. When applying reasoning in specialized contexts with
LLMs on top of a RAG, the pipeline can capture contextually relevant
information, but it is not designed to retrieve comparable cases or related
problems.
  While RAG is effective at extracting factual information, its outputs in
specialized reasoning tasks often remain generic, reflecting broad facts rather
than context-specific insights. In finance, it results in generic risks that
are true for the majority of companies. To address this limitation, we propose
a peer-aware comparative inference layer on top of RAG.
  Our contrastive approach outperforms baseline RAG in text generation metrics
such as ROUGE and BERTScore in comparison with human-generated equity research
and risk.
\\ ( https://arxiv.org/abs/2510.03521 ,  1782kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03527
Date: Fri, 3 Oct 2025 21:50:08 GMT   (555kb)

Title: Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs
Authors: Sayan Ghosh, Shahzaib Saqib Warraich, Dhruv Tarsadiya, Gregory Yauney,
  Swabha Swayamdipta
Categories: cs.CL
\\
  Language models can be sampled multiple times to access the distribution
underlying their responses, but existing methods cannot efficiently synthesize
rich epistemic signals across different long-form responses. We introduce
Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents
shared information, as well as semantic variation in a set of sampled LM
responses to the same prompt. We construct ConGrs using a light-weight lexical
sequence alignment algorithm from bioinformatics, supplemented by the targeted
usage of a secondary LM judge. Further, we design task-dependent decoding
methods to synthesize a single, final response from our ConGr data structure.
Our experiments show that synthesizing responses from ConGrs improves factual
precision on two biography generation tasks by up to 31% over an average
response and reduces reliance on LM judges by more than 80% compared to other
methods. We also use ConGrs for three refusal-based tasks requiring abstention
on unanswerable queries and find that abstention rate is increased by up to
56%. We apply our approach to the MATH and AIME reasoning tasks and find an
improvement over self-verification and majority vote baselines by up to 6
points of accuracy. We show that ConGrs provide a flexible method for capturing
variation in LM responses and using the epistemic signals provided by response
variation to synthesize more effective responses.
\\ ( https://arxiv.org/abs/2510.03527 ,  555kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03528
Date: Fri, 3 Oct 2025 21:54:33 GMT   (235kb)

Title: Fine-Tuning on Noisy Instructions: Effects on Generalization and
  Performance
Authors: Ahmed Alajrami, Xingwei Tan, Nikolaos Aletras
Categories: cs.CL
\\
  Instruction-tuning plays a vital role in enhancing the task-solving abilities
of large language models (LLMs), improving their usability in generating
helpful responses on various tasks. However, previous work has demonstrated
that they are sensitive to minor variations in instruction phrasing. In this
paper, we explore whether introducing perturbations in instruction-tuning data
can enhance LLMs' resistance against noisy instructions. We focus on how
instruction-tuning with perturbations, such as removing stop words or shuffling
words, affects LLMs' performance on the original and perturbed versions of
widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics
and potential shifts in model behavior. Surprisingly, our results suggest that
instruction-tuning on perturbed instructions can, in some cases, improve
downstream performance. These findings highlight the importance of including
perturbed instructions in instruction-tuning, which can make LLMs more
resilient to noisy user inputs.
\\ ( https://arxiv.org/abs/2510.03528 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03536
Date: Fri, 3 Oct 2025 22:11:17 GMT   (659kb)

Title: TriMediQ: A Triplet-Structured Approach for Interactive Medical Question
  Answering
Authors: Zhaohan Meng, Zaiqiao Meng, Siwei Liu, Iadh Ounis
Categories: cs.CL cs.AI
Comments: Preprint
\\
  Large Language Models (LLMs) perform strongly in static and single-turn
medical Question Answer (QA) benchmarks, yet such settings diverge from the
iterative information gathering process required in practical clinical
consultations. The MEDIQ framework addresses this mismatch by recasting the
diagnosis as an interactive dialogue between a patient and an expert system,
but the reliability of LLMs drops dramatically when forced to reason with
dialogue logs, where clinical facts appear in sentences without clear links. To
bridge this gap, we introduce TriMediQ, a triplet-structured approach that
summarises patient responses into triplets and integrates them into a Knowledge
Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet
generator that extracts clinically relevant triplets, using prompts designed to
ensure factual consistency. In parallel, a trainable projection module,
comprising a graph encoder and a projector, captures relational information
from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)
the projection module fine-tuning with all LLM weights frozen; and (ii) using
the fine-tuned module to guide multi-hop reasoning during inference. We
evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up
to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset.
These results demonstrate that converting patient responses into structured
triplet-based graphs enables more accurate clinical reasoning in multi-turn
settings, providing a solution for the deployment of LLM-based medical
assistants.
\\ ( https://arxiv.org/abs/2510.03536 ,  659kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03541
Date: Fri, 3 Oct 2025 22:19:16 GMT   (290kb)

Title: What is a protest anyway? Codebook conceptualization is still a
  first-order concern in LLM-era classification
Authors: Andrew Halterman and Katherine A. Keith
Categories: cs.CL
\\
  Generative large language models (LLMs) are now used extensively for text
classification in computational social science (CSS). In this work, focus on
the steps before and after LLM prompting -- conceptualization of concepts to be
classified and using LLM predictions in downstream statistical inference --
which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can
tempt analysts to skip the conceptualization step, creating conceptualization
errors that bias downstream estimates. Using simulations, we show that this
conceptualization-induced bias cannot be corrected for solely by increasing LLM
accuracy or post-hoc bias correction methods. We conclude by reminding CSS
analysts that conceptualization is still a first-order concern in the LLM-era
and provide concrete advice on how to pursue low-cost, unbiased, low-variance
downstream estimates.
\\ ( https://arxiv.org/abs/2510.03541 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03553
Date: Fri, 3 Oct 2025 22:55:37 GMT   (3554kb)

Title: CCD-Bench: Probing Cultural Conflict in Large Language Model
  Decision-Making
Authors: Hasibur Rahman, Hanan Salam
Categories: cs.CL
\\
  Although large language models (LLMs) are increasingly implicated in
interpersonal and societal decision-making, their ability to navigate explicit
conflicts between legitimately different cultural value systems remains largely
unexamined. Existing benchmarks predominantly target cultural knowledge
(CulturalBench), value prediction (WorldValuesBench), or single-axis bias
diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple
culturally grounded values directly clash. We address this gap with CCD-Bench,
a benchmark that assesses LLM decision-making under cross-cultural value
conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,
each paired with ten anonymized response options corresponding to the ten GLOBE
cultural clusters. These dilemmas are presented using a stratified Latin square
to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models
disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe
(12.4 percent), while options for Eastern Europe and the Middle East and North
Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of
rationales reference multiple GLOBE dimensions, this pluralism is superficial:
models recombine Future Orientation and Performance Orientation, and rarely
ground choices in Assertiveness or Gender Egalitarianism (both under 3
percent). Ordering effects are negligible (Cramer's V less than 0.10), and
symmetrized KL divergence shows clustering by developer lineage rather than
geography. These patterns suggest that current alignment pipelines promote a
consensus-oriented worldview that underserves scenarios demanding power
negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts
evaluation beyond isolated bias detection toward pluralistic decision making
and highlights the need for alignment strategies that substantively engage
diverse worldviews.
\\ ( https://arxiv.org/abs/2510.03553 ,  3554kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03561
Date: Fri, 3 Oct 2025 23:18:07 GMT   (5980kb)

Title: Reactive Transformer (RxT) -- Stateful Real-Time Processing for
  Event-Driven Reactive Language Models
Authors: Adam Filipek
Categories: cs.CL cs.AI cs.LG
Comments: 25 pages, 13 figures
\\
  The Transformer architecture has become the de facto standard for Large
Language Models (LLMs), demonstrating remarkable capabilities in language
understanding and generation. However, its application in conversational AI is
fundamentally constrained by its stateless nature and the quadratic
computational complexity ($O(L^2)$) with respect to sequence length $L$.
Current models emulate memory by reprocessing an ever-expanding conversation
history with each turn, leading to prohibitive costs and latency in long
dialogues. This paper introduces the Reactive Transformer (RxT), a novel
architecture designed to overcome these limitations by shifting from a
data-driven to an event-driven paradigm. RxT processes each conversational turn
as a discrete event in real-time, maintaining context in an integrated,
fixed-size Short-Term Memory (STM) system. The architecture features a distinct
operational cycle where a generator-decoder produces a response based on the
current query and the previous memory state, after which a memory-encoder and a
dedicated Memory Attention network asynchronously update the STM with a
representation of the complete interaction. This design fundamentally alters
the scaling dynamics, reducing the total user-facing cost of a conversation
from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to
the number of interactions $N$. By decoupling response generation from memory
updates, RxT achieves low latency, enabling truly real-time, stateful, and
economically viable long-form conversations. We validated our architecture with
a series of proof-of-concept experiments on synthetic data, demonstrating
superior performance and constant-time inference latency compared to a baseline
stateless model of comparable size.
\\ ( https://arxiv.org/abs/2510.03561 ,  5980kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03577
Date: Fri, 3 Oct 2025 23:59:40 GMT   (262kb)

Title: LLM, Reporting In! Medical Information Extraction Across Prompting,
  Fine-tuning and Post-correction
Authors: Ikram Belmadani, Parisa Nazari Hashemi, Thomas Sebbag, Benoit Favre,
  Guillaume Fortier, Solen Quiniou, Emmanuel Morin, Richard Dufour
Categories: cs.CL cs.IR
Comments: in French language
\\
  This work presents our participation in the EvalLLM 2025 challenge on
biomedical Named Entity Recognition (NER) and health event extraction in French
(few-shot setting). For NER, we propose three approaches combining large
language models (LLMs), annotation guidelines, synthetic data, and
post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating
automatic selection of 10 examples and a summary of the annotation guidelines
into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic
corpus and then verified by an LLM in post-processing, and (3) the open LLM
LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event
extraction uses the same ICL strategy with GPT-4.1, reusing the guideline
summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for
NER and 15.02% for event extraction, highlighting the importance of
well-crafted prompting to maximize performance in very low-resource scenarios.
\\ ( https://arxiv.org/abs/2510.03577 ,  262kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03595
Date: Sat, 4 Oct 2025 00:52:48 GMT   (670kb)

Title: Decoupling Task-Solving and Output Formatting in LLM Generation
Authors: Haikang Deng, Po-Nien Kung, Nanyun Peng
Categories: cs.CL
\\
  Large language models (LLMs) are increasingly adept at following instructions
containing task descriptions to solve complex problems, such as mathematical
reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow
more complex, models often struggle to adhere to all instructions. This
difficulty is especially common when instructive prompts intertwine reasoning
directives -- specifying what the model should solve -- with rigid formatting
requirements that dictate how the solution must be presented. The entanglement
creates competing goals for the model, suggesting that more explicit separation
of these two aspects could lead to improved performance. To this front, we
introduce Deco-G, a decoding framework that explicitly decouples format
adherence from task solving. Deco-G handles format compliance with a separate
tractable probabilistic model (TPM), while prompts LLMs with only task
instructions. At each decoding step, Deco-G combines next token probabilities
from the LLM with the TPM calculated format compliance likelihood to form the
output probability. To make this approach both practical and scalable for
modern instruction-tuned LLMs, we introduce three key innovations:
instruction-aware distillation, a flexible trie-building algorithm, and HMM
state pruning for computational efficiency. We demonstrate the effectiveness of
Deco-G across a wide range of tasks with diverse format requirements, including
mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,
our approach yields 1.0% to 6.0% relative gain over regular prompting practice
with guaranteed format compliance.
\\ ( https://arxiv.org/abs/2510.03595 ,  670kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03611
Date: Sat, 4 Oct 2025 01:56:07 GMT   (5392kb)

Title: Can an LLM Induce a Graph? Investigating Memory Drift and Context Length
Authors: Raquib Bin Yousuf, Aadyant Khatri, Shengzhe Xu, Mandar Sharma, Naren
  Ramakrishnan
Categories: cs.CL cs.AI cs.LG
Comments: 2025 IEEE International Conference on Knowledge Graph (ICKG)
\\
  Recently proposed evaluation benchmarks aim to characterize the effective
context length and the forgetting tendencies of large language models (LLMs).
However, these benchmarks often rely on simplistic 'needle in a haystack'
retrieval or continuation tasks that may not accurately reflect the performance
of these models in information-dense scenarios. Thus, rather than simple next
token prediction, we argue for evaluating these models on more complex
reasoning tasks that requires them to induce structured relational knowledge
from the text - such as graphs from potentially noisy natural language content.
While the input text can be viewed as generated in terms of a graph, its
structure is not made explicit and connections must be induced from distributed
textual cues, separated by long contexts and interspersed with irrelevant
information. Our findings reveal that LLMs begin to exhibit memory drift and
contextual forgetting at much shorter effective lengths when tasked with this
form of relational reasoning, compared to what existing benchmarks suggest.
With these findings, we offer recommendations for the optimal use of popular
LLMs for complex reasoning tasks. We further show that even models specialized
for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in
these settings. These results point to significant limitations in the models'
ability to abstract structured knowledge from unstructured input and highlight
the need for architectural adaptations to improve long-range reasoning.
\\ ( https://arxiv.org/abs/2510.03611 ,  5392kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03639
Date: Sat, 4 Oct 2025 02:56:33 GMT   (1970kb)

Title: Towards Unsupervised Speech Recognition at the Syllable-Level
Authors: Liming Wang, Junrui Ni, Kai-Wei Chang, Saurabhchand Bhati, David
  Harwath, Mark Hasegawa-Johnson, James R. Glass
Categories: cs.CL cs.AI
\\
  Training speech recognizers with unpaired speech and text -- known as
unsupervised speech recognition (UASR) -- is a crucial step toward extending
ASR to low-resource languages in the long-tail distribution and enabling
multimodal learning from non-parallel data. However, existing approaches based
on phones often rely on costly resources such as grapheme-to-phoneme converters
(G2Ps) and struggle to generalize to languages with ambiguous phoneme
boundaries due to training instability. In this paper, we address both
challenges by introducing a syllable-level UASR framework based on masked
language modeling, which avoids the need for G2P and the instability of
GAN-based methods. Our approach achieves up to a 40\% relative reduction in
character error rate (CER) on LibriSpeech and generalizes effectively to
Mandarin, a language that has remained particularly difficult for prior
methods. Code will be released upon acceptance.
\\ ( https://arxiv.org/abs/2510.03639 ,  1970kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03663
Date: Sat, 4 Oct 2025 04:30:13 GMT   (11888kb)

Title: UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG
Authors: Xiangyu Peng, Cab Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Chien-Sheng
  Wu
Categories: cs.CL
\\
  Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.
\\ ( https://arxiv.org/abs/2510.03663 ,  11888kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03683
Date: Sat, 4 Oct 2025 05:38:46 GMT   (1356kb)

Title: Fine-Tuning Large Language Models with QLoRA for Offensive Language
  Detection in Roman Urdu-English Code-Mixed Text
Authors: Nisar Hussain, Amna Qasim, Gull Mehak, Muhammad Zain, Momina Hafeez,
  Grigori Sidorov
Categories: cs.CL
Comments: 25 pages, 22 figures
\\
  The use of derogatory terms in languages that employ code mixing, such as
Roman Urdu, presents challenges for Natural Language Processing systems due to
unstated grammar, inconsistent spelling, and a scarcity of labeled data. In
this work, we propose a QLoRA based fine tuning framework to improve offensive
language detection in Roman Urdu-English text. We translated the Roman
Urdu-English code mixed dataset into English using Google Translate to leverage
English LLMs, while acknowledging that this translation reduces direct
engagement with code mixing features. Our focus is on classification
performance using English translated low resource inputs. We fine tuned several
transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B
v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient
adaptation. Models were trained and evaluated on a manually annotated Roman
Urdu dataset for offensive vs non offensive content. Of all tested models, the
highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral
7B at 89.66, surpassing traditional transformer baselines. These results
demonstrate the efficacy of QLoRA in fine tuning high performing models for low
resource environments such as code mixed offensive language detection, and
confirm the potential of LLMs for this task. This work advances a scalable
approach to Roman Urdu moderation and paves the way for future multilingual
offensive detection systems based on LLMs.
\\ ( https://arxiv.org/abs/2510.03683 ,  1356kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03687
Date: Sat, 4 Oct 2025 06:00:48 GMT   (1263kb)

Title: MedReflect: Teaching Medical LLMs to Self-Improve via Reflective
  Correction
Authors: Yue Huang, Yanyuan Chen, Dexuan Xu, Weihua Yue, Huamin Zhang, Meikang
  Qiu, Yu Huang
Categories: cs.CL cs.AI
\\
  Medical problem solving demands expert knowledge and intricate reasoning.
Recent studies of large language models (LLMs) attempt to ease this complexity
by introducing external knowledge verification through retrieval-augmented
generation or by training on reasoning datasets. However, these approaches
suffer from drawbacks such as retrieval overhead and high annotation costs, and
they heavily rely on substituted external assistants to reach limited
performance in medical field. In this paper, we introduce MedReflect, a
generalizable framework designed to inspire LLMs with a physician-like
reflective thinking mode. MedReflect generates a single-pass reflection chain
that includes initial hypothesis generation, self-questioning, self-answering
and decision refinement. This self-verified and self-reflective nature releases
large language model's latent capability in medical problem-solving without
external retrieval or heavy annotation. We demonstrate that MedReflect enables
cost-efficient medical dataset construction: with merely 2,000 randomly sampled
training examples and a light fine-tuning, this approach achieves notable
absolute accuracy improvements across a series of medical benchmarks while
cutting annotation requirements. Our results provide evidence that LLMs can
learn to solve specialized medical problems via self-reflection and
self-improve, reducing reliance on external supervision and extensive
task-specific fine-tuning data.
\\ ( https://arxiv.org/abs/2510.03687 ,  1263kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03748
Date: Sat, 4 Oct 2025 09:26:30 GMT   (232kb)

Title: TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for
  Improved English-Persian and English-German Translation
Authors: Ramtin Kakavand and Ebrahim Ansari
Categories: cs.CL cs.AI
Comments: 12 pages
\\
  Large Language Models (LLMs) have consistently demonstrated strong
performance in machine translation, especially when guided by high-quality
prompts. Few-shot prompting is an effective technique to improve translation
quality; however, most existing example selection methods focus solely on
query-to-example similarity and do not account for the quality of the examples.
In this work, we propose TreePrompt, a novel example selection approach that
learns LLM preferences to identify high-quality, contextually relevant examples
within a tree-structured framework. To further explore the balance between
similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)
and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -
English-Persian (MIZAN) and English-German (WMT19) - show that integrating
TreePrompt with AFSP or Random selection leads to improved translation
performance.
\\ ( https://arxiv.org/abs/2510.03748 ,  232kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03758
Date: Sat, 4 Oct 2025 09:51:00 GMT   (563kb)

Title: Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's
  Disease Diagnosis from Speech
Authors: Ilias Tougui, Mehdi Zakroum, Mounir Ghogho
Categories: cs.CL cs.SD eess.AS
\\
  Parkinson's Disease (PD) affects over 10 million people worldwide, with
speech impairments in up to 89% of patients. Current speech-based detection
systems analyze entire utterances, potentially overlooking the diagnostic value
of specific phonetic elements. We developed a granularity-aware approach for
multilingual PD detection using an automated pipeline that extracts
time-aligned phonemes, syllables, and words from recordings. Using Italian,
Spanish, and English datasets, we implemented a bidirectional LSTM with
multi-head attention to compare diagnostic performance across the different
granularity levels. Phoneme-level analysis achieved superior performance with
AUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates
enhanced diagnostic capability for cross-linguistic PD detection. Importantly,
attention analysis revealed that the most informative speech features align
with those used in established clinical protocols: sustained vowels (/a/, /e/,
/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)
at syllable level, and /pataka/ sequences at word level. Source code will be
available at https://github.com/jetliqs/clearpd.
\\ ( https://arxiv.org/abs/2510.03758 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03762
Date: Sat, 4 Oct 2025 10:07:14 GMT   (573kb)

Title: Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning
  Affects Multilingual Sense Disambiguation in LLMs
Authors: Deshan Sumanathilaka, Nicholas Micallef, Julian Hough
Categories: cs.CL
Comments: Paper accepted at GlobalNLP 2025: Workshop on beyond English: Natural
  Language Processing for All Languages in an Era of Large Language Models" 9
  pages, 3 figures, 2 Tables
\\
  Recent advances in Large Language Models (LLMs) have significantly reshaped
the landscape of Natural Language Processing (NLP). Among the various prompting
techniques, few-shot prompting has gained considerable attention for its
practicality and effectiveness. This study investigates how few-shot prompting
strategies impact the Word Sense Disambiguation (WSD) task, particularly
focusing on the biases introduced by imbalanced sample distributions. We use
the GLOSSGPT prompting method, an advanced approach for English WSD, to test
its effectiveness across five languages: English, German, Spanish, French, and
Italian. Our results show that imbalanced few-shot examples can cause incorrect
sense predictions in multilingual languages, but this issue does not appear in
English. To assess model behavior, we evaluate both the GPT-4o and
LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual
WSD to sample distribution in few-shot settings, emphasizing the need for
balanced and representative prompting strategies.
\\ ( https://arxiv.org/abs/2510.03762 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03781
Date: Sat, 4 Oct 2025 11:09:10 GMT   (38kb)

Title: Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text
  Processing: A 1.2M Corpus Development
Authors: Majid Asgari-Bidhendi, Muhammad Amin Ghaseminia, Alireza Shahbazi,
  Sayyed Ali Hossayni, Najmeh Torabian, Behrouz Minaei-Bidgoli
Categories: cs.CL cs.AI
Comments: 9 pages, 3 figures
\\
  This paper presents the development of Rezwan, a large-scale AI-assisted
Hadith corpus comprising over 1.2M narrations, extracted and structured through
a fully automated pipeline. Building on digital repositories such as Maktabat
Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for
segmentation, chain--text separation, validation, and multi-layer enrichment.
Each narration is enhanced with machine translation into twelve languages,
intelligent diacritization, abstractive summarization, thematic tagging, and
cross-text semantic analysis. This multi-step process transforms raw text into
a richly annotated research-ready infrastructure for digital humanities and
Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled
narrations, assessed by six domain experts. Results show near-human accuracy in
structured tasks such as chain--text separation (9.33/10) and summarization
(9.33/10), while highlighting ongoing challenges in diacritization and semantic
similarity detection. Comparative analysis against the manually curated Noor
Corpus demonstrates the superiority of Najm in both scale and quality, with a
mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis
confirms the economic feasibility of the AI approach: tasks requiring over
229,000 hours of expert labor were completed within months at a fraction of the
cost. The work introduces a new paradigm in religious text processing by
showing how AI can augment human expertise, enabling large-scale, multilingual,
and semantically enriched access to Islamic heritage.
\\ ( https://arxiv.org/abs/2510.03781 ,  38kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03799
Date: Sat, 4 Oct 2025 12:39:39 GMT   (60kb)

Title: Mechanistic Interpretability of Socio-Political Frames in Language
  Models
Authors: Hadi Asghari, Sami Nenno
Categories: cs.CL cs.AI cs.CY
Comments: Peer-reviewed and presented at Advances in Interpretable Machine
  Learning and Artificial Intelligence (AIMLAI) Workshop at ECML/PKDD 2024
\\
  This paper explores the ability of large language models to generate and
recognize deep cognitive frames, particularly in socio-political contexts. We
demonstrate that LLMs are highly fluent in generating texts that evoke specific
frames and can recognize these frames in zero-shot settings. Inspired by
mechanistic interpretability research, we investigate the location of the
`strict father' and `nurturing parent' frames within the model's hidden
representation, identifying singular dimensions that correlate strongly with
their presence. Our findings contribute to understanding how LLMs capture and
express meaningful human concepts.
\\ ( https://arxiv.org/abs/2510.03799 ,  60kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03805
Date: Sat, 4 Oct 2025 13:24:26 GMT   (1182kb)

Title: Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in
  Large Language Models
Authors: Canhui Wu, Qiong Cao, Chang Li, Zhenfang Wang, Chao Xue, Yuwei Fan,
  Wei Xi, and Xiaodong He
Categories: cs.CL cs.AI
Comments: 20pages, 7 figures
ACM-class: I.2.7
\\
  Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks
but often suffer from excessive verbosity, known as "overthinking." Existing
solutions via reinforcement learning (RL) typically penalize generated tokens
to promote conciseness. However, these methods encounter two challenges:
responses with fewer tokens do not always correspond to fewer reasoning steps,
and models may develop hacking behavior in later stages of training by
discarding reasoning steps to minimize token usage. In this work, we introduce
\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more
efficient reasoning by favoring compact reasoning steps. Our step-aware reward
function prioritizes correctness while imposing penalties for redundant steps,
and withholds rewards for incorrect responses to prevent the reinforcement of
erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when
the length of any output step exceeds the upper limit, we halt updates to
prevent hacking behavior caused by merging steps. Extensive experiments across
four reasoning benchmarks demonstrate that SP achieves state-of-the-art
accuracy while significantly reducing response length. For instance, on AIME24,
SP reduces token usage by \textbf{69.7\%}.
\\ ( https://arxiv.org/abs/2510.03805 ,  1182kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03808
Date: Sat, 4 Oct 2025 13:33:42 GMT   (428kb)

Title: Annotate Rhetorical Relations with INCEpTION: A Comparison with
  Automatic Approaches
Authors: Mehedi Hasan Emon
Categories: cs.CL
\\
  This research explores the annotation of rhetorical relations in discourse
using the INCEpTION tool and compares manual annotation with automatic
approaches based on large language models. The study focuses on sports reports
(specifically cricket news) and evaluates the performance of BERT, DistilBERT,
and Logistic Regression models in classifying rhetorical relations such as
elaboration, contrast, background, and cause-effect. The results show that
DistilBERT achieved the highest accuracy, highlighting its potential for
efficient discourse relation prediction. This work contributes to the growing
intersection of discourse parsing and transformer-based NLP. (This paper was
conducted as part of an academic requirement under the supervision of Prof. Dr.
Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:
Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,
NLP.
\\ ( https://arxiv.org/abs/2510.03808 ,  428kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03898
Date: Sat, 4 Oct 2025 18:34:34 GMT   (3899kb)

Title: Read Between the Lines: A Benchmark for Uncovering Political Bias in
  Bangla News Articles
Authors: Nusrat Jahan Lia, Shubhashis Roy Dipta, Abdullah Khan Zehady, Naymul
  Islam, Madhusodan Chakraborty, Abdullah Al Wasif
Categories: cs.CL
\\
  Detecting media bias is crucial, specifically in the South Asian region.
Despite this, annotated datasets and computational studies for Bangla political
bias research remain scarce. Crucially because, political stance detection in
Bangla news requires understanding of linguistic cues, cultural context, subtle
biases, rhetorical strategies, code-switching, implicit sentiment, and
socio-political background. To address this, we introduce the first benchmark
dataset of 200 politically significant and highly debated Bangla news articles,
labeled for government-leaning, government-critique, and neutral stances,
alongside diagnostic analyses for evaluating large language models (LLMs). Our
comprehensive evaluation of 28 proprietary and open-source LLMs shows strong
performance in detecting government-critique content (F1 up to 0.83) but
substantial difficulty with neutral articles (F1 as low as 0.00). Models also
tend to over-predict government-leaning stances, often misinterpreting
ambiguous narratives. This dataset and its associated diagnostics provide a
foundation for advancing stance detection in Bangla media research and offer
insights for improving LLM performance in low-resource languages.
\\ ( https://arxiv.org/abs/2510.03898 ,  3899kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03913
Date: Sat, 4 Oct 2025 19:40:10 GMT   (836kb)

Title: PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small
  Language Models in Persian
Authors: Mohammad Amin Abbasi, Hassan Naderi
Categories: cs.CL
\\
  This study presents PsychoLexTherapy, a framework for simulating
psychotherapeutic reasoning in Persian using small language models (SLMs). The
framework tackles the challenge of developing culturally grounded,
therapeutically coherent dialogue systems with structured memory for multi-turn
interactions in underrepresented languages. To ensure privacy and feasibility,
PsychoLexTherapy is optimized for on-device deployment, enabling use without
external servers. Development followed a three-stage process: (i) assessing
SLMs psychological knowledge with PsychoLexEval; (ii) designing and
implementing the reasoning-oriented PsychoLexTherapy framework; and (iii)
constructing two evaluation datasets-PsychoLexQuery (real Persian user
questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark
against multiple baselines. Experiments compared simple prompting, multi-agent
debate, and structured therapeutic reasoning paths. Results showed that
deliberate model selection balanced accuracy, efficiency, and privacy. On
PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic
LLM-as-a-judge evaluation and was ranked highest by human evaluators in a
single-turn preference study. In multi-turn tests with PsychoLexDialogue, the
long-term memory module proved essential: while naive history concatenation
caused incoherence and information loss, the full framework achieved the
highest ratings in empathy, coherence, cultural fit, and personalization.
Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and
culturally aligned foundation for Persian psychotherapy simulation,
contributing novel datasets, a reproducible evaluation pipeline, and empirical
insights into structured memory for therapeutic reasoning.
\\ ( https://arxiv.org/abs/2510.03913 ,  836kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03997
Date: Sun, 5 Oct 2025 02:16:35 GMT   (397kb)

Title: Mapping Patient-Perceived Physician Traits from Nationwide Online
  Reviews with LLMs
Authors: Junjie Luo, Rui Han, Arshana Welivita, Zeleikun Di, Jingfu Wu, Xuzhe
  Zhi, Ritu Agarwal, Gordon Gao
Categories: cs.CL
\\
  Understanding how patients perceive their physicians is essential to
improving trust, communication, and satisfaction. We present a large language
model (LLM)-based pipeline that infers Big Five personality traits and five
patient-oriented subjective judgments. The analysis encompasses 4.1 million
patient reviews of 226,999 U.S. physicians from an initial pool of one million.
We validate the method through multi-model comparison and human expert
benchmarking, achieving strong agreement between human and LLM assessments
(correlation coefficients 0.72-0.89) and external validity through correlations
with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis
reveals systematic patterns: male physicians receive higher ratings across all
traits, with largest disparities in clinical competence perceptions;
empathy-related traits predominate in pediatrics and psychiatry; and all traits
positively predict overall satisfaction. Cluster analysis identifies four
distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly
high traits) to "Underperforming" (22.6%, consistently low). These findings
demonstrate that automated trait extraction from patient narratives can provide
interpretable, validated metrics for understanding physician-patient
relationships at scale, with implications for quality measurement, bias
detection, and workforce development in healthcare.
\\ ( https://arxiv.org/abs/2510.03997 ,  397kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03999
Date: Sun, 5 Oct 2025 02:18:23 GMT   (422kb)

Title: Simulating and Understanding Deceptive Behaviors in Long-Horizon
  Interactions
Authors: Yang Xu, Xuanming Zhang, Min-Hsuan Yeh, Jwala Dhamala, Ousmane Dia,
  Rahul Gupta, Yixuan Li
Categories: cs.CL
\\
  Deception is a pervasive feature of human communication and an emerging
concern in large language models (LLMs). While recent studies document
instances of LLM deception under pressure, most evaluations remain confined to
single-turn prompts and fail to capture the long-horizon interactions in which
deceptive strategies typically unfold. We introduce the first simulation
framework for probing and evaluating deception in LLMs under extended sequences
of interdependent tasks and dynamic contextual pressures. Our framework
instantiates a multi-agent system: a performer agent tasked with completing
tasks and a supervisor agent that evaluates progress, provides feedback, and
maintains evolving states of trust. An independent deception auditor then
reviews full trajectories to identify when and how deception occurs. We conduct
extensive experiments across 11 frontier models, spanning both closed- and
open-source systems, and find that deception is model-dependent, increases with
event pressure, and consistently erodes supervisor trust. Qualitative analyses
further reveal distinct strategies of concealment, equivocation, and
falsification. Our findings establish deception as an emergent risk in
long-horizon interactions and provide a foundation for evaluating future LLMs
in real-world, trust-sensitive contexts.
\\ ( https://arxiv.org/abs/2510.03999 ,  422kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04001
Date: Sun, 5 Oct 2025 02:22:26 GMT   (156kb)

Title: Named Entity Recognition in COVID-19 tweets with Entity Knowledge
  Augmentation
Authors: Xuankang Zhang and Jiangming Liu
Categories: cs.CL cs.AI
Comments: Work in progress
\\
  The COVID-19 pandemic causes severe social and economic disruption around the
world, raising various subjects that are discussed over social media.
Identifying pandemic-related named entities as expressed on social media is
fundamental and important to understand the discussions about the pandemic.
However, there is limited work on named entity recognition on this topic due to
the following challenges: 1) COVID-19 texts in social media are informal and
their annotations are rare and insufficient to train a robust recognition
model, and 2) named entity recognition in COVID-19 requires extensive
domain-specific knowledge. To address these issues, we propose a novel entity
knowledge augmentation approach for COVID-19, which can also be applied in
general biomedical named entity recognition in both informal text format and
formal text format. Experiments carried out on the COVID-19 tweets dataset and
PubMed dataset show that our proposed entity knowledge augmentation improves
NER performance in both fully-supervised and few-shot settings. Our source code
is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master
\\ ( https://arxiv.org/abs/2510.04001 ,  156kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04002
Date: Sun, 5 Oct 2025 02:30:11 GMT   (5255kb)

Title: AgriGPT-VL: Agricultural Vision-Language Understanding Suite
Authors: Bo Yang, Yunkui Chen, Lanfei Feng, Yu Zhang, Xiao Xu, Jianyu Zhang,
  Nueraili Aierken, Runhe Huang, Hongjian Lin, Yibin Ying, Shijian Li
Categories: cs.CL
\\
  Despite rapid advances in multimodal large language models, agricultural
applications remain constrained by the scarcity of domain-tailored models,
curated vision-language corpora, and rigorous evaluation. To address these
challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for
agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,
the largest vision-language corpus for agriculture to our knowledge, curated by
a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M
image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO
reinforcement learning samples. Second, we develop AgriGPT-VL, an
agriculture-specialized vision-language model trained via a progressive
curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO
refinement. This method achieves strong multimodal reasoning while preserving
text-only capability. Third, we establish AgriBench-VL-4K, a compact yet
challenging evaluation suite with open-ended and image-grounded questions,
paired with multi-metric evaluation and an LLM-as-a-judge framework.
Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on
AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge
evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K
with no noticeable degradation of language ability. Ablation studies further
confirm consistent gains from our alignment and GRPO refinement stages. We will
open source all of the resources to support reproducible research and
deployment in low-resource agricultural settings.
\\ ( https://arxiv.org/abs/2510.04002 ,  5255kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04013
Date: Sun, 5 Oct 2025 03:14:05 GMT   (7027kb)

Title: LLM Microscope: What Model Internals Reveal About Answer Correctness and
  Context Utilization
Authors: Jiarui Liu, Jivitesh Jain, Mona Diab, Nishant Subramani
Categories: cs.CL
\\
  Although large language models (LLMs) have tremendous utility,
trustworthiness is still a chief concern: models often generate incorrect
information with high confidence. While contextual information can help guide
generation, identifying when a query would benefit from retrieved context and
assessing the effectiveness of that context remains challenging. In this work,
we operationalize interpretability methods to ascertain whether we can predict
the correctness of model outputs from the model's activations alone. We also
explore whether model internals contain signals about the efficacy of external
context. We consider correct, incorrect, and irrelevant context and introduce
metrics to distinguish amongst them. Experiments on six different models reveal
that a simple classifier trained on intermediate layer activations of the first
output token can predict output correctness with about 75% accuracy, enabling
early auditing. Our model-internals-based metric significantly outperforms
prompting baselines at distinguishing between correct and incorrect context,
guarding against inaccuracies introduced by polluted context. These findings
offer a lens to better understand the underlying decision-making processes of
LLMs. Our code is publicly available at
https://github.com/jiarui-liu/LLM-Microscope
\\ ( https://arxiv.org/abs/2510.04013 ,  7027kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04016
Date: Sun, 5 Oct 2025 03:31:59 GMT   (190kb)

Title: Thai Semantic End-of-Turn Detection for Real-Time Voice Agents
Authors: Thanapol Popit, Natthapath Rungseesiripak, Monthol Charattrakool,
  Saksorn Ruangtanusak
Categories: cs.CL cs.AI
Comments: IEEE ICSEC 2025
\\
  Fluid voice-to-voice interaction requires reliable and low-latency detection
of when a user has finished speaking. Traditional audio-silence end-pointers
add hundreds of milliseconds of delay and fail under hesitations or
language-specific phenomena. We present, to our knowledge, the first systematic
study of Thai text-only end-of-turn (EOT) detection for real-time agents. We
compare zero-shot and few-shot prompting of compact LLMs to supervised
fine-tuning of lightweight transformers. Using transcribed subtitles from the
YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final
particles), we formulate EOT as a binary decision over token boundaries. We
report a clear accuracy-latency tradeoff and provide a public-ready
implementation plan. This work establishes a Thai baseline and demonstrates
that small, fine-tuned models can deliver near-instant EOT decisions suitable
for on-device agents.
\\ ( https://arxiv.org/abs/2510.04016 ,  190kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04031
Date: Sun, 5 Oct 2025 04:45:53 GMT   (210kb)

Title: Does Using Counterfactual Help LLMs Explain Textual Importance in
  Classification?
Authors: Nelvin Tan, James Asikin Cheung, Yu-Ching Shih, Dong Yang, Amol
  Salunkhe
Categories: cs.CL cs.AI
Comments: 8 pages, 2 figures
\\
  Large language models (LLMs) are becoming useful in many domains due to their
impressive abilities that arise from large training datasets and large model
sizes. More recently, they have been shown to be very effective in textual
classification tasks, motivating the need to explain the LLMs' decisions.
Motivated by practical constrains where LLMs are black-boxed and LLM calls are
expensive, we study how incorporating counterfactuals into LLM reasoning can
affect the LLM's ability to identify the top words that have contributed to its
classification decision. To this end, we introduce a framework called the
decision changing rate that helps us quantify the importance of the top words
in classification. Our experimental results show that using counterfactuals can
be helpful.
\\ ( https://arxiv.org/abs/2510.04031 ,  210kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04032
Date: Sun, 5 Oct 2025 04:46:30 GMT   (28kb)

Title: Small Language Models for Emergency Departments Decision Support: A
  Benchmark Study
Authors: Zirui Wang, Jiajun Wu, Braden Teitge, Jessalyn Holodinsky, Steve Drew
Categories: cs.CL cs.AI
Comments: Accepted to 2025 IEEE International Conference on Autonomous and
  Trusted Computing (ATC 2025)
\\
  Large language models (LLMs) have become increasingly popular in medical
domains to assist physicians with a variety of clinical and operational tasks.
Given the fast-paced and high-stakes environment of emergency departments
(EDs), small language models (SLMs), characterized by a reduction in parameter
count compared to LLMs, offer significant potential due to their inherent
reasoning capability and efficient performance. This enables SLMs to support
physicians by providing timely and accurate information synthesis, thereby
improving clinical decision-making and workflow efficiency. In this paper, we
present a comprehensive benchmark designed to identify SLMs suited for ED
decision support, taking into account both specialized medical expertise and
broad general problem-solving capabilities. In our evaluations, we focus on
SLMs that have been trained on a mixture of general-domain and medical corpora.
A key motivation for emphasizing SLMs is the practical hardware limitations,
operational cost constraints, and privacy concerns in the typical real-world
deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and
PubMedQA, with the medical abstracts dataset emulating tasks aligned with real
ED physicians' daily tasks. Experimental results reveal that general-domain
SLMs surprisingly outperform their medically fine-tuned counterparts across
these diverse benchmarks for ED. This indicates that for ED, specialized
medical fine-tuning of the model may not be required.
\\ ( https://arxiv.org/abs/2510.04032 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04045
Date: Sun, 5 Oct 2025 05:39:50 GMT   (725kb)

Title: Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment
Authors: Yunfan Zhang, Kathleen McKeown, Smaranda Muresan
Categories: cs.CL cs.LG
Comments: ACL EMNLP 2025
\\
  Large Language Models (LLMs) are typically trained to reflect a relatively
uniform set of values, which limits their applicability to tasks that require
understanding of nuanced human perspectives. Recent research has underscored
the importance of enabling LLMs to support steerable pluralism -- the capacity
to adopt a specific perspective and align generated outputs with it. In this
work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be
applied to building steerable pluralistic models. We explore several methods,
including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on
synthetic explanations, and Reinforcement Learning with Verifiable Rewards
(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA
datasets. Among the methods studied, RLVR consistently outperforms others and
demonstrates strong training sample efficiency. We further analyze the
generated CoT traces with respect to faithfulness and safety.
\\ ( https://arxiv.org/abs/2510.04045 ,  725kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04071
Date: Sun, 5 Oct 2025 07:22:44 GMT   (2294kb)

Title: What Makes Diffusion Language Models Super Data Learners?
Authors: Zitian Gao, Haoming Luo, Lynx Chen, Jason Klein Liu, Ran Tao, Joey
  Zhou, Bryan Dai
Categories: cs.CL
Comments: Technical report, work in progress
\\
  Recent studies have shown that diffusion language models achieve remarkable
data efficiency under limited-data constraints, yet the underlying mechanisms
remain unclear. In this work, we perform extensive ablation experiments to
disentangle the sources of this efficiency. Our results show that random
masking of input tokens plays the dominant role. We further show that similar
gains can be obtained through in MLP dropout and weight decay, indicating that
stochastic regularization broadly enhances data efficiency in multi-epoch
training. Our code is available at
https://github.com/zitian-gao/data-efficiency.
\\ ( https://arxiv.org/abs/2510.04071 ,  2294kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04080
Date: Sun, 5 Oct 2025 07:57:26 GMT   (16966kb)

Title: PoLi-RL: A Point-to-List Reinforcement Learning Framework for
  Conditional Semantic Textual Similarity
Authors: Zixin Song, Bowen Zhang, Qian-Wen Zhang, Di Yin, Xing Sun and Chunping
  Li
Categories: cs.CL
\\
  Conditional Semantic Textual Similarity (C-STS) measures the semantic
proximity between text segments under a specific condition, thereby overcoming
the ambiguity inherent in traditional STS. However, existing methods are
largely confined to discriminative models, failing to fully integrate recent
breakthroughs in the NLP community concerning Large Language Models (LLMs) and
Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this
task, as it can directly optimize the non-differentiable Spearman ranking
metric and guide the reasoning process required by C-STS. However, we find that
naively applying listwise RL fails to produce meaningful improvements, as the
model is overwhelmed by complex, coarse-grained reward signals. To address this
challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning
framework. PoLi-RL employs a two-stage curriculum: it first trains the model
with simple pointwise rewards to establish fundamental scoring capabilities,
then transitions to a hybrid reward that combines pointwise, pairwise, and
listwise objectives to refine the model's ability to discern subtle semantic
distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward
(PSRR) mechanism that computes ranking rewards in parallel slices, where each
slice comprises same-indexed completions from different samples. This provides
a precise, differentiated learning signal for each individual completion,
enabling granular credit assignment and effective optimization. On the official
C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18,
establishing a new SOTA for the cross-encoder architecture. As the first work
to successfully apply RL to C-STS, our study introduces a powerful and precise
paradigm for training LLMs on complex, ranking-based conditional judgment
tasks.
\\ ( https://arxiv.org/abs/2510.04080 ,  16966kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04081
Date: Sun, 5 Oct 2025 07:59:24 GMT   (1325kb)

Title: Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model
  Reasoning
Authors: Honglin Lin, Qizhi Pei, Xin Gao, Zhuoshi Pan, Yu Li, Juntao Li,
  Conghui He, Lijun Wu
Categories: cs.CL cs.PL
Comments: Accepted by NeurIPS2025
\\
  Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.
\\ ( https://arxiv.org/abs/2510.04081 ,  1325kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04120
Date: Sun, 5 Oct 2025 09:45:51 GMT   (3715kb)

Title: Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual
  Irrelevance, Context Leveraging and Syntactic Influence
Authors: Fengying Ye, Shanshan Wang, Lidia S. Chao, Derek F. Wong
Categories: cs.CL cs.AI
\\
  Metaphor analysis is a complex linguistic phenomenon shaped by context and
external factors. While Large Language Models (LLMs) demonstrate advanced
capabilities in knowledge integration, contextual reasoning, and creative
generation, their mechanisms for metaphor comprehension remain insufficiently
explored. This study examines LLMs' metaphor-processing abilities from three
perspectives: (1) Concept Mapping: using embedding space projections to
evaluate how LLMs map concepts in target domains (e.g., misinterpreting "fall
in love" as "drop down from love"); (2) Metaphor-Literal Repository: analyzing
metaphorical words and their literal counterparts to identify inherent
metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how
metaphorical syntactic structures influence LLMs' performance. Our findings
reveal that LLMs generate 15\%-25\% conceptually irrelevant interpretations,
depend on metaphorical indicators in training data rather than contextual cues,
and are more sensitive to syntactic irregularities than to structural
comprehension. These insights underline the limitations of LLMs in metaphor
analysis and call for more robust computational approaches.
\\ ( https://arxiv.org/abs/2510.04120 ,  3715kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04124
Date: Sun, 5 Oct 2025 09:57:40 GMT   (12kb)

Title: Sri Lanka Document Datasets: A Large-Scale, Multilingual Resource for
  Law, News, and Policy (v20251005)
Authors: Nuwan I. Senaratna
Categories: cs.CL
Comments: 4 pages
\\
  We present a collection of open, machine-readable document datasets covering
parliamentary proceedings, legal judgments, government publications, news, and
tourism statistics from Sri Lanka. As of v20251005, the collection currently
comprises 215,670 documents (60.3 GB) across 13 datasets in Sinhala, Tamil, and
English. The datasets are updated daily and mirrored on GitHub and Hugging
Face. These resources aim to support research in computational linguistics,
legal analytics, socio-political studies, and multilingual natural language
processing. We describe the data sources, collection pipeline, formats, and
potential use cases, while discussing licensing and ethical considerations.
\\ ( https://arxiv.org/abs/2510.04124 ,  12kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04139
Date: Sun, 5 Oct 2025 10:36:36 GMT   (1268kb)

Title: Fine Tuning Methods for Low-resource Languages
Authors: Tim Bakkenes, Daniel Wang, and Anton Johansson
Categories: cs.CL cs.LG
\\
  The rise of Large Language Models has not been inclusive of all cultures. The
models are mostly trained on English texts and culture which makes them
underperform in other languages and cultural contexts. By developing a
generalizable method for preparing culturally relevant datasets and
post-training the Gemma 2 model, this project aimed to increase the performance
of Gemma 2 for an underrepresented language and showcase how others can do the
same to unlock the power of Generative AI in their country and preserve their
cultural heritage.
\\ ( https://arxiv.org/abs/2510.04139 ,  1268kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04147
Date: Sun, 5 Oct 2025 10:52:28 GMT   (344kb)

Title: Self Speculative Decoding for Diffusion Large Language Models
Authors: Yifeng Gao, Ziang Ji, Yuxuan Wang, Biqing Qi, Hanlin Xu, Linfeng Zhang
Categories: cs.CL
\\
  Diffusion-based Large Language Models (dLLMs) have emerged as a competitive
alternative to autoregressive models, offering unique advantages through
bidirectional attention and parallel generation paradigms. However, the
generation results of current parallel decoding methods deviate from stepwise
decoding, introducing potential performance degradation, which limits their
practical deployment. To address this problem, we propose \textbf{S}elf
\textbf{S}peculative \textbf{D}ecoding (SSD), a lossless inference acceleration
method that leverages the dLLM itself as both speculative decoding drafter and
verifier without auxiliary modules. SSD introduces a self-drafting mechanism
where the model generates predictions for multiple positions, then verifies
them through hierarchical verification trees in a single forward pass. Unlike
traditional speculative decoding that requires separate draft models, SSD
eliminates model redundancy and memory overhead by exploiting the dLLM's
inherent parallel prediction capability for multiple positions. This
self-speculative approach allows the model to progressively verify and accept
multiple tokens in a single forward pass. Our experiments demonstrate that SSD
achieves up to 3.46$\times$ speedup while keeping the output identical to
stepwise decoding on open source models such as LLaDA and Dream. Code will be
made publicly available on GitHub.
\\ ( https://arxiv.org/abs/2510.04147 ,  344kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04182
Date: Sun, 5 Oct 2025 12:50:39 GMT   (1332kb)

Title: Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought
  Policy Optimization
Authors: Wengao Ye, Yan Liang, Lianlei Shan
Categories: cs.CL cs.AI
\\
  Recent advancements in Large Language Models (LLMs) have shifted from
explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning,
where intermediate thoughts are represented as vectors rather than text.
However, latent reasoning can be brittle on challenging, out-of-distribution
tasks where robust reasoning is most critical. To overcome these limitations,
we introduce Latent Thought Policy Optimization (LTPO), a parameter-free
framework that enhances LLM reasoning entirely at test time, without requiring
model parameter updates. LTPO treats intermediate latent "thought" vectors as
dynamic parameters that are actively optimized for each problem instance. It
employs an online policy gradient method guided by an intrinsic,
confidence-based reward signal computed directly from the frozen LLM's own
output distributions, eliminating the need for external supervision or
expensive text generation during optimization. Extensive experiments on five
reasoning benchmarks show that LTPO not only matches or surpasses strong
baselines on standard tasks but also demonstrates remarkable robustness where
others fail. Most notably, on highly challenging AIME benchmarks where existing
latent reasoning baselines collapse to near-zero accuracy, LTPO delivers
substantial improvements, showcasing a unique capability for complex reasoning.
\\ ( https://arxiv.org/abs/2510.04182 ,  1332kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04204
Date: Sun, 5 Oct 2025 13:38:31 GMT   (5517kb)

Title: CALM Before the STORM: Unlocking Native Reasoning for Optimization
  Modeling
Authors: Zhengyang Tang, Zihan Ye, Chenyu Huang, Xuhan Huang, Chengpeng Li,
  Sihang Li, Guanhua Chen, Ming Yan, Zizhuo Wang, Hongyuan Zha, Dayiheng Liu,
  Benyou Wang
Categories: cs.CL cs.AI cs.CE cs.LG
Comments: Work in progress
\\
  Large Reasoning Models (LRMs) have demonstrated strong capabilities in
complex multi-step reasoning, opening new opportunities for automating
optimization modeling. However, existing domain adaptation methods, originally
designed for earlier instruction-tuned models, often fail to exploit the
advanced reasoning patterns of modern LRMs -- In particular, we show that
direct fine-tuning on traditional \textit{non-reflective} datasets leads to
limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose
\textbf{CALM} (\textit{Corrective Adaptation with Lightweight Modification}), a
framework that progressively refines LRMs within their native reasoning modes
for optimization modeling tasks. In CALM, an expert intervener identifies
reasoning flaws and provides concise corrective hints, which the LRM
incorporates to produce improved reasoning trajectories. These interventions
modify fewer than 2.6\% of generated tokens, but generate high-quality data for
soft adaptation through supervised fine-tuning. The adapted model is then
further improved through reinforcement learning. Building on CALM, we develop
\textbf{STORM} (\textit{Smart Thinking Optimization Reasoning Model}), a
4B-parameter LRM that achieves a new state-of-the-art average accuracy of
68.9\% across five popular optimization modeling benchmarks, matching the
performance of a 671B LRM. These results demonstrate that dynamic, hint-based
data synthesis both preserves and amplifies the native reasoning patterns of
modern LRMs, offering a more effective and scalable path towards expert-level
performance on challenging optimization modeling tasks.
\\ ( https://arxiv.org/abs/2510.04204 ,  5517kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04214
Date: Sun, 5 Oct 2025 14:08:01 GMT   (2577kb)

Title: Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for
  Alignment frm Heterogeneous Rewards
Authors: Zhuoran Zhuang, Ye Chen, Xia Zeng, Chao Luo, Luhui Liu, Yihan Chen
Categories: cs.CL
\\
  We study deploying large language models (LLMs) as business development (BD)
agents for persuasive price negotiation in online travel agencies (OTAs), where
aligning traveler affordability and hotel profitability directly affects
bookings, partner relationships, and access to travel. The agent must follow a
Standard Operating Procedure (SOP) while conducting multi-turn persuasion,
interpreting colloquial inputs, and adhering to guardrails (no over-promising,
no hallucinations). Conventional post-training -- supervised fine-tuning (SFT)
or single-source reward optimization -- overfits scripts, misses nuanced
persuasive style, and fails to enforce verifiable business constraints.
  We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement
learning post-training framework that aligns an LLM with heterogeneous rewards:
a preference-trained reward model (RM) for dense human alignment, a reward
judge (RJ) for high-level persuasive behavior and SOP compliance, and
programmatic reward functions (RF) for deterministic checks on numerics,
formatting, and guardrails. A straightforward enhancement mechanism is proposed
to combine the RM with RJ and RF signals to curb reward hacking and improve
negotiation quality. In production-style evaluations -- approximately 150 turns
from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts
average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference
Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO),
increases the share of conversations with at least one excellent response to
66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix
rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also
observe emergent capabilities -- proactive empathy, localized reasoning,
calibrated tactics -- that surpass gold annotations.
\\ ( https://arxiv.org/abs/2510.04214 ,  2577kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04226
Date: Sun, 5 Oct 2025 14:29:15 GMT   (305kb)

Title: Epistemic Diversity and Knowledge Collapse in Large Language Models
Authors: Dustin Wright, Sarah Masud, Jared Moore, Srishti Yadav, Maria
  Antoniak, Chan Young Park, Isabelle Augenstein
Categories: cs.CL cs.AI cs.CY cs.IR cs.LG
Comments: 16 pages; 8 figures, 4 tables
\\
  Large language models (LLMs) tend to generate lexically, semantically, and
stylistically homogenous texts. This poses a risk of knowledge collapse, where
homogenous LLMs mediate a shrinking in the range of accessible information over
time. Existing works on homogenization are limited by a focus on closed-ended
multiple-choice setups or fuzzy semantic features, and do not look at trends
across time and cultural contexts. To overcome this, we present a new
methodology to measure epistemic diversity, i.e., variation in real-world
claims in LLM outputs, which we use to perform a broad empirical study of LLM
knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200
prompt variations sourced from real user chats. For the topics in our study, we
show that while newer models tend to generate more diverse claims, nearly all
models are less epistemically diverse than a basic web search. We find that
model size has a negative impact on epistemic diversity, while
retrieval-augmented generation (RAG) has a positive impact, though the
improvement from RAG varies by the cultural context. Finally, compared to a
traditional knowledge source (Wikipedia), we find that country-specific claims
reflect the English language more than the local one, highlighting a gap in
epistemic representation
\\ ( https://arxiv.org/abs/2510.04226 ,  305kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04230
Date: Sun, 5 Oct 2025 14:39:41 GMT   (1961kb)

Title: Pushing on Multilingual Reasoning Models with Language-Mixed
  Chain-of-Thought
Authors: Guijin Son, Donghun Yang, Hitesh Laxmichand Patel, Amit Agarwal,
  Hyunwoo Ko, Chanuk Lim, Srikant Panda, Minhyuk Kim, Nikunj Drolia, Dasol
  Choi, Kyong-Ha Lee, Youngjae Yu
Categories: cs.CL
Comments: Work in Progress
\\
  Recent frontier models employ long chain-of-thought reasoning to explore
solution spaces in context and achieve stonger performance. While many works
study distillation to build smaller yet capable models, most focus on English
and little is known about language-specific reasoning. To bridge this gap, we
first introduct **Language-Mixed CoT**, a reasoning schema that switches
between English and a target language, using English as an anchor to excel in
reasoning while minimizing translation artificats. As a Korean case study, we
curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and
code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k
high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5,
Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves
state-of-the-art performance, with the highest overall average score (64.0 \pm
25), ranking first on 5/9 benchmarks and second on the remainder. Samller and
mid-sized models also benefit substantially, with an average improvement of
+18.6 points across teh evaluated nine benchmarks. Ablations show
**Language-Mixed CoT** is more effective than monolingual CoT, also resulting
in cross-lingual and mult-modal performance gains. We release our data-curation
pipeline, evaluation system, datasets, and models to advance research on
language-specific reasoning. Data and model collection:
https://huggingface.co/KOREAson.
\\ ( https://arxiv.org/abs/2510.04230 ,  1961kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04268
Date: Sun, 5 Oct 2025 16:17:33 GMT   (744kb)

Title: LongTail-Swap: benchmarking language models' abilities on rare words
Authors: Robin Algayres and Charles-\'Eric Saint-James and Mahi Luthra and
  Jiayi Shen and Dongyan Lin and Youssef Benchekroun and Rashel Moritz and Juan
  Pino and Emmanuel Dupoux
Categories: cs.CL cs.AI
\\
  Children learn to speak with a low amount of data and can be taught new words
on a few-shot basis, making them particularly data-efficient learners. The
BabyLM challenge aims at exploring language model (LM) training in the low-data
regime but uses metrics that concentrate on the head of the word distribution.
Here, we introduce LongTail-Swap (LT-Swap), a benchmark that focuses on the
tail of the distribution, i.e., measures the ability of LMs to learn new words
with very little exposure, like infants do. LT-Swap is a pretraining
corpus-specific test set of acceptable versus unacceptable sentence pairs that
isolate semantic and syntactic usage of rare words. Models are evaluated in a
zero-shot fashion by computing the average log probabilities over the two
members of each pair. We built two such test sets associated with the 10M words
and 100M words BabyLM training sets, respectively, and evaluated 16 models from
the BabyLM leaderboard. Our results not only highlight the poor performance of
language models on rare words but also reveal that performance differences
across LM architectures are much more pronounced in the long tail than in the
head. This offers new insights into which architectures are better at handling
rare word generalization. We've also made the code publicly avail
\\ ( https://arxiv.org/abs/2510.04268 ,  744kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04285
Date: Sun, 5 Oct 2025 16:55:58 GMT   (3863kb)

Title: Probing Geometry of Next Token Prediction Using Cumulant Expansion of
  the Softmax Entropy
Authors: Karthik Viswanathan and Sang Eon Park
Categories: cs.CL cond-mat.stat-mech cs.LG stat.ML
Comments: 14 pages, 7 figures. Poster at HiLD 2025: 3rd Workshop on
  High-dimensional Learning Dynamics
\\
  We introduce a cumulant-expansion framework for quantifying how large
language models (LLMs) internalize higher-order statistical structure during
next-token prediction. By treating the softmax entropy of each layer's logit
distribution as a perturbation around its "center" distribution, we derive
closed-form cumulant observables that isolate successively higher-order
correlations. Empirically, we track these cumulants in GPT-2 and Pythia models
on Pile-10K prompts. (i) Structured prompts exhibit a characteristic
rise-and-plateau profile across layers, whereas token-shuffled prompts remain
flat, revealing the dependence of the cumulant profile on meaningful context.
(ii) During training, all cumulants increase monotonically before saturating,
directly visualizing the model's progression from capturing variance to
learning skew, kurtosis, and higher-order statistical structures. (iii)
Mathematical prompts show distinct cumulant signatures compared to general
text, quantifying how models employ fundamentally different processing
mechanisms for mathematical versus linguistic content. Together, these results
establish cumulant analysis as a lightweight, mathematically grounded probe of
feature-learning dynamics in high-dimensional neural networks.
\\ ( https://arxiv.org/abs/2510.04285 ,  3863kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04286
Date: Sun, 5 Oct 2025 16:57:32 GMT   (7718kb)

Title: SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained
  and Balanced Transformer Scaling
Authors: Harshil Vejendla
Categories: cs.CL cs.AI cs.LG
Comments: EMNLP 2025 Main, 8 pages, 9 figures
\\
  Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a
sparse subset of feed-forward experts. Token-level routing, however, assigns an
entire semantic spectrum to each expert, creating capacity bottlenecks,
load-balancing pathologies, and limited specialization. We introduce SliceMoE,
an architecture that routes contiguous slices of a token's hidden vector. A
d-dimensional embedding is partitioned into S slices, and for each slice, a
lightweight shared router predicts the top-k experts. Experts operate on their
assigned slices independently, and outputs are reassembled, maintaining
per-token FLOP efficiency. Because slices from different tokens interleave
within an expert, utilization is naturally smoother. We propose a slice-level
capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels.
Experiments on WikiText-103 language modeling, WMT En-De translation, and three
text-classification datasets show SliceMoE attains up to 1.7x faster inference
than dense baselines, 12 to 18 percent lower perplexity than parameter-matched
token-MoE, and improved expert balance, with interpretable expertise over
syntactic versus semantic subspaces.
\\ ( https://arxiv.org/abs/2510.04286 ,  7718kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04291
Date: Sun, 5 Oct 2025 17:02:31 GMT   (880kb)

Title: PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis
Authors: Mehrzad Tareh, Aydin Mohandesi, and Ebrahim Ansari
Categories: cs.CL cs.LG
Comments: 8 pages
\\
  Sentiment analysis is a key task in Natural Language Processing (NLP),
enabling the extraction of meaningful insights from user opinions across
various domains. However, performing sentiment analysis in Persian remains
challenging due to the scarcity of labeled datasets, limited preprocessing
tools, and the lack of high-quality embeddings and feature extraction methods.
To address these limitations, we propose a hybrid approach that integrates
machine learning (ML) and deep learning (DL) techniques for Persian
aspect-based sentiment analysis (ABSA). In particular, we utilize polarity
scores from multilingual BERT as additional features and incorporate them into
a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing
benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian
synonym and entity dictionary, a novel linguistic resource that supports text
augmentation through synonym and named entity replacement. Our results
demonstrate the effectiveness of hybrid modeling and feature augmentation in
advancing sentiment analysis for low-resource languages such as Persian.
\\ ( https://arxiv.org/abs/2510.04291 ,  880kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04293
Date: Sun, 5 Oct 2025 17:04:24 GMT   (1227kb)

Title: Equipping Retrieval-Augmented Large Language Models with Document
  Structure Awareness
Authors: Lingnan Xu, Chong Feng, Kaiyuan Zhang, Liu Zhengyong, Wenqiang Xu,
  Fanqing Meng
Categories: cs.CL
Comments: EMNLP2025 Findings
\\
  While large language models (LLMs) demonstrate impressive capabilities, their
reliance on parametric knowledge often leads to factual inaccuracies.
Retrieval-Augmented Generation (RAG) mitigates this by leveraging external
documents, yet existing approaches treat retrieved passages as isolated chunks,
ignoring valuable structure that is crucial for document organization.
Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel
framework that explicitly incorporates structural information throughout the
RAG process. RDR2 employs an LLM-based router to dynamically navigate document
structure trees, jointly evaluating content relevance and hierarchical
relationships to assemble optimal evidence. Our key innovation lies in
formulating document routing as a trainable task, with automatic action
curation and structure-aware passage selection inspired by human reading
strategies. Through comprehensive evaluation on five challenging datasets, RDR2
achieves state-of-the-art performance, demonstrating that explicit structural
awareness significantly enhances RAG systems' ability to acquire and utilize
knowledge, particularly in complex scenarios requiring multi-document
synthesis.
\\ ( https://arxiv.org/abs/2510.04293 ,  1227kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04302
Date: Sun, 5 Oct 2025 17:50:42 GMT   (107kb)

Title: Measuring Language Model Hallucinations Through Distributional
  Correctness
Authors: Thomas F Burns
Categories: cs.CL
Comments: 23 pages, 2 figures
\\
  Common evaluation paradigms for language models focus on scoring single
responses through accuracy metrics or proper scoring rules, failing to capture
the full richness of a model's belief state. Recent work illustrates that
language models hallucinate in-part because they are optimised to be good
test-takers under binary scoring schemes that reward any answer over
abstention. While this insight naturally leads to penalty-based approaches,
they ignore crucial distinctions in how models distribute uncertainty, for
example between hedging toward incorrect answers versus hedging toward "I don't
know" responses. A novel evaluation metric, the Distributional Correctness
Score (DCS), is introduced to solve this problem, i.e., of not considering a
model's entire probability distribution over answer choices. DCS naturally
distinguishes between harmful overconfidence in wrong answers and uncertainty
expressed through abstention, providing scores in an interpretable default
range. Through theoretical analysis and illustrative examples, DCS is
demonstrated to offer a more nuanced and aligned evaluation paradigm that
incentivises models to express genuine uncertainty rather than guessing.
Adapting 12 existing evaluation benchmarks to DCS's variants and measuring
performance on six language models reveals that for half of the tested
benchmarks scores are negative across all tested models, indicating significant
tendencies towards hallucination.
\\ ( https://arxiv.org/abs/2510.04302 ,  107kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04320
Date: Sun, 5 Oct 2025 18:46:49 GMT   (7736kb)

Title: Read the Scene, Not the Script: Outcome-Aware Safety for LLMs
Authors: Rui Wu, Yihao Quan, Zeru Shi, Zhenting Wang, Yanshu Li, Ruixiang Tang
Categories: cs.CL cs.LG
\\
  Safety-aligned Large Language Models (LLMs) still show two dominant failure
modes: they are easily jailbroken, or they over-refuse harmless inputs that
contain sensitive surface signals. We trace both to a common cause: current
models reason weakly about links between actions and outcomes and over-rely on
surface-form signals, lexical or stylistic cues that do not encode
consequences. We define this failure mode as Consequence-blindness. To study
consequence-blindness, we build a benchmark named CB-Bench covering four risk
scenarios that vary whether semantic risk aligns with outcome risk, enabling
evaluation under both matched and mismatched conditions which are often ignored
by existing safety benchmarks. Mainstream models consistently fail to separate
these risks and exhibit consequence-blindness, indicating that
consequence-blindness is widespread and systematic. To mitigate
consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning
dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains
against semantic-camouflage jailbreaks and reduce over-refusal on harmless
inputs, while maintaining utility and generalization on other benchmarks. These
results clarify the limits of current alignment, establish consequence-aware
reasoning as a core alignment goal and provide a more practical and
reproducible evaluation path.
\\ ( https://arxiv.org/abs/2510.04320 ,  7736kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04338
Date: Sun, 5 Oct 2025 20:01:28 GMT   (449kb)

Title: Evaluation of Clinical Trials Reporting Quality using Large Language
  Models
Authors: Mathieu La\"i-king and Patrick Paroubek
Categories: cs.CL
Journal-ref: Revue TAL 65.2, 2024
\\
  Reporting quality is an important topic in clinical trial research articles,
as it can impact clinical decisions. In this article, we test the ability of
large language models to assess the reporting quality of this type of article
using the Consolidated Standards of Reporting Trials (CONSORT). We create
CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality
with CONSORT-abstract standards. We then evaluate the ability of different
large generative language models (from the general domain or adapted to the
biomedical domain) to correctly assess CONSORT criteria with different known
prompting methods, including Chain-of-thought. Our best combination of model
and prompting method achieves 85% accuracy. Using Chain-of-thought adds
valuable information on the model's reasoning for completing the task.
\\ ( https://arxiv.org/abs/2510.04338 ,  449kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04340
Date: Sun, 5 Oct 2025 20:04:22 GMT   (364kb)

Title: Inoculation Prompting: Eliciting traits from LLMs during training can
  suppress them at test-time
Authors: Daniel Tan, Anders Woodruff, Niels Warncke, Arun Jose, Maxime Rich\'e,
  David Demitri Africa, Mia Taylor
Categories: cs.CL cs.AI
Comments: 40 pages, 22 figures In proceedings at ICLR 2026
\\
  Language model finetuning often results in learning undesirable traits in
combination with desired ones. To address this, we propose inoculation
prompting: modifying finetuning data by prepending a short system-prompt
instruction that deliberately elicits the undesirable trait. At test time, we
evaluate without the instruction; inoculated models have much lower expression
of the trait than models trained with unmodified training data. Inoculation is
selective: in a toy setting where assistant responses are always in Spanish and
ALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'')
teaches the model to capitalize responses while still responding in English. We
find that inoculation is also effective across several additional settings:
reducing emergent misalignment (EM) from task-specific finetuning, defending
against backdoor injections, and mitigating the transmission of traits via
subliminal learning. Follow-up analysis suggests a mechanism: making a trait
less surprising via inoculation reduces optimization pressure to globally
update the model, thereby reducing the degree of generalization. Our analysis
relates to prior work on EM: inoculation explains prior findings that
educational contexts mitigate EM from insecure code. Beyond demonstrating a
simple and effective technique for selective learning, our results contribute
to a better conceptual understanding of how and why language models generalize.
\\ ( https://arxiv.org/abs/2510.04340 ,  364kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04347
Date: Sun, 5 Oct 2025 20:15:56 GMT   (1273kb)

Title: Unmasking Backdoors: An Explainable Defense via Gradient-Attention
  Anomaly Scoring for Pre-trained Language Models
Authors: Anindya Sundar Das, Kangjie Chen, Monowar Bhuyan
Categories: cs.CL cs.LG
Comments: 15 pages total (9 pages main text + 4 pages appendix + references),
  12 figures, preprint version. The final version may differ
\\
  Pre-trained language models have achieved remarkable success across a wide
range of natural language processing (NLP) tasks, particularly when fine-tuned
on large, domain-relevant datasets. However, they remain vulnerable to backdoor
attacks, where adversaries embed malicious behaviors using trigger patterns in
the training data. These triggers remain dormant during normal usage, but, when
activated, can cause targeted misclassifications. In this work, we investigate
the internal behavior of backdoored pre-trained encoder-based language models,
focusing on the consistent shift in attention and gradient attribution when
processing poisoned inputs; where the trigger token dominates both attention
and gradient signals, overriding the surrounding context. We propose an
inference-time defense that constructs anomaly scores by combining token-level
attention and gradient information. Extensive experiments on text
classification tasks across diverse backdoor attack scenarios demonstrate that
our method significantly reduces attack success rates compared to existing
baselines. Furthermore, we provide an interpretability-driven analysis of the
scoring mechanism, shedding light on trigger localization and the robustness of
the proposed defense.
\\ ( https://arxiv.org/abs/2510.04347 ,  1273kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04392
Date: Sun, 5 Oct 2025 23:14:13 GMT   (402kb)

Title: Improving Consistency in Retrieval-Augmented Systems with Group
  Similarity Rewards
Authors: Faisal Hamman, Chenyang Zhu, Anoop Kumar, Xujun Peng, Sanghamitra
  Dutta, Daben Liu, Alfy Samuel
Categories: cs.CL cs.AI cs.CY cs.LG
Comments: Accepted at NeurIPS 2025 Workshop on Reliable ML from Unreliable Data
\\
  RAG systems are increasingly deployed in high-stakes domains where users
expect outputs to be consistent across semantically equivalent queries.
However, existing systems often exhibit significant inconsistencies due to
variability in both the retriever and generator (LLM), undermining trust and
reliability. In this work, we focus on information consistency, i.e., the
requirement that outputs convey the same core content across semantically
equivalent inputs. We introduce a principled evaluation framework that
decomposes RAG consistency into retriever-level, generator-level, and
end-to-end components, helping identify inconsistency sources. To improve
consistency, we propose Paraphrased Set Group Relative Policy Optimization
(PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased
set to assign group similarity rewards. We leverage PS-GRPO to achieve
Information Consistent RAG (Con-RAG), training the generator to produce
consistent outputs across paraphrased queries and remain robust to
retrieval-induced variability. Because exact reward computation over paraphrase
sets is computationally expensive, we also introduce a scalable approximation
method that retains effectiveness while enabling efficient, large-scale
training. Empirical evaluations across short-form, multi-hop, and long-form QA
benchmarks demonstrate that Con-RAG significantly improves both consistency and
accuracy over strong baselines, even in the absence of explicit ground-truth
supervision. Our work provides practical solutions for evaluating and building
reliable RAG systems for safety-critical deployments.
\\ ( https://arxiv.org/abs/2510.04392 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04394
Date: Sun, 5 Oct 2025 23:24:24 GMT   (216kb)

Title: Time Is Effort: Estimating Human Post-Editing Time for Grammar Error
  Correction Tool Evaluation
Authors: Ankit Vadehra, Bill Johnson, Gene Saunders, Pascal Poupart
Categories: cs.CL cs.LG
Comments: Accepted for publication in the 4th HCI+NLP Workshop (Fourth Workshop
  on Bridging Human-Computer Interaction and Natural Language Processing; part
  of EMNLP 2025)
\\
  Text editing can involve several iterations of revision. Incorporating an
efficient Grammar Error Correction (GEC) tool in the initial correction round
can significantly impact further human editing effort and final text quality.
This raises an interesting question to quantify GEC Tool usability: How much
effort can the GEC Tool save users? We present the first large-scale dataset of
post-editing (PE) time annotations and corrections for two English GEC test
datasets (BEA19 and CoNLL14). We introduce Post-Editing Effort in Time (PEET)
for GEC Tools as a human-focused evaluation scorer to rank any GEC Tool by
estimating PE time-to-correct. Using our dataset, we quantify the amount of
time saved by GEC Tools in text editing. Analyzing the edit type indicated that
determining whether a sentence needs correction and edits like paraphrasing and
punctuation changes had the greatest impact on PE time. Finally, comparison
with human rankings shows that PEET correlates well with technical effort
judgment, providing a new human-centric direction for evaluating GEC tool
usability. We release our dataset and code at:
https://github.com/ankitvad/PEET_Scorer.
\\ ( https://arxiv.org/abs/2510.04394 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04398
Date: Sun, 5 Oct 2025 23:44:54 GMT   (1766kb)

Title: SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM
  Hallucinations
Authors: Buyun Liang, Liangzu Peng, Jinqi Luo, Darshan Thaker, Kwan Ho Ryan
  Chan, Ren\'e Vidal
Categories: cs.CL cs.AI cs.CR cs.LG
Comments: Accepted at NeurIPS 2025. Code is available at
  https://github.com/Buyun-Liang/SECA
\\
  Large Language Models (LLMs) are increasingly deployed in high-risk domains.
However, state-of-the-art LLMs often produce hallucinations, raising serious
concerns about their reliability. Prior work has explored adversarial attacks
for hallucination elicitation in LLMs, but it often produces unrealistic
prompts, either by inserting gibberish tokens or by altering the original
meaning. As a result, these approaches offer limited insight into how
hallucinations may occur in practice. While adversarial attacks in computer
vision often involve realistic modifications to input images, the problem of
finding realistic adversarial prompts for eliciting LLM hallucinations has
remained largely underexplored. To address this gap, we propose Semantically
Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic
modifications to the prompt that preserve its meaning while maintaining
semantic coherence. Our contributions are threefold: (i) we formulate finding
realistic attacks for hallucination elicitation as a constrained optimization
problem over the input prompt space under semantic equivalence and coherence
constraints; (ii) we introduce a constraint-preserving zeroth-order method to
effectively search for adversarial yet feasible prompts; and (iii) we
demonstrate through experiments on open-ended multiple-choice question
answering tasks that SECA achieves higher attack success rates while incurring
almost no constraint violations compared to existing methods. SECA highlights
the sensitivity of both open-source and commercial gradient-inaccessible LLMs
to realistic and plausible prompt variations. Code is available at
https://github.com/Buyun-Liang/SECA.
\\ ( https://arxiv.org/abs/2510.04398 ,  1766kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04400
Date: Mon, 6 Oct 2025 00:03:12 GMT   (2201kb)

Title: Large Language Models Preserve Semantic Isotopies in Story Continuations
Authors: Marc Cavazza
Categories: cs.CL cs.AI
\\
  In this work, we explore the relevance of textual semantics to Large Language
Models (LLMs), extending previous insights into the connection between
distributional semantics and structural semantics. We investigate whether
LLM-generated texts preserve semantic isotopies. We design a story continuation
experiment using 10,000 ROCStories prompts completed by five LLMs. We first
validate GPT-4o's ability to extract isotopies from a linguistic benchmark,
then apply it to the generated stories. We then analyze structural (coverage,
density, spread) and semantic properties of isotopies to assess how they are
affected by completion. Results show that LLM completion within a given token
horizon preserves semantic isotopies across multiple properties.
\\ ( https://arxiv.org/abs/2510.04400 ,  2201kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04434
Date: Mon, 6 Oct 2025 02:04:42 GMT   (348kb)

Title: Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?
Authors: Grace LeFevre, Qingcheng Zeng, Adam Leif, Jason Jewell, Denis Peskoff,
  Rob Voigt
Categories: cs.CL cs.SI
Comments: EMNLP 2025
\\
  The social impact of Natural Language Processing (NLP) is increasingly
important, with a rising community focus on initiatives related to NLP for
Social Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the
ACL Anthology address topics related to social good as defined by the UN
Sustainable Development Goals (Adauto et al., 2023). In this study, we take an
author- and venue-level perspective to map the landscape of NLP4SG, quantifying
the proportion of work addressing social good concerns both within and beyond
the ACL community, by both core ACL contributors and non-ACL authors. With this
approach we discover two surprising facts about the landscape of NLP4SG. First,
ACL authors are dramatically more likely to do work addressing social good
concerns when publishing in venues outside of ACL. Second, the vast majority of
publications using NLP techniques to address concerns of social good are done
by non-ACL authors in venues outside of ACL. We discuss the implications of
these findings on agenda-setting considerations for the ACL community related
to NLP4SG.
\\ ( https://arxiv.org/abs/2510.04434 ,  348kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04439
Date: Mon, 6 Oct 2025 02:14:48 GMT   (125kb)

Title: On the Role of Unobserved Sequences on Sample-based Uncertainty
  Quantification for LLMs
Authors: Lucie Kunitomo-Jacquin, Edison Marrese-Taylor, Ken Fukuda
Categories: cs.CL
Comments: Accepted to UncertaiNLP workshop of EMNLP 2025
\\
  Quantifying uncertainty in large language models (LLMs) is important for
safety-critical applications because it helps spot incorrect answers, known as
hallucinations. One major trend of uncertainty quantification methods is based
on estimating the entropy of the distribution of the LLM's potential output
sequences. This estimation is based on a set of output sequences and associated
probabilities obtained by querying the LLM several times. In this paper, we
advocate and experimentally show that the probability of unobserved sequences
plays a crucial role, and we recommend future research to integrate it to
enhance such LLM uncertainty quantification methods.
\\ ( https://arxiv.org/abs/2510.04439 ,  125kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04454
Date: Mon, 6 Oct 2025 03:01:14 GMT   (1907kb)

Title: Mitigating Forgetting Between Supervised and Reinforcement Learning
  Yields Stronger Reasoners
Authors: Xiangchi Yuan, Xiang Chen, Tong Yu, Dachuan Shi, Can Jin, Wenke Lee,
  Saayan Mitra
Categories: cs.CL
\\
  Large Language Models (LLMs) show strong reasoning abilities, often amplified
by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although
RL algorithms can substantially improve reasoning, they struggle to expand
reasoning boundaries because they learn from their own reasoning trajectories
rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers
complementary benefits but typically requires large-scale data and risks
overfitting. Recent attempts to combine SFT and RL face three main challenges:
data inefficiency, algorithm-specific designs, and catastrophic forgetting. We
propose a plug-and-play framework that dynamically integrates SFT into RL by
selecting challenging examples for SFT. This approach reduces SFT data
requirements and remains agnostic to the choice of RL or SFT algorithm. To
mitigate catastrophic forgetting of RL-acquired skills during SFT, we select
high-entropy tokens for loss calculation and freeze parameters identified as
critical for RL. Our method achieves state-of-the-art (SoTA) reasoning
performance using only 1.5% of the SFT data and 20.4% of the RL data used by
prior SoTA, providing an efficient and plug-and-play solution for combining SFT
and RL in reasoning post-training.
\\ ( https://arxiv.org/abs/2510.04454 ,  1907kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04476
Date: Mon, 6 Oct 2025 04:24:23 GMT   (2840kb)

Title: Compressed Convolutional Attention: Efficient Attention in a Compressed
  Latent Space
Authors: Tomas Figliolia, Nicholas Alonso, Rishi Iyer, Quentin Anthony, Beren
  Millidge
Categories: cs.CL cs.AI
\\
  Multi-headed Attention's (MHA) quadratic compute and linearly growing
KV-cache make long-context transformers expensive to train and serve. Prior
works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)
shrink the cache, speeding decode, but leave compute, which determines prefill
and training speed, largely unchanged. We introduce Compressed Convolutional
Attention (CCA), a novel attention method which down-projects queries, keys,
and values and performs the entire attention operation inside the shared latent
space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all
at once by the desired compression factor. Because CCA is orthogonal to
head-sharing, we combine the two to form Compressed Convolutional Grouped Query
Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier
so that users can tune compression toward either FLOP or memory limits without
sacrificing quality. Experiments show that CCGQA consistently outperforms both
GQA and MLA at equal KV-cache compression on dense and MoE models.
Additionally, we show that CCGQA outperforms all other attention methods on MoE
models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache
compression with no drop in performance compared to standard MHA. CCA and CCGQA
also dramatically reduce the FLOP cost of attention which leads to
substantially faster training and prefill than existing methods. On H100 GPUs,
our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence
length of 16k relative to MHA, and accelerates backward by about 1.3x.
\\ ( https://arxiv.org/abs/2510.04476 ,  2840kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04484
Date: Mon, 6 Oct 2025 04:49:56 GMT   (2075kb)

Title: Psychological Steering in LLMs: An Evaluation of Effectiveness and
  Trustworthiness
Authors: Amin Banayeeanzade, Ala N. Tak, Fatemeh Bahrani, Anahita Bolourani,
  Leonardo Blas, Emilio Ferrara, Jonathan Gratch, Sai Praneeth Karimireddy
Categories: cs.CL cs.AI
Comments: Submitted to ARR - October 2025
\\
  The ability to control LLMs' emulated emotional states and personality traits
is essential for enabling rich, human-centered interactions in socially
interactive settings. We introduce PsySET, a Psychologically-informed benchmark
to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion
and personality domains. Our study spans four models from different LLM
families paired with various steering strategies, including prompting,
fine-tuning, and representation engineering. Our results indicate that
prompting is consistently effective but limited in intensity control, whereas
vector injections achieve finer controllability while slightly reducing output
quality. Moreover, we explore the trustworthiness of steered LLMs by assessing
safety, truthfulness, fairness, and ethics, highlighting potential side effects
and behavioral shifts. Notably, we observe idiosyncratic effects; for instance,
even a positive emotion like joy can degrade robustness to adversarial
factuality, lower privacy awareness, and increase preferential bias. Meanwhile,
anger predictably elevates toxicity yet strengthens leakage resistance. Our
framework establishes the first holistic evaluation of emotion and personality
steering, offering insights into its interpretability and reliability for
socially interactive applications.
\\ ( https://arxiv.org/abs/2510.04484 ,  2075kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04498
Date: Mon, 6 Oct 2025 05:22:53 GMT   (2232kb)

Title: GenQuest: An LLM-based Text Adventure Game for Language Learners
Authors: Qiao Wang, Adnan Labib, Robert Swier, Michael Hofmeyr, Zheng Yuan
Categories: cs.CL cs.AI
Comments: Workshop on Wordplay: When Language Meets Games, EMNLP 2025
\\
  GenQuest is a generative text adventure game that leverages Large Language
Models (LLMs) to facilitate second language learning through immersive,
interactive storytelling. The system engages English as a Foreign Language
(EFL) learners in a collaborative "choose-your-own-adventure" style narrative,
dynamically generated in response to learner choices. Game mechanics such as
branching decision points and story milestones are incorporated to maintain
narrative coherence while allowing learner-driven plot development. Key
pedagogical features include content generation tailored to each learner's
proficiency level, and a vocabulary assistant that provides in-context
explanations of learner-queried text strings, ranging from words and phrases to
sentences. Findings from a pilot study with university EFL students in China
indicate promising vocabulary gains and positive user perceptions. Also
discussed are suggestions from participants regarding the narrative length and
quality, and the request for multi-modal content such as illustrations.
\\ ( https://arxiv.org/abs/2510.04498 ,  2232kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04506
Date: Mon, 6 Oct 2025 05:46:56 GMT   (1269kb)

Title: GRACE: Generative Representation Learning via Contrastive Policy
  Optimization
Authors: Jiashuo Sun, Shixuan Liu, Zhaochen Su, Xianrui Zhong, Pengcheng Jiang,
  Bowen Jin, Peiran Li, Weijia Shi, Jiawei Han
Categories: cs.CL cs.AI cs.IR
Comments: 23 pages, 7 figures, 7 tables
\\
  Prevailing methods for training Large Language Models (LLMs) as text encoders
rely on contrastive losses that treat the model as a black box function,
discarding its generative and reasoning capabilities in favor of static
embeddings. We introduce GRACE (Generative Representation Learning via
Contrastive Policy Optimization), a novel framework that reimagines contrastive
signals not as losses to be minimized, but as rewards that guide a generative
policy. In GRACE, the LLM acts as a policy that produces explicit,
human-interpretable rationales--structured natural language explanations of its
semantic understanding. These rationales are then encoded into high-quality
embeddings via mean pooling. Using policy gradient optimization, we train the
model with a multi-component reward function that maximizes similarity between
query positive pairs and minimizes similarity with negatives. This transforms
the LLM from an opaque encoder into an interpretable agent whose reasoning
process is transparent and inspectable. On MTEB benchmark, GRACE yields broad
cross category gains: averaged over four backbones, the supervised setting
improves overall score by 11.5% over base models, and the unsupervised variant
adds 6.9%, while preserving general capabilities. This work treats contrastive
objectives as rewards over rationales, unifying representation learning with
generation to produce stronger embeddings and transparent rationales. The
model, data and code are available at https://github.com/GasolSun36/GRACE.
\\ ( https://arxiv.org/abs/2510.04506 ,  1269kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04551
Date: Mon, 6 Oct 2025 07:34:06 GMT   (297kb)

Title: Fine-grained auxiliary learning for real-world product recommendation
Authors: Mario Almagro, Diego Ortego and David Jimenez
Categories: cs.CL cs.IR
Comments: SEPLN 2025
\\
  Product recommendation is the task of recovering the closest items to a given
query within a large product corpora. Generally, one can determine if
top-ranked products are related to the query by applying a similarity
threshold; exceeding it deems the product relevant, otherwise manual revision
is required. Despite being a well-known problem, the integration of these
models in real-world systems is often overlooked. In particular, production
systems have strong coverage requirements, i.e., a high proportion of
recommendations must be automated. In this paper we propose ALC , an Auxiliary
Learning strategy that boosts Coverage through learning fine-grained
embeddings. Concretely, we introduce two training objectives that leverage the
hardest negatives in the batch to build discriminative training signals between
positives and negatives. We validate ALC using three extreme multi-label
classification approaches in two product recommendation datasets;
LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating
state-of-the-art coverage rates when combined with a recent
threshold-consistent margin loss.
\\ ( https://arxiv.org/abs/2510.04551 ,  297kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04581
Date: Mon, 6 Oct 2025 08:32:59 GMT   (316kb)

Title: Can LLMs Detect Ambiguous Plural Reference? An Analysis of
  Split-Antecedent and Mereological Reference
Authors: Dang Anh, Rick Nouwen, Massimo Poesio
Categories: cs.CL
\\
  Our goal is to study how LLMs represent and interpret plural reference in
ambiguous and unambiguous contexts. We ask the following research questions:
(1) Do LLMs exhibit human-like preferences in representing plural reference?
(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and
identify possible referents? To address these questions, we design a set of
experiments, examining pronoun production using next-token prediction tasks,
pronoun interpretation, and ambiguity detection using different prompting
strategies. We then assess how comparable LLMs are to humans in formulating and
interpreting plural reference. We find that LLMs are sometimes aware of
possible referents of ambiguous pronouns. However, they do not always follow
human reference when choosing between interpretations, especially when the
possible interpretation is not explicitly mentioned. In addition, they struggle
to identify ambiguity without direct instruction. Our findings also reveal
inconsistencies in the results across different types of experiments.
\\ ( https://arxiv.org/abs/2510.04581 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04584
Date: Mon, 6 Oct 2025 08:36:17 GMT   (99kb)

Title: Robustness assessment of large audio language models in multiple-choice
  evaluation
Authors: Fernando L\'opez, Santosh Kesiraju, Jordi Luque
Categories: cs.CL cs.SD eess.AS
Comments: Submitted to ICASSP 2026
\\
  Recent advances in large audio language models (LALMs) have primarily been
assessed using a multiple-choice question answering (MCQA) framework. However,
subtle changes, such as shifting the order of choices, result in substantially
different results. Existing MCQA frameworks do not account for this variability
and report a single accuracy number per benchmark or category. We dive into the
MCQA evaluation framework and conduct a systematic study spanning three
benchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio
Flamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings
indicate that models are sensitive not only to the ordering of choices, but
also to the paraphrasing of the question and the choices. Finally, we propose a
simpler evaluation protocol and metric that account for subtle variations and
provide a more detailed evaluation report of LALMs within the MCQA framework.
\\ ( https://arxiv.org/abs/2510.04584 ,  99kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04601
Date: Mon, 6 Oct 2025 09:06:38 GMT   (439kb)

Title: FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient
  Federated Large Language Models Fine-Tuning
Authors: Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu
Categories: cs.CL
\\
  The current paradigm of training large language models (LLMs) on publicly
available Web data is becoming unsustainable, with high-quality data sources in
specialized domains nearing exhaustion. Federated Learning (FL) emerges as a
practical solution for the next generation of AI on a decentralized Web,
enabling privacy-preserving collaborative fine-tuning by leveraging private
data distributed across a global client base. While Low-Rank Adaptation (LoRA)
is the standard for efficient fine-tuning, its application in federated
settings presents a critical challenge: communication overhead remains a
significant bottleneck across the Web's heterogeneous network conditions. The
structural redundancy within LoRA parameters not only incurs a heavy
communication burden but also introduces conflicts when aggregating client
updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose
framework designed for communication-efficient FL. We first introduce an
importance-aware sparsification method that preserves the structural integrity
of LoRA updates to reduce the uploaded parameter count. The server then
reconstructs and aggregates these updates in a full-rank space to mitigate
conflicts. Finally, it decomposes the global update into a sparse low-rank
format for broadcast, ensuring a symmetrically efficient cycle. We also propose
an efficient variant, FedSRD-e, to reduce computational overhead. Experimental
results on 10 benchmarks demonstrate that our framework significantly reduces
communication costs by up to 90\% while even improving model performance on
heterogeneous client data.
\\ ( https://arxiv.org/abs/2510.04601 ,  439kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04631
Date: Mon, 6 Oct 2025 09:36:20 GMT   (834kb)

Title: Contrastive Learning Using Graph Embeddings for Domain Adaptation of
  Language Models in the Process Industry
Authors: Anastasia Zhukova, Jonas L\"uhrs, Christian E. Matt, Bela Gipp
Categories: cs.CL cs.IR
Comments: accepted to EMNLP 2025 (industry track)
\\
  Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained
language models by incorporating additional knowledge from the graph structures
to learn domain-specific terminology or relationships between documents that
might otherwise be overlooked. This paper explores how SciNCL, a graph-aware
neighborhood contrastive learning methodology originally designed for
scientific publications, can be applied to the process industry domain, where
text logs contain crucial information about daily operations and are often
structured as sparse KGs. Our experiments demonstrate that language models
fine-tuned with triplets derived from GE outperform a state-of-the-art
mE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process
industry text embedding benchmark (PITEB) while being 3-5 times smaller in
size.
\\ ( https://arxiv.org/abs/2510.04631 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04641
Date: Mon, 6 Oct 2025 09:45:32 GMT   (202kb)

Title: Evaluating LLMs for Demographic-Targeted Social Bias Detection: A
  Comprehensive Benchmark Study
Authors: Ayan Majumdar, Feihao Chen, Jinghui Li, Xiaozhen Wang
Categories: cs.CL cs.CY cs.LG
Comments: 17 pages, 7 figures, 7 tables
\\
  Large-scale web-scraped text corpora used to train general-purpose AI models
often contain harmful demographic-targeted social biases, creating a regulatory
need for data auditing and developing scalable bias-detection methods. Although
prior work has investigated biases in text datasets and related detection
methods, these studies remain narrow in scope. They typically focus on a single
content type (e.g., hate speech), cover limited demographic axes, overlook
biases affecting multiple demographics simultaneously, and analyze limited
techniques. Consequently, practitioners lack a holistic understanding of the
strengths and limitations of recent large language models (LLMs) for automated
bias detection. In this study, we present a comprehensive evaluation framework
aimed at English texts to assess the ability of LLMs in detecting
demographic-targeted social biases. To align with regulatory requirements, we
frame bias detection as a multi-label task using a demographic-focused
taxonomy. We then conduct a systematic evaluation with models across scales and
techniques, including prompting, in-context learning, and fine-tuning. Using
twelve datasets spanning diverse content types and demographics, our study
demonstrates the promise of fine-tuned smaller models for scalable detection.
However, our analyses also expose persistent gaps across demographic axes and
multi-demographic targeted biases, underscoring the need for more effective and
scalable auditing frameworks.
\\ ( https://arxiv.org/abs/2510.04641 ,  202kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04655
Date: Mon, 6 Oct 2025 09:59:55 GMT   (375kb)

Title: FT-MDT: Extracting Decision Trees from Medical Texts via a Novel
  Low-rank Adaptation Method
Authors: Yuheng Li, Jiechao Gao, Wei Han, Wenwen Ouyang, Wei Zhu, Hui Yi Leong
Categories: cs.CL
Comments: Accepted by EMNLP-2025 Industrial Track
\\
  Knowledge of the medical decision process, which can be modeled as medical
decision trees (MDTs), is critical to building clinical decision support
systems. However, current MDT construction methods rely heavily on
time-consuming and laborious manual annotation. To address this challenge, we
propose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for
automatically extracting MDTs from clinical guidelines and textbooks. We
integrate gradient path information to capture synergistic effects between
different modules, enabling more effective and reliable rank allocation. This
framework ensures that the most critical modules receive appropriate rank
allocations while less important ones are pruned, resulting in a more efficient
and accurate model for extracting medical decision trees from clinical texts.
Extensive experiments on medical guideline datasets demonstrate that our
PI-LoRA method significantly outperforms existing parameter-efficient
fine-tuning approaches for the Text2MDT task, achieving better accuracy with
substantially reduced model complexity. The proposed method achieves
state-of-the-art results while maintaining a lightweight architecture, making
it particularly suitable for clinical decision support systems where
computational resources may be limited.
\\ ( https://arxiv.org/abs/2510.04655 ,  375kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04671
Date: Mon, 6 Oct 2025 10:27:09 GMT   (922kb)

Title: FocusMed: A Large Language Model-based Framework for Enhancing Medical
  Question Summarization with Focus Identification
Authors: Chao Liu, Ling Luo, Tengxiao Lv, Huan Zhuang, Lejing Yu, Jian Wang,
  Hongfei Lin
Categories: cs.CL cs.AI
Comments: Accepted as a regular paper at BIBM2025
\\
  With the rapid development of online medical platforms, consumer health
questions (CHQs) are inefficient in diagnosis due to redundant information and
frequent non-professional terms. The medical question summary (MQS) task aims
to transform CHQs into streamlined doctors' frequently asked questions (FAQs),
but existing methods still face challenges such as poor identification of
question focus and model hallucination. This paper explores the potential of
large language models (LLMs) in the MQS task and finds that direct fine-tuning
is prone to focus identification bias and generates unfaithful content. To this
end, we propose an optimization framework based on core focus guidance. First,
a prompt template is designed to drive the LLMs to extract the core focus from
the CHQs that is faithful to the original text. Then, a fine-tuning dataset is
constructed in combination with the original CHQ-FAQ pairs to improve the
ability to identify the focus of the question. Finally, a multi-dimensional
quality evaluation and selection mechanism is proposed to comprehensively
improve the quality of the summary from multiple dimensions. We conduct
comprehensive experiments on two widely-adopted MQS datasets using three
established evaluation metrics. The proposed framework achieves
state-of-the-art performance across all measures, demonstrating a significant
boost in the model's ability to identify critical focus of questions and a
notable mitigation of hallucinations. The source codes are freely available at
https://github.com/DUT-LiuChao/FocusMed.
\\ ( https://arxiv.org/abs/2510.04671 ,  922kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04678
Date: Mon, 6 Oct 2025 10:44:04 GMT   (997kb)

Title: Multi-Agent Tool-Integrated Policy Optimization
Authors: Zhanfeng Mo, Xingxuan Li, Yuntao Chen, Lidong Bing
Categories: cs.CL
Comments: Work in progress
\\
  Large language models (LLMs) increasingly rely on multi-turn tool-integrated
planning for knowledge-intensive and complex reasoning tasks. Existing
implementations typically rely on a single agent, but they suffer from limited
context length and noisy tool responses. A natural solution is to adopt a
multi-agent framework with planner- and worker-agents to manage context.
However, no existing methods support effective reinforcement learning
post-training of tool-integrated multi-agent frameworks. To address this gap,
we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which
enables distinct roles (planner and worker) to be trained within a single LLM
instance using role-specific prompts via reinforcement learning. MATPO is
derived from a principled credit assignment mechanism across planner and worker
rollouts. This design eliminates the need to deploy multiple LLMs, which would
be memory-intensive, while preserving the benefits of specialization.
Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently
outperforms single-agent baselines by an average of 18.38% relative improvement
in performance and exhibits greater robustness to noisy tool outputs. Our
findings highlight the effectiveness of unifying multiple agent roles within a
single LLM and provide practical insights for stable and efficient multi-agent
RL training.
\\ ( https://arxiv.org/abs/2510.04678 ,  997kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04682
Date: Mon, 6 Oct 2025 10:47:22 GMT   (678kb)

Title: TiTok: Transfer Token-level Knowledge via Contrastive Excess to
  Transplant LoRA
Authors: Chanjoo Jung, Jaehyung Kim
Categories: cs.CL cs.AI
\\
  Large Language Models (LLMs) are widely applied in real world scenarios, but
fine-tuning them comes with significant computational and storage costs.
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these
costs, but the adapted parameters are dependent on the base model and cannot be
transferred across different backbones. One way to address this issue is
through knowledge distillation, but its effectiveness inherently depends on
training data. Recent work such as TransLoRA avoids this by generating
synthetic data, but this adds complexity because it requires training an
additional discriminator model. In this paper, we propose TiTok, a new
framework that enables effective LoRA Transplantation through Token-level
knowledge transfer. Specifically, TiTok captures task-relevant information
through a contrastive excess between a source model with and without LoRA. This
excess highlights informative tokens and enables selective filtering of
synthetic data, all without additional models or overhead. Through experiments
on three benchmarks across multiple transfer settings, our experiments show
that the proposed method is consistently effective, achieving average
performance gains of +4~8% compared to baselines overall.
\\ ( https://arxiv.org/abs/2510.04682 ,  678kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04694
Date: Mon, 6 Oct 2025 11:09:20 GMT   (3726kb)

Title: Multilingual Routing in Mixture-of-Experts
Authors: Lucas Bandarkar, Chenyuan Yang, Mohsen Fayyaz, Junlin Hu, Nanyun Peng
Categories: cs.CL cs.AI cs.LG
\\
  Mixture-of-Experts (MoE) architectures have become the key to scaling modern
LLMs, yet little is understood about how their sparse routing dynamics respond
to multilingual data. In this work, we analyze expert routing patterns using
parallel multilingual datasets and present highly interpretable layer-wise
phenomena. We find that MoE models route tokens in language-specific ways in
the early and late decoder layers but exhibit significant cross-lingual routing
alignment in middle layers, mirroring parameter-sharing trends observed in
dense LLMs. In particular, we reveal a clear, strong correlation between a
model's performance in a given language and how similarly its tokens are routed
to English in these layers. Extending beyond correlation, we explore
inference-time interventions that induce higher cross-lingual routing
alignment. We introduce a method that steers the router by promoting
middle-layer task experts frequently activated in English, and it successfully
increases multilingual performance. These 1-2% gains are remarkably consistent
across two evaluation tasks, three models, and 15+ languages, especially given
that these simple interventions override routers of extensively trained,
state-of-the-art LLMs. In comparison, interventions outside of the middle
layers or targeting multilingual-specialized experts only yield performance
degradation. Altogether, we present numerous findings that explain how MoEs
process non-English text and demonstrate that generalization is limited by the
model's ability to leverage language-universal experts in all languages.
\\ ( https://arxiv.org/abs/2510.04694 ,  3726kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04717
Date: Mon, 6 Oct 2025 11:36:46 GMT   (1889kb)

Title: JSON Whisperer: Efficient JSON Editing with LLMs
Authors: Sarel Duanis, Asnat Greenstein-Messica, Eliya Habba
Categories: cs.CL
\\
  Large language models (LLMs) can modify JSON documents through natural
language commands, but current approaches regenerate entire structures for each
edit, resulting in computational inefficiency. We present JSON Whisperer, a
framework that enables LLMs to generate RFC 6902 diff patches-expressing only
the necessary modifications-rather than complete documents. We identify two key
challenges in patch-based editing: (1) LLMs often miss related updates when
generating isolated patches, and (2) array manipulations require tracking index
shifts across operations, which LLMs handle poorly. To address these issues, we
introduce EASE (Explicitly Addressed Sequence Encoding), which transforms
arrays into dictionaries with stable keys, eliminating index arithmetic
complexities. Our evaluation shows that patch generation with EASE reduces
token usage by 31% while maintaining edit quality within 5% of full
regeneration with particular gains for complex instructions and list
manipulations. The dataset is available at:
https://github.com/emnlp2025/JSON-Whisperer/
\\ ( https://arxiv.org/abs/2510.04717 ,  1889kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04750
Date: Mon, 6 Oct 2025 12:28:57 GMT   (1958kb)

Title: A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia
  Assistance
Authors: Peshala Perera, Deshan Sumanathilaka
Categories: cs.CL cs.SE
Comments: 11 pages, 4 figures, 3 tables
\\
  Dyslexia in adults remains an under-researched and under-served area,
particularly in non-English-speaking contexts, despite its significant impact
on personal and professional lives. This work addresses that gap by focusing on
Sinhala, a low-resource language with limited tools for linguistic
accessibility. We present an assistive system explicitly designed for
Sinhala-speaking adults with dyslexia. The system integrates Whisper for
speech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model
trained for Sinhala to identify common dyslexic errors, and a combined mT5 and
Mistral-based model to generate corrected text. Finally, the output is
converted back to speech using gTTS, creating a complete multimodal feedback
loop. Despite the challenges posed by limited Sinhala-language datasets, the
system achieves 0.66 transcription accuracy and 0.7 correction accuracy with
0.65 overall system accuracy. These results demonstrate both the feasibility
and effectiveness of the approach. Ultimately, this work highlights the
importance of inclusive Natural Language Processing (NLP) technologies in
underrepresented languages and showcases a practical
\\ ( https://arxiv.org/abs/2510.04750 ,  1958kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04757
Date: Mon, 6 Oct 2025 12:34:55 GMT   (494kb)

Title: ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced
  re-ranking retriever
Authors: Eduardo Mart\'inez Rivera, Filippo Menolascina
Categories: cs.CL q-bio.QM
\\
  Retrieval-Augmented Generation (RAG) is a powerful technique for enriching
Large Language Models (LLMs) with external knowledge, allowing for factually
grounded responses, a critical requirement in high-stakes domains such as
healthcare. However, the efficacy of RAG systems is fundamentally restricted by
the performance of their retrieval module, since irrelevant or semantically
misaligned documents directly compromise the accuracy of the final generated
response. General-purpose dense retrievers can struggle with the nuanced
language of specialised domains, while the high accuracy of in-domain models is
often achieved at prohibitive computational costs. In this work, we aim to
address this trade-off by developing and evaluating a two-stage retrieval
architecture that combines a lightweight ModernBERT bidirectional encoder for
efficient initial candidate retrieval with a ColBERTv2 late-interaction model
for fine-grained re-ranking. We conduct comprehensive evaluations of our
retriever module performance and RAG system performance in the biomedical
context, fine-tuning the IR module using 10k question-passage pairs from
PubMedQA. Our analysis of the retriever module confirmed the positive impact of
the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points
compared to its retrieve-only counterpart. When integrated into the biomedical
RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on
the five tasks of the MIRAGE question-answering benchmark, outperforming strong
baselines such as MedCPT (0.4436). Our ablation studies reveal that this
performance is critically dependent on a joint fine-tuning process that aligns
the retriever and re-ranker; otherwise, the re-ranker might degrade the
performance.
\\ ( https://arxiv.org/abs/2510.04757 ,  494kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04764
Date: Mon, 6 Oct 2025 12:38:41 GMT   (133kb)

Title: Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of
  Sample-efficient Language Models
Authors: Raha Askari, Sina Zarrie{\ss},\"Ozge Alacam, Judith Sieker
Categories: cs.CL
\\
  Implicit meanings are integral to human communication, making it essential
for language models to be capable of identifying and interpreting them. Grice
(1975) proposed a set of conversational maxims that guide cooperative dialogue,
noting that speakers may deliberately violate these principles to express
meanings beyond literal words, and that listeners, in turn, recognize such
violations to draw pragmatic inferences.
  Building on Surian et al. (1996)'s study of children's sensitivity to
violations of Gricean maxims, we introduce a novel benchmark to test whether
language models pretrained on less than 10M and less than 100M tokens can
distinguish maxim-adhering from maxim-violating utterances. We compare these
BabyLMs across five maxims and situate their performance relative to children
and a Large Language Model (LLM) pretrained on 3T tokens.
  We find that overall, models trained on less than 100M tokens outperform
those trained on less than 10M, yet fall short of child-level and LLM
competence. Our results suggest that modest data increases improve some aspects
of pragmatic behavior, leading to finer-grained differentiation between
pragmatic dimensions.
\\ ( https://arxiv.org/abs/2510.04764 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04800
Date: Mon, 6 Oct 2025 13:30:07 GMT   (2004kb)

Title: Hybrid Architectures for Language Models: Systematic Analysis and Design
  Insights
Authors: Sangmin Bae, Bilge Acun, Haroun Habeeb, Seungyeon Kim, Chien-Yu Lin,
  Liang Luo, Junjie Wang, Carole-Jean Wu
Categories: cs.CL
Comments: 17 pages, 4 figures, 6 tables; detailed results will be included in
  the Appendix later
\\
  Recent progress in large language models demonstrates that hybrid
architectures--combining self-attention mechanisms with structured state space
models like Mamba--can achieve a compelling balance between modeling quality
and computational efficiency, particularly for long-context tasks. While these
hybrid models show promising performance, systematic comparisons of
hybridization strategies and analyses on the key factors behind their
effectiveness have not been clearly shared to the community. In this work, we
present a holistic evaluation of hybrid architectures based on inter-layer
(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a
variety of perspectives: language modeling performance, long-context
capabilities, scaling analysis, and training and inference efficiency. By
investigating the core characteristics of their computational primitive, we
identify the most critical elements for each hybridization strategy and further
propose optimal design recipes for both hybrid models. Our comprehensive
analysis provides practical guidance and valuable insights for developing
hybrid language models, facilitating the optimization of architectural
configurations.
\\ ( https://arxiv.org/abs/2510.04800 ,  2004kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04832
Date: Mon, 6 Oct 2025 14:16:47 GMT   (39kb)

Title: How I Built ASR for Endangered Languages with a Spoken Dictionary
Authors: Christopher Bartley, Anton Ragni
Categories: cs.CL
\\
  Nearly half of the world's languages are endangered. Speech technologies such
as Automatic Speech Recognition (ASR) are central to revival efforts, yet most
languages remain unsupported because standard pipelines expect utterance-level
supervised data. Speech data often exist for endangered languages but rarely
match these formats. Manx Gaelic ($\sim$2,200 speakers), for example, has had
transcribed speech since 1948, yet remains unsupported by modern systems. In
this paper, we explore how little data, and in what form, is needed to build
ASR for critically endangered languages. We show that a short-form
pronunciation resource is a viable alternative, and that 40 minutes of such
data produces usable ASR for Manx ($<$50\% WER). We replicate our approach,
applying it to Cornish ($\sim$600 speakers), another critically endangered
language. Results show that the barrier to entry, in quantity and form, is far
lower than previously thought, giving hope to endangered language communities
that cannot afford to meet the requirements arbitrarily imposed upon them.
\\ ( https://arxiv.org/abs/2510.04832 ,  39kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04848
Date: Mon, 6 Oct 2025 14:33:38 GMT   (251kb)

Title: Instability in Downstream Task Performance During LLM Pretraining
Authors: Yuto Nishida, Masaru Isonuma, Yusuke Oda
Categories: cs.CL
Comments: Accepted to EMNLP 2025 Findings
\\
  When training large language models (LLMs), it is common practice to track
downstream task performance throughout the training process and select the
checkpoint with the highest validation score. However, downstream metrics often
exhibit substantial fluctuations, making it difficult to identify the
checkpoint that truly represents the best-performing model. In this study, we
empirically analyze the stability of downstream task performance in an LLM
trained on diverse web-scale corpora. We find that task scores frequently
fluctuate throughout training, both at the aggregate and example levels. To
address this instability, we investigate two post-hoc checkpoint integration
methods: checkpoint averaging and ensemble, motivated by the hypothesis that
aggregating neighboring checkpoints can reduce performance volatility. We
demonstrate both empirically and theoretically that these methods improve
downstream performance stability without requiring any changes to the training
procedure.
\\ ( https://arxiv.org/abs/2510.04848 ,  251kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04849
Date: Mon, 6 Oct 2025 14:36:30 GMT   (340kb)

Title: When Models Lie, We Learn: Multilingual Span-Level Hallucination
  Detection with PsiloQA
Authors: Elisei Rykov, Kseniia Petrushina, Maksim Savkin, Valerii Olisov, Artem
  Vazhentsev, Kseniia Titova, Alexander Panchenko, Vasily Konovalov, Julia
  Belikova
Categories: cs.CL
\\
  Hallucination detection remains a fundamental challenge for the safe and
reliable deployment of large language models (LLMs), especially in applications
requiring factual accuracy. Existing hallucination benchmarks often operate at
the sequence level and are limited to English, lacking the fine-grained,
multilingual supervision needed for a comprehensive evaluation. In this work,
we introduce PsiloQA, a large-scale, multilingual dataset annotated with
span-level hallucinations across 14 languages. PsiloQA is constructed through
an automated three-stage pipeline: generating question-answer pairs from
Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse
LLMs in a no-context setting, and automatically annotating hallucinated spans
using GPT-4o by comparing against golden answers and retrieved context. We
evaluate a wide range of hallucination detection methods -- including
uncertainty quantification, LLM-based tagging, and fine-tuned encoder models --
and show that encoder-based models achieve the strongest performance across
languages. Furthermore, PsiloQA demonstrates effective cross-lingual
generalization and supports robust knowledge transfer to other benchmarks, all
while being significantly more cost-efficient than human-annotated datasets.
Our dataset and results advance the development of scalable, fine-grained
hallucination detection in multilingual settings.
\\ ( https://arxiv.org/abs/2510.04849 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04850
Date: Mon, 6 Oct 2025 14:37:02 GMT   (474kb)

Title: Detecting Distillation Data from Reasoning Models
Authors: Hengxiang Zhang, Hyeong Kyu Choi, Yixuan Li, Hongxin Wei
Categories: cs.CL cs.AI
\\
  Reasoning distillation has emerged as an efficient and powerful paradigm for
enhancing the reasoning capabilities of large language models. However,
reasoning distillation may inadvertently cause benchmark contamination, where
evaluation data included in distillation datasets can inflate performance
metrics of distilled models. In this work, we formally define the task of
distillation data detection, which is uniquely challenging due to the partial
availability of distillation data. Then, we propose a novel and effective
method Token Probability Deviation (TBD), which leverages the probability
patterns of the generated output tokens. Our method is motivated by the
analysis that distilled models tend to generate near-deterministic tokens for
seen questions, while producing more low-probability tokens for unseen
questions. Our key idea behind TBD is to quantify how far the generated tokens'
probabilities deviate from a high reference probability. In effect, our method
achieves competitive detection performance by producing lower scores for seen
questions than for unseen questions. Extensive experiments demonstrate the
effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of
0.470 on the S1 dataset.
\\ ( https://arxiv.org/abs/2510.04850 ,  474kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04891
Date: Mon, 6 Oct 2025 15:11:46 GMT   (3098kb)

Title: SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful
  Requests
Authors: Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea,
  Zhijing Jin
Categories: cs.CL cs.AI cs.LG
\\
  Large language models (LLMs) are increasingly deployed in contexts where
their failures can have direct sociopolitical consequences. Yet, existing
safety benchmarks rarely test vulnerabilities in domains such as political
manipulation, propaganda and disinformation generation, or surveillance and
information control. We introduce SocialHarmBench, a dataset of 585 prompts
spanning 7 sociopolitical categories and 34 countries, designed to surface
where LLMs most acutely fail in politically charged contexts. Our evaluations
reveal several shortcomings: open-weight models exhibit high vulnerability to
harmful compliance, with Mistral-7B reaching attack success rates as high as
97% to 98% in domains such as historical revisionism, propaganda, and political
manipulation. Moreover, temporal and geographic analyses show that LLMs are
most fragile when confronted with 21st-century or pre-20th-century contexts,
and when responding to prompts tied to regions such as Latin America, the USA,
and the UK. These findings demonstrate that current safeguards fail to
generalize to high-stakes sociopolitical settings, exposing systematic biases
and raising concerns about the reliability of LLMs in preserving human rights
and democratic values. We share the SocialHarmBench benchmark at
https://huggingface.co/datasets/psyonp/SocialHarmBench.
\\ ( https://arxiv.org/abs/2510.04891 ,  3098kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04919
Date: Mon, 6 Oct 2025 15:33:35 GMT   (203kb)

Title: Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment
Authors: Davood Rafiei and Morgan Lindsay Heisler and Weiwei Zhang and
  Mohammadreza Pourreza and Yong Zhang
Categories: cs.CL cs.AI cs.DB
\\
  Supervised Fine-Tuning (SFT) is an effective method for adapting Large
Language Models (LLMs) on downstream tasks. However, variability in training
data can hinder a model's ability to generalize across domains. This paper
studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or
text to SQL), examining how well SFT training data matches the structural
characteristics of target queries and how this alignment impacts model
performance. We hypothesize that alignment can be accurately estimated by
comparing the distributions of structural SQL features across the training set,
target data, and the model's predictions prior to SFT. Through comprehensive
experiments on three large cross-domain NL2SQL benchmarks and multiple model
families, we show that structural alignment is a strong predictor of
fine-tuning success. When alignment is high, SFT yields substantial gains in
accuracy and SQL generation quality; when alignment is low, improvements are
marginal or absent. These findings highlight the importance of alignment-aware
data selection for effective fine-tuning and generalization in NL2SQL tasks.
\\ ( https://arxiv.org/abs/2510.04919 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04933
Date: Mon, 6 Oct 2025 15:41:22 GMT   (2925kb)

Title: The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination
  Detection in Large Language Models
Authors: Amir Hameed Mir
Categories: cs.CL cs.AI cs.IT cs.LG cs.NE math.IT
Comments: Comments: 14 pages, 14 figures, 5 tables. Code available at:
  https://github.com/sirraya-tech/Sirraya_LSD_Code
Report-no: (Sirraya-Labs-LSD-2025)
MSC-class: 68T50, 68T07, 62H30
ACM-class: I.2.7; I.2.6; F.2.2; H.3.3
\\
  Large Language Models (LLMs) often produce fluent yet factually incorrect
statements-a phenomenon known as hallucination-posing serious risks in
high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric
framework for hallucination detection that analyzes the evolution of
hidden-state semantics across transformer layers. Unlike prior methods that
rely on multiple sampling passes or external verification sources, LSD operates
intrinsically within the model's representational space. Using margin-based
contrastive learning, LSD aligns hidden activations with ground-truth
embeddings derived from a factual encoder, revealing a distinct separation in
semantic trajectories: factual responses preserve stable alignment, while
hallucinations exhibit pronounced semantic drift across depth. Evaluated on the
TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an
F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming
SelfCheckGPT and Semantic Entropy baselines while requiring only a single
forward pass. This efficiency yields a 5-20x speedup over sampling-based
methods without sacrificing precision or interpretability. LSD offers a
scalable, model-agnostic mechanism for real-time hallucination monitoring and
provides new insights into the geometry of factual consistency within large
language models.
\\ ( https://arxiv.org/abs/2510.04933 ,  2925kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04945
Date: Mon, 6 Oct 2025 15:46:54 GMT   (134kb)

Title: A First Context-Free Grammar Applied to Nawatl Corpora Augmentation
Authors: Juan-Jos\'e Guzm\'an-Landa, Juan-Manuel Torres-Moreno, Miguel
  Figueroa-Saavedra, Ligia Quintana-Torres, Martha-Lorena Avenda\~no-Garrido,
  Graham Ranger
Categories: cs.CL cs.AI
Comments: 11 pages, 7 tables, 1 figure
\\
  In this article we introduce a context-free grammar (CFG) for the Nawatl
language. Nawatl (or Nahuatl) is an Amerindian language of the $\pi$-language
type, i.e. a language with few digital resources, in which the corpora
available for machine learning are virtually non-existent. The objective here
is to generate a significant number of grammatically correct artificial
sentences, in order to increase the corpora available for language model
training. We want to show that a grammar enables us significantly to expand a
corpus in Nawatl which we call $\pi$-\textsc{yalli}. The corpus, thus enriched,
enables us to train algorithms such as FastText and to evaluate them on
sentence-level semantic tasks. Preliminary results show that by using the
grammar, comparative improvements are achieved over some LLMs. However, it is
observed that to achieve more significant improvement, grammars that model the
Nawatl language even more effectively are required.
\\ ( https://arxiv.org/abs/2510.04945 ,  134kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04950
Date: Mon, 6 Oct 2025 15:50:39 GMT   (337kb)

Title: Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy
  (short paper)
Authors: Om Dobariya and Akhil Kumar
Categories: cs.CL cs.AI cs.LG cs.NE stat.ME
Comments: 5 pages, 3 tables; includes Limitations and Ethical Considerations
  sections; short paper under submission to Findings of ACL 2025
\\
  The wording of natural language prompts has been shown to influence the
performance of large language models (LLMs), yet the role of politeness and
tone remains underexplored. In this study, we investigate how varying levels of
prompt politeness affect model accuracy on multiple-choice questions. We
created a dataset of 50 base questions spanning mathematics, science, and
history, each rewritten into five tone variants: Very Polite, Polite, Neutral,
Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we
evaluated responses across these conditions and applied paired sample t-tests
to assess statistical significance. Contrary to expectations, impolite prompts
consistently outperformed polite ones, with accuracy ranging from 80.8% for
Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from
earlier studies that associated rudeness with poorer outcomes, suggesting that
newer LLMs may respond differently to tonal variation. Our results highlight
the importance of studying pragmatic aspects of prompting and raise broader
questions about the social dimensions of human-AI interaction.
\\ ( https://arxiv.org/abs/2510.04950 ,  337kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04983
Date: Mon, 6 Oct 2025 16:19:57 GMT   (294kb)

Title: AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework
  for Identifying Cultural Capital in STEM Narratives
Authors: Khalid Mehtab Khan, Anagha Kulkarni
Categories: cs.CL cs.AI cs.CY cs.LG
\\
  Identifying cultural capital (CC) themes in student reflections can offer
valuable insights that help foster equitable learning environments in
classrooms. However, themes such as aspirational goals or family support are
often woven into narratives, rather than appearing as direct keywords. This
makes them difficult to detect for standard NLP models that process sentences
in isolation. The core challenge stems from a lack of awareness, as standard
models are pre-trained on general corpora, leaving them blind to the
domain-specific language and narrative context inherent to the data. To address
this, we introduce AWARE, a framework that systematically attempts to improve a
transformer model's awareness for this nuanced task. AWARE has three core
components: 1) Domain Awareness, adapting the model's vocabulary to the
linguistic style of student reflections; 2) Context Awareness, generating
sentence embeddings that are aware of the full essay context; and 3) Class
Overlap Awareness, employing a multi-label strategy to recognize the
coexistence of themes in a single sentence. Our results show that by making the
model explicitly aware of the properties of the input, AWARE outperforms a
strong baseline by 2.1 percentage points in Macro-F1 and shows considerable
improvements across all themes. This work provides a robust and generalizable
methodology for any text classification task in which meaning depends on the
context of the narrative.
\\ ( https://arxiv.org/abs/2510.04983 ,  294kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05003
Date: Mon, 6 Oct 2025 16:42:11 GMT   (211kb)

Title: Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical
  Chain-of-Thought Reasoning
Authors: Imran Mansha
Categories: cs.CL cs.AI
Comments: 6 pages, 2 figures. Submitted to arXiv for open access
\\
  Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated
remarkable reasoning abilities but require significant computational resources
for fine-tuning. This paper presents a resource-efficient fine-tuning approach
for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating
under constrained GPU and memory settings. Using parameter-efficient tuning
techniques such as LoRA and QLoRA, we adapt the base model on publicly
available medical reasoning datasets. The model achieves improved reasoning
coherence and factual accuracy while reducing memory usage by up to 60%
compared to standard full fine-tuning. Experimental evaluation demonstrates
that lightweight adaptations can retain strong reasoning capability in medical
question-answering tasks. This work highlights practical strategies for
deploying LLMs in low-resource research environments and provides insights into
balancing efficiency and domain specialization for medical AI systems.
\\ ( https://arxiv.org/abs/2510.05003 ,  211kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05025
Date: Mon, 6 Oct 2025 17:03:50 GMT   (1671kb)

Title: Imperceptible Jailbreaking against Large Language Models
Authors: Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia,
  Tianyu Pang
Categories: cs.CL cs.AI cs.CR
\\
  Jailbreaking attacks on the vision modality typically rely on imperceptible
adversarial perturbations, whereas attacks on the textual modality are
generally assumed to require visible modifications (e.g., non-semantic
suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a
class of Unicode characters called variation selectors. By appending invisible
variation selectors to malicious questions, the jailbreak prompts appear
visually identical to original malicious questions on screen, while their
tokenization is "secretly" altered. We propose a chain-of-search pipeline to
generate such adversarial suffixes to induce harmful responses. Our experiments
show that our imperceptible jailbreaks achieve high attack success rates
against four aligned LLMs and generalize to prompt injection attacks, all
without producing any visible modifications in the written prompt. Our code is
available at https://github.com/sail-sg/imperceptible-jailbreaks.
\\ ( https://arxiv.org/abs/2510.05025 ,  1671kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05026
Date: Mon, 6 Oct 2025 17:04:22 GMT   (95kb)

Title: A Set of Quebec-French Corpus of Regional Expressions and Terms
Authors: David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury
Categories: cs.CL
Comments: Submitted to ACL Rolling Review of October
\\
  The tasks of idiom understanding and dialect understanding are both
well-established benchmarks in natural language processing. In this paper, we
propose combining them, and using regional idioms as a test of dialect
understanding. Towards this end, we propose two new benchmark datasets for the
Quebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic
phrases, and QFrCoRT, which comprises 171 regional instances of idiomatic
words. We explain how to construct these corpora, so that our methodology can
be replicated for other dialects. Our experiments with 94 LLM demonstrate that
our regional idiom benchmarks are a reliable tool for measuring a model's
proficiency in a specific dialect.
\\ ( https://arxiv.org/abs/2510.05026 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05038
Date: Mon, 6 Oct 2025 17:12:53 GMT   (643kb)

Title: Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time
  Optimization
Authors: Omri Uzan, Asaf Yehudai, Roi pony, Eyal Shnarch, Ariel Gera
Categories: cs.CL
\\
  Multimodal encoders have pushed the boundaries of visual document retrieval,
matching textual query tokens directly to image patches and achieving
state-of-the-art performance on public benchmarks. Recent models relying on
this paradigm have massively scaled the sizes of their query and document
representations, presenting obstacles to deployment and scalability in
real-world pipelines. Furthermore, purely vision-centric approaches may be
constrained by the inherent modality gap still exhibited by modern
vision-language models. In this work, we connect these challenges to the
paradigm of hybrid retrieval, investigating whether a lightweight dense text
retriever can enhance a stronger vision-centric model. Existing hybrid methods,
which rely on coarse-grained fusion of ranks or scores, fail to exploit the
rich interactions within each model's representation space. To address this, we
introduce Guided Query Refinement (GQR), a novel test-time optimization method
that refines a primary retriever's query embedding using guidance from a
complementary retriever's scores. Through extensive experiments on visual
document retrieval benchmarks, we demonstrate that GQR allows vision-centric
models to match the performance of models with significantly larger
representations, while being up to 14x faster and requiring 54x less memory.
Our findings show that GQR effectively pushes the Pareto frontier for
performance and efficiency in multimodal retrieval. We release our code at
https://github.com/IBM/test-time-hybrid-retrieval
\\ ( https://arxiv.org/abs/2510.05038 ,  643kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05046
Date: Mon, 6 Oct 2025 17:26:41 GMT   (91kb)

Title: COLE: a Comprehensive Benchmark for French Language Understanding
  Evaluation
Authors: David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury
Categories: cs.CL
Comments: Submitted to ACL Rolling Review of October
\\
  To address the need for a more comprehensive evaluation of French Natural
Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23
diverse task covering a broad range of NLU capabilities, including sentiment
analysis, paraphrase detection, grammatical judgment, and reasoning, with a
particular focus on linguistic phenomena relevant to the French language. We
benchmark 94 large language models (LLM), providing an extensive analysis of
the current state of French NLU. Our results highlight a significant
performance gap between closed- and open-weights models and identify key
challenging frontiers for current LLMs, such as zero-shot extractive
question-answering (QA), fine-grained word sense disambiguation, and
understanding of regional language variations. We release COLE as a public
resource to foster further progress in French language modelling.
\\ ( https://arxiv.org/abs/2510.05046 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05069
Date: Mon, 6 Oct 2025 17:46:34 GMT   (5499kb)

Title: SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior
  Reasoning LLMs
Authors: Dachuan Shi, Abedelkadir Asi, Keying Li, Xiangchi Yuan, Leyan Pan,
  Wenke Lee, Wen Xiao
Categories: cs.CL cs.AI
Comments: Code: https://github.com/sdc17/SwiReasoning, Website:
  https://swireasoning.github.io/
\\
  Recent work shows that, beyond discrete reasoning through explicit
chain-of-thought steps, which are limited by the boundaries of natural
languages, large language models (LLMs) can also reason continuously in latent
space, allowing richer information per step and thereby improving token
efficiency. Despite this promise, latent reasoning still faces two challenges,
especially in training-free settings: 1) purely latent reasoning broadens the
search distribution by maintaining multiple implicit paths, which diffuses
probability mass, introduces noise, and impedes convergence to a single
high-confidence solution, thereby hurting accuracy; and 2) overthinking
persists even without explicit text, wasting tokens and degrading efficiency.
To address these issues, we introduce SwiReasoning, a training-free framework
for LLM reasoning which features two key innovations: 1) SwiReasoning
dynamically switches between explicit and latent reasoning, guided by
block-wise confidence estimated from entropy trends in next-token
distributions, to balance exploration and exploitation and promote timely
convergence. 2) By limiting the maximum number of thinking-block switches,
SwiReasoning curbs overthinking and improves token efficiency across varying
problem difficulties. On widely used mathematics and STEM benchmarks,
SwiReasoning consistently improves average accuracy by 1.5%-2.8% across
reasoning LLMs of different model families and scales. Furthermore, under
constrained budgets, SwiReasoning improves average token efficiency by 56%-79%,
with larger gains as budgets tighten.
\\ ( https://arxiv.org/abs/2510.05069 ,  5499kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05077
Date: Mon, 6 Oct 2025 17:49:58 GMT   (588kb)

Title: Slm-mux: Orchestrating small language models for reasoning
Authors: Chenyu Wang, Zishen Wan, Hao Kang, Emma Chen, Zhiqiang Xie, Tushar
  Krishna, Vijay Janapa Reddi, Yilun Du
Categories: cs.CL cs.AI
\\
  With the rapid development of language models, the number of small language
models (SLMs) has grown significantly. Although they do not achieve
state-of-the-art accuracy, they are more efficient and often excel at specific
tasks. This raises a natural question: can multiple SLMs be orchestrated into a
system where each contributes effectively, achieving higher accuracy than any
individual model? Existing orchestration methods have primarily targeted
frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To
address this gap, we propose a three-stage approach for orchestrating SLMs.
First, we introduce SLM-MUX, a multi-model architecture that effectively
coordinates multiple SLMs. Building on this, we develop two optimization
strategies: (i) a model selection search that identifies the most complementary
SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our
approach delivers strong results: Compared to existing orchestration methods,
our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%
on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and
GSM8K, and matches its performance on MATH. We further provide theoretical
analyses to substantiate the advantages of our method. In summary, we
demonstrate that SLMs can be effectively orchestrated into more accurate and
efficient systems through the proposed approach.
\\ ( https://arxiv.org/abs/2510.05077 ,  588kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05087
Date: Mon, 6 Oct 2025 17:55:04 GMT   (7410kb)

Title: TeachLM: Post-Training LLMs for Education Using Authentic Learning Data
Authors: Janos Perczel, Jin Chow, Dorottya Demszky
Categories: cs.CL cs.AI
Comments: 28 pages, 9 figures
\\
  The promise of generative AI to revolutionize education is constrained by the
pedagogical limits of large language models (LLMs). A major issue is the lack
of access to high-quality training data that reflect the learning of actual
students. Prompt engineering has emerged as a stopgap, but the ability of
prompts to encode complex pedagogical strategies in rule-based natural language
is inherently limited. To address this gap we introduce TeachLM - an LLM
optimized for teaching through parameter-efficient fine-tuning of
state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000
hours of one-on-one, longitudinal student-tutor interactions maintained by
Polygence, which underwent a rigorous anonymization process to protect privacy.
We use parameter-efficient fine-tuning to develop an authentic student model
that enables the generation of high-fidelity synthetic student-tutor dialogues.
Building on this capability, we propose a novel multi-turn evaluation protocol
that leverages synthetic dialogue generation to provide fast, scalable, and
reproducible assessments of the dialogical capabilities of LLMs. Our
evaluations demonstrate that fine-tuning on authentic learning data
significantly improves conversational and pedagogical performance - doubling
student talk time, improving questioning style, increasing dialogue turns by
50%, and greater personalization of instruction.
\\ ( https://arxiv.org/abs/2510.05087 ,  7410kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05090
Date: Mon, 6 Oct 2025 17:56:46 GMT   (846kb)

Title: Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for
  Diffusion Large Language Models
Authors: Runchu Tian, Junxia Cui, Xueqiang Xu, Feng Yao, Jingbo Shang
Categories: cs.CL cs.AI
Comments: 17 pages, 8 figures. Work in progress
\\
  Diffusion large language models (dLLMs) have recently emerged as a promising
alternative to autoregressive (AR) models, offering advantages such as
accelerated parallel decoding and bidirectional context modeling. However, the
vanilla decoding strategy in discrete dLLMs suffers from a critical limitation:
once a token is accepted, it can no longer be revised in subsequent steps. As a
result, early mistakes persist across iterations, harming both intermediate
predictions and final output quality. To address this issue, we propose
Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding
strategy that leverages cross-validation among predicted tokens. Unlike
existing methods that follow a single progressive unmasking procedure,
Tolerator introduces a two-stage process: (i) sequence fill-up and (ii)
iterative refinement by remasking and decoding a subset of tokens while
treating the remaining as context. This design enables previously accepted
tokens to be reconsidered and corrected when necessary, leading to more
reliable diffusion decoding outputs. We evaluate Tolerator on five standard
benchmarks covering language understanding, code generation, and mathematics.
Experiments show that our method achieves consistent improvements over the
baselines under the same computational budget. These findings suggest that
decoding algorithms are crucial to realizing the full potential of diffusion
large language models. Code and data are publicly available.
\\ ( https://arxiv.org/abs/2510.05090 ,  846kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03287
Date: Mon, 29 Sep 2025 04:14:11 GMT   (10030kb)

Title: SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific
  Tumor Dynamics
Authors: Moinak Bhattacharya, Gagandeep Singh, Prateek Prasanna
Categories: cs.CV
\\
  Accurate prediction of tumor trajectories under standard-of-care (SoC)
therapies remains a major unmet need in oncology. This capability is essential
for optimizing treatment planning and anticipating disease progression.
Conventional reaction-diffusion models are limited in scope, as they fail to
capture tumor dynamics under heterogeneous therapeutic paradigms. There is
hence a critical need for computational frameworks that can realistically
simulate SoC interventions while accounting for inter-patient variability in
genomics, demographics, and treatment regimens. We introduce Standard-of-Care
Digital Twin (SoC-DT), a differentiable framework that unifies
reaction-diffusion tumor growth models, discrete SoC interventions (surgery,
chemotherapy, radiotherapy) along with genomic and demographic personalization
to predict post-treatment tumor structure on imaging. An implicit-explicit
exponential time-differencing solver, IMEX-SoC, is also proposed, which ensures
stability, positivity, and scalability in SoC treatment situations. Evaluated
on both synthetic data and real world glioma data, SoC-DT consistently
outperforms classical PDE baselines and purely data-driven neural models in
predicting tumor dynamics. By bridging mechanistic interpretability with modern
differentiable solvers, SoC-DT establishes a principled foundation for
patient-specific digital twins in oncology, enabling biologically consistent
tumor dynamics estimation. Code will be made available upon acceptance.
\\ ( https://arxiv.org/abs/2510.03287 ,  10030kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03292
Date: Mon, 29 Sep 2025 16:29:11 GMT   (3422kb)

Title: Visualizing Celebrity Dynamics in Video Content: A Proposed Approach
  Using Face Recognition Timestamp Data
Authors: Do\u{g}anay Demir, \.Ilknur Durgar Elkahlout
Categories: cs.CV
\\
  In an era dominated by video content, understanding its structure and
dynamics has become increasingly important. This paper presents a hybrid
framework that combines a distributed multi-GPU inference system with an
interactive visualization platform for analyzing celebrity dynamics in video
episodes. The inference framework efficiently processes large volumes of video
data by leveraging optimized ONNX models, heterogeneous batch inference, and
high-throughput parallelism, ensuring scalable generation of timestamped
appearance records. These records are then transformed into a comprehensive
suite of visualizations, including appearance frequency charts, duration
analyses, pie charts, co-appearance matrices, network graphs, stacked area
charts, seasonal comparisons, and heatmaps. Together, these visualizations
provide multi-dimensional insights into video content, revealing patterns in
celebrity prominence, screen-time distribution, temporal dynamics,
co-appearance relationships, and intensity across episodes and seasons. The
interactive nature of the system allows users to dynamically explore data,
identify key moments, and uncover evolving relationships between individuals.
By bridging distributed recognition with structured, visually-driven analytics,
this work enables new possibilities for entertainment analytics, content
creation strategies, and audience engagement studies.
\\ ( https://arxiv.org/abs/2510.03292 ,  3422kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03294
Date: Mon, 29 Sep 2025 17:15:07 GMT   (1177kb)

Title: Domain-Robust Marine Plastic Detection Using Vision Models
Authors: Saanvi Kataria
Categories: cs.CV
Comments: 16 pages, 5 figures, 1 table
\\
  Marine plastic pollution is a pressing environmental threat, making reliable
automation for underwater debris detection essential. However, vision systems
trained on one dataset often degrade on new imagery due to domain shift. This
study benchmarks models for cross-domain robustness, training convolutional
neural networks - CNNs (MobileNetV2, ResNet-18, EfficientNet-B0) and vision
transformers (DeiT-Tiny, ViT-B16) on a labeled underwater dataset and then
evaluates them on a balanced cross-domain test set built from plastic-positive
images drawn from a different source and negatives from the training domain.
Two zero-shot models were assessed, CLIP ViT-L14 and Google's Gemini 2.0 Flash,
that leverage pretraining to classify images without fine-tuning. Results show
the lightweight MobileNetV2 delivers the strongest cross-domain performance (F1
0.97), surpassing larger models. All fine-tuned models achieved high Precision
(around 99%), but differ in Recall, indicating varying sensitivity to plastic
instances. Zero-shot CLIP is comparatively sensitive (Recall around 80%) yet
prone to false positives (Precision around 56%), whereas Gemini exhibits the
inverse profile (Precision around 99%, Recall around 81%). Error analysis
highlights recurring confusions with coral textures, suspended particulates,
and specular glare. Overall, compact CNNs with supervised training can
generalize effectively for cross-domain underwater detection, while large
pretrained vision-language models provide complementary strengths.
\\ ( https://arxiv.org/abs/2510.03294 ,  1177kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03295
Date: Mon, 29 Sep 2025 18:52:38 GMT   (250kb)

Title: Multimodal Arabic Captioning with Interpretable Visual Concept
  Integration
Authors: Passant Elchafei, Amany Fashwan
Categories: cs.CV cs.CL cs.LG
\\
  We present VLCAP, an Arabic image captioning framework that integrates
CLIP-based visual label retrieval with multimodal text generation. Rather than
relying solely on end-to-end captioning, VLCAP grounds generation in
interpretable Arabic visual concepts extracted with three multilingual
encoders, mCLIP, AraCLIP, and Jina V4, each evaluated separately for label
retrieval. A hybrid vocabulary is built from training captions and enriched
with about 21K general domain labels translated from the Visual Genome dataset,
covering objects, attributes, and scenes. The top-k retrieved labels are
transformed into fluent Arabic prompts and passed along with the original image
to vision-language models. In the second stage, we tested Qwen-VL and Gemini
Pro Vision for caption generation, resulting in six encoder-decoder
configurations. The results show that mCLIP + Gemini Pro Vision achieved the
best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL
obtained the highest LLM-judge score (36.33%). This interpretable pipeline
enables culturally coherent and contextually accurate Arabic captions.
\\ ( https://arxiv.org/abs/2510.03295 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03297
Date: Mon, 29 Sep 2025 21:41:22 GMT   (831kb)

Title: Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study
  with Balanced vs Imbalanced Regimes
Authors: Akshar Gothi
Categories: cs.CV cs.AI cs.LG
Comments: 5 pages, 1 figure, 9 tables. Code and artifacts:
  https://github.com/akshar27/spacenet-cnn-vs-vit (release v1.0.1)
\\
  We present a controlled comparison of a convolutional neural network
(EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two
label-distribution regimes: a naturally imbalanced five-class split and a
balanced-resampled split with 700 images per class (70:20:10 train/val/test).
With matched preprocessing (224x224, ImageNet normalization), lightweight
augmentations, and a 40-epoch budget on a single NVIDIA P100, we report
accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics
(model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93%
test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive
at 93% with a larger parameter count and runtime. On the balanced split, both
models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains
competitive, indicating that balancing narrows architecture gaps while CNNs
retain an efficiency edge. We release manifests, logs, and per-image
predictions to support reproducibility.
\\ ( https://arxiv.org/abs/2510.03297 ,  831kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03314
Date: Tue, 30 Sep 2025 23:50:55 GMT   (12579kb)

Title: A Comprehensive Review on Artificial Intelligence Empowered Solutions
  for Enhancing Pedestrian and Cyclist Safety
Authors: Shucheng Zhang, Yan Shi, Bingzhang Wang, Yuang Zhang, Muhammad
  Monjurul Karim, Kehua Chen, Chenxi Liu, Mehrdad Nasri, Yinhai Wang
Categories: cs.CV cs.AI
Comments: 20 pages, 4 figures, 5 tables
\\
  Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and
cyclists, remains a critical global challenge, as conventional
infrastructure-based measures often prove inadequate in dynamic urban
environments. Recent advances in artificial intelligence (AI), particularly in
visual perception and reasoning, open new opportunities for proactive and
context-aware VRU protection. However, existing surveys on AI applications for
VRUs predominantly focus on detection, offering limited coverage of other
vision-based tasks that are essential for comprehensive VRU understanding and
protection. This paper presents a state-of-the-art review of recent progress in
camera-based AI sensing systems for VRU safety, with an emphasis on
developments from the past five years and emerging research trends. We
systematically examine four core tasks, namely detection and classification,
tracking and reidentification, trajectory prediction, and intent recognition
and prediction, which together form the backbone of AI-empowered proactive
solutions for VRU protection in intelligent transportation systems. To guide
future research, we highlight four major open challenges from the perspectives
of data, model, and deployment. By linking advances in visual AI with practical
considerations for real-world implementation, this survey aims to provide a
foundational reference for the development of next-generation sensing systems
to enhance VRU safety.
\\ ( https://arxiv.org/abs/2510.03314 ,  12579kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03316
Date: Wed, 1 Oct 2025 00:53:45 GMT   (840kb)

Title: The View From Space: Navigating Instrumentation Differences with EOFMs
Authors: Ryan P. Demilt, Nicholas LaHaye, Karis Tenneson
Categories: cs.CV cs.AI cs.LG
\\
  Earth Observation Foundation Models (EOFMs) have exploded in prevalence as
tools for processing the massive volumes of remotely sensed and other earth
observation data, and for delivering impact on the many essential earth
monitoring tasks. An emerging trend posits using the outputs of pre-trained
models as 'embeddings' which summarize high dimensional data to be used for
generic tasks such as similarity search and content-specific queries. However,
most EOFM models are trained only on single modalities of data and then applied
or benchmarked by matching bands across different modalities. It is not clear
from existing work what impact diverse sensor architectures have on the
internal representations of the present suite of EOFMs. We show in this work
that the representation space of EOFMs is highly sensitive to sensor
architecture and that understanding this difference gives a vital perspective
on the pitfalls of current EOFM design and signals for how to move forward as
model developers, users, and a community guided by robust remote-sensing
science.
\\ ( https://arxiv.org/abs/2510.03316 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03317
Date: Wed, 1 Oct 2025 01:18:27 GMT   (559kb)

Title: Photorealistic Inpainting for Perturbation-based Explanations in
  Ecological Monitoring
Authors: G\"unel Aghakishiyeva, Jiayi Zhou, Saagar Arya, James David Poling,
  Holly R. Houliston, Jamie N. Womble, David W. Johnston, Brinnae Bent
Categories: cs.CV cs.AI
Comments: Accepted to NeurIPS 2025 Imageomics Workshop
\\
  Ecological monitoring is increasingly automated by vision models, yet opaque
predictions limit trust and field adoption. We present an inpainting-guided,
perturbation-based explanation technique that produces photorealistic,
mask-localized edits that preserve scene context. Unlike masking or blurring,
these edits stay in-distribution and reveal which fine-grained morphological
cues drive predictions in tasks such as species recognition and trait
attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for
harbor seal detection in Glacier Bay drone imagery, using
Segment-Anything-Model-refined masks to support two interventions: (i) object
removal/replacement (e.g., replacing seals with plausible ice/water or boats)
and (ii) background replacement with original animals composited onto new
scenes. Explanations are assessed by re-scoring perturbed images (flip rate,
confidence drop) and by expert review for ecological plausibility and
interpretability. The resulting explanations localize diagnostic structures,
avoid deletion artifacts common to traditional perturbations, and yield
domain-relevant insights that support expert validation and more trustworthy
deployment of AI in ecology.
\\ ( https://arxiv.org/abs/2510.03317 ,  559kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03318
Date: Wed, 1 Oct 2025 01:34:38 GMT   (5685kb)

Title: Advances in Medical Image Segmentation: A Comprehensive Survey with a
  Focus on Lumbar Spine Applications
Authors: Ahmed Kabil, Ghada Khoriba, Mina Yousef, Essam A. Rashed
Categories: cs.CV
Comments: Computers in Biology and Medicine (to appear)
\\
  Medical Image Segmentation (MIS) stands as a cornerstone in medical image
analysis, playing a pivotal role in precise diagnostics, treatment planning,
and monitoring of various medical conditions. This paper presents a
comprehensive and systematic survey of MIS methodologies, bridging the gap
between traditional image processing techniques and modern deep learning
approaches. The survey encompasses thresholding, edge detection, region-based
segmentation, clustering algorithms, and model-based techniques while also
delving into state-of-the-art deep learning architectures such as Convolutional
Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely
adopted U-Net and its variants. Moreover, integrating attention mechanisms,
semi-supervised learning, generative adversarial networks (GANs), and
Transformer-based models is thoroughly explored. In addition to covering
established methods, this survey highlights emerging trends, including hybrid
architectures, cross-modality learning, federated and distributed learning
frameworks, and active learning strategies, which aim to address challenges
such as limited labeled datasets, computational complexity, and model
generalizability across diverse imaging modalities. Furthermore, a specialized
case study on lumbar spine segmentation is presented, offering insights into
the challenges and advancements in this relatively underexplored anatomical
region. Despite significant progress in the field, critical challenges persist,
including dataset bias, domain adaptation, interpretability of deep learning
models, and integration into real-world clinical workflows.
\\ ( https://arxiv.org/abs/2510.03318 ,  5685kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03328
Date: Wed, 1 Oct 2025 18:22:03 GMT   (2200kb)

Title: DECOR: Deep Embedding Clustering with Orientation Robustness
Authors: Fiona Victoria Stanley Jothiraj, Arunaggiri Pandian Karunanidhi, Seth
  A. Eichmeyer
Categories: cs.CV cs.LG
\\
  In semiconductor manufacturing, early detection of wafer defects is critical
for product yield optimization. However, raw wafer data from wafer quality
tests are often complex, unlabeled, imbalanced and can contain multiple defects
on a single wafer, making it crucial to design clustering methods that remain
reliable under such imperfect data conditions. We introduce DECOR, a deep
clustering with orientation robustness framework that groups complex defect
patterns from wafer maps into consistent clusters. We evaluate our method on
the open source MixedWM38 dataset, demonstrating its ability to discover
clusters without manual tuning. DECOR explicitly accounts for orientation
variations in wafer maps, ensuring that spatially similar defects are
consistently clustered regardless of its rotation or alignment. Experiments
indicate that our method outperforms existing clustering baseline methods, thus
providing a reliable and scalable solution in automated visual inspection
systems.
\\ ( https://arxiv.org/abs/2510.03328 ,  2200kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03337
Date: Thu, 2 Oct 2025 09:31:51 GMT   (1893kb)

Title: Error correction in multiclass image classification of facial emotion on
  unbalanced samples
Authors: Andrey A. Lebedev, Victor B. Kazantsev, Sergey V. Stasenko
Categories: cs.CV q-bio.NC
\\
  This paper considers the problem of error correction in multi-class
classification of face images on unbalanced samples. The study is based on the
analysis of a data frame containing images labeled by seven different emotional
states of people of different ages. Particular attention is paid to the problem
of class imbalance, in which some emotions significantly prevail over others.
To solve the classification problem, a neural network model based on LSTM with
an attention mechanism focusing on key areas of the face that are informative
for emotion recognition is used. As part of the experiments, the model is
trained on all possible configurations of subsets of six classes with
subsequent error correction for the seventh class, excluded at the training
stage. The results show that correction is possible for all classes, although
the degree of success varies: some classes are better restored, others are
worse. In addition, on the test sample, when correcting some classes, an
increase in key quality metrics for small classes was recorded, which indicates
the promise of the proposed approach in solving applied problems related to the
search for rare events, for example, in anti-fraud systems. Thus, the proposed
method can be effectively applied in facial expression analysis systems and in
tasks requiring stable classification under skewed class distribution.
\\ ( https://arxiv.org/abs/2510.03337 ,  1893kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03341
Date: Thu, 2 Oct 2025 13:19:18 GMT   (1524kb)

Title: OpusAnimation: Code-Based Dynamic Chart Generation
Authors: Bozheng Li, Miao Yang, Zhenhan Chen, Jiawang Cao, Mushui Liu, Yi Lu,
  Yongliang Wu, Bin Zhang, Yangguang Ji, Licheng Tang, Jay Wu, Wenbo Zhu
Categories: cs.CV
Comments: working in progress
\\
  Dynamic Chart Generation (DCG) involves producing code-rendered animated
visualizations as charts. While recent advances in multi-modal large language
models (MLLMs) have significantly improved their capability on static chart
generation and comprehension, MLLMs' potential for handling dynamic chart
generation and understanding remains underexplored. To bridge this research
gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first
benchmark evaluating MLLM's capability on dynamic chart generation tasks from
three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and
Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with
annotations covering instruction-code-video triplets and QA pairs for both code
and video evaluation. Based on DCG-8K, we explored a two-stage training recipe,
proposing Joint-Code-Visual Reward for group relative policy optimization to
construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking
result reveals shortcomings of existing MLLMs in the visual-to-chart task, and
our model beats the best open-sourced MLLM with an average 8.31% performance
gain across three tasks, and shows on par performance against proprietary
models with only 3B parameters, proving the effectiveness of our training
recipe. Our code and dataset will be publicly available.
\\ ( https://arxiv.org/abs/2510.03341 ,  1524kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03348
Date: Thu, 2 Oct 2025 17:00:14 GMT   (4427kb)

Title: Visual Odometry with Transformers
Authors: Vlardimir Yugay, Duy-Kien Nguyen, Theo Gevers, Cees G. M. Snoek,
  Martin R. Oswald
Categories: cs.CV
\\
  Modern monocular visual odometry methods typically combine pre-trained deep
learning components with optimization modules, resulting in complex pipelines
that rely heavily on camera calibration and hyperparameter tuning, and often
struggle in unseen real-world scenarios. Recent large-scale 3D models trained
on massive amounts of multi-modal data have partially alleviated these
challenges, providing generalizable dense reconstruction and camera pose
estimation. Still, they remain limited in handling long videos and providing
accurate per-frame estimates, which are required for visual odometry. In this
work, we demonstrate that monocular visual odometry can be addressed
effectively in an end-to-end manner, thereby eliminating the need for
handcrafted components such as bundle adjustment, feature matching, camera
calibration, or dense 3D reconstruction. We introduce VoT, short for Visual
odometry Transformer, which processes sequences of monocular frames by
extracting features and modeling global relationships through temporal and
spatial attention. Unlike prior methods, VoT directly predicts camera motion
without estimating dense geometry and relies solely on camera poses for
supervision. The framework is modular and flexible, allowing seamless
integration of various pre-trained encoders as feature extractors. Experimental
results demonstrate that VoT scales effectively with larger datasets, benefits
substantially from stronger pre-trained backbones, generalizes across diverse
camera motions and calibration settings, and outperforms traditional methods
while running more than 3 times faster. The code will be released.
\\ ( https://arxiv.org/abs/2510.03348 ,  4427kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03352
Date: Thu, 2 Oct 2025 20:16:00 GMT   (31971kb)

Title: Inference-Time Search using Side Information for Diffusion-based Image
  Reconstruction
Authors: Mahdi Farahbakhsh, Vishnu Teja Kunde, Dileep Kalathil, Krishna
  Narayanan, Jean-Francois Chamberland
Categories: cs.CV cs.AI cs.LG
\\
  Diffusion models have emerged as powerful priors for solving inverse
problems. However, existing approaches typically overlook side information that
could significantly improve reconstruction quality, especially in severely
ill-posed settings. In this work, we propose a novel inference-time search
algorithm that guides the sampling process using the side information in a
manner that balances exploration and exploitation. This enables more accurate
and reliable reconstructions, providing an alternative to the gradient-based
guidance that is prone to reward-hacking artifacts. Our approach can be
seamlessly integrated into a wide range of existing diffusion-based image
reconstruction pipelines. Through extensive experiments on a number of inverse
problems, such as box inpainting, super-resolution, and various deblurring
tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that
our approach consistently improves the qualitative and quantitative performance
of diffusion-based image reconstruction algorithms. We also show the superior
performance of our approach with respect to other baselines, including reward
gradient-based guidance algorithms. The code is available at
\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this
repository}.
\\ ( https://arxiv.org/abs/2510.03352 ,  31971kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03353
Date: Thu, 2 Oct 2025 20:39:29 GMT   (3728kb)

Title: Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges,
  and Applications
Authors: Larissa S. Gomes, Gustavo P. Almeida, Bryan U. Moreira, Marco Quiroz,
  Breno Xavier, Lucas Soares, Stephanie L. Bri\~ao, Felipe G. Oliveira, and
  Paulo L. J. Drews-Jr
Categories: cs.CV
Comments: Published in the Conference on Graphics, Patterns and Images
  (SIBGRAPI). This 4-page paper presents a timeline of publicly available
  datasets up to the year 2025
ACM-class: I.4.9; I.5.0; H.3.1; I.2.6
\\
  Sonar images are relevant for advancing underwater exploration, autonomous
navigation, and ecosystem monitoring. However, the progress depends on data
availability. The scarcity of publicly available, well-annotated sonar image
datasets creates a significant bottleneck for the development of robust machine
learning models. This paper presents a comprehensive and concise review of the
current landscape of sonar image datasets, seeking not only to catalog existing
resources but also to contextualize them, identify gaps, and provide a clear
roadmap, serving as a base guide for researchers of any kind who wish to start
or advance in the field of underwater acoustic data analysis. We mapped
publicly accessible datasets across various sonar modalities, including Side
Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS),
Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar
(DIDSON). An analysis was conducted on applications such as classification,
detection, segmentation, and 3D reconstruction. This work focuses on
state-of-the-art advancements, incorporating newly released datasets. The
findings are synthesized into a master table and a chronological timeline,
offering a clear and accessible comparison of characteristics, sizes, and
annotation details datasets.
\\ ( https://arxiv.org/abs/2510.03353 ,  3728kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03356
Date: Thu, 2 Oct 2025 23:11:04 GMT   (3609kb)

Title: Learned Display Radiance Fields with Lensless Cameras
Authors: Ziyang Chen, Yuta Itoh, Kaan Ak\c{s}it
Categories: cs.CV cs.ET
\\
  Calibrating displays is a basic and regular task that content creators must
perform to maintain optimal visual experience, yet it remains a troublesome
issue. Measuring display characteristics from different viewpoints often
requires specialized equipment and a dark room, making it inaccessible to most
users. To avoid specialized hardware requirements in display calibrations, our
work co-designs a lensless camera and an Implicit Neural Representation based
algorithm for capturing display characteristics from various viewpoints. More
specifically, our pipeline enables efficient reconstruction of light fields
emitted from a display from a viewing cone of 46.6{\deg} X 37.6{\deg}. Our
emerging pipeline paves the initial steps towards effortless display
calibration and characterization.
\\ ( https://arxiv.org/abs/2510.03356 ,  3609kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03361
Date: Fri, 3 Oct 2025 01:48:38 GMT   (15501kb)

Title: Provenance Networks: End-to-End Exemplar-Based Explainability
Authors: Ali Kayyam, Anusha Madan Gopal, M. Anthony Lewis
Categories: cs.CV cs.AI cs.LG
\\
  We introduce provenance networks, a novel class of neural models designed to
provide end-to-end, training-data-driven explainability. Unlike conventional
post-hoc methods, provenance networks learn to link each prediction directly to
its supporting training examples as part of the model's normal operation,
embedding interpretability into the architecture itself. Conceptually, the
model operates similarly to a learned KNN, where each output is justified by
concrete exemplars weighted by relevance in the feature space. This approach
facilitates systematic investigations of the trade-off between memorization and
generalization, enables verification of whether a given input was included in
the training set, aids in the detection of mislabeled or anomalous data points,
enhances resilience to input perturbations, and supports the identification of
similar inputs contributing to the generation of a new data point. By jointly
optimizing the primary task and the explainability objective, provenance
networks offer insights into model behavior that traditional deep networks
cannot provide. While the model introduces additional computational cost and
currently scales to moderately sized datasets, it provides a complementary
approach to existing explainability techniques. In particular, it addresses
critical challenges in modern deep learning, including model opaqueness,
hallucination, and the assignment of credit to data contributors, thereby
improving transparency, robustness, and trustworthiness in neural models.
\\ ( https://arxiv.org/abs/2510.03361 ,  15501kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03363
Date: Fri, 3 Oct 2025 03:28:18 GMT   (31591kb)

Title: Unified Unsupervised Anomaly Detection via Matching Cost Filtering
Authors: Zhe Zhang, Mingxiu Cai, Gaochang Wu, Jing Zhang, Lingqiao Liu, Dacheng
  Tao, Tianyou Chai, Xiatian Zhu
Categories: cs.CV cs.AI eess.IV
Comments: 63 pages (main paper and supplementary material), 39 figures, 58
  tables. Submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)
\\
  Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level
anomalies using only normal training data, with wide applications such as
industrial inspection and medical analysis, where anomalies are scarce due to
privacy concerns and cold-start constraints. Existing methods, whether
reconstruction-based (restoring normal counterparts) or embedding-based
(pretrained representations), fundamentally conduct image- or feature-level
matching to generate anomaly maps. Nonetheless, matching noise has been largely
overlooked, limiting their detection ability. Beyond earlier focus on unimodal
RGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB--3D
and RGB--Text, enabled by point cloud sensing and vision--language models.
Despite shared challenges, these lines remain largely isolated, hindering a
comprehensive understanding and knowledge transfer. In this paper, we advocate
unified UAD for both unimodal and multimodal settings in the matching
perspective. Under this insight, we present Unified Cost Filtering (UCF), a
generic post-hoc refinement framework for refining anomaly cost volume of any
UAD model. The cost volume is constructed by matching a test sample against
normal samples from the same or different modalities, followed by a learnable
filtering module with multi-layer attention guidance from the test sample,
mitigating matching noise and highlighting subtle anomalies. Comprehensive
experiments on 22 diverse benchmarks demonstrate the efficacy of UCF in
enhancing a variety of UAD methods, consistently achieving new state-of-the-art
results in both unimodal (RGB) and multimodal (RGB--3D, RGB--Text) UAD
scenarios. Code and models will be released at
https://github.com/ZHE-SAPI/CostFilter-AD.
\\ ( https://arxiv.org/abs/2510.03363 ,  31591kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03376
Date: Fri, 3 Oct 2025 13:52:09 GMT   (5367kb)

Title: Visual Language Model as a Judge for Object Detection in Industrial
  Diagrams
Authors: Sanjukta Ghosh
Categories: cs.CV eess.IV
Comments: Pre-review version submitted to IEEE ICASSP 2026
\\
  Industrial diagrams such as piping and instrumentation diagrams (P&IDs) are
essential for the design, operation, and maintenance of industrial plants.
Converting these diagrams into digital form is an important step toward
building digital twins and enabling intelligent industrial automation. A
central challenge in this digitalization process is accurate object detection.
Although recent advances have significantly improved object detection
algorithms, there remains a lack of methods to automatically evaluate the
quality of their outputs. This paper addresses this gap by introducing a
framework that employs Visual Language Models (VLMs) to assess object detection
results and guide their refinement. The approach exploits the multimodal
capabilities of VLMs to identify missing or inconsistent detections, thereby
enabling automated quality assessment and improving overall detection
performance on complex industrial diagrams.
\\ ( https://arxiv.org/abs/2510.03376 ,  5367kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03441
Date: Fri, 3 Oct 2025 19:04:15 GMT   (1408kb)

Title: Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task
  Learning
Authors: Chashi Mahiul Islam, Oteo Mamo, Samuel Jacob Chacko, Xiuwen Liu,
  Weikuan Yu
Categories: cs.CV cs.AI cs.LG
Comments: 12 pages, 5 figures
MSC-class: 68T45, 68T10, 68T40
\\
  Vision-language models (VLMs) have advanced multimodal reasoning but still
face challenges in spatial reasoning for 3D scenes and complex object
configurations. To address this, we introduce SpatialViLT, an enhanced VLM that
integrates spatial features like depth maps, 3D coordinates, and edge maps
through a multi-task learning framework. This approach enriches multimodal
embeddings with spatial understanding. We propose two variants: SpatialViLT and
MaskedSpatialViLT, focusing on full and masked object regions, respectively.
Additionally, SpatialEnsemble combines both approaches, achieving
state-of-the-art accuracy. Our models excel in spatial reasoning categories
such as directional, topological, and proximity relations, as demonstrated on
the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a
significant step in enhancing the spatial intelligence of AI systems, crucial
for advanced multimodal understanding and real-world applications.
\\ ( https://arxiv.org/abs/2510.03441 ,  1408kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03452
Date: Fri, 3 Oct 2025 19:19:42 GMT   (8964kb)

Title: Denoising of Two-Phase Optically Sectioned Structured Illumination
  Reconstructions Using Encoder-Decoder Networks
Authors: Allison Davis, Yezhi Shen, Xiaoyu Ji, Fengqing Zhu
Categories: cs.CV
Comments: 5 pages, 4 figures, submitted to ICASSP 2026
\\
  Structured illumination (SI) enhances image resolution and contrast by
projecting patterned light onto a sample. In two-phase optical-sectioning SI
(OS-SI), reduced acquisition time introduces residual artifacts that
conventional denoising struggles to suppress. Deep learning offers an
alternative to traditional methods; however, supervised training is limited by
the lack of clean, optically sectioned ground-truth data. We investigate
encoder-decoder networks for artifact reduction in two-phase OS-SI, using
synthetic training pairs formed by applying real artifact fields to synthetic
images. An asymmetrical denoising autoencoder (DAE) and a U-Net are trained on
the synthetic data, then evaluated on real OS-SI images. Both networks improve
image clarity, with each excelling against different artifact types. These
results demonstrate that synthetic training enables supervised denoising of
OS-SI images and highlight the potential of encoder-decoder networks to
streamline reconstruction workflows.
\\ ( https://arxiv.org/abs/2510.03452 ,  8964kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03455
Date: Fri, 3 Oct 2025 19:21:23 GMT   (16657kb)

Title: PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway
  Expression Prediction from Histology
Authors: Sejuti Majumder, Saarthak Kapse, Moinak Bhattacharya, Xuan Xu, Alisa
  Yurovsky, Prateek Prasanna
Categories: cs.CV
\\
  Integrating histopathology with spatial transcriptomics (ST) provides a
powerful opportunity to link tissue morphology with molecular function. Yet
most existing multimodal approaches rely on a small set of highly variable
genes, which limits predictive scope and overlooks the coordinated biological
programs that shape tissue phenotypes. We present PEaRL (Pathway Enhanced
Representation Learning), a multimodal framework that represents
transcriptomics through pathway activation scores computed with ssGSEA. By
encoding biologically coherent pathway signals with a transformer and aligning
them with histology features via contrastive learning, PEaRL reduces
dimensionality, improves interpretability, and strengthens cross-modal
correspondence. Across three cancer ST datasets (breast, skin, and lymph node),
PEaRL consistently outperforms SOTA methods, yielding higher accuracy for both
gene- and pathway-level expression prediction (up to 58.9 percent and 20.4
percent increase in Pearson correlation coefficient compared to SOTA). These
results demonstrate that grounding transcriptomic representation in pathways
produces more biologically faithful and interpretable multimodal models,
advancing computational pathology beyond gene-level embeddings.
\\ ( https://arxiv.org/abs/2510.03455 ,  16657kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03483
Date: Fri, 3 Oct 2025 20:01:00 GMT   (7511kb)

Title: DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical
  Image Segmentation and Prognosis
Authors: Numan Saeed, Tausifa Jan Saleem, Fadillah Maani, Muhammad Ridzuan, Hu
  Wang and Mohammad Yaqub
Categories: cs.CV cs.AI
\\
  Deep learning for medical imaging is hampered by task-specific models that
lack generalizability and prognostic capabilities, while existing 'universal'
approaches suffer from simplistic conditioning and poor medical semantic
understanding. To address these limitations, we introduce DuPLUS, a deep
learning framework for efficient multi-modal medical image analysis. DuPLUS
introduces a novel vision-language framework that leverages hierarchical
semantic prompts for fine-grained control over the analysis task, a capability
absent in prior universal models. To enable extensibility to other medical
tasks, it includes a hierarchical, text-controlled architecture driven by a
unique dual-prompt mechanism. For segmentation, DuPLUS is able to generalize
across three imaging modalities, ten different anatomically various medical
datasets, encompassing more than 30 organs and tumor types. It outperforms the
state-of-the-art task specific and universal models on 8 out of 10 datasets. We
demonstrate extensibility of its text-controlled architecture by seamless
integration of electronic health record (EHR) data for prognosis prediction,
and on a head and neck cancer dataset, DuPLUS achieved a Concordance Index (CI)
of 0.69. Parameter-efficient fine-tuning enables rapid adaptation to new tasks
and modalities from varying centers, establishing DuPLUS as a versatile and
clinically relevant solution for medical image analysis. The code for this work
is made available at: https://anonymous.4open.science/r/DuPLUS-6C52
\\ ( https://arxiv.org/abs/2510.03483 ,  7511kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03501
Date: Fri, 3 Oct 2025 20:25:58 GMT   (45073kb)

Title: Real-Time Threaded Houbara Detection and Segmentation for Wildlife
  Conservation using Mobile Platforms
Authors: Lyes Saad Saoud, Loic Lesobre, Enrico Sorato, Irfan Hussain
Categories: cs.CV cs.AI cs.RO
\\
  Real-time animal detection and segmentation in natural environments are vital
for wildlife conservation, enabling non-invasive monitoring through remote
camera streams. However, these tasks remain challenging due to limited
computational resources and the cryptic appearance of many species. We propose
a mobile-optimized two-stage deep learning framework that integrates a
Threading Detection Model (TDM) to parallelize YOLOv10-based detection and
MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach
improves real-time performance by reducing latency through threading. YOLOv10
handles detection while MobileSAM performs lightweight segmentation, both
executed concurrently for efficient resource use. On the cryptic Houbara
Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627,
mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10
operates at 43.7 ms per frame, confirming real-time readiness. We introduce a
curated Houbara dataset of 40,000 annotated images to support model training
and evaluation across diverse conditions. The code and dataset used in this
study are publicly available on GitHub at
https://github.com/LyesSaadSaoud/mobile-houbara-detseg. For interactive demos
and additional resources, visit
https://lyessaadsaoud.github.io/LyesSaadSaoud-Threaded-YOLO-SAM-Houbara.
\\ ( https://arxiv.org/abs/2510.03501 ,  45073kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03511
Date: Fri, 3 Oct 2025 20:51:25 GMT   (1906kb)

Title: Platonic Transformers: A Solid Choice For Equivariance
Authors: Mohammad Mohaiminul Islam, Rishabh Anand, David R. Wessels, Friso de
  Kruiff, Thijs P. Kuipers, Rex Ying, Clara I. S\'anchez, Sharvaree Vadgama,
  Georg B\"okman, Erik J. Bekkers
Categories: cs.CV cs.AI cs.LG eess.IV
\\
  While widespread, Transformers lack inductive biases for geometric symmetries
common in science and computer vision. Existing equivariant methods often
sacrifice the efficiency and flexibility that make Transformers so effective
through complex, computationally intensive designs. We introduce the Platonic
Transformer to resolve this trade-off. By defining attention relative to
reference frames from the Platonic solid symmetry groups, our method induces a
principled weight-sharing scheme. This enables combined equivariance to
continuous translations and Platonic symmetries, while preserving the exact
architecture and computational cost of a standard Transformer. Furthermore, we
show that this attention is formally equivalent to a dynamic group convolution,
which reveals that the model learns adaptive geometric filters and enables a
highly scalable, linear-time convolutional variant. Across diverse benchmarks
in computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular
property prediction (QM9, OMol25), the Platonic Transformer achieves
competitive performance by leveraging these geometric constraints at no
additional cost.
\\ ( https://arxiv.org/abs/2510.03511 ,  1906kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03540
Date: Fri, 3 Oct 2025 22:17:41 GMT   (228kb)

Title: Domain Generalization for Semantic Segmentation: A Survey
Authors: Manuel Schwonberg, Hanno Gottschalk
Categories: cs.CV
Comments: Accepted to CVPR2025W
\\
  The generalization of deep neural networks to unknown domains is a major
challenge despite their tremendous progress in recent years. For this reason,
the dynamic area of domain generalization (DG) has emerged. In contrast to
unsupervised domain adaptation, there is no access to or knowledge about the
target domains, and DG methods aim to generalize across multiple different
unseen target domains. Domain generalization is particularly relevant for the
task semantic segmentation which is used in several areas such as biomedicine
or automated driving. This survey provides a comprehensive overview of the
rapidly evolving topic of domain generalized semantic segmentation. We cluster
and review existing approaches and identify the paradigm shift towards
foundation-model-based domain generalization. Finally, we provide an extensive
performance comparison of all approaches, which highlights the significant
influence of foundation models on domain generalization. This survey seeks to
advance domain generalization research and inspire scientists to explore new
research directions.
\\ ( https://arxiv.org/abs/2510.03540 ,  228kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03543
Date: Fri, 3 Oct 2025 22:25:52 GMT   (1786kb)

Title: From Scope to Script: An Automated Report Generation Model for
  Gastrointestinal Endoscopy
Authors: Evandros Kaklamanos, Kristjana Kristinsdottir, Jonathan Huang, Dustin
  Carlson, Rajesh Keswani, John Pandolfino, Mozziyar Etemadi
Categories: cs.CV
\\
  Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and
colonoscopy play a critical role in diagnosing and managing gastrointestinal
(GI) disorders. However, the documentation burden associated with these
procedures place significant strain on gastroenterologists, contributing to
inefficiencies in clinical workflows and physician burnout. To address this
challenge, we propose a novel automated report generation model that leverages
a transformer-based vision encoder and text decoder within a two-stage training
framework. In the first stage, both components are pre-trained on image/text
caption pairs to capture generalized vision-language features, followed by
fine-tuning on images/report pairs to generate clinically meaningful findings.
Our approach not only streamlines the documentation process but also holds
promise for reducing physician workload and improving patient care.
\\ ( https://arxiv.org/abs/2510.03543 ,  1786kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03545
Date: Fri, 3 Oct 2025 22:31:24 GMT   (5151kb)

Title: SketchPlan: Diffusion Based Drone Planning From Human Sketches
Authors: Sixten Norelius, Aaron O. Feldman, Mac Schwager
Categories: cs.CV cs.RO
Comments: Code available at https://github.com/sixnor/SketchPlan
\\
  We propose SketchPlan, a diffusion-based planner that interprets 2D
hand-drawn sketches over depth images to generate 3D flight paths for drone
navigation. SketchPlan comprises two components: a SketchAdapter that learns to
map the human sketches to projected 2D paths, and DiffPath, a diffusion model
that infers 3D trajectories from 2D projections and a first person view depth
image. Our model achieves zero-shot sim-to-real transfer, generating accurate
and safe flight paths in previously unseen real-world environments. To train
the model, we build a synthetic dataset of 32k flight paths using a diverse set
of photorealistic 3D Gaussian Splatting scenes. We automatically label the data
by computing 2D projections of the 3D flight paths onto the camera plane, and
use this to train the DiffPath diffusion model. However, since real human 2D
sketches differ significantly from ideal 2D projections, we additionally label
872 of the 3D flight paths with real human sketches and use this to train the
SketchAdapter to infer the 2D projection from the human sketch. We demonstrate
SketchPlan's effectiveness in both simulated and real-world experiments, and
show through ablations that training on a mix of human labeled and auto-labeled
data together with a modular design significantly boosts its capabilities to
correctly interpret human intent and infer 3D paths. In real-world drone tests,
SketchPlan achieved 100\% success in low/medium clutter and 40\% in unseen
high-clutter environments, outperforming key ablations by 20-60\% in task
completion.
\\ ( https://arxiv.org/abs/2510.03545 ,  5151kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03548
Date: Fri, 3 Oct 2025 22:37:03 GMT   (14625kb)

Title: Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm
  Impersonation in AI-based Videoconferencing
Authors: Danial Samadi Vahdati, Tai Duc Nguyen, Ekta Prashnani, Koki Nagano,
  David Luebke, Orazio Gallo, Matthew Stamm
Categories: cs.CV cs.AI
\\
  AI-based talking-head videoconferencing systems reduce bandwidth by sending a
compact pose-expression latent and re-synthesizing RGB at the receiver, but
this latent can be puppeteered, letting an attacker hijack a victim's likeness
in real time. Because every frame is synthetic, deepfake and synthetic video
detectors fail outright. To address this security problem, we exploit a key
observation: the pose-expression latent inherently contains biometric
information of the driving identity. Therefore, we introduce the first
biometric leakage defense without ever looking at the reconstructed RGB video:
a pose-conditioned, large-margin contrastive encoder that isolates persistent
identity cues inside the transmitted latent while cancelling transient pose and
expression. A simple cosine test on this disentangled embedding flags illicit
identity swaps as the video is rendered. Our experiments on multiple
talking-head generation models show that our method consistently outperforms
existing puppeteering defenses, operates in real-time, and shows strong
generalization to out-of-distribution scenarios.
\\ ( https://arxiv.org/abs/2510.03548 ,  14625kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03550
Date: Fri, 3 Oct 2025 22:38:35 GMT   (4867kb)

Title: Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything,
  Anytime!
Authors: Junbao Zhou, Yuan Zhou, Kesen Zhao, Qingshan Xu, Beier Zhu, Richang
  Hong, Hanwang Zhang
Categories: cs.CV
\\
  Achieving streaming, fine-grained control over the outputs of autoregressive
video diffusion models remains challenging, making it difficult to ensure that
they consistently align with user expectations. To bridge this gap, we propose
\textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new
task that enables users to modify generated videos \emph{anytime} on
\emph{anything} via fine-grained, interactive drag. Beyond DragVideo and
SG-I2V, REVEL unifies drag-style video manipulation as editing and animating
video frames with both supporting user-specified translation, deformation, and
rotation effects, making drag operations versatile. In resolving REVEL, we
observe: \emph{i}) drag-induced perturbations accumulate in latent space,
causing severe latent distribution drift that halts the drag process;
\emph{ii}) streaming drag is easily disturbed by context frames, thereby
yielding visually unnatural outcomes. We thus propose a training-free approach,
\textbf{DragStream}, comprising: \emph{i}) an adaptive distribution
self-rectification strategy that leverages neighboring frames' statistics to
effectively constrain the drift of latent embeddings; \emph{ii}) a
spatial-frequency selective optimization mechanism, allowing the model to fully
exploit contextual information while mitigating its interference via
selectively propagating visual cues along generation. Our method can be
seamlessly integrated into existing autoregressive video diffusion models, and
extensive experiments firmly demonstrate the effectiveness of our DragStream.
\\ ( https://arxiv.org/abs/2510.03550 ,  4867kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03555
Date: Fri, 3 Oct 2025 22:59:40 GMT   (1460kb)

Title: GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for
  Ensemble of Foundation Models in Digital Pathology Image Analysis
Authors: Peiran Quan, Zifan Gu, Zhuo Zhao, Qin Zhou, Donghan M. Yang, Ruichen
  Rong, Yang Xie, Guanghua Xiao
Categories: cs.CV cs.AI
\\
  Foundation models (FMs) have transformed computational pathology by providing
powerful, general-purpose feature extractors. However, adapting and
benchmarking individual FMs for specific diagnostic tasks is often
time-consuming and resource-intensive, especially given their scale and
diversity. To address this challenge, we introduce Group-Aggregative Selection
Multi-Instance Learning (GAS-MIL), a flexible ensemble framework that
seamlessly integrates features from multiple FMs, preserving their
complementary strengths without requiring manual feature selection or extensive
task-specific fine-tuning. Across classification tasks in three cancer
datasets-prostate (PANDA), ovarian (UBC-OCEAN), and breast (TCGA-BrCa)-GAS-MIL
consistently achieves superior or on-par performance relative to individual FMs
and established MIL methods, demonstrating its robustness and generalizability.
By enabling efficient integration of heterogeneous FMs, GAS-MIL streamlines
model deployment for pathology and provides a scalable foundation for future
multimodal and precision oncology applications.
\\ ( https://arxiv.org/abs/2510.03555 ,  1460kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03558
Date: Fri, 3 Oct 2025 23:11:30 GMT   (6777kb)

Title: Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted
  First Aid
Authors: Shen Chang, Renran Tian, Nicole Adams, Nan Kong
Categories: cs.CV
\\
  Rapid naloxone delivery via drones offers a promising solution for responding
to opioid overdose emergencies (OOEs), by extending lifesaving interventions to
medically untrained bystanders before emergency medical services (EMS) arrive.
Recognizing the critical role of bystander situational awareness (SA) in
human-autonomy teaming (HAT), we address a key research gap in real-time SA
assessment by introducing the Drone-Assisted Naloxone Delivery Simulation
Dataset (DANDSD). This pioneering dataset captures HAT during simulated OOEs,
where college students without medical training act as bystanders tasked with
administering intranasal naloxone to a mock overdose victim. Leveraging this
dataset, we propose a video-based real-time SA assessment framework that
utilizes graph embeddings and transformer models to assess bystander SA in real
time. Our approach integrates visual perception and comprehension cues--such as
geometric, kinematic, and interaction graph features--and achieves
high-performance SA prediction. It also demonstrates strong temporal
segmentation accuracy, outperforming the FINCH baseline by 9% in Mean over
Frames (MoF) and 5% in Intersection over Union (IoU). This work supports the
development of adaptive drone systems capable of guiding bystanders
effectively, ultimately improving emergency response outcomes and saving lives.
\\ ( https://arxiv.org/abs/2510.03558 ,  6777kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03570
Date: Fri, 3 Oct 2025 23:38:45 GMT   (619kb)

Title: Evaluating OCR performance on food packaging labels in South Africa
Authors: Mayimunah Nagayi, Alice Khan, Tamryn Frank, Rina Swart, and Clement
  Nyirenda
Categories: cs.CV cs.AI
Comments: 17 pages
\\
  This study evaluates four open-source Optical Character Recognition (OCR)
systems which are Tesseract, EasyOCR, PaddleOCR, and TrOCR on real world food
packaging images. The aim is to assess their ability to extract ingredient
lists and nutrition facts panels. Accurate OCR for packaging is important for
compliance and nutrition monitoring but is challenging due to multilingual
text, dense layouts, varied fonts, glare, and curved surfaces. A dataset of 231
products (1,628 images) was processed by all four models to assess speed and
coverage, and a ground truth subset of 113 images (60 products) was created for
accuracy evaluation. Metrics include Character Error Rate (CER), Word Error
Rate (WER), BLEU, ROUGE-L, F1, coverage, and execution time. On the ground
truth subset, Tesseract achieved the lowest CER (0.912) and the highest BLEU
(0.245). EasyOCR provided a good balance between accuracy and multilingual
support. PaddleOCR achieved near complete coverage but was slower because it
ran on CPU only due to GPU incompatibility, and TrOCR produced the weakest
results despite GPU acceleration. These results provide a packaging-specific
benchmark, establish a baseline, and highlight directions for layout-aware
methods and text localization.
\\ ( https://arxiv.org/abs/2510.03570 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03584
Date: Sat, 4 Oct 2025 00:24:44 GMT   (9493kb)

Title: FrameOracle: Learning What to See and How Much to See in Videos
Authors: Chaoyu Li, Tianzhi Li, Fei Tao, Zhenyu Zhao, Ziqian Wu, Maozheng Zhao,
  Juntong Song, Cheng Niu, Pooyan Fazli
Categories: cs.CV
\\
  Vision-language models (VLMs) have advanced video understanding, but their
performance is limited by the number of input frames they can process. Existing
frame sampling strategies, such as uniform or fixed-budget selection, often
fail to adapt to variations in information density or task complexity,
resulting in inefficiency and information loss. To address this, we present
FrameOracle, a lightweight and plug-and-play module that predicts both (1)
which frames are most relevant to a given query and (2) how many frames are
needed. FrameOracle is trained using a four-stage curriculum, with the first
three stages relying on weak proxy signals such as cross-modal similarity. In
the final stage, it leverages stronger supervision from a new dataset we
introduce, FrameOracle-41K, the first large-scale VideoQA collection to provide
keyframe annotations specifying the minimal set of frames required to answer
each question. Extensive experiments across five VLMs and six benchmarks
demonstrate that FrameOracle reduces 16-frame inputs to an average of 10.4
frames without any loss in accuracy. When starting from 64-frame candidates, it
reduces the input to an average of 13.9 frames while improving accuracy by
1.4%, achieving state-of-the-art efficiency-accuracy trade-offs for scalable
video understanding.
\\ ( https://arxiv.org/abs/2510.03584 ,  9493kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03591
Date: Sat, 4 Oct 2025 00:43:10 GMT   (4287kb)

Title: A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games
Authors: Faliu Yi, Sherif Abdelfattah, Wei Huang, Adrian Brown
Categories: cs.CV cs.AI
Comments: Accepted at the 21st AAAI Conference on Artificial Intelligence and
  Interactive Digital Entertainment (AIIDE 2025)
\\
  Manual identification of visual bugs in video games is a resource-intensive
and costly process, often demanding specialized domain knowledge. While
supervised visual bug detection models offer a promising solution, their
reliance on extensive labeled datasets presents a significant challenge due to
the infrequent occurrence of such bugs. To overcome this limitation, we propose
a hybrid Co-FineTuning (CFT) method that effectively integrates both labeled
and unlabeled data. Our approach leverages labeled samples from the target game
and diverse co-domain games, additionally incorporating unlabeled data to
enhance feature representation learning. This strategy maximizes the utility of
all available data, substantially reducing the dependency on labeled examples
from the specific target game. The developed framework demonstrates enhanced
scalability and adaptability, facilitating efficient visual bug detection
across various game titles. Our experimental results show the robustness of the
proposed method for game visual bug detection, exhibiting superior performance
compared to conventional baselines across multiple gaming environments.
Furthermore, CFT maintains competitive performance even when trained with only
50% of the labeled data from the target game.
\\ ( https://arxiv.org/abs/2510.03591 ,  4287kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03598
Date: Sat, 4 Oct 2025 01:22:41 GMT   (1614kb)

Title: Exploring the Hierarchical Reasoning Model for Small Natural-Image
  Classification Without Augmentation
Authors: Alexander V. Mantzaris
Categories: cs.CV cs.LG
\\
  This paper asks whether the Hierarchical Reasoning Model (HRM) with the two
Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep
supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical
image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a
deliberately raw regime: no data augmentation, identical optimizer family with
one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes
stably and performs well on MNIST ($\approx 98\%$ test accuracy), but on small
natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches
65.0\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains
77.2\% while training $\sim 30\times$ faster per epoch; on CIFAR-100, HRM
achieves only 29.7\% test accuracy despite 91.5\% train accuracy, while the
same CNN reaches 45.3\% test with 50.5\% train accuracy. Loss traces and error
analyses indicate healthy optimization but insufficient image-specific
inductive bias for HRM in this regime. It is concluded that, for
small-resolution image classification without augmentation, HRM is not
competitive with even simple convolutional architectures as the HRM currently
exist but this does not exclude possibilities that modifications to the model
may allow it to improve greatly.
\\ ( https://arxiv.org/abs/2510.03598 ,  1614kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03606
Date: Sat, 4 Oct 2025 01:38:56 GMT   (10982kb)

Title: Unsupervised Transformer Pre-Training for Images: Self-Distillation,
  Mean Teachers, and Random Crops
Authors: Mattia Scardecchia
Categories: cs.CV cs.LG eess.IV
\\
  Recent advances in self-supervised learning (SSL) have made it possible to
learn general-purpose visual features that capture both the high-level
semantics and the fine-grained spatial structure of images. Most notably, the
recent DINOv2 has established a new state of the art by surpassing weakly
supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we
examine the core ideas behind its approach, multi-crop view augmentation and
self-distillation with a mean teacher, and trace their development in previous
work. We then compare the performance of DINO and DINOv2 with other SSL and WSL
methods across various downstream tasks, and highlight some remarkable emergent
properties of their learned features with transformer backbones. We conclude by
briefly discussing DINOv2's limitations, its impact, and future research
directions.
\\ ( https://arxiv.org/abs/2510.03606 ,  10982kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03608
Date: Sat, 4 Oct 2025 01:48:52 GMT   (1423kb)

Title: Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual
  Boosting Loop for FSCIL
Authors: Ruitao Wu, Yifan Zhao, Guangyao Chen, Jia Li
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\
  Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially
learn new classes from minimal examples without forgetting prior knowledge, a
task complicated by the stability-plasticity dilemma and data scarcity. Current
FSCIL methods often struggle with generalization due to their reliance on
limited datasets. While diffusion models offer a path for data augmentation,
their direct application can lead to semantic misalignment or ineffective
guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel
framework that establishes a mutual boosting loop between diffusion model and
FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a
dynamic, multi-faceted reward function derived from the classifier's state
directs the diffusion model. This reward system operates at two levels: the
feature level ensures semantic coherence and diversity using prototype-anchored
maximum mean discrepancy and dimension-wise variance matching, while the logits
level promotes exploratory image generation and enhances inter-class
discriminability through confidence recalibration and cross-session
confusion-aware mechanisms. This co-evolutionary process, where generated
images refine the classifier and an improved classifier state yields better
reward signals, demonstrably achieves state-of-the-art performance on FSCIL
benchmarks, significantly enhancing both knowledge retention and new class
learning.
\\ ( https://arxiv.org/abs/2510.03608 ,  1423kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03666
Date: Sat, 4 Oct 2025 04:46:21 GMT   (2483kb)

Title: MonitorVLM:A Vision Language Framework for Safety Violation Detection in
  Mining Operations
Authors: Jiang Wu, Sichao Wu, Yinsong Ma, Guangyuan Yu, Haoyuan Xu, Lifang
  Zheng, Jingliang Duan
Categories: cs.CV cs.AI
\\
  Industrial accidents, particularly in high-risk domains such as surface and
underground mining, are frequently caused by unsafe worker behaviors.
Traditional manual inspection remains labor-intensive, error-prone, and
insufficient for large-scale, dynamic environments, highlighting the urgent
need for intelligent and automated safety monitoring. In this paper, we present
MonitorVLM, a novel vision--language framework designed to detect safety
violations directly from surveillance video streams. MonitorVLM introduces
three key innovations: (1) a domain-specific violation dataset comprising 9,000
vision--question--answer (VQA) samples across 40 high-frequency mining
regulations, enriched with augmentation and auxiliary detection cues; (2) a
clause filter (CF) module that dynamically selects the Top-$K$ most relevant
clauses, reducing inference latency by 13.56\% while maintaining accuracy; and
(3) a behavior magnifier (BM) module that enhances worker regions to improve
fine-grained action recognition, yielding additional gains of 3.45% in
precision and 8.62% in recall. Experimental results demonstrate that MonitorVLM
significantly outperforms baseline vision--language models, achieving
improvements of 22.01% in precision, 34.22\% in recall, and 28.37% in F1 score
over the 72B unfine-tuned baseline. A lightweight web-based interface further
integrates MonitorVLM into practical workflows, enabling automatic violation
reporting with video timestamping. This study highlights the potential of
multimodal large models to enhance occupational safety monitoring in mining and
beyond.
\\ ( https://arxiv.org/abs/2510.03666 ,  2483kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03675
Date: Sat, 4 Oct 2025 05:02:15 GMT   (2059kb)

Title: A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy
  Accident Detection in Intelligent Transportation Systems
Authors: Siva Sai, Saksham Gupta, Vinay Chamola, Rajkumar Buyya
Categories: cs.CV
\\
  The integration of Diffusion Models into Intelligent Transportation Systems
(ITS) is a substantial improvement in the detection of accidents. We present a
novel hybrid model integrating guidance classification with diffusion
techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input
for our proposed diffusion model and processing image tensors as our
conditioning, our approach creates a robust classification framework. Our model
consists of multiple conditional modules, which aim to modulate the linear
projection of inputs using time embeddings and image covariate embeddings,
allowing the network to adapt its behavior dynamically throughout the diffusion
process. To address the computationally intensive nature of diffusion models,
our implementation is cloud-based, enabling scalable and efficient processing.
Our strategy overcomes the shortcomings of conventional classification
approaches by leveraging diffusion models inherent capacity to effectively
understand complicated data distributions. We investigate important diffusion
characteristics, such as timestep schedulers, timestep encoding techniques,
timestep count, and architectural design changes, using a thorough ablation
study, and have conducted a comprehensive evaluation of the proposed model
against the baseline models on a publicly available dataset. The proposed
diffusion model performs best in image-based accident detection with an
accuracy of 97.32%.
\\ ( https://arxiv.org/abs/2510.03675 ,  2059kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03689
Date: Sat, 4 Oct 2025 06:02:12 GMT   (16902kb)

Title: SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection
Authors: Zhengyi Liu, Xinrui Wang, Xianyong Fang, Zhengzheng Tu, Linbo Wang
Categories: cs.CV
Comments: Accepted by TMM
\\
  RGB-T salient object detection (SOD) aims to segment attractive objects by
combining RGB and thermal infrared images. To enhance performance, the Segment
Anything Model has been fine-tuned for this task. However, the imbalance
convergence of two modalities and significant gradient difference between high-
and low- activations are ignored, thereby leaving room for further performance
enhancement. In this paper, we propose a model called \textit{SAMSOD}, which
utilizes unimodal supervision to enhance the learning of non-dominant modality
and employs gradient deconfliction to reduce the impact of conflicting
gradients on model convergence. The method also leverages two decoupled
adapters to separately mask high- and low-activation neurons, emphasizing
foreground objects by enhancing background learning. Fundamental experiments on
RGB-T SOD benchmark datasets and generalizability experiments on scribble
supervised RGB-T SOD, fully supervised RGB-D SOD datasets and full-supervised
RGB-D rail surface defect detection all demonstrate the effectiveness of our
proposed method.
\\ ( https://arxiv.org/abs/2510.03689 ,  16902kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03701
Date: Sat, 4 Oct 2025 06:50:02 GMT   (24726kb)

Title: Referring Expression Comprehension for Small Objects
Authors: Kanoko Goto, Takumi Hirose, Mahiro Ukai, Shuhei Kurita, Nakamasa Inoue
Categories: cs.CV cs.AI
\\
  Referring expression comprehension (REC) aims to localize the target object
described by a natural language expression. Recent advances in vision-language
learning have led to significant performance improvements in REC tasks.
However, localizing extremely small objects remains a considerable challenge
despite its importance in real-world applications such as autonomous driving.
To address this issue, we introduce a novel dataset and method for REC
targeting small objects. First, we present the small object REC (SOREC)
dataset, which consists of 100,000 pairs of referring expressions and
corresponding bounding boxes for small objects in driving scenarios. Second, we
propose the progressive-iterative zooming adapter (PIZA), an adapter module for
parameter-efficient fine-tuning that enables models to progressively zoom in
and localize small objects. In a series of experiments, we apply PIZA to
GroundingDINO and demonstrate a significant improvement in accuracy on the
SOREC dataset. Our dataset, codes and pre-trained models are publicly available
on the project page.
\\ ( https://arxiv.org/abs/2510.03701 ,  24726kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03717
Date: Sat, 4 Oct 2025 07:42:30 GMT   (3200kb)

Title: Artery-Vein Segmentation from Fundus Images using Deep Learning
Authors: Sharan SK, Subin Sahayam, Umarani Jayaraman, and Lakshmi Priya A
Categories: cs.CV cs.AI
Comments: 12 pages, 6 figures, preprint under review
\\
  Segmenting of clinically important retinal blood vessels into arteries and
veins is a prerequisite for retinal vessel analysis. Such analysis can provide
potential insights and bio-markers for identifying and diagnosing various
retinal eye diseases. Alteration in the regularity and width of the retinal
blood vessels can act as an indicator of the health of the vasculature system
all over the body. It can help identify patients at high risk of developing
vasculature diseases like stroke and myocardial infarction. Over the years,
various Deep Learning architectures have been proposed to perform retinal
vessel segmentation. Recently, attention mechanisms have been increasingly used
in image segmentation tasks. The work proposes a new Deep Learning approach for
artery-vein segmentation. The new approach is based on the Attention mechanism
that is incorporated into the WNet Deep Learning model, and we call the model
as Attention-WNet. The proposed approach has been tested on publicly available
datasets such as HRF and DRIVE datasets. The proposed approach has outperformed
other state-of-art models available in the literature.
\\ ( https://arxiv.org/abs/2510.03717 ,  3200kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03721
Date: Sat, 4 Oct 2025 07:51:59 GMT   (5232kb)

Title: Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer
  to Models
Authors: Leander Girrbach and Stephan Alaniz and Genevieve Smith and Trevor
  Darrell and Zeynep Akata
Categories: cs.CV cs.CL cs.CY cs.LG
Comments: 48 pages
\\
  Vision-language models trained on large-scale multimodal datasets show strong
demographic biases, but the role of training data in producing these biases
remains unclear. A major barrier has been the lack of demographic annotations
in web-scale datasets such as LAION-400M. We address this gap by creating
person-centric annotations for the full dataset, including over 276 million
bounding boxes, perceived gender and race/ethnicity labels, and automatically
generated captions. These annotations are produced through validated automatic
labeling pipelines combining object detection, multimodal captioning, and
finetuned classifiers. Using them, we uncover demographic imbalances and
harmful associations, such as the disproportionate linking of men and
individuals perceived as Black or Middle Eastern with crime-related and
negative content. We also show that 60-70% of gender bias in CLIP and Stable
Diffusion can be linearly explained by direct co-occurrences in the data. Our
resources establish the first large-scale empirical link between dataset
composition and downstream model bias.
\\ ( https://arxiv.org/abs/2510.03721 ,  5232kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03725
Date: Sat, 4 Oct 2025 08:05:54 GMT   (3406kb)

Title: Mapping Rio de Janeiro's favelas: general-purpose vs. satellite-specific
  neural networks
Authors: Thomas Hallopeau, Joris Gu\'erin, Laurent Demagistri, Youssef Fouzai,
  Renata Gracie, Vanderlei Pascoal De Matos, Helen Gurgel and Nadine Dessay
Categories: cs.CV cs.LG
Comments: 6 pages, 1 figure, 1 table. Presented at the 21st Brazilian Symposium
  on Remote Sensing (SBSR 2025)
\\
  While deep learning methods for detecting informal settlements have already
been developed, they have not yet fully utilized the potential offered by
recent pretrained neural networks. We compare two types of pretrained neural
networks for detecting the favelas of Rio de Janeiro: 1. Generic networks
pretrained on large diverse datasets of unspecific images, 2. A specialized
network pretrained on satellite imagery. While the latter is more specific to
the target task, the former has been pretrained on significantly more images.
Hence, this research investigates whether task specificity or data volume
yields superior performance in urban informal settlement detection.
\\ ( https://arxiv.org/abs/2510.03725 ,  3406kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03747
Date: Sat, 4 Oct 2025 09:22:26 GMT   (1158kb)

Title: LoRA Patching: Exposing the Fragility of Proactive Defenses against
  Deepfakes
Authors: Zuomin Qu, Yimao Guo, Qianyue Hu, Wei Lu
Categories: cs.CV
\\
  Deepfakes pose significant societal risks, motivating the development of
proactive defenses that embed adversarial perturbations in facial images to
prevent manipulation. However, in this paper, we show that these preemptive
defenses often lack robustness and reliability. We propose a novel approach,
Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch
into Deepfake generators to bypass state-of-the-art defenses. A learnable
gating mechanism adaptively controls the effect of the LoRA patch and prevents
gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature
Alignment (MMFA) loss, encouraging the features of adversarial outputs to align
with those of the desired outputs at the semantic level. Beyond bypassing, we
present defensive LoRA patching, embedding visible warnings in the outputs as a
complementary solution to mitigate this newly identified security
vulnerability. With only 1,000 facial examples and a single epoch of
fine-tuning, LoRA patching successfully defeats multiple proactive defenses.
These results reveal a critical weakness in current paradigms and underscore
the need for more robust Deepfake defense strategies. Our code is available at
https://github.com/ZOMIN28/LoRA-Patching.
\\ ( https://arxiv.org/abs/2510.03747 ,  1158kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03751
Date: Sat, 4 Oct 2025 09:29:58 GMT   (2863kb)

Title: The Overlooked Value of Test-time Reference Sets in Visual Place
  Recognition
Authors: Mubariz Zaffar, Liangliang Nan, Sebastian Scherer, Julian F. P. Kooij
Categories: cs.CV
Comments: Accepted at ICCV 2025 Workshop CrocoDL
\\
  Given a query image, Visual Place Recognition (VPR) is the task of retrieving
an image of the same place from a reference database with robustness to
viewpoint and appearance changes. Recent works show that some VPR benchmarks
are solved by methods using Vision-Foundation-Model backbones and trained on
large-scale and diverse VPR-specific datasets. Several benchmarks remain
challenging, particularly when the test environments differ significantly from
the usual VPR training datasets. We propose a complementary, unexplored source
of information to bridge the train-test domain gap, which can further improve
the performance of State-of-the-Art (SOTA) VPR methods on such challenging
benchmarks. Concretely, we identify that the test-time reference set, the
"map", contains images and poses of the target domain, and must be available
before the test-time query is received in several VPR applications. Therefore,
we propose to perform simple Reference-Set-Finetuning (RSF) of VPR models on
the map, boosting the SOTA (~2.3% increase on average for Recall@1) on these
challenging datasets. Finetuned models retain generalization, and RSF works
across diverse test datasets.
\\ ( https://arxiv.org/abs/2510.03751 ,  2863kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03763
Date: Sat, 4 Oct 2025 10:08:14 GMT   (2348kb)

Title: Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up
  Sharpness Aware Minimization
Authors: Jiaxin Deng, Junbiao Pang
Categories: cs.CV cs.AI
\\
  Sharpness-Aware Minimization (SAM) improves model generalization but doubles
the computational cost of Stochastic Gradient Descent (SGD) by requiring twice
the gradient calculations per optimization step. To mitigate this, we propose
Adaptively sampling-Reusing-mixing decomposed gradients to significantly
accelerate SAM (ARSAM). Concretely, we firstly discover that SAM's gradient can
be decomposed into the SGD gradient and the Projection of the Second-order
gradient onto the First-order gradient (PSF). Furthermore, we observe that the
SGD gradient and PSF dynamically evolve during training, emphasizing the
growing role of the PSF to achieve a flat minima. Therefore, ARSAM is proposed
to the reused PSF and the timely updated PSF still maintain the model's
generalization ability. Extensive experiments show that ARSAM achieves
state-of-the-art accuracies comparable to SAM across diverse network
architectures. On CIFAR-10/100, ARSAM is comparable to SAM while providing a
speedup of about 40\%. Moreover, ARSAM accelerates optimization for the various
challenge tasks (\textit{e.g.}, human pose estimation, and model quantization)
without sacrificing performance, demonstrating its broad practicality.% The
code is publicly accessible at: https://github.com/ajiaaa/ARSAM.
\\ ( https://arxiv.org/abs/2510.03763 ,  2348kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03767
Date: Sat, 4 Oct 2025 10:29:15 GMT   (626kb)

Title: CoPA: Hierarchical Concept Prompting and Aggregating Network for
  Explainable Diagnosis
Authors: Yiheng Dong, Yi Lin, Xin Yang
Categories: cs.CV
Comments: Accepted by MICCAI2025
DOI: 10.1007/978-3-032-05185-1_7
\\
  The transparency of deep learning models is essential for clinical
diagnostics. Concept Bottleneck Model provides clear decision-making processes
for diagnosis by transforming the latent space of black-box models into
human-understandable concepts. However, concept-based methods still face
challenges in concept capture capabilities. These methods often rely on encode
features solely from the final layer, neglecting shallow and multiscale
features, and lack effective guidance in concept encoding, hindering
fine-grained concept extraction. To address these issues, we introduce Concept
Prompting and Aggregating (CoPA), a novel framework designed to capture
multilayer concepts under prompt guidance. This framework utilizes the
Concept-aware Embedding Generator (CEG) to extract concept representations from
each layer of the visual encoder. Simultaneously, these representations serve
as prompts for Concept Prompt Tuning (CPT), steering the model towards
amplifying critical concept-related visual cues. Visual representations from
each layer are aggregated to align with textual concept representations. With
the proposed method, valuable concept-wise information in the images is
captured and utilized effectively, thus improving the performance of concept
and disease prediction. Extensive experimental results demonstrate that CoPA
outperforms state-of-the-art methods on three public datasets. Code is
available at https://github.com/yihengd/CoPA.
\\ ( https://arxiv.org/abs/2510.03767 ,  626kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03769
Date: Sat, 4 Oct 2025 10:37:34 GMT   (4620kb)

Title: Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score
  Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D
  Segmentation
Authors: Shimaa Elbana and Ahmad Kamal and Shahd Ahmed Ali and Ahmad Al-Kabbany
Categories: cs.CV eess.SP
\\
  The increasing size and complexity of medical imaging datasets, particularly
in 3D formats, present significant barriers to collaborative research and
transferability. This study investigates whether the ZFP compression technique
can mitigate these challenges without compromising the performance of automated
cerebrovascular segmentation, a critical first step in intracranial aneurysm
detection. We apply ZFP in both its error tolerance and fixed-rate modes to a
large scale, and one of the most recent, datasets in the literature, 3D medical
dataset containing ground-truth vascular segmentations. The segmentation
quality on the compressed volumes is rigorously compared to the uncompressed
baseline (Dice approximately equals 0.8774). Our findings reveal that ZFP can
achieve substantial data reduction--up to a 22.89:1 ratio in error tolerance
mode--while maintaining a high degree of fidelity, with the mean Dice
coefficient remaining high at 0.87656. These results demonstrate that ZFP is a
viable and powerful tool for enabling more efficient and accessible research on
large-scale medical datasets, fostering broader collaboration across the
community.
\\ ( https://arxiv.org/abs/2510.03769 ,  4620kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03786
Date: Sat, 4 Oct 2025 11:25:10 GMT   (4100kb)

Title: MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based
  Fusion for Medical Image Segmentation
Authors: T-Mai Bui, Fares Bougourzi, Fadi Dornaika, Vinh Truong Hoang
Categories: cs.CV
\\
  In recent years, deep learning has shown near-expert performance in
segmenting complex medical tissues and tumors. However, existing models are
often task-specific, with performance varying across modalities and anatomical
regions. Balancing model complexity and performance remains challenging,
particularly in clinical settings where both accuracy and efficiency are
critical. To address these issues, we propose a hybrid segmentation
architecture featuring a three-branch encoder that integrates CNNs,
Transformers, and a Mamba-based Attention Fusion (MAF) mechanism to capture
local, global, and long-range dependencies. A multi-scale attention-based CNN
decoder reconstructs fine-grained segmentation maps while preserving contextual
consistency. Additionally, a co-attention gate enhances feature selection by
emphasizing relevant spatial and semantic information across scales during both
encoding and decoding, improving feature interaction and cross-scale
communication. Extensive experiments on multiple benchmark datasets show that
our approach outperforms state-of-the-art methods in accuracy and
generalization, while maintaining comparable computational complexity. By
effectively balancing efficiency and effectiveness, our architecture offers a
practical and scalable solution for diverse medical imaging tasks. Source code
and trained models will be publicly released upon acceptance to support
reproducibility and further research.
\\ ( https://arxiv.org/abs/2510.03786 ,  4100kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03797
Date: Sat, 4 Oct 2025 12:21:02 GMT   (2216kb)

Title: Road Damage and Manhole Detection using Deep Learning for Smart Cities:
  A Polygonal Annotation Approach
Authors: Rasel Hossen, Diptajoy Mistry, Mushiur Rahman, Waki As Sami Atikur
  Rahman Hridoy, Sajib Saha, Muhammad Ibrahim
Categories: cs.CV cs.LG
Comments: 13 pages
\\
  Urban safety and infrastructure maintenance are critical components of smart
city development. Manual monitoring of road damages is time-consuming, highly
costly, and error-prone. This paper presents a deep learning approach for
automated road damage and manhole detection using the YOLOv9 algorithm with
polygonal annotations. Unlike traditional bounding box annotation, we employ
polygonal annotations for more precise localization of road defects. We develop
a novel dataset comprising more than one thousand images which are mostly
collected from Dhaka, Bangladesh. This dataset is used to train a YOLO-based
model for three classes, namely Broken, Not Broken, and Manhole. We achieve
78.1% overall image-level accuracy. The YOLOv9 model demonstrates strong
performance for Broken (86.7% F1-score) and Not Broken (89.2% F1-score)
classes, with challenges in Manhole detection (18.2% F1-score) due to class
imbalance. Our approach offers an efficient and scalable solution for
monitoring urban infrastructure in developing countries.
\\ ( https://arxiv.org/abs/2510.03797 ,  2216kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03821
Date: Sat, 4 Oct 2025 14:37:14 GMT   (2057kb)

Title: Contrastive-SDE: Guiding Stochastic Differential Equations with
  Contrastive Learning for Unpaired Image-to-Image Translation
Authors: Venkata Narendra Kotyada, Revanth Eranki, Nagesh Bhattu Sristy
Categories: cs.CV
Comments: 9 pages, 3 figures
\\
  Unpaired image-to-image translation involves learning mappings between source
domain and target domain in the absence of aligned or corresponding samples.
Score based diffusion models have demonstrated state-of-the-art performance in
generative tasks. Their ability to approximate complex data distributions
through stochastic differential equations (SDEs) enables them to generate
high-fidelity and diverse outputs, making them particularly well-suited for
unpaired I2I settings. In parallel, contrastive learning provides a powerful
framework for learning semantic similarities without the need for explicit
supervision or paired data. By pulling together representations of semantically
similar samples and pushing apart dissimilar ones, contrastive methods are
inherently aligned with the objectives of unpaired translation. Its ability to
selectively enforce semantic consistency at the feature level makes contrastive
learning particularly effective for guiding generation in unpaired scenarios.
In this work, we propose a time-dependent contrastive learning approach where a
model is trained with SimCLR by considering an image and its domain invarient
feature as a positive pair, enabling the preservation of domain-invariant
features and the discarding of domain-specific ones. The learned contrastive
model then guides the inference of a pretrained SDE for the I2I translation
task. We empirically compare Contrastive-SDE with several baselines across
three common unpaired I2I tasks, using four metrics for evaluation.
Constrastive-SDE achieves comparable results to the state-of-the-art on several
metrics. Furthermore, we observe that our model converges significantly faster
and requires no label supervision or classifier training, making it a more
efficient alternative for this task.
\\ ( https://arxiv.org/abs/2510.03821 ,  2057kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03827
Date: Sat, 4 Oct 2025 14:56:40 GMT   (3597kb)

Title: LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action
  Models Beyond Memorization
Authors: Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang,
  Duanfeng Chu, Pan Zhou, Lichao Sun
Categories: cs.CV cs.RO
Comments: 12 pages,7 figures, 5 tables
\\
  LIBERO has emerged as a widely adopted benchmark for evaluating
Vision-Language-Action (VLA) models; however, its current training and
evaluation settings are problematic, often leading to inflated performance
estimates and preventing fair model comparison. To address these issues, we
introduce LIBERO-PRO, an extended LIBERO benchmark that systematically
evaluates model performance under reasonable perturbations across four
dimensions: manipulated objects, initial states, task instructions, and
environments. Experimental results reveal that, although existing models
achieve over 90% accuracy under the standard LIBERO evaluation, their
performance collapses to 0.0% under our generalized setting. Crucially, this
discrepancy exposes the models' reliance on rote memorization of action
sequences and environment layouts from the training set, rather than genuine
task understanding or environmental perception. For instance, models persist in
executing grasping actions when the target object is replaced with irrelevant
items, and their outputs remain unchanged even when given corrupted
instructions or even messy tokens. These findings expose the severe flaws in
current evaluation practices, and we call on the community to abandon
misleading methodologies in favor of robust assessments of model generalization
and comprehension. Our code is available at:
https://github.com/Zxy-MLlab/LIBERO-PRO.
\\ ( https://arxiv.org/abs/2510.03827 ,  3597kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03840
Date: Sat, 4 Oct 2025 15:38:39 GMT   (4492kb)

Title: Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large
  Vision-Language Models
Authors: Pranav Sharma, Shivank Garg, Durga Toshniwal
Categories: cs.CV
Comments: ACM MM'25, MALLM Workshop
\\
  Recent advances in image generation models have led to models that produce
synthetic images that are increasingly difficult for standard AI detectors to
identify, even though they often remain distinguishable by humans. To identify
this discrepancy, we introduce \textbf{Mirage}, a curated dataset comprising a
diverse range of AI-generated images exhibiting visible artifacts, where
current state-of-the-art detection methods largely fail. Furthermore, we
investigate whether Large Vision-Language Models (LVLMs), which are
increasingly employed as substitutes for human judgment in various tasks, can
be leveraged for explainable AI image detection. Our experiments on both Mirage
and existing benchmark datasets demonstrate that while LVLMs are highly
effective at detecting AI-generated images with visible artifacts, their
performance declines when confronted with images lacking such cues.
\\ ( https://arxiv.org/abs/2510.03840 ,  4492kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03853
Date: Sat, 4 Oct 2025 15:56:52 GMT   (40320kb)

Title: UGround: Towards Unified Visual Grounding with Unrolled Transformers
Authors: Rui Qian, Xin Yin, Chuanhang Deng, Zhiyuan Peng, Jian Xiong, Wei Zhai,
  Dejing Dou
Categories: cs.CV
Comments: https://github.com/rui-qian/UGround
\\
  We present UGround, a \textbf{U}nified visual \textbf{Ground}ing paradigm
that dynamically selects intermediate layers across \textbf{U}nrolled
transformers as ``mask as prompt'', diverging from the prevailing pipeline that
leverages the fixed last hidden layer as ``\texttt{<SEG>} as prompt''. UGround
addresses two primary challenges posed by the prevailing paradigm: (1) its
reliance on the fixed last hidden layer, which sequentially amplifies
cumulative errors arising from layer-by-layer propagation without intermediate
correction, and (2) its use of \texttt{<SEG>} as a prompt, which implicitly
projects textual embeddings into visual space without explicit spatial cues
(\eg, coordinates). Central to UGround is Policy-Prompted Masking, which
comprises two key components: Stochastic Skip Connection (SSC) and Mask as
Prompt (MasP). SSC is a reinforcement learning policy that, via stochastic
sampling, allows each \texttt{<SEG>} token to slide across unrolled transformer
layers, enabling dynamic layer selection at which it connects to the vision
model (\eg, SAM) in a skip-connection fashion. Given the selected hidden layer,
MasP uses the similarity map derived from the \texttt{<SEG>} token and image
tokens as a soft logit mask to prompt SAM for mask generation, offering
explicit spatial cues through its activation regions. To validate the
effectiveness of UGround, we, for the first time, have unified visual grounding
within a single framework from an attribute perspective, spanning from
traditional refer expression segmentation to newly proposed reasoning
segmentation, single-target to multi-target, positive query to false premise
(empty target). All codes and models are publicly available at
\href{https://github.com/rui-qian/UGround}{https://github.com/rui-qian/UGround}.
\\ ( https://arxiv.org/abs/2510.03853 ,  40320kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03857
Date: Sat, 4 Oct 2025 16:11:13 GMT   (10167kb)

Title: Optimized Minimal 4D Gaussian Splatting
Authors: Minseo Lee, Byeonghyeon Lee, Lucas Yunkyu Lee, Eunsoo Lee, Sangmin
  Kim, Seunghyeon Song, Joo Chan Lee, Jong Hwan Ko, Jaesik Park, Eunbyung Park
Categories: cs.CV
Comments: 17 pages, 8 figures
\\
  4D Gaussian Splatting has emerged as a new paradigm for dynamic scene
representation, enabling real-time rendering of scenes with complex motions.
However, it faces a major challenge of storage overhead, as millions of
Gaussians are required for high-fidelity reconstruction. While several studies
have attempted to alleviate this memory burden, they still face limitations in
compression ratio or visual quality. In this work, we present OMG4 (Optimized
Minimal 4D Gaussian Splatting), a framework that constructs a compact set of
salient Gaussians capable of faithfully representing 4D Gaussian models. Our
method progressively prunes Gaussians in three stages: (1) Gaussian Sampling to
identify primitives critical to reconstruction fidelity, (2) Gaussian Pruning
to remove redundancies, and (3) Gaussian Merging to fuse primitives with
similar characteristics. In addition, we integrate implicit appearance
compression and generalize Sub-Vector Quantization (SVQ) to 4D representations,
further reducing storage while preserving quality. Extensive experiments on
standard benchmark datasets demonstrate that OMG4 significantly outperforms
recent state-of-the-art methods, reducing model sizes by over 60% while
maintaining reconstruction quality. These results position OMG4 as a
significant step forward in compact 4D scene representation, opening new
possibilities for a wide range of applications. Our source code is available at
https://minshirley.github.io/OMG4/.
\\ ( https://arxiv.org/abs/2510.03857 ,  10167kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03858
Date: Sat, 4 Oct 2025 16:12:03 GMT   (30013kb)

Title: Cross-View Open-Vocabulary Object Detection in Aerial Imagery
Authors: Jyoti Kini, Rohit Gupta, Mubarak Shah
Categories: cs.CV
\\
  Traditional object detection models are typically trained on a fixed set of
classes, limiting their flexibility and making it costly to incorporate new
categories. Open-vocabulary object detection addresses this limitation by
enabling models to identify unseen classes without explicit training.
Leveraging pretrained models contrastively trained on abundantly available
ground-view image-text classification pairs provides a strong foundation for
open-vocabulary object detection in aerial imagery. Domain shifts, viewpoint
variations, and extreme scale differences make direct knowledge transfer across
domains ineffective, requiring specialized adaptation strategies. In this
paper, we propose a novel framework for adapting open-vocabulary
representations from ground-view images to solve object detection in aerial
imagery through structured domain alignment. The method introduces contrastive
image-to-image alignment to enhance the similarity between aerial and
ground-view embeddings and employs multi-instance vocabulary associations to
align aerial images with text embeddings. Extensive experiments on the xView,
DOTAv2, VisDrone, DIOR, and HRRSD datasets are used to validate our approach.
Our open-vocabulary model achieves improvements of +6.32 mAP on DOTAv2, +4.16
mAP on VisDrone (Images), and +3.46 mAP on HRRSD in the zero-shot setting when
compared to finetuned closed-vocabulary dataset-specific model performance,
thus paving the way for more flexible and scalable object detection systems in
aerial applications.
\\ ( https://arxiv.org/abs/2510.03858 ,  30013kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03869
Date: Sat, 4 Oct 2025 16:37:38 GMT   (1758kb)

Title: Exploring the Challenge and Value of Deep Learning in Automated Skin
  Disease Diagnosis
Authors: Runhao Liu, Ziming Chen and Peng Zhang
Categories: cs.CV
\\
  Skin cancer is one of the most prevalent and deadly forms of cancer
worldwide, which highlights the critical importance of early detection and
diagnosis in improving patient outcomes. Deep learning (DL) has shown
significant promise in enhancing the accuracy and efficiency of automated skin
disease diagnosis, particularly in detecting and evaluating skin lesions and
classification. However, there are still several challenges for DL-based skin
cancer diagnosis, including complex features, image noise, intra-class
variation, inter-class similarity, and data imbalance. By synthesizing recent
research, this review discusses innovative approaches to cope with these
challenges, such as data augmentation, hybrid models, and feature fusion, etc.
Furthermore, the review highlights the integration of DL models into clinical
workflows, offering insights into the potential of deep learning to
revolutionize skin disease diagnosis and improve clinical decision-making. This
article follows a comprehensive methodology based on the PRISMA framework and
emphasizes the need for continued advancements to fully unlock the
transformative potential of DL in dermatological care.
\\ ( https://arxiv.org/abs/2510.03869 ,  1758kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03870
Date: Sat, 4 Oct 2025 16:40:18 GMT   (11786kb)

Title: SDAKD: Student Discriminator Assisted Knowledge Distillation for
  Super-Resolution Generative Adversarial Networks
Authors: Nikolaos Kaparinos, Vasileios Mezaris
Categories: cs.CV
Comments: Under review
\\
  Generative Adversarial Networks (GANs) achieve excellent performance in
generative tasks, such as image super-resolution, but their computational
requirements make difficult their deployment on resource-constrained devices.
While knowledge distillation is a promising research direction for GAN
compression, effectively training a smaller student generator is challenging
due to the capacity mismatch between the student generator and the teacher
discriminator. In this work, we propose Student Discriminator Assisted
Knowledge Distillation (SDAKD), a novel GAN distillation methodology that
introduces a student discriminator to mitigate this capacity mismatch. SDAKD
follows a three-stage training strategy, and integrates an adapted feature map
distillation approach in its last two training stages. We evaluated SDAKD on
two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our
experiments demonstrate consistent improvements over the baselines and SOTA GAN
knowledge distillation methods. The SDAKD source code will be made openly
available upon acceptance of the paper.
\\ ( https://arxiv.org/abs/2510.03870 ,  11786kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03873
Date: Sat, 4 Oct 2025 16:50:30 GMT   (2452kb)

Title: PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and
  Postural Diagnosis
Authors: Saja Al-Dabet, Sherzod Turaev, Nazar Zaki, Arif O. Khan, Luai Eldweik
Categories: cs.CV cs.AI
Comments: This is a preprint version of a manuscript under review. All rights
  reserved by the authors
\\
  Diagnosing ocular-induced abnormal head posture (AHP) requires a
comprehensive analysis of both head pose and ocular movements. However,
existing datasets focus on these aspects separately, limiting the development
of integrated diagnostic approaches and restricting AI-driven advancements in
AHP analysis. To address this gap, we introduce PoseGaze-AHP, a novel 3D
dataset that synchronously captures head pose and gaze movement information for
ocular-induced AHP assessment. Structured clinical data were extracted from
medical literature using large language models (LLMs) through an iterative
process with the Claude 3.5 Sonnet model, combining stepwise, hierarchical, and
complex prompting strategies. The extracted records were systematically imputed
and transformed into 3D representations using the Neural Head Avatar (NHA)
framework. The dataset includes 7,920 images generated from two head textures,
covering a broad spectrum of ocular conditions. The extraction method achieved
an overall accuracy of 91.92%, demonstrating its reliability for clinical
dataset construction. PoseGaze-AHP is the first publicly available resource
tailored for AI-driven ocular-induced AHP diagnosis, supporting the development
of accurate and privacy-compliant diagnostic tools.
\\ ( https://arxiv.org/abs/2510.03873 ,  2452kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03874
Date: Sat, 4 Oct 2025 16:51:08 GMT   (6573kb)

Title: DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human
Authors: Yunhao Li, Sijing Wu, Yucheng Zhu, Huiyu Duan, Zicheng Zhang, Guangtao
  Zhai
Categories: cs.CV
\\
  With the rapid development of 3D scanning and reconstruction technologies,
dynamic digital human avatars based on 4D meshes have become increasingly
popular. A high-precision dynamic digital human avatar can be applied to
various fields such as game production, animation generation, and remote
immersive communication. However, these 4D human avatar meshes are prone to
being degraded by various types of noise during the processes of collection,
compression, and transmission, thereby affecting the viewing experience of
users. In light of this fact, quality assessment of dynamic 4D digital humans
becomes increasingly important. In this paper, we first propose a large-scale
dynamic digital human quality assessment dataset, DHQA-4D, which contains 32
high-quality real-scanned 4D human mesh sequences, 1920 distorted textured 4D
human meshes degraded by 11 textured distortions, as well as their
corresponding textured and non-textured mean opinion scores (MOSs). Equipped
with DHQA-4D dataset, we analyze the influence of different types of distortion
on human perception for textured dynamic 4D meshes and non-textured dynamic 4D
meshes. Additionally, we propose DynaMesh-Rater, a novel large multimodal model
(LMM) based approach that is able to assess both textured 4D meshes and
non-textured 4D meshes. Concretely, DynaMesh-Rater elaborately extracts
multi-dimensional features, including visual features from a projected 2D
video, motion features from cropped video clips, and geometry features from the
4D human mesh to provide comprehensive quality-related information. Then we
utilize a LMM model to integrate the multi-dimensional features and conduct a
LoRA-based instruction tuning technique to teach the LMM model to predict the
quality scores. Extensive experimental results on the DHQA-4D dataset
demonstrate the superiority of our DynaMesh-Rater method over previous quality
assessment methods.
\\ ( https://arxiv.org/abs/2510.03874 ,  6573kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03876
Date: Sat, 4 Oct 2025 16:59:26 GMT   (2698kb)

Title: Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive
  Spatial Feature Fusion
Authors: Runhao Liu, Ziming Chen and Peng Zhang
Categories: cs.CV
\\
  Skin cancer classification remains a challenging problem due to high
inter-class similarity, intra-class variability, and image noise in dermoscopic
images. To address these issues, we propose an improved ResNet-50 model
enhanced with Adaptive Spatial Feature Fusion (ASFF), which adaptively
integrates multi-scale semantic and surface features to improve feature
representation and reduce overfitting. The ResNet-50 model is enhanced with an
adaptive feature fusion mechanism to achieve more effective multi-scale feature
extraction and improve overall performance. Specifically, a dual-branch design
fuses high-level semantic and mid-level detail features, which are processed
through global average pooling and fully connected layers to generate adaptive
weights for weighted fusion, thereby strengthening feature learning and
reducing the impact of noise on classification. The method is evaluated on a
subset of the ISIC 2020 dataset containing 3297 benign and malignant skin
lesion images. Experimental results show that the proposed ASFF-based ResNet-50
achieves the best overall performance compared with 5 classic convolutional
neural networks (CNNs) models. The proposed model reached an accuracy of 93.18%
along with higher precision, recall, specificity, and F1 score. The improved
model achieves an AUC value of 0.9670 and 0.9717 in the P-R and ROC curve,
respectively. Then, the evaluation based on Grad-CAM further proved that the
improved model adaptively focuses on lesion-relevant regions while suppressing
irrelevant background information, thereby validating its enhanced feature
learning capability from a deep representation perspective. These findings
demonstrate that the proposed approach provides a more effective and efficient
solution for computer-aided skin cancer diagnosis.
\\ ( https://arxiv.org/abs/2510.03876 ,  2698kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03878
Date: Sat, 4 Oct 2025 17:06:46 GMT   (908kb)

Title: Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional
  Neural Networks
Authors: Ajo Babu George and Sreehari J R Ajo Babu George and Sreehari J R Ajo
  Babu George and Sreehari J R
Categories: cs.CV cs.AI
\\
  Aims Late diagnosis of Oral Squamous Cell Carcinoma (OSCC) contributes
significantly to its high global mortality rate, with over 50\% of cases
detected at advanced stages and a 5-year survival rate below 50\% according to
WHO statistics. This study aims to improve early detection of OSCC by
developing a multimodal deep learning framework that integrates clinical,
radiological, and histopathological images using a weighted ensemble of
DenseNet-121 convolutional neural networks (CNNs). Material and Methods A
retrospective study was conducted using publicly available datasets
representing three distinct medical imaging modalities. Each modality-specific
dataset was used to train a DenseNet-121 CNN via transfer learning.
Augmentation and modality-specific preprocessing were applied to increase
robustness. Predictions were fused using a validation-weighted ensemble
strategy. Evaluation was performed using accuracy, precision, recall, F1-score.
Results High validation accuracy was achieved for radiological (100\%) and
histopathological (95.12\%) modalities, with clinical images performing lower
(63.10\%) due to visual heterogeneity. The ensemble model demonstrated improved
diagnostic robustness with an overall accuracy of 84.58\% on a multimodal
validation dataset of 55 samples. Conclusion The multimodal ensemble framework
bridges gaps in the current diagnostic workflow by offering a non-invasive,
AI-assisted triage tool that enhances early identification of high-risk
lesions. It supports clinicians in decision-making, aligning with global
oncology guidelines to reduce diagnostic delays and improve patient outcomes.
\\ ( https://arxiv.org/abs/2510.03878 ,  908kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03880
Date: Sat, 4 Oct 2025 17:12:54 GMT   (4865kb)

Title: Exploring Instruction Data Quality for Explainable Image Quality
  Assessment
Authors: Yunhao Li, Sijing Wu, Huiyu Duan, Yucheng Zhu, Qi Jia, Guangtao Zhai
Categories: cs.CV
\\
  In recent years, with the rapid development of powerful multimodal large
language models (MLLMs), explainable image quality assessment (IQA) has
gradually become popular, aiming at providing quality-related descriptions and
answers of images. To achieve this goal, recent methods seek to construct a
large-scale instruction tuning dataset to empower the MLLM with quality
perception ability following the well-known scaling law. However, a large
amount of instruction tuning data may cause substantial computational costs and
redundant data, which in turn will cause harm to the performance of the model.
To cope with this problem, in this paper, we challenge the scaling law and
systematically investigate the role of data quality of the instruction tuning
dataset for explainable IQA. Using a powerful pre-trained MLLM, we first
investigate the changes in model performance after fine-tuning with different
sizes of instruction tuning data. We find that selecting a subset of the data
set randomly using an appropriate ratio can even lead to better results than
training with the entire instruction tuning dataset, demonstrating the
redundancy of current explainable IQA instruction tuning data. Beyond randomly
sampling a subset, we propose a clustering-based data selection framework with
three stages: clustering feature extraction, cluster quota allocation, and
cluster sampling strategy. Then we systematically analyze the choices of each
stage and propose a simple but efficient data selection method IQA-Select for
explainable IQA. The experimental results demonstrate that IQA-Select can
achieve 102.1% and 103.7% performance of full fine-tuning using only 10%
selected data in Q-Bench and AesBench respectively, significantly reducing
computational costs while achieving better performance.
\\ ( https://arxiv.org/abs/2510.03880 ,  4865kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03896
Date: Sat, 4 Oct 2025 18:33:27 GMT   (35611kb)

Title: Bridge Thinking and Acting: Unleashing Physical Potential of VLM with
  Generalizable Action Expert
Authors: Mingyu Liu, Zheng Huang, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du,
  Yating Wang, Haoyi Zhu, Hao Chen, Chunhua Shen
Categories: cs.CV cs.RO
\\
  Although Vision-Language Models (VLM) have demonstrated impressive planning
and reasoning capabilities, translating these abilities into the physical world
introduces significant challenges. Conventional Vision-Language-Action (VLA)
models, which integrate reasoning and action into a monolithic architecture,
generalize poorly because they are constrained by scarce, narrow-domain data.
While recent dual-system approaches attempt to decouple "thinking" from
"acting", they are often constrained by semantic ambiguities within the action
module. This ambiguity makes large-scale, cross-task training infeasible.
Consequently, these systems typically necessitate fine-tuning on newly
collected data when deployed to novel environments, and the cooperation
mechanism between the two systems remains ill-defined. To address these
limitations, we introduce, for the first time, a framework centered around a
generalizable action expert. Our approach utilizes sparse 3D trajectories as an
intermediate representation, effectively bridging the high-level planning
capabilities of the VLM with the low-level physical action module. During the
planning phase, the VLM is only required to generate coarse 3D waypoints. These
waypoints are then processed by our generalizable action expert, which refines
them into dense, executable action sequences by sampling real-time point cloud
observations of the environment. To promote training efficiency and robust
generalization, we introduce a novel "Action Pre-training, Pointcloud
Fine-tuning" paradigm. Our method combines the broad generalization
capabilities of VLMs in visual understanding and planning with the
fine-grained, action-level generalization of action expert.
\\ ( https://arxiv.org/abs/2510.03896 ,  35611kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03903
Date: Sat, 4 Oct 2025 18:56:41 GMT   (824kb)

Title: Zero-Shot Fine-Grained Image Classification Using Large Vision-Language
  Models
Authors: Md. Atabuzzaman, Andrew Zhang, Chris Thomas
Categories: cs.CV
Comments: Accepted to EMNLP 2025 Findings
\\
  Large Vision-Language Models (LVLMs) have demonstrated impressive performance
on vision-language reasoning tasks. However, their potential for zero-shot
fine-grained image classification, a challenging task requiring precise
differentiation between visually similar categories, remains underexplored. We
present a novel method that transforms zero-shot fine-grained image
classification into a visual question-answering framework, leveraging LVLMs'
comprehensive understanding capabilities rather than relying on direct class
name generation. We enhance model performance through a novel attention
intervention technique. We also address a key limitation in existing datasets
by developing more comprehensive and precise class description benchmarks. We
validate the effectiveness of our method through extensive experimentation
across multiple fine-grained image classification benchmarks. Our proposed
method consistently outperforms the current state-of-the-art (SOTA) approach,
demonstrating both the effectiveness of our method and the broader potential of
LVLMs for zero-shot fine-grained classification tasks. Code and Datasets:
https://github.com/Atabuzzaman/Fine-grained-classification
\\ ( https://arxiv.org/abs/2510.03903 ,  824kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03906
Date: Sat, 4 Oct 2025 19:05:04 GMT   (5043kb)

Title: From Filters to VLMs: Benchmarking Defogging Methods through Object
  Detection and Segmentation Performance
Authors: Ardalan Aryashad, Parsa Razmara, Amin Mahjoub, Seyedarmin Azizi, Mahdi
  Salmani, Arad Firouzkouhi
Categories: cs.CV
\\
  Autonomous driving perception systems are particularly vulnerable in foggy
conditions, where light scattering reduces contrast and obscures fine details
critical for safe operation. While numerous defogging methods exist-from
handcrafted filters to learned restoration models-improvements in image
fidelity do not consistently translate into better downstream detection and
segmentation. Moreover, prior evaluations often rely on synthetic data, leaving
questions about real-world transferability. We present a structured empirical
study that benchmarks a comprehensive set of pipelines, including (i) classical
filters, (ii) modern defogging networks, (iii) chained variants
(filter$\rightarrow$model, model$\rightarrow$filter), and (iv) prompt-driven
visual--language image editing models (VLM) applied directly to foggy images.
Using Foggy Cityscapes, we assess both image quality and downstream performance
on object detection (mAP) and segmentation (PQ, RQ, SQ). Our analysis reveals
when defogging helps, when chaining yields synergy or degradation, and how
VLM-based editors compare to dedicated approaches. In addition, we evaluate
qualitative rubric-based scores from a VLM judge and quantify their alignment
with task metrics, showing strong correlations with mAP. Together, these
results establish a transparent, task-oriented benchmark for defogging methods
and highlight the conditions under which preprocessing genuinely improves
autonomous perception in adverse weather.
\\ ( https://arxiv.org/abs/2510.03906 ,  5043kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03909
Date: Sat, 4 Oct 2025 19:16:28 GMT   (9200kb)

Title: Generating Human Motion Videos using a Cascaded Text-to-Video Framework
Authors: Hyelin Nam, Hyojun Go, Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung
Categories: cs.CV
Comments: 18 pages, 7 figures, Project Page:https://hyelinnam.github.io/Cameo/
\\
  Human video generation is becoming an increasingly important task with broad
applications in graphics, entertainment, and embodied AI. Despite the rapid
progress of video diffusion models (VDMs), their use for general-purpose human
video generation remains underexplored, with most works constrained to
image-to-video setups or narrow domains like dance videos. In this work, we
propose CAMEO, a cascaded framework for general human motion video generation.
It seamlessly bridges Text-to-Motion (T2M) models and conditional VDMs,
mitigating suboptimal factors that may arise in this process across both
training and inference through carefully designed components. Specifically, we
analyze and prepare both textual prompts and visual conditions to effectively
train the VDM, ensuring robust alignment between motion descriptions,
conditioning signals, and the generated videos. Furthermore, we introduce a
camera-aware conditioning module that connects the two stages, automatically
selecting viewpoints aligned with the input text to enhance coherence and
reduce manual intervention. We demonstrate the effectiveness of our approach on
both the MovieGen benchmark and a newly introduced benchmark tailored to the
T2M-VDM combination, while highlighting its versatility across diverse use
cases.
\\ ( https://arxiv.org/abs/2510.03909 ,  9200kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03915
Date: Sat, 4 Oct 2025 19:41:11 GMT   (31875kb)

Title: OpenFLAME: Federated Visual Positioning System to Enable Large-Scale
  Augmented Reality Applications
Authors: Sagar Bharadwaj, Harrison Williams, Luke Wang, Michael Liang, Tao Jin,
  Srinivasan Seshan, Anthony Rowe
Categories: cs.CV cs.DC cs.RO
\\
  World-scale augmented reality (AR) applications need a ubiquitous 6DoF
localization backend to anchor content to the real world consistently across
devices. Large organizations such as Google and Niantic are 3D scanning outdoor
public spaces in order to build their own Visual Positioning Systems (VPS).
These centralized VPS solutions fail to meet the needs of many future AR
applications -- they do not cover private indoor spaces because of privacy
concerns, regulations, and the labor bottleneck of updating and maintaining 3D
scans. In this paper, we present OpenFLAME, a federated VPS backend that allows
independent organizations to 3D scan and maintain a separate VPS service for
their own spaces. This enables access control of indoor 3D scans, distributed
maintenance of the VPS backend, and encourages larger coverage. Sharding of VPS
services introduces several unique challenges -- coherency of localization
results across spaces, quality control of VPS services, selection of the right
VPS service for a location, and many others. We introduce the concept of
federated image-based localization and provide reference solutions for managing
and merging data across maps without sharing private data.
\\ ( https://arxiv.org/abs/2510.03915 ,  31875kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03921
Date: Sat, 4 Oct 2025 19:55:30 GMT   (2616kb)

Title: Talking Tennis: Language Feedback from 3D Biomechanical Action
  Recognition
Authors: Arushi Dashore, Aryan Anumala, Emily Hui, Olivia Yang
Categories: cs.CV cs.AI cs.HC
Comments: 10 pages, 4 figures, 2 tables
ACM-class: I.2.10; I.5.4; I.2.7
\\
  Automated tennis stroke analysis has advanced significantly with the
integration of biomechanical motion cues alongside deep learning techniques,
enhancing stroke classification accuracy and player performance evaluation.
Despite these advancements, existing systems often fail to connect
biomechanical insights with actionable language feedback that is both
accessible and meaningful to players and coaches. This research project
addresses this gap by developing a novel framework that extracts key
biomechanical features (such as joint angles, limb velocities, and kinetic
chain patterns) from motion data using Convolutional Neural Network Long
Short-Term Memory (CNN-LSTM)-based models. These features are analyzed for
relationships influencing stroke effectiveness and injury risk, forming the
basis for feedback generation using large language models (LLMs). Leveraging
the THETIS dataset and feature extraction techniques, our approach aims to
produce feedback that is technically accurate, biomechanically grounded, and
actionable for end-users. The experimental setup evaluates this framework on
classification performance and interpretability, bridging the gap between
explainable AI and sports biomechanics.
\\ ( https://arxiv.org/abs/2510.03921 ,  2616kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03955
Date: Sat, 4 Oct 2025 21:48:40 GMT   (4320kb)

Title: Harnessing Synthetic Preference Data for Enhancing Temporal
  Understanding of Video-LLMs
Authors: Sameep Vani, Shreyas Jena, Maitreya Patel, Chitta Baral, Somak Aditya,
  Yezhou Yang
Categories: cs.CV
Comments: 17 pages, 9 figures, 6 tables. Presents TimeWarp, a synthetic
  preference data framework to improve temporal understanding in Video-LLMs,
  showing consistent gains across seven benchmarks. Includes supplementary
  material in the Appendix
\\
  While Video Large Language Models (Video-LLMs) have demonstrated remarkable
performance across general video understanding benchmarks-particularly in video
captioning and descriptive tasks-they consistently underperform on tasks that
require fine-grained temporal understanding. This limitation arises due to the
lack of visual complexity and temporal nuance in current fine-tuning datasets,
leading these models to rely heavily on language-based reasoning rather than
truly understanding video dynamics. In this work, we propose TimeWarp, a
systematic method to create a targeted synthetic temporal dataset to fine-tune
the model's responses to encourage it to focus on the given input video. We
introduce a large-scale preference dataset, created using TimeWarp, that
captures intricate temporal dynamics often overlooked, grounding the model's
responses to visual and temporal information. We demonstrate that when our
method is applied to existing models, it significantly improves performance on
temporal understanding benchmarks, highlighting the effectiveness of our
proposed datasets in advancing temporal understanding in Video-LLMs, resulting
in an absolute improvement in performance across seven benchmarks. Code is
available at https://github.com/sameepv21/timewarp.
\\ ( https://arxiv.org/abs/2510.03955 ,  4320kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03978
Date: Sat, 4 Oct 2025 23:38:18 GMT   (611kb)

Title: No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language
  Models
Authors: Min Woo Sun, Alejandro Lozano, Javier Gamazo Tejero, Vishwesh Nath,
  Xiao Xiao Sun, James Burgess, Yuhui Zhang, Kun Yuan, Robert Tibshirani, Sean
  Huver, Serena Yeung-Levy
Categories: cs.CV cs.CL
\\
  Embedding vision-language models (VLMs) are typically pretrained with short
text windows (<77 tokens), which forces the truncation of long-format captions.
Yet, the distribution of biomedical captions from large-scale open source
literature reveals that a huge portion of captions far exceed 77 tokens. To
this end, we investigate the impact of pretraining on long-format biomedical
captions by extending the context length of text encoders in VLMs. We find that
longer context (thus, enabling additional supervision provided in long-format
captions) correlates with better retrieval and classification performance.
Given this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M
image-caption pairs enriched with context-aware descriptions from full-text
articles, providing longer and additional textual supervision. Using
BIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a
text encoder supporting windows of up to 512 tokens. Our model extends context
capacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption
retrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in
Recall@1 and +2% average improvements in classification, while also converging
faster than short-context. Our results demonstrate that long-context modeling
is a promising direction for advancing biomedical VLMs.
\\ ( https://arxiv.org/abs/2510.03978 ,  611kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03993
Date: Sun, 5 Oct 2025 01:52:19 GMT   (170kb)

Title: Keep It on a Leash: Controllable Pseudo-label Generation Towards
  Realistic Long-Tailed Semi-Supervised Learning
Authors: Yaxin Hou, Bo Han, Yuheng Jia, Hui Liu, Junhui Hou
Categories: cs.CV cs.LG
Comments: The paper is accepted by NeurIPS 2025
\\
  Current long-tailed semi-supervised learning methods assume that labeled data
exhibit a long-tailed distribution, and unlabeled data adhere to a typical
predefined distribution (i.e., long-tailed, uniform, or inverse long-tailed).
However, the distribution of the unlabeled data is generally unknown and may
follow an arbitrary distribution. To tackle this challenge, we propose a
Controllable Pseudo-label Generation (CPG) framework, expanding the labeled
dataset with the progressively identified reliable pseudo-labels from the
unlabeled dataset and training the model on the updated labeled dataset with a
known distribution, making it unaffected by the unlabeled data distribution.
Specifically, CPG operates through a controllable self-reinforcing optimization
cycle: (i) at each training step, our dynamic controllable filtering mechanism
selectively incorporates reliable pseudo-labels from the unlabeled dataset into
the labeled dataset, ensuring that the updated labeled dataset follows a known
distribution; (ii) we then construct a Bayes-optimal classifier using logit
adjustment based on the updated labeled data distribution; (iii) this improved
classifier subsequently helps identify more reliable pseudo-labels in the next
training step. We further theoretically prove that this optimization cycle can
significantly reduce the generalization error under some conditions.
Additionally, we propose a class-aware adaptive augmentation module to further
improve the representation of minority classes, and an auxiliary branch to
maximize data utilization by leveraging all labeled and unlabeled samples.
Comprehensive evaluations on various commonly used benchmark datasets show that
CPG achieves consistent improvements, surpassing state-of-the-art methods by up
to \textbf{15.97\%} in accuracy. The code is available at
https://github.com/yaxinhou/CPG.
\\ ( https://arxiv.org/abs/2510.03993 ,  170kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04003
Date: Sun, 5 Oct 2025 02:34:38 GMT   (12964kb)

Title: Enhancing OCR for Sino-Vietnamese Language Processing via Fine-tuned
  PaddleOCRv5
Authors: Minh Hoang Nguyen and Su Nguyen Thiet
Categories: cs.CV cs.CL
Comments: 5 pages, 6 figures, 2 tables
MSC-class: 68T50, 68T50, 68T10
ACM-class: I.2.7; I.5; I.7.5
\\
  Recognizing and processing Classical Chinese (Han-Nom) texts play a vital
role in digitizing Vietnamese historical documents and enabling cross-lingual
semantic research. However, existing OCR systems struggle with degraded scans,
non-standard glyphs, and handwriting variations common in ancient sources. In
this work, we propose a fine-tuning approach for PaddleOCRv5 to improve
character recognition on Han-Nom texts. We retrain the text recognition module
using a curated subset of ancient Vietnamese Chinese manuscripts, supported by
a full training pipeline covering preprocessing, LMDB conversion, evaluation,
and visualization. Experimental results show a significant improvement over the
base model, with exact accuracy increasing from 37.5 percent to 50.0 percent,
particularly under noisy image conditions. Furthermore, we develop an
interactive demo that visually compares pre- and post-fine-tuning recognition
results, facilitating downstream applications such as Han-Vietnamese semantic
alignment, machine translation, and historical linguistics research. The demo
is available at https://huggingface.co/spaces/MinhDS/Fine-tuned-PaddleOCRv5.
\\ ( https://arxiv.org/abs/2510.04003 ,  12964kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04021
Date: Sun, 5 Oct 2025 04:03:17 GMT   (2538kb)

Title: Fit Pixels, Get Labels: Meta-learned Implicit Networks for Image
  Segmentation
Authors: Kushal Vyas and Ashok Veeraraghavan and Guha Balakrishnan
Categories: cs.CV
Comments: MICCAI 2025 (oral). Final peer-reviewed copy accessible at publisher
  DOI https://link.springer.com/chapter/10.1007/978-3-032-04947-6_19 . Project
  page, https://kushalvyas.github.io/metaseg.html
DOI: 10.1007/978-3-032-04947-6_19
\\
  Implicit neural representations (INRs) have achieved remarkable successes in
learning expressive yet compact signal representations. However, they are not
naturally amenable to predictive tasks such as segmentation, where they must
learn semantic structures over a distribution of signals. In this study, we
introduce MetaSeg, a meta-learning framework to train INRs for medical image
segmentation. MetaSeg uses an underlying INR that simultaneously predicts per
pixel intensity values and class labels. It then uses a meta-learning procedure
to find optimal initial parameters for this INR over a training dataset of
images and segmentation maps, such that the INR can simply be fine-tuned to fit
pixels of an unseen test image, and automatically decode its class labels. We
evaluated MetaSeg on 2D and 3D brain MRI segmentation tasks and report Dice
scores comparable to commonly used U-Net models, but with $90\%$ fewer
parameters. MetaSeg offers a fresh, scalable alternative to traditional
resource-heavy architectures such as U-Nets and vision transformers for medical
image segmentation. Our project is available at
https://kushalvyas.github.io/metaseg.html .
\\ ( https://arxiv.org/abs/2510.04021 ,  2538kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04022
Date: Sun, 5 Oct 2025 04:03:31 GMT   (19340kb)

Title: Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved
  Reasoning
Authors: Chendong Wang, Donglin Bai, Yifan Yang, Xiao Jin, Anlan Zhang, Rui
  Wang, Shiqi Jiang, Yuqing Yang, Hao Wu, Qi Dai, Chong Luo, Ting Cao, Lili
  Qiu, Suman Banerjee
Categories: cs.CV
\\
  We present \emph{Video-in-the-Loop} (ViTL), a two-stage long-video QA
framework that preserves a fixed token budget by first \emph{localizing}
question-relevant interval(s) with a low-fps skim and then \emph{answering} via
span-aware reallocation of visual tokens at higher effective frame rate,
emitting an interleaved output with both spans and the final option for direct
attribution. We also introduce \dataname{}, which converts description based
event graphs into \emph{span-grounded} multiple-choice QA by pairing each
question with \emph{ground-truth} time span(s) and related reasoning. ViTL is
trained end-to-end with an interleaved group-relative objective that couples
temporal IoU for localization with answer correctness, allowing credit to flow
from answers back to spans without increasing compute. Under fixed token
budgets, ViTL attains up to 8.6% with 50% less frame input on long-video QA and
temporal grounding (e.g., Charades-STA, ActivityNet-Captions) and ablations
show that span-aware token reallocation consistently surpasses uniform
sampling. Together, \dataname{} and ViTL provide an interpretable,
compute-efficient recipe for scalable long-video QA.
\\ ( https://arxiv.org/abs/2510.04022 ,  19340kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04024
Date: Sun, 5 Oct 2025 04:05:37 GMT   (2081kb)

Title: Enhancing Fake News Video Detection via LLM-Driven Creative Process
  Simulation
Authors: Yuyan Bu, Qiang Sheng, Juan Cao, Shaofei Wang, Peng Qi, Yuhui Shi,
  Beizhe Hu
Categories: cs.CV cs.MM
Comments: ACM CIKM 2025
DOI: 10.1145/3746252.3760933
\\
  The emergence of fake news on short video platforms has become a new
significant societal concern, necessitating automatic video-news-specific
detection. Current detectors primarily rely on pattern-based features to
separate fake news videos from real ones. However, limited and less diversified
training data lead to biased patterns and hinder their performance. This
weakness stems from the complex many-to-many relationships between video
material segments and fabricated news events in real-world scenarios: a single
video clip can be utilized in multiple ways to create different fake
narratives, while a single fabricated event often combines multiple distinct
video segments. However, existing datasets do not adequately reflect such
relationships due to the difficulty of collecting and annotating large-scale
real-world data, resulting in sparse coverage and non-comprehensive learning of
the characteristics of potential fake news video creation. To address this
issue, we propose a data augmentation framework, AgentAug, that generates
diverse fake news videos by simulating typical creative processes. AgentAug
implements multiple LLM-driven pipelines of four fabrication categories for
news video creation, combined with an active learning strategy based on
uncertainty sampling to select the potentially useful augmented samples during
training. Experimental results on two benchmark datasets demonstrate that
AgentAug consistently improves the performance of short video fake news
detectors.
\\ ( https://arxiv.org/abs/2510.04024 ,  2081kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04034
Date: Sun, 5 Oct 2025 04:56:07 GMT   (1664kb)

Title: Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention
  Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance
  Existing Frameworks
Authors: Linn Bieske, Carla Lorente
Categories: cs.CV cs.AI
\\
  Recent advances in image editing have shifted from manual pixel manipulation
to employing deep learning methods like stable diffusion models, which now
leverage cross-attention mechanisms for text-driven control. This transition
has simplified the editing process but also introduced variability in results,
such as inconsistent hair color changes. Our research aims to enhance the
precision and reliability of prompt-to-prompt image editing frameworks by
exploring and optimizing hyperparameters. We present a comprehensive study of
the "word swap" method, develop an "attention re-weight method" for better
adaptability, and propose the "CL P2P" framework to address existing
limitations like cycle inconsistency. This work contributes to understanding
and improving the interaction between hyperparameter settings and the
architectural choices of neural network models, specifically their attention
mechanisms, which significantly influence the composition and quality of the
generated images.
\\ ( https://arxiv.org/abs/2510.04034 ,  1664kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04039
Date: Sun, 5 Oct 2025 05:15:45 GMT   (4311kb)

Title: \textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced
  GUI Visual Grounding
Authors: Bin Lei, Nuo Xu, Ali Payani, Mingyi Hong, Chunhua Liao, Yu Cao, Caiwen
  Ding
Categories: cs.CV cs.AI
\\
  Multimodal large language models (MLLMs) have markedly expanded the
competence of graphical user-interface (GUI) systems, propelling them beyond
controlled simulations into complex, real-world environments across diverse
platforms. However, practical usefulness is still bounded by the reliability of
visual grounding, i.e., mapping textual references to exact on-screen elements.
This limitation prevents the system from accurately performing pointer-level
actions such as clicking or dragging. To address it, we introduce GUI-Spotlight
-- a model trained for image-grounded reasoning that dynamically invokes
multiple specialized tools to iteratively narrow its focus to the relevant
region of the screen, thereby substantially improving visual grounding
accuracy. On the ScreenSpot-Pro benchmark, GUI-Spotlight trained with only
18.5K training samples achieves 52.8\% accuracy, surpassing V2P-7B (50.6\% with
9.6M training samples) and GTA-1-7B (50.1\% with 1.56M training samples).
\\ ( https://arxiv.org/abs/2510.04039 ,  4311kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04044
Date: Sun, 5 Oct 2025 05:35:12 GMT   (21kb)

Title: Quantization Range Estimation for Convolutional Neural Networks
Authors: Bingtao Yang, Yujia Wang, Mengzhi Jiao, and Hongwei Huo
Categories: cs.CV cs.AI
Comments: 11 pages, 5 tables, research report
MSC-class: 00-01
ACM-class: I.2.6; K.3.2
\\
  Post-training quantization for reducing the storage of deep neural network
models has been demonstrated to be an effective way in various tasks. However,
low-bit quantization while maintaining model accuracy is a challenging problem.
In this paper, we present a range estimation method to improve the quantization
performance for post-training quantization. We model the range estimation into
an optimization problem of minimizing quantization errors by layer-wise local
minima. We prove this problem is locally convex and present an efficient search
algorithm to find the optimal solution. We propose the application of the above
search algorithm to the transformed weights space to do further improvement in
practice. Our experiments demonstrate that our method outperforms
state-of-the-art performance generally on top-1 accuracy for image
classification tasks on the ResNet series models and Inception-v3 model. The
experimental results show that the proposed method has almost no loss of top-1
accuracy in 8-bit and 6-bit settings for image classifications, and the
accuracy of 4-bit quantization is also significantly improved. The code is
available at https://github.com/codeiscommitting/REQuant.
\\ ( https://arxiv.org/abs/2510.04044 ,  21kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04057
Date: Sun, 5 Oct 2025 06:37:26 GMT   (10404kb)

Title: MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene
  Generation
Authors: Zhenyu Pan, Yucheng Lu, Han Liu
Categories: cs.CV cs.AI
Comments: The Thirty-Ninth Annual Conference on Neural Information Processing
  Systems (NeurIPS 2025)
\\
  We present MetaFind, a scene-aware tri-modal compositional retrieval
framework designed to enhance scene generation in the metaverse by retrieving
3D assets from large-scale repositories. MetaFind addresses two core
challenges: (i) inconsistent asset retrieval that overlooks spatial, semantic,
and stylistic constraints, and (ii) the absence of a standardized retrieval
paradigm specifically tailored for 3D asset retrieval, as existing approaches
mainly rely on general-purpose 3D shape representation models. Our key
innovation is a flexible retrieval mechanism that supports arbitrary
combinations of text, image, and 3D modalities as queries, enhancing spatial
reasoning and style consistency by jointly modeling object-level features
(including appearance) and scene-level layout structures. Methodologically,
MetaFind introduces a plug-and-play equivariant layout encoder ESSGNN that
captures spatial relationships and object appearance features, ensuring
retrieved 3D assets are contextually and stylistically coherent with the
existing scene, regardless of coordinate frame transformations. The framework
supports iterative scene construction by continuously adapting retrieval
results to current scene updates. Empirical evaluations demonstrate the
improved spatial and stylistic consistency of MetaFind in various retrieval
tasks compared to baseline methods.
\\ ( https://arxiv.org/abs/2510.04057 ,  10404kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04063
Date: Sun, 5 Oct 2025 06:51:47 GMT   (724kb)

Title: Ordinal Encoding as a Regularizer in Binary Loss for Solar Flare
  Prediction
Authors: Chetraj Pandey, Jinsu Hong, Anli Ji, Rafal A. Angryk, Berkay Aydin
Categories: cs.CV astro-ph.SR
Comments: This is a preprint submitted to ICDM Workshop (SABID 2025). 6 pages,
  2 Figures
\\
  The prediction of solar flares is typically formulated as a binary
classification task, distinguishing events as either Flare (FL) or No-Flare
(NF) according to a specified threshold (for example, greater than or equal to
C-class, M-class, or X-class). However, this binary framework neglects the
inherent ordinal relationships among the sub-classes contained within each
category (FL and NF). Several studies on solar flare prediction have
empirically shown that the most frequent misclassifications occur near this
prediction threshold. This suggests that the models struggle to differentiate
events that are similar in intensity but fall on opposite sides of the binary
threshold. To mitigate this limitation, we propose a modified loss function
that integrates the ordinal information among the sub-classes of the binarized
flare labels into the conventional binary cross-entropy (BCE) loss. This
approach serves as an ordinality-aware, data-driven regularization method that
penalizes the incorrect predictions of flare events in close proximity to the
prediction threshold more heavily than those away from the boundary during
model optimization. By incorporating ordinal weighting into the loss function,
we aim to enhance the model's learning process by leveraging the ordinal
characteristics of the data, thereby improving its overall performance.
\\ ( https://arxiv.org/abs/2510.04063 ,  724kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04066
Date: Sun, 5 Oct 2025 06:58:11 GMT   (30633kb)

Title: QuantDemoire: Quantization with Outlier Aware for Image Demoir\'eing
Authors: Zheng Chen, Kewei Zhang, Xiaoyang Liu, Weihang Zhang, Mengfan Wang,
  Yifan Fu, Yulun Zhang
Categories: cs.CV
Comments: Code is available at: https://github.com/zhengchen1999/QuantDemoire
\\
  Demoir\'eing aims to remove moir\'e artifacts that often occur in images.
While recent deep learning-based methods have achieved promising results, they
typically require substantial computational resources, limiting their
deployment on edge devices. Model quantization offers a compelling solution.
However, directly applying existing quantization methods to demoir\'eing models
introduces severe performance degradation. The main reasons are distribution
outliers and weakened representations in smooth regions. To address these
issues, we propose QuantDemoire, a post-training quantization framework
tailored to demoir\'eing. It contains two key components. **First}, we
introduce an outlier-aware quantizer to reduce errors from outliers. It uses
sampling-based range estimation to reduce activation outliers, and keeps a few
extreme weights in FP16 with negligible cost. **Second**, we design a
frequency-aware calibration strategy. It emphasizes low- and mid-frequency
components during fine-tuning, which mitigates banding artifacts caused by
low-bit quantization. Extensive experiments validate that our QuantDemoire
achieves large reductions in parameters and computation while maintaining
quality. Meanwhile, it outperforms existing quantization methods by over **4
dB** on W4A4. Code is released at:
https://github.com/zhengchen1999/QuantDemoire.
\\ ( https://arxiv.org/abs/2510.04066 ,  30633kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04069
Date: Sun, 5 Oct 2025 07:20:06 GMT   (5560kb)

Title: Diffusion Low Rank Hybrid Reconstruction for Sparse View Medical Imaging
Authors: Zongyin Deng, Qing Zhou, Yuhao Fang, Zijian Wang, Yao Lu, Ye Zhang,
  and Chun Li
Categories: cs.CV
\\
  This work presents TV-LoRA, a novel method for low-dose sparse-view CT
reconstruction that combines a diffusion generative prior (NCSN++ with SDE
modeling) and multi-regularization constraints, including anisotropic TV and
nuclear norm (LoRA), within an ADMM framework. To address ill-posedness and
texture loss under extremely sparse views, TV-LoRA integrates generative and
physical constraints, and utilizes a 2D slice-based strategy with FFT
acceleration and tensor-parallel optimization for efficient inference.
Experiments on AAPM-2016, CTHD, and LIDC datasets with
$N_{\mathrm{view}}=8,4,2$ show that TV-LoRA consistently surpasses benchmarks
in SSIM, texture recovery, edge clarity, and artifact suppression,
demonstrating strong robustness and generalizability. Ablation studies confirm
the complementary effects of LoRA regularization and diffusion priors, while
the FFT-PCG module provides a speedup. Overall, Diffusion + TV-LoRA achieves
high-fidelity, efficient 3D CT reconstruction and broad clinical applicability
in low-dose, sparse-sampling scenarios.
\\ ( https://arxiv.org/abs/2510.04069 ,  5560kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04100
Date: Sun, 5 Oct 2025 08:58:08 GMT   (5763kb)

Title: TOPO-Bench: An Open-Source Topological Mapping Evaluation Framework with
  Quantifiable Perceptual Aliasing
Authors: Jiaming Wang, Diwen Liu, Jizhuo Chen, Harold Soh
Categories: cs.CV cs.AI
Comments: Jiaming Wang, Diwen Liu, and Jizhuo Chen contributed equally
\\
  Topological mapping offers a compact and robust representation for
navigation, but progress in the field is hindered by the lack of standardized
evaluation metrics, datasets, and protocols. Existing systems are assessed
using different environments and criteria, preventing fair and reproducible
comparisons. Moreover, a key challenge - perceptual aliasing - remains
under-quantified, despite its strong influence on system performance. We
address these gaps by (1) formalizing topological consistency as the
fundamental property of topological maps and showing that localization accuracy
provides an efficient and interpretable surrogate metric, and (2) proposing the
first quantitative measure of dataset ambiguity to enable fair comparisons
across environments. To support this protocol, we curate a diverse benchmark
dataset with calibrated ambiguity levels, implement and release deep-learned
baseline systems, and evaluate them alongside classical methods. Our
experiments and analysis yield new insights into the limitations of current
approaches under perceptual aliasing. All datasets, baselines, and evaluation
tools are fully open-sourced to foster consistent and reproducible research in
topological mapping.
\\ ( https://arxiv.org/abs/2510.04100 ,  5763kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04111
Date: Sun, 5 Oct 2025 09:30:59 GMT   (13916kb)

Title: Learning Efficient Meshflow and Optical Flow from Event Cameras
Authors: Xinglong Luo, Ao Luo, Kunming Luo, Zhengning Wang, Ping Tan, Bing
  Zeng, and Shuaicheng Liu
Categories: cs.CV
Comments: Accepted by TPAMI 2025
DOI: 10.1109/TPAMI.2025.3615144
\\
  In this paper, we explore the problem of event-based meshflow estimation, a
novel task that involves predicting a spatially smooth sparse motion field from
event cameras. To start, we review the state-of-the-art in event-based flow
estimation, highlighting two key areas for further research: i) the lack of
meshflow-specific event datasets and methods, and ii) the underexplored
challenge of event data density. First, we generate a large-scale
High-Resolution Event Meshflow (HREM) dataset, which showcases its superiority
by encompassing the merits of high resolution at 1280x720, handling dynamic
objects and complex motion patterns, and offering both optical flow and
meshflow labels. These aspects have not been fully explored in previous works.
Besides, we propose Efficient Event-based MeshFlow (EEMFlow) network, a
lightweight model featuring a specially crafted encoder-decoder architecture to
facilitate swift and accurate meshflow estimation. Furthermore, we upgrade
EEMFlow network to support dense event optical flow, in which a
Confidence-induced Detail Completion (CDC) module is proposed to preserve sharp
motion boundaries. We conduct comprehensive experiments to show the exceptional
performance and runtime efficiency (30x faster) of our EEMFlow model compared
to the recent state-of-the-art flow method. As an extension, we expand HREM
into HREM+, a multi-density event dataset contributing to a thorough study of
the robustness of existing methods across data with varying densities, and
propose an Adaptive Density Module (ADM) to adjust the density of input event
data to a more optimal range, enhancing the model's generalization ability. We
empirically demonstrate that ADM helps to significantly improve the performance
of EEMFlow and EEMFlow+ by 8% and 10%, respectively. Code and dataset are
released at https://github.com/boomluo02/EEMFlowPlus.
\\ ( https://arxiv.org/abs/2510.04111 ,  13916kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04125
Date: Sun, 5 Oct 2025 09:58:51 GMT   (28729kb)

Title: Joint Learning of Pose Regression and Denoising Diffusion with Score
  Scaling Sampling for Category-level 6D Pose Estimation
Authors: Seunghyun Lee, Tae-Kyun Kim
Categories: cs.CV
\\
  Latest diffusion models have shown promising results in category-level 6D
object pose estimation by modeling the conditional pose distribution with depth
image input. The existing methods, however, suffer from slow convergence during
training, learning its encoder with the diffusion denoising network in
end-to-end fashion, and require an additional network that evaluates sampled
pose hypotheses to filter out low-quality pose candidates. In this paper, we
propose a novel pipeline that tackles these limitations by two key components.
First, the proposed method pretrains the encoder with the direct pose
regression head, and jointly learns the networks via the regression head and
the denoising diffusion head, significantly accelerating training convergence
while achieving higher accuracy. Second, sampling guidance via time-dependent
score scaling is proposed s.t. the exploration-exploitation trade-off is
effectively taken, eliminating the need for the additional evaluation network.
The sampling guidance maintains multi-modal characteristics of symmetric
objects at early denoising steps while ensuring high-quality pose generation at
final steps. Extensive experiments on multiple benchmarks including REAL275,
HouseCat6D, and ROPE, demonstrate that the proposed method, simple yet
effective, achieves state-of-the-art accuracies even with single-pose
inference, while being more efficient in both training and inference.
\\ ( https://arxiv.org/abs/2510.04125 ,  28729kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04142
Date: Sun, 5 Oct 2025 10:42:21 GMT   (2818kb)

Title: Learning from All: Concept Alignment for Autonomous Distillation from
  Multiple Drifting MLLMs
Authors: Xiaoyu Yang, Jie Lu, En Yu
Categories: cs.CV cs.AI cs.LG
\\
  This paper identifies a critical yet underexplored challenge in distilling
from multimodal large language models (MLLMs): the reasoning trajectories
generated by multiple drifting teachers exhibit concept drift, whereby their
reasoning distributions evolve unpredictably and transmit biases to the student
model, ultimately compromising its performance. To tackle this issue, we
pioneer a theoretical connection between concept drift and knowledge
distillation, casting the non-stationary reasoning dynamics from multiple MLLM
teachers as next-token prediction of multi-stream reasoning trajectories.Guided
by concept drift, we introduce the "learn, compare, critique" paradigm,
culminating in autonomous preference optimization (APO). Under the active
guidance of the teachers, the student model first learns and self-distils
preferred thinking by comparing multiple teachers. It then engages in critical
reflection over the drifting inference from teachers, performing concept
alignment through APO, ultimately yielding a robust, consistent, and
generalizable model.Extensive experiments demonstrate our superior performance
of consistency, robustness and generalization within knowledge distillation.
Besides, we also contributed a large-scale dataset, CXR-MAX (Multi-teachers
Alignment X-rays), comprising 170,982 distilled reasoning trajectories derived
from publicly accessible MLLMs based on MIMIC-CXR. Our code and data are public
at: https://anonymous.4open.science/r/Autonomous-Distillation/.
\\ ( https://arxiv.org/abs/2510.04142 ,  2818kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04145
Date: Sun, 5 Oct 2025 10:48:54 GMT   (33693kb)

Title: Automating construction safety inspections using a multi-modal
  vision-language RAG framework
Authors: Chenxin Wang, Elyas Asadi Shamsabadi, Zhaohui Chen, Luming Shen,
  Alireza Ahmadian Fard Fini, Daniel Dias-da-Costa
Categories: cs.CV cs.CL cs.IR
Comments: 33 pages, 11 figures, 7 tables
\\
  Conventional construction safety inspection methods are often inefficient as
they require navigating through large volume of information. Recent advances in
large vision-language models (LVLMs) provide opportunities to automate safety
inspections through enhanced visual and linguistic understanding. However,
existing applications face limitations including irrelevant or unspecific
responses, restricted modal inputs and hallucinations. Utilisation of Large
Language Models (LLMs) for this purpose is constrained by availability of
training data and frequently lack real-time adaptability. This study introduces
SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG)
framework for automating construction safety inspection reports by integrating
visual and audio inputs. Using real-world data, SiteShield outperformed
unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04,
precision of 0.76, and recall of 0.96. The findings indicate that SiteShield
offers a novel pathway to enhance information retrieval and efficiency in
generating safety reports.
\\ ( https://arxiv.org/abs/2510.04145 ,  33693kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04174
Date: Sun, 5 Oct 2025 12:28:54 GMT   (1665kb)

Title: BLADE: Bias-Linked Adaptive DEbiasing
Authors: Piyush Arora, Navlika Singh, Vasubhya Diwan, Pratik Mazumder
Categories: cs.CV
Comments: The authors have contributed equally
\\
  Neural networks have revolutionized numerous fields, yet they remain
vulnerable to a critical flaw: the tendency to learn implicit biases, spurious
correlations between certain attributes and target labels in training data.
These biases are often more prevalent and easier to learn, causing models to
rely on superficial patterns rather than task-relevant features necessary for
generalization. Existing methods typically rely on strong assumptions, such as
prior knowledge of these biases or access to bias-conflicting samples, i.e.,
samples that contradict spurious correlations and counterbalance bias-aligned
samples, samples that conform to these spurious correlations. However, such
assumptions are often impractical in real-world settings. We propose BLADE
({B}ias-{L}inked {A}daptive {DE}biasing), a generative debiasing framework that
requires no prior knowledge of bias or bias-conflicting samples. BLADE first
trains a generative model to translate images across bias domains while
preserving task-relevant features. Then, it adaptively refines each image with
its synthetic counterpart based on the image's susceptibility to bias. To
encourage robust representations, BLADE aligns an image with its
bias-translated synthetic counterpart that shares task-relevant features but
differs in bias, while misaligning it with samples sharing the same bias. We
evaluate BLADE on multiple benchmark datasets and show that it significantly
outperforms state-of-the-art methods. Notably, it exceeds the closest baseline
by an absolute margin of around 18% on the corrupted CIFAR-10 dataset under the
worst group setting, establishing a new benchmark in bias mitigation and
demonstrating its potential for developing more robust deep learning models
without explicit supervision.
\\ ( https://arxiv.org/abs/2510.04174 ,  1665kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04180
Date: Sun, 5 Oct 2025 12:48:43 GMT   (1838kb)

Title: From Segments to Concepts: Interpretable Image Classification via
  Concept-Guided Segmentation
Authors: Ran Eisenberg, Amit Rozner, Ethan Fetaya, Ofir Lindenbaum
Categories: cs.CV cs.LG
\\
  Deep neural networks have achieved remarkable success in computer vision;
however, their black-box nature in decision-making limits interpretability and
trust, particularly in safety-critical applications. Interpretability is
crucial in domains where errors have severe consequences. Existing models not
only lack transparency but also risk exploiting unreliable or misleading
features, which undermines both robustness and the validity of their
explanations. Concept Bottleneck Models (CBMs) aim to improve transparency by
reasoning through human-interpretable concepts. Still, they require costly
concept annotations and lack spatial grounding, often failing to identify which
regions support each concept. We propose SEG-MIL-CBM, a novel framework that
integrates concept-guided image segmentation into an attention-based multiple
instance learning (MIL) framework, where each segmented region is treated as an
instance and the model learns to aggregate evidence across them. By reasoning
over semantically meaningful regions aligned with high-level concepts, our
model highlights task-relevant evidence, down-weights irrelevant cues, and
produces spatially grounded, concept-level explanations without requiring
annotations of concepts or groups. SEG-MIL-CBM achieves robust performance
across settings involving spurious correlations (unintended dependencies
between background and label), input corruptions (perturbations that degrade
visual quality), and large-scale benchmarks, while providing transparent,
concept-level explanations.
\\ ( https://arxiv.org/abs/2510.04180 ,  1838kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04188
Date: Sun, 5 Oct 2025 13:01:08 GMT   (18561kb)

Title: Let Features Decide Their Own Solvers: Hybrid Feature Caching for
  Diffusion Transformers
Authors: Shikang Zheng, Guantao Chen, Qinming Zhou, Yuqi Lin, Lixuan He, Chang
  Zou, Peiliang Cai, Jiacheng Liu, Linfeng Zhang
Categories: cs.CV
\\
  Diffusion Transformers offer state-of-the-art fidelity in image and video
synthesis, but their iterative sampling process remains a major bottleneck due
to the high cost of transformer forward passes at each timestep. To mitigate
this, feature caching has emerged as a training-free acceleration technique
that reuses or forecasts hidden representations. However, existing methods
often apply a uniform caching strategy across all feature dimensions, ignoring
their heterogeneous dynamic behaviors. Therefore, we adopt a new perspective by
modeling hidden feature evolution as a mixture of ODEs across dimensions, and
introduce HyCa, a Hybrid ODE solver inspired caching framework that applies
dimension-wise caching strategies. HyCa achieves near-lossless acceleration
across diverse domains and models, including 5.55 times speedup on FLUX, 5.56
times speedup on HunyuanVideo, 6.24 times speedup on Qwen-Image and
Qwen-Image-Edit without retraining.
\\ ( https://arxiv.org/abs/2510.04188 ,  18561kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04201
Date: Sun, 5 Oct 2025 13:35:30 GMT   (39017kb)

Title: World-To-Image: Grounding Text-to-Image Generation with Agent-Driven
  World Knowledge
Authors: Moo Hyun Son, Jintaek Oh, Sun Bin Mun, Jaechul Roh, Sehyun Choi
Categories: cs.CV cs.AI
\\
  While text-to-image (T2I) models can synthesize high-quality images, their
performance degrades significantly when prompted with novel or
out-of-distribution (OOD) entities due to inherent knowledge cutoffs. We
introduce World-To-Image, a novel framework that bridges this gap by empowering
T2I generation with agent-driven world knowledge. We design an agent that
dynamically searches the web to retrieve images for concepts unknown to the
base model. This information is then used to perform multimodal prompt
optimization, steering powerful generative backbones toward an accurate
synthesis. Critically, our evaluation goes beyond traditional metrics,
utilizing modern assessments like LLMGrader and ImageReward to measure true
semantic fidelity. Our experiments show that World-To-Image substantially
outperforms state-of-the-art methods in both semantic alignment and visual
aesthetics, achieving +8.1% improvement in accuracy-to-prompt on our curated
NICE benchmark. Our framework achieves these results with high efficiency in
less than three iterations, paving the way for T2I systems that can better
reflect the ever-changing real world. Our demo code is available
here\footnote{https://github.com/mhson-kyle/World-To-Image}.
\\ ( https://arxiv.org/abs/2510.04201 ,  39017kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04220
Date: Sun, 5 Oct 2025 14:23:51 GMT   (19992kb)

Title: MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned
  Semantic Clustering
Authors: Lixuan He, Shikang Zheng, Linfeng Zhang
Categories: cs.CV cs.AI cs.LG
\\
  Autoregressive (AR) models have shown great promise in image generation, yet
they face a fundamental inefficiency stemming from their core component: a
vast, unstructured vocabulary of visual tokens. This conventional approach
treats tokens as a flat vocabulary, disregarding the intrinsic structure of the
token embedding space where proximity often correlates with semantic
similarity. This oversight results in a highly complex prediction task, which
hinders training efficiency and limits final generation quality. To resolve
this, we propose Manifold-Aligned Semantic Clustering (MASC), a principled
framework that constructs a hierarchical semantic tree directly from the
codebook's intrinsic structure. MASC employs a novel geometry-aware distance
metric and a density-driven agglomerative construction to model the underlying
manifold of the token embeddings. By transforming the flat, high-dimensional
prediction task into a structured, hierarchical one, MASC introduces a
beneficial inductive bias that significantly simplifies the learning problem
for the AR model. MASC is designed as a plug-and-play module, and our extensive
experiments validate its effectiveness: it accelerates training by up to 57%
and significantly improves generation quality, reducing the FID of LlamaGen-XL
from 2.87 to 2.58. MASC elevates existing AR frameworks to be highly
competitive with state-of-the-art methods, establishing that structuring the
prediction space is as crucial as architectural innovation for scalable
generative modeling.
\\ ( https://arxiv.org/abs/2510.04220 ,  19992kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04225
Date: Sun, 5 Oct 2025 14:29:01 GMT   (2829kb)

Title: Zoom-In to Sort AI-Generated Images Out
Authors: Yikun Ji, Yan Hong, Bowen Deng, jun lan, Huijia Zhu, Weiqiang Wang,
  Liqing Zhang, Jianfu Zhang
Categories: cs.CV cs.AI cs.CL
Comments: 9 pages, 6 images (19 pages, 11 figures including appendix)
MSC-class: 68T45
ACM-class: I.2.10; I.2.7
\\
  The rapid growth of AI-generated imagery has blurred the boundary between
real and synthetic content, raising critical concerns for digital integrity.
Vision-language models (VLMs) offer interpretability through explanations but
often fail to detect subtle artifacts in high-quality synthetic images. We
propose ZoomIn, a two-stage forensic framework that improves both accuracy and
interpretability. Mimicking human visual inspection, ZoomIn first scans an
image to locate suspicious regions and then performs a focused analysis on
these zoomed-in areas to deliver a grounded verdict. To support training, we
introduce MagniFake, a dataset of 20,000 real and high-quality synthetic images
annotated with bounding boxes and forensic explanations, generated through an
automated VLM-based pipeline. Our method achieves 96.39% accuracy with robust
generalization, while providing human-understandable explanations grounded in
visual evidence.
\\ ( https://arxiv.org/abs/2510.04225 ,  2829kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04231
Date: Sun, 5 Oct 2025 14:44:04 GMT   (5862kb)

Title: A Recursive Pyramidal Algorithm for Solving the Image Registration
  Problem
Authors: Stefan Dirnstorfer
Categories: cs.CV
\\
  The problem of image registration is finding a transformation that aligns two
images, such that the corresponding points are in the same location. This paper
introduces a simple, end-to-end trainable algorithm that is implementable in a
few lines of Python code. The approach is shown to work with very little
training data and training time, while achieving accurate results in some
settings. An example application to stereo vision was trained from 74 images on
a 19x15 input window. With just a dozen lines of Python code this algorithm
excels in brevity and may serve as a good start in related scenarios with
limitations to training data, training time or code complexity.
\\ ( https://arxiv.org/abs/2510.04231 ,  5862kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04232
Date: Sun, 5 Oct 2025 14:44:09 GMT   (579kb)

Title: Detection of retinal diseases using an accelerated reused convolutional
  network
Authors: Amin Ahmadi Kasani, Hedieh Sajedi
Categories: cs.CV cs.LG
Journal-ref: Computers in Biology and Medicine Volume 184, January 2025, 109466
DOI: 10.1016/j.compbiomed.2024.109466
\\
  Convolutional neural networks are continually evolving, with some efforts
aimed at improving accuracy, others at increasing speed, and some at enhancing
accessibility. Improving accessibility broadens the application of neural
networks across a wider range of tasks, including the detection of eye
diseases. Early diagnosis of eye diseases and consulting an ophthalmologist can
prevent many vision disorders. Given the importance of this issue, various
datasets have been collected from the cornea to facilitate the process of
making neural network models. However, most of the methods introduced in the
past are computationally complex. In this study, we tried to increase the
accessibility of deep neural network models. We did this at the most
fundamental level, specifically by redesigning and optimizing the convolutional
layers. By doing so, we created a new general model that incorporates our novel
convolutional layer named ArConv layers. Thanks to the efficient performance of
this new layer, the model has suitable complexity for use in mobile phones and
can perform the task of diagnosing the presence of disease with high accuracy.
The final model we present contains only 1.3 million parameters. In comparison
to the MobileNetV2 model, which has 2.2 million parameters, our model
demonstrated better accuracy when trained and evaluated on the RfMiD dataset
under identical conditions, achieving an accuracy of 0.9328 versus 0.9266 on
the RfMiD test set.
\\ ( https://arxiv.org/abs/2510.04232 ,  579kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04236
Date: Sun, 5 Oct 2025 15:03:31 GMT   (34051kb)

Title: Scaling Sequence-to-Sequence Generative Neural Rendering
Authors: Shikun Liu, Kam Woh Ng, Wonbong Jang, Jiadong Guo, Junlin Han, Haozhe
  Liu, Yiannis Douratsos, Juan C. P\'erez, Zijian Zhou, Chi Phung, Tao Xiang,
  Juan-Manuel P\'erez-R\'ua
Categories: cs.CV
Comments: Project Page: https://shikun.io/projects/kaleido
\\
  We present Kaleido, a family of generative models designed for
photorealistic, unified object- and scene-level neural rendering. Kaleido
operates on the principle that 3D can be regarded as a specialised sub-domain
of video, expressed purely as a sequence-to-sequence image synthesis task.
Through a systemic study of scaling sequence-to-sequence generative neural
rendering, we introduce key architectural innovations that enable our model to:
i) perform generative view synthesis without explicit 3D representations; ii)
generate any number of 6-DoF target views conditioned on any number of
reference views via a masked autoregressive framework; and iii) seamlessly
unify 3D and video modelling within a single decoder-only rectified flow
transformer. Within this unified framework, Kaleido leverages large-scale video
data for pre-training, which significantly improves spatial consistency and
reduces reliance on scarce, camera-labelled 3D datasets -- all without any
architectural modifications. Kaleido sets a new state-of-the-art on a range of
view synthesis benchmarks. Its zero-shot performance substantially outperforms
other generative methods in few-view settings, and, for the first time, matches
the quality of per-scene optimisation methods in many-view settings.
\\ ( https://arxiv.org/abs/2510.04236 ,  34051kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04243
Date: Sun, 5 Oct 2025 15:18:53 GMT   (1080kb)

Title: The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast):
  Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and
  Test-Time Adaptation
Authors: Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua
  Chen, Fan Wang, Jianguo Zhang
Categories: cs.CV
Comments: 11 pages, 3 figures
\\
  Accurate liver segmentation from contrast-enhanced MRI is essential for
diagnosis, treatment planning, and disease monitoring. However, it remains
challenging due to limited annotated data, heterogeneous enhancement protocols,
and significant domain shifts across scanners and institutions. Traditional
image-to-image translation frameworks have made great progress in domain
generalization, but their application is not straightforward. For example,
Pix2Pix requires image registration, and cycle-GAN cannot be integrated
seamlessly into segmentation pipelines. Meanwhile, these methods are originally
used to deal with cross-modality scenarios, and often introduce structural
distortions and suffer from unstable training, which may pose drawbacks in our
single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a
compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary
phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised
mean teacher scheme to exploit large amounts of unlabeled volumes. A domain
adaptation module, incorporating a randomized histogram-based style appearance
transfer function and a trainable contrast-aware network, enriches domain
diversity and mitigates cross-center variability. Furthermore, a continual
test-time adaptation strategy is employed to improve robustness during
inference. Extensive experiments demonstrate that our framework consistently
outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff
Distance while exhibiting strong generalization to unseen domains under
low-annotation conditions.
\\ ( https://arxiv.org/abs/2510.04243 ,  1080kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04245
Date: Sun, 5 Oct 2025 15:26:03 GMT   (2807kb)

Title: Concept-Based Masking: A Patch-Agnostic Defense Against Adversarial
  Patch Attacks
Authors: Ayushi Mehrotra, Derek Peng, Dipkamal Bhusal, Nidhi Rastogi
Categories: cs.CV cs.AI
Comments: neurips workshop
\\
  Adversarial patch attacks pose a practical threat to deep learning models by
forcing targeted misclassifications through localized perturbations, often
realized in the physical world. Existing defenses typically assume prior
knowledge of patch size or location, limiting their applicability. In this
work, we propose a patch-agnostic defense that leverages concept-based
explanations to identify and suppress the most influential concept activation
vectors, thereby neutralizing patch effects without explicit detection.
Evaluated on Imagenette with a ResNet-50, our method achieves higher robust and
clean accuracy than the state-of-the-art PatchCleanser, while maintaining
strong performance across varying patch sizes and locations. Our results
highlight the promise of combining interpretability with robustness and suggest
concept-driven defenses as a scalable strategy for securing machine learning
models against adversarial patch attacks.
\\ ( https://arxiv.org/abs/2510.04245 ,  2807kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04282
Date: Sun, 5 Oct 2025 16:52:12 GMT   (9990kb)

Title: Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual
  Place Recognition
Authors: Yu Kiu (Idan) Lau, Chao Chen, Ge Jin, Chen Feng
Categories: cs.CV
Comments: 8 pages, 6 figures
\\
  Sequential Visual Place Recognition (Seq-VPR) leverages transformers to
capture spatio-temporal features effectively; however, existing approaches
prioritize performance at the expense of flexibility and efficiency. In
practice, a transformer-based Seq-VPR model should be flexible to the number of
frames per sequence (seq-length), deliver fast inference, and have low memory
usage to meet real-time constraints. To our knowledge, no existing
transformer-based Seq-VPR method achieves both flexibility and efficiency. To
address this gap, we propose Adapt-STformer, a Seq-VPR method built around our
novel Recurrent Deformable Transformer Encoder (Recurrent-DTE), which uses an
iterative recurrent mechanism to fuse information from multiple sequential
frames. This design naturally supports variable seq-lengths, fast inference,
and low memory usage. Experiments on the Nordland, Oxford, and NuScenes
datasets show that Adapt-STformer boosts recall by up to 17% while reducing
sequence extraction time by 36% and lowering memory usage by 35% compared to
the second-best baseline.
\\ ( https://arxiv.org/abs/2510.04282 ,  9990kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04290
Date: Sun, 5 Oct 2025 17:02:01 GMT   (33247kb)

Title: ChronoEdit: Towards Temporal Reasoning for Image Editing and World
  Simulation
Authors: Jay Zhangjie Wu, Xuanchi Ren, Tianchang Shen, Tianshi Cao, Kai He,
  Yifan Lu, Ruiyuan Gao, Enze Xie, Shiyi Lan, Jose M. Alvarez, Jun Gao, Sanja
  Fidler, Zian Wang, Huan Ling
Categories: cs.CV
Comments: Project Page: https://research.nvidia.com/labs/toronto-ai/chronoedit
\\
  Recent advances in large generative models have significantly advanced image
editing and in-context image generation, yet a critical gap remains in ensuring
physical consistency, where edited objects must remain coherent. This
capability is especially vital for world simulation related tasks. In this
paper, we present ChronoEdit, a framework that reframes image editing as a
video generation problem. First, ChronoEdit treats the input and edited images
as the first and last frames of a video, allowing it to leverage large
pretrained video generative models that capture not only object appearance but
also the implicit physics of motion and interaction through learned temporal
consistency. Second, ChronoEdit introduces a temporal reasoning stage that
explicitly performs editing at inference time. Under this setting, the target
frame is jointly denoised with reasoning tokens to imagine a plausible editing
trajectory that constrains the solution space to physically viable
transformations. The reasoning tokens are then dropped after a few steps to
avoid the high computational cost of rendering a full video. To validate
ChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for
contexts that require physical consistency, and demonstrate that ChronoEdit
surpasses state-of-the-art baselines in both visual fidelity and physical
plausibility. Code and models for both the 14B and 2B variants of ChronoEdit
will be released on the project page:
https://research.nvidia.com/labs/toronto-ai/chronoedit
\\ ( https://arxiv.org/abs/2510.04290 ,  33247kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04312
Date: Sun, 5 Oct 2025 18:14:50 GMT   (4396kb)

Title: CARE-PD: A Multi-Site Anonymized Clinical Dataset for Parkinson's
  Disease Gait Assessment
Authors: Vida Adeli, Ivan Klabucar, Javad Rajabi, Benjamin Filtjens, Soroush
  Mehraban, Diwei Wang, Hyewon Seo, Trung-Hieu Hoang, Minh N. Do, Candice
  Muller, Claudia Oliveira, Daniel Boari Coelho, Pieter Ginis, Moran Gilat,
  Alice Nieuwboer, Joke Spildooren, Lucas Mckay, Hyeokhyen Kwon, Gari Clifford,
  Christine Esper, Stewart Factor, Imari Genias, Amirhossein Dadashzadeh, Leia
  Shum, Alan Whone, Majid Mirmehdi, Andrea Iaboni, Babak Taati
Categories: cs.CV
Comments: Accepted at the Thirty-Ninth Conference on Neural Information
  Processing Systems (NeurIPS 2025)
\\
  Objective gait assessment in Parkinson's Disease (PD) is limited by the
absence of large, diverse, and clinically annotated motion datasets. We
introduce CARE-PD, the largest publicly available archive of 3D mesh gait data
for PD, and the first multi-site collection spanning 9 cohorts from 8 clinical
centers. All recordings (RGB video or motion capture) are converted into
anonymized SMPL meshes via a harmonized preprocessing pipeline. CARE-PD
supports two key benchmarks: supervised clinical score prediction (estimating
Unified Parkinson's Disease Rating Scale, UPDRS, gait scores) and unsupervised
motion pretext tasks (2D-to-3D keypoint lifting and full-body 3D
reconstruction). Clinical prediction is evaluated under four generalization
protocols: within-dataset, cross-dataset, leave-one-dataset-out, and
multi-dataset in-domain adaptation. To assess clinical relevance, we compare
state-of-the-art motion encoders with a traditional gait-feature baseline,
finding that encoders consistently outperform handcrafted features. Pretraining
on CARE-PD reduces MPJPE (from 60.8mm to 7.5mm) and boosts PD severity macro-F1
by 17 percentage points, underscoring the value of clinically curated, diverse
training data. CARE-PD and all benchmark code are released for non-commercial
research at https://neurips2025.care-pd.ca/.
\\ ( https://arxiv.org/abs/2510.04312 ,  4396kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04315
Date: Sun, 5 Oct 2025 18:28:21 GMT   (45478kb)

Title: GenAR: Next-Scale Autoregressive Generation for Spatial Gene Expression
  Prediction
Authors: Jiarui Ouyang, Yihui Wang, Yihang Gao, Yingxue Xu, Shu Yang, Hao Chen
Categories: cs.CV
\\
  Spatial Transcriptomics (ST) offers spatially resolved gene expression but
remains costly. Predicting expression directly from widely available
Hematoxylin and Eosin (H&E) stained images presents a cost-effective
alternative. However, most computational approaches (i) predict each gene
independently, overlooking co-expression structure, and (ii) cast the task as
continuous regression despite expression being discrete counts. This mismatch
can yield biologically implausible outputs and complicate downstream analyses.
We introduce GenAR, a multi-scale autoregressive framework that refines
predictions from coarse to fine. GenAR clusters genes into hierarchical groups
to expose cross-gene dependencies, models expression as codebook-free discrete
token generation to directly predict raw counts, and conditions decoding on
fused histological and spatial embeddings. From an information-theoretic
perspective, the discrete formulation avoids log-induced biases and the
coarse-to-fine factorization aligns with a principled conditional
decomposition. Extensive experimental results on four Spatial Transcriptomics
datasets across different tissue types demonstrate that GenAR achieves
state-of-the-art performance, offering potential implications for precision
medicine and cost-effective molecular profiling. Code is publicly available at
https://github.com/oyjr/genar.
\\ ( https://arxiv.org/abs/2510.04315 ,  45478kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04333
Date: Sun, 5 Oct 2025 19:31:24 GMT   (8362kb)

Title: RAP: 3D Rasterization Augmented End-to-End Planning
Authors: Lan Feng, Yang Gao, Eloi Zablocki, Quanyi Li, Wuyang Li, Sichao Liu,
  Matthieu Cord, and Alexandre Alahi
Categories: cs.CV cs.RO
\\
  Imitation learning for end-to-end driving trains policies only on expert
demonstrations. Once deployed in a closed loop, such policies lack recovery
data: small mistakes cannot be corrected and quickly compound into failures. A
promising direction is to generate alternative viewpoints and trajectories
beyond the logged path. Prior work explores photorealistic digital twins via
neural rendering or game engines, but these methods are prohibitively slow and
costly, and thus mainly used for evaluation. In this work, we argue that
photorealism is unnecessary for training end-to-end planners. What matters is
semantic fidelity and scalability: driving depends on geometry and dynamics,
not textures or lighting. Motivated by this, we propose 3D Rasterization, which
replaces costly rendering with lightweight rasterization of annotated
primitives, enabling augmentations such as counterfactual recovery maneuvers
and cross-agent view synthesis. To transfer these synthetic views effectively
to real-world deployment, we introduce a Raster-to-Real feature-space alignment
that bridges the sim-to-real gap. Together, these components form Rasterization
Augmented Planning (RAP), a scalable data augmentation pipeline for planning.
RAP achieves state-of-the-art closed-loop robustness and long-tail
generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo
Open Dataset Vision-based E2E Driving, and Bench2Drive. Our results show that
lightweight rasterization with feature alignment suffices to scale E2E
training, offering a practical alternative to photorealistic rendering. Project
page: https://alan-lanfeng.github.io/RAP/.
\\ ( https://arxiv.org/abs/2510.04333 ,  8362kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04365
Date: Sun, 5 Oct 2025 21:19:33 GMT   (7274kb)

Title: Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise
  for Momentary Trajectory Prediction
Authors: Yuhao Luo, Yuang Zhang, Kehua Chen, Xinyu Zheng, Shucheng Zhang, Sikai
  Chen and Yinhai Wang
Categories: cs.CV
Comments: 13 pages, 7 figures, 3 tables
\\
  Accurate pedestrian trajectory prediction is crucial for ensuring safety and
efficiency in autonomous driving and human-robot interaction scenarios. Earlier
studies primarily utilized sufficient observational data to predict future
trajectories. However, in real-world scenarios, such as pedestrians suddenly
emerging from blind spots, sufficient observational data is often unavailable
(i.e. momentary trajectory), making accurate prediction challenging and
increasing the risk of traffic accidents. Therefore, advancing research on
pedestrian trajectory prediction under extreme scenarios is critical for
enhancing traffic safety. In this work, we propose a novel framework termed
Diffusion^2, tailored for momentary trajectory prediction. Diffusion^2 consists
of two sequentially connected diffusion models: one for backward prediction,
which generates unobserved historical trajectories, and the other for forward
prediction, which forecasts future trajectories. Given that the generated
unobserved historical trajectories may introduce additional noise, we propose a
dual-head parameterization mechanism to estimate their aleatoric uncertainty
and design a temporally adaptive noise module that dynamically modulates the
noise scale in the forward diffusion process. Empirically, Diffusion^2 sets a
new state-of-the-art in momentary trajectory prediction on ETH/UCY and Stanford
Drone datasets.
\\ ( https://arxiv.org/abs/2510.04365 ,  7274kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04390
Date: Sun, 5 Oct 2025 22:55:17 GMT   (5031kb)

Title: MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D
  World Simulator
Authors: Xuehai He, Shijie Zhou, Thivyanth Venkateswaran, Kaizhi Zheng, Ziyu
  Wan, Achuta Kadambi, Xin Eric Wang
Categories: cs.CV cs.AI cs.CL
\\
  World models that support controllable
  and editable spatiotemporal environments are valuable
  for robotics, enabling scalable training data, repro ducible evaluation, and
flexible task design. While
  recent text-to-video models generate realistic dynam ics, they are
constrained to 2D views and offer limited
  interaction. We introduce MorphoSim, a language guided framework that
generates 4D scenes with
  multi-view consistency and object-level controls. From
  natural language instructions, MorphoSim produces
  dynamic environments where objects can be directed,
  recolored, or removed, and scenes can be observed
  from arbitrary viewpoints. The framework integrates
  trajectory-guided generation with feature field dis tillation, allowing edits
to be applied interactively
  without full re-generation. Experiments show that Mor phoSim maintains high
scene fidelity while enabling
  controllability and editability. The code is available
  at https://github.com/eric-ai-lab/Morph4D.
\\ ( https://arxiv.org/abs/2510.04390 ,  5031kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04401
Date: Mon, 6 Oct 2025 00:11:24 GMT   (930kb)

Title: Your Vision-Language Model Can't Even Count to 20: Exposing the Failures
  of VLMs in Compositional Counting
Authors: Xuyang Guo, Zekai Huang, Zhenmei Shi, Zhao Song, Jiahao Zhang
Categories: cs.CV cs.AI
\\
  Vision-Language Models (VLMs) have become a central focus of today's AI
community, owing to their impressive abilities gained from training on
large-scale vision-language data from the Web. These models have demonstrated
strong performance across diverse tasks, including image understanding, video
understanding, complex visual reasoning, and embodied AI. Despite these
noteworthy successes, a fundamental question remains: Can VLMs count objects
correctly? In this paper, we introduce a simple yet effective benchmark,
VLMCountBench, designed under a minimalist setting with only basic geometric
shapes (e.g., triangles, circles) and their compositions, focusing exclusively
on counting tasks without interference from other factors. We adopt strict
independent variable control and systematically study the effects of simple
properties such as color, size, and prompt refinement in a controlled ablation.
Our empirical results reveal that while VLMs can count reliably when only one
shape type is present, they exhibit substantial failures when multiple shape
types are combined (i.e., compositional counting). This highlights a
fundamental empirical limitation of current VLMs and motivates important
directions for future research.
\\ ( https://arxiv.org/abs/2510.04401 ,  930kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04410
Date: Mon, 6 Oct 2025 00:53:50 GMT   (73638kb)

Title: CodeFormer++: Blind Face Restoration Using Deformable Registration and
  Deep Metric Learning
Authors: Venkata Bharath Reddy Reddem, Akshay P Sarashetti, Ranjith Merugu,
  Amit Satish Unde
Categories: cs.CV
\\
  Blind face restoration (BFR) has attracted increasing attention with the rise
of generative methods. Most existing approaches integrate generative priors
into the restoration pro- cess, aiming to jointly address facial detail
generation and identity preservation. However, these methods often suffer from
a trade-off between visual quality and identity fidelity, leading to either
identity distortion or suboptimal degradation removal. In this paper, we
present CodeFormer++, a novel framework that maximizes the utility of
generative priors for high-quality face restoration while preserving identity.
We decompose BFR into three sub-tasks: (i) identity- preserving face
restoration, (ii) high-quality face generation, and (iii) dynamic fusion of
identity features with realistic texture details. Our method makes three key
contributions: (1) a learning-based deformable face registration module that
semantically aligns generated and restored faces; (2) a texture guided
restoration network to dynamically extract and transfer the texture of
generated face to boost the quality of identity-preserving restored face; and
(3) the integration of deep metric learning for BFR with the generation of
informative positive and hard negative samples to better fuse identity-
preserving and generative features. Extensive experiments on real-world and
synthetic datasets demonstrate that, the pro- posed CodeFormer++ achieves
superior performance in terms of both visual fidelity and identity consistency.
\\ ( https://arxiv.org/abs/2510.04410 ,  73638kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04428
Date: Mon, 6 Oct 2025 01:51:13 GMT   (11986kb)

Title: A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame
  Selection For Video Question Answering
Authors: Yuanhao Zou, Shengji Jin, Andong Deng, Youpeng Zhao, Jun Wang, Chen
  Chen
Categories: cs.CV
\\
  Effectively applying Vision-Language Models (VLMs) to Video Question
Answering (VideoQA) hinges on selecting a concise yet comprehensive set of
frames, as processing entire videos is computationally infeasible. However,
current frame selection methods face a critical trade-off: approaches relying
on lightweight similarity models, such as CLIP, often fail to capture the
nuances of complex queries, resulting in inaccurate similarity scores that
cannot reflect the authentic query-frame relevance, which further undermines
frame selection. Meanwhile, methods that leverage a VLM for deeper analysis
achieve higher accuracy but incur prohibitive computational costs. To address
these limitations, we propose A.I.R., a training-free approach for Adaptive,
Iterative, and Reasoning-based frame selection. We leverage a powerful VLM to
perform deep, semantic analysis on complex queries, and this analysis is
deployed within a cost-effective iterative loop that processes only a small
batch of the most high-potential frames at a time. Extensive experiments on
various VideoQA benchmarks demonstrate that our approach outperforms existing
frame selection methods, significantly boosts the performance of the foundation
VLM, and achieves substantial gains in computational efficiency over other
VLM-based techniques.
\\ ( https://arxiv.org/abs/2510.04428 ,  11986kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04450
Date: Mon, 6 Oct 2025 02:48:13 GMT   (26384kb)

Title: REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer
  Consistency Regularization
Authors: Qiyuan He, Yicong Li, Haotian Ye, Jinghao Wang, Xinyao Liao, Pheng-Ann
  Heng, Stefano Ermon, James Zou, Angela Yao
Categories: cs.CV
Comments: 27 pages, 23 figures, 5 tables
\\
  Visual autoregressive (AR) generation offers a promising path toward unifying
vision and language models, yet its performance remains suboptimal against
diffusion models. Prior work often attributes this gap to tokenizer limitations
and rasterization ordering. In this work, we identify a core bottleneck from
the perspective of generator-tokenizer inconsistency, i.e., the AR-generated
tokens may not be well-decoded by the tokenizer. To address this, we propose
reAR, a simple training strategy introducing a token-wise regularization
objective: when predicting the next token, the causal transformer is also
trained to recover the visual embedding of the current token and predict the
embedding of the target token under a noisy context. It requires no changes to
the tokenizer, generation order, inference pipeline, or external models.
Despite its simplicity, reAR substantially improves performance. On ImageNet,
it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard
rasterization-based tokenizer. When applied to advanced tokenizers, it achieves
a gFID of 1.42 with only 177M parameters, matching the performance with larger
state-of-the-art diffusion models (675M).
\\ ( https://arxiv.org/abs/2510.04450 ,  26384kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04472
Date: Mon, 6 Oct 2025 04:06:40 GMT   (16813kb)

Title: SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object
  Detection
Authors: Baber Jan, Saeed Anwar, Aiman H. El-Maleh, Abdul Jabbar Siddiqui,
  Abdul Bais
Categories: cs.CV cs.AI cs.LG eess.IV
\\
  Camouflaged object detection segments objects with intrinsic similarity and
edge disruption. Current detection methods rely on accumulated complex
components. Each approach adds components such as boundary modules, attention
mechanisms, and multi-scale processors independently. This accumulation creates
a computational burden without proportional gains. To manage this complexity,
they process at reduced resolutions, eliminating fine details essential for
camouflage. We present SPEGNet, addressing fragmentation through a unified
design. The architecture integrates multi-scale features via channel
calibration and spatial enhancement. Boundaries emerge directly from
context-rich representations, maintaining semantic-spatial alignment.
Progressive refinement implements scale-adaptive edge modulation with peak
influence at intermediate resolutions. This design strikes a balance between
boundary precision and regional consistency. SPEGNet achieves 0.887 $S_\alpha$
on CAMO, 0.890 on COD10K, and 0.895 on NC4K, with real-time inference speed.
Our approach excels across scales, from tiny, intricate objects to large,
pattern-similar ones, while handling occlusion and ambiguous boundaries. Code,
model weights, and results are available on
\href{https://github.com/Baber-Jan/SPEGNet}{https://github.com/Baber-Jan/SPEGNet}.
\\ ( https://arxiv.org/abs/2510.04472 ,  16813kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04477
Date: Mon, 6 Oct 2025 04:26:39 GMT   (2541kb)

Title: MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical
  Vision-Language Models
Authors: Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang
Categories: cs.CV cs.AI cs.CL cs.LG
\\
  Bridging clinical diagnostic reasoning with AI remains a central challenge in
medical imaging. We introduce MedCLM, an automated pipeline that converts
detection datasets into large-scale medical visual question answering (VQA)
data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ
segmentation and structured rationales. These contextual signals enable medical
vision-language models to generate question-answer pairs with step-by-step
reasoning. To utilize this data effectively, we propose an Integrated
CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes
for visual grounding, a Medium stage that encourages implicit localization, and
a Hard stage for weakly supervised reasoning. Experimental results demonstrate
that MedCLM attains state-of-the-art performance on several medical VQA
benchmarks, providing a scalable framework for developing clinically aligned
medical vision-language models.
\\ ( https://arxiv.org/abs/2510.04477 ,  2541kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04479
Date: Mon, 6 Oct 2025 04:28:39 GMT   (5622kb)

Title: VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery
Authors: Nonghai Zhang, Zeyu Zhang, Jiazi Wang, Yang Zhao, Hao Tang
Categories: cs.CV
\\
  Vision-Language Models (VLMs) have achieved significant progress in
multimodal understanding tasks, demonstrating strong capabilities particularly
in general tasks such as image captioning and visual reasoning. However, when
dealing with specialized cultural heritage domains like 3D vase artifacts,
existing models face severe data scarcity issues and insufficient domain
knowledge limitations. Due to the lack of targeted training data, current VLMs
struggle to effectively handle such culturally significant specialized tasks.
To address these challenges, we propose the VaseVQA-3D dataset, which serves as
the first 3D visual question answering dataset for ancient Greek pottery
analysis, collecting 664 ancient Greek vase 3D models with corresponding
question-answer data and establishing a complete data construction pipeline. We
further develop the VaseVLM model, enhancing model performance in vase artifact
analysis through domain-adaptive training. Experimental results validate the
effectiveness of our approach, where we improve by 12.8% on R@1 metrics and by
6.6% on lexical similarity compared with previous state-of-the-art on the
VaseVQA-3D dataset, significantly improving the recognition and understanding
of 3D vase artifacts, providing new technical pathways for digital heritage
preservation research.
\\ ( https://arxiv.org/abs/2510.04479 ,  5622kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04483
Date: Mon, 6 Oct 2025 04:46:42 GMT   (8013kb)

Title: TBStar-Edit: From Image Editing Pattern Shifting to Consistency
  Enhancement
Authors: Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, XuBin Li, Tiezheng Ge
Categories: cs.CV
\\
  Recent advances in image generation and editing technologies have enabled
state-of-the-art models to achieve impressive results in general domains.
However, when applied to e-commerce scenarios, these general models often
encounter consistency limitations. To address this challenge, we introduce
TBStar-Edit, an new image editing model tailored for the e-commerce domain.
Through rigorous data engineering, model architecture design and training
strategy, TBStar-Edit achieves precise and high-fidelity image editing while
maintaining the integrity of product appearance and layout. Specifically, for
data engineering, we establish a comprehensive data construction pipeline,
encompassing data collection, construction, filtering, and augmentation, to
acquire high-quality, instruction-following, and strongly consistent editing
data to support model training. For model architecture design, we design a
hierarchical model framework consisting of a base model, pattern shifting
modules, and consistency enhancement modules. For model training, we adopt a
two-stage training strategy to enhance the consistency preservation: first
stage for editing pattern shifting, and second stage for consistency
enhancement. Each stage involves training different modules with separate
datasets. Finally, we conduct extensive evaluations of TBStar-Edit on a
self-proposed e-commerce benchmark, and the results demonstrate that
TBStar-Edit outperforms existing general-domain editing models in both
objective metrics (VIE Score) and subjective user preference.
\\ ( https://arxiv.org/abs/2510.04483 ,  8013kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04504
Date: Mon, 6 Oct 2025 05:45:56 GMT   (3394kb)

Title: Asynchronous Denoising Diffusion Models for Aligning Text-to-Image
  Generation
Authors: Zijing Hu, Yunze Tong, Fengda Zhang, Junkun Yuan, Jun Xiao, Kun Kuang
Categories: cs.CV
Comments: 22 pages, 11 figures, 5 tables
\\
  Diffusion models have achieved impressive results in generating high-quality
images. Yet, they often struggle to faithfully align the generated images with
the input prompts. This limitation arises from synchronous denoising, where all
pixels simultaneously evolve from random noise to clear images. As a result,
during generation, the prompt-related regions can only reference the unrelated
regions at the same noise level, failing to obtain clear context and ultimately
impairing text-to-image alignment. To address this issue, we propose
asynchronous diffusion models -- a novel framework that allocates distinct
timesteps to different pixels and reformulates the pixel-wise denoising
process. By dynamically modulating the timestep schedules of individual pixels,
prompt-related regions are denoised more gradually than unrelated regions,
thereby allowing them to leverage clearer inter-pixel context. Consequently,
these prompt-related regions achieve better alignment in the final images.
Extensive experiments demonstrate that our asynchronous diffusion models can
significantly improve text-to-image alignment across diverse prompts. The code
repository for this work is available at https://github.com/hu-zijing/AsynDM.
\\ ( https://arxiv.org/abs/2510.04504 ,  3394kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04533
Date: Mon, 6 Oct 2025 06:53:29 GMT   (46636kb)

Title: TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion
  Sampling
Authors: Hyunmin Cho, Donghoon Ahn, Susung Hong, Jee Eun Kim, Seungryong Kim,
  Kyong Hwan Jin
Categories: cs.CV
Comments: 16 pages, 9 figures, 5 tables
\\
  Recent diffusion models achieve the state-of-the-art performance in image
generation, but often suffer from semantic inconsistencies or hallucinations.
While various inference-time guidance methods can enhance generation, they
often operate indirectly by relying on external signals or architectural
modifications, which introduces additional computational overhead. In this
paper, we propose Tangential Amplifying Guidance (TAG), a more efficient and
direct guidance method that operates solely on trajectory signals without
modifying the underlying diffusion model. TAG leverages an intermediate sample
as a projection basis and amplifies the tangential components of the estimated
scores with respect to this basis to correct the sampling trajectory. We
formalize this guidance process by leveraging a first-order Taylor expansion,
which demonstrates that amplifying the tangential component steers the state
toward higher-probability regions, thereby reducing inconsistencies and
enhancing sample quality. TAG is a plug-and-play, architecture-agnostic module
that improves diffusion sampling fidelity with minimal computational addition,
offering a new perspective on diffusion guidance.
\\ ( https://arxiv.org/abs/2510.04533 ,  46636kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04564
Date: Mon, 6 Oct 2025 08:00:59 GMT   (6335kb)

Title: Conditional Representation Learning for Customized Tasks
Authors: Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng
Categories: cs.CV
\\
  Conventional representation learning methods learn a universal representation
that primarily captures dominant semantics, which may not always align with
customized downstream tasks. For instance, in animal habitat analysis,
researchers prioritize scene-related features, whereas universal embeddings
emphasize categorical semantics, leading to suboptimal results. As a solution,
existing approaches resort to supervised fine-tuning, which however incurs high
computational and annotation costs. In this paper, we propose Conditional
Representation Learning (CRL), aiming to extract representations tailored to
arbitrary user-specified criteria. Specifically, we reveal that the semantics
of a space are determined by its basis, thereby enabling a set of descriptive
words to approximate the basis for a customized feature space. Building upon
this insight, given a user-specified criterion, CRL first employs a large
language model (LLM) to generate descriptive texts to construct the semantic
basis, then projects the image representation into this conditional feature
space leveraging a vision-language model (VLM). The conditional representation
better captures semantics for the specific criterion, which could be utilized
for multiple customized tasks. Extensive experiments on classification and
retrieval tasks demonstrate the superiority and generality of the proposed CRL.
The code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.
\\ ( https://arxiv.org/abs/2510.04564 ,  6335kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04587
Date: Mon, 6 Oct 2025 08:44:04 GMT   (15029kb)

Title: Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole
  Slide Image Diagnosis Behavior
Authors: Sheng Wang, Ruiming Wu, Charles Herndon, Yihang Liu, Shunsuke Koga,
  Jeanne Shen, Zhi Huang
Categories: cs.CV
\\
  Diagnosing a whole-slide image is an interactive, multi-stage process
involving changes in magnification and movement between fields. Although recent
pathology foundation models are strong, practical agentic systems that decide
what field to examine next, adjust magnification, and deliver explainable
diagnoses are still lacking. The blocker is data: scalable, clinically aligned
supervision of expert viewing behavior that is tacit and experience-based, not
written in textbooks or online, and therefore absent from large language model
training. We introduce the AI Session Recorder, which works with standard WSI
viewers to unobtrusively record routine navigation and convert the viewer logs
into standardized behavioral commands (inspect or peek at discrete
magnifications) and bounding boxes. A lightweight human-in-the-loop review
turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired
"where to look" and "why it matters" supervision produced at roughly six times
lower labeling time. Using this behavioral data, we build Pathologist-o3, a
two-stage agent that first proposes regions of interest and then performs
behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection,
it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the
state-of-the-art OpenAI o3 model and generalizing across backbones. To our
knowledge, this constitutes one of the first behavior-grounded agentic systems
in pathology. Turning everyday viewer logs into scalable, expert-validated
supervision, our framework makes agentic pathology practical and establishes a
path to human-aligned, upgradeable clinical AI.
\\ ( https://arxiv.org/abs/2510.04587 ,  15029kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04628
Date: Mon, 6 Oct 2025 09:33:35 GMT   (9785kb)

Title: A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote
  Sensing Classification
Authors: Hao Liu, Yunhao Gao, Wei Li, Mingyang Zhang, Maoguo Gong, Lorenzo
  Bruzzone
Categories: cs.CV
\\
  Deep learning-based methods have achieved significant success in remote
sensing Earth observation data analysis. Numerous feature fusion techniques
address multimodal remote sensing image classification by integrating global
and local features. However, these techniques often struggle to extract
structural and detail features from heterogeneous and redundant multimodal
images. With the goal of introducing frequency domain learning to model key and
sparse detail features, this paper introduces the spatial-spectral-frequency
interaction network (S$^2$Fin), which integrates pairwise fusion modules across
the spatial, spectral, and frequency domains. Specifically, we propose a
high-frequency sparse enhancement transformer that employs sparse
spatial-spectral attention to optimize the parameters of the high-frequency
filter. Subsequently, a two-level spatial-frequency fusion strategy is
introduced, comprising an adaptive frequency channel module that fuses
low-frequency structures with enhanced high-frequency details, and a
high-frequency resonance mask that emphasizes sharp edges via phase similarity.
In addition, a spatial-spectral attention fusion module further enhances
feature extraction at intermediate layers of the network. Experiments on four
benchmark multimodal datasets with limited labeled data demonstrate that
S$^2$Fin performs superior classification, outperforming state-of-the-art
methods. The code is available at https://github.com/HaoLiu-XDU/SSFin.
\\ ( https://arxiv.org/abs/2510.04628 ,  9785kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04630
Date: Mon, 6 Oct 2025 09:35:57 GMT   (3437kb)

Title: SFANet: Spatial-Frequency Attention Network for Deepfake Detection
Authors: Vrushank Ahire, Aniruddh Muley, Shivam Zample, Siddharth Verma, Pranav
  Menon, Surbhi Madan, Abhinav Dhall
Categories: cs.CV cs.AI cs.MM
Journal-ref: IEEE SPS Signal Processing Cup at ICASSP 2025
\\
  Detecting manipulated media has now become a pressing issue with the recent
rise of deepfakes. Most existing approaches fail to generalize across diverse
datasets and generation techniques. We thus propose a novel ensemble framework,
combining the strengths of transformer-based architectures, such as Swin
Transformers and ViTs, and texture-based methods, to achieve better detection
accuracy and robustness. Our method introduces innovative data-splitting,
sequential training, frequency splitting, patch-based attention, and face
segmentation techniques to handle dataset imbalances, enhance high-impact
regions (e.g., eyes and mouth), and improve generalization. Our model achieves
state-of-the-art performance when tested on the DFWild-Cup dataset, a diverse
subset of eight deepfake datasets. The ensemble benefits from the
complementarity of these approaches, with transformers excelling in global
feature extraction and texturebased methods providing interpretability. This
work demonstrates that hybrid models can effectively address the evolving
challenges of deepfake detection, offering a robust solution for real-world
applications.
\\ ( https://arxiv.org/abs/2510.04630 ,  3437kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04645
Date: Mon, 6 Oct 2025 09:46:17 GMT   (563kb)

Title: Do Superpixel Segmentation Methods Influence Deforestation Image
  Classification?
Authors: Hugo Resende and Fabio A. Faria and Eduardo B. Neto and Isabela
  Borlido and Victor Sundermann and Silvio Jamil F. Guimar\~aes and \'Alvaro L.
  Fazenda
Categories: cs.CV
Comments: 15 pages, 3 figures, paper accepted to present at CIARP 2025
\\
  Image segmentation is a crucial step in various visual applications,
including environmental monitoring through remote sensing. In the context of
the ForestEyes project, which combines citizen science and machine learning to
detect deforestation in tropical forests, image segments are used for labeling
by volunteers and subsequent model training. Traditionally, the Simple Linear
Iterative Clustering (SLIC) algorithm is adopted as the segmentation method.
However, recent studies have indicated that other superpixel-based methods
outperform SLIC in remote sensing image segmentation, and might suggest that
they are more suitable for the task of detecting deforested areas. In this
sense, this study investigated the impact of the four best segmentation
methods, together with SLIC, on the training of classifiers for the target
application. Initially, the results showed little variation in performance
among segmentation methods, even when selecting the top five classifiers using
the PyCaret AutoML library. However, by applying a classifier fusion approach
(ensemble of classifiers), noticeable improvements in balanced accuracy were
observed, highlighting the importance of both the choice of segmentation method
and the combination of machine learning-based models for deforestation
detection tasks.
\\ ( https://arxiv.org/abs/2510.04645 ,  563kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04648
Date: Mon, 6 Oct 2025 09:52:18 GMT   (6482kb)

Title: EduPersona: Benchmarking Subjective Ability Boundaries of Virtual
  Student Agents
Authors: Buyuan Zhu and Shiyu Hu and Yiping Ma and Yuanming Zhang and Kang Hao
  Cheong
Categories: cs.CV cs.CY
Comments: Preprint, Under review
\\
  As large language models are increasingly integrated into education, virtual
student agents are becoming vital for classroom simulation and teacher
training. Yet their classroom-oriented subjective abilities remain largely
unassessed, limiting understanding of model boundaries and hindering
trustworthy deployment. We present EduPersona, a large-scale benchmark spanning
two languages, three subjects, and ten persona types based on the Big Five
theory. The dataset contains 1,308 authentic classroom dialogue rounds,
corresponding to 12,814 teacher-student Q&A turns, and is further expanded
through persona stylization into roughly 10 times larger scale (128k turns),
providing a solid foundation for evaluation. Building on this resource, we
decompose hard-to-quantify subjective performance into three progressive tasks:
TASK1 basic coherence (whether behavior, emotion, expression, and voice align
with classroom context), TASK2 student realism, and TASK3 long-term persona
consistency, thereby establishing an evaluation framework grounded in
educational theory and research value. We conduct systematic experiments on
three representative LLMs, comparing their original versions with ten
persona-fine-tuned variants trained on EduPersona. Results show consistent and
significant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%,
and TASK3 +14.9%. These improvements highlight the dataset's effectiveness and
research value, while also revealing the heterogeneous difficulty of persona
modeling. In summary, EduPersona delivers the first classroom benchmark
centered on subjective abilities, establishes a decoupled and verifiable
research paradigm, and we will open-source both the dataset and the framework
to support the broader research community in advancing trustworthy and
human-like AI for education.
\\ ( https://arxiv.org/abs/2510.04648 ,  6482kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04654
Date: Mon, 6 Oct 2025 09:58:43 GMT   (9316kb)

Title: MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture
  of Movement Experts
Authors: Andy C\v{a}trun\v{a}, Adrian Cosma, Emilian R\v{a}doi
Categories: cs.CV
Comments: 4 Figures, 4 Tables
\\
  Gait encodes rich biometric and behavioural information, yet leveraging the
manner of walking to infer psychological traits remains a challenging and
underexplored problem. We introduce a hierarchical Multi-Stage Mixture of
Movement Experts (MoME) architecture for multi-task prediction of psychological
attributes from gait sequences represented as 2D poses. MoME processes the
walking cycle in four stages of movement complexity, employing lightweight
expert models to extract spatio-temporal features and task-specific gating
modules to adaptively weight experts across traits and stages. Evaluated on the
PsyMo benchmark covering 17 psychological traits, our method outperforms
state-of-the-art gait analysis models, achieving a 37.47% weighted F1 score at
the run level and 44.6% at the subject level. Our experiments show that
integrating auxiliary tasks such as identity recognition, gender prediction,
and BMI estimation further improves psychological trait estimation. Our
findings demonstrate the viability of multi-task gait-based learning for
psychological trait estimation and provide a foundation for future research on
movement-informed psychological inference.
\\ ( https://arxiv.org/abs/2510.04654 ,  9316kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04668
Date: Mon, 6 Oct 2025 10:22:46 GMT   (46983kb)

Title: ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion
  Models via Token-wise Adaptation and Attention Disentanglement
Authors: Habin Lim, Yeongseob Won, Juwon Seo and Gyeong-Moon Park
Categories: cs.CV
Comments: 14 pages, 13 figures, to be published in ICCV 2025
\\
  In recent years, multi-concept personalization for text-to-image (T2I)
diffusion models to represent several subjects in an image has gained much more
attention. The main challenge of this task is "concept mixing", where multiple
learned concepts interfere or blend undesirably in the output image. To address
this issue, in this paper, we present ConceptSplit, a novel framework to split
the individual concepts through training and inference. Our framework comprises
two key components. First, we introduce Token-wise Value Adaptation (ToVA), a
merging-free training method that focuses exclusively on adapting the value
projection in cross-attention. Based on our empirical analysis, we found that
modifying the key projection, a common approach in existing methods, can
disrupt the attention mechanism and lead to concept mixing. Second, we propose
Latent Optimization for Disentangled Attention (LODA), which alleviates
attention entanglement during inference by optimizing the input latent. Through
extensive qualitative and quantitative experiments, we demonstrate that
ConceptSplit achieves robust multi-concept personalization, mitigating
unintended concept interference. Code is available at
https://github.com/KU-VGI/ConceptSplit
\\ ( https://arxiv.org/abs/2510.04668 ,  46983kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04705
Date: Mon, 6 Oct 2025 11:19:05 GMT   (2559kb)

Title: Label-Efficient Cross-Modality Generalization for Liver Segmentation in
  Multi-Phase MRI
Authors: Quang-Khai Bui-Tran, Minh-Toan Dinh, Thanh-Huy Nguyen, Ba-Thinh Lam,
  Mai-Anh Vu, and Ulas Bagci
Categories: cs.CV
Comments: 11 pages, 3 figures
\\
  Accurate liver segmentation in multi-phase MRI is vital for liver fibrosis
assessment, yet labeled data is often scarce and unevenly distributed across
imaging modalities and vendor systems. We propose a label-efficient
segmentation approach that promotes cross-modality generalization under
real-world conditions, where GED4 hepatobiliary-phase annotations are limited,
non-contrast sequences (T1WI, T2WI, DWI) are unlabeled, and spatial
misalignment and missing phases are common. Our method integrates a
foundation-scale 3D segmentation backbone adapted via fine-tuning, co-training
with cross pseudo supervision to leverage unlabeled volumes, and a standardized
preprocessing pipeline. Without requiring spatial registration, the model
learns to generalize across MRI phases and vendors, demonstrating robust
segmentation performance in both labeled and unlabeled domains. Our results
exhibit the effectiveness of our proposed label-efficient baseline for liver
segmentation in multi-phase, multi-vendor MRI and highlight the potential of
combining foundation model adaptation with co-training for real-world clinical
imaging tasks.
\\ ( https://arxiv.org/abs/2510.04705 ,  2559kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04706
Date: Mon, 6 Oct 2025 11:20:56 GMT   (12460kb)

Title: ID-Consistent, Precise Expression Generation with Blendshape-Guided
  Diffusion
Authors: Foivos Paraperas Papantoniou, Stefanos Zafeiriou
Categories: cs.CV
Comments: ICCVW 2025, Code: https://github.com/foivospar/Arc2Face
\\
  Human-centric generative models designed for AI-driven storytelling must
bring together two core capabilities: identity consistency and precise control
over human performance. While recent diffusion-based approaches have made
significant progress in maintaining facial identity, achieving fine-grained
expression control without compromising identity remains challenging. In this
work, we present a diffusion-based framework that faithfully reimagines any
subject under any particular facial expression. Building on an ID-consistent
face foundation model, we adopt a compositional design featuring an expression
cross-attention module guided by FLAME blendshape parameters for explicit
control. Trained on a diverse mixture of image and video data rich in
expressive variation, our adapter generalizes beyond basic emotions to subtle
micro-expressions and expressive transitions, overlooked by prior works. In
addition, a pluggable Reference Adapter enables expression editing in real
images by transferring the appearance from a reference frame during synthesis.
Extensive quantitative and qualitative evaluations show that our model
outperforms existing methods in tailored and identity-consistent expression
generation. Code and models can be found at
https://github.com/foivospar/Arc2Face.
\\ ( https://arxiv.org/abs/2510.04706 ,  12460kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04712
Date: Mon, 6 Oct 2025 11:30:40 GMT   (21216kb)

Title: ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion
  Model
Authors: Luo Cheng, Song Siyang, Yan Siyuan, Yu Zhen, Ge Zongyuan
Categories: cs.CV cs.HC cs.MM
Comments: Accepted to ACM Multimedia
\\
  The automatic generation of diverse and human-like facial reactions in dyadic
dialogue remains a critical challenge for human-computer interaction systems.
Existing methods fail to model the stochasticity and dynamics inherent in real
human reactions. To address this, we propose ReactDiff, a novel temporal
diffusion framework for generating diverse facial reactions that are
appropriate for responding to any given dialogue context. Our key insight is
that plausible human reactions demonstrate smoothness, and coherence over time,
and conform to constraints imposed by human facial anatomy. To achieve this,
ReactDiff incorporates two vital priors (spatio-temporal facial kinematics)
into the diffusion process: i) temporal facial behavioral kinematics and ii)
facial action unit dependencies. These two constraints guide the model toward
realistic human reaction manifolds, avoiding visually unrealistic jitters,
unstable transitions, unnatural expressions, and other artifacts. Extensive
experiments on the REACT2024 dataset demonstrate that our approach not only
achieves state-of-the-art reaction quality but also excels in diversity and
reaction appropriateness.
\\ ( https://arxiv.org/abs/2510.04712 ,  21216kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04714
Date: Mon, 6 Oct 2025 11:33:09 GMT   (4020kb)

Title: Object-Centric Representation Learning for Enhanced 3D Scene Graph
  Prediction
Authors: KunHo Heo, GiHyun Kim, SuYeon Kim, MyeongAh Cho
Categories: cs.CV
Comments: Accepted by NeurIPS 2025. Code:
  https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes
\\
  3D Semantic Scene Graph Prediction aims to detect objects and their semantic
relationships in 3D scenes, and has emerged as a crucial technology for
robotics and AR/VR applications. While previous research has addressed dataset
limitations and explored various approaches including Open-Vocabulary settings,
they frequently fail to optimize the representational capacity of object and
relationship features, showing excessive reliance on Graph Neural Networks
despite insufficient discriminative capability. In this work, we demonstrate
through extensive analysis that the quality of object features plays a critical
role in determining overall scene graph accuracy. To address this challenge, we
design a highly discriminative object feature encoder and employ a contrastive
pretraining strategy that decouples object representation learning from the
scene graph prediction. This design not only enhances object classification
accuracy but also yields direct improvements in relationship prediction.
Notably, when plugging in our pretrained encoder into existing frameworks, we
observe substantial performance improvements across all evaluation metrics.
Additionally, whereas existing approaches have not fully exploited the
integration of relationship information, we effectively combine both geometric
and semantic features to achieve superior relationship prediction.
Comprehensive experiments on the 3DSSG dataset demonstrate that our approach
significantly outperforms previous state-of-the-art methods. Our code is
publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.
\\ ( https://arxiv.org/abs/2510.04714 ,  4020kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04723
Date: Mon, 6 Oct 2025 11:43:34 GMT   (1110kb)

Title: Benchmark on Monocular Metric Depth Estimation in Wildlife Setting
Authors: Niccol\`o Niccoli and Lorenzo Seidenari and Ilaria Greco and Francesco
  Rovero
Categories: cs.CV
\\
  Camera traps are widely used for wildlife monitoring, but extracting accurate
distance measurements from monocular images remains challenging due to the lack
of depth information. While monocular depth estimation (MDE) methods have
advanced significantly, their performance in natural wildlife environments has
not been systematically evaluated. This work introduces the first benchmark for
monocular metric depth estimation in wildlife monitoring conditions. We
evaluate four state-of-the-art MDE methods (Depth Anything V2, ML Depth Pro,
ZoeDepth, and Metric3D) alongside a geometric baseline on 93 camera trap images
with ground truth distances obtained using calibrated ChARUCO patterns. Our
results demonstrate that Depth Anything V2 achieves the best overall
performance with a mean absolute error of 0.454m and correlation of 0.962,
while methods like ZoeDepth show significant degradation in outdoor natural
environments (MAE: 3.087m). We find that median-based depth extraction
consistently outperforms mean-based approaches across all deep learning
methods. Additionally, we analyze computational efficiency, with ZoeDepth being
fastest (0.17s per image) but least accurate, while Depth Anything V2 provides
an optimal balance of accuracy and speed (0.22s per image). This benchmark
establishes performance baselines for wildlife applications and provides
practical guidance for implementing depth estimation in conservation monitoring
systems.
\\ ( https://arxiv.org/abs/2510.04723 ,  1110kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04739
Date: Mon, 6 Oct 2025 12:11:53 GMT   (5854kb)

Title: ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics
  in Sports Broadcasts
Authors: Mehdi Houshmand Sarkhoosh, Fr{\o}y {\O}ye, Henrik Nestor S{\o}rlie,
  Nam Hoang Vu, Dag Johansen, Cise Midoglu, Tomas Kupka, P{\aa}l Halvorsen
Categories: cs.CV cs.MM
Comments: This work has been submitted to the IEEE for possible publication
\\
  Quantifying sponsor visibility in sports broadcasts is a critical marketing
task traditionally hindered by manual, subjective, and unscalable analysis
methods. While automated systems offer an alternative, their reliance on
axis-aligned Horizontal Bounding Box (HBB) leads to inaccurate exposuremetrics
when logos appear rotated or skewed due to dynamic camera angles and
perspective distortions. This paper introduces ExposureEngine, an end-to-end
system designed for accurate, rotation-aware sponsor visibility analytics in
sports broadcasts, demonstrated in a soccer case study. Our approach predicts
Oriented Bounding Box (OBB) to provide a geometrically precise fit to each logo
regardless of the orientation on-screen. To train and evaluate our detector, we
developed a new dataset comprising 1,103 frames from Swedish elite soccer,
featuring 670 unique sponsor logos annotated with OBBs. Our model achieves a
mean Average Precision (mAP@0.5) of 0.859, with a precision of 0.96 and recall
of 0.87, demonstrating robust performance in localizing logos under diverse
broadcast conditions. The system integrates these detections into an analytical
pipeline that calculates precise visibility metrics, such as exposure duration
and on-screen coverage. Furthermore, we incorporate a language-driven agentic
layer, enabling users to generate reports, summaries, and media content through
natural language queries. The complete system, including the dataset and the
analytics dashboard, provides a comprehensive solution for auditable and
interpretable sponsor measurement in sports media. An overview of the
ExposureEngine is available online: https://youtu.be/tRw6OBISuW4 .
\\ ( https://arxiv.org/abs/2510.04739 ,  5854kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04741
Date: Mon, 6 Oct 2025 12:13:56 GMT   (5994kb)

Title: Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small
  Target Detection
Authors: Alina Ciocarlan, Sylvie Le H\'egarat-Mascle, Sidonie Lefebvre
Categories: cs.CV
\\
  Infrared Small Target Detection (IRSTD) is a challenging task in defense
applications, where complex backgrounds and tiny target sizes often result in
numerous false alarms using conventional object detectors. To overcome this
limitation, we propose Anomaly-Aware YOLO (AA-YOLO), which integrates a
statistical anomaly detection test into its detection head. By treating small
targets as unexpected patterns against the background, AA-YOLO effectively
controls the false alarm rate. Our approach not only achieves competitive
performance on several IRSTD benchmarks, but also demonstrates remarkable
robustness in scenarios with limited training data, noise, and domain shifts.
Furthermore, since only the detection head is modified, our design is highly
generic and has been successfully applied across various YOLO backbones,
including lightweight models. It also provides promising results when
integrated into an instance segmentation YOLO. This versatility makes AA-YOLO
an attractive solution for real-world deployments where resources are
constrained. The code will be publicly released.
\\ ( https://arxiv.org/abs/2510.04741 ,  5994kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04753
Date: Mon, 6 Oct 2025 12:31:15 GMT   (4032kb)

Title: Beyond Appearance: Transformer-based Person Identification from
  Conversational Dynamics
Authors: Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo
Categories: cs.CV
\\
  This paper investigates the performance of transformer-based architectures
for person identification in natural, face-to-face conversation scenario. We
implement and evaluate a two-stream framework that separately models spatial
configurations and temporal motion patterns of 133 COCO WholeBody keypoints,
extracted from a subset of the CANDOR conversational corpus. Our experiments
compare pre-trained and from-scratch training, investigate the use of velocity
features, and introduce a multi-scale temporal transformer for hierarchical
motion modeling. Results demonstrate that domain-specific training
significantly outperforms transfer learning, and that spatial configurations
carry more discriminative information than temporal dynamics. The spatial
transformer achieves 95.74% accuracy, while the multi-scale temporal
transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%,
confirming that postural and dynamic information are complementary. These
findings highlight the potential of transformer architectures for person
identification in natural interactions and provide insights for future
multimodal and cross-cultural studies.
\\ ( https://arxiv.org/abs/2510.04753 ,  4032kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04759
Date: Mon, 6 Oct 2025 12:36:07 GMT   (7738kb)

Title: Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open
  Vocabulary Occupancy Prediction
Authors: Chi Yan and Dan Xu
Categories: cs.CV cs.AI
Comments: Project Page: https://yanchi-3dv.github.io/PG-Occ
\\
  The 3D occupancy prediction task has witnessed remarkable progress in recent
years, playing a crucial role in vision-based autonomous driving systems. While
traditional methods are limited to fixed semantic categories, recent approaches
have moved towards predicting text-aligned features to enable open-vocabulary
text queries in real-world scenes. However, there exists a trade-off in
text-aligned scene modeling: sparse Gaussian representation struggles to
capture small objects in the scene, while dense representation incurs
significant computational overhead. To address these limitations, we present
PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables
open-vocabulary 3D occupancy prediction. Our framework employs progressive
online densification, a feed-forward strategy that gradually enhances the 3D
Gaussian representation to capture fine-grained scene details. By iteratively
enhancing the representation, the framework achieves increasingly precise and
detailed scene understanding. Another key contribution is the introduction of
an anisotropy-aware sampling strategy with spatio-temporal fusion, which
adaptively assigns receptive fields to Gaussians at different scales and
stages, enabling more effective feature aggregation and richer scene
information capture. Through extensive evaluations, we demonstrate that PG-Occ
achieves state-of-the-art performance with a relative 14.3% mIoU improvement
over the previous best performing method. Code and pretrained models will be
released upon publication on our project page:
https://yanchi-3dv.github.io/PG-Occ
\\ ( https://arxiv.org/abs/2510.04759 ,  7738kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04770
Date: Mon, 6 Oct 2025 12:43:59 GMT   (1927kb)

Title: Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary
  Learning
Authors: Xiaomeng Fan, Yuchuan Mao, Zhi Gao, Yuwei Wu, Jin Chen, Yunde Jia
Categories: cs.CV cs.LG
\\
  Open-vocabulary learning requires modeling the data distribution in open
environments, which consists of both seen-class and unseen-class data.
  Existing methods estimate the distribution in open environments using
seen-class data, where the absence of unseen classes makes the estimation error
inherently unidentifiable.
  Intuitively, learning beyond the seen classes is crucial for distribution
estimation to bound the estimation error.
  We theoretically demonstrate that the distribution can be effectively
estimated by generating unseen-class data, through which the estimation error
is upper-bounded.
  Building on this theoretical insight, we propose a novel open-vocabulary
learning method, which generates unseen-class data for estimating the
distribution in open environments. The method consists of a class-domain-wise
data generation pipeline and a distribution alignment algorithm. The data
generation pipeline generates unseen-class data under the guidance of a
hierarchical semantic tree and domain information inferred from the seen-class
data, facilitating accurate distribution estimation. With the generated data,
the distribution alignment algorithm estimates and maximizes the posterior
probability to enhance generalization in open-vocabulary learning. Extensive
experiments on $11$ datasets demonstrate that our method outperforms baseline
approaches by up to $14\%$, highlighting its effectiveness and superiority.
\\ ( https://arxiv.org/abs/2510.04770 ,  1927kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04772
Date: Mon, 6 Oct 2025 12:48:46 GMT   (2333kb)

Title: Federated Learning for Surgical Vision in Appendicitis Classification:
  Results of the FedSurg EndoVis 2024 Challenge
Authors: Max Kirchner, Hanna Hoffmann, Alexander C. Jenke, Oliver L. Saldanha,
  Kevin Pfeiffer, Weam Kanjo, Julia Alekseenko, Claas de Boer, Santhi Raj
  Kolamuri, Lorenzo Mazza, Nicolas Padoy, Sophia Bano, Annika Reinke, Lena
  Maier-Hein, Danail Stoyanov, Jakob N. Kather, Fiona R. Kolbinger, Sebastian
  Bodenstedt, and Stefanie Speidel
Categories: cs.CV cs.LG
Comments: A challenge report pre-print (31 pages), including 7 tables and 8
  figures
\\
  Purpose: The FedSurg challenge was designed to benchmark the state of the art
in federated learning for surgical video classification. Its goal was to assess
how well current methods generalize to unseen clinical centers and adapt
through local fine-tuning while enabling collaborative model development
without sharing patient data. Methods: Participants developed strategies to
classify inflammation stages in appendicitis using a preliminary version of the
multi-center Appendix300 video dataset. The challenge evaluated two tasks:
generalization to an unseen center and center-specific adaptation after
fine-tuning. Submitted approaches included foundation models with linear
probing, metric learning with triplet loss, and various FL aggregation schemes
(FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and
Expected Cost, with ranking robustness evaluated via bootstrapping and
statistical testing. Results: In the generalization task, performance across
centers was limited. In the adaptation task, all teams improved after
fine-tuning, though ranking stability was low. The ViViT-based submission
achieved the strongest overall performance. The challenge highlighted
limitations in generalization, sensitivity to class imbalance, and difficulties
in hyperparameter tuning in decentralized training, while spatiotemporal
modeling and context-aware preprocessing emerged as promising strategies.
Conclusion: The FedSurg Challenge establishes the first benchmark for
evaluating FL strategies in surgical video classification. Findings highlight
the trade-off between local personalization and global robustness, and
underscore the importance of architecture choice, preprocessing, and loss
design. This benchmarking offers a reference point for future development of
imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.
\\ ( https://arxiv.org/abs/2510.04772 ,  2333kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04781
Date: Mon, 6 Oct 2025 12:58:41 GMT   (35157kb)

Title: Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage
  Digitization
Authors: Javed Ahmad, Federico Dassi\`e, Selene Frascella, Gabriele Marchello,
  Ferdinando Cannella, Arianna Traviglia
Categories: cs.CV
Comments: 9 pages
\\
  High-fidelity 3D scanning is essential for preserving cultural heritage
artefacts, supporting documentation, analysis, and long-term conservation.
However, conventional methods typically require specialized expertise and
manual intervention to maintain optimal scanning conditions and coverage. We
present an automated two-robot scanning system that eliminates the need for
handheld or semi-automatic workflows by combining coordinated robotic
manipulation with high-resolution 3D scanning. Our system parameterizes the
scanning space into distinct regions, enabling coordinated motion planning
between a scanner-equipped robot and a tray-handling robot. Optimized
trajectory planning and waypoint distribution ensure comprehensive surface
coverage, minimize occlusions, and balance reconstruction accuracy with system
efficiency. Experimental results show that our approach achieves significantly
lower Chamfer Distance and higher F-score compared to baseline methods,
offering superior geometric accuracy, improved digitization efficiency, and
reduced reliance on expert operators.
\\ ( https://arxiv.org/abs/2510.04781 ,  35157kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04794
Date: Mon, 6 Oct 2025 13:18:27 GMT   (5614kb)

Title: A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid
  Transformation and Fundamental Matrix Estimation
Authors: Alon Kaya, Igal Bilik, Inna Stainvas
Categories: cs.CV
\\
  Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs)
have reshaped computer vision through pretrained feature representations that
enable strong transfer learning for diverse tasks. However, their efficiency as
backbone architectures for geometric estimation tasks involving image
deformations in low-data regimes remains an open question. This work considers
two such tasks: 1) estimating 2D rigid transformations between pairs of images
and 2) predicting the fundamental matrix for stereo image pairs, an important
problem in various applications, such as autonomous mobility, robotics, and 3D
scene reconstruction. Addressing this intriguing question, this work
systematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet)
with ViT-based foundation models (CLIP-ViT variants and DINO) in various data
size settings, including few-shot scenarios. These pretrained models are
optimized for classification or contrastive learning, encouraging them to focus
mostly on high-level semantics. The considered tasks require balancing local
and global features differently, challenging the straightforward adoption of
these models as the backbone. Empirical comparative analysis shows that,
similar to training from scratch, ViTs outperform CNNs during refinement in
large downstream-data scenarios. However, in small data scenarios, the
inductive bias and smaller capacity of CNNs improve their performance, allowing
them to match that of a ViT. Moreover, ViTs exhibit stronger generalization in
cross-domain evaluation where the data distribution changes. These results
emphasize the importance of carefully selecting model architectures for
refinement, motivating future research towards hybrid architectures that
balance local and global representations.
\\ ( https://arxiv.org/abs/2510.04794 ,  5614kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04797
Date: Fri, 3 Oct 2025 16:27:53 GMT   (118560kb)

Title: DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category
  Virtual Try-On and Virtual Try-All with Integrated Image Editing
Authors: Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee
  Kiat Koo, Karim Bouyarmane
Categories: cs.CV cs.AI
Comments: Submitted to CVPR 2025 and Published at CVPR 2025 AI for Content
  Creation workshop
\\
  The rapid growth of e-commerce has intensified the demand for Virtual Try-On
(VTO) technologies, enabling customers to realistically visualize products
overlaid on their own images. Despite recent advances, existing VTO models face
challenges with fine-grained detail preservation, robustness to real-world
imagery, efficient sampling, image editing capabilities, and generalization
across diverse product categories. In this paper, we present DiT-VTON, a novel
VTO framework that leverages a Diffusion Transformer (DiT), renowned for its
performance on text-conditioned image generation, adapted here for the
image-conditioned VTO task. We systematically explore multiple DiT
configurations, including in-context token concatenation, channel
concatenation, and ControlNet integration, to determine the best setup for VTO
image conditioning.
  To enhance robustness, we train the model on an expanded dataset encompassing
varied backgrounds, unstructured references, and non-garment categories,
demonstrating the benefits of data scaling for VTO adaptability. DiT-VTON also
redefines the VTO task beyond garment try-on, offering a versatile Virtual
Try-All (VTA) solution capable of handling a wide range of product categories
and supporting advanced image editing functionalities such as pose
preservation, localized editing, texture transfer, and object-level
customization. Experimental results show that our model surpasses
state-of-the-art methods on VITON-HD, achieving superior detail preservation
and robustness without reliance on additional condition encoders. It also
outperforms models with VTA and image editing capabilities on a diverse dataset
spanning thousands of product categories.
\\ ( https://arxiv.org/abs/2510.04797 ,  118560kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04802
Date: Mon, 6 Oct 2025 13:35:51 GMT   (3670kb)

Title: Did you just see that? Arbitrary view synthesis for egocentric replay of
  operating room workflows from ambient sensors
Authors: Han Zhang, Lalithkumar Seenivasan, Jose L. Porras, Roger D.
  Soberanis-Mukul, Hao Ding, Hongchao Shu, Benjamin D. Killeen, Ankita Ghosh,
  Lonny Yarmus, Masaru Ishii, Angela Christine Argento, and Mathias Unberath
Categories: cs.CV cs.AI
\\
  Observing surgical practice has historically relied on fixed vantage points
or recollections, leaving the egocentric visual perspectives that guide
clinical decisions undocumented. Fixed-camera video can capture surgical
workflows at the room-scale, but cannot reconstruct what each team member
actually saw. Thus, these videos only provide limited insights into how
decisions that affect surgical safety, training, and workflow optimization are
made. Here we introduce EgoSurg, the first framework to reconstruct the
dynamic, egocentric replays for any operating room (OR) staff directly from
wall-mounted fixed-camera video, and thus, without intervention to clinical
workflow. EgoSurg couples geometry-driven neural rendering with diffusion-based
view enhancement, enabling high-visual fidelity synthesis of arbitrary and
egocentric viewpoints at any moment. In evaluation across multi-site surgical
cases and controlled studies, EgoSurg reconstructs person-specific visual
fields and arbitrary viewpoints with high visual quality and fidelity. By
transforming existing OR camera infrastructure into a navigable dynamic 3D
record, EgoSurg establishes a new foundation for immersive surgical data
science, enabling surgical practice to be visualized, experienced, and analyzed
from every angle.
\\ ( https://arxiv.org/abs/2510.04802 ,  3670kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04819
Date: Mon, 6 Oct 2025 14:01:39 GMT   (26170kb)

Title: Visual Representations inside the Language Model
Authors: Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han,
  Ranjay Krishna
Categories: cs.CV cs.CL
Comments: Accepted to COLM 2025
\\
  Despite interpretability work analyzing VIT encoders and transformer
activations, we don't yet understand why Multimodal Language Models (MLMs)
struggle on perception-heavy tasks. We offer an under-studied perspective by
examining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and
Llama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the
flow of visual information through the language model, finding that image value
tokens encode sufficient information to perform several perception-heavy tasks
zero-shot: segmentation, semantic correspondence, temporal correspondence, and
referring expression detection. We find that while the language model does
augment the visual information received from the projection of input visual
encodings-which we reveal correlates with overall MLM perception capability-it
contains less visual information on several tasks than the equivalent visual
encoder (SigLIP) that has not undergone MLM finetuning. Further, we find that
the visual information corresponding to input-agnostic image key tokens in
later layers of language models contains artifacts which reduce perception
capability of the overall MLM. Next, we discuss controlling visual information
in the language model, showing that adding a text prefix to the image input
improves perception capabilities of visual representations. Finally, we reveal
that if language models were able to better control their visual information,
their perception would significantly improve; e.g., in 33.3% of Art Style
questions in the BLINK benchmark, perception information present in the
language model is not surfaced to the output! Our findings reveal insights into
the role of key-value tokens in multimodal systems, paving the way for deeper
mechanistic interpretability of MLMs and suggesting new directions for training
their visual encoder and language model components.
\\ ( https://arxiv.org/abs/2510.04819 ,  26170kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04822
Date: Mon, 6 Oct 2025 14:06:34 GMT   (5746kb)

Title: AvatarVTON: 4D Virtual Try-On for Animatable Avatars
Authors: Zicheng Jiang, Jixin Gao, Shengfeng He, Xinzhe Li, Yulong Zheng,
  Zhaotong Yang, Junyu Dong, Yong Du
Categories: cs.CV
\\
  We propose AvatarVTON, the first 4D virtual try-on framework that generates
realistic try-on results from a single in-shop garment image, enabling free
pose control, novel-view rendering, and diverse garment choices. Unlike
existing methods, AvatarVTON supports dynamic garment interactions under
single-view supervision, without relying on multi-view garment captures or
physics priors. The framework consists of two key modules: (1) a Reciprocal
Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes
avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer,
which decomposes Gaussian maps into view-pose-invariant and view-pose-specific
components, enabling adaptive, non-linear garment deformations. To establish a
benchmark for 4D virtual try-on, we extend existing baselines with unified
modules for fair qualitative and quantitative comparisons. Extensive
experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic
garment realism, making it well-suited for AR/VR, gaming, and digital-human
applications.
\\ ( https://arxiv.org/abs/2510.04822 ,  5746kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04823
Date: Mon, 6 Oct 2025 14:07:03 GMT   (1932kb)

Title: Flow Matching for Conditional MRI-CT and CBCT-CT Image Synthesis
Authors: Arnela Hadzic, Simon Johannes Joham and Martin Urschler
Categories: cs.CV
\\
  Generating synthetic CT (sCT) from MRI or CBCT plays a crucial role in
enabling MRI-only and CBCT-based adaptive radiotherapy, improving treatment
precision while reducing patient radiation exposure. To address this task, we
adopt a fully 3D Flow Matching (FM) framework, motivated by recent work
demonstrating FM's efficiency in producing high-quality images. In our
approach, a Gaussian noise volume is transformed into an sCT image by
integrating a learned FM velocity field, conditioned on features extracted from
the input MRI or CBCT using a lightweight 3D encoder. We evaluated the method
on the SynthRAD2025 Challenge benchmark, training separate models for MRI
$\rightarrow$ sCT and CBCT $\rightarrow$ sCT across three anatomical regions:
abdomen, head and neck, and thorax. Validation and testing were performed
through the challenge submission system. The results indicate that the method
accurately reconstructs global anatomical structures; however, preservation of
fine details was limited, primarily due to the relatively low training
resolution imposed by memory and runtime constraints. Future work will explore
patch-based training and latent-space flow models to improve resolution and
local structural fidelity.
\\ ( https://arxiv.org/abs/2510.04823 ,  1932kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04838
Date: Mon, 6 Oct 2025 14:22:28 GMT   (4994kb)

Title: Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation
Authors: Muquan Li, Hang Gou, Dongyang Zhang, Shuang Liang, Xiurui Xie, Deqiang
  Ouyang, and Ke Qin
Categories: cs.CV cs.LG
\\
  The growing demand for efficient deep learning has positioned dataset
distillation as a pivotal technique for compressing training dataset while
preserving model performance. However, existing inner-loop optimization methods
for dataset distillation typically rely on random truncation strategies, which
lack flexibility and often yield suboptimal results. In this work, we observe
that neural networks exhibit distinct learning dynamics across different
training stages-early, middle, and late-making random truncation ineffective.
To address this limitation, we propose Automatic Truncated Backpropagation
Through Time (AT-BPTT), a novel framework that dynamically adapts both
truncation positions and window sizes according to intrinsic gradient behavior.
AT-BPTT introduces three key components: (1) a probabilistic mechanism for
stage-aware timestep selection, (2) an adaptive window sizing strategy based on
gradient variation, and (3) a low-rank Hessian approximation to reduce
computational overhead. Extensive experiments on CIFAR-10, CIFAR-100,
Tiny-ImageNet, and ImageNet-1K show that AT-BPTT achieves state-of-the-art
performance, improving accuracy by an average of 6.16% over baseline methods.
Moreover, our approach accelerates inner-loop optimization by 3.9x while saving
63% memory cost.
\\ ( https://arxiv.org/abs/2510.04838 ,  4994kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04840
Date: Mon, 6 Oct 2025 14:25:03 GMT   (2199kb)

Title: Detailed Aerial Mapping of Photovoltaic Power Plants Through
  Semantically Significant Keypoints
Authors: Viktor Koz\'ak, Jan Chudoba, Libor P\v{r}eu\v{c}il
Categories: cs.CV
Comments: 10 pages, 18 figures
\\
  An accurate and up-to-date model of a photovoltaic (PV) power plant is
essential for its optimal operation and maintenance. However, such a model may
not be easily available. This work introduces a novel approach for PV power
plant mapping based on aerial overview images. It enables the automation of the
mapping process while removing the reliance on third-party data. The presented
mapping method takes advantage of the structural layout of the power plants to
achieve detailed modeling down to the level of individual PV modules. The
approach relies on visual segmentation of PV modules in overview images and the
inference of structural information in each image, assigning modules to
individual benches, rows, and columns. We identify visual keypoints related to
the layout and use these to merge detections from multiple images while
maintaining their structural integrity. The presented method was experimentally
verified and evaluated on two different power plants. The final fusion of 3D
positions and semantic structures results in a compact georeferenced model
suitable for power plant maintenance.
\\ ( https://arxiv.org/abs/2510.04840 ,  2199kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04844
Date: Mon, 6 Oct 2025 14:31:53 GMT   (893kb)

Title: From Actions to Kinesics: Extracting Human Psychological States through
  Bodily Movements
Authors: Cheyu Lin and Katherine A. Flanigan
Categories: cs.CV
Comments: The 15th International Workshop on Structural Health Monitoring
  (IWSHM)
\\
  Understanding the dynamic relationship between humans and the built
environment is a key challenge in disciplines ranging from environmental
psychology to reinforcement learning (RL). A central obstacle in modeling these
interactions is the inability to capture human psychological states in a way
that is both generalizable and privacy preserving. Traditional methods rely on
theoretical models or questionnaires, which are limited in scope, static, and
labor intensive. We present a kinesics recognition framework that infers the
communicative functions of human activity -- known as kinesics -- directly from
3D skeleton joint data. Combining a spatial-temporal graph convolutional
network (ST-GCN) with a convolutional neural network (CNN), the framework
leverages transfer learning to bypass the need for manually defined mappings
between physical actions and psychological categories. The approach preserves
user anonymity while uncovering latent structures in bodily movements that
reflect cognitive and emotional states. Our results on the Dyadic User
EngagemenT (DUET) dataset demonstrate that this method enables scalable,
accurate, and human-centered modeling of behavior, offering a new pathway for
enhancing RL-driven simulations of human-environment interaction.
\\ ( https://arxiv.org/abs/2510.04844 ,  893kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04854
Date: Mon, 6 Oct 2025 14:40:22 GMT   (4785kb)

Title: Read the Room: Inferring Social Context Through Dyadic Interaction
  Recognition in Cyber-physical-social Infrastructure Systems
Authors: Cheyu Lin, John Martins, Katherine A. Flanigan, Ph.D
Categories: cs.CV
Comments: ASCE International Conference on Computing in Civil Engineering 2024
\\
  Cyber-physical systems (CPS) integrate sensing, computing, and control to
improve infrastructure performance, focusing on economic goals like performance
and safety. However, they often neglect potential human-centered (or
''social'') benefits. Cyber-physical-social infrastructure systems (CPSIS) aim
to address this by aligning CPS with social objectives. This involves defining
social benefits, understanding human interactions with each other and
infrastructure, developing privacy-preserving measurement methods, modeling
these interactions for prediction, linking them to social benefits, and
actuating the physical environment to foster positive social outcomes. This
paper delves into recognizing dyadic human interactions using real-world data,
which is the backbone to measuring social behavior. This lays a foundation to
address the need to enhance understanding of the deeper meanings and mutual
responses inherent in human interactions. While RGB cameras are informative for
interaction recognition, privacy concerns arise. Depth sensors offer a
privacy-conscious alternative by analyzing skeletal movements. This study
compares five skeleton-based interaction recognition algorithms on a dataset of
12 dyadic interactions. Unlike single-person datasets, these interactions,
categorized into communication types like emblems and affect displays, offer
insights into the cultural and emotional aspects of human interactions.
\\ ( https://arxiv.org/abs/2510.04854 ,  4785kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04856
Date: Mon, 6 Oct 2025 14:45:41 GMT   (91kb)

Title: ERDE: Entropy-Regularized Distillation for Early-exit
Authors: Martial Guidez, Stefan Duffner, Yannick Alpou, Oscar R\"oth,
  Christophe Garcia
Categories: cs.CV cs.LG
\\
  Although deep neural networks and in particular Convolutional Neural Networks
have demonstrated state-of-the-art performance in image classification with
relatively high efficiency, they still exhibit high computational costs, often
rendering them impractical for real-time and edge applications. Therefore, a
multitude of compression techniques have been developed to reduce these costs
while maintaining accuracy. In addition, dynamic architectures have been
introduced to modulate the level of compression at execution time, which is a
desirable property in many resource-limited application scenarios. The proposed
method effectively integrates two well-established optimization techniques:
early exits and knowledge distillation, where a reduced student early-exit
model is trained from a more complex teacher early-exit model. The primary
contribution of this research lies in the approach for training the student
early-exit model. In comparison to the conventional Knowledge Distillation
loss, our approach incorporates a new entropy-based loss for images where the
teacher's classification was incorrect. The proposed method optimizes the
trade-off between accuracy and efficiency, thereby achieving significant
reductions in computational complexity without compromising classification
performance. The validity of this approach is substantiated by experimental
results on image classification datasets CIFAR10, CIFAR100 and SVHN, which
further opens new research perspectives for Knowledge Distillation in other
contexts.
\\ ( https://arxiv.org/abs/2510.04856 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04859
Date: Mon, 6 Oct 2025 14:48:36 GMT   (4340kb)

Title: \mu DeepIQA: deep learning-based fast and robust image quality
  assessment with local predictions for optical microscopy
Authors: Elena Corbetta and Thomas Bocklitz
Categories: cs.CV physics.data-an q-bio.QM
Comments: 16 pages, 6 figures. \mu DeepIQA is publicly available at
  https://git.photonicdata.science/elena.corbetta/udeepiqa
\\
  Optical microscopy is one of the most widely used techniques in research
studies for life sciences and biomedicine. These applications require reliable
experimental pipelines to extract valuable knowledge from the measured samples
and must be supported by image quality assessment (IQA) to ensure correct
processing and analysis of the image data. IQA methods are implemented with
variable complexity. However, while most quality metrics have a straightforward
implementation, they might be time consuming and computationally expensive when
evaluating a large dataset. In addition, quality metrics are often designed for
well-defined image features and may be unstable for images out of the ideal
domain.
  To overcome these limitations, recent works have proposed deep learning-based
IQA methods, which can provide superior performance, increased generalizability
and fast prediction. Our method, named $\mathrm{\mu}$DeepIQA, is inspired by
previous studies and applies a deep convolutional neural network designed for
IQA on natural images to optical microscopy measurements. We retrained the same
architecture to predict individual quality metrics and global quality scores
for optical microscopy data. The resulting models provide fast and stable
predictions of image quality by generalizing quality estimation even outside
the ideal range of standard methods. In addition, $\mathrm{\mu}$DeepIQA
provides patch-wise prediction of image quality and can be used to visualize
spatially varying quality in a single image. Our study demonstrates that
optical microscopy-based studies can benefit from the generalizability of deep
learning models due to their stable performance in the presence of outliers,
the ability to assess small image patches, and rapid predictions.
\\ ( https://arxiv.org/abs/2510.04859 ,  4340kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04864
Date: Mon, 6 Oct 2025 14:51:24 GMT   (31801kb)

Title: In-Field Mapping of Grape Yield and Quality with Illumination-Invariant
  Deep Learning
Authors: Ciem Cornelissen, Sander De Coninck, Axel Willekens, Sam Leroux,
  Pieter Simoens
Categories: cs.CV
Comments: Accepted manuscript for the IEEE Internet of Things Journal. The
  final version will be available on IEEE Xplore. \c{opyright} 2025 IEEE
Journal-ref: IEEE Internet of Things Journal, 2025
DOI: 10.1109/JIOT.2025.3617805
\\
  This paper presents an end-to-end, IoT-enabled robotic system for the
non-destructive, real-time, and spatially-resolved mapping of grape yield and
quality (Brix, Acidity) in vineyards. The system features a comprehensive
analytical pipeline that integrates two key modules: a high-performance model
for grape bunch detection and weight estimation, and a novel deep learning
framework for quality assessment from hyperspectral (HSI) data. A critical
barrier to in-field HSI is the ``domain shift" caused by variable illumination.
To overcome this, our quality assessment is powered by the Light-Invariant
Spectral Autoencoder (LISA), a domain-adversarial framework that learns
illumination-invariant features from uncalibrated data. We validated the
system's robustness on a purpose-built HSI dataset spanning three distinct
illumination domains: controlled artificial lighting (lab), and variable
natural sunlight captured in the morning and afternoon. Results show the
complete pipeline achieves a recall (0.82) for bunch detection and a $R^2$
(0.76) for weight prediction, while the LISA module improves quality prediction
generalization by over 20% compared to the baselines. By combining these robust
modules, the system successfully generates high-resolution, georeferenced data
of both grape yield and quality, providing actionable, data-driven insights for
precision viticulture.
\\ ( https://arxiv.org/abs/2510.04864 ,  31801kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04876
Date: Mon, 6 Oct 2025 15:00:20 GMT   (40982kb)

Title: BenthiCat: An opti-acoustic dataset for advancing benthic classification
  and habitat mapping
Authors: Hayat Rajani, Valerio Franchi, Borja Martinez-Clavel Valles, Raimon
  Ramos, Rafael Garcia and Nuno Gracias
Categories: cs.CV cs.LG
Comments: Article under review by IJRR
ACM-class: I.2.6; I.4.6; I.5.1; I.5.4
\\
  Benthic habitat mapping is fundamental for understanding marine ecosystems,
guiding conservation efforts, and supporting sustainable resource management.
Yet, the scarcity of large, annotated datasets limits the development and
benchmarking of machine learning models in this domain. This paper introduces a
thorough multi-modal dataset, comprising about a million side-scan sonar (SSS)
tiles collected along the coast of Catalonia (Spain), complemented by
bathymetric maps and a set of co-registered optical images from targeted
surveys using an autonomous underwater vehicle (AUV). Approximately \num{36000}
of the SSS tiles have been manually annotated with segmentation masks to enable
supervised fine-tuning of classification models. All the raw sensor data,
together with mosaics, are also released to support further exploration and
algorithm development. To address challenges in multi-sensor data fusion for
AUVs, we spatially associate optical images with corresponding SSS tiles,
facilitating self-supervised, cross-modal representation learning. Accompanying
open-source preprocessing and annotation tools are provided to enhance
accessibility and encourage research. This resource aims to establish a
standardized benchmark for underwater habitat mapping, promoting advancements
in autonomous seafloor classification and multi-sensor integration.
\\ ( https://arxiv.org/abs/2510.04876 ,  40982kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04912
Date: Mon, 6 Oct 2025 15:26:08 GMT   (3067kb)

Title: Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for
  Motorbike Detection in Kigali Autonomous Driving Context
Authors: Ngeyen Yinkfu, Sunday Nwovu, Jonathan Kayizzi, Angelique Uwamahoro
Categories: cs.CV cs.LG
Comments: 3 figures, 2 tables
\\
  In Kigali, Rwanda, motorcycle taxis are a primary mode of transportation,
often navigating unpredictably and disregarding traffic rules, posing
significant challenges for autonomous driving systems. This study compares four
object detection models--YOLOv5, Faster R-CNN, SSD, and RetinaNet--for
motorbike detection using a custom dataset of 198 images collected in Kigali.
Implemented in PyTorch with transfer learning, the models were evaluated for
accuracy, localization, and inference speed to assess their suitability for
real-time navigation in resource-constrained settings. We identify
implementation challenges, including dataset limitations and model
complexities, and recommend simplified architectures for future work to enhance
accessibility for autonomous systems in developing countries like Rwanda.
\\ ( https://arxiv.org/abs/2510.04912 ,  3067kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04916
Date: Mon, 6 Oct 2025 15:30:39 GMT   (4915kb)

Title: A Semantics-Aware Hierarchical Self-Supervised Approach to
  Classification of Remote Sensing Images
Authors: Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone
Categories: cs.CV
Comments: 12 pages, 6 figures
ACM-class: I.4.6; I.4.8; I.4.10
\\
  Deep learning has become increasingly important in remote sensing image
classification due to its ability to extract semantic information from complex
data. Classification tasks often include predefined label hierarchies that
represent the semantic relationships among classes. However, these hierarchies
are frequently overlooked, and most approaches focus only on fine-grained
classification schemes. In this paper, we present a novel Semantics-Aware
Hierarchical Consensus (SAHC) method for learning hierarchical features and
relationships by integrating hierarchy-specific classification heads within a
deep network architecture, each specialized in different degrees of class
granularity. The proposed approach employs trainable hierarchy matrices, which
guide the network through the learning of the hierarchical structure in a
self-supervised manner. Furthermore, we introduce a hierarchical consensus
mechanism to ensure consistent probability distributions across different
hierarchical levels. This mechanism acts as a weighted ensemble being able to
effectively leverage the inherent structure of the hierarchical classification
task. The proposed SAHC method is evaluated on three benchmark datasets with
different degrees of hierarchical complexity on different tasks, using distinct
backbone architectures to effectively emphasize its adaptability. Experimental
results show both the effectiveness of the proposed approach in guiding network
learning and the robustness of the hierarchical consensus for remote sensing
image classification tasks.
\\ ( https://arxiv.org/abs/2510.04916 ,  4915kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04923
Date: Mon, 6 Oct 2025 15:35:08 GMT   (2308kb)

Title: REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung
  Disease Diagnosis
Authors: Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin
  Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R.
  Scott Budinger, Anthony J. Esposito, Alexander Misharin, Alok Choudhary,
  Ankit Agrawal, and Ulas Bagci
Categories: cs.CV cs.AI
Comments: 10 pages, 4 figures, 2 tables
\\
  Mixture-of-Experts (MoE) architectures have significantly contributed to
scalable machine learning by enabling specialized subnetworks to tackle complex
tasks efficiently. However, traditional MoE systems lack domain-specific
constraints essential for medical imaging, where anatomical structure and
regional disease heterogeneity strongly influence pathological patterns. Here,
we introduce Regional Expert Networks (REN), the first anatomically-informed
MoE framework tailored specifically for medical image classification. REN
leverages anatomical priors to train seven specialized experts, each dedicated
to distinct lung lobes and bilateral lung combinations, enabling precise
modeling of region-specific pathological variations. Multi-modal gating
mechanisms dynamically integrate radiomics biomarkers and deep learning (DL)
features (CNN, ViT, Mamba) to weight expert contributions optimally. Applied to
interstitial lung disease (ILD) classification, REN achieves consistently
superior performance: the radiomics-guided ensemble reached an average AUC of
0.8646 +/- 0.0467, a +12.5 percent improvement over the SwinUNETR baseline (AUC
0.7685, p = 0.031). Region-specific experts further revealed that lower-lobe
models achieved AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79)
and aligning with known disease progression patterns. Through rigorous
patient-level cross-validation, REN demonstrates strong generalizability and
clinical interpretability, presenting a scalable, anatomically-guided approach
readily extensible to other structured medical imaging applications.
\\ ( https://arxiv.org/abs/2510.04923 ,  2308kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04939
Date: Mon, 6 Oct 2025 15:44:33 GMT   (4506kb)

Title: Unsupervised Active Learning via Natural Feature Progressive Framework
Authors: Yuxi Liu, Catherine Lalman and Yimin Yang
Categories: cs.CV cs.AI cs.LG
Comments: Under review at IEEE TPAMI
\\
  The effectiveness of modern deep learning models is predicated on the
availability of large-scale, human-annotated datasets, a process that is
notoriously expensive and time-consuming. While Active Learning (AL) offers a
strategic solution by labeling only the most informative and representative
data, its iterative nature still necessitates significant human involvement.
Unsupervised Active Learning (UAL) presents an alternative by shifting the
annotation burden to a single, post-selection step. Unfortunately, prevailing
UAL methods struggle to achieve state-of-the-art performance. These approaches
typically rely on local, gradient-based scoring for sample importance
estimation, which not only makes them vulnerable to ambiguous and noisy data
but also hinders their capacity to select samples that adequately represent the
full data distribution. Moreover, their use of shallow, one-shot linear
selection falls short of a true UAL paradigm. In this paper, we propose the
Natural Feature Progressive Framework (NFPF), a UAL method that revolutionizes
how sample importance is measured. At its core, NFPF employs a Specific Feature
Learning Machine (SFLM) to effectively quantify each sample's contribution to
model performance. We further utilize the SFLM to define a powerful
Reconstruction Difference metric for initial sample selection. Our
comprehensive experiments show that NFPF significantly outperforms all
established UAL methods and achieves performance on par with supervised AL
methods on vision datasets. Detailed ablation studies and qualitative
visualizations provide compelling evidence for NFPF's superior performance,
enhanced robustness, and improved data distribution coverage.
\\ ( https://arxiv.org/abs/2510.04939 ,  4506kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04947
Date: Mon, 6 Oct 2025 15:48:27 GMT   (3287kb)

Title: Bidirectional Mammogram View Translation with Column-Aware and Implicit
  3D Conditional Diffusion
Authors: Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang
Categories: cs.CV cs.AI
Comments: BIBM2025 accept, 8 pages, 4 figures
\\
  Dual-view mammography, including craniocaudal (CC) and mediolateral oblique
(MLO) projections, offers complementary anatomical views crucial for breast
cancer diagnosis. However, in real-world clinical workflows, one view may be
missing, corrupted, or degraded due to acquisition errors or compression
artifacts, limiting the effectiveness of downstream analysis. View-to-view
translation can help recover missing views and improve lesion alignment. Unlike
natural images, this task in mammography is highly challenging due to large
non-rigid deformations and severe tissue overlap in X-ray projections, which
obscure pixel-level correspondences. In this paper, we propose Column-Aware and
Implicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram view
translation framework based on conditional diffusion model. To address
cross-view structural misalignment, we first design a column-aware
cross-attention mechanism that leverages the geometric property that
anatomically corresponding regions tend to lie in similar column positions
across views. A Gaussian-decayed bias is applied to emphasize local column-wise
correlations while suppressing distant mismatches. Furthermore, we introduce an
implicit 3D structure reconstruction module that back-projects noisy 2D latents
into a coarse 3D feature volume based on breast-view projection geometry. The
reconstructed 3D structure is refined and injected into the denoising UNet to
guide cross-view generation with enhanced anatomical awareness. Extensive
experiments demonstrate that CA3D-Diff achieves superior performance in
bidirectional tasks, outperforming state-of-the-art methods in visual fidelity
and structural consistency. Furthermore, the synthesized views effectively
improve single-view malignancy classification in screening settings,
demonstrating the practical value of our method in real-world diagnostics.
\\ ( https://arxiv.org/abs/2510.04947 ,  3287kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04961
Date: Mon, 6 Oct 2025 15:57:31 GMT   (15468kb)

Title: SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization
Authors: Th\'eophane Vallaeys, Jakob Verbeek, Matthieu Cord
Categories: cs.CV
\\
  Tokenizers are a key component of state-of-the-art generative image models,
extracting the most important features from the signal while reducing data
dimension and redundancy. Most current tokenizers are based on KL-regularized
variational autoencoders (KL-VAE), trained with reconstruction, perceptual and
adversarial losses. Diffusion decoders have been proposed as a more principled
alternative to model the distribution over images conditioned on the latent.
However, matching the performance of KL-VAE still requires adversarial losses,
as well as a higher decoding time due to iterative sampling. To address these
limitations, we introduce a new pixel diffusion decoder architecture for
improved scaling and training stability, benefiting from transformer components
and GAN-free training. We use distillation to replicate the performance of the
diffusion decoder in an efficient single-step decoder. This makes SSDD the
first diffusion decoder optimized for single-step reconstruction trained
without adversarial losses, reaching higher reconstruction quality and faster
sampling than KL-VAE. In particular, SSDD improves reconstruction FID from
$0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generation
quality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used as
a drop-in replacement for KL-VAE, and for building higher-quality and faster
generative models.
\\ ( https://arxiv.org/abs/2510.04961 ,  15468kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04966
Date: Mon, 6 Oct 2025 15:58:27 GMT   (14203kb)

Title: ActiveMark: on watermarking of visual foundation models via massive
  activations
Authors: Anna Chistyakova, Mikhail Pautov
Categories: cs.CV cs.AI
\\
  Being trained on large and vast datasets, visual foundation models (VFMs) can
be fine-tuned for diverse downstream tasks, achieving remarkable performance
and efficiency in various computer vision applications. The high computation
cost of data collection and training motivates the owners of some VFMs to
distribute them alongside the license to protect their intellectual property
rights. However, a dishonest user of the protected model's copy may illegally
redistribute it, for example, to make a profit. As a consequence, the
development of reliable ownership verification tools is of great importance
today, since such methods can be used to differentiate between a redistributed
copy of the protected model and an independent model. In this paper, we propose
an approach to ownership verification of visual foundation models by
fine-tuning a small set of expressive layers of a VFM along with a small
encoder-decoder network to embed digital watermarks into an internal
representation of a hold-out set of input images. Importantly, the watermarks
embedded remain detectable in the functional copies of the protected model,
obtained, for example, by fine-tuning the VFM for a particular downstream task.
Theoretically and experimentally, we demonstrate that the proposed method
yields a low probability of false detection of a non-watermarked model and a
low probability of false misdetection of a watermarked model.
\\ ( https://arxiv.org/abs/2510.04966 ,  14203kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05006
Date: Mon, 6 Oct 2025 16:50:02 GMT   (345kb)

Title: Latent Uncertainty Representations for Video-based Driver Action and
  Intention Recognition
Authors: Koen Vellenga, H. Joe Steinhauer, Jonas Andersson, Anders Sj\"ogren
Categories: cs.CV cs.LG
Comments: 16 pages, 8 figures, 7 tables, under submission
\\
  Deep neural networks (DNNs) are increasingly applied to safety-critical tasks
in resource-constrained environments, such as video-based driver action and
intention recognition. While last layer probabilistic deep learning (LL-PDL)
methods can detect out-of-distribution (OOD) instances, their performance
varies. As an alternative to last layer approaches, we propose extending
pre-trained DNNs with transformation layers to produce multiple latent
representations to estimate the uncertainty. We evaluate our latent uncertainty
representation (LUR) and repulsively trained LUR (RLUR) approaches against
eight PDL methods across four video-based driver action and intention
recognition datasets, comparing classification performance, calibration, and
uncertainty-based OOD detection. We also contribute 28,000 frame-level action
labels and 1,194 video-level intention labels for the NuScenes dataset. Our
results show that LUR and RLUR achieve comparable in-distribution
classification performance to other LL-PDL approaches. For uncertainty-based
OOD detection, LUR matches top-performing PDL methods while being more
efficient to train and easier to tune than approaches that require Markov-Chain
Monte Carlo sampling or repulsive training procedures.
\\ ( https://arxiv.org/abs/2510.05006 ,  345kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05015
Date: Mon, 6 Oct 2025 16:55:07 GMT   (1305kb)

Title: Exploring the Efficacy of Modified Transfer Learning in Identifying
  Parkinson's Disease Through Drawn Image Patterns
Authors: Nabil Daiyan, Md Rakibul Haque
Categories: cs.CV
Comments: 5 pages, 11 figures, published on 2024 2nd International Conference
  on Information and Communication Technology (ICICT 2024)
\\
  Parkinson's disease (PD) is a progressive neurodegenerative condition
characterized by the death of dopaminergic neurons, leading to various movement
disorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects,
yet traditional diagnostic methods are often cumbersome and costly. In this
study, a machine learning-based approach is proposed using hand-drawn spiral
and wave images as potential biomarkers for PD detection. Our methodology
leverages convolutional neural networks (CNNs), transfer learning, and
attention mechanisms to improve model performance and resilience against
overfitting. To enhance the diversity and richness of both spiral and wave
categories, the training dataset undergoes augmentation to increase the number
of images. The proposed architecture comprises three phases: utilizing
pre-trained CNNs, incorporating custom convolutional layers, and ensemble
voting. Employing hard voting further enhances performance by aggregating
predictions from multiple models. Experimental results show promising accuracy
rates. For spiral images, weighted average precision, recall, and F1-score are
90%, and for wave images, they are 96.67%. After combining the predictions
through ensemble hard voting, the overall accuracy is 93.3%. These findings
underscore the potential of machine learning in early PD diagnosis, offering a
non-invasive and cost-effective solution to improve patient outcomes.
\\ ( https://arxiv.org/abs/2510.05015 ,  1305kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05034
Date: Mon, 6 Oct 2025 17:10:44 GMT   (8695kb)

Title: Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large
  Multimodal Models
Authors: Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang
  Shen, Jiani Liu, Hang Hua, Junjia Guo, Yunzhong Xiao, Chao Huang, Zhiyuan
  Wang, Susan Liang, Xinyi Liu, Yizhi Song, Yuhe Nie, Jia-Xing Zhong, Bozheng
  Li, Daiqing Qi, Ziyun Zeng, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Daiki
  Shimada, Han Liu, Jiebo Luo, Chenliang Xu
Categories: cs.CV
Comments: The 1st version
\\
  Video understanding represents the most challenging frontier in computer
vision, requiring models to reason about complex spatiotemporal relationships,
long-term dependencies, and multimodal evidence. The recent emergence of
Video-Large Multimodal Models (Video-LMMs), which integrate visual encoders
with powerful decoder-based language models, has demonstrated remarkable
capabilities in video understanding tasks. However, the critical phase that
transforms these models from basic perception systems into sophisticated
reasoning engines, post-training, remains fragmented across the literature.
This survey provides the first comprehensive examination of post-training
methodologies for Video-LMMs, encompassing three fundamental pillars:
supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)
from verifiable objectives, and test-time scaling (TTS) through enhanced
inference computation. We present a structured taxonomy that clarifies the
roles, interconnections, and video-specific adaptations of these techniques,
addressing unique challenges such as temporal localization, spatiotemporal
grounding, long video efficiency, and multimodal evidence integration. Through
systematic analysis of representative methods, we synthesize key design
principles, insights, and evaluation protocols while identifying critical open
challenges in reward design, scalability, and cost-performance optimization. We
further curate essential benchmarks, datasets, and metrics to facilitate
rigorous assessment of post-training effectiveness. This survey aims to provide
researchers and practitioners with a unified framework for advancing Video-LMM
capabilities. Additional resources and updates are maintained at:
https://github.com/yunlong10/Awesome-Video-LMM-Post-Training
\\ ( https://arxiv.org/abs/2510.05034 ,  8695kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05051
Date: Mon, 6 Oct 2025 17:31:32 GMT   (15294kb)

Title: SegMASt3R: Geometry Grounded Segment Matching
Authors: Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad
  Haris Khan, Sourav Garg, Madhava Krishna
Categories: cs.CV
Comments: Accepted to The Thirty-Ninth Annual Conference on Neural Information
  Processing Systems (NeurIPS 2025) as a Spotlight (top 3.5%)
\\
  Segment matching is an important intermediate task in computer vision that
establishes correspondences between semantically or geometrically coherent
regions across images. Unlike keypoint matching, which focuses on localized
features, segment matching captures structured regions, offering greater
robustness to occlusions, lighting variations, and viewpoint changes. In this
paper, we leverage the spatial understanding of 3D foundation models to tackle
wide-baseline segment matching, a challenging setting involving extreme
viewpoint shifts. We propose an architecture that uses the inductive bias of
these 3D foundation models to match segments across image pairs with up to 180
degree view-point change. Extensive experiments show that our approach
outperforms state-of-the-art methods, including the SAM2 video propagator and
local feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++
and Replica datasets. We further demonstrate benefits of the proposed model on
relevant downstream tasks, including 3D instance segmentation and image-goal
navigation. Project Page: https://segmast3r.github.io/
\\ ( https://arxiv.org/abs/2510.05051 ,  15294kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05053
Date: Mon, 6 Oct 2025 17:32:48 GMT   (4976kb)

Title: No-reference Quality Assessment of Contrast-distorted Images using
  Contrast-enhanced Pseudo Reference
Authors: Mohammad-Ali Mahmoudpour, Saeed Mahmoudpour
Categories: cs.CV
\\
  Contrast change is an important factor that affects the quality of images.
During image capturing, unfavorable lighting conditions can cause contrast
change and visual quality loss. While various methods have been proposed to
assess the quality of images under different distortions such as blur and
noise, contrast distortion has been largely overlooked as its visual impact and
properties are different from other conventional types of distortions. In this
paper, we propose a no-reference image quality assessment (NR-IQA) metric for
contrast-distorted images. Using a set of contrast enhancement algorithms, we
aim to generate pseudo-reference images that are visually close to the actual
reference image, such that the NR problem is transformed to a Full-reference
(FR) assessment with higher accuracy. To this end, a large dataset of
contrast-enhanced images is produced to train a classification network that can
select the most suitable contrast enhancement algorithm based on image content
and distortion for pseudo-reference image generation. Finally, the evaluation
is performed in the FR manner to assess the quality difference between the
contrast-enhanced (pseudoreference) and degraded images. Performance evaluation
of the proposed method on three databases containing contrast distortions
(CCID2014, TID2013, and CSIQ), indicates the promising performance of the
proposed method.
\\ ( https://arxiv.org/abs/2510.05053 ,  4976kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05071
Date: Mon, 6 Oct 2025 17:47:45 GMT   (65kb)

Title: Neuroplastic Modular Framework: Cross-Domain Image Classification of
  Garbage and Industrial Surfaces
Authors: Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami
Categories: cs.CV
\\
  Efficient and accurate classification of waste and industrial surface defects
is essential for ensuring sustainable waste management and maintaining high
standards in quality control. This paper introduces the Neuroplastic Modular
Classifier, a novel hybrid architecture designed for robust and adaptive image
classification in dynamic environments. The model combines a ResNet-50 backbone
for localized feature extraction with a Vision Transformer (ViT) to capture
global semantic context. Additionally, FAISS-based similarity retrieval is
incorporated to provide a memory-like reference to previously encountered data,
enriching the model's feature space. A key innovation of our architecture is
the neuroplastic modular design composed of expandable, learnable blocks that
dynamically grow during training when performance plateaus. Inspired by
biological learning systems, this mechanism allows the model to adapt to data
complexity over time, improving generalization. Beyond garbage classification,
we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),
which involves industrial defect detection on metal surfaces. Experimental
results across domains show that the proposed architecture outperforms
traditional static models in both accuracy and adaptability. The Neuroplastic
Modular Classifier offers a scalable, high-performance solution for real-world
image classification, with strong applicability in both environmental and
industrial domains.
\\ ( https://arxiv.org/abs/2510.05071 ,  65kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05091
Date: Mon, 6 Oct 2025 17:56:55 GMT   (5198kb)

Title: Factuality Matters: When Image Generation and Editing Meet Structured
  Visuals
Authors: Le Zhuo, Songhao Han, Yuandong Pu, Boxiang Qiu, Sayak Paul, Yue Liao,
  Yihao Liu, Jie Shao, Xi Chen, Si Liu, Hongsheng Li
Categories: cs.CV
Comments: Project page: https://structvisuals.github.io
\\
  While modern visual generation models excel at creating aesthetically
pleasing natural images, they struggle with producing or editing structured
visuals like charts, diagrams, and mathematical figures, which demand
composition planning, text rendering, and multimodal reasoning for factual
fidelity. To address this, we present the first comprehensive, systematic
investigation of this domain, encompassing data construction, model training,
and an evaluation benchmark. First, we construct a large-scale dataset of 1.3
million high-quality structured image pairs derived from executable drawing
programs and augmented with chain-of-thought reasoning annotations. Building on
it, we train a unified model that integrates a VLM with FLUX.1 Kontext via a
lightweight connector for enhanced multimodal understanding. A three-stage
training curriculum enables progressive feature alignment, knowledge infusion,
and reasoning-augmented generation, further boosted by an external reasoner at
inference time. Finally, we introduce StructBench, a novel benchmark for
generation and editing with over 1,700 challenging instances, and an
accompanying evaluation metric, StructScore, which employs a multi-round Q\&A
protocol to assess fine-grained factual accuracy. Evaluations of 15 models
reveal that even leading closed-source systems remain far from satisfactory.
Our model attains strong editing performance, and inference-time reasoning
yields consistent gains across diverse architectures. By releasing the dataset,
model, and benchmark, we aim to advance unified multimodal foundations for
structured visuals.
\\ ( https://arxiv.org/abs/2510.05091 ,  5198kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05093
Date: Mon, 6 Oct 2025 17:57:39 GMT   (8122kb)

Title: Character Mixing for Video Generation
Authors: Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou
Categories: cs.CV
\\
  Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where
characters interact naturally across different worlds? We study inter-character
interaction in text-to-video generation, where the key challenge is to preserve
each character's identity and behaviors while enabling coherent cross-context
interaction. This is difficult because characters may never have coexisted and
because mixing styles often causes style delusion, where realistic characters
appear cartoonish or vice versa. We introduce a framework that tackles these
issues with Cross-Character Embedding (CCE), which learns identity and
behavioral logic across multimodal sources, and Cross-Character Augmentation
(CCA), which enriches training with synthetic co-existence and mixed-style
data. Together, these techniques allow natural interactions between previously
uncoexistent characters without losing stylistic fidelity. Experiments on a
curated benchmark of cartoons and live-action series with 10 characters show
clear improvements in identity preservation, interaction quality, and
robustness to style delusion, enabling new forms of generative
storytelling.Additional results and videos are available on our project page:
https://tingtingliao.github.io/mimix/.
\\ ( https://arxiv.org/abs/2510.05093 ,  8122kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05094
Date: Mon, 6 Oct 2025 17:57:59 GMT   (22018kb)

Title: VChain: Chain-of-Visual-Thought for Reasoning in Video Generation
Authors: Ziqi Huang, Ning Yu, Gordon Chen, Haonan Qiu, Paul Debevec, Ziwei Liu
Categories: cs.CV
Comments: Project page: https://eyeline-labs.github.io/VChain Code:
  https://github.com/Eyeline-Labs/VChain
\\
  Recent video generation models can produce smooth and visually appealing
clips, but they often struggle to synthesize complex dynamics with a coherent
chain of consequences. Accurately modeling visual outcomes and state
transitions over time remains a core challenge. In contrast, large language and
multimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and
future prediction capabilities. To bridge these strengths, we introduce VChain,
a novel inference-time chain-of-visual-thought framework that injects visual
reasoning signals from multimodal models into video generation. Specifically,
VChain contains a dedicated pipeline that leverages large multimodal models to
generate a sparse set of critical keyframes as snapshots, which are then used
to guide the sparse inference-time tuning of a pre-trained video generator only
at these key moments. Our approach is tuning-efficient, introduces minimal
overhead and avoids dense supervision. Extensive experiments on complex,
multi-step scenarios show that VChain significantly enhances the quality of
generated videos.
\\ ( https://arxiv.org/abs/2510.05094 ,  22018kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05096
Date: Mon, 6 Oct 2025 17:58:02 GMT   (6815kb)

Title: Paper2Video: Automatic Video Generation from Scientific Papers
Authors: Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou
Categories: cs.CV cs.AI cs.CL cs.MA cs.MM
Comments: 20 pages, 8 figures
\\
  Academic presentation videos have become an essential medium for research
communication, yet producing them remains highly labor-intensive, often
requiring hours of slide design, recording, and editing for a short 2 to 10
minutes video. Unlike natural video, presentation video generation involves
distinctive challenges: inputs from research papers, dense multi-modal
information (text, figures, tables), and the need to coordinate multiple
aligned channels such as slides, subtitles, speech, and human talker. To
address these challenges, we introduce PaperTalker, the first benchmark of 101
research papers paired with author-created presentation videos, slides, and
speaker metadata. We further design four tailored evaluation metrics--Meta
Similarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos
convey the paper's information to the audience. Building on this foundation, we
propose PaperTalker, the first multi-agent framework for academic presentation
video generation. It integrates slide generation with effective layout
refinement by a novel effective tree search visual choice, cursor grounding,
subtitling, speech synthesis, and talking-head rendering, while parallelizing
slide-wise generation for efficiency. Experiments on Paper2Video demonstrate
that the presentation videos produced by our approach are more faithful and
informative than existing baselines, establishing a practical step toward
automated and ready-to-use academic video generation. Our dataset, agent, and
code are available at https://github.com/showlab/Paper2Video.
\\ ( https://arxiv.org/abs/2510.05096 ,  6815kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03557
Date: Fri, 3 Oct 2025 23:02:48 GMT   (9020kb)

Title: Cosmological Hydrodynamics at Exascale: A Trillion-Particle Leap in
  Capability
Authors: Nicholas Frontiere, J.D. Emberson, Michael Buehlmann, Esteban M.
  Rangel, Salman Habib, Katrin Heitmann, Patricia Larsen, Vitali Morozov,
  Adrian Pope, Claude-Andr\'e Faucher-Gigu\`ere, Antigoni Georgiadou, Damien
  Lebrun-Grandi\'e, Andrey Prokopenko
Categories: cs.DC astro-ph.CO astro-ph.IM cs.PF physics.comp-ph
\\
  Resolving the most fundamental questions in cosmology requires simulations
that match the scale, fidelity, and physical complexity demanded by
next-generation sky surveys. To achieve the realism needed for this critical
scientific partnership, detailed gas dynamics, along with a host of
astrophysical effects, must be treated self-consistently with gravity for
end-to-end modeling of structure formation. As an important step on this
roadmap, exascale computing enables simulations that span survey-scale volumes
while incorporating key subgrid processes that shape complex cosmic structures.
We present results from CRK-HACC, a cosmological hydrodynamics code built for
the extreme scalability requirements set by modern cosmological surveys. Using
separation-of-scale techniques, GPU-resident tree solvers, in situ analysis
pipelines, and multi-tiered I/O, CRK-HACC executed Frontier-E: a four trillion
particle full-sky simulation, over an order of magnitude larger than previous
efforts. The run achieved 513.1 PFLOPs peak performance, processing 46.6
billion particles per second and writing more than 100 PB of data in just over
one week of runtime.
\\ ( https://arxiv.org/abs/2510.03557 ,  9020kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03872
Date: Sat, 4 Oct 2025 16:49:19 GMT   (456kb)

Title: Datacenter Energy Optimized Power Profiles
Authors: Sreedhar Narayanaswamy, Pratikkumar Dilipkumar Patel, Ian Karlin,
  Apoorv Gupta, Sudhir Saripalli, Janey Guo
Categories: cs.DC
\\
  This paper presents datacenter power profiles, a new NVIDIA software feature
released with Blackwell B200, aimed at improving energy efficiency and/or
performance. The initial feature provides coarse-grain user control for HPC and
AI workloads leveraging hardware and software innovations for intelligent power
management and domain knowledge of HPC and AI workloads. The resulting
workload-aware optimization recipes maximize computational throughput while
operating within strict facility power constraints. The phase-1 Blackwell
implementation achieves up to 15% energy savings while maintaining performance
levels above 97% for critical applications, enabling an overall throughput
increase of up to 13% in a power-constrained facility.
  KEYWORDS GPU power management, energy efficiency, power profile, HPC
optimization, Max-Q, Blackwell architecture
\\ ( https://arxiv.org/abs/2510.03872 ,  456kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03891
Date: Sat, 4 Oct 2025 18:05:31 GMT   (567kb)

Title: Toward Co-adapting Machine Learning Job Shape and Cluster Topology
Authors: Shawn Shuoshuo Chen, Daiyaan Arfeen, Minlan Yu, Peter Steenkiste,
  Srinivasan Seshan
Categories: cs.DC cs.NI
\\
  Allocating resources to distributed machine learning jobs in multi-tenant
torus-topology clusters must meet each job's specific placement and
communication requirements, which are typically described using shapes. There
is an inherent tension between minimizing network contention and maximizing
cluster utilization when placing various-shaped jobs. While existing schedulers
typically optimize for one objective at the expense of the other, we
demonstrate that both can be achieved simultaneously.
  Our proposed approach, RFold, adapts both job shapes and the underlying
cluster topology at runtime. This is accomplished by combining two techniques:
(1) identifying homomorphic job shapes that support the jobs communication
needs, and (2) reconfiguring the optical circuit switch-enabled topology to
support more diverse job shapes. Preliminary evaluation performed on a
4096-node torus cluster simulator indicates that RFold can improve absolute
cluster utilization by 57% and reduce job completion time by up to 11x relative
to existing methods
\\ ( https://arxiv.org/abs/2510.03891 ,  567kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03970
Date: Sat, 4 Oct 2025 23:01:59 GMT   (1343kb)

Title: Towards Carbon-Aware Container Orchestration: Predicting Workload Energy
  Consumption with Federated Learning
Authors: Zainab Saad, Jialin Yang, Henry Leung, Steve Drew
Categories: cs.DC cs.AI
Comments: Accepted to 2025 IEEE Smart World Congress (SWC 2025)
\\
  The growing reliance on large-scale data centers to run resource-intensive
workloads has significantly increased the global carbon footprint, underscoring
the need for sustainable computing solutions. While container orchestration
platforms like Kubernetes help optimize workload scheduling to reduce carbon
emissions, existing methods often depend on centralized machine learning models
that raise privacy concerns and struggle to generalize across diverse
environments. In this paper, we propose a federated learning approach for
energy consumption prediction that preserves data privacy by keeping sensitive
operational data within individual enterprises. By extending the Kubernetes
Efficient Power Level Exporter (Kepler), our framework trains XGBoost models
collaboratively across distributed clients using Flower's FedXgbBagging
aggregation using a bagging strategy, eliminating the need for centralized data
sharing. Experimental results on the SPECPower benchmark dataset show that our
FL-based approach achieves 11.7 percent lower Mean Absolute Error compared to a
centralized baseline. This work addresses the unresolved trade-off between data
privacy and energy prediction efficiency in prior systems such as Kepler and
CASPER and offers enterprises a viable pathway toward sustainable cloud
computing without compromising operational privacy.
\\ ( https://arxiv.org/abs/2510.03970 ,  1343kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04186
Date: Sun, 5 Oct 2025 12:57:07 GMT   (3782kb)

Title: From Patchwork to Network: A Comprehensive Framework for Demand Analysis
  and Fleet Optimization of Urban Air Mobility
Authors: Xuan Jiang, Xuanyu Zhou, Yibo Zhao, Shangqing Cao, Jinhua Zhao, Mark
  Hansen, Raja Sengupta
Categories: cs.DC
\\
  Urban Air Mobility (UAM) presents a transformative vision for metropolitan
transportation, but its practical implementation is hindered by substantial
infrastructure costs and operational complexities. We address these challenges
by modeling a UAM network that leverages existing regional airports and
operates with an optimized, heterogeneous fleet of aircraft. We introduce
LPSim, a Large-Scale Parallel Simulation framework that utilizes multi-GPU
computing to co-optimize UAM demand, fleet operations, and ground
transportation interactions simultaneously. Our equilibrium search algorithm is
extended to accurately forecast demand and determine the most efficient fleet
composition. Applied to a case study of the San Francisco Bay Area, our results
demonstrate that this UAM model can yield over 20 minutes' travel time savings
for 230,000 selected trips. However, the analysis also reveals that system-wide
success is critically dependent on seamless integration with ground access and
dynamic scheduling.
\\ ( https://arxiv.org/abs/2510.04186 ,  3782kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04310
Date: Sun, 5 Oct 2025 18:06:12 GMT   (1038kb)

Title: Beyond Canonical Rounds: Communication Abstractions for Optimal
  Byzantine Resilience
Authors: Hagit Attiya, Itay Flam, Jennifer L. Welch
Categories: cs.DC
Comments: 31 pages, 4 figures, 1 table, 5 algorithms
\\
  We study communication abstractions for asynchronous Byzantine fault
tolerance with optimal failure resilience, where $n > 3f$. Two classic patterns
-- canonical asynchronous rounds and communication-closed layers -- have long
been considered as general frameworks for designing distributed algorithms,
making asynchronous executions appear synchronous and enabling modular
reasoning.
  We show that these patterns are inherently limited in the critical resilience
regime $3f < n \le 5f$. Several key tasks -- such as approximate and crusader
agreement, reliable broadcast and gather -- cannot be solved by bounded-round
canonical-round algorithms, and are unsolvable if communication closure is
imposed. These results explain the historical difficulty of achieving
optimal-resilience algorithms within round-based frameworks.
  On the positive side, we show that the gather abstraction admits
constant-time solutions with optimal resilience ($n > 3f$), and supports
modular reductions. Specifically, we present the first optimally-resilient
algorithm for connected consensus by reducing it to gather.
  Our results demonstrate that while round-based abstractions are analytically
convenient, they obscure the true complexity of Byzantine fault-tolerant
algorithms. Richer communication patterns such as gather provide a better
foundation for modular, optimal-resilience design.
\\ ( https://arxiv.org/abs/2510.04310 ,  1038kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04404
Date: Mon, 6 Oct 2025 00:25:22 GMT   (334kb)

Title: Next-Generation Event-Driven Architectures: Performance, Scalability,
  and Intelligent Orchestration Across Messaging Frameworks
Authors: Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Ahsan Habib Tareq
Categories: cs.DC cs.PF
Comments: 45 pages, 8 tables, 1 figure. Comprehensive evaluation of 12
  messaging frameworks with AI-enhanced orchestration system
MSC-class: 68M14, 68T05, 90C59
ACM-class: C.2.4; D.4.4; D.4.8; I.2.6
\\
  Modern distributed systems demand low-latency, fault-tolerant event
processing that exceeds traditional messaging architecture limits. While
frameworks including Apache Kafka, RabbitMQ, Apache Pulsar, NATS JetStream, and
serverless event buses have matured significantly, no unified comparative study
evaluates them holistically under standardized conditions. This paper presents
the first comprehensive benchmarking framework evaluating 12 messaging systems
across three representative workloads: e-commerce transactions, IoT telemetry
ingestion, and AI inference pipelines. We introduce AIEO (AI-Enhanced Event
Orchestration), employing machine learning-driven predictive scaling,
reinforcement learning for dynamic resource allocation, and multi-objective
optimization. Our evaluation reveals fundamental trade-offs: Apache Kafka
achieves peak throughput (1.2M messages/sec, 18ms p95 latency) but requires
substantial operational expertise; Apache Pulsar provides balanced performance
(950K messages/sec, 22ms p95) with superior multi-tenancy; serverless solutions
offer elastic scaling for variable workloads despite higher baseline latency
(80-120ms p95). AIEO demonstrates 34\% average latency reduction, 28\% resource
utilization improvement, and 42% cost optimization across all platforms. We
contribute standardized benchmarking methodologies, open-source intelligent
orchestration, and evidence-based decision guidelines. The evaluation
encompasses 2,400+ experimental configurations with rigorous statistical
analysis, providing comprehensive performance characterization and establishing
foundations for next-generation distributed system design.
\\ ( https://arxiv.org/abs/2510.04404 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04644
Date: Mon, 6 Oct 2025 09:45:59 GMT   (31kb)

Title: The R(1)W(1) Communication Model for Self-Stabilizing Distributed
  Algorithms
Authors: Hirotsugu Kakugawa, Sayaka Kamei, Masahiro Shibata and Fukuhito
  Ooshita
Categories: cs.DC
\\
  Self-stabilization is a versatile methodology in the design of fault-tolerant
distributed algorithms for transient faults. A self-stabilizing system
automatically recovers from any kind and any finite number of transient faults.
This property is specifically useful in modern distributed systems with a large
number of components. In this paper, we propose a new communication and
execution model named the R(1)W(1) model in which each process can read and
write its own and neighbors' local variables in a single step. We propose
self-stabilizing distributed algorithms in the R(1)W(1) model for the problems
of maximal matching, minimal k-dominating set and maximal k-dependent set.
Finally, we propose an example transformer, based on randomized distance-two
local mutual exclusion, to simulate algorithms designed for the R(1)W(1) model
in the synchronous message passing model with synchronized clocks.
\\ ( https://arxiv.org/abs/2510.04644 ,  31kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03405
Date: Fri, 3 Oct 2025 18:01:57 GMT   (148kb)

Title: LegalSim: Multi-Agent Simulation of Legal Systems for Discovering
  Procedural Exploits
Authors: Sanket Badhe
Categories: cs.MA cs.AI cs.CR
Comments: 12 pages with 2 figures, accepted at the NLLP workshop at EMNLP 2025
\\
  We present LegalSim, a modular multi-agent simulation of adversarial legal
proceedings that explores how AI systems can exploit procedural weaknesses in
codified rules. Plaintiff and defendant agents choose from a constrained action
space (for example, discovery requests, motions, meet-and-confer, sanctions)
governed by a JSON rules engine, while a stochastic judge model with calibrated
grant rates, cost allocations, and sanction tendencies resolves outcomes. We
compare four policies: PPO, a contextual bandit with an LLM, a direct LLM
policy, and a hand-crafted heuristic; Instead of optimizing binary case
outcomes, agents are trained and evaluated using effective win rate and a
composite exploit score that combines opponent-cost inflation, calendar
pressure, settlement pressure at low merit, and a rule-compliance margin.
Across configurable regimes (e.g., bankruptcy stays, inter partes review, tax
procedures) and heterogeneous judges, we observe emergent ``exploit chains'',
such as cost-inflating discovery sequences and calendar-pressure tactics that
remain procedurally valid yet systemically harmful. Evaluation via cross-play
and Bradley-Terry ratings shows, PPO wins more often, the bandit is the most
consistently competitive across opponents, the LLM trails them, and the
heuristic is weakest. The results are stable in judge settings, and the
simulation reveals emergent exploit chains, motivating red-teaming of legal
rule systems in addition to model-level testing.
\\ ( https://arxiv.org/abs/2510.03405 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03534
Date: Fri, 3 Oct 2025 22:08:08 GMT   (4237kb)

Title: Long-Term Mapping of the Douro River Plume with Multi-Agent
  Reinforcement Learning
Authors: Nicol\`o Dal Fabbro, Milad Mesbahi, Renato Mendes, Jo\~ao Borges de
  Sousa, George J. Pappas
Categories: cs.MA cs.LG cs.SY eess.SY stat.ML
\\
  We study the problem of long-term (multiple days) mapping of a river plume
using multiple autonomous underwater vehicles (AUVs), focusing on the Douro
river representative use-case. We propose an energy - and communication -
efficient multi-agent reinforcement learning approach in which a central
coordinator intermittently communicates with the AUVs, collecting measurements
and issuing commands. Our approach integrates spatiotemporal Gaussian process
regression (GPR) with a multi-head Q-network controller that regulates
direction and speed for each AUV. Simulations using the Delft3D ocean model
demonstrate that our method consistently outperforms both single- and
multi-agent benchmarks, with scaling the number of agents both improving mean
squared error (MSE) and operational endurance. In some instances, our algorithm
demonstrates that doubling the number of AUVs can more than double endurance
while maintaining or improving accuracy, underscoring the benefits of
multi-agent coordination. Our learned policies generalize across unseen
seasonal regimes over different months and years, demonstrating promise for
future developments of data-driven long-term monitoring of dynamic plume
environments.
\\ ( https://arxiv.org/abs/2510.03534 ,  4237kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04192
Date: Sun, 5 Oct 2025 13:17:12 GMT   (2444kb)

Title: Cooperative Flexibility Exchange: Fair and Comfort-Aware Decentralized
  Resource Allocation
Authors: Rabiya Khalid and Evangelos Pournaras
Categories: cs.MA cs.AI
\\
  The growing electricity demand and increased use of smart appliances are
placing new pressures on power grids, making efficient energy management more
important than ever. The existing energy management systems often prioritize
system efficiency (balanced energy demand and supply) at the expense of user
comfort. This paper addresses this gap by proposing a novel decentralized
multi-agent coordination-based demand-side management system. The proposed
system enables individual agents to coordinate for demand-side energy
optimization while improving the user comfort and maintaining the system
efficiency. A key innovation of this work is the introduction of a slot
exchange mechanism, where agents first receive optimized appliance-level energy
consumption schedules and then coordinate with each other to adjust these
schedules through slot exchanges. This approach improves user comfort even when
agents show non-altruistic behaviour, and it scales well with large
populations. The system also promotes fairness by balancing satisfaction levels
across users. For performance evaluation, a real-world dataset is used, and the
results demonstrate that the proposed slot exchange mechanism increases user
comfort and fairness without raising system inefficiency cost, making it a
practical and scalable solution for future smart grids.
\\ ( https://arxiv.org/abs/2510.04192 ,  2444kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04271
Date: Sun, 5 Oct 2025 16:26:42 GMT   (4661kb)

Title: Small Fleet, Big Impact: Enhancing Shared Micromobility Efficiency
  through Minimal Autonomous Vehicle Deployment
Authors: Heng Tan, Hua Yan, Lucas Yang, Yu Yang
Categories: cs.MA
Comments: 10 pages, 11 figures, BuildSys 2025
\\
  Shared micromobility systems, such as electric scooters and bikes, have
gained widespread popularity as sustainable alternatives to traditional
transportation modes. However, these systems face persistent challenges due to
spatio-temporal demand fluctuations, often resulting in a mismatch between
vehicle supply and user demand. Existing shared micromobility vehicle
scheduling methods typically redistribute vehicles once or twice per day, which
makes them vulnerable to performance degradation under atypical conditions. In
this work, we design to augment existing micromobility scheduling methods by
integrating a small number of autonomous shared micromobility vehicles (ASMVs),
which possess self-rebalancing capabilities to dynamically adapt to real-time
demand. Specifically, we introduce SMART, a hierarchical reinforcement learning
framework that jointly optimizes high-level initial deployment and low-level
real-time rebalancing for ASMVs. We evaluate our framework based on real-world
e-scooter usage data from Chicago. Our experiment results show that our
framework is highly effective and possesses strong generalization capability,
allowing it to seamlessly integrate with existing vehicle scheduling methods
and significantly enhance overall micromobility service performance.
\\ ( https://arxiv.org/abs/2510.04271 ,  4661kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04303
Date: Sun, 5 Oct 2025 17:51:52 GMT   (16kb)

Title: Audit the Whisper: Detecting Steganographic Collusion in Multi-Agent
  LLMs
Authors: Om Tailor
Categories: cs.MA cs.AI
Comments: 8 pages, 0 figures
\\
  Multi-agent deployments of large language models (LLMs) are increasingly
embedded in market, allocation, and governance workflows, yet covert
coordination among agents can silently erode trust and social welfare. Existing
audits are dominated by heuristics that lack theoretical guarantees, struggle
to transfer across tasks, and seldom ship with the infrastructure needed for
independent replication. We introduce \emph{Audit the Whisper}, a
conference-grade research artifact that spans theory, benchmark design,
detection, and reproducibility. Our contributions are: (i) a channel-capacity
analysis showing how interventions such as paraphrase, rate limiting, and role
permutation impose quantifiable capacity penalties -- operationalized via
paired-run Kullback--Leibler diagnostics -- that tighten mutual-information
thresholds with finite-sample guarantees; (ii) \textsc{ColludeBench}-v0,
covering pricing, first-price auctions, and peer review with configurable
covert schemes, deterministic manifests, and reward instrumentation; and (iii)
a calibrated auditing pipeline that fuses cross-run mutual information,
permutation invariance, watermark variance, and fairness-aware acceptance bias,
each tuned to a \(10^{-3}\) false-positive budget. Across 600 audited runs
spanning 12 intervention conditions, the union meta-test attains TPR~$=1$ with
zero observed false alarms, while ablations surface the price-of-auditing
trade-off and highlight fairness-driven colluders invisible to MI alone. We
release regeneration scripts, seed-stamped manifests, and documentation so that
external auditors can reproduce every figure and extend the framework with
minimal effort.
\\ ( https://arxiv.org/abs/2510.04303 ,  16kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04368
Date: Sun, 5 Oct 2025 21:23:21 GMT   (72kb)

Title: NegotiationGym: Self-Optimizing Agents in a Multi-Agent Social
  Simulation Environment
Authors: Shashank Mangla, Chris Hokamp, Jack Boylan, Demian Gholipour
  Ghalandari, Yuuv Jauhari, Lauren Cassidy, Oisin Duffy
Categories: cs.MA cs.AI
Comments: SocialSim Workshop at COLM 2025
\\
  We design and implement NegotiationGym, an API and user interface for
configuring and running multi-agent social simulations focused upon negotiation
and cooperation. The NegotiationGym codebase offers a user-friendly,
configuration-driven API that enables easy design and customization of
simulation scenarios. Agent-level utility functions encode optimization
criteria for each agent, and agents can self-optimize by conducting multiple
interaction rounds with other agents, observing outcomes, and modifying their
strategies for future rounds.
\\ ( https://arxiv.org/abs/2510.04368 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04787
Date: Mon, 6 Oct 2025 13:08:55 GMT   (3432kb)

Title: Trade in Minutes! Rationality-Driven Agentic System for Quantitative
  Financial Trading
Authors: Zifan Song, Kaitao Song, Guosheng Hu, Ding Qi, Junyao Gao, Xiaohua
  Wang, Dongsheng Li, Cairong Zhao
Categories: cs.MA cs.AI
Comments: 16 pages, 6 figures
\\
  Recent advancements in large language models (LLMs) and agentic systems have
shown exceptional decision-making capabilities, revealing significant potential
for autonomic finance. Current financial trading agents predominantly simulate
anthropomorphic roles that inadvertently introduce emotional biases and rely on
peripheral information, while being constrained by the necessity for continuous
inference during deployment. In this paper, we pioneer the harmonization of
strategic depth in agents with the mechanical rationality essential for
quantitative trading. Consequently, we present TiMi (Trade in Minutes), a
rationality-driven multi-agent system that architecturally decouples strategy
development from minute-level deployment. TiMi leverages specialized LLM
capabilities of semantic analysis, code programming, and mathematical reasoning
within a comprehensive policy-optimization-deployment chain. Specifically, we
propose a two-tier analytical paradigm from macro patterns to micro
customization, layered programming design for trading bot implementation, and
closed-loop optimization driven by mathematical reflection. Extensive
evaluations across 200+ trading pairs in stock and cryptocurrency markets
empirically validate the efficacy of TiMi in stable profitability, action
efficiency, and risk control under volatile market dynamics.
\\ ( https://arxiv.org/abs/2510.04787 ,  3432kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:2510.03243 (*cross-listing*)
Date: Thu, 25 Sep 2025 07:26:38 GMT   (118kb)

Title: PARS: Low-Latency LLM Serving via Pairwise Learning-to-Rank
Authors: Yiheng Tao, Yihe Zhang, Matthew T. Dearing, Xin Wang, Yuping Fan,
  Zhiling Lan
Categories: cs.LG cs.AI cs.DC cs.PF
\\
  Efficient scheduling of LLM inference tasks is essential for achieving low
latency and high throughput, particularly with the growing use of
reasoning-capable LLMs. Traditional strategies like First-Come-First-Serve
(FCFS) often suffer from Head-of-Line (HOL) blocking, where long-running tasks
delay shorter ones queued behind them. In this paper, we introduce PARS, a
prompt-aware LLM task scheduler that improves serving efficiency by
approximating shortest-job-first (SJF) scheduling through pairwise ranking with
margin ranking loss. PARS focuses on impactful scheduling decisions and is
seamlessly integrated into the state-of-the-art LLM serving system vLLM. It
effectively predicts response-length-based task ordering, reducing latency with
minimal overhead. Extensive experiments across multiple LLMs and real-world
inference datasets show that PARS significantly improves performance, including
for reasoning workloads. Furthermore, our cross-model evaluations demonstrate
that the design generalizes well, enabling effective scheduling even when
predictors are trained on different LLMs.
\\ ( https://arxiv.org/abs/2510.03243 ,  118kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03244 (*cross-listing*)
Date: Thu, 25 Sep 2025 14:02:26 GMT   (3931kb)

Title: VIFO: Visual Feature Empowered Multivariate Time Series Forecasting with
  Cross-Modal Fusion
Authors: Yanlong Wang, Hang Yu, Jian Xu, Fei Ma, Hongkang Zhang, Tongtong Feng,
  Zijian Zhang, Shao-Lun Huang, Danny Dongning Sun, Xiao-Ping Zhang
Categories: cs.LG cs.AI cs.CV
\\
  Large time series foundation models often adopt channel-independent
architectures to handle varying data dimensions, but this design ignores
crucial cross-channel dependencies. Concurrently, existing multimodal
approaches have not fully exploited the power of large vision models (LVMs) to
interpret spatiotemporal data. Additionally, there remains significant
unexplored potential in leveraging the advantages of information extraction
from different modalities to enhance time series forecasting performance. To
address these gaps, we propose the VIFO, a cross-modal forecasting model. VIFO
uniquely renders multivariate time series into image, enabling pre-trained LVM
to extract complex cross-channel patterns that are invisible to
channel-independent models. These visual features are then aligned and fused
with representations from the time series modality. By freezing the LVM and
training only 7.45% of its parameters, VIFO achieves competitive performance on
multiple benchmarks, offering an efficient and effective solution for capturing
cross-variable relationships in
\\ ( https://arxiv.org/abs/2510.03244 ,  3931kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03245 (*cross-listing*)
Date: Thu, 25 Sep 2025 15:00:44 GMT   (10024kb)

Title: Frequency-Aware Model Parameter Explorer: A new attribution method for
  improving explainability
Authors: Ali Yavari, Alireza Mohamadi, Elham Beydaghi, Rainer A. Leitgeb
Categories: cs.LG cs.AI cs.CV
Comments: Preprint
\\
  Ensuring the reliability of deep neural networks (DNNs) in the presence of
real world noise and intentional perturbations remains a significant challenge.
To address this, attribution methods have been proposed, though their efficacy
remains suboptimal and necessitates further refinement. In this paper, we
propose a novel category of transferable adversarial attacks, called
transferable frequency-aware attacks, enabling frequency-aware exploration via
both high-and low-frequency components. Based on this type of attacks, we also
propose a novel attribution method, named Frequency-Aware Model Parameter
Explorer (FAMPE), which improves the explainability for DNNs. Relative to the
current state-of-the-art method AttEXplore, our FAMPE attains an average gain
of 13.02% in Insertion Score, thereby outperforming existing approaches.
Through detailed ablation studies, we also investigate the role of both high-
and low-frequency components in explainability.
\\ ( https://arxiv.org/abs/2510.03245 ,  10024kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03246 (*cross-listing*)
Date: Thu, 25 Sep 2025 19:16:50 GMT   (278kb)

Title: StructPrune: Structured Global Pruning asymptotics with
  $\mathcal{O}(\sqrt{N})$ GPU Memory
Authors: Xinyuan Song, Guangji Bai, Liang Zhao
Categories: cs.LG cs.AI
\\
  Pruning is critical for scaling large language models (LLMs). Global pruning
achieves strong performance but requires $\mathcal{O}(N)$ memory, which is
infeasible for billion-parameter models. Local pruning reduces GPU memory usage
to that of a single layer by pruning layers independently, but it neglects
inter-layer dependencies and often leads to suboptimal performance in
high-sparsity regimes. Unlike unstructured pruning, structured pruning produces
regular sparsity patterns that align well with GPU kernels and library
optimizations, making it more hardware-efficient. However, structured pruning
typically relies on global pruning, since structured patterns are more prone to
severe performance degradation under local optimization. To jointly achieve
structured pruning and the memory efficiency of local pruning, we propose a
divide-and-conquer strategy that decomposes the global pruning problem into
coordinated subproblems across different modules, each of which fits within
limited GPU memory. Building on this idea, we design \textbf{STRUPRUNE}, an
ADMM-based framework that integrates structured sparsity into the pruning
process, combining the memory efficiency of local pruning with the hardware
compatibility of structured methods. We derive a closed-form analytical
solution for structured pruning masks that provides an explicit rule for
layer-wise sparsity allocation, and further develop an energy-based asymptotic
framework yielding a softmax-form allocation scheme that simplifies
optimization while adapting to heterogeneous layer importance. Experiments
demonstrate that STRUPRUNE matches the perplexity of global structured pruning
while reducing memory cost from $\mathcal{O}(N)$ to $\mathcal{O}(\sqrt{N})$,
enabling practical deployment at the billion-parameter scale.
\\ ( https://arxiv.org/abs/2510.03246 ,  278kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03247 (*cross-listing*)
Date: Thu, 25 Sep 2025 23:08:03 GMT   (180kb)

Title: Towards Multimodal Active Learning: Efficient Learning with Limited
  Paired Data
Authors: Jiancheng Zhang, Yinglun Zhu
Categories: cs.LG cs.AI
\\
  Active learning (AL) is a principled strategy to reduce annotation cost in
data-hungry deep learning. However, existing AL algorithms focus almost
exclusively on unimodal data, overlooking the substantial annotation burden in
multimodal learning. We introduce the first framework for multimodal active
learning with unaligned data, where the learner must actively acquire
cross-modal alignments rather than labels on pre-aligned pairs. This setting
captures the practical bottleneck in modern multimodal pipelines such as CLIP
and SigLIP, where unimodal features are easy to obtain but high-quality
alignment is costly. We develop a new algorithm that combines uncertainty and
diversity principles in a modality-aware design, achieves linear-time
acquisition, and applies seamlessly to both pool-based and streaming-based
settings. Extensive experiments on benchmark datasets demonstrate that our
approach consistently reduces multimodal annotation cost while preserving
performance; for instance, on the ColorSwap dataset it cuts annotation
requirements by up to $40\%$ without loss in accuracy.
\\ ( https://arxiv.org/abs/2510.03247 ,  180kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03248 (*cross-listing*)
Date: Fri, 26 Sep 2025 01:48:27 GMT   (5017kb)

Title: Real-Time Brain Biomechanics Prediction with Neural Operators: Toward
  Clinically Deployable Traumatic Brain Injury Models
Authors: Anusha Agarwal, Dibakar Roy Sarkar and Somdatta Goswami
Categories: cs.LG cs.AI cs.CV physics.med-ph
\\
  Traumatic brain injury (TBI) remains a major public health concern, with over
69 million cases annually worldwide. Finite element (FE) models offer
high-fidelity predictions of brain deformation but are computationally
expensive, requiring hours per simulation and limiting their clinical utility
for rapid decision-making. This study benchmarks state-of-the-art neural
operator (NO) architectures for rapid, patient-specific prediction of brain
displacement fields, aiming to enable real-time TBI modeling in clinical and
translational settings. We formulated TBI modeling as an operator learning
problem, mapping subject-specific anatomical MRI, magnetic resonance
elastography (MRE) stiffness maps, and demographic features to full-field 3D
brain displacement predictions. Four architectures - Fourier Neural Operator
(FNO), Factorized FNO (F-FNO), Multi-Grid FNO (MG-FNO), and Deep Operator
Network (DeepONet) were trained and evaluated on 249 MRE datasets across
physiologically relevant frequencies (20 - 90 Hz). MG-FNO achieved the highest
accuracy (MSE = 0.0023, 94.3\% spatial fidelity) and preserved fine-scale
features, while F-FNO converged 2$\times$ faster than standard FNO. DeepONet
offered the fastest inference (14.5 iterations/s) with a 7$\times$
computational speed-up over MG-FNO, suggesting utility for embedded or edge
computing applications. All NOs reduced computation time from hours to
milliseconds without sacrificing anatomical realism. NOs provide an efficient,
resolution-invariant approach for predicting brain deformation, opening the
door to real-time, patient-specific TBI risk assessment, clinical triage
support, and optimization of protective equipment. These results highlight the
potential for NO-based digital twins of the human brain, enabling scalable,
on-demand biomechanical modeling in both clinical and population health
contexts.
\\ ( https://arxiv.org/abs/2510.03248 ,  5017kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03251 (*cross-listing*)
Date: Fri, 26 Sep 2025 05:53:48 GMT   (17026kb)

Title: Numerion: A Multi-Hypercomplex Model for Time Series Forecasting
Authors: Hanzhong Cao, Wenbo Yan and Ying Tan
Categories: cs.LG cs.AI
\\
  Many methods aim to enhance time series forecasting by decomposing the series
through intricate model structures and prior knowledge, yet they are inevitably
limited by computational complexity and the robustness of the assumptions. Our
research uncovers that in the complex domain and higher-order hypercomplex
spaces, the characteristic frequencies of time series naturally decrease.
Leveraging this insight, we propose Numerion, a time series forecasting model
based on multiple hypercomplex spaces. Specifically, grounded in theoretical
support, we generalize linear layers and activation functions to hypercomplex
spaces of arbitrary power-of-two dimensions and introduce a novel
Real-Hypercomplex-Real Domain Multi-Layer Perceptron (RHR-MLP) architecture.
Numerion utilizes multiple RHR-MLPs to map time series into hypercomplex spaces
of varying dimensions, naturally decomposing and independently modeling the
series, and adaptively fuses the latent patterns exhibited in different spaces
through a dynamic fusion mechanism. Experiments validate the model`s
performance, achieving state-of-the-art results on multiple public datasets.
Visualizations and quantitative analyses comprehensively demonstrate the
ability of multi-dimensional RHR-MLPs to naturally decompose time series and
reveal the tendency of higher dimensional hypercomplex spaces to capture lower
frequency features.
\\ ( https://arxiv.org/abs/2510.03251 ,  17026kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03252 (*cross-listing*)
Date: Fri, 26 Sep 2025 07:32:43 GMT   (27880kb)

Title: Universal Multi-Domain Translation via Diffusion Routers
Authors: Duc Kieu, Kien Do, Tuan Hoang, Thao Minh Le, Tung Kieu, Dang Nguyen,
  Thin Nguyen
Categories: cs.LG cs.AI cs.CV
\\
  Multi-domain translation (MDT) aims to learn translations between multiple
domains, yet existing approaches either require fully aligned tuples or can
only handle domain pairs seen in training, limiting their practicality and
excluding many cross-domain mappings. We introduce universal MDT (UMDT), a
generalization of MDT that seeks to translate between any pair of $K$ domains
using only $K-1$ paired datasets with a central domain. To tackle this problem,
we propose Diffusion Router (DR), a unified diffusion-based framework that
models all central$\leftrightarrow$non-central translations with a single noise
predictor conditioned on the source and target domain labels. DR enables
indirect non-central translations by routing through the central domain. We
further introduce a novel scalable learning strategy with a variational-bound
objective and an efficient Tweedie refinement procedure to support direct
non-central mappings. Through evaluation on three large-scale UMDT benchmarks,
DR achieves state-of-the-art results for both indirect and direct translations,
while lowering sampling cost and unlocking novel tasks such as
sketch$\leftrightarrow$segmentation. These results establish DR as a scalable
and versatile framework for universal translation across multiple domains.
\\ ( https://arxiv.org/abs/2510.03252 ,  27880kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03253 (*cross-listing*)
Date: Fri, 26 Sep 2025 08:43:39 GMT   (836kb)

Title: Solving the Granularity Mismatch: Hierarchical Preference Learning for
  Long-Horizon LLM Agents
Authors: Heyang Gao, Zexu Sun, Erxue Min, Hengyi Cai, Shuaiqiang Wang, Dawei
  Yin, Xu Chen
Categories: cs.LG cs.AI
Comments: Preprint
ACM-class: I.2.7
\\
  Large Language Models (LLMs) as autonomous agents are increasingly tasked
with solving complex, long-horizon problems. Aligning these agents via
preference-based offline methods like Direct Preference Optimization (DPO) is a
promising direction, yet it faces a critical granularity mismatch.
Trajectory-level DPO provides a signal that is too coarse for precise credit
assignment, while step-level DPO is often too myopic to capture the value of
multi-step behaviors. To resolve this challenge, we introduce Hierarchical
Preference Learning (HPL), a hierarchical framework that optimizes LLM agents
by leveraging preference signals at multiple, synergistic granularities. While
HPL incorporates trajectory- and step-level DPO for global and local policy
stability, its core innovation lies in group-level preference optimization
guided by a dual-layer curriculum. Our approach first decomposes expert
trajectories into semantically coherent action groups and then generates
contrasting suboptimal groups to enable preference learning at a fine-grained,
sub-task level. Then, instead of treating all preference pairs equally, HPL
introduces a curriculum scheduler that organizes the learning process from
simple to complex. This curriculum is structured along two axes: the group
length, representing sub-task complexity, and the sample difficulty, defined by
the reward gap between preferred and dispreferred action groups. Experiments on
three challenging agent benchmarks show that HPL outperforms existing
state-of-the-art methods. Our analyses demonstrate that the hierarchical DPO
loss effectively integrates preference signals across multiple granularities,
while the dual-layer curriculum is crucial for enabling the agent to solve a
wide range of tasks, from simple behaviors to complex multi-step sequences.
\\ ( https://arxiv.org/abs/2510.03253 ,  836kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03255 (*cross-listing*)
Date: Fri, 26 Sep 2025 09:25:16 GMT   (3396kb)

Title: SciTS: Scientific Time Series Understanding and Generation with LLMs
Authors: Wen Wu, Ziyang Zhang, Liwei Liu, Xuenan Xu, Junlin Liu, Ke Fan, Qitan
  Lv, Jimin Zhuang, Chen Zhang, Zheqi Yuan, Siyuan Hou, Tianyi Lin, Kai Chen,
  Bowen Zhou, Chao Zhang
Categories: cs.LG cs.AI
\\
  The scientific reasoning ability of large language models (LLMs) has recently
attracted significant attention. Time series, as a fundamental modality in
scientific data, presents unique challenges that are often overlooked in
current multimodal LLMs, which either encode numerical sequences as text or
convert them into images. Such approaches may be insufficient for comprehensive
scientific time series understanding and generation. Existing unified time
series models typically specialise in either forecasting or analysis, and their
effectiveness on non-periodic, heterogeneous scientific signals remains
unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12
scientific domains and 43 tasks, with over 50k+ instances, both univariate and
multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz
in frequency. We benchmark 17 models, including text-only LLMs, multimodal
LLMs, and unified time series models, and find that general-purpose LLMs
exhibit stronger generalisability than specialised time series models, while
representing time series as text or images limits their performance due to
excessively long sequences and loss of numerical precision, respectively. We
then introduce TimeOmni, a framework that equips LLMs with the ability to
understand and generate time series while remaining compatible with
general-purpose LLM training. This work fills a gap in both dedicated
benchmarks and modelling frameworks for scientific time series, paving the way
for LLMs to understand and generate complex temporal scientific data.
\\ ( https://arxiv.org/abs/2510.03255 ,  3396kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03257 (*cross-listing*)
Date: Fri, 26 Sep 2025 13:15:18 GMT   (4055kb)

Title: Triple-BERT: Do We Really Need MARL for Order Dispatch on Ride-Sharing
  Platforms?
Authors: Zijian Zhao, Sen Li
Categories: cs.LG cs.AI cs.MA
\\
  On-demand ride-sharing platforms, such as Uber and Lyft, face the intricate
real-time challenge of bundling and matching passengers-each with distinct
origins and destinations-to available vehicles, all while navigating
significant system uncertainties. Due to the extensive observation space
arising from the large number of drivers and orders, order dispatching, though
fundamentally a centralized task, is often addressed using Multi-Agent
Reinforcement Learning (MARL). However, independent MARL methods fail to
capture global information and exhibit poor cooperation among workers, while
Centralized Training Decentralized Execution (CTDE) MARL methods suffer from
the curse of dimensionality. To overcome these challenges, we propose
Triple-BERT, a centralized Single Agent Reinforcement Learning (MARL) method
designed specifically for large-scale order dispatching on ride-sharing
platforms. Built on a variant TD3, our approach addresses the vast action space
through an action decomposition strategy that breaks down the joint action
probability into individual driver action probabilities. To handle the
extensive observation space, we introduce a novel BERT-based network, where
parameter reuse mitigates parameter growth as the number of drivers and orders
increases, and the attention mechanism effectively captures the complex
relationships among the large pool of driver and orders. We validate our method
using a real-world ride-hailing dataset from Manhattan. Triple-BERT achieves
approximately an 11.95% improvement over current state-of-the-art methods, with
a 4.26% increase in served orders and a 22.25% reduction in pickup times. Our
code, trained model parameters, and processed data are publicly available at
the repository https://github.com/RS2002/Triple-BERT .
\\ ( https://arxiv.org/abs/2510.03257 ,  4055kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03258 (*cross-listing*)
Date: Fri, 26 Sep 2025 13:34:07 GMT   (1202kb)

Title: POEM: Explore Unexplored Reliable Samples to Enhance Test-Time
  Adaptation
Authors: Chang'an Yi, Xiaohui Deng, Shuaicheng Niu, and Yan Zhou
Categories: cs.LG cs.AI
Comments: 11pages,6 figures
\\
  Test-time adaptation (TTA) aims to transfer knowledge from a source model to
unknown test data with potential distribution shifts in an online manner. Many
existing TTA methods rely on entropy as a confidence metric to optimize the
model. However, these approaches are sensitive to the predefined entropy
threshold, influencing which samples are chosen for model adaptation.
Consequently, potentially reliable target samples are often overlooked and
underutilized. For instance, a sample's entropy might slightly exceed the
threshold initially, but fall below it after the model is updated. Such samples
can provide stable supervised information and offer a normal range of gradients
to guide model adaptation. In this paper, we propose a general approach,
\underline{POEM}, to promote TTA via ex\underline{\textbf{p}}loring the
previously unexpl\underline{\textbf{o}}red reliabl\underline{\textbf{e}}
sa\underline{\textbf{m}}ples. Additionally, we introduce an extra Adapt Branch
network to strike a balance between extracting domain-agnostic representations
and achieving high performance on target data. Comprehensive experiments across
multiple architectures demonstrate that POEM consistently outperforms existing
TTA methods in both challenging scenarios and real-world domain shifts, while
remaining computationally efficient. The effectiveness of POEM is evaluated
through extensive analyses and thorough ablation studies. Moreover, the core
idea behind POEM can be employed as an augmentation strategy to boost the
performance of existing TTA approaches. The source code is publicly available
at \emph{https://github.com/ycarobot/POEM}
\\ ( https://arxiv.org/abs/2510.03258 ,  1202kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03259 (*cross-listing*)
Date: Fri, 26 Sep 2025 14:05:48 GMT   (2448kb)

Title: Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement
  Learning
Authors: Yoonjeon Kim, Doohyuk Jang, Eunho Yang
Categories: cs.LG cs.AI
Comments: preprint
\\
  Recent studies on reasoning models explore the meta-awareness of language
models, the ability to know how to think by itself. We argue that large
reasoning models lack this meta-awareness property by proving severe
misalignment between true rollouts and predicted meta information. We posit
that aligning meta-prediction with true rollouts will lead to significant
performance gains. To verify this hypothesis, we design a training pipeline
that boosts Meta-Awareness via Self-Alignment (MASA), and prove that enhanced
meta-awareness directly translates to improved accuracy. Unlike existing
meta-cognitive reasoning models, our method does not require external training
sources but leverages self-generated signals to train meta-awareness. Moreover,
our method enables efficient training by i) filtering out zero-variance prompts
that are either trivial or unsolvable and ii) cutting off lengthy rollouts when
they are unlikely to lead to correct answers. The results are inspiring: our
strategy yields significant improvements in both accuracy and training
efficiency on in-domain tasks and shows strong generalization to out-of-domain
benchmarks. More specifically, our method can speed up GRPO training by over
1.28x to reach the same performance, and achieve a 19.3% gain in accuracy on
AIME25, and a 6.2 % average gain over six mathematics benchmarks. Training with
meta-cognitive guidance enhances out-of-domain generalization, giving a 3.87 %
boost on GPQA-Diamond and a 2.08 % overall accuracy gain across 13 benchmarks
spanning logical, scientific, and coding domains.
\\ ( https://arxiv.org/abs/2510.03259 ,  2448kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03260 (*cross-listing*)
Date: Fri, 26 Sep 2025 15:14:36 GMT   (3253kb)

Title: Semantic-Inductive Attribute Selection for Zero-Shot Learning
Authors: Juan Jose Herrera-Aranda and Guillermo Gomez-Trenado and Francisco
  Herrera and Isaac Triguero
Categories: cs.LG cs.AI
Comments: 26 pages, 9 figures, code available at
  https://kiedie.github.io/Semantic-Inductive-Attribute-Selection-for-Zero-Shot-Learning/
\\
  Zero-Shot Learning is an important paradigm within General-Purpose Artificial
Intelligence Systems, particularly in those that operate in open-world
scenarios where systems must adapt to new tasks dynamically. Semantic spaces
play a pivotal role as they bridge seen and unseen classes, but whether
human-annotated or generated by a machine learning model, they often contain
noisy, redundant, or irrelevant attributes that hinder performance. To address
this, we introduce a partitioning scheme that simulates unseen conditions in an
inductive setting (which is the most challenging), allowing attribute relevance
to be assessed without access to semantic information from unseen classes.
Within this framework, we study two complementary feature-selection strategies
and assess their generalisation. The first adapts embedded feature selection to
the particular demands of ZSL, turning model-driven rankings into meaningful
semantic pruning; the second leverages evolutionary computation to directly
explore the space of attribute subsets more broadly. Experiments on five
benchmark datasets (AWA2, CUB, SUN, aPY, FLO) show that both methods
consistently improve accuracy on unseen classes by reducing redundancy, but in
complementary ways: RFS is efficient and competitive though dependent on
critical hyperparameters, whereas GA is more costly yet explores the search
space more broadly and avoids such dependence. These results confirm that
semantic spaces are inherently redundant and highlight the proposed
partitioning scheme as an effective tool to refine them under inductive
conditions.
\\ ( https://arxiv.org/abs/2510.03260 ,  3253kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03262 (*cross-listing*)
Date: Fri, 26 Sep 2025 18:44:03 GMT   (36759kb)

Title: Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from
  Orthogonal Monte Carlo Dropout
Authors: Andi Zhang, Xuan Ding, Haofan Wang, Steven McDonagh, Samuel Kaski
Categories: cs.LG cs.AI cs.CV
\\
  We propose Orthogonal Monte Carlo Dropout, a mechanism that enforces strict
orthogonality when combining sparse semantic vectors without extra time
complexity. LoRA, a popular fine-tuning method for large models, typically
trains a module to represent a specific concept such as an object or a style.
When multiple LoRAs are merged, for example to generate an object in a
particular style, their semantic vectors may interfere with each other. Our
method guarantees, at the theoretical and runtime levels, that merged LoRAs
remain orthogonal and thus free from direct interference. However, empirical
analysis reveals that such orthogonality does not lead to the semantic
disentanglement or compositionality highlighted in prior work on compositional
adaptation. This finding suggests that inter-LoRA orthogonality alone may be
insufficient for achieving true semantic compositionality, prompting a
re-examination of its role in adapter merging.
\\ ( https://arxiv.org/abs/2510.03262 ,  36759kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03263 (*cross-listing*)
Date: Fri, 26 Sep 2025 19:11:01 GMT   (14772kb)

Title: Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned
  Models
Authors: Agnieszka Polowczyk, Alicja Polowczyk, Joanna Waczy\'nska, Piotr
  Borycki, Przemys{\l}aw Spurek
Categories: cs.LG cs.AI
\\
  The impressive capability of modern text-to-image models to generate
realistic visuals has come with a serious drawback: they can be misused to
create harmful, deceptive or unlawful content. This has accelerated the push
for machine unlearning. This new field seeks to selectively remove specific
knowledge from a model's training data without causing a drop in its overall
performance. However, it turns out that actually forgetting a given concept is
an extremely difficult task. Models exposed to attacks using adversarial
prompts show the ability to generate so-called unlearned concepts, which can be
not only harmful but also illegal. In this paper, we present considerations
regarding the ability of models to forget and recall knowledge, introducing the
Memory Self-Regeneration task. Furthermore, we present MemoRa strategy, which
we consider to be a regenerative approach supporting the effective recovery of
previously lost knowledge. Moreover, we propose that robustness in knowledge
retrieval is a crucial yet underexplored evaluation measure for developing more
robust and effective unlearning techniques. Finally, we demonstrate that
forgetting occurs in two distinct ways: short-term, where concepts can be
quickly recalled, and long-term, where recovery is more challenging.
\\ ( https://arxiv.org/abs/2510.03263 ,  14772kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03264 (*cross-listing*)
Date: Fri, 26 Sep 2025 20:08:51 GMT   (875kb)

Title: Front-Loading Reasoning: The Synergy between Pretraining and
  Post-Training Data
Authors: Syeda Nahida Akter, Shrimai Prabhumoye, Eric Nyberg, Mostofa Patwary,
  Mohammad Shoeybi, Yejin Choi, Bryan Catanzaro
Categories: cs.LG cs.AI
\\
  The prevailing paradigm for enhancing the reasoning abilities of LLMs
revolves around post-training on high-quality, reasoning-intensive data. While
emerging literature suggests that reasoning data is increasingly incorporated
also during the mid-training stage-a practice that is relatively more
proprietary and less openly characterized-the role of such data in pretraining
remains unclear. In particular, due to the opaqueness of pretraining corpora in
most frontier models, the effect of reasoning data introduced at different
phases of pre- and/or post-training is relatively less reported in the
scientific literature. This raises several important questions: Is adding
reasoning data earlier during pretraining any better than introducing it during
post-training? Could earlier inclusion risk overfitting and harm
generalization, or instead establish durable foundations that later fine-tuning
cannot recover? We conduct the first systematic study of how reasoning
data-varying in scale, diversity, and quality-affects LLM performance when
introduced at different stages of training. We find that front-loading
reasoning data into pretraining is critical (19% avg gain), establishing
foundational capabilities that cannot be fully replicated by later-stage SFT,
even with more data. We uncover an asymmetric principle for optimal data
allocation: pretraining benefits most from broad diversity in reasoning
patterns (11% avg gain), while SFT is more sensitive to data quality (15% avg
gain). We show that high-quality pretraining data has latent effects, activated
only after SFT, and that naively scaling SFT data can be detrimental, washing
away the benefits of early reasoning injection. Our results challenge the
conventional separation of language modeling and reasoning, providing a
principled guide for strategically allocating data across the entire training
pipeline to build more capable models.
\\ ( https://arxiv.org/abs/2510.03264 ,  875kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03265 (*cross-listing*)
Date: Fri, 26 Sep 2025 20:39:52 GMT   (5137kb)

Title: MindCraft: How Concept Trees Take Shape In Deep Models
Authors: Bowei Tian, Yexiao He, Wanghao Ye, Ziyao Wang, Meng Liu, Ang Li
Categories: cs.LG cs.AI
\\
  Large-scale foundation models demonstrate strong performance across language,
vision, and reasoning tasks. However, how they internally structure and
stabilize concepts remains elusive. Inspired by causal inference, we introduce
the MindCraft framework built upon Concept Trees. By applying spectral
decomposition at each layer and linking principal directions into branching
Concept Paths, Concept Trees reconstruct the hierarchical emergence of
concepts, revealing exactly when they diverge from shared representations into
linearly separable subspaces. Empirical evaluations across diverse scenarios
across disciplines, including medical diagnosis, physics reasoning, and
political decision-making, show that Concept Trees recover semantic
hierarchies, disentangle latent concepts, and can be widely applied across
multiple domains. The Concept Tree establishes a widely applicable and powerful
framework that enables in-depth analysis of conceptual representations in deep
models, marking a significant step forward in the foundation of interpretable
AI.
\\ ( https://arxiv.org/abs/2510.03265 ,  5137kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03267 (*cross-listing*)
Date: Sat, 27 Sep 2025 03:01:48 GMT   (1531kb)

Title: PT$^2$-LLM: Post-Training Ternarization for Large Language Models
Authors: Xianglong Yan, Chengzhu Bao, Zhiteng Li, Tianao Zhang, Kaicheng Yang,
  Haotong Qin, Ruobing Xie, Xingwu Sun, Yulun Zhang
Categories: cs.LG cs.AI
\\
  Large Language Models (LLMs) have shown impressive capabilities across
diverse tasks, but their large memory and compute demands hinder deployment.
Ternarization has gained attention as a promising compression technique,
delivering substantial size reduction and high computational efficiency.
However, its potential in the post-training quantization (PTQ) setting remains
underexplored, due to the challenge of training-free parameter optimization and
the quantization difficulty posed by outliers and dispersed weights. To address
these issues, we propose PT$^2$-LLM, a post-training ternarization framework
tailored for LLMs. At its core is an Asymmetric Ternary Quantizer equipped with
a two-stage refinement pipeline: (1) Iterative Ternary Fitting (ITF), which
alternates between optimal ternary grid construction and flexible rounding to
minimize quantization error, and (2) Activation-aware Grid Alignment (AGA),
which further refines the ternary grid to better match full-precision outputs.
In addition, we propose a plug-and-play Structural Similarity-based Reordering
(SSR) strategy that leverages inter-column structural similarity to ease
quantization and mitigate outlier effects, further enhancing overall
performance. Extensive experiments demonstrate that PT$^2$-LLM delivers
competitive performance against state-of-the-art (SOTA) 2-bit PTQ methods with
lower memory cost, while also accelerating both prefill and decoding to achieve
end-to-end speedup. The code and models will be available at
https://github.com/XIANGLONGYAN/PT2-LLM.
\\ ( https://arxiv.org/abs/2510.03267 ,  1531kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03268 (*cross-listing*)
Date: Sat, 27 Sep 2025 04:21:00 GMT   (3777kb)

Title: Decrypt Modality Gap in Multimodal Contrastive Learning: From Convergent
  Representation to Pair Alignment
Authors: Lingjie Yi, Raphael Douady, Chao Chen
Categories: cs.LG cs.AI
\\
  Multimodal contrastive learning (MCL) aims to embed data from different
modalities in a shared embedding space. However, empirical evidence shows that
representations from different modalities occupy completely separate regions of
embedding space, a phenomenon referred to as the modality gap. Moreover,
experimental findings on how the size of the modality gap influences downstream
performance are inconsistent. These observations raise two key questions: (1)
What causes the modality gap? (2) How does it affect downstream tasks? To
address these questions, this paper introduces the first theoretical framework
for analyzing the convergent optimal representations of MCL and the modality
alignment when training is optimized. Specifically, we prove that without any
constraint or under the cone constraint, the modality gap converges to zero.
Under the subspace constraint (i.e., representations of two modalities fall
into two distinct hyperplanes due to dimension collapse), the modality gap
converges to the smallest angle between the two hyperplanes. This result
identifies \emph{dimension collapse} as the fundamental origin of the modality
gap. Furthermore, our theorems demonstrate that paired samples cannot be
perfectly aligned under the subspace constraint. The modality gap influences
downstream performance by affecting the alignment between sample pairs. We
prove that, in this case, perfect alignment between two modalities can still be
achieved via two ways: hyperplane rotation and shared space projection.
\\ ( https://arxiv.org/abs/2510.03268 ,  3777kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03269 (*cross-listing*)
Date: Sat, 27 Sep 2025 04:54:59 GMT   (235kb)

Title: General Exploratory Bonus for Optimistic Exploration in RLHF
Authors: Wendi Li, Changdae Oh, Yixuan Li
Categories: cs.LG cs.AI cs.CL
\\
  Optimistic exploration is central to improving sample efficiency in
reinforcement learning with human feedback, yet existing exploratory bonus
methods to incentivize exploration often fail to realize optimism. We provide a
theoretical analysis showing that current formulations, under KL or
$\alpha$-divergence regularization, unintentionally bias exploration toward
high-probability regions of the reference model, thereby reinforcing
conservative behavior instead of promoting discovery of uncertain regions. To
address this pitfall, we introduce the General Exploratory Bonus (GEB), a novel
theoretical framework that provably satisfies the optimism principle. GEB
counteracts divergence-induced bias via reference-dependent reward regulation
and unifies prior heuristic bonuses as special cases, while extending naturally
across the full $\alpha$-divergence family. Empirically, GEB consistently
outperforms baselines on alignment tasks across multiple divergence settings
and large language model backbones. These results demonstrate that GEB offers
both a principled and practical solution for optimistic exploration in RLHF.
\\ ( https://arxiv.org/abs/2510.03269 ,  235kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03270 (*cross-listing*)
Date: Sat, 27 Sep 2025 05:41:55 GMT   (301kb)

Title: CoDA: Coding LM via Diffusion Adaptation
Authors: Haolin Chen, Shiyu Wang, Can Qin, Bo Pang, Zuxin Liu, Jielin Qiu,
  Jianguo Zhang, Yingbo Zhou, Zeyuan Chen, Ran Xu, Shelby Heinecke, Silvio
  Savarese, Caiming Xiong, Huan Wang, Weiran Yao
Categories: cs.LG cs.AI
ACM-class: I.2.7
\\
  Diffusion language models promise bidirectional context and infilling
capabilities that autoregressive coders lack, yet practical systems remain
heavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU
with a fully open-source training pipeline. CoDA pairs large-scale diffusion
pre-training with code-centric mid-training and instruction tuning, enabling
confidence-guided sampling that keeps inference latency competitive. On
Humaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses
diffusion models up to 7B parameters. Our release includes model checkpoints,
evaluation harnesses, and TPU training pipelines to accelerate research on
lightweight diffusion-based coding assistants.
\\ ( https://arxiv.org/abs/2510.03270 ,  301kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03271 (*cross-listing*)
Date: Sat, 27 Sep 2025 07:42:54 GMT   (5612kb)

Title: Decision Potential Surface: A Theoretical and Practical Approximation of
  LLM's Decision Boundary
Authors: Zi Liang and Zhiyao Wu and Haoyang Shang and Yulin Jin and Qingqing Ye
  and Huadi Zheng and Peizhao Hu and Haibo Hu
Categories: cs.LG cs.AI
Comments: Source code: https://github.com/liangzid/DPS
\\
  Decision boundary, the subspace of inputs where a machine learning model
assigns equal classification probabilities to two classes, is pivotal in
revealing core model properties and interpreting behaviors. While analyzing the
decision boundary of large language models (LLMs) has raised increasing
attention recently, constructing it for mainstream LLMs remains computationally
infeasible due to the enormous vocabulary-sequence sizes and the
auto-regressive nature of LLMs. To address this issue, in this paper we propose
Decision Potential Surface (DPS), a new notion for analyzing LLM decision
boundary. DPS is defined on the confidences in distinguishing different
sampling sequences for each input, which naturally captures the potential of
decision boundary. We prove that the zero-height isohypse in DPS is equivalent
to the decision boundary of an LLM, with enclosed regions representing decision
regions. By leveraging DPS, for the first time in the literature, we propose an
approximate decision boundary construction algorithm, namely $K$-DPS, which
only requires K-finite times of sequence sampling to approximate an LLM's
decision boundary with negligible error. We theoretically derive the upper
bounds for the absolute error, expected error, and the error concentration
between K-DPS and the ideal DPS, demonstrating that such errors can be
trade-off with sampling times. Our results are empirically validated by
extensive experiments across various LLMs and corpora.
\\ ( https://arxiv.org/abs/2510.03271 ,  5612kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03272 (*cross-listing*)
Date: Sat, 27 Sep 2025 08:58:47 GMT   (8006kb)

Title: PDE-Transformer: A Continuous Dynamical Systems Approach to Sequence
  Modeling
Authors: Yukun Zhang, Xueqing Zhou
Categories: cs.LG cs.AI
\\
  The Transformer architecture has revolutionized artificial intelligence, yet
a principled theoretical understanding of its internal mechanisms remains
elusive. This paper introduces a novel analytical framework that
reconceptualizes the Transformer's discrete, layered structure as a continuous
spatiotemporal dynamical system governed by a master Partial Differential
Equation (PDE). Within this paradigm, we map core architectural components to
distinct mathematical operators: self-attention as a non-local interaction, the
feed-forward network as a local reaction, and, critically, residual connections
and layer normalization as indispensable stabilization mechanisms. We do not
propose a new model, but rather employ the PDE system as a theoretical probe to
analyze the mathematical necessity of these components. By comparing a standard
Transformer with a PDE simulator that lacks explicit stabilizers, our
experiments provide compelling empirical evidence for our central thesis. We
demonstrate that without residual connections, the system suffers from
catastrophic representational drift, while the absence of layer normalization
leads to unstable, explosive training dynamics. Our findings reveal that these
seemingly heuristic "tricks" are, in fact, fundamental mathematical stabilizers
required to tame an otherwise powerful but inherently unstable continuous
system. This work offers a first-principles explanation for the Transformer's
design and establishes a new paradigm for analyzing deep neural networks
through the lens of continuous dynamics.
\\ ( https://arxiv.org/abs/2510.03272 ,  8006kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03273 (*cross-listing*)
Date: Sat, 27 Sep 2025 09:28:14 GMT   (402kb)

Title: Learning without Global Backpropagation via Synergistic Information
  Distillation
Authors: Chenhao Ye, Ming Tang
Categories: cs.LG cs.AI
\\
  Backpropagation (BP), while foundational to deep learning, imposes two
critical scalability bottlenecks: update locking, where network modules remain
idle until the entire backward pass completes, and high memory consumption due
to storing activations for gradient computation. To address these limitations,
we introduce Synergistic Information Distillation (SID), a novel training
framework that reframes deep learning as a cascade of local cooperative
refinement problems. In SID, a deep network is structured as a pipeline of
modules, each imposed with a local objective to refine a probabilistic belief
about the ground-truth target. This objective balances fidelity to the target
with consistency to the belief from its preceding module. By decoupling the
backward dependencies between modules, SID enables parallel training and hence
eliminates update locking and drastically reduces memory requirements.
Meanwhile, this design preserves the standard feed-forward inference pass,
making SID a versatile drop-in replacement for BP. We provide a theoretical
foundation, proving that SID guarantees monotonic performance improvement with
network depth. Empirically, SID consistently matches or surpasses the
classification accuracy of BP, exhibiting superior scalability and pronounced
robustness to label noise.Code is available at:
https://github.com/ychAlbert/sid-bp
\\ ( https://arxiv.org/abs/2510.03273 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03274 (*cross-listing*)
Date: Sat, 27 Sep 2025 13:50:42 GMT   (350kb)

Title: Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion
  Large Language Models
Authors: Tianao Zhang, Zhiteng Li, Xianglong Yan, Haotong Qin, Yong Guo, and
  Yulun Zhang
Categories: cs.LG cs.AI
\\
  Diffusion large language models (dLLMs), which offer bidirectional context
and flexible masked-denoising generation, are emerging as a compelling
alternative to autoregressive (AR) LLMs. However, like AR LLMs, their model
sizes continue to grow, motivating weight compression for deployment. Although
post-training quantization (PTQ) is effective for AR LLMs, directly
transferring it to dLLMs at 2-bit leads to unsatisfactory performance. To
tackle these challenges, we propose Quant-dLLM, an ultra-low-bit PTQ framework
tailored to dLLMs. Since masked-denoising activations in dLLMs differ from the
fully visible signals assumed by standard PTQ methods, we introduce Masked
Calibration Simulation (MCS) to align calibration with the timestep-dependent
masking, which yields more reliable calibrations. Moreover, we propose a
Data-aware Any-order Quantizer (DAQ) that learns ultra-low-bit weight
representations via an optimization algorithm. It performs iterative
approximation guided by our simulated calibration data. In addition, under a
strict 2-bit budget, we introduce Adaptive Blockwise Mixed Precision (ABMP), a
sensitivity-based precision allocation scheme that adaptively assigns bit width
across channel groups. When restricted to 2-bit precision, Quant-dLLM
consistently achieves higher accuracy than state-of-the-art (SOTA) AR-transfer
PTQ methods on dLLMs. The code and models will be available at:
https://github.com/ZTA2785/Quant-dLLM.
\\ ( https://arxiv.org/abs/2510.03274 ,  350kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03275 (*cross-listing*)
Date: Sat, 27 Sep 2025 14:49:58 GMT   (596kb)

Title: SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size
Authors: Junhao Xia and Ming Zhao and Limin Xiao and Xiujun Zhang
Categories: cs.LG cs.AI cs.CV
\\
  Large language models (LLMs) face significant computational and memory
challenges, making extremely low-bit quantization crucial for their efficient
deployment. In this work, we introduce SDQ-LLM: Sigma-Delta Quantization for
1-bit LLMs of any size, a novel framework that enables extremely low-bit
quantization of LLMs while preserving their linguistic reasoning capabilities.
A distinctive feature of SDQ-LLM is the continuous adjustability of the
Over-Sampling Ratio (OSR), enabling dynamic adaptation to memory or VRAM
constraints by selecting fractional OSR (e.g. 2.5 times) for an optimal
trade-off between model size and accuracy. SDQ-LLM uses upsampling combined
with Sigma-Delta Quantizer to binarize or ternarize LLMs weights, encoding
high-precision parameters into 1-bit or 1.58-bit representations, replacing the
multiplication operations within linear layers with addition. This approach
significantly enhances inference efficiency under extremely low-bit
quantization. To further reduce the loss of quantization precision, we
incorporate Hadamard-based weight smoothing prior to quantization, improving
the stability and robustness of the weight representations. Furthermore, to
fully leverage the continuity of the OSR and reduce precision loss, recognizing
the correlation between quantization sensitivity and weight variance, we
propose a fine-grained, layer- and linear-wise OSR allocation strategy,
MultiOSR. This strategy distributes OSR both across layers and within each
layer, based on weight variance and parameter scale. Finally, extensive
experiments on OPT and LLaMA model families demonstrate that SDQ-LLM achieves a
more efficient and high-precision performance even under highly aggressive
low-OSR settings. Our code is available at
https://github.com/Dreamlittlecat/LLM-Quant-Factory.
\\ ( https://arxiv.org/abs/2510.03275 ,  596kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03276 (*cross-listing*)
Date: Sun, 28 Sep 2025 08:35:31 GMT   (95kb)

Title: QuadEnhancer: Leveraging Quadratic Transformations to Enhance Deep
  Neural Networks
Authors: Qian Chen, Linxin Yang, Akang Wang, Xiaodong Luo, Yin Zhang
Categories: cs.LG cs.AI
Comments: 39th Conference on Neural Information Processing Systems (NeurIPS
  2025)
\\
  The combination of linear transformations and non-linear activation functions
forms the foundation of most modern deep neural networks, enabling them to
approximate highly complex functions. This paper explores the introduction of
quadratic transformations to further increase nonlinearity in neural networks,
with the aim of enhancing the performance of existing architectures. To reduce
parameter complexity and computational complexity, we propose a lightweight
quadratic enhancer that uses low-rankness, weight sharing, and sparsification
techniques. For a fixed architecture, the proposed approach introduces
quadratic interactions between features at every layer, while only adding
negligible amounts of additional model parameters and forward computations. We
conduct a set of proof-of-concept experiments for the proposed method across
three tasks: image classification, text classification, and fine-tuning
large-language models. In all tasks, the proposed approach demonstrates clear
and substantial performance gains.
\\ ( https://arxiv.org/abs/2510.03276 ,  95kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03278 (*cross-listing*)
Date: Sun, 28 Sep 2025 11:06:46 GMT   (404kb)

Title: Quantifying constraint hierarchies in Bayesian PINNs via per-constraint
  Hessian decomposition
Authors: Filip Landgren
Categories: cs.LG cs.AI
Comments: 5 pages, 2 figures
\\
  Bayesian physics-informed neural networks (B-PINNs) merge data with governing
equations to solve differential equations under uncertainty. However,
interpreting uncertainty and overconfidence in B-PINNs requires care due to the
poorly understood effects the physical constraints have on the network;
overconfidence could reflect warranted precision, enforced by the constraints,
rather than miscalibration. Motivated by the need to further clarify how
individual physical constraints shape these networks, we introduce a scalable,
matrix-free Laplace framework that decomposes the posterior Hessian into
contributions from each constraint and provides metrics to quantify their
relative influence on the loss landscape. Applied to the Van der Pol equation,
our method tracks how constraints sculpt the network's geometry and shows,
directly through the Hessian, how changing a single loss weight non-trivially
redistributes curvature and effective dominance across the others.
\\ ( https://arxiv.org/abs/2510.03278 ,  404kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03279 (*cross-listing*)
Date: Sun, 28 Sep 2025 14:40:58 GMT   (11493kb)

Title: MemMamba: Rethinking Memory Patterns in State Space Model
Authors: Youjin Wang, Yangjingyi Chen, Jiahao Yan, Jiaxuan Lu and Xiao Sun
Categories: cs.LG cs.AI cs.CL
\\
  With the explosive growth of data, long-sequence modeling has become
increasingly important in tasks such as natural language processing and
bioinformatics. However, existing methods face inherent trade-offs between
efficiency and memory. Recurrent neural networks suffer from gradient vanishing
and explosion, making them hard to scale. Transformers can model global
dependencies but are constrained by quadratic complexity. Recently, selective
state-space models such as Mamba have demonstrated high efficiency with O(n)
time and O(1) recurrent inference, yet their long-range memory decays
exponentially. In this work, we conduct mathematical derivations and
information-theoretic analysis to systematically uncover the memory decay
mechanism of Mamba, answering a fundamental question: what is the nature of
Mamba's long-range memory and how does it retain information? To quantify key
information loss, we further introduce horizontal-vertical memory fidelity
metrics that capture degradation both within and across layers. Inspired by how
humans distill and retain salient information when reading long documents, we
propose MemMamba, a novel architectural framework that integrates state
summarization mechanism together with cross-layer and cross-token attention,
which alleviates long-range forgetting while preserving linear complexity.
MemMamba achieves significant improvements over existing Mamba variants and
Transformers on long-sequence benchmarks such as PG19 and Passkey Retrieval,
while delivering a 48% speedup in inference efficiency. Both theoretical
analysis and empirical results demonstrate that MemMamba achieves a
breakthrough in the complexity-memory trade-off, offering a new paradigm for
ultra-long sequence modeling.
\\ ( https://arxiv.org/abs/2510.03279 ,  11493kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03280 (*cross-listing*)
Date: Sun, 28 Sep 2025 16:20:02 GMT   (3179kb)

Title: Training Optimal Large Diffusion Language Models
Authors: Jinjie Ni, Qian Liu, Chao Du, Longxu Dou, Hang Yan, Zili Wang, Tianyu
  Pang, Michael Qizhe Shieh
Categories: cs.LG cs.AI cs.CL
\\
  We introduce Quokka, the first systematic scaling law for diffusion language
models (DLMs), encompassing both compute-constrained and data-constrained
regimes, and studying the key modeling and optimization designs. Quokka is a
good friend of Chinchilla and provides wider scopes. We hope the results would
bring short-term practical guidance in DLMs training and long-term inspirations
for the whole AI community.
\\ ( https://arxiv.org/abs/2510.03280 ,  3179kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03283 (*cross-listing*)
Date: Sun, 28 Sep 2025 18:45:28 GMT   (1321kb)

Title: MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous
  Retraining Alignment
Authors: Yufei Li, Yu Fu, Yue Dong, Cong Liu
Categories: cs.LG cs.AI cs.CL cs.DC
Comments: 14 pages, 15 figures
\\
  Large language models (LLMs) deployed on edge servers are increasingly used
in latency-sensitive applications such as personalized assistants,
recommendation, and content moderation. However, the non-stationary nature of
user data necessitates frequent retraining, which introduces a fundamental
tension between inference latency and model accuracy under constrained GPU
resources. Existing retraining strategies either delay model updates,
over-commit resources to retraining, or overlook iteration-level retraining
granularity. In this paper, we identify that iteration-level scheduling is
crucial for adapting retraining frequency to model drift without violating
service-level objectives (SLOs). We propose MACE, a hybrid LLM system that
colocates concurrent inference (prefill, decode) and fine-tuning, with
intelligent memory management to maximize task performance while promising
inference throughput. MACE leverages the insight that not all model updates
equally affect output alignment and allocates GPU cycles accordingly to balance
throughput, latency, and update freshness. Our trace-driven evaluation shows
that MACE matches or exceeds continuous retraining while reducing inference
latency by up to 63% and maintaining throughput under resource constraints.
Compared to periodic retraining, MACE improves latency breakdown across
prefill, decode, and finetune stages, and sustains GPU utilization above 85% in
NVIDIA AGX Orin. These results demonstrate that iteration-level hybrid
scheduling is a promising direction for deploying LLMs with continual learning
capabilities on edge platforms.
\\ ( https://arxiv.org/abs/2510.03283 ,  1321kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03284 (*cross-listing*)
Date: Sun, 28 Sep 2025 20:06:37 GMT   (1577kb)

Title: Edge-FIT: Federated Instruction Tuning of Quantized LLMs for
  Privacy-Preserving Smart Home Environments
Authors: Vinay Venkatesh, Vamsidhar R Kamanuru, Lav Kumar, Nikita Kothari
Categories: cs.LG cs.AI
Comments: 7 pages, 1 figure
\\
  This paper proposes Edge-FIT (Federated Instruction Tuning on the Edge), a
scalable framework for Federated Instruction Tuning (FIT) of Large Language
Models (LLMs). Traditional Federated Learning (TFL) methods, like FedAvg, fail
when confronted with the massive parameter size of LLMs [3], [6]. Our Edge-FIT
framework combines federated learning with 4-bit Quantized Low-Rank Adaptation
(QLORA), mitigating the core issues of communication and computational
overhead. We demonstrate this by filtering the general-purpose Databricks Dolly
15k dataset for the IoT domain. Experimental results show the Edge-FIT tuned
Llama 2(7B) achieves an F1-Score of 0.89. We also demonstrate a viable
trade-off using the 3.8B Phi-3-mini model, validating Edge-FIT as a scalable
framework for decentralized LLM deployment on home compute gateways.
\\ ( https://arxiv.org/abs/2510.03284 ,  1577kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03286 (*cross-listing*)
Date: Mon, 29 Sep 2025 04:07:38 GMT   (1082kb)

Title: A Biologically Interpretable Cognitive Architecture for Online
  Structuring of Episodic Memories into Cognitive Maps
Authors: E.A. Dzhivelikian and A.I. Panov
Categories: q-bio.NC cs.AI
\\
  Cognitive maps provide a powerful framework for understanding spatial and
abstract reasoning in biological and artificial agents. While recent
computational models link cognitive maps to hippocampal-entorhinal mechanisms,
they often rely on global optimization rules (e.g., backpropagation) that lack
biological plausibility. In this work, we propose a novel cognitive
architecture for structuring episodic memories into cognitive maps using local,
Hebbian-like learning rules, compatible with neural substrate constraints. Our
model integrates the Successor Features framework with episodic memories,
enabling incremental, online learning through agent-environment interaction. We
demonstrate its efficacy in a partially observable grid-world, where the
architecture autonomously organizes memories into structured representations
without centralized optimization. This work bridges computational neuroscience
and AI, offering a biologically grounded approach to cognitive map formation in
artificial adaptive agents.
\\ ( https://arxiv.org/abs/2510.03286 ,  1082kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03288 (*cross-listing*)
Date: Mon, 29 Sep 2025 07:09:19 GMT   (1849kb)

Title: LogAction: Consistent Cross-system Anomaly Detection through Logs via
  Active Domain
Authors: Chiming Duan, Minghua He, Pei Xiao, Tong Jia, Xin Zhang, Zhewei Zhong,
  Xiang Luo, Yan Niu, Lingzhe Zhang, Yifan Wu, Siyu Yu, Weijie Hong, Ying Li,
  Gang Huang
Categories: cs.LG cs.AI cs.DC cs.SE
Comments: The 40th IEEE/ACM International Conference on Automated Software
  Engineering, ASE 2025
\\
  Log-based anomaly detection is a essential task for ensuring the reliability
and performance of software systems. However, the performance of existing
anomaly detection methods heavily relies on labeling, while labeling a large
volume of logs is highly challenging. To address this issue, many approaches
based on transfer learning and active learning have been proposed.
Nevertheless, their effectiveness is hindered by issues such as the gap between
source and target system data distributions and cold-start problems. In this
paper, we propose LogAction, a novel log-based anomaly detection model based on
active domain adaptation. LogAction integrates transfer learning and active
learning techniques. On one hand, it uses labeled data from a mature system to
train a base model, mitigating the cold-start issue in active learning. On the
other hand, LogAction utilize free energy-based sampling and uncertainty-based
sampling to select logs located at the distribution boundaries for manual
labeling, thus addresses the data distribution gap in transfer learning with
minimal human labeling efforts. Experimental results on six different
combinations of datasets demonstrate that LogAction achieves an average 93.01%
F1 score with only 2% of manual labels, outperforming some state-of-the-art
methods by 26.28%. Website: https://logaction.github.io
\\ ( https://arxiv.org/abs/2510.03288 ,  1849kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03289 (*cross-listing*)
Date: Mon, 29 Sep 2025 12:07:09 GMT   (840kb)

Title: Why mask diffusion does not work
Authors: Haocheng Sun, Cynthia Xin Wen, Edward Hong Wang
Categories: cs.LG cs.AI cs.CL
\\
  The main advantages of diffusion language models over autoregressive (AR)
models lie in their ability to support parallel generation and bidirectional
attention, enabling a more controllable generation process. In recent years,
open-source mask diffusion language models have emerged, most of which are
based on a variant known as absorbing diffusion. However, this paper
demonstrates why mask diffusion faces inherent difficulties in achieving
parallel generation and bidirectional attention. We also propose the most
effective training and inference strategies for mask diffusion.
\\ ( https://arxiv.org/abs/2510.03289 ,  840kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03291 (*cross-listing*)
Date: Mon, 29 Sep 2025 13:38:28 GMT   (586kb)

Title: UniPruning: Unifying Local Metric and Global Feedback for Scalable
  Sparse LLMs
Authors: Yizhuo Ding, Wanying Qu, Jiawei Geng, Wenqi Shao, Yanwei Fu
Categories: cs.LG cs.AI
\\
  Large Language Models (LLMs) achieve strong performance across diverse tasks
but face prohibitive computational and memory costs. Pruning offers a promising
path by inducing sparsity while preserving architectural flexibility. However,
existing methods struggle to balance efficiency and robustness: local metric
approaches prune layer by layer but often collapse under high sparsity, whereas
global feedback methods enforce consistency at the cost of expensive weight
updates or restrictive semi-structured formats. We present UniPruning, a
unified post-training pruning framework that combines the speed of local
saliency metrics with the stability of global coordination, enabled by a mirror
descent based optimization, all without updating model weights. UniPruning
leverages fast layer-wise scoring and a lightweight global controller to
allocate a single sparsity budget, supporting both unstructured and
semi-structured N :M pruning within one framework. After a brief calibration,
it can generate pruning masks for arbitrary sparsity levels in one shot, and
adapts seamlessly to hardware-aware constraints. Extensive experiments on
multiple pretrained LLM families and standard benchmarks show that UniPruning
consistently delivers competitive or superior perplexity and zero-shot
accuracy. Ablation studies further highlight the importance of mirror descent
and local saliency anchoring. Overall, UniPruning provides an efficient,
principled, and scalable solution for sparsifying large-scale LLMs. Our code is
available at: https://github.com/RainbowQTT/UniPruning.
\\ ( https://arxiv.org/abs/2510.03291 ,  586kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03293 (*cross-listing*)
Date: Mon, 29 Sep 2025 16:29:17 GMT   (4344kb)

Title: From Score Distributions to Balance: Plug-and-Play Mixture-of-Experts
  Routing
Authors: Rana Shahout, Colin Cai, Yilun Du, Minlan Yu, Michael Mitzenmacher
Categories: cs.LG cs.AI cs.DC
\\
  Mixture-of-Experts (MoE) models can scale parameter capacity by routing each
token to a subset of experts through a learned gate function. While conditional
routing reduces training costs, it shifts the burden on inference memory:
expert parameters and activations consume memory, limiting the number of
experts per device. As tokens are routed, some experts become overloaded while
others are underutilized. Because experts are mapped to GPUs, this imbalance
translates directly into degraded system performance in terms of latency,
throughput, and cost. We present LASER, a plug-and-play, inference-time routing
algorithm that balances load while preserving accuracy. LASER adapts to the
shape of the gate's score distribution. When scores provide a clear preference,
it routes to the strongest experts; when scores are more uniform, it broadens
the set of viable experts and routes to the least-loaded among them. Because
LASER relies only on gate scores from a trained model, it integrates directly
into existing MoE inference pipelines without retraining or finetuning. We
evaluate LASER on Mixtral-8x7B and DeepSeek-MoE-16b-chat across four datasets
(ARC-Easy, ARC-Challenge, MMLU, and GSM8K). LASER improves load balancing,
translating into lower latency and higher throughput, while keeping the
accuracy changes negligible.
\\ ( https://arxiv.org/abs/2510.03293 ,  4344kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03301 (*cross-listing*)
Date: Tue, 30 Sep 2025 07:45:49 GMT   (1869kb)

Title: Dynamic Meta-Learning for Adaptive XGBoost-Neural Ensembles
Authors: Arthur Sedek
Categories: cs.LG cs.AI
\\
  This paper introduces a novel adaptive ensemble framework that
synergistically combines XGBoost and neural networks through sophisticated
meta-learning. The proposed method leverages advanced uncertainty
quantification techniques and feature importance integration to dynamically
orchestrate model selection and combination. Experimental results demonstrate
superior predictive performance and enhanced interpretability across diverse
datasets, contributing to the development of more intelligent and flexible
machine learning systems.
\\ ( https://arxiv.org/abs/2510.03301 ,  1869kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03306 (*cross-listing*)
Date: Tue, 30 Sep 2025 18:57:02 GMT   (2588kb)

Title: Atlas-free Brain Network Transformer
Authors: Shuai Huang, Xuan Kan, James J. Lah, Deqiang Qiu
Categories: q-bio.NC cs.AI cs.LG cs.NE eess.IV
\\
  Current atlas-based approaches to brain network analysis rely heavily on
standardized anatomical or connectivity-driven brain atlases. However, these
fixed atlases often introduce significant limitations, such as spatial
misalignment across individuals, functional heterogeneity within predefined
regions, and atlas-selection biases, collectively undermining the reliability
and interpretability of the derived brain networks. To address these
challenges, we propose a novel atlas-free brain network transformer (atlas-free
BNT) that leverages individualized brain parcellations derived directly from
subject-specific resting-state fMRI data. Our approach computes ROI-to-voxel
connectivity features in a standardized voxel-based feature space, which are
subsequently processed using the BNT architecture to produce comparable
subject-level embeddings. Experimental evaluations on sex classification and
brain-connectome age prediction tasks demonstrate that our atlas-free BNT
consistently outperforms state-of-the-art atlas-based methods, including
elastic net, BrainGNN, Graphormer and the original BNT. Our atlas-free approach
significantly improves the precision, robustness, and generalizability of brain
network analyses. This advancement holds great potential to enhance
neuroimaging biomarkers and clinical diagnostic tools for personalized
precision medicine.
\\ ( https://arxiv.org/abs/2510.03306 ,  2588kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03308 (*cross-listing*)
Date: Tue, 30 Sep 2025 19:32:30 GMT   (3494kb)

Title: Creative synthesis of kinematic mechanisms
Authors: Jiong Lin, Jialong Ning, Judah Goldfeder, Hod Lipson
Categories: cs.GR cs.AI cs.CV
Comments: 6pages, 6 figures
\\
  In this paper, we formulate the problem of kinematic synthesis for planar
linkages as a cross-domain image generation task. We develop a planar linkages
dataset using RGB image representations, covering a range of mechanisms: from
simple types such as crank-rocker and crank-slider to more complex eight-bar
linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE)
is employed to explore the potential of image generative models for
synthesizing unseen motion curves and simulating novel kinematics. By encoding
the drawing speed of trajectory points as color gradients, the same
architecture also supports kinematic synthesis conditioned on both trajectory
shape and velocity profiles. We validate our method on three datasets of
increasing complexity: a standard four-bar linkage set, a mixed set of four-bar
and crank-slider mechanisms, and a complex set including multi-loop mechanisms.
Preliminary results demonstrate the effectiveness of image-based
representations for generative mechanical design, showing that mechanisms with
revolute and prismatic joints, and potentially cams and gears, can be
represented and synthesized within a unified image generation framework.
\\ ( https://arxiv.org/abs/2510.03308 ,  3494kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03310 (*cross-listing*)
Date: Tue, 30 Sep 2025 20:20:58 GMT   (4751kb)

Title: Predicting Effects, Missing Distributions: Evaluating LLMs as Human
  Behavior Simulators in Operations Management
Authors: Runze Zhang, Xiaowei Zhang, Mingyang Zhao
Categories: cs.LG cs.AI
\\
  LLMs are emerging tools for simulating human behavior in business, economics,
and social science, offering a lower-cost complement to laboratory experiments,
field studies, and surveys. This paper evaluates how well LLMs replicate human
behavior in operations management. Using nine published experiments in
behavioral operations, we assess two criteria: replication of hypothesis-test
outcomes and distributional alignment via Wasserstein distance. LLMs reproduce
most hypothesis-level effects, capturing key decision biases, but their
response distributions diverge from human data, including for strong commercial
models. We also test two lightweight interventions -- chain-of-thought
prompting and hyperparameter tuning -- which reduce misalignment and can
sometimes let smaller or open-source models match or surpass larger systems.
\\ ( https://arxiv.org/abs/2510.03310 ,  4751kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03326 (*cross-listing*)
Date: Wed, 1 Oct 2025 16:04:06 GMT   (42206kb)

Title: NS-Pep: De novo Peptide Design with Non-Standard Amino Acids
Authors: Tao Guo, Junbo Yin, Yu Wang, Xin Gao
Categories: q-bio.BM cs.AI
\\
  Peptide drugs incorporating non-standard amino acids (NSAAs) offer improved
binding affinity and improved pharmacological properties. However, existing
peptide design methods are limited to standard amino acids, leaving NSAA-aware
design largely unexplored. We introduce NS-Pep, a unified framework for
co-designing peptide sequences and structures with NSAAs. The main challenge is
that NSAAs are extremely underrepresented-even the most frequent one, SEP,
accounts for less than 0.4% of residues-resulting in a severe long-tailed
distribution. To improve generalization to rare amino acids, we propose Residue
Frequency-Guided Modification (RFGM), which mitigates over-penalization through
frequency-aware logit calibration, supported by both theoretical and empirical
analysis. Furthermore, we identify that insufficient side-chain modeling limits
geometric representation of NSAAs. To address this, we introduce Progressive
Side-chain Perception (PSP) for coarse-to-fine torsion and location prediction,
and Interaction-Aware Weighting (IAW) to emphasize pocket-proximal residues.
Moreover, NS-Pep generalizes naturally to the peptide folding task with NSAAs,
addressing a major limitation of current tools. Experiments show that NS-Pep
improves sequence recovery rate and binding affinity by 6.23% and 5.12%,
respectively, and outperforms AlphaFold3 by 17.76% in peptide folding success
rate.
\\ ( https://arxiv.org/abs/2510.03326 ,  42206kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03331 (*cross-listing*)
Date: Wed, 1 Oct 2025 20:10:57 GMT   (249kb)

Title: Intelligent Healthcare Ecosystems: Optimizing the Iron Triangle of
  Healthcare (Access, Cost, Quality)
Authors: Vivek Acharya
Categories: cs.CY cs.AI
Comments: 8 pages, 4 figures, formatted per MDPI guidelines, APA-style numbered
  references
MSC-class: 68T07, 92C55, 92C60
ACM-class: I.2.1; J.3; H.3.5
\\
  The United States spends nearly 17% of GDP on healthcare yet continues to
face uneven access and outcomes. This well-known trade-off among cost, quality,
and access - the "iron triangle" - motivates a system-level redesign. This
paper proposes an Intelligent Healthcare Ecosystem (iHE): an integrated,
data-driven framework that uses generative AI and large language models,
federated learning, interoperability standards (FHIR, TEFCA), and digital twins
to improve access and quality while lowering cost. We review historical
spending trends, waste, and international comparisons; introduce a value
equation that jointly optimizes access, quality, and cost; and synthesize
evidence on the enabling technologies and operating model for iHE. Methods
follow a narrative review of recent literature and policy reports. Results
outline core components (AI decision support, interoperability, telehealth,
automation) and show how iHE can reduce waste, personalize care, and support
value-based payment while addressing privacy, bias, and adoption challenges. We
argue that a coordinated iHE can bend - if not break - the iron triangle,
moving the system toward care that is more accessible, affordable, and high
quality.
\\ ( https://arxiv.org/abs/2510.03331 ,  249kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03336 (*cross-listing*)
Date: Thu, 2 Oct 2025 06:54:55 GMT   (17kb)

Title: Linguistic and Audio Embedding-Based Machine Learning for Alzheimer's
  Dementia and Mild Cognitive Impairment Detection: Insights from the PROCESS
  Challenge
Authors: Adharsha Sam Edwin Sam Devahi, Sohail Singh Sangha, Prachee
  Priyadarshinee, Jithin Thilakan, Ivan Fu Xing Tan, Christopher Johann Clarke,
  Sou Ka Lon, Balamurali B T, Yow Wei Quin, Chen Jer-Ming
Categories: cs.SD cs.AI cs.LG
\\
  Early detection of Alzheimer's Dementia (AD) and Mild Cognitive Impairment
(MCI) is critical for timely intervention, yet current diagnostic approaches
remain resource-intensive and invasive. Speech, encompassing both acoustic and
linguistic dimensions, offers a promising non-invasive biomarker for cognitive
decline. In this study, we present a machine learning framework for the PROCESS
Challenge, leveraging both audio embeddings and linguistic features derived
from spontaneous speech recordings. Audio representations were extracted using
Whisper embeddings from the Cookie Theft description task, while linguistic
features-spanning pronoun usage, syntactic complexity, filler words, and clause
structure-were obtained from transcriptions across Semantic Fluency, Phonemic
Fluency, and Cookie Theft picture description. Classification models aimed to
distinguish between Healthy Controls (HC), MCI, and AD participants, while
regression models predicted Mini-Mental State Examination (MMSE) scores.
Results demonstrated that voted ensemble models trained on concatenated
linguistic features achieved the best classification performance (F1 = 0.497),
while Whisper embedding-based ensemble regressors yielded the lowest MMSE
prediction error (RMSE = 2.843). Comparative evaluation within the PROCESS
Challenge placed our models among the top submissions in regression task, and
mid-range for classification, highlighting the complementary strengths of
linguistic and audio embeddings. These findings reinforce the potential of
multimodal speech-based approaches for scalable, non-invasive cognitive
assessment and underline the importance of integrating task-specific linguistic
and acoustic markers in dementia detection.
\\ ( https://arxiv.org/abs/2510.03336 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03339 (*cross-listing*)
Date: Thu, 2 Oct 2025 11:17:24 GMT   (1637kb)

Title: Pool Me Wisely: On the Effect of Pooling in Transformer-Based Models
Authors: Sofiane Ennadir, Levente Z\'olyomi, Oleg Smirnov, Tianze Wang, John
  Pertoft, Filip Cornell, Lele Cao
Categories: cs.LG cs.AI
\\
  Transformer models have become the dominant backbone for sequence modeling,
leveraging self-attention to produce contextualized token representations.
These are typically aggregated into fixed-size vectors via pooling operations
for downstream tasks. While much of the literature has focused on attention
mechanisms, the role of pooling remains underexplored despite its critical
impact on model behavior. In this paper, we introduce a theoretical framework
that rigorously characterizes the expressivity of Transformer-based models
equipped with widely used pooling methods by deriving closed-form bounds on
their representational capacity and the ability to distinguish similar inputs.
Our analysis extends to different variations of attention formulations,
demonstrating that these bounds hold across diverse architectural variants. We
empirically evaluate pooling strategies across tasks requiring both global and
local contextual understanding, spanning three major modalities: computer
vision, natural language processing, and time-series analysis. Results reveal
consistent trends in how pooling choices affect accuracy, sensitivity, and
optimization behavior. Our findings unify theoretical and empirical
perspectives, providing practical guidance for selecting or designing pooling
mechanisms suited to specific tasks. This work positions pooling as a key
architectural component in Transformer models and lays the foundation for more
principled model design beyond attention alone.
\\ ( https://arxiv.org/abs/2510.03339 ,  1637kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03340 (*cross-listing*)
Date: Thu, 2 Oct 2025 12:06:29 GMT   (2736kb)

Title: Learning Pareto-Optimal Pandemic Intervention Policies with MORL
Authors: Marian Chen, Miri Zilka
Categories: cs.LG cs.AI cs.CY q-bio.PE
\\
  The COVID-19 pandemic underscored a critical need for intervention strategies
that balance disease containment with socioeconomic stability. We approach this
challenge by designing a framework for modeling and evaluating disease-spread
prevention strategies. Our framework leverages multi-objective reinforcement
learning (MORL) - a formulation necessitated by competing objectives - combined
with a new stochastic differential equation (SDE) pandemic simulator,
calibrated and validated against global COVID-19 data. Our simulator reproduces
national-scale pandemic dynamics with orders of magnitude higher fidelity than
other models commonly used in reinforcement learning (RL) approaches to
pandemic intervention. Training a Pareto-Conditioned Network (PCN) agent on
this simulator, we illustrate the direct policy trade-offs between
epidemiological control and economic stability for COVID-19. Furthermore, we
demonstrate the framework's generality by extending it to pathogens with
different epidemiological profiles, such as polio and influenza, and show how
these profiles lead the agent to discover fundamentally different intervention
policies. To ground our work in contemporary policymaking challenges, we apply
the model to measles outbreaks, quantifying how a modest 5% drop in vaccination
coverage necessitates significantly more stringent and costly interventions to
curb disease spread. This work provides a robust and adaptable framework to
support transparent, evidence-based policymaking for mitigating public health
crises.
\\ ( https://arxiv.org/abs/2510.03340 ,  2736kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03343 (*cross-listing*)
Date: Thu, 2 Oct 2025 14:45:26 GMT   (362kb)

Title: Defining a Strategic Action Plan for AI in Higher Education
Authors: Nikolaos Avouris
Categories: cs.CY cs.AI
Comments: to be cited: N. Avouris (2025), Defining a Strategic Action Plan for
  AI in Higher Education, Proceedings International Scientific Conference on
  Digital Competencies in Higher Education, Tirana, September 2025, pp. 141-151
\\
  This paper discusses key challenges of Artificial Intelligence in Education,
with main focus on higher education institutions. We start with reviewing
normative actions of international organizations and concerns expressed about
the current technical landscape. Then we proceed with proposing a framework
that comprises five key dimensions relating to the main challenges relating to
AI in higher education institutions, followed by five key strategic actions
that the main stakeholders need to take in order to address the current
developments. We map these actions to the main stakeholders of higher education
and propose a deployment plan. This defines a framework along the dimensions:
Challenges, Actions, Stakeholders, Deployment CASD. Examples of AI specific
actions at the institutional and individual course level are also provided and
discussed.
\\ ( https://arxiv.org/abs/2510.03343 ,  362kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03345 (*cross-listing*)
Date: Thu, 2 Oct 2025 15:10:31 GMT   (1565kb)

Title: Pilot selection in the era of Virtual reality: algorithms for accurate
  and interpretable machine learning models
Authors: Luoma Ke, Guangpeng Zhang, Jibo He, Yajing Li, Yan Li, Xufeng Liu,
  Peng Fang
Categories: cs.LG cs.AI
\\
  With the rapid growth of the aviation industry, there is a need for a large
number of flight crew. How to select the right pilots in a cost-efficient
manner has become an important research question. In the current study,
twenty-three pilots were recruited from China Eastern Airlines, and 23 novices
were from the community of Tsinghua University. A novel approach incorporating
machine learning and virtual reality technology was applied to distinguish
features between these participants with different flight skills. Results
indicate that SVM with the MIC feature selection method consistently achieved
the highest prediction performance on all metrics with an Accuracy of 0.93, an
AUC of 0.96, and an F1 of 0.93, which outperforms four other classifier
algorithms and two other feature selection methods. From the perspective of
feature selection methods, the MIC method can select features with a nonlinear
relationship to sampling labels, instead of a simple filter-out. Our new
implementation of the SVM + MIC algorithm outperforms all existing pilot
selection algorithms and perhaps provides the first implementation based on eye
tracking and flight dynamics data. This study's VR simulation platforms and
algorithms can be used for pilot selection and training.
\\ ( https://arxiv.org/abs/2510.03345 ,  1565kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03346 (*cross-listing*)
Date: Thu, 2 Oct 2025 16:01:54 GMT   (4069kb)

Title: KVComm: Enabling Efficient LLM Communication through Selective KV
  Sharing
Authors: Xiangyu Shi, Marco Chiesa, Gerald Q. Maguire Jr., Dejan Kostic
Categories: cs.LG cs.AI cs.MA
\\
  Large Language Models (LLMs) are increasingly deployed in multi-agent
systems, where effective inter-model communication is crucial. Existing
communication protocols either rely on natural language, incurring high
inference costs and information loss, or on hidden states, which suffer from
information concentration bias and inefficiency. To address these limitations,
we propose KVComm, a novel communication framework that enables efficient
communication between LLMs through selective sharing of KV pairs. KVComm
leverages the rich information encoded in the KV pairs while avoiding the
pitfalls of hidden states. We introduce a KV layer-wise selection strategy
based on attention importance scores with a Gaussian prior to identify the most
informative KV pairs for communication. Extensive experiments across diverse
tasks and model pairs demonstrate that KVComm achieves comparable performance
to the upper-bound method, which directly merges inputs to one model without
any communication, while transmitting as few as 30\% of layers' KV pairs. Our
study highlights the potential of KV pairs as an effective medium for inter-LLM
communication, paving the way for scalable and efficient multi-agent systems.
\\ ( https://arxiv.org/abs/2510.03346 ,  4069kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03349 (*cross-listing*)
Date: Thu, 2 Oct 2025 17:57:16 GMT   (3352kb)

Title: AgentCaster: Reasoning-Guided Tornado Forecasting
Authors: Michael Chen
Categories: cs.LG cs.AI cs.CL physics.ao-ph
\\
  There is a growing need to evaluate Large Language Models (LLMs) on complex,
high-impact, real-world tasks to assess their true readiness as reasoning
agents. To address this gap, we introduce AgentCaster, a contamination-free
framework employing multimodal LLMs end-to-end for the challenging,
long-horizon task of tornado forecasting. Within AgentCaster, models interpret
heterogeneous spatiotemporal data from a high-resolution convection-allowing
forecast archive. We assess model performance over a 40-day period featuring
diverse historical data, spanning several major tornado outbreaks and including
over 500 tornado reports. Each day, models query interactively from a pool of
3,625 forecast maps and 40,125 forecast soundings for a forecast horizon of
12-36 hours. Probabilistic tornado-risk polygon predictions are verified
against ground truths derived from geometric comparisons across disjoint risk
bands in projected coordinate space. To quantify accuracy, we propose
domain-specific TornadoBench and TornadoHallucination metrics, with
TornadoBench highly challenging for both LLMs and domain expert human
forecasters. Notably, human experts significantly outperform state-of-the-art
models, which demonstrate a strong tendency to hallucinate and overpredict risk
intensity, struggle with precise geographic placement, and exhibit poor
spatiotemporal reasoning in complex, dynamically evolving systems. AgentCaster
aims to advance research on improving LLM agents for challenging reasoning
tasks in critical domains.
\\ ( https://arxiv.org/abs/2510.03349 ,  3352kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03351 (*cross-listing*)
Date: Thu, 2 Oct 2025 19:38:46 GMT   (2256kb)

Title: Interpretable Neuropsychiatric Diagnosis via Concept-Guided Graph Neural
  Networks
Authors: Song Wang, Zhenyu Lei, Zhen Tan, Jundong Li, Javier Rasero, Aiying
  Zhang, Chirag Agarwal
Categories: cs.LG cs.AI eess.IV
\\
  Nearly one in five adolescents currently live with a diagnosed mental or
behavioral health condition, such as anxiety, depression, or conduct disorder,
underscoring the urgency of developing accurate and interpretable diagnostic
tools. Resting-state functional magnetic resonance imaging (rs-fMRI) provides a
powerful lens into large-scale functional connectivity, where brain regions are
modeled as nodes and inter-regional synchrony as edges, offering clinically
relevant biomarkers for psychiatric disorders. While prior works use graph
neural network (GNN) approaches for disorder prediction, they remain complex
black-boxes, limiting their reliability and clinical translation. In this work,
we propose CONCEPTNEURO, a concept-based diagnosis framework that leverages
large language models (LLMs) and neurobiological domain knowledge to
automatically generate, filter, and encode interpretable functional
connectivity concepts. Each concept is represented as a structured subgraph
linking specific brain regions, which are then passed through a concept
classifier. Our design ensures predictions through clinically meaningful
connectivity patterns, enabling both interpretability and strong predictive
performance. Extensive experiments across multiple psychiatric disorder
datasets demonstrate that CONCEPTNEURO-augmented GNNs consistently outperform
their vanilla counterparts, improving accuracy while providing transparent,
clinically aligned explanations. Furthermore, concept analyses highlight
disorder-specific connectivity patterns that align with expert knowledge and
suggest new hypotheses for future investigation, establishing CONCEPTNEURO as
an interpretable, domain-informed framework for psychiatric disorder diagnosis.
\\ ( https://arxiv.org/abs/2510.03351 ,  2256kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03358 (*cross-listing*)
Date: Thu, 2 Oct 2025 23:56:17 GMT   (17739kb)

Title: Understanding Transformers for Time Series: Rank Structure,
  Flow-of-ranks, and Compressibility
Authors: Annan Yu, Danielle C. Maddix, Boran Han, Xiyuan Zhang, Abdul Fatir
  Ansari, Oleksandr Shchur, Christos Faloutsos, Andrew Gordon Wilson, Michael
  W. Mahoney, Yuyang Wang
Categories: cs.LG cs.AI
Comments: 42 pages
\\
  Transformers are widely used across data modalities, and yet the principles
distilled from text models often transfer imperfectly to models trained to
other modalities. In this paper, we analyze Transformers through the lens of
rank structure. Our focus is on the time series setting, where the structural
properties of the data differ remarkably from those of text or vision. We show
that time-series embeddings, unlike text or vision, exhibit sharply decaying
singular value spectra: small patch sizes and smooth continuous mappings
concentrate the data into low-rank subspaces. From this, we prove that the
associated $Q/K/V$ projections admit accurate low-rank approximations, and that
attention layers become compressible in proportion to the decay of the
embedding spectrum. We introduce the concept of flow-of-ranks, a phenomenon by
which nonlinear mixing across depth inflates the rank, explaining why early
layers are most amenable to compression and why ranks grow with depth. Guided
by these theoretical and empirical results, we use these insights to compress
Chronos, a large time series foundation model, achieving a reduction of $65\%$
in inference time and $81\%$ in memory, without loss of accuracy. Our findings
provide principled guidance for allocating width, depth, and heads in time
series foundation models, and for exploiting their inherent compressibility.
\\ ( https://arxiv.org/abs/2510.03358 ,  17739kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03360 (*cross-listing*)
Date: Fri, 3 Oct 2025 00:18:26 GMT   (2966kb)

Title: Physics-informed Neural-operator Predictive Control for Drag Reduction
  in Turbulent Flows
Authors: Zelin Zhao, Zongyi Li, Kimia Hassibi, Kamyar Azizzadenesheli, Junchi
  Yan, H. Jane Bae, Di Zhou, Anima Anandkumar
Categories: cs.LG cs.AI math.OC physics.flu-dyn
\\
  Assessing turbulence control effects for wall friction numerically is a
significant challenge since it requires expensive simulations of turbulent
fluid dynamics. We instead propose an efficient deep reinforcement learning
(RL) framework for modeling and control of turbulent flows. It is model-based
RL for predictive control (PC), where both the policy and the observer models
for turbulence control are learned jointly using Physics Informed Neural
Operators (PINO), which are discretization invariant and can capture fine
scales in turbulent flows accurately. Our PINO-PC outperforms prior model-free
reinforcement learning methods in various challenging scenarios where the flows
are of high Reynolds numbers and unseen, i.e., not provided during model
training. We find that PINO-PC achieves a drag reduction of 39.0\% under a
bulk-velocity Reynolds number of 15,000, outperforming previous fluid control
methods by more than 32\%.
\\ ( https://arxiv.org/abs/2510.03360 ,  2966kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03364 (*cross-listing*)
Date: Fri, 3 Oct 2025 03:38:58 GMT   (4632kb)

Title: Diffusion-Based, Data-Assimilation-Enabled Super-Resolution of
  Hub-height Winds
Authors: Xiaolong Ma, Xu Dong, Ashley Tarrant, Lei Yang, Rao Kotamarthi, Jiali
  Wang, Feng Yan, Rajkumar Kettimuthu
Categories: cs.LG cs.AI
\\
  High-quality observations of hub-height winds are valuable but sparse in
space and time. Simulations are widely available on regular grids but are
generally biased and too coarse to inform wind-farm siting or to assess
extreme-weather-related risks (e.g., gusts) at infrastructure scales. To fully
utilize both data types for generating high-quality, high-resolution hub-height
wind speeds (tens to ~100m above ground), this study introduces WindSR, a
diffusion model with data assimilation for super-resolution downscaling of
hub-height winds. WindSR integrates sparse observational data with simulation
fields during downscaling using state-of-the-art diffusion models. A
dynamic-radius blending method is introduced to merge observations with
simulations, providing conditioning for the diffusion process. Terrain
information is incorporated during both training and inference to account for
its role as a key driver of winds. Evaluated against
convolutional-neural-network and generative-adversarial-network baselines,
WindSR outperforms them in both downscaling efficiency and accuracy. Our data
assimilation reduces WindSR's model bias by approximately 20% relative to
independent observations.
\\ ( https://arxiv.org/abs/2510.03364 ,  4632kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03366 (*cross-listing*)
Date: Fri, 3 Oct 2025 04:13:06 GMT   (540kb)

Title: Disentangling Recall and Reasoning in Transformer Models through
  Layer-wise Attention and Activation Analysis
Authors: Harshwardhan Fartale, Ashish Kattamuri, Rahul Raja, Arpita Vats,
  Ishita Prasad, Akshata Kishore Moharir
Categories: cs.LG cs.AI
\\
  Transformer-based language models excel at both recall (retrieving memorized
facts) and reasoning (performing multi-step inference), but whether these
abilities rely on distinct internal mechanisms remains unclear. Distinguishing
recall from reasoning is crucial for predicting model generalization, designing
targeted evaluations, and building safer interventions that affect one ability
without disrupting the other.We approach this question through mechanistic
interpretability, using controlled datasets of synthetic linguistic puzzles to
probe transformer models at the layer, head, and neuron level. Our pipeline
combines activation patching and structured ablations to causally measure
component contributions to each task type. Across two model families (Qwen and
LLaMA), we find that interventions on distinct layers and attention heads lead
to selective impairments: disabling identified "recall circuits" reduces
fact-retrieval accuracy by up to 15\% while leaving reasoning intact, whereas
disabling "reasoning circuits" reduces multi-step inference by a comparable
margin. At the neuron level, we observe task-specific firing patterns, though
these effects are less robust, consistent with neuronal polysemanticity.Our
results provide the first causal evidence that recall and reasoning rely on
separable but interacting circuits in transformer models. These findings
advance mechanistic interpretability by linking circuit-level structure to
functional specialization and demonstrate how controlled datasets and causal
interventions can yield mechanistic insights into model cognition, informing
safer deployment of large language models.
\\ ( https://arxiv.org/abs/2510.03366 ,  540kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03368 (*cross-listing*)
Date: Fri, 3 Oct 2025 05:55:48 GMT   (110kb)

Title: An Adaptive Responsible AI Governance Framework for Decentralized
  Organizations
Authors: Kiana Jafari Meimandi, Anka Reuel, Gabriela Aranguiz-Dias, Hatim
  Rahama, Ala-Eddine Ayadi, Xavier Boullier, J\'er\'emy Verdo, Louis Montanie,
  Mykel Kochenderfer
Categories: cs.CY cs.AI
\\
  This paper examines the assessment challenges of Responsible AI (RAI)
governance efforts in globally decentralized organizations through a case study
collaboration between a leading research university and a multinational
enterprise. While there are many proposed frameworks for RAI, their application
in complex organizational settings with distributed decision-making authority
remains underexplored. Our RAI assessment, conducted across multiple business
units and AI use cases, reveals four key patterns that shape RAI
implementation: (1) complex interplay between group-level guidance and local
interpretation, (2) challenges translating abstract principles into operational
practices, (3) regional and functional variation in implementation approaches,
and (4) inconsistent accountability in risk oversight. Based on these findings,
we propose an Adaptive RAI Governance (ARGO) Framework that balances central
coordination with local autonomy through three interdependent layers: shared
foundation standards, central advisory resources, and contextual local
implementation. We contribute insights from academic-industry collaboration for
RAI assessments, highlighting the importance of modular governance approaches
that accommodate organizational complexity while maintaining alignment with
responsible AI principles. These lessons offer practical guidance for
organizations navigating the transition from RAI principles to operational
practice within decentralized structures.
\\ ( https://arxiv.org/abs/2510.03368 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03369 (*cross-listing*)
Date: Fri, 3 Oct 2025 06:04:59 GMT   (1423kb)

Title: TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum
  Design
Authors: Huazhen Wang, Huimin Yang, Hainbin Lin, Yan Dong, Lili Chen,
  Liangliang Xia, Wenwen Xu
Categories: cs.CY cs.AI
Comments: 16 pages, 4 figures
\\
  Interdisciplinary teaching is a cornerstone of modern curriculum reform, but
its implementation is hindered by challenges in knowledge integration and
time-consuming lesson planning. Existing tools often lack the required
pedagogical and domain-specific depth.We introduce TriQuest, an AI-copilot
platform designed to solve these problems. TriQuest uses large language models
and knowledge graphs via an intuitive GUI to help teachers efficiently generate
high-quality interdisciplinary lesson plans. Its core features include
intelligent knowledge integration from various disciplines and a human-computer
collaborative review process to ensure quality and innovation.In a study with
43 teachers, TriQuest increased curriculum design efficiency by an average of
75% and improved lesson plan quality scores by 41%. It also significantly
lowered design barriers and cognitive load. Our work presents a new paradigm
for empowering teacher professional development with intelligent technologies.
\\ ( https://arxiv.org/abs/2510.03369 ,  1423kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03370 (*cross-listing*)
Date: Fri, 3 Oct 2025 07:42:22 GMT   (1220kb)

Title: InstructPLM-mu: 1-Hour Fine-Tuning of ESM2 Beats ESM3 in Protein
  Mutation Predictions
Authors: Junde Xu, Yapin Shi, Lijun Lang, Taoyong Cui, Zhiming Zhang, Guangyong
  Chen, Jiezhong Qiu, Pheng-Ann Heng
Categories: q-bio.QM cs.AI cs.CE
Comments: preprint
\\
  Multimodal protein language models deliver strong performance on
mutation-effect prediction, but training such models from scratch demands
substantial computational resources. In this paper, we propose a fine-tuning
framework called InstructPLM-mu and try to answer a question: \textit{Can
multimodal fine-tuning of a pretrained, sequence-only protein language model
match the performance of models trained end-to-end? } Surprisingly, our
experiments show that fine-tuning ESM2 with structural inputs can reach
performance comparable to ESM3. To understand how this is achieved, we
systematically compare three different feature-fusion designs and fine-tuning
recipes. Our results reveal that both the fusion method and the tuning strategy
strongly affect final accuracy, indicating that the fine-tuning process is not
trivial. We hope this work offers practical guidance for injecting structure
into pretrained protein language models and motivates further research on
better fusion mechanisms and fine-tuning protocols.
\\ ( https://arxiv.org/abs/2510.03370 ,  1220kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03371 (*cross-listing*)
Date: Fri, 3 Oct 2025 08:25:21 GMT   (509kb)

Title: Distributed Low-Communication Training with Decoupled Momentum
  Optimization
Authors: Sasho Nedelkoski, Alexander Acker, Odej Kao, Soeren Becker, Dominik
  Scheinert
Categories: cs.LG cs.AI cs.DC
Comments: NeurIPS 2025 - DynaFront 2025: Dynamics at the Frontiers of
  Optimization, Sampling, and Games Workshop
\\
  The training of large models demands substantial computational resources,
typically available only in data centers with high-bandwidth interconnects.
However, reducing the reliance on high-bandwidth interconnects between nodes
enables the use of distributed compute resources as an alternative to
centralized data center training. Building on recent advances in distributed
model training, we propose an approach that further reduces communication by
combining infrequent synchronizations across distributed model replicas with
gradient momentum compression. In particular, we treat the optimizer momentum
as a signal and decompose the Nesterov momentum into high- and low-frequency
components via the discrete cosine transform (DCT). Only the high-frequency
components are synchronized across model replicas every $H$ steps. Empirically,
our method achieves up to a $16\times$ reduction in communication compared to
the baseline DiLoCo, and it generalizes across architectures, including
transformer-based language models and convolutional neural networks for images.
Overall, this work advances the feasibility of training large models on
distributed nodes with low-bandwidth interconnects.
\\ ( https://arxiv.org/abs/2510.03371 ,  509kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03372 (*cross-listing*)
Date: Fri, 3 Oct 2025 08:55:40 GMT   (8000kb)

Title: Real-time nonlinear inversion of magnetic resonance elastography with
  operator learning
Authors: Juampablo E. Heras Rivera, Caitlin M. Neher, Mehmet Kurt
Categories: eess.IV cs.AI cs.CV
\\
  $\textbf{Purpose:}$ To develop and evaluate an operator learning framework
for nonlinear inversion (NLI) of brain magnetic resonance elastography (MRE)
data, which enables real-time inversion of elastograms with comparable spatial
accuracy to NLI.
  $\textbf{Materials and Methods:}$ In this retrospective study, 3D MRE data
from 61 individuals (mean age, 37.4 years; 34 female) were used for development
of the framework. A predictive deep operator learning framework (oNLI) was
trained using 10-fold cross-validation, with the complex curl of the measured
displacement field as inputs and NLI-derived reference elastograms as outputs.
A structural prior mechanism, analogous to Soft Prior Regularization in the MRE
literature, was incorporated to improve spatial accuracy. Subject-level
evaluation metrics included Pearson's correlation coefficient, absolute
relative error, and structural similarity index measure between predicted and
reference elastograms across brain regions of different sizes to understand
accuracy. Statistical analyses included paired t-tests comparing the proposed
oNLI variants to the convolutional neural network baselines.
  $\textbf{Results:}$ Whole brain absolute percent error was 8.4 $\pm$ 0.5
($\mu'$) and 10.0 $\pm$ 0.7 ($\mu''$) for oNLI and 15.8 $\pm$ 0.8 ($\mu'$) and
26.1 $\pm$ 1.1 ($\mu''$) for CNNs. Additionally, oNLI outperformed
convolutional architectures as per Pearson's correlation coefficient, $r$, in
the whole brain and across all subregions for both the storage modulus and loss
modulus (p < 0.05).
  $\textbf{Conclusion:}$ The oNLI framework enables real-time MRE inversion
(30,000x speedup), outperforming CNN-based approaches and maintaining the
fine-grained spatial accuracy achievable with NLI in the brain.
\\ ( https://arxiv.org/abs/2510.03372 ,  8000kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03374 (*cross-listing*)
Date: Fri, 3 Oct 2025 12:42:37 GMT   (818kb)

Title: Lightweight Prompt Engineering for Cognitive Alignment in Educational
  AI: A OneClickQuiz Case Study
Authors: Antoun Yaacoub, Zainab Assaghir, J\'er\^ome Da-Rugna
Categories: cs.CY cs.AI cs.CL
Comments: Published in the 36th Central European Conference on Information and
  Intelligent Systems(CECIIS)at: Vara\v{z}din, Croatia. September 17-19/2025.
  ISSN 1847-2001 (Print). ISSN 1848-2295 (Online)
\\
  The rapid integration of Artificial Intelligence (AI) into educational
technology promises to revolutionize content creation and assessment. However,
the quality and pedagogical alignment of AI-generated content remain critical
challenges. This paper investigates the impact of lightweight prompt
engineering strategies on the cognitive alignment of AI-generated questions
within OneClickQuiz, a Moodle plugin leveraging generative AI. We evaluate
three prompt variants-a detailed baseline, a simpler version, and a
persona-based approach-across Knowledge, Application, and Analysis levels of
Bloom's Taxonomy. Utilizing an automated classification model (from prior work)
and human review, our findings demonstrate that explicit, detailed prompts are
crucial for precise cognitive alignment. While simpler and persona-based
prompts yield clear and relevant questions, they frequently misalign with
intended Bloom's levels, generating outputs that are either too complex or
deviate from the desired cognitive objective. This study underscores the
importance of strategic prompt engineering in fostering pedagogically sound
AI-driven educational solutions and advises on optimizing AI for quality
content generation in learning analytics and smart learning environments.
\\ ( https://arxiv.org/abs/2510.03374 ,  818kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03379 (*cross-listing*)
Date: Fri, 3 Oct 2025 15:06:19 GMT   (175kb)

Title: Can an AI-Powered Presentation Platform Based On The Game "Just a
  Minute" Be Used To Improve Students' Public Speaking Skills?
Authors: Frederic Higham, Tommy Yuan
Categories: cs.CY cs.AI
Comments: 11 pages, to be presented orally at the International Conference on
  Education and Artificial Intelligence Technologies (Nov 2025)
\\
  This study explores the effectiveness of applying AI and gamification into a
presentation platform aimed at University students wanting to improve their
public speaking skills in their native tongue. Specifically, a platform based
on the radio show, Just a Minute (JAM), is explored. In this game, players are
challenged to speak fluently on a topic for 60 seconds without repeating
themselves, hesitating or deviating from the topic. JAM has proposed benefits
such as allowing students to improve their spontaneous speaking skills and
reduce their use of speech disfluencies ("um", "uh", etc.).
  Previous research has highlighted the difficulties students face when
speaking publicly, the main one being anxiety. AI Powered Presentation
Platforms (AI-PPPs), where students can speak with an immersive AI audience and
receive real-time feedback, have been explored as a method to improve student's
speaking skills and confidence. So far they have shown promising results which
this study aims to build upon.
  A group of students from the University of York are enlisted to evaluate the
effectiveness of the JAM platform. They are asked to fill in a questionnaire,
play through the game twice and then complete a final questionnaire to discuss
their experiences playing the game. Various statistics are gathered during
their gameplay such as the number of points they gained and the number of rules
they broke. The results showed that students found the game promising and
believed that their speaking skills could improve if they played the game for
longer. More work will need to be carried out to prove the effectiveness of the
game beyond the short term.
\\ ( https://arxiv.org/abs/2510.03379 ,  175kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03380 (*cross-listing*)
Date: Fri, 3 Oct 2025 15:23:43 GMT   (2238kb,D)

Title: A Robust Clustered Federated Learning Approach for Non-IID Data with
  Quantity Skew
Authors: Michael Ben Ali (IRIT, IRIT-SIG, UT3), Imen Megdiche (IRIT, IRIT-SIG,
  INUC), Andr\'e Peninou (IRIT, IRIT-SIG, UT2J), Olivier Teste (IRIT-SIG, IRIT,
  UT2J, Comue de Toulouse)
Categories: cs.LG cs.AI
\\
  Federated Learning (FL) is a decentralized paradigm that enables a
client-server architecture to collaboratively train a global Artificial
Intelligence model without sharing raw data, thereby preserving privacy. A key
challenge in FL is Non-IID data. Quantity Skew (QS) is a particular problem of
Non-IID, where clients hold highly heterogeneous data volumes. Clustered
Federated Learning (CFL) is an emergent variant of FL that presents a promising
solution to Non-IID problem. It improves models' performance by grouping
clients with similar data distributions into clusters. CFL methods generally
fall into two operating strategies. In the first strategy, clients select the
cluster that minimizes the local training loss. In the second strategy, the
server groups clients based on local model similarities. However, most CFL
methods lack systematic evaluation under QS but present significant challenges
because of it. In this paper, we present two main contributions. The first one
is an evaluation of state-of-the-art CFL algorithms under various Non-IID
settings, applying multiple QS scenarios to assess their robustness. Our second
contribution is a novel iterative CFL algorithm, named CORNFLQS, which proposes
an optimal coordination between both operating strategies of CFL. Our approach
is robust against the different variations of QS settings. We conducted
intensive experiments on six image classification datasets, resulting in 270
Non-IID configurations. The results show that CORNFLQS achieves the highest
average ranking in both accuracy and clustering quality, as well as strong
robustness to QS perturbations. Overall, our approach outperforms actual CFL
algorithms.
\\ ( https://arxiv.org/abs/2510.03380 ,  2238kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03381 (*cross-listing*)
Date: Fri, 3 Oct 2025 15:26:56 GMT   (5987kb)

Title: Cross-Modal Reconstruction Pretraining for Ramp Flow Prediction at
  Highway Interchanges
Authors: Yongchao Li, Jun Chen, Zhuoxuan Li, Chao Gao, Yang Li, Chu Zhang,
  Changyin Dong
Categories: cs.LG cs.AI
\\
  Interchanges are crucial nodes for vehicle transfers between highways, yet
the lack of real-time ramp detectors creates blind spots in traffic prediction.
To address this, we propose a Spatio-Temporal Decoupled Autoencoder (STDAE), a
two-stage framework that leverages cross-modal reconstruction pretraining. In
the first stage, STDAE reconstructs historical ramp flows from mainline data,
forcing the model to capture intrinsic spatio-temporal relations. Its decoupled
architecture with parallel spatial and temporal autoencoders efficiently
extracts heterogeneous features. In the prediction stage, the learned
representations are integrated with models such as GWNet to enhance accuracy.
Experiments on three real-world interchange datasets show that STDAE-GWNET
consistently outperforms thirteen state-of-the-art baselines and achieves
performance comparable to models using historical ramp data. This demonstrates
its effectiveness in overcoming detector scarcity and its plug-and-play
potential for diverse forecasting pipelines.
\\ ( https://arxiv.org/abs/2510.03381 ,  5987kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03413 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:22:47 GMT   (24751kb)

Title: Report of the 2025 Workshop on Next-Generation Ecosystems for Scientific
  Computing: Harnessing Community, Software, and AI for Cross-Disciplinary Team
  Science
Authors: L.C. McInnes, D. Arnold, P. Balaprakash, M. Bernhardt, B. Cerny, A.
  Dubey, R. Giles, D.W. Hood, M.A. Leung, V. Lopez-Marrero, P. Messina, O.B.
  Newton, C. Oehmen, S.M. Wild, J. Willenbring, L. Woodley, T. Baylis, D.E.
  Bernholdt, C. Camano, J. Cohoon, C. Ferenbaugh, S.M. Fiore, S. Gesing, D.
  Gomez-Zara, J. Howison, T. Islam, D. Kepczynski, C. Lively, H. Menon, B.
  Messer, M. Ngom, U. Paliath, M.E. Papka, I. Qualters, E.M. Raybourn, K.
  Riley, P. Rodriguez, D. Rouson, M. Schwalbe, S.K. Seal, O. Surer, V. Taylor,
  and L. Wu
Categories: cs.CE cs.AI cs.MS
Comments: 38 pages, 6 figures
Report-no: ANL-25/47
MSC-class: 68T01, 68U01, 97M10
ACM-class: I.6.0; I.2.0; G.4; D.0
\\
  This report summarizes insights from the 2025 Workshop on Next-Generation
Ecosystems for Scientific Computing: Harnessing Community, Software, and AI for
Cross-Disciplinary Team Science, which convened more than 40 experts from
national laboratories, academia, industry, and community organizations to chart
a path toward more powerful, sustainable, and collaborative scientific software
ecosystems. To address urgent challenges at the intersection of
high-performance computing (HPC), AI, and scientific software, participants
envisioned agile, robust ecosystems built through socio-technical
co-design--the intentional integration of social and technical components as
interdependent parts of a unified strategy. This approach combines advances in
AI, HPC, and software with new models for cross-disciplinary collaboration,
training, and workforce development. Key recommendations include building
modular, trustworthy AI-enabled scientific software systems; enabling
scientific teams to integrate AI systems into their workflows while preserving
human creativity, trust, and scientific rigor; and creating innovative training
pipelines that keep pace with rapid technological change. Pilot projects were
identified as near-term catalysts, with initial priorities focused on hybrid
AI/HPC infrastructure, cross-disciplinary collaboration and pedagogy,
responsible AI guidelines, and prototyping of public-private partnerships. This
report presents a vision of next-generation ecosystems for scientific computing
where AI, software, hardware, and human expertise are interwoven to drive
discovery, expand access, strengthen the workforce, and accelerate scientific
progress.
\\ ( https://arxiv.org/abs/2510.03413 ,  24751kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03415 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:23:26 GMT   (1137kb)

Title: PLSEMANTICSBENCH: Large Language Models As Programming Language
  Interpreters
Authors: Aditya Thimmaiah, Jiyang Zhang, Jayanth Srinivasa, Junyi Jessy Li, and
  Milos Gligoric
Categories: cs.PL cs.AI cs.CL cs.SE
\\
  As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.
\\ ( https://arxiv.org/abs/2510.03415 ,  1137kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03417 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:24:14 GMT   (13041kb)

Title: NEXUS: Network Exploration for eXploiting Unsafe Sequences in Multi-Turn
  LLM Jailbreaks
Authors: Javad Rafiei Asl, Sidhant Narula, Mohammad Ghasemigol, Eduardo Blanco,
  Daniel Takabi
Categories: cs.CR cs.AI
Comments: Javad Rafiei Asl and Sidhant Narula are co-first authors
\\
  Large Language Models (LLMs) have revolutionized natural language processing
but remain vulnerable to jailbreak attacks, especially multi-turn jailbreaks
that distribute malicious intent across benign exchanges and bypass alignment
mechanisms. Existing approaches often explore the adversarial space poorly,
rely on hand-crafted heuristics, or lack systematic query refinement. We
present NEXUS (Network Exploration for eXploiting Unsafe Sequences), a modular
framework for constructing, refining, and executing optimized multi-turn
attacks. NEXUS comprises: (1) ThoughtNet, which hierarchically expands a
harmful intent into a structured semantic network of topics, entities, and
query chains; (2) a feedback-driven Simulator that iteratively refines and
prunes these chains through attacker-victim-judge LLM collaboration using
harmfulness and semantic-similarity benchmarks; and (3) a Network Traverser
that adaptively navigates the refined query space for real-time attacks. This
pipeline uncovers stealthy, high-success adversarial paths across LLMs. On
several closed-source and open-source LLMs, NEXUS increases attack success rate
by 2.1% to 19.4% over prior methods. Code: https://github.com/inspire-lab/NEXUS
\\ ( https://arxiv.org/abs/2510.03417 ,  13041kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03419 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:26:23 GMT   (25395kb)

Title: Multi-task neural diffusion processes for uncertainty-quantified wind
  power prediction
Authors: Joseph Rawson, Domniki Ladopoulou and Petros Dellaportas
Categories: cs.LG cs.AI stat.AP stat.ML
Comments: 36 pages, 13 figures, 2 tables,
\\
  Uncertainty-aware wind power prediction is essential for grid integration and
reliable wind farm operation. We apply neural diffusion processes (NDPs)-a
recent class of models that learn distributions over functions-and extend them
to a multi-task NDP (MT-NDP) framework for wind power prediction. We provide
the first empirical evaluation of NDPs in real supervisory control and data
acquisition (SCADA) data. We introduce a task encoder within MT-NDPs to capture
cross-turbine correlations and enable few-shot adaptation to unseen turbines.
The proposed MT-NDP framework outperforms single-task NDPs and GPs in terms of
point accuracy and calibration, particularly for wind turbines whose behaviour
deviates from the fleet average. In general, NDP-based models deliver
calibrated and scalable predictions suitable for operational deployment,
offering sharper, yet trustworthy, predictive intervals that can support
dispatch and maintenance decisions in modern wind farms.
\\ ( https://arxiv.org/abs/2510.03419 ,  25395kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03426 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:38:26 GMT   (6504kb)

Title: Generalized Orders of Magnitude for Scalable, Parallel,
  High-Dynamic-Range Computation
Authors: Franz A. Heinsen and Leo Kozachkov
Categories: cs.LG cs.AI cs.NA math.NA
Comments: 18 pages, 4 figures (main text). 14 pages, 21 figures (appendix)
Journal-ref: Transactions on Machine Learning Research (TMLR), 2025
\\
  Many domains, from deep learning to finance, require compounding real numbers
over long sequences, often leading to catastrophic numerical underflow or
overflow. We introduce generalized orders of magnitude (GOOMs), a principled
extension of traditional orders of magnitude that incorporates floating-point
numbers as a special case, and which in practice enables stable computation
over significantly larger dynamic ranges of real numbers than previously
possible. We implement GOOMs, along with an efficient custom parallel prefix
scan, to support native execution on parallel hardware such as GPUs. We
demonstrate that our implementation of GOOMs outperforms traditional approaches
with three representative experiments, all of which were previously considered
impractical or impossible, and now become possible and practical: (1)
compounding real matrix products far beyond standard floating-point limits; (2)
estimating spectra of Lyapunov exponents in parallel, orders of magnitude
faster than with previous methods, applying a novel selective-resetting method
to prevent state colinearity; and (3) capturing long-range dependencies in deep
recurrent neural networks with non-diagonal recurrent states, computed in
parallel via a prefix scan, without requiring any form of stabilization. Our
results show that our implementation of GOOMs, combined with efficient parallel
scanning, offers a scalable and numerically robust alternative to conventional
floating-point numbers for high-dynamic-range applications.
\\ ( https://arxiv.org/abs/2510.03426 ,  6504kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03431 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:49:51 GMT   (7374kb)

Title: Application of a Virtual Imaging Framework for Investigating a Deep
  Learning-Based Reconstruction Method for 3D Quantitative Photoacoustic
  Computed Tomography
Authors: Refik Mert Cam, Seonyeong Park, Umberto Villa, Mark A. Anastasio
Categories: physics.med-ph cs.AI eess.SP
Comments: Preprint submitted to Elsevier Photoacoustics
\\
  Quantitative photoacoustic computed tomography (qPACT) is a promising imaging
modality for estimating physiological parameters such as blood oxygen
saturation. However, developing robust qPACT reconstruction methods remains
challenging due to computational demands, modeling difficulties, and
experimental uncertainties. Learning-based methods have been proposed to
address these issues but remain largely unvalidated. Virtual imaging (VI)
studies are essential for validating such methods early in development, before
proceeding to less-controlled phantom or in vivo studies. Effective VI studies
must employ ensembles of stochastically generated numerical phantoms that
accurately reflect relevant anatomy and physiology. Yet, most prior VI studies
for qPACT relied on overly simplified phantoms. In this work, a realistic VI
testbed is employed for the first time to assess a representative 3D
learning-based qPACT reconstruction method for breast imaging. The method is
evaluated across subject variability and physical factors such as measurement
noise and acoustic aberrations, offering insights into its strengths and
limitations.
\\ ( https://arxiv.org/abs/2510.03431 ,  7374kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03438 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:58:15 GMT   (2622kb)

Title: Scalable Ground Station Selection for Large LEO Constellations
Authors: Grace Ra Kim, Duncan Eddy, Vedant Srinivas, and Mykel J. Kochenderfer
Categories: cs.NI cs.AI cs.SY eess.SY
Comments: 14 pages, 7 tables, 10 figures, submitted to IEEE Aeroconf 2026
\\
  Effective ground station selection is critical for low Earth orbiting (LEO)
satellite constellations to minimize operational costs, maximize data downlink
volume, and reduce communication gaps between access windows. Traditional
ground station selection typically begins by choosing from a fixed set of
locations offered by Ground Station-as-a-Service (GSaaS) providers, which helps
reduce the problem scope to optimizing locations over existing infrastructure.
However, finding a globally optimal solution for stations using existing
mixed-integer programming methods quickly becomes intractable at scale,
especially when considering multiple providers and large satellite
constellations. To address this issue, we introduce a scalable, hierarchical
framework that decomposes the global selection problem into single-satellite,
short time-window subproblems. Optimal station choices from each subproblem are
clustered to identify consistently high-value locations across all decomposed
cases. Cluster-level sets are then matched back to the closest GSaaS candidate
sites to produce a globally feasible solution. This approach enables scalable
coordination while maintaining near-optimal performance. We evaluate our
method's performance on synthetic Walker-Star test cases (1-10 satellites, 1-10
stations), achieving solutions within 95% of the global IP optimum for all test
cases. Real-world evaluations on Capella Space (5 satellites), ICEYE (40), and
Planet's Flock (96) show that while exact IP solutions fail to scale, our
framework continues to deliver high-quality site selections.
\\ ( https://arxiv.org/abs/2510.03438 ,  2622kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03442 (*cross-listing*)
Date: Fri, 3 Oct 2025 19:04:15 GMT   (3188kb)

Title: The Argument is the Explanation: Structured Argumentation for Trust in
  Agents
Authors: Ege Cakar, Per Ola Kristensson
Categories: cs.LG cs.AI cs.MA
Comments: 8 pages, 4 figures, 6 tables, submitted to IAAI-26
\\
  Humans are black boxes -- we cannot observe their neural processes, yet
society functions by evaluating verifiable arguments. AI explainability should
follow this principle: stakeholders need verifiable reasoning chains, not
mechanistic transparency. We propose using structured argumentation to provide
a level of explanation and verification neither interpretability nor
LLM-generated explanation is able to offer. Our pipeline achieves
state-of-the-art 94.44 macro F1 on the AAEC published train/test split (5.7
points above prior work) and $0.81$ macro F1, $\sim$0.07 above previous
published results with comparable data setups, for Argumentative MicroTexts
relation classification, converting LLM text into argument graphs and enabling
verification at each inferential step. We demonstrate this idea on multi-agent
risk assessment using the Structured What-If Technique, where specialized
agents collaborate transparently to carry out risk assessment otherwise
achieved by humans alone. Using Bipolar Assumption-Based Argumentation, we
capture support/attack relationships, thereby enabling automatic hallucination
detection via fact nodes attacking arguments. We also provide a verification
mechanism that enables iterative refinement through test-time feedback without
retraining. For easy deployment, we provide a Docker container for the
fine-tuned AMT model, and the rest of the code with the Bipolar ABA Python
package on GitHub.
\\ ( https://arxiv.org/abs/2510.03442 ,  3188kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03463 (*cross-listing*)
Date: Fri, 3 Oct 2025 19:35:23 GMT   (501kb)

Title: ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering
  Framework
Authors: Vali Tawosi, Keshav Ramani, Salwa Alamir, Xiaomo Liu
Categories: cs.SE cs.AI
\\
  Multi-agent Large Language Model (LLM) systems have been leading the way in
applied LLM research across a number of fields. One notable area is software
development, where researchers have advanced the automation of code
implementation, code testing, code maintenance, inter alia, using LLM agents.
However, software development is a multifaceted environment that extends beyond
just code. As such, a successful LLM system must factor in multiple stages of
the software development life-cycle (SDLC). In this paper, we propose a vision
for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework,
which follows the above SDLC philosophy such that it may work within an agile
software development team to perform several tasks end-to-end. ALMAS aligns its
agents with agile roles, and can be used in a modular fashion to seamlessly
integrate with human developers and their development environment. We showcase
the progress towards ALMAS through our published works and a use case
demonstrating the framework, where ALMAS is able to seamlessly generate an
application and add a new feature.
\\ ( https://arxiv.org/abs/2510.03463 ,  501kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03472 (*cross-listing*)
Date: Fri, 3 Oct 2025 19:49:37 GMT   (779kb)

Title: Destination-to-Chutes Task Mapping Optimization for Multi-Robot
  Coordination in Robotic Sorting Systems
Authors: Yulun Zhang, Alexandre O. G. Barbosa, Federico Pecora, Jiaoyang Li
Categories: cs.RO cs.AI cs.MA
Comments: Accepted to IEEE International Symposium on Multi-Robot and
  Multi-Agent Systems (MRS) 2025
\\
  We study optimizing a destination-to-chutes task mapping to improve
throughput in Robotic Sorting Systems (RSS), where a team of robots sort
packages on a sortation floor by transporting them from induct workstations to
eject chutes based on their shipping destinations (e.g. Los Angeles or
Pittsburgh). The destination-to-chutes task mapping is used to determine which
chutes a robot can drop its package. Finding a high-quality task mapping is
challenging because of the complexity of a real-world RSS. First, optimizing
task mapping is interdependent with robot target assignment and path planning.
Second, chutes will be CLOSED for a period of time once they receive sufficient
packages to allow for downstream processing. Third, task mapping quality
directly impacts the downstream processing, as scattered chutes for the same
destination increase package handling time. In this paper, we first formally
define task mappings and the problem of Task Mapping Optimization (TMO). We
then present a simulator of RSS to evaluate task mappings. We then present a
simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear
Programming, demonstrating the advantage of our optimized task mappings over
the greedily generated ones in various RSS setups with different map sizes,
numbers of chutes, and destinations. Finally, we use Quality Diversity
algorithms to analyze the throughput of a diverse set of task mappings. Our
code is available online at https://github.com/lunjohnzhang/tmo_public.
\\ ( https://arxiv.org/abs/2510.03472 ,  779kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03486 (*cross-listing*)
Date: Fri, 3 Oct 2025 20:06:31 GMT   (5399kb)

Title: Reasoning-based Anomaly Detection Framework: A Real-time, Scalable, and
  Automated Approach to Anomaly Detection Across Domains
Authors: Anupam Panwar, Himadri Pal, Jiali Chen, Kyle Cho, Riddick Jiang, Miao
  Zhao, Rajiv Krishnamurthy
Categories: cs.LG cs.AI
Comments: 11 pages, 7 figures
\\
  Detecting anomalies in large, distributed systems presents several
challenges. The first challenge arises from the sheer volume of data that needs
to be processed. Flagging anomalies in a high-throughput environment calls for
a careful consideration of both algorithm and system design. The second
challenge comes from the heterogeneity of time-series datasets that leverage
such a system in production. In practice, anomaly detection systems are rarely
deployed for a single use case. Typically, there are several metrics to
monitor, often across several domains (e.g. engineering, business and
operations). A one-size-fits-all approach rarely works, so these systems need
to be fine-tuned for every application - this is often done manually. The third
challenge comes from the fact that determining the root-cause of anomalies in
such settings is akin to finding a needle in a haystack. Identifying (in real
time) a time-series dataset that is associated causally with the anomalous
time-series data is a very difficult problem. In this paper, we describe a
unified framework that addresses these challenges. Reasoning based Anomaly
Detection Framework (RADF) is designed to perform real time anomaly detection
on very large datasets. This framework employs a novel technique (mSelect) that
automates the process of algorithm selection and hyper-parameter tuning for
each use case. Finally, it incorporates a post-detection capability that allows
for faster triaging and root-cause determination. Our extensive experiments
demonstrate that RADF, powered by mSelect, surpasses state-of-the-art anomaly
detection models in AUC performance for 5 out of 9 public benchmarking
datasets. RADF achieved an AUC of over 0.85 for 7 out of 9 datasets, a
distinction unmatched by any other state-of-the-art model.
\\ ( https://arxiv.org/abs/2510.03486 ,  5399kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03495 (*cross-listing*)
Date: Fri, 3 Oct 2025 20:18:58 GMT   (693kb)

Title: AgentHub: A Research Agenda for Agent Sharing Infrastructure
Authors: Erik Pautsch, Tanmay Singla, Wenxin Jiang, Huiyun Peng, Behnaz
  Hassanshahi, Konstantin L\"aufer, George K.Thiruvathukal, James C. Davis
Categories: cs.SE cs.AI
\\
  LLM-based agents are rapidly proliferating, yet the infrastructure for
discovering, evaluating, and governing them remains fragmented compared to
mature ecosystems like software package registries (e.g., npm) and model hubs
(e.g., Hugging Face). Recent research and engineering works have begun to
consider the requisite infrastructure, but so far they focus narrowly -- on
distribution, naming, or protocol negotiation. However, considering broader
software engineering requirements would improve open-source distribution and
ease reuse. We therefore propose AgentHub, a research agenda for agent sharing.
By framing the key challenges of capability clarity, lifecycle transparency,
interoperability, governance, security, and workflow integration, AgentHub
charts a community-wide agenda for building reliable and scalable agent
ecosystems. Our vision is a future where agents can be shared, trusted, and
composed as seamlessly as today's software libraries.
\\ ( https://arxiv.org/abs/2510.03495 ,  693kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03514 (*cross-listing*)
Date: Fri, 3 Oct 2025 20:55:04 GMT   (2065kb)

Title: Red Lines and Grey Zones in the Fog of War: Benchmarking Legal Risk,
  Moral Harm, and Regional Bias in Large Language Model Military
  Decision-Making
Authors: Toby Drinkall
Categories: cs.CY cs.AI cs.CL
Comments: 54 pages; 11 figures
\\
  As military organisations consider integrating large language models (LLMs)
into command and control (C2) systems for planning and decision support,
understanding their behavioural tendencies is critical. This study develops a
benchmarking framework for evaluating aspects of legal and moral risk in
targeting behaviour by comparing LLMs acting as agents in multi-turn simulated
conflict. We introduce four metrics grounded in International Humanitarian Law
(IHL) and military doctrine: Civilian Target Rate (CTR) and Dual-use Target
Rate (DTR) assess compliance with legal targeting principles, while Mean and
Max Simulated Non-combatant Casualty Value (SNCV) quantify tolerance for
civilian harm.
  We evaluate three frontier models, GPT-4o, Gemini-2.5, and LLaMA-3.1, through
90 multi-agent, multi-turn crisis simulations across three geographic regions.
Our findings reveal that off-the-shelf LLMs exhibit concerning and
unpredictable targeting behaviour in simulated conflict environments. All
models violated the IHL principle of distinction by targeting civilian objects,
with breach rates ranging from 16.7% to 66.7%. Harm tolerance escalated through
crisis simulations with MeanSNCV increasing from 16.5 in early turns to 27.7 in
late turns. Significant inter-model variation emerged: LLaMA-3.1 selected an
average of 3.47 civilian strikes per simulation with MeanSNCV of 28.4, while
Gemini-2.5 selected 0.90 civilian strikes with MeanSNCV of 17.6. These
differences indicate that model selection for deployment constitutes a choice
about acceptable legal and moral risk profiles in military operations.
  This work seeks to provide a proof-of-concept of potential behavioural risks
that could emerge from the use of LLMs in Decision Support Systems (AI DSS) as
well as a reproducible benchmarking framework with interpretable metrics for
standardising pre-deployment testing.
\\ ( https://arxiv.org/abs/2510.03514 ,  2065kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03520 (*cross-listing*)
Date: Fri, 3 Oct 2025 21:24:41 GMT   (1022kb)

Title: Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer
  Language Models
Authors: Kartik Pandit, Sourav Ganguly, Arnesh Banerjee, Shaahin Angizi and
  Arnob Ghosh
Categories: cs.LG cs.AI cs.SY eess.SY
\\
  Ensuring safety is a foundational requirement for large language models
(LLMs). Achieving an appropriate balance between enhancing the utility of model
outputs and mitigating their potential for harm is a complex and persistent
challenge. Contemporary approaches frequently formalize this problem within the
framework of Constrained Markov Decision Processes (CMDPs) and employ
established CMDP optimization techniques. However, these methods exhibit two
notable limitations. First, their reliance on reward and cost functions renders
performance highly sensitive to the underlying scoring mechanism, which must
capture semantic meaning rather than being triggered by superficial keywords.
Second, CMDP-based training entails tuning dual-variable, a process that is
both computationally expensive and does not provide any provable safety
guarantee for a fixed dual variable that can be exploitable through adversarial
jailbreaks. To overcome these limitations, we introduce Certifiable Safe-RLHF
(CS-RLHF) that introduces a cost model trained on a large-scale corpus to
assign semantically grounded safety scores. In contrast to the lagrangian-based
approach, CS-RLHF adopts a rectified penalty-based formulation. This design
draws on the theory of exact penalty functions in constrained optimization,
wherein constraint satisfaction is enforced directly through a suitably chosen
penalty term. With an appropriately scaled penalty, feasibility of the safety
constraints can be guaranteed at the optimizer, eliminating the need for
dual-variable updates. Empirical evaluation demonstrates that CS-RLHF
outperforms state-of-the-art LLM model responses rendering at-least 5 times
efficient against nominal and jail-breaking prompts
\\ ( https://arxiv.org/abs/2510.03520 ,  1022kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03544 (*cross-listing*)
Date: Fri, 3 Oct 2025 22:28:46 GMT   (8375kb)

Title: Agile Tradespace Exploration for Space Rendezvous Mission Design via
  Transformers
Authors: Yuji Takubo, Daniele Gammelli, Marco Pavone, Simone D'Amico
Categories: math.OC cs.AI cs.RO
Comments: 14 pages, 7 figures
\\
  Spacecraft rendezvous enables on-orbit servicing, debris removal, and crewed
docking, forming the foundation for a scalable space economy. Designing such
missions requires rapid exploration of the tradespace between control cost and
flight time across multiple candidate targets. However, multi-objective
optimization in this setting is challenging, as the underlying constraints are
often highly nonconvex, and mission designers must balance accuracy (e.g.,
solving the full problem) with efficiency (e.g., convex relaxations), slowing
iteration and limiting design agility. To address these challenges, this paper
proposes an AI-powered framework that enables agile mission design for a wide
range of Earth orbit rendezvous scenarios. Given the orbital information of the
target spacecraft, boundary conditions, and a range of flight times, this work
proposes a Transformer-based architecture that generates, in a single
parallelized inference step, a set of near-Pareto optimal trajectories across
varying flight times, thereby enabling rapid mission trade studies. The model
is further extended to accommodate variable flight times and perturbed orbital
dynamics, supporting realistic multi-objective trade-offs. Validation on
chance-constrained rendezvous problems with passive safety constraints
demonstrates that the model generalizes across both flight times and dynamics,
consistently providing high-quality initial guesses that converge to superior
solutions in fewer iterations. Moreover, the framework efficiently approximates
the Pareto front, achieving runtimes comparable to convex relaxation by
exploiting parallelized inference. Together, these results position the
proposed framework as a practical surrogate for nonconvex trajectory generation
and mark an important step toward AI-driven trajectory design for accelerating
preliminary mission planning in real-world rendezvous applications.
\\ ( https://arxiv.org/abs/2510.03544 ,  8375kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03569 (*cross-listing*)
Date: Fri, 3 Oct 2025 23:33:50 GMT   (7906kb)

Title: Longitudinal Flow Matching for Trajectory Modeling
Authors: Mohammad Mohaiminul Islam, Thijs P. Kuipers, Sharvaree Vadgama, Coen
  de Vente, Afsana Khan, Clara I. S\'anchez, Erik J. Bekkers
Categories: cs.LG cs.AI cs.CV stat.ML
\\
  Generative models for sequential data often struggle with sparsely sampled
and high-dimensional trajectories, typically reducing the learning of dynamics
to pairwise transitions. We propose \textit{Interpolative Multi-Marginal Flow
Matching} (IMMFM), a framework that learns continuous stochastic dynamics
jointly consistent with multiple observed time points. IMMFM employs a
piecewise-quadratic interpolation path as a smooth target for flow matching and
jointly optimizes drift and a data-driven diffusion coefficient, supported by a
theoretical condition for stable learning. This design captures intrinsic
stochasticity, handles irregular sparse sampling, and yields subject-specific
trajectories. Experiments on synthetic benchmarks and real-world longitudinal
neuroimaging datasets show that IMMFM outperforms existing methods in both
forecasting accuracy and further downstream tasks.
\\ ( https://arxiv.org/abs/2510.03569 ,  7906kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03571 (*cross-listing*)
Date: Fri, 3 Oct 2025 23:46:31 GMT   (446kb)

Title: Generalization of Graph Neural Network Models for Distribution Grid
  Fault Detection
Authors: Burak Karabulut, Carlo Manna, Chris Develder
Categories: cs.LG cs.AI cs.SY eess.SY
Comments: This paper has been submitted and accepted for IEEE SmartGridComm
  2025
ACM-class: I.2.6; I.2.7; C.2.1
\\
  Fault detection in power distribution grids is critical for ensuring system
reliability and preventing costly outages. Moreover, fault detection
methodologies should remain robust to evolving grid topologies caused by
factors such as reconfigurations, equipment failures, and Distributed Energy
Resource (DER) integration. Current data-driven state-of-the-art methods use
Recurrent Neural Networks (RNNs) for temporal modeling and Graph Neural
Networks (GNNs) for spatial learning, in an RNN+GNN pipeline setting (RGNN in
short). Specifically, for power system fault diagnosis, Graph Convolutional
Networks (GCNs) have been adopted. Yet, various more advanced GNN architectures
have been proposed and adopted in domains outside of power systems. In this
paper, we set out to systematically and consistently benchmark various GNN
architectures in an RNN+GNN pipeline model. Specifically, to the best of our
knowledge, we are the first to (i) propose to use GraphSAGE and Graph Attention
(GAT, GATv2) in an RGNN for fault diagnosis, and (ii) provide a comprehensive
benchmark against earlier proposed RGNN solutions (RGCN) as well as pure RNN
models (especially Gated Recurrent Unit (GRU)), particularly (iii) exploring
their generalization potential for deployment in different settings than those
used for training them. Our experimental results on the IEEE 123-node
distribution network show that RGATv2 has superior generalization capabilities,
maintaining high performance with an F1-score reduction of $\sim$12% across
different topology settings. In contrast, pure RNN models largely fail,
experiencing an F1-score reduction of up to $\sim$60%, while other RGNN
variants also exhibit significant performance degradation, i.e., up to
$\sim$25% lower F1-scores.
\\ ( https://arxiv.org/abs/2510.03571 ,  446kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03578 (*cross-listing*)
Date: Sat, 4 Oct 2025 00:06:31 GMT   (1845kb)

Title: Latent Mixture of Symmetries for Sample-Efficient Dynamic Learning
Authors: Haoran Li and Chenhan Xiao and Muhao Guo and Yang Weng
Categories: cs.LG cs.AI stat.ML
Comments: 30 pages, 6 figures
\\
  Learning dynamics is essential for model-based control and Reinforcement
Learning in engineering systems, such as robotics and power systems. However,
limited system measurements, such as those from low-resolution sensors, demand
sample-efficient learning. Symmetry provides a powerful inductive bias by
characterizing equivariant relations in system states to improve sample
efficiency. While recent methods attempt to discover symmetries from data, they
typically assume a single global symmetry group and treat symmetry discovery
and dynamic learning as separate tasks, leading to limited expressiveness and
error accumulation. In this paper, we propose the Latent Mixture of Symmetries
(Latent MoS), an expressive model that captures a mixture of symmetry-governed
latent factors from complex dynamical measurements. Latent MoS focuses on
dynamic learning while locally and provably preserving the underlying symmetric
transformations. To further capture long-term equivariance, we introduce a
hierarchical architecture that stacks MoS blocks. Numerical experiments in
diverse physical systems demonstrate that Latent MoS outperforms
state-of-the-art baselines in interpolation and extrapolation tasks while
offering interpretable latent representations suitable for future geometric and
safety-critical analyses.
\\ ( https://arxiv.org/abs/2510.03578 ,  1845kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03582 (*cross-listing*)
Date: Sat, 4 Oct 2025 00:15:45 GMT   (33230kb)

Title: Deep learning the sources of MJO predictability: a spectral view of
  learned features
Authors: Lin Yao, Da Yang, James P.C. Duncan, Ashesh Chattopadhyay, Pedram
  Hassanzadeh, Wahid Bhimji, and Bin Yu
Categories: physics.ao-ph cs.AI
\\
  The Madden-Julian oscillation (MJO) is a planetary-scale, intraseasonal
tropical rainfall phenomenon crucial for global weather and climate; however,
its dynamics and predictability remain poorly understood. Here, we leverage
deep learning (DL) to investigate the sources of MJO predictability, motivated
by a central difference in MJO theories: which spatial scales are essential for
driving the MJO? We first develop a deep convolutional neural network (DCNN) to
forecast the MJO indices (RMM and ROMI). Our model predicts RMM and ROMI up to
21 and 33 days, respectively, achieving skills comparable to leading
subseasonal-to-seasonal models such as NCEP. To identify the spatial scales
most relevant for MJO forecasting, we conduct spectral analysis of the latent
feature space and find that large-scale patterns dominate the learned signals.
Additional experiments show that models using only large-scale signals as the
input have the same skills as those using all the scales, supporting the
large-scale view of the MJO. Meanwhile, we find that small-scale signals remain
informative: surprisingly, models using only small-scale input can still
produce skillful forecasts up to 1-2 weeks ahead. We show that this is achieved
by reconstructing the large-scale envelope of the small-scale activities, which
aligns with the multi-scale view of the MJO. Altogether, our findings support
that large-scale patterns--whether directly included or reconstructed--may be
the primary source of MJO predictability.
\\ ( https://arxiv.org/abs/2510.03582 ,  33230kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03592 (*cross-listing*)
Date: Sat, 4 Oct 2025 00:47:20 GMT   (1903kb)

Title: Deep Reinforcement Learning for Multi-Agent Coordination
Authors: Kehinde O. Aina and Sehoon Ha
Categories: cs.LG cs.AI cs.MA cs.RO
Comments: 11 pages, 8 figures, 1 table, presented at SWARM 2022, to be
  published in Journal of Artificial Life and Robotics
\\
  We address the challenge of coordinating multiple robots in narrow and
confined environments, where congestion and interference often hinder
collective task performance. Drawing inspiration from insect colonies, which
achieve robust coordination through stigmergy -- modifying and interpreting
environmental traces -- we propose a Stigmergic Multi-Agent Deep Reinforcement
Learning (S-MADRL) framework that leverages virtual pheromones to model local
and social interactions, enabling decentralized emergent coordination without
explicit communication. To overcome the convergence and scalability limitations
of existing algorithms such as MADQN, MADDPG, and MAPPO, we leverage curriculum
learning, which decomposes complex tasks into progressively harder
sub-problems. Simulation results show that our framework achieves the most
effective coordination of up to eight agents, where robots self-organize into
asymmetric workload distributions that reduce congestion and modulate group
performance. This emergent behavior, analogous to strategies observed in
nature, demonstrates a scalable solution for decentralized multi-agent
coordination in crowded environments with communication constraints.
\\ ( https://arxiv.org/abs/2510.03592 ,  1903kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03597 (*cross-listing*)
Date: Sat, 4 Oct 2025 01:20:30 GMT   (4431kb)

Title: Neon: Negative Extrapolation From Self-Training Improves Image
  Generation
Authors: Sina Alemohammad, Zhangyang Wang, Richard G. Baraniuk
Categories: cs.GR cs.AI cs.LG
\\
  Scaling generative AI models is bottlenecked by the scarcity of high-quality
training data. The ease of synthesizing from a generative model suggests using
(unverified) synthetic data to augment a limited corpus of real data for the
purpose of fine-tuning in the hope of improving performance. Unfortunately,
however, the resulting positive feedback loop leads to model autophagy disorder
(MAD, aka model collapse) that results in a rapid degradation in sample quality
and/or diversity. In this paper, we introduce Neon (for Negative Extrapolation
frOm self-traiNing), a new learning method that turns the degradation from
self-training into a powerful signal for self-improvement. Given a base model,
Neon first fine-tunes it on its own self-synthesized data but then,
counterintuitively, reverses its gradient updates to extrapolate away from the
degraded weights. We prove that Neon works because typical inference samplers
that favor high-probability regions create a predictable anti-alignment between
the synthetic and real data population gradients, which negative extrapolation
corrects to better align the model with the true data distribution. Neon is
remarkably easy to implement via a simple post-hoc merge that requires no new
real data, works effectively with as few as 1k synthetic samples, and typically
uses less than 1% additional training compute. We demonstrate Neon's
universality across a range of architectures (diffusion, flow matching,
autoregressive, and inductive moment matching models) and datasets (ImageNet,
CIFAR-10, and FFHQ). In particular, on ImageNet 256x256, Neon elevates the
xAR-L model to a new state-of-the-art FID of 1.02 with only 0.36% additional
training compute. Code is available at https://github.com/SinaAlemohammad/Neon
\\ ( https://arxiv.org/abs/2510.03597 ,  4431kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03604 (*cross-listing*)
Date: Sat, 4 Oct 2025 01:37:40 GMT   (1346kb)

Title: Deep Domain Adaptation for Turbofan Engine Remaining Useful Life
  Prediction: Methodologies, Evaluation and Future Trends
Authors: Yucheng Wang, Mohamed Ragab, Yubo Hou, Zhenghua Chen, Min Wu, and
  Xiaoli Li
Categories: cs.LG cs.AI
\\
  Remaining Useful Life (RUL) prediction for turbofan engines plays a vital
role in predictive maintenance, ensuring operational safety and efficiency in
aviation. Although data-driven approaches using machine learning and deep
learning have shown potential, they face challenges such as limited data and
distribution shifts caused by varying operating conditions. Domain Adaptation
(DA) has emerged as a promising solution, enabling knowledge transfer from
source domains with abundant data to target domains with scarce data while
mitigating distributional shifts. Given the unique properties of turbofan
engines, such as complex operating conditions, high-dimensional sensor data,
and slower-changing signals, it is essential to conduct a focused review of DA
techniques specifically tailored to turbofan engines. To address this need,
this paper provides a comprehensive review of DA solutions for turbofan engine
RUL prediction, analyzing key methodologies, challenges, and recent
advancements. A novel taxonomy tailored to turbofan engines is introduced,
organizing approaches into methodology-based (how DA is applied),
alignment-based (where distributional shifts occur due to operational
variations), and problem-based (why certain adaptations are needed to address
specific challenges). This taxonomy offers a multidimensional view that goes
beyond traditional classifications by accounting for the distinctive
characteristics of turbofan engine data and the standard process of applying DA
techniques to this area. Additionally, we evaluate selected DA techniques on
turbofan engine datasets, providing practical insights for practitioners and
identifying key challenges. Future research directions are identified to guide
the development of more effective DA techniques, advancing the state of RUL
prediction for turbofan engines.
\\ ( https://arxiv.org/abs/2510.03604 ,  1346kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03610 (*cross-listing*)
Date: Sat, 4 Oct 2025 01:55:05 GMT   (288kb)

Title: PentestMCP: A Toolkit for Agentic Penetration Testing
Authors: Zachary Ezetta, Wu-chang Feng
Categories: cs.CR cs.AI
\\
  Agentic AI is transforming security by automating many tasks being performed
manually. While initial agentic approaches employed a monolithic architecture,
the Model-Context-Protocol has now enabled a remote-procedure call (RPC)
paradigm to agentic applications, allowing for the flexible construction and
composition of multi-function agents. This paper describes PentestMCP, a
library of MCP server implementations that support agentic penetration testing.
By supporting common penetration testing tasks such as network scanning,
resource enumeration, service fingerprinting, vulnerability scanning,
exploitation, and post-exploitation, PentestMCP allows a developer to customize
multi-agent workflows for performing penetration tests.
\\ ( https://arxiv.org/abs/2510.03610 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03614 (*cross-listing*)
Date: Sat, 4 Oct 2025 01:58:55 GMT   (4115kb)

Title: Neural Bayesian Filtering
Authors: Christopher Solinas, Radovan Haluska, David Sychrovsky, Finbarr
  Timbers, Nolan Bard, Michael Buro, Martin Schmid, Nathan R. Sturtevant,
  Michael Bowling
Categories: cs.LG cs.AI stat.ML
\\
  We present Neural Bayesian Filtering (NBF), an algorithm for maintaining
distributions over hidden states, called beliefs, in partially observable
systems. NBF is trained to find a good latent representation of the beliefs
induced by a task. It maps beliefs to fixed-length embedding vectors, which
condition generative models for sampling. During filtering, particle-style
updates compute posteriors in this embedding space using incoming observations
and the environment's dynamics. NBF combines the computational efficiency of
classical filters with the expressiveness of deep generative models - tracking
rapidly shifting, multimodal beliefs while mitigating the risk of particle
impoverishment. We validate NBF in state estimation tasks in three partially
observable environments.
\\ ( https://arxiv.org/abs/2510.03614 ,  4115kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03623 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:07:58 GMT   (1378kb)

Title: Explainable but Vulnerable: Adversarial Attacks on XAI Explanation in
  Cybersecurity Applications
Authors: Maraz Mia, Mir Mehedi A. Pritom
Categories: cs.CR cs.AI
Comments: 10 pages, 9 figures, 4 tables
Journal-ref: The 7th IEEE International Conference on Trust, Privacy, and
  Security in Intelligent Systems, and Applications (IEEE-TPS 2025)
\\
  Explainable Artificial Intelligence (XAI) has aided machine learning (ML)
researchers with the power of scrutinizing the decisions of the black-box
models. XAI methods enable looking deep inside the models' behavior, eventually
generating explanations along with a perceived trust and transparency. However,
depending on any specific XAI method, the level of trust can vary. It is
evident that XAI methods can themselves be a victim of post-adversarial attacks
that manipulate the expected outcome from the explanation module. Among such
attack tactics, fairwashing explanation (FE), manipulation explanation (ME),
and backdoor-enabled manipulation attacks (BD) are the notable ones. In this
paper, we try to understand these adversarial attack techniques, tactics, and
procedures (TTPs) on explanation alteration and thus the effect on the model's
decisions. We have explored a total of six different individual attack
procedures on post-hoc explanation methods such as SHAP (SHapley Additive
exPlanations), LIME (Local Interpretable Model-agnostic Explanation), and IG
(Integrated Gradients), and investigated those adversarial attacks in
cybersecurity applications scenarios such as phishing, malware, intrusion, and
fraudulent website detection. Our experimental study reveals the actual
effectiveness of these attacks, thus providing an urgency for immediate
attention to enhance the resiliency of XAI methods and their applications.
\\ ( https://arxiv.org/abs/2510.03623 ,  1378kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03633 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:31:44 GMT   (250kb)

Title: Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis
Authors: An Vuong and Susan Gauch
Categories: cs.LG cs.AI
Comments: 17th International Conference on Knowledge Discovery, Knowledge
  Engineering and Knowledge Management (KDIR 2025), Marbella, Spain, Oct.
  22-24, 2025 (to appear) Best Student Paper Finalist
\\
  Accurately predicting short-term stock price movement remains a challenging
task due to the market's inherent volatility and sensitivity to investor
sentiment. This paper discusses a deep learning framework that integrates
emotion features extracted from tweet data with historical stock price
information to forecast significant price changes on the following day. We
utilize Meta's Llama 3.1-8B-Instruct model to preprocess tweet data, thereby
enhancing the quality of emotion features derived from three emotion analysis
approaches: a transformer-based DistilRoBERTa classifier from the Hugging Face
library and two lexicon-based methods using National Research Council Canada
(NRC) resources. These features are combined with previous-day stock price data
to train a Long Short-Term Memory (LSTM) model. Experimental results on TSLA,
AAPL, and AMZN stocks show that all three emotion analysis methods improve the
average accuracy for predicting significant price movements, compared to the
baseline model using only historical stock prices, which yields an accuracy of
13.5%. The DistilRoBERTa-based stock prediction model achieves the best
performance, with accuracy rising from 23.6% to 38.5% when using LLaMA-enhanced
emotion analysis. These results demonstrate that using large language models to
preprocess tweet content enhances the effectiveness of emotion analysis which
in turn improves the accuracy of predicting significant stock price movements.
\\ ( https://arxiv.org/abs/2510.03633 ,  250kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03638 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:49:22 GMT   (389kb)

Title: Implicit Models: Expressive Power Scales with Test-Time Compute
Authors: Jialin Liu, Lisang Ding, Stanley Osher, Wotao Yin
Categories: cs.LG cs.AI math.RT stat.ML
\\
  Implicit models, an emerging model class, compute outputs by iterating a
single parameter block to a fixed point. This architecture realizes an
infinite-depth, weight-tied network that trains with constant memory,
significantly reducing memory needs for the same level of performance compared
to explicit models. While it is empirically known that these compact models can
often match or even exceed larger explicit networks by allocating more
test-time compute, the underlying mechanism remains poorly understood.
  We study this gap through a nonparametric analysis of expressive power. We
provide a strict mathematical characterization, showing that a simple and
regular implicit operator can, through iteration, progressively express more
complex mappings. We prove that for a broad class of implicit models, this
process lets the model's expressive power scale with test-time compute,
ultimately matching a much richer function class. The theory is validated
across three domains: image reconstruction, scientific computing, and
operations research, demonstrating that as test-time iterations increase, the
complexity of the learned mapping rises, while the solution quality
simultaneously improves and stabilizes.
\\ ( https://arxiv.org/abs/2510.03638 ,  389kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03650 (*cross-listing*)
Date: Sat, 4 Oct 2025 03:32:41 GMT   (2576kb)

Title: LLM-Guided Evolutionary Program Synthesis for Quasi-Monte Carlo Design
Authors: Amir Sadikov
Categories: cs.LG cs.AI cs.CE cs.NA cs.NE math.NA
\\
  Low-discrepancy point sets and digital sequences underpin quasi-Monte Carlo
(QMC) methods for high-dimensional integration. We cast two long-standing QMC
design problems as program synthesis and solve them with an LLM-guided
evolutionary loop that mutates and selects code under task-specific fitness:
(i) constructing finite 2D/3D point sets with low star discrepancy, and (ii)
choosing Sobol' direction numbers that minimize randomized QMC error on
downstream integrands. Our two-phase procedure combines constructive code
proposals with iterative numerical refinement. On finite sets, we rediscover
known optima in small 2D cases and set new best-known 2D benchmarks for N >=
40, while matching most known 3D optima up to the proven frontier (N <= 8) and
reporting improved 3D benchmarks beyond. On digital sequences, evolving Sobol'
parameters yields consistent reductions in randomized quasi-Monte Carlo (rQMC)
mean-squared error for several 32-dimensional option-pricing tasks relative to
widely used Joe--Kuo parameters, while preserving extensibility to any sample
size and compatibility with standard randomizations. Taken together, the
results demonstrate that LLM-driven evolutionary program synthesis can automate
the discovery of high-quality QMC constructions, recovering classical designs
where they are optimal and improving them where finite-N structure matters.
Data and code are available at
https://github.com/hockeyguy123/openevolve-star-discrepancy.git.
\\ ( https://arxiv.org/abs/2510.03650 ,  2576kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03659 (*cross-listing*)
Date: Sat, 4 Oct 2025 04:14:50 GMT   (4147kb)

Title: Does higher interpretability imply better utility? A Pairwise Analysis
  on Sparse Autoencoders
Authors: Xu Wang, Yan Hu, Benyou Wang and Difan Zou
Categories: cs.LG cs.AI cs.CL stat.ML
Comments: 24 pages
\\
  Sparse Autoencoders (SAEs) are widely used to steer large language models
(LLMs), based on the assumption that their interpretable features naturally
enable effective model behavior steering. Yet, a fundamental question remains
unanswered: does higher interpretability indeed imply better steering utility?
To answer this question, we train 90 SAEs across three LLMs (Gemma-2-2B,
Qwen-2.5-3B, Gemma-2-9B), spanning five architectures and six sparsity levels,
and evaluate their interpretability and steering utility based on SAEBench
(arXiv:2501.12345) and AxBench (arXiv:2502.23456) respectively, and perform a
rank-agreement analysis via Kendall's rank coefficients (tau b). Our analysis
reveals only a relatively weak positive association (tau b approx 0.298),
indicating that interpretability is an insufficient proxy for steering
performance. We conjecture the interpretability utility gap may stem from the
selection of SAE features, as not all of them are equally effective for
steering. To further find features that truly steer the behavior of LLMs, we
propose a novel selection criterion called Delta Token Confidence, which
measures how much amplifying a feature changes the next token distribution. We
show that our method improves the steering performance of three LLMs by 52.52
percent compared to the current best output score based criterion
(arXiv:2503.34567). Strikingly, after selecting features with high Delta Token
Confidence, the correlation between interpretability and utility vanishes (tau
b approx 0), and can even become negative. This further highlights the
divergence between interpretability and utility for the most effective steering
features.
\\ ( https://arxiv.org/abs/2510.03659 ,  4147kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03662 (*cross-listing*)
Date: Sat, 4 Oct 2025 04:20:18 GMT   (1491kb)

Title: Operationalizing Data Minimization for Privacy-Preserving LLM Prompting
Authors: Jijie Zhou, Niloofar Mireshghallah, Tianshi Li
Categories: cs.LG cs.AI
\\
  The rapid deployment of large language models (LLMs) in consumer applications
has led to frequent exchanges of personal information. To obtain useful
responses, users often share more than necessary, increasing privacy risks via
memorization, context-based personalization, or security breaches. We present a
framework to formally define and operationalize data minimization: for a given
user prompt and response model, quantifying the least privacy-revealing
disclosure that maintains utility, and we propose a priority-queue tree search
to locate this optimal point within a privacy-ordered transformation space. We
evaluated the framework on four datasets spanning open-ended conversations
(ShareGPT, WildChat) and knowledge-intensive tasks with single-ground-truth
answers (CaseHold, MedQA), quantifying achievable data minimization with nine
LLMs as the response model. Our results demonstrate that larger frontier LLMs
can tolerate stronger data minimization while maintaining task quality than
smaller open-source models (85.7% redaction for GPT-5 vs. 19.3% for
Qwen2.5-0.5B). By comparing with our search-derived benchmarks, we find that
LLMs struggle to predict optimal data minimization directly, showing a bias
toward abstraction that leads to oversharing. This suggests not just a privacy
gap, but a capability gap: models may lack awareness of what information they
actually need to solve a task.
\\ ( https://arxiv.org/abs/2510.03662 ,  1491kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03691 (*cross-listing*)
Date: Sat, 4 Oct 2025 06:05:57 GMT   (392kb)

Title: REG: A Regularization Optimizer for Robust Training Dynamics
Authors: Zehua Liu, Han Wu, Xiaojin Fu, Shuqi Liu, Xiongwei Han, Tao Zhong,
  Mingxuan Yuan
Categories: cs.LG cs.AI
\\
  Optimizers are crucial for the efficient training of Large Language Models
(LLMs). While AdamW is the de facto standard, recent structure-aware optimizers
like Muon have emerged, which regularize gradient updates by operating on
entire weight matrices. The Muon optimizer balances the gradient updates along
all the directions. However, Muon's reliance on the matrix sign function can
lead to training instability, exhibits incompatibility when fine-tuning models
pre-trained with AdamW. To address these limitations, we propose \textbf{REG},
a novel optimizer that replaces Muon's aggressive matrix sign operator with the
Row-and-Column-Scaling (RACS) operator. Theoretically grounded in balancing a
matrix, the RACS operator regularizes the update steps in a less drastic
manner, making it simpler to implement and more compatible with established
training dynamics. Through extensive empirical experiments on LLM training, we
demonstrate that our REG optimizer not only achieves superior performance and
stability over AdamW, but also maintains consistency with the AdamW training
paradigm. This consistency is particularly evident during the fine-tuning
stage, where REG optimizer avoids the performance degradation observed with
Muon.
\\ ( https://arxiv.org/abs/2510.03691 ,  392kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03699 (*cross-listing*)
Date: Sat, 4 Oct 2025 06:40:32 GMT   (10473kb)

Title: Dissecting Larval Zebrafish Hunting using Deep Reinforcement Learning
  Trained RNN Agents
Authors: Raaghav Malik, Satpreet H. Singh, Sonja Johnson-Yu, Nathan Wu, Roy
  Harpaz, Florian Engert, Kanaka Rajan
Categories: q-bio.NC cs.AI cs.LG cs.NE cs.SY eess.SY
ACM-class: I.2.6; I.2.0; I.5.1
\\
  Larval zebrafish hunting provides a tractable setting to study how ecological
and energetic constraints shape adaptive behavior in both biological brains and
artificial agents. Here we develop a minimal agent-based model, training
recurrent policies with deep reinforcement learning in a bout-based zebrafish
simulator. Despite its simplicity, the model reproduces hallmark hunting
behaviors -- including eye vergence-linked pursuit, speed modulation, and
stereotyped approach trajectories -- that closely match real larval zebrafish.
Quantitative trajectory analyses show that pursuit bouts systematically reduce
prey angle by roughly half before strike, consistent with measurements. Virtual
experiments and parameter sweeps vary ecological and energetic constraints,
bout kinematics (coupled vs. uncoupled turns and forward motion), and
environmental factors such as food density, food speed, and vergence limits.
These manipulations reveal how constraints and environments shape pursuit
dynamics, strike success, and abort rates, yielding falsifiable predictions for
neuroscience experiments. These sweeps identify a compact set of constraints --
binocular sensing, the coupling of forward speed and turning in bout
kinematics, and modest energetic costs on locomotion and vergence -- that are
sufficient for zebrafish-like hunting to emerge. Strikingly, these behaviors
arise in minimal agents without detailed biomechanics, fluid dynamics, circuit
realism, or imitation learning from real zebrafish data. Taken together, this
work provides a normative account of zebrafish hunting as the optimal balance
between energetic cost and sensory benefit, highlighting the trade-offs that
structure vergence and trajectory dynamics. We establish a virtual lab that
narrows the experimental search space and generates falsifiable predictions
about behavior and neural coding.
\\ ( https://arxiv.org/abs/2510.03699 ,  10473kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03706 (*cross-listing*)
Date: Sat, 4 Oct 2025 07:11:20 GMT   (31635kb)

Title: EmbodiSwap for Zero-Shot Robot Imitation Learning
Authors: Eadom Dessalene, Pavan Mantripragada, Michael Maynord and Yiannis
  Aloimonos
Categories: cs.RO cs.AI cs.CV cs.LG
Comments: Video link:
  https://drive.google.com/file/d/1UccngwgPqUwPMhBja7JrXfZoTquCx_Qe/view?usp=sharing
\\
  We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.
\\ ( https://arxiv.org/abs/2510.03706 ,  31635kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03734 (*cross-listing*)
Date: Sat, 4 Oct 2025 08:38:03 GMT   (1515kb)

Title: Cost Efficient Fairness Audit Under Partial Feedback
Authors: Nirjhar Das, Mohit Sharma, Praharsh Nanavati, Kirankumar Shiragur,
  Amit Deshpande
Categories: cs.LG cs.AI cs.CY stat.ML
Comments: Accepted at NeurIPS 2025 RegML Workshop; Reliable ML Workshop
\\
  We study the problem of auditing the fairness of a given classifier under
partial feedback, where true labels are available only for positively
classified individuals, (e.g., loan repayment outcomes are observed only for
approved applicants). We introduce a novel cost model for acquiring additional
labeled data, designed to more accurately reflect real-world costs such as
credit assessment, loan processing, and potential defaults. Our goal is to find
optimal fairness audit algorithms that are more cost-effective than random
exploration and natural baselines.
  In our work, we consider two audit settings: a black-box model with no
assumptions on the data distribution, and a mixture model, where features and
true labels follow a mixture of exponential family distributions. In the
black-box setting, we propose a near-optimal auditing algorithm under mild
assumptions and show that a natural baseline can be strictly suboptimal. In the
mixture model setting, we design a novel algorithm that achieves significantly
lower audit cost than the black-box case. Our approach leverages prior work on
learning from truncated samples and maximum-a-posteriori oracles, and extends
known results on spherical Gaussian mixtures to handle exponential family
mixtures, which may be of independent interest. Moreover, our algorithms apply
to popular fairness metrics including demographic parity, equal opportunity,
and equalized odds. Empirically, we demonstrate strong performance of our
algorithms on real-world fair classification datasets like Adult Income and Law
School, consistently outperforming natural baselines by around 50% in terms of
audit cost.
\\ ( https://arxiv.org/abs/2510.03734 ,  1515kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03744 (*cross-listing*)
Date: Sat, 4 Oct 2025 09:09:06 GMT   (15kb)

Title: HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model
  Adaptation for Long-Term Daily Runoff Forecasting
Authors: Qianfei Fan, Jiayu Wei, Peijun Zhu, Wensheng Ye, Meie Fang
Categories: cs.LG cs.AI cs.DC cs.NE physics.geo-ph
Comments: V1
\\
  Accurate decade-scale daily runoff forecasting in small watersheds is
difficult because signals blend drifting trends, multi-scale seasonal cycles,
regime shifts, and sparse extremes. Prior deep models (DLinear, TimesNet,
PatchTST, TiDE, Nonstationary Transformer, LSTNet, LSTM) usually target single
facets and under-utilize unlabeled spans, limiting regime adaptivity. We
propose HydroFusion-LMF, a unified framework that (i) performs a learnable
trend-seasonal-residual decomposition to reduce non-stationarity, (ii) routes
residuals through a compact heterogeneous expert set (linear refinement,
frequency kernel, patch Transformer, recurrent memory, dynamically normalized
attention), (iii) fuses expert outputs via a hydrologic context-aware gate
conditioned on day-of-year phase, antecedent precipitation, local variance,
flood indicators, and static basin attributes, and (iv) augments supervision
with a semi-supervised multi-task objective (composite MSE/MAE + extreme
emphasis + NSE/KGE, masked reconstruction, multi-scale contrastive alignment,
augmentation consistency, variance-filtered pseudo-labeling). Optional adapter
/ LoRA layers inject a frozen foundation time-series encoder efficiently. On a
~10-year daily dataset HydroFusion-LMF attains MSE 1.0128 / MAE 0.5818,
improving the strongest baseline (DLinear) by 10.2% / 10.3% and the mean
baseline by 24.6% / 17.1%. We observe simultaneous MSE and MAE reductions
relative to baselines. The framework balances interpretability (explicit
components, sparse gating) with performance, advancing label-efficient
hydrologic forecasting under non-stationarity.
\\ ( https://arxiv.org/abs/2510.03744 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03755 (*cross-listing*)
Date: Sat, 4 Oct 2025 09:40:43 GMT   (11868kb)

Title: Code4MeV2: a Research-oriented Code-completion Platform
Authors: Roham Koohestani, Parham Bateni, Aydin Ebrahimi, Behdad Etezadi,
  Kiarash Karimi, Maliheh Izadi
Categories: cs.SE cs.AI
Comments: Under review for submission at a conference
\\
  The adoption of AI-powered code completion tools in software development has
increased substantially, yet the user interaction data produced by these
systems remain proprietary within large corporations. This creates a barrier
for the academic community, as researchers must often develop dedicated
platforms to conduct studies on human--AI interaction, making reproducible
research and large-scale data analysis impractical. In this work, we introduce
Code4MeV2, a research-oriented, open-source code completion plugin for
JetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a
client--server architecture and features inline code completion and a
context-aware chat assistant. Its core contribution is a modular and
transparent data collection framework that gives researchers fine-grained
control over telemetry and context gathering. Code4MeV2 achieves
industry-comparable performance in terms of code completion, with an average
latency of 200~ms. We assess our tool through a combination of an expert
evaluation and a user study with eight participants. Feedback from both
researchers and daily users highlights its informativeness and usefulness. We
invite the community to adopt and contribute to this tool. More information
about the tool can be found at https://app.code4me.me.
\\ ( https://arxiv.org/abs/2510.03755 ,  11868kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03760 (*cross-listing*)
Date: Sat, 4 Oct 2025 10:00:25 GMT   (1071kb)

Title: EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large
  Language Models
Authors: Ping Guo, Chenyu Zhu, Siyuan Chen, Fei Liu, Xi Lin, Zhichao Lu, Qingfu
  Zhang
Categories: cs.LG cs.AI
Comments: Under Review of ICLR 2026
\\
  CUDA kernel optimization has become a critical bottleneck for AI performance,
as deep learning training and inference efficiency directly depends on highly
optimized GPU kernels.
  Despite the promise of Large Language Models (LLMs) for automating kernel
optimization, this field suffers from a fragmented ecosystem of isolated and
incomparable approaches with unclear problem formulations.
  Furthermore, general-purpose LLM code evolution methods cannot meet strict
correctness requirements of CUDA kernel optimization.
  We address these fundamental challenges by first formalizing CUDA kernel
optimization as a code optimization task with a clear objective, constraints,
and evaluation metrics.
  We then establish the first systematic LLM-based code evolution framework,
EvoEngineer, that provides guidance for designing and adapting optimization
strategies to achieve a balance between performance and correctness.
  Finally, we implement a kernel optimization system based on this framework
and conduct extensive experiments on 91 real-world CUDA kernels.
  Our results demonstrate that EvoEngineer achieves a principled balance
between performance and correctness, with the highest averaged median speedup
of \textbf{2.72}$\times$ over baseline CUDA kernels and a code validity rate of
\textbf{69.8}\%, outperforming existing methods on both dimensions.
  Our method achieves a maximum speedup of \textbf{36.75}$\times$ among all
operations over PyTorch kernels and delivers the highest speedup on \textbf{28}
(\textbf{56.0\%}) of 50 operations that achieve over \textbf{2$\times$}
acceleration.
\\ ( https://arxiv.org/abs/2510.03760 ,  1071kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03761 (*cross-listing*)
Date: Sat, 4 Oct 2025 10:03:17 GMT   (639kb)

Title: You Have Been LaTeXpOsEd: A Systematic Analysis of Information Leakage
  in Preprint Archives Using Large Language Models
Authors: Richard A. Dubniczky, Bertalan Borsos, Tihanyi Norbert
Categories: cs.CR cs.AI
\\
  The widespread use of preprint repositories such as arXiv has accelerated the
communication of scientific results but also introduced overlooked security
risks. Beyond PDFs, these platforms provide unrestricted access to original
source materials, including LaTeX sources, auxiliary code, figures, and
embedded comments. In the absence of sanitization, submissions may disclose
sensitive information that adversaries can harvest using open-source
intelligence. In this work, we present the first large-scale security audit of
preprint archives, analyzing more than 1.2 TB of source data from 100,000 arXiv
submissions. We introduce LaTeXpOsEd, a four-stage framework that integrates
pattern matching, logical filtering, traditional harvesting techniques, and
large language models (LLMs) to uncover hidden disclosures within
non-referenced files and LaTeX comments. To evaluate LLMs' secret-detection
capabilities, we introduce LLMSec-DB, a benchmark on which we tested 25
state-of-the-art models. Our analysis uncovered thousands of PII leaks,
GPS-tagged EXIF files, publicly available Google Drive and Dropbox folders,
editable private SharePoint links, exposed GitHub and Google credentials, and
cloud API keys. We also uncovered confidential author communications, internal
disagreements, and conference submission credentials, exposing information that
poses serious reputational risks to both researchers and institutions. We urge
the research community and repository operators to take immediate action to
close these hidden security gaps. To support open science, we release all
scripts and methods from this study but withhold sensitive findings that could
be misused, in line with ethical principles. The source code and related
material are available at the project website https://github.com/LaTeXpOsEd
\\ ( https://arxiv.org/abs/2510.03761 ,  639kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03788 (*cross-listing*)
Date: Sat, 4 Oct 2025 11:44:29 GMT   (1595kb)

Title: Lightweight and Data-Efficient MultivariateTime Series Forecasting using
  Residual-Stacked Gaussian (RS-GLinear) Architecture
Authors: Abukar Ali
Categories: cs.CE cs.AI
\\
  Following the success of Transformer architectures in language modeling,
particularly their ability to capture long-range dependencies, researchers have
explored how these architectures can be adapted for time-series forecasting.
Transformer-based models have been proposed to handle both short- and long-term
dependencies when predicting future values from historical data. However,
studies such as those by Zeng et al. (2022) and Rizvi et al. (2025) have
reported mixed results in long-term forecasting tasks. In this work, we
evaluate the Gaussian-based Linear architecture introduced by Rizvi et al.
(2025) and present an enhanced version called the Residual Stacked Gaussian
Linear (RSGL) model. We also investigate the broader applicability of the RSGL
model in additional domains, including financial time series and
epidemiological data. Experimental results show that the RSGL model achieves
improved prediction accuracy and robustness compared to both the baseline
Gaussian Linear and Transformer-based models.
\\ ( https://arxiv.org/abs/2510.03788 ,  1595kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03807 (*cross-listing*)
Date: Sat, 4 Oct 2025 13:29:56 GMT   (2976kb)

Title: 6G-Enabled Digital Twin Framework for Real-Time Cyber-Physical Systems:
  An Experimental Validation with Industrial Bearing Fault Detection
Authors: Vaskar Chakma, Wooyeol Choi
Categories: cs.NI cs.AI cs.LG
\\
  Current Cyber-Physical Systems (CPS) integrated with Digital Twin (DT)
technology face critical limitations in achieving real-time performance for
mission-critical industrial applications. Existing 5G-enabled systems suffer
from latencies exceeding 10ms, which are inadequate for applications requiring
sub-millisecond response times, such as autonomous industrial control and
predictive maintenance. This research aims to develop and validate a 6G-enabled
Digital Twin framework that achieves ultra-low latency communication and
real-time synchronization between physical industrial assets and their digital
counterparts, specifically targeting bearing fault detection as a critical
industrial use case. The proposed framework integrates terahertz communications
(0.1-1 THz), intelligent reflecting surfaces, and edge artificial intelligence
within a five-layer architecture. Experimental validation was conducted using
the Case Western Reserve University (CWRU) bearing dataset, implementing
comprehensive feature extraction (15 time and frequency domain features) and
Random Forest classification algorithms. The system performance was evaluated
against traditional WiFi-6 and 5G networks across multiple metrics, including
classification accuracy, end-to-end latency, and scalability. It achieved 97.7%
fault classification accuracy with 0.8ms end-to-end latency, representing a
15.6x improvement over WiFi-6 (12.5ms) and 5.25x improvement over 5G (4.2ms)
networks. The system demonstrated superior scalability with sub-linear
processing time growth and maintained consistent performance across four
bearing fault categories (normal, inner race, outer race, and ball faults) with
macro-averaged F1-scores exceeding 97%.
\\ ( https://arxiv.org/abs/2510.03807 ,  2976kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03812 (*cross-listing*)
Date: Sat, 4 Oct 2025 13:43:43 GMT   (3404kb)

Title: ReTiDe: Real-Time Denoising for Energy-Efficient Motion Picture
  Processing with FPGAs
Authors: Changhong Li, Cl\'ement Bled, Rosa Fernandez, Shreejith Shanker
Categories: eess.IV cs.AI
Comments: This paper has been accepted by the 22nd ACM SIGGRAPH European
  Conference on Visual Media Production (CVMP 2025)
DOI: 10.1145/3756863.3769710
\\
  Denoising is a core operation in modern video pipelines. In codecs, in-loop
filters suppress sensor noise and quantisation artefacts to improve
rate-distortion performance; in cinema post-production, denoisers are used for
restoration, grain management, and plate clean-up. However, state-of-the-art
deep denoisers are computationally intensive and, at scale, are typically
deployed on GPUs, incurring high power and cost for real-time, high-resolution
streams. This paper presents Real-Time Denoise (ReTiDe), a hardware-accelerated
denoising system that serves inference on data-centre Field Programmable Gate
Arrays (FPGAs). A compact convolutional model is quantised (post-training
quantisation plus quantisation-aware fine-tuning) to INT8 and compiled for AMD
Deep Learning Processor Unit (DPU)-based FPGAs. A client-server integration
offloads computation from the host CPU/GPU to a networked FPGA service, while
remaining callable from existing workflows, e.g., NUKE, without disrupting
artist tooling. On representative benchmarks, ReTiDe delivers 37.71$\times$
Giga Operations Per Second (GOPS) throughput and 5.29$\times$ higher energy
efficiency than prior FPGA denoising accelerators, with negligible degradation
in Peak Signal-to-Noise Ratio (PSNR)/Structural Similarity Index (SSIM). These
results indicate that specialised accelerators can provide practical, scalable
denoising for both encoding pipelines and post-production, reducing energy per
frame without sacrificing quality or workflow compatibility. Code is available
at https://github.com/RCSL-TCD/ReTiDe.
\\ ( https://arxiv.org/abs/2510.03812 ,  3404kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03813 (*cross-listing*)
Date: Sat, 4 Oct 2025 13:51:32 GMT   (15568kb)

Title: Diverse Text-to-Image Generation via Contrastive Noise Optimization
Authors: Byungjun Kim, Soobin Um, Jong Chul Ye
Categories: cs.GR cs.AI cs.CV cs.LG
\\
  Text-to-image (T2I) diffusion models have demonstrated impressive performance
in generating high-fidelity images, largely enabled by text-guided inference.
However, this advantage often comes with a critical drawback: limited
diversity, as outputs tend to collapse into similar modes under strong text
guidance. Existing approaches typically optimize intermediate latents or text
conditions during inference, but these methods deliver only modest gains or
remain sensitive to hyperparameter tuning. In this work, we introduce
Contrastive Noise Optimization, a simple yet effective method that addresses
the diversity issue from a distinct perspective. Unlike prior techniques that
adapt intermediate latents, our approach shapes the initial noise to promote
diverse outputs. Specifically, we develop a contrastive loss defined in the
Tweedie data space and optimize a batch of noise latents. Our contrastive
optimization repels instances within the batch to maximize diversity while
keeping them anchored to a reference sample to preserve fidelity. We further
provide theoretical insights into the mechanism of this preprocessing to
substantiate its effectiveness. Extensive experiments across multiple T2I
backbones demonstrate that our approach achieves a superior quality-diversity
Pareto frontier while remaining robust to hyperparameter choices.
\\ ( https://arxiv.org/abs/2510.03813 ,  15568kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03814 (*cross-listing*)
Date: Sat, 4 Oct 2025 13:55:19 GMT   (9173kb)

Title: Detecting Invariant Manifolds in ReLU-Based RNNs
Authors: Lukas Eisenmann, Alena Br\"andle, Zahra Monfared, Daniel Durstewitz
Categories: cs.LG cs.AI math.DS
\\
  Recurrent Neural Networks (RNNs) have found widespread applications in
machine learning for time series prediction and dynamical systems
reconstruction, and experienced a recent renaissance with improved training
algorithms and architectural designs. Understanding why and how trained RNNs
produce their behavior is important for scientific and medical applications,
and explainable AI more generally. An RNN's dynamical repertoire depends on the
topological and geometrical properties of its state space. Stable and unstable
manifolds of periodic points play a particularly important role: They dissect a
dynamical system's state space into different basins of attraction, and their
intersections lead to chaotic dynamics with fractal geometry. Here we introduce
a novel algorithm for detecting these manifolds, with a focus on
piecewise-linear RNNs (PLRNNs) employing rectified linear units (ReLUs) as
their activation function. We demonstrate how the algorithm can be used to
trace the boundaries between different basins of attraction, and hence to
characterize multistability, a computationally important property. We further
show its utility in finding so-called homoclinic points, the intersections
between stable and unstable manifolds, and thus establish the existence of
chaos in PLRNNs. Finally we show for an empirical example, electrophysiological
recordings from a cortical neuron, how insights into the underlying dynamics
could be gained through our method.
\\ ( https://arxiv.org/abs/2510.03814 ,  9173kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03824 (*cross-listing*)
Date: Sat, 4 Oct 2025 14:44:47 GMT   (5713kb)

Title: Proximal Diffusion Neural Sampler
Authors: Wei Guo, Jaemoo Choi, Yuchen Zhu, Molei Tao, Yongxin Chen
Categories: cs.LG cs.AI stat.ML
Comments: 31 pages, 12 figures
\\
  The task of learning a diffusion-based neural sampler for drawing samples
from an unnormalized target distribution can be viewed as a stochastic optimal
control problem on path measures. However, the training of neural samplers can
be challenging when the target distribution is multimodal with significant
barriers separating the modes, potentially leading to mode collapse. We propose
a framework named \textbf{Proximal Diffusion Neural Sampler (PDNS)} that
addresses these challenges by tackling the stochastic optimal control problem
via proximal point method on the space of path measures. PDNS decomposes the
learning process into a series of simpler subproblems that create a path
gradually approaching the desired distribution. This staged procedure traces a
progressively refined path to the desired distribution and promotes thorough
exploration across modes. For a practical and efficient realization, we
instantiate each proximal step with a proximal weighted denoising cross-entropy
(WDCE) objective. We demonstrate the effectiveness and robustness of PDNS
through extensive experiments on both continuous and discrete sampling tasks,
including challenging scenarios in molecular dynamics and statistical physics.
\\ ( https://arxiv.org/abs/2510.03824 ,  5713kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03829 (*cross-listing*)
Date: Sat, 4 Oct 2025 15:02:03 GMT   (5302kb)

Title: A4FN: an Agentic AI Architecture for Autonomous Flying Networks
Authors: Andr\'e Coelho, Pedro Ribeiro, Helder Fontes, Rui Campos
Categories: cs.NI cs.AI
Comments: This paper has been accepted for presentation in the Auto ML for
  Zero-Touch Network Management Workshop (WS04-01) at the IEEE International
  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) 2025
\\
  This position paper presents A4FN, an Agentic Artificial Intelligence (AI)
architecture for intent-driven automation in Flying Networks (FNs) using
Unmanned Aerial Vehicles (UAVs) as access nodes. A4FN leverages Generative AI
and Large Language Models (LLMs) to enable real-time, context-aware network
control via a distributed agentic system. It comprises two components: the
Perception Agent (PA), which semantically interprets multimodal input --
including imagery, audio, and telemetry data -- from UAV-mounted sensors to
derive Service Level Specifications (SLSs); and the Decision-and-Action Agent
(DAA), which reconfigures the network based on inferred intents. A4FN embodies
key properties of Agentic AI, including autonomy, goal-driven reasoning, and
continuous perception-action cycles. Designed for mission-critical,
infrastructure-limited scenarios such as disaster response, it supports
adaptive reconfiguration, dynamic resource management, and interoperability
with emerging wireless technologies. The paper details the A4FN architecture,
its core innovations, and open research challenges in multi-agent coordination
and Agentic AI integration in next-generation FNs.
\\ ( https://arxiv.org/abs/2510.03829 ,  5302kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03856 (*cross-listing*)
Date: Sat, 4 Oct 2025 16:06:10 GMT   (2913kb)

Title: AI-Assisted Pleural Effusion Volume Estimation from Contrast-Enhanced CT
  Images
Authors: Sanhita Basu, Tomas Fr\"oding, Ali Teymur Kahraman, Dimitris
  Toumpanakis, Tobias Sj\"oblom
Categories: eess.IV cs.AI cs.CV
\\
  Background: Pleural Effusions (PE) is a common finding in many different
clinical conditions, but accurately measuring their volume from CT scans is
challenging. Purpose: To improve PE segmentation and quantification for
enhanced clinical management, we have developed and trained a semi-supervised
deep learning framework on contrast-enhanced CT volumes. Materials and Methods:
This retrospective study collected CT Pulmonary Angiogram (CTPA) data from
internal and external datasets. A subset of 100 cases was manually annotated
for model training, while the remaining cases were used for testing and
validation. A novel semi-supervised deep learning framework, Teacher-Teaching
Assistant-Student (TTAS), was developed and used to enable efficient training
in non-segmented examinations. Segmentation performance was compared to that of
state-of-the-art models. Results: 100 patients (mean age, 72 years, 28
[standard deviation]; 55 men) were included in the study. The TTAS model
demonstrated superior segmentation performance compared to state-of-the-art
models, achieving a mean Dice score of 0.82 (95% CI, 0.79 - 0.84) versus 0.73
for nnU-Net (p < 0.0001, Student's T test). Additionally, TTAS exhibited a
four-fold lower mean Absolute Volume Difference (AbVD) of 6.49 mL (95% CI, 4.80
- 8.20) compared to nnU-Net's AbVD of 23.16 mL (p < 0.0001). Conclusion: The
developed TTAS framework offered superior PE segmentation, aiding accurate
volume determination from CT scans.
\\ ( https://arxiv.org/abs/2510.03856 ,  2913kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03862 (*cross-listing*)
Date: Sat, 4 Oct 2025 16:15:54 GMT   (106kb)

Title: Designing Empirical Studies on LLM-Based Code Generation: Towards a
  Reference Framework
Authors: Nathalia Nascimento, Everton Guimaraes, Paulo Alencar
Categories: cs.SE cs.AI
Comments: 5 pages
MSC-class: 500
\\
  The rise of large language models (LLMs) has introduced transformative
potential in automated code generation, addressing a wide range of software
engineering challenges. However, empirical evaluation of LLM-based code
generation lacks standardization, with studies varying widely in goals, tasks,
and metrics, which limits comparability and reproducibility. In this paper, we
propose a theoretical framework for designing and reporting empirical studies
on LLM-based code generation. The framework is grounded in both our prior
experience conducting such experiments and a comparative analysis of key
similarities and differences among recent studies. It organizes evaluation
around core components such as problem sources, quality attributes, and
metrics, supporting structured and systematic experimentation. We demonstrate
its applicability through representative case mappings and identify
opportunities for refinement. Looking forward, we plan to evolve the framework
into a more robust and mature tool for standardizing LLM evaluation across
software engineering contexts.
\\ ( https://arxiv.org/abs/2510.03862 ,  106kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03865 (*cross-listing*)
Date: Sat, 4 Oct 2025 16:22:19 GMT   (246kb)

Title: Unlocking Reasoning Capabilities in LLMs via Reinforcement Learning
  Exploration
Authors: Wenhao Deng and Long Wei and Chenglei Yu and Tailin Wu
Categories: cs.LG cs.AI cs.CL
\\
  Reinforcement learning with verifiable rewards (RLVR) has recently enhanced
the reasoning capabilities of large language models (LLMs), particularly for
mathematical problem solving. However, a fundamental limitation remains: as the
sampling budget increases, the advantage of RLVR-trained models over their
pretrained bases often diminishes or even vanishes, revealing a strong
dependence on the base model's restricted search space. We attribute this
phenomenon to the widespread use of the reverse Kullback-Leibler (KL)
divergence regularizer, whose mode-seeking behavior keeps the policy trapped
inside the base model's support region and hampers wider exploration. To
address this issue, we propose RAPO (Rewards-Aware Policy Optimization), an
algorithm to promote broader yet focused exploration. Our method (i) utilizes
the forward KL penalty to replace the reverse KL penalty for
out-of-distribution exploration, and (ii) reweights the reference policy to
facilitate adaptive in-distribution exploration. We train Qwen2.5-3B and 7B
models with RAPO on the 8K SimpleRL-Zero dataset, without supervised
fine-tuning, and evaluate them on AIME2024 and AIME2025. Results show that RAPO
consistently improves problem-solving performance. Notably, RAPO enables models
to surpass the base model's performance ceiling and solves previously
intractable problems, advancing the frontier of RLVR for challenging reasoning
tasks.
\\ ( https://arxiv.org/abs/2510.03865 ,  246kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03868 (*cross-listing*)
Date: Sat, 4 Oct 2025 16:28:54 GMT   (4197kb)

Title: AI Adoption Across Mission-Driven Organizations
Authors: Dalia Ali, Muneeb Ahmed, Hailan Wang, Arfa Khan, Naira Paola Arnez
  Jordan, Sunnie S. Y. Kim, Meet Dilip Muchhala, Anne Kathrin Merkle, Orestis
  Papakyriakopoulos
Categories: cs.CY cs.AI
Comments: 16 pages, Submitted for CHI 2026
\\
  Despite AI's promise for addressing global challenges, empirical
understanding of AI adoption in mission-driven organizations (MDOs) remains
limited. While research emphasizes individual applications or ethical
principles, little is known about how resource-constrained, values-driven
organizations navigate AI integration across operations. We conducted thematic
analysis of semi-structured interviews with 15 practitioners from
environmental, humanitarian, and development organizations across the Global
North and South contexts. Our analysis examines how MDOs currently deploy AI,
what barriers constrain adoption, and how practitioners envision future
integration. MDOs adopt AI selectively, with sophisticated deployment in
content creation and data analysis while maintaining human oversight for
mission-critical applications. When AI's efficiency benefits conflict with
organizational values, decision-making stalls rather than negotiating
trade-offs. This study contributes empirical evidence that AI adoption in MDOs
should be understood as conditional rather than inevitable, proceeding only
where it strengthens organizational sovereignty and mission integrity while
preserving human-centered approaches essential to their missions.
\\ ( https://arxiv.org/abs/2510.03868 ,  4197kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03871 (*cross-listing*)
Date: Sat, 4 Oct 2025 16:48:36 GMT   (773kb)

Title: Optimal Scaling Needs Optimal Norm
Authors: Oleg Filatov, Jiangtao Wang, Jan Ebert, Stefan Kesselheim
Categories: cs.LG cs.AI stat.ML
\\
  Despite recent progress in optimal hyperparameter transfer under model and
dataset scaling, no unifying explanatory principle has been established. Using
the Scion optimizer, we discover that joint optimal scaling across model and
dataset sizes is governed by a single invariant: the operator norm of the
output layer. Across models with up to 1.3B parameters trained on up to 138B
tokens, the optimal learning rate/batch size pair $(\eta^{\ast}, B^{\ast})$
consistently has the same operator norm value - a phenomenon we term norm
transfer. This constant norm condition is necessary but not sufficient: while
for each dataset size, multiple $(\eta, B)$ reach the optimal norm, only a
unique $(\eta^{\ast}, B^{\ast})$ achieves the best loss. As a sufficient
condition, we provide the first measurement of $(\eta^{\ast}, B^{\ast})$
scaling with dataset size for Scion, and find that the scaling rules are
consistent with those of the Adam optimizer. Tuning per-layer-group learning
rates also improves model performance, with the output layer being the most
sensitive and hidden layers benefiting from lower learning rates. We provide
practical insights on norm-guided optimal scaling and release our Distributed
Scion (Disco) implementation with logs from over two thousand runs to support
research on LLM training dynamics at scale.
\\ ( https://arxiv.org/abs/2510.03871 ,  773kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03879 (*cross-listing*)
Date: Sat, 4 Oct 2025 17:08:36 GMT   (1447kb)

Title: Adversarial Agent Collaboration for C to Rust Translation
Authors: Tianyu Li, Ruishi Li, Bo Wang, Brandon Paulsen, Umang Mathur, Prateek
  Saxena
Categories: cs.SE cs.AI
\\
  Translating C to memory-safe languages, like Rust, prevents critical memory
safety vulnerabilities that are prevalent in legacy C software. Existing
approaches for C to safe Rust translation, including LLM-assisted ones, do not
generalize on larger (> 500 LoC) C codebases because they depend on complex
program analyses that frequently break. In this work, we present ACToR
(Adversarial C To Rust translator), a simple LLM agent-based approach. Inspired
by GANs, ACToR pits a generator agent against a discriminator agent, which
collaborate to iteratively generate a Rust translation. On each iteration, the
translator agent synthesizes and refines a Rust translation to pass an existing
suite of tests, and then the discriminator agent finds new failing tests. We
demonstrate that ACToR translates all of the 63 real-world command line
utilities considered in our benchmarks, which have an average size of 485 lines
of code, and it achieves over 90% test pass rate with zero human intervention.
To our knowledge, it is the first such system that reliably translates C
programs of this scale. Furthermore, ACToR improves translation correctness by
up to 18.9% compared to baseline, non-adversarial approaches.
\\ ( https://arxiv.org/abs/2510.03879 ,  1447kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03914 (*cross-listing*)
Date: Sat, 4 Oct 2025 19:40:42 GMT   (631kb)

Title: Refactoring with LLMs: Bridging Human Expertise and Machine
  Understanding
Authors: Yonnel Chen Kuang Piao and Jean Carlors Paul and Leuson Da Silva and
  Arghavan Moradi Dakhel and Mohammad Hamdaqa and Foutse Khomh
Categories: cs.SE cs.AI
Comments: 43 pages, 2 figures, 9 tables
\\
  Code refactoring is a fundamental software engineering practice aimed at
improving code quality and maintainability. Despite its importance, developers
often neglect refactoring due to the significant time, effort, and resources it
requires, as well as the lack of immediate functional rewards. Although several
automated refactoring tools have been proposed, they remain limited in
supporting a broad spectrum of refactoring types. In this study, we explore
whether instruction strategies inspired by human best-practice guidelines can
enhance the ability of Large Language Models (LLMs) to perform diverse
refactoring tasks automatically. Leveraging the instruction-following and code
comprehension capabilities of state-of-the-art LLMs (e.g., GPT-mini and
DeepSeek-V3), we draw on Martin Fowler's refactoring guidelines to design
multiple instruction strategies that encode motivations, procedural steps, and
transformation objectives for 61 well-known refactoring types. We evaluate
these strategies on benchmark examples and real-world code snippets from GitHub
projects. Our results show that instruction designs grounded in Fowler's
guidelines enable LLMs to successfully perform all benchmark refactoring types
and preserve program semantics in real-world settings, an essential criterion
for effective refactoring. Moreover, while descriptive instructions are more
interpretable to humans, our results show that rule-based instructions often
lead to better performance in specific scenarios. Interestingly, allowing
models to focus on the overall goal of refactoring, rather than prescribing a
fixed transformation type, can yield even greater improvements in code quality.
\\ ( https://arxiv.org/abs/2510.03914 ,  631kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03923 (*cross-listing*)
Date: Sat, 4 Oct 2025 19:59:21 GMT   (5758kb)

Title: On the Convergence and Size Transferability of Continuous-depth Graph
  Neural Networks
Authors: Mingsong Yan, Charles Kulick, Sui Tang
Categories: cs.LG cs.AI
\\
  Continuous-depth graph neural networks, also known as Graph Neural
Differential Equations (GNDEs), combine the structural inductive bias of Graph
Neural Networks (GNNs) with the continuous-depth architecture of Neural ODEs,
offering a scalable and principled framework for modeling dynamics on graphs.
In this paper, we present a rigorous convergence analysis of GNDEs with
time-varying parameters in the infinite-node limit, providing theoretical
insights into their size transferability. To this end, we introduce Graphon
Neural Differential Equations (Graphon-NDEs) as the infinite-node limit of
GNDEs and establish their well-posedness. Leveraging tools from graphon theory
and dynamical systems, we prove the trajectory-wise convergence of GNDE
solutions to Graphon-NDE solutions. Moreover, we derive explicit convergence
rates under two deterministic graph sampling regimes: (1) weighted graphs
sampled from smooth graphons, and (2) unweighted graphs sampled from
$\{0,1\}$-valued (discontinuous) graphons. We further establish size
transferability bounds, providing theoretical justification for the practical
strategy of transferring GNDE models trained on moderate-sized graphs to
larger, structurally similar graphs without retraining. Numerical experiments
using synthetic and real data support our theoretical findings.
\\ ( https://arxiv.org/abs/2510.03923 ,  5758kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03930 (*cross-listing*)
Date: Sat, 4 Oct 2025 20:21:39 GMT   (14771kb)

Title: LLM Chemistry Estimation for Multi-LLM Recommendation
Authors: Huascar Sanchez, Briland Hitaj
Categories: cs.LG cs.AI cs.CL
Comments: 20 pages, 5 figures, 5 tables
\\
  Multi-LLM collaboration promises accurate, robust, and context-aware
solutions, yet existing approaches rely on implicit selection and output
assessment without analyzing whether collaborating models truly complement or
conflict. We introduce LLM Chemistry -- a framework that measures when LLM
combinations exhibit synergistic or antagonistic behaviors that shape
collective performance beyond individual capabilities. We formalize the notion
of chemistry among LLMs, propose algorithms that quantify it by analyzing
interaction dependencies, and recommend optimal model ensembles accordingly.
Our theoretical analysis shows that chemistry among collaborating LLMs is most
evident under heterogeneous model profiles, with its outcome impact shaped by
task type, group size, and complexity. Evaluation on classification,
summarization, and program repair tasks provides initial evidence for these
task-dependent effects, thereby reinforcing our theoretical results. This
establishes LLM Chemistry as both a diagnostic factor in multi-LLM systems and
a foundation for ensemble recommendation.
\\ ( https://arxiv.org/abs/2510.03930 ,  14771kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03952 (*cross-listing*)
Date: Sat, 4 Oct 2025 21:37:14 GMT   (20kb)

Title: Strategy Logic, Imperfect Information, and Hyperproperties
Authors: Raven Beutner, Bernd Finkbeiner
Categories: cs.LO cs.AI cs.MA
Comments: KR 2025
\\
  Strategy logic (SL) is a powerful temporal logic that enables first-class
reasoning over strategic behavior in multi-agent systems (MAS). In many MASs,
the agents (and their strategies) cannot observe the global state of the
system, leading to many extensions of SL centered around imperfect information,
such as strategy logic with imperfect information (SL$_\mathit{ii}$). Along
orthogonal lines, researchers have studied the combination of strategic
behavior and hyperproperties. Hyperproperties are system properties that relate
multiple executions in a system and commonly arise when specifying security
policies. Hyper Strategy Logic (HyperSL) is a temporal logic that combines
quantification over strategies with the ability to express hyperproperties on
the executions of different strategy profiles. In this paper, we study the
relation between SL$_\mathit{ii}$ and HyperSL. Our main result is that both
logics (restricted to formulas where no state formulas are nested within path
formulas) are equivalent in the sense that we can encode SL$_\mathit{ii}$
instances into HyperSL instances and vice versa. For the former direction, we
build on the well-known observation that imperfect information is a
hyperproperty. For the latter direction, we construct a self-composition of
MASs and show how we can simulate hyperproperties using imperfect information.
\\ ( https://arxiv.org/abs/2510.03952 ,  20kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03962 (*cross-listing*)
Date: Sat, 4 Oct 2025 22:20:48 GMT   (236kb)

Title: SPEAR: Soft Prompt Enhanced Anomaly Recognition for Time Series Data
Authors: Hanzhe Wei, Jiajun Wu, Jialin Yang, Henry Leung, Steve Drew
Categories: cs.LG cs.AI
Comments: Accepted to 2025 IEEE International Conference on Autonomous and
  Trusted Computing (ATC 2025)
\\
  Time series anomaly detection plays a crucial role in a wide range of fields,
such as healthcare and internet traffic monitoring. The emergence of large
language models (LLMs) offers new opportunities for detecting anomalies in the
ubiquitous time series data. Traditional approaches struggle with
variable-length time series sequences and context-based anomalies. We propose
Soft Prompt Enhanced Anomaly Recognition (SPEAR), a novel approach to leverage
LLMs for anomaly detection with soft prompts and quantization. Our methodology
involves quantizing and transforming the time series data into input embeddings
and combining them with learnable soft prompt embeddings. These combined
embeddings are then fed into a frozen LLM. The soft prompts are updated
iteratively based on a cross-entropy loss, allowing the model to adapt to time
series anomaly detection. The use of soft prompts helps adapt LLMs effectively
to time series tasks, while quantization ensures optimal handling of sequences,
as LLMs are designed to handle discrete sequences. Our experimental results
demonstrate that soft prompts effectively increase LLMs' performance in
downstream tasks regarding time series anomaly detection.
\\ ( https://arxiv.org/abs/2510.03962 ,  236kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03971 (*cross-listing*)
Date: Sat, 4 Oct 2025 23:10:38 GMT   (809kb)

Title: What Can You Do When You Have Zero Rewards During RL?
Authors: Jatin Prakash, Anirudh Buvanesh
Categories: cs.LG cs.AI
\\
  Reinforcement learning (RL) with outcome-based rewards has proven effective
for improving large language models (LLMs) on complex reasoning tasks. However,
its success often depends on the base model occasionally sampling correct
solutions. When no correct solutions are sampled, training encounters a
zero-reward barrier where learning stalls due to zero gradients. We study this
scenario through the graph search task introduced in Bachmann et al. (2024) and
evaluate recent methods that incorporate desirable components such as dense
rewards, diversity incentives, and improved credit assignment. Our experiments
show that none of these approaches overcome the zero-reward barrier if the base
model never produces a correct answer. In contrast, we find that a simple
data-centric intervention of adding easier samples to the training set enables
the model to eventually solve the original hard task despite starting from zero
reward. Importantly, this succeeds without modifying the RL algorithm itself.
Because official implementations of several baselines were unavailable, we
developed our own, which allowed us to conduct a detailed analysis of their
failure modes. We release these implementations to support further research at:
https://github.com/rl4reasoning/rl-baselines
\\ ( https://arxiv.org/abs/2510.03971 ,  809kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03988 (*cross-listing*)
Date: Sun, 5 Oct 2025 01:15:32 GMT   (1111kb)

Title: Distilling Reasoning into Student LLMs: Local Naturalness for Selecting
  Teacher Data
Authors: Hoang Anh Just, Myeongseob Ko, Ruoxi Jia
Categories: cs.LG cs.AI
Comments: Preprint
\\
  Distilling long reasoning traces (10K+ tokens) from stronger teacher models
into smaller student LLMs via SFT has emerged as a standard paradigm. This
approach is practical and efficient: it leverages the ease of generating
abundant reasoning data from stronger models and provides a direct, data-driven
way to teach less capable models better reasoning. While previous work has
largely focused on prompt selection with responses from a single teacher, the
equally important problem of choosing the best response when multiple teacher
outputs are available for a single prompt remains underexplored. This challenge
becomes important in a multi-teacher setting, where different students may
benefit from the outputs of different teachers. This paper fills that gap with
a systematic study of response selection for reasoning distillation. We first
show that the current method, which picks responses the student assigns the
highest global log-probability (global naturalness), fails when responses come
from multiple teachers, i.e., global naturalness no longer correlates with
downstream performance, especially as the reasoning traces from strong teachers
become longer. To overcome this problem, we introduce Local Naturalness, which
measures the student's log-probabilities over short, sequential reasoning steps
conditioned only on a small local window. Local Naturalness enables two
applications: 1) Teacher Selection: Aggregating local scores across prompts
reliably identifies the most helpful teacher. 2) Response Selection from a
Multiple Teachers: When mixing answers from many teachers, Local Naturalness
boosts a 32B student's accuracy on math benchmarks by 9.4pp over global
selection, also surpassing the performance achieved by training on data from
the single best teacher. These results highlight the power of localized data
quality evaluation and data mixing for more effective reasoning distillation.
\\ ( https://arxiv.org/abs/2510.03988 ,  1111kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03989 (*cross-listing*)
Date: Sun, 5 Oct 2025 01:16:08 GMT   (84kb)

Title: A Mathematical Explanation of Transformers for Large Language Models and
  GPTs
Authors: Xue-Cheng Tai, Hao Liu, Lingfeng Li, Raymond H. Chan
Categories: cs.LG cs.AI cs.NA math.NA
\\
  The Transformer architecture has revolutionized the field of sequence
modeling and underpins the recent breakthroughs in large language models
(LLMs). However, a comprehensive mathematical theory that explains its
structure and operations remains elusive. In this work, we propose a novel
continuous framework that rigorously interprets the Transformer as a
discretization of a structured integro-differential equation. Within this
formulation, the self-attention mechanism emerges naturally as a non-local
integral operator, and layer normalization is characterized as a projection to
a time-dependent constraint. This operator-theoretic and variational
perspective offers a unified and interpretable foundation for understanding the
architecture's core components, including attention, feedforward layers, and
normalization. Our approach extends beyond previous theoretical analyses by
embedding the entire Transformer operation in continuous domains for both token
indices and feature dimensions. This leads to a principled and flexible
framework that not only deepens theoretical insight but also offers new
directions for architecture design, analysis, and control-based
interpretations. This new interpretation provides a step toward bridging the
gap between deep learning architectures and continuous mathematical modeling,
and contributes a foundational perspective to the ongoing development of
interpretable and theoretically grounded neural network models.
\\ ( https://arxiv.org/abs/2510.03989 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03992 (*cross-listing*)
Date: Sun, 5 Oct 2025 01:50:34 GMT   (201kb)

Title: Quantifying Distributional Robustness of Agentic Tool-Selection
Authors: Jehyeok Yeon, Isha Chaudhary, Gagandeep Singh
Categories: cs.CR cs.AI
\\
  Large language models (LLMs) are increasingly deployed in agentic systems
where they map user intents to relevant external tools to fulfill a task. A
critical step in this process is tool selection, where a retriever first
surfaces candidate tools from a larger pool, after which the LLM selects the
most appropriate one. This pipeline presents an underexplored attack surface
where errors in selection can lead to severe outcomes like unauthorized data
access or denial of service, all without modifying the agent's model or code.
While existing evaluations measure task performance in benign settings, they
overlook the specific vulnerabilities of the tool selection mechanism under
adversarial conditions. To address this gap, we introduce ToolCert, the first
statistical framework that formally certifies tool selection robustness.
ToolCert models tool selection as a Bernoulli success process and evaluates it
against a strong, adaptive attacker who introduces adversarial tools with
misleading metadata, and are iteratively refined based on the agent's previous
choices. By sampling these adversarial interactions, ToolCert produces a
high-confidence lower bound on accuracy, formally quantifying the agent's
worst-case performance. Our evaluation with ToolCert uncovers the severe
fragility: under attacks injecting deceptive tools or saturating retrieval, the
certified accuracy bound drops near zero, an average performance drop of over
60% compared to non-adversarial settings. For attacks targeting the retrieval
and selection stages, the certified accuracy bound plummets to less than 20%
after just a single round of adversarial adaptation. ToolCert thus reveals
previously unexamined security threats inherent to tool selection and provides
a principled method to quantify an agent's robustness to such threats, a
necessary step for the safe deployment of agentic systems.
\\ ( https://arxiv.org/abs/2510.03992 ,  201kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03995 (*cross-listing*)
Date: Sun, 5 Oct 2025 02:11:40 GMT   (240kb)

Title: PrivSpike: Employing Homomorphic Encryption for Private Inference of
  Deep Spiking Neural Networks
Authors: Nges Brian Njungle, Eric Jahns, Milan Stojkov, and Michel A. Kinsy
Categories: cs.CR cs.AI
Comments: 13 pages, 5 figures
Report-no: STAM-Center-REP-05
ACM-class: I.2; E.m
\\
  Deep learning has become a cornerstone of modern machine learning. It relies
heavily on vast datasets and significant computational resources for high
performance. This data often contains sensitive information, making privacy a
major concern in deep learning. Spiking Neural Networks (SNNs) have emerged as
an energy-efficient alternative to conventional deep learning approaches.
Nevertheless, SNNs still depend on large volumes of data, inheriting all the
privacy challenges of deep learning. Homomorphic encryption addresses this
challenge by allowing computations to be performed on encrypted data, ensuring
data confidentiality throughout the entire processing pipeline. In this paper,
we introduce PRIVSPIKE, a privacy-preserving inference framework for SNNs using
the CKKS homomorphic encryption scheme. PRIVSPIKE supports arbitrary depth SNNs
and introduces two key algorithms for evaluating the Leaky Integrate-and-Fire
activation function: (1) a polynomial approximation algorithm designed for
high-performance SNN inference, and (2) a novel scheme-switching algorithm that
optimizes precision at a higher computational cost. We evaluate PRIVSPIKE on
MNIST, CIFAR-10, Neuromorphic MNIST, and CIFAR-10 DVS using models from LeNet-5
and ResNet-19 architectures, achieving encrypted inference accuracies of
98.10%, 79.3%, 98.1%, and 66.0%, respectively. On a consumer-grade CPU, SNN
LeNet-5 models achieved inference times of 28 seconds on MNIST and 212 seconds
on Neuromorphic MNIST. For SNN ResNet-19 models, inference took 784 seconds on
CIFAR-10 and 1846 seconds on CIFAR-10 DVS. These results establish PRIVSPIKE as
a viable and efficient solution for secure SNN inference, bridging the gap
between energy-efficient deep neural networks and strong cryptographic privacy
guarantees while outperforming prior encrypted SNN solutions.
\\ ( https://arxiv.org/abs/2510.03995 ,  240kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03998 (*cross-listing*)
Date: Sun, 5 Oct 2025 02:16:52 GMT   (16kb)

Title: AI-Driven Grading and Moderation for Collaborative Projects in Computer
  Science Education
Authors: Songmei Yu, Andrew Zagula
Categories: cs.HC cs.AI cs.CY
Comments: Accepted at the 23rd International Conference on Education and
  Information Systems, Technologies and Applications (EISTA 2025)
DOI: 10.54808/IMSCI2025.01.6
\\
  Collaborative group projects are integral to computer science education, as
they foster teamwork, problem-solving skills, and industry-relevant
competencies. However, assessing individual contributions within group settings
has long been a challenge. Traditional assessment strategies, such as the equal
distribution of grades or subjective peer assessments, often fall short in
terms of fairness, objectivity, and scalability, particularly in large
classrooms. This paper introduces a semi-automated, AI-assisted grading system
that evaluates both project quality and individual effort using repository
mining, communication analytics, and machine learning models. The system
comprises modules for project evaluation, contribution analysis, and grade
computation, integrating seamlessly with platforms like GitHub. A pilot
deployment in a senior-level course demonstrated high alignment with instructor
assessments, increased student satisfaction, and reduced instructor grading
effort. We conclude by discussing implementation considerations, ethical
implications, and proposed enhancements to broaden applicability.
\\ ( https://arxiv.org/abs/2510.03998 ,  16kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04008 (*cross-listing*)
Date: Sun, 5 Oct 2025 02:57:40 GMT   (3860kb)

Title: Replacing Softmax Similarity with a Sharpened Angular Similarity: Theory
  and Practice of Scaling To Billion-Context Attention
Authors: Sahil Joshi, Agniva Chowdhury, Amar Kanakamedala, Ekam Singh, Evan Tu,
  Anshumali Shrivastava
Categories: cs.LG cs.AI
Comments: 28 pages, 7 figures
\\
  Softmax Attention has a quadratic time complexity, which becomes prohibitive
to run at long contexts, even with highly optimized GPU kernels. For example,
FlashAttention (an exact, GPU-optimized implementation of Softmax Attention)
cannot complete a single forward-backward pass of a multi-head attention layer
once the context exceeds ~4 million tokens on an NVIDIA GH200 (96 GB). We
introduce RACE Attention, a kernel-inspired alternative to Softmax Attention
that is linear in sequence length and embedding dimension. RACE Attention
replaces the exponential kernel with a sharpened angular (cosine) similarity,
and approximates attention outputs via randomized projections and soft
Locality-Sensitive Hashing (LSH). Across language modeling, masked language
modeling, and text classification, RACE Attention matches the accuracy of
strong baselines while reducing runtime and memory. In a controlled scale test,
it processes up to 12 million tokens during a single forward-backward pass on
an NVIDIA GH200 GPU and 75 million tokens on an Intel Xeon Gold 5220R CPU, well
beyond the practical limits of the current state-of-the-art attention
implementations. RACE Attention thus offers a practical, theoretically grounded
mechanism for outrageously long context windows on today's hardware. We hope
that it gets adopted in practice.
\\ ( https://arxiv.org/abs/2510.04008 ,  3860kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04019 (*cross-listing*)
Date: Sun, 5 Oct 2025 03:53:16 GMT   (269kb)

Title: Principled and Tractable RL for Reasoning with Diffusion Language Models
Authors: Anthony Zhan
Categories: cs.LG cs.AI cs.CL
\\
  Diffusion large language models (dLLMs) are a new paradigm of
non-autoregressive language models that are trained to predict multiple tokens
in parallel and generate text via iterative unmasking. Recent works have
successfully pretrained dLLMs to parity with autoregressive LLMs at the 8B
scale, but dLLMs have yet to benefit from modern post-training techniques, e.g.
reinforcement learning (RL), that have proven effective for autoregressive
models. Crucially, algorithms designed for traditional LLMs aren't directly
compatible with diffusion frameworks due to inherent differences in modeling
assumptions. Moreover, existing attempts at dLLM post-training with RL rely on
heuristic-based objectives with no theoretical grounding. In this work, we
present Amortized Group Relative Policy Optimization (AGRPO), a principled
on-policy RL algorithm designed specifically for dLLMs. AGRPO uses Monte Carlo
sampling to compute an unbiased policy gradient estimate, making it the first
tractable, faithful adaptation of policy gradient methods for dLLMs. We
demonstrate AGRPO's effectiveness on different math/reasoning tasks, a common
setting for RL with LLMs, achieving up to +7.6% absolute gain on GSM8K and 3.8x
performance on the Countdown task over the baseline LLaDA-8B-Instruct model and
1.3x performance gains over comparable RL methods such as diffu-GRPO.
Furthermore, these gains persist across different numbers of sampling steps at
inference time, achieving better tradeoffs between compute and performance. Our
results demonstrate that online RL algorithms can be extended to diffusion LLMs
in principled ways, maintaining both theoretical soundness and practical
effectiveness.
\\ ( https://arxiv.org/abs/2510.04019 ,  269kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04020 (*cross-listing*)
Date: Sun, 5 Oct 2025 03:57:38 GMT   (12551kb)

Title: Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement
  Learning Approach with Generative World Models
Authors: Hao Wu, Yuan Gao, Xingjian Shi, Shuaipeng Li, Fan Xu, Fan Zhang,
  Zhihong Zhu, Weiyan Wang, Xiao Luo, Kun Wang, Xian Wu, Xiaomeng Huang
Categories: cs.LG cs.AI
\\
  To address the dual challenges of inherent stochasticity and
non-differentiable metrics in physical spatiotemporal forecasting, we propose
Spatiotemporal Forecasting as Planning (SFP), a new paradigm grounded in
Model-Based Reinforcement Learning. SFP constructs a novel Generative World
Model to simulate diverse, high-fidelity future states, enabling an
"imagination-based" environmental simulation. Within this framework, a base
forecasting model acts as an agent, guided by a beam search-based planning
algorithm that leverages non-differentiable domain metrics as reward signals to
explore high-return future sequences. These identified high-reward candidates
then serve as pseudo-labels to continuously optimize the agent's policy through
iterative self-training, significantly reducing prediction error and
demonstrating exceptional performance on critical domain metrics like capturing
extreme events.
\\ ( https://arxiv.org/abs/2510.04020 ,  12551kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04028 (*cross-listing*)
Date: Sun, 5 Oct 2025 04:31:33 GMT   (4705kb)

Title: The Debate on RLVR Reasoning Capability Boundary: Shrinkage, Expansion,
  or Both? A Two-Stage Dynamic View
Authors: Xinhao Yao, Lu Yu, Xiaolin Hu, Fengwei Teng, Qing Cui, Jun Zhou, Yong
  Liu
Categories: cs.LG cs.AI
\\
  The ongoing debate on whether reinforcement learning with verifiable rewards
(RLVR) expands or shrinks the reasoning capabilities of large language models
(LLMs) remains unresolved. Some studies contend that RLVR mainly improves
sampling efficiency but at the expense of diversity and exploratory capacity,
resulting in capability boundary shrinkage. In contrast, others demonstrate
that prolonged training can lead to the emergence of novel reasoning
strategies, suggesting capability boundary expansion. To reconcile these
contradictory findings, we theoretically and empirically show that both
perspectives are partially valid-each aligning with a separate phase in an
inherent two-stage probability mass dynamic: (1) Exploitation stage: initially,
the model primarily samples explored high-reward and low-reward tokens, while
rarely selecting the potentially optimal token. Positive advantage estimates
increase the probability of high-reward tokens and decrease those of low-reward
tokens, yet the optimal token's probability remains largely unchanged during
this stage. (2) Exploration stage: as training advances, the growth rate of
previously acquired high-reward tokens slows as their probabilities approach
saturation. When a potentially optimal token-now receiving positive advantage
estimates-is occasionally sampled, its probability increases, while those of
the originally high-reward tokens decrease. This dynamic suggests that
over-exploitation during the exploitation stage may lead to capability boundary
shrinkage, whereas prolonged training into the exploration stage can promote an
expansion of the reasoning capability boundary. Building upon our insights, we
revisit the potential of only using relative negative gradients for prolonging
training, providing a theoretical and empirical foundation for the development
of more advanced reasoning capabilities.
\\ ( https://arxiv.org/abs/2510.04028 ,  4705kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04067 (*cross-listing*)
Date: Sun, 5 Oct 2025 07:06:02 GMT   (795kb)

Title: What Scales in Cross-Entropy Scaling Law?
Authors: Junxi Yan, Zixi Wei, Jingtao Zhan, Qingyao Ai, Yiqun Liu
Categories: cs.LG cs.AI cs.CL
\\
  The cross-entropy scaling law has long served as a key tool for guiding the
development of large language models. It shows that cross-entropy loss
decreases in a predictable power-law rate as the model size increases. However,
recent evidence indicates that this law breaks down at very large scales: the
loss decreases more slowly than expected, which causes significant trouble for
developing large language models. In this paper, we hypothesize that the root
cause lies in the fact that cross-entropy itself does not truly scale; instead,
only one of its hidden components does. To investigate this, we introduce a
novel decomposition of cross-entropy into three parts: Error-Entropy,
Self-Alignment, and Confidence. We show both theoretically and empirically that
this decomposition precisely captures the training dynamics and optimization
objectives. Through extensive experiments on multiple datasets and 32 models
spanning five orders of magnitude in size, we find that only error-entropy
follows a robust power-law scaling, while the other two terms remain largely
invariant. Moreover, error-entropy constitutes the dominant share of
cross-entropy in small models but diminishes in proportion as models grow
larger. This explains why the cross-entropy scaling law appears accurate at
small scales but fails at very large ones. Our findings establish the
error-entropy scaling law as a more accurate description of model behavior. We
believe it will have wide applications in the training, understanding, and
future development of large language models.
\\ ( https://arxiv.org/abs/2510.04067 ,  795kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04072 (*cross-listing*)
Date: Sun, 5 Oct 2025 07:22:54 GMT   (19748kb)

Title: Slow-Fast Policy Optimization: Reposition-Before-Update for LLM
  Reasoning
Authors: Ziyan Wang, Zheng Wang, Jie Fu, Xingwei Qu, Qi Cheng, Shengpu Tang,
  Minjia Zhang, Xiaoming Huo
Categories: cs.LG cs.AI cs.CL stat.ML
\\
  Reinforcement learning (RL) has become central to enhancing reasoning in
large language models (LLMs). Yet on-policy algorithms such as Group Relative
Policy Optimization (GRPO) often suffer in early training: noisy gradients from
low-quality rollouts lead to unstable updates and inefficient exploration. We
introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient
framework to address these limitations via decomposing each step into three
stages: a short fast trajectory of inner steps on the same batch, a reposition
mechanism to control off-policy drift, and a final slow correction. This
reposition-before-update design preserves the objective and rollout process
unchanged, making SFPO plug-compatible with existing policy-gradient pipelines.
Extensive experiments demonstrate that SFPO consistently improves stability,
reduces rollouts, and accelerates convergence of reasoning RL training.
Specifically, it outperforms GRPO by up to 2.80 points in average on math
reasoning benchmarks. It also achieves up to 4.93\texttimes{} fewer rollouts
and a 4.19\texttimes{} reduction in wall-clock time to match GRPO's best
accuracy.
\\ ( https://arxiv.org/abs/2510.04072 ,  19748kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04087 (*cross-listing*)
Date: Sun, 5 Oct 2025 08:23:08 GMT   (573kb)

Title: A Contextual Quality Reward Model for Reliable and Efficient Best-of-N
  Sampling
Authors: Hyung Gyu Rho
Categories: stat.ME cs.AI cs.LG
DOI: 10.21203/rs.3.rs-7594024/v1
\\
  Modern preference alignment techniques, such as Best-of-N (BoN) sampling,
rely on reward models trained with pairwise comparison data. While effective at
learning relative preferences, this paradigm fails to capture a signal of
response acceptability, leaving systems vulnerable to selecting the least bad
of many unacceptable options. This is particularly problematic for hard
prompts, where the risk of such false acceptances increases with the number of
samples. In this paper, we address this critical reliability gap by introducing
a new data collection and modeling framework. By augmenting preference data
with an outside option, inspired by discrete choice models, we train a reward
model that can distinguish not just what is \textit{better}, but what is
\textit{good enough}. We leverage this capability to create an adaptive
inference strategy, best of mini-N in-loop, which partitions the generation
budget into sequential loops with a calibrated, early-exit condition. Our
experiments show that when tuned as an alignment guardrail, it reduces
reliability failures by 70\%, and when tuned as an inference accelerator, it
improves average inference speed by over 22\% in IMDB-sentiment setting. We
thus provide a principled and flexible framework for practitioners to
explicitly manage the trade-off between reliability and computational
efficiency.
\\ ( https://arxiv.org/abs/2510.04087 ,  573kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04088 (*cross-listing*)
Date: Sun, 5 Oct 2025 08:23:40 GMT   (408kb)

Title: Offline Reinforcement Learning in Large State Spaces: Algorithms and
  Guarantees
Authors: Nan Jiang, Tengyang Xie
Categories: cs.LG cs.AI stat.ML
Comments: To appear in Statistical Science
\\
  This article introduces the theory of offline reinforcement learning in large
state spaces, where good policies are learned from historical data without
online interactions with the environment. Key concepts introduced include
expressivity assumptions on function approximation (e.g., Bellman completeness
vs. realizability) and data coverage (e.g., all-policy vs. single-policy
coverage). A rich landscape of algorithms and results is described, depending
on the assumptions one is willing to make and the sample and computational
complexity guarantees one wishes to achieve. We also discuss open questions and
connections to adjacent areas.
\\ ( https://arxiv.org/abs/2510.04088 ,  408kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04090 (*cross-listing*)
Date: Sun, 5 Oct 2025 08:28:37 GMT   (1528kb)

Title: Using predefined vector systems as latent space configuration for neural
  network supervised training on data with arbitrarily large number of classes
Authors: Nikita Gabdullin
Categories: cs.LG cs.AI cs.CV
Comments: 28 pages, 12 figures, 10 tables, 12 equations, 1 algorithm
\\
  Supervised learning (SL) methods are indispensable for neural network (NN)
training used to perform classification tasks. While resulting in very high
accuracy, SL training often requires making NN parameter number dependent on
the number of classes, limiting their applicability when the number of classes
is extremely large or unknown in advance. In this paper we propose a
methodology that allows one to train the same NN architecture regardless of the
number of classes. This is achieved by using predefined vector systems as the
target latent space configuration (LSC) during NN training. We discuss the
desired properties of target configurations and choose randomly perturbed
vectors of An root system for our experiments. These vectors are used to
successfully train encoders and visual transformers (ViT) on Cinic-10 and
ImageNet-1K in low- and high-dimensional cases by matching NN predictions with
the predefined vectors. Finally, ViT is trained on a dataset with 1.28 million
classes illustrating the applicability of the method to training on datasets
with extremely large number of classes. In addition, potential applications of
LSC in lifelong learning and NN distillation are discussed illustrating
versatility of the proposed methodology.
\\ ( https://arxiv.org/abs/2510.04090 ,  1528kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04098 (*cross-listing*)
Date: Sun, 5 Oct 2025 08:50:28 GMT   (732kb)

Title: Efficient Training of Spiking Neural Networks by Spike-aware Data
  Pruning
Authors: Chenxiang Ma, Xinyi Chen, Yujie Wu, Kay Chen Tan, Jibin Wu
Categories: cs.NE cs.AI
\\
  Spiking neural networks (SNNs), recognized as an energy-efficient alternative
to traditional artificial neural networks (ANNs), have advanced rapidly through
the scaling of models and datasets. However, such scaling incurs considerable
training overhead, posing challenges for researchers with limited computational
resources and hindering the sustained development of SNNs. Data pruning is a
promising strategy for accelerating training by retaining the most informative
examples and discarding redundant ones, but it remains largely unexplored in
SNNs. Directly applying ANN-based data pruning methods to SNNs fails to capture
the intrinsic importance of examples and suffers from high gradient variance.
To address these challenges, we propose a novel spike-aware data pruning (SADP)
method. SADP reduces gradient variance by determining each example's selection
probability to be proportional to its gradient norm, while avoiding the high
cost of direct gradient computation through an efficient upper bound, termed
spike-aware importance score. This score accounts for the influence of
all-or-nothing spikes on the gradient norm and can be computed with negligible
overhead. Extensive experiments across diverse datasets and architectures
demonstrate that SADP consistently outperforms data pruning baselines and
achieves training speedups close to the theoretical maxima at different pruning
ratios. Notably, SADP reduces training time by 35% on ImageNet while
maintaining accuracy comparable to that of full-data training. This work,
therefore, establishes a data-centric paradigm for efficient SNN training and
paves the way for scaling SNNs to larger models and datasets. The source code
will be released publicly after the review process.
\\ ( https://arxiv.org/abs/2510.04098 ,  732kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04126 (*cross-listing*)
Date: Sun, 5 Oct 2025 09:59:26 GMT   (1804kb)

Title: Attending on Multilevel Structure of Proteins enables Accurate
  Prediction of Cold-Start Drug-Target Interactions
Authors: Ziying Zhang, Yaqing Wang, Yuxuan Sun, Min Ye, Quanming Yao
Categories: cs.LG cs.AI
\\
  Cold-start drug-target interaction (DTI) prediction focuses on interaction
between novel drugs and proteins. Previous methods typically learn transferable
interaction patterns between structures of drug and proteins to tackle it.
However, insight from proteomics suggest that protein have multi-level
structures and they all influence the DTI. Existing works usually represent
protein with only primary structures, limiting their ability to capture
interactions involving higher-level structures. Inspired by this insight, we
propose ColdDTI, a framework attending on protein multi-level structure for
cold-start DTI prediction. We employ hierarchical attention mechanism to mine
interaction between multi-level protein structures (from primary to quaternary)
and drug structures at both local and global granularities. Then, we leverage
mined interactions to fuse structure representations of different levels for
final prediction. Our design captures biologically transferable priors,
avoiding the risk of overfitting caused by excessive reliance on representation
learning. Experiments on benchmark datasets demonstrate that ColdDTI
consistently outperforms previous methods in cold-start settings.
\\ ( https://arxiv.org/abs/2510.04126 ,  1804kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04127 (*cross-listing*)
Date: Sun, 5 Oct 2025 09:59:56 GMT   (28221kb)

Title: Learning-Based Hashing for ANN Search: Foundations and Early Advances
Authors: Sean Moran
Categories: cs.IR cs.AI cs.CV cs.LG
\\
  Approximate Nearest Neighbour (ANN) search is a fundamental problem in
information retrieval, underpinning large-scale applications in computer
vision, natural language processing, and cross-modal search. Hashing-based
methods provide an efficient solution by mapping high-dimensional data into
compact binary codes that enable fast similarity computations in Hamming space.
Over the past two decades, a substantial body of work has explored learning to
hash, where projection and quantisation functions are optimised from data
rather than chosen at random.
  This article offers a foundational survey of early learning-based hashing
methods, with an emphasis on the core ideas that shaped the field. We review
supervised, unsupervised, and semi-supervised approaches, highlighting how
projection functions are designed to generate meaningful embeddings and how
quantisation strategies convert these embeddings into binary codes. We also
examine extensions to multi-bit and multi-threshold models, as well as early
advances in cross-modal retrieval.
  Rather than providing an exhaustive account of the most recent methods, our
goal is to introduce the conceptual foundations of learning-based hashing for
ANN search. By situating these early models in their historical context, we aim
to equip readers with a structured understanding of the principles, trade-offs,
and open challenges that continue to inform current research in this area.
\\ ( https://arxiv.org/abs/2510.04127 ,  28221kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04130 (*cross-listing*)
Date: Sun, 5 Oct 2025 10:08:33 GMT   (3258kb)

Title: On the Limitations and Capabilities of Position Embeddings for Length
  Generalization
Authors: Yang Chen, Yitao Liang, Zhouchen Lin
Categories: cs.LG cs.AI
\\
  In Transformers, Position Embeddings (PEs) significantly influence Length
Generalization (LG) performance, yet their fundamental role remains unclear. In
this work, we investigate the limitations and capabilities of PEs in achieving
LG. We theoretically analyze PEs in Position-Only Linear Attentions (POLAs),
introducing Linear Representation Complexity (LRC) to characterize when PEs
enable LG. Our analysis shows that PEs do not expand computational capabilities
but structure learned computations across positions. Extending to practical
Transformers, we propose Sequential Representation Complexity (SRC) and
conjecture that LG is possible if and only if SRC remains invariant across
scales. We support this hypothesis with empirical evidence in various reasoning
tasks. To enhance LG, we introduce Scale Hint, allowing flexible instance
scaling, and a Learning-Based Position Embedding framework that automatically
learns positional relations. Our work provides theoretical insights and
practical strategies for improving LG in Transformers.
\\ ( https://arxiv.org/abs/2510.04130 ,  3258kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04134 (*cross-listing*)
Date: Sun, 5 Oct 2025 10:34:19 GMT   (3406kb)

Title: PhaseFormer: From Patches to Phases for Efficient and Effective Time
  Series Forecasting
Authors: Yiming Niu, Jinliang Deng, Yongxin Tong
Categories: cs.LG cs.AI
\\
  Periodicity is a fundamental characteristic of time series data and has long
played a central role in forecasting. Recent deep learning methods strengthen
the exploitation of periodicity by treating patches as basic tokens, thereby
improving predictive effectiveness. However, their efficiency remains a
bottleneck due to large parameter counts and heavy computational costs. This
paper provides, for the first time, a clear explanation of why patch-level
processing is inherently inefficient, supported by strong evidence from
real-world data. To address these limitations, we introduce a phase perspective
for modeling periodicity and present an efficient yet effective solution,
PhaseFormer. PhaseFormer features phase-wise prediction through compact phase
embeddings and efficient cross-phase interaction enabled by a lightweight
routing mechanism. Extensive experiments demonstrate that PhaseFormer achieves
state-of-the-art performance with around 1k parameters, consistently across
benchmark datasets. Notably, it excels on large-scale and complex datasets,
where models with comparable efficiency often struggle. This work marks a
significant step toward truly efficient and effective time series forecasting.
Code is available at this repository:
https://github.com/neumyor/PhaseFormer_TSL
\\ ( https://arxiv.org/abs/2510.04134 ,  3406kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04135 (*cross-listing*)
Date: Sun, 5 Oct 2025 10:34:30 GMT   (119kb)

Title: GA4GC: Greener Agent for Greener Code via Multi-Objective Configuration
  Optimization
Authors: Jingzhi Gong, Yixin Bian, Luis de la Cal, Giovanni Pinna, Anisha
  Uteem, David Williams, Mar Zamorano, Karine Even-Mendoza, W.B. Langdon,
  Hector Menendez, Federica Sarro
Categories: cs.SE cs.AI
Comments: Accepted by SSBSE'25 Challenge Track
\\
  Coding agents powered by LLMs face critical sustainability and scalability
challenges in industrial deployment, with single runs consuming over 100k
tokens and incurring environmental costs that may exceed optimization benefits.
This paper introduces GA4GC, the first framework to systematically optimize
coding agent runtime (greener agent) and code performance (greener code)
trade-offs by discovering Pareto-optimal agent hyperparameters and prompt
templates. Evaluation on the SWE-Perf benchmark demonstrates up to 135x
hypervolume improvement, reducing agent runtime by 37.7% while improving
correctness. Our findings establish temperature as the most critical
hyperparameter, and provide actionable strategies to balance agent
sustainability with code optimization effectiveness in industrial deployment.
\\ ( https://arxiv.org/abs/2510.04135 ,  119kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04146 (*cross-listing*)
Date: Sun, 5 Oct 2025 10:50:52 GMT   (1327kb)

Title: Beyond Next-Token Prediction: A Performance Characterization of
  Diffusion versus Autoregressive Language Models
Authors: Minseo Kim, Coleman Hooper, Aditya Tomar, Chenfeng Xu, Mehrdad
  Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami
Categories: cs.LG cs.AI cs.CL
Comments: 11 pages, 5 figures
\\
  Large Language Models (LLMs) have achieved state-of-the-art performance on a
broad range of Natural Language Processing (NLP) tasks, including document
processing and coding. Autoregressive Language Models (ARMs), which generate
tokens sequentially conditioned on all previous tokens, have been the
predominant paradigm for LLMs. However, while these networks have achieved high
accuracy across a range of downstream tasks, they exhibit low arithmetic
intensity due to the inherent sequential dependency with next-token prediction.
Recently, Diffusion Language Models (DLMs) have emerged as a promising
alternative architecture. DLMs generate output text in parallel, breaking the
limitations of sequential dependency. However, the performance implications of
DLMs relative to commonly deployed ARMs are not fully understood. In this work,
we present a comprehensive performance study analyzing the performance
characteristics of ARMs and DLMs, using both theoretical analysis and profiling
data to characterize the trade-offs between these approaches. We illustrate
that although DLMs exhibit higher arithmetic intensity compared to ARMs because
of their capability to utilize parallelism across sequence lengths, they fail
to scale effectively to longer contexts. We then explore DLMs with block-wise
decoding, outlining how this approach allows for increased arithmetic
intensity, while still scaling well to long contexts (similar to ARMs). We also
show interesting trade-offs for batched inference, where we find that ARMs
exhibit superior throughput, as they benefit more from parallelism across
sequences in the batch. Finally, we highlight opportunities for accelerating
DLM inference, and, in particular, highlight the importance of reducing the
number of sampling steps for allowing open-source DLMs to provide improved
latency relative to ARMs.
\\ ( https://arxiv.org/abs/2510.04146 ,  1327kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04166 (*cross-listing*)
Date: Sun, 5 Oct 2025 11:48:49 GMT   (471kb)

Title: Multi Language Models for On-the-Fly Syntax Highlighting
Authors: Marco Edoardo Palma, Pooja Rani, Harald C. Gall
Categories: cs.SE cs.AI
\\
  Syntax highlighting is a critical feature in modern software development
environments, enhancing code readability and developer productivity. However,
delivering accurate highlighting in real time remains challenging for online
and web-based development tools due to strict time and memory constraints on
backend services. These systems must serve highlights rapidly and frequently,
even when code is partially valid or invalid. This has led to on-the-fly syntax
highlighting, where visual annotations are generated just before content is
served, often at high request rates and under incomplete input conditions. To
meet these demands efficiently, state-of-the-art models use deep learning to
learn the behavior of brute-force syntax highlighting resolvers, tools that are
easy to implement but too slow for production. Through the Deep Abstraction
process, brute-force strategies are encoded into fast statistical models that
achieve both high accuracy and low-latency inference. Despite their success,
such models face key challenges: they support only one programming language per
model, require large datasets from slow brute-force generators, and involve
resource-intensive training. In multi-language environments, this means
maintaining multiple independent models, increasing system complexity and
operational cost. This work addresses these issues by introducing a unified
model capable of highlighting up to six mainstream programming languages,
reducing deployment complexity by a factor of six and improving performance on
unseen languages. A novel normalization technique significantly enhances model
generalization, while few-shot learning experiments show that a small number of
oracle samples can replace large datasets, minimizing dependence on brute-force
generators. Combined, these innovations enable efficient, scalable, and
cost-effective syntax highlighting across diverse programming languages.
\\ ( https://arxiv.org/abs/2510.04166 ,  471kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04187 (*cross-listing*)
Date: Sun, 5 Oct 2025 13:01:05 GMT   (10269kb)

Title: A Complement to Neural Networks for Anisotropic Inelasticity at Finite
  Strains
Authors: Hagen Holthusen and Ellen Kuhl
Categories: cs.CE cs.AI
Comments: 40 pages, 19 figures
MSC-class: 65, 74
ACM-class: I.6; J.2
\\
  We propose a complement to constitutive modeling that augments neural
networks with material principles to capture anisotropy and inelasticity at
finite strains. The key element is a dual potential that governs dissipation,
consistently incorporates anisotropy, and-unlike conventional convex
formulations-satisfies the dissipation inequality without requiring convexity.
  Our neural network architecture employs invariant-based input representations
in terms of mixed elastic, inelastic and structural tensors. It adapts Input
Convex Neural Networks, and introduces Input Monotonic Neural Networks to
broaden the admissible potential class. To bypass exponential-map time
integration in the finite strain regime and stabilize the training of inelastic
materials, we employ recurrent Liquid Neural Networks.
  The approach is evaluated at both material point and structural scales. We
benchmark against recurrent models without physical constraints and validate
predictions of deformation and reaction forces for unseen boundary value
problems. In all cases, the method delivers accurate and stable performance
beyond the training regime. The neural network and finite element
implementations are available as open-source and are accessible to the public
via https://doi.org/10.5281/zenodo.17199965.
\\ ( https://arxiv.org/abs/2510.04187 ,  10269kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04189 (*cross-listing*)
Date: Sun, 5 Oct 2025 13:02:38 GMT   (288kb)

Title: Finite Time Analysis of Constrained Natural Critic-Actor Algorithm with
  Improved Sample Complexity
Authors: Prashansa Panda and Shalabh Bhatnagar
Categories: cs.LG cs.AI
\\
  Recent studies have increasingly focused on non-asymptotic convergence
analyses for actor-critic (AC) algorithms. One such effort introduced a
two-timescale critic-actor algorithm for the discounted cost setting using a
tabular representation, where the usual roles of the actor and critic are
reversed. However, only asymptotic convergence was established there.
Subsequently, both asymptotic and non-asymptotic analyses of the critic-actor
algorithm with linear function approximation were conducted. In our work, we
introduce the first natural critic-actor algorithm with function approximation
for the long-run average cost setting and under inequality constraints. We
provide the non-asymptotic convergence guarantees for this algorithm. Our
analysis establishes optimal learning rates and we also propose a modification
to enhance sample complexity. We further show the results of experiments on
three different Safety-Gym environments where our algorithm is found to be
competitive in comparison with other well known algorithms.
\\ ( https://arxiv.org/abs/2510.04189 ,  288kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04205 (*cross-listing*)
Date: Sun, 5 Oct 2025 13:39:18 GMT   (11kb)

Title: PolyKAN: A Polyhedral Analysis Framework for Provable and Minimal KAN
  Compression
Authors: Di Zhang
Categories: cs.LG cs.AI cs.NA math.NA math.OC
Comments: 10
MSC-class: 68T07, 41A15, 52B11
ACM-class: F.2.2; G.1.2; I.2.6
\\
  Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to
traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability
and a strong mathematical foundation. However, their parameter efficiency
remains a significant challenge for practical deployment. This paper introduces
PolyKAN, a novel theoretical framework for KAN compression that provides formal
guarantees on both model size reduction and approximation error. By leveraging
the inherent piecewise polynomial structure of KANs, we formulate the
compression problem as one of optimal polyhedral region merging. We establish a
rigorous polyhedral characterization of KANs, develop a complete theory of
$\epsilon$-equivalent compression, and design an optimal dynamic programming
algorithm that guarantees minimal compression under specified error bounds. Our
theoretical analysis demonstrates that PolyKAN achieves provably minimal
compression while maintaining strict error control, with polynomial-time
complexity in all network parameters. The framework provides the first formal
foundation for KAN compression with mathematical guarantees, opening new
directions for efficient deployment of interpretable neural architectures.
\\ ( https://arxiv.org/abs/2510.04205 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04212 (*cross-listing*)
Date: Sun, 5 Oct 2025 14:01:24 GMT   (24667kb)

Title: Why Low-Precision Transformer Training Fails: An Analysis on Flash
  Attention
Authors: Haiquan Qiu, Quanming Yao
Categories: cs.LG cs.AI
Comments: 19 pages, 10 figures
\\
  The pursuit of computational efficiency has driven the adoption of
low-precision formats for training transformer models. However, this progress
is often hindered by notorious training instabilities. This paper provides the
first mechanistic explanation for a long-standing and unresolved failure case
where training with flash attention in low-precision settings leads to
catastrophic loss explosions. Our in-depth analysis reveals that the failure is
not a random artifact but caused by two intertwined phenomena: the emergence of
similar low-rank representations within the attention mechanism and the
compounding effect of biased rounding errors inherent in low-precision
arithmetic. We demonstrate how these factors create a vicious cycle of error
accumulation that corrupts weight updates, ultimately derailing the training
dynamics. To validate our findings, we introduce a minimal modification to the
flash attention that mitigates the bias in rounding errors. This simple change
stabilizes the training process, confirming our analysis and offering a
practical solution to this persistent problem.
\\ ( https://arxiv.org/abs/2510.04212 ,  24667kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04217 (*cross-listing*)
Date: Sun, 5 Oct 2025 14:20:17 GMT   (891kb)

Title: MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language
  Models through Activation Steering
Authors: Chenlu Ding, Jiancan Wu, Leheng Sheng, Fan Zhang, Yancheng Yuan, Xiang
  Wang, Xiangnan He
Categories: cs.LG cs.AI
\\
  Multimodal large language models (MLLMs) have demonstrated remarkable
capabilities across vision-language tasks, yet their large-scale deployment
raises pressing concerns about memorized private data, outdated knowledge, and
harmful content. Existing unlearning approaches for MLLMs typically adapt
training-based strategies such as gradient ascent or preference optimization,
but these methods are computationally expensive, irreversible, and often
distort retained knowledge. In this work, we propose MLLMEraser, an
input-aware, training-free framework for test-time unlearning. Our approach
leverages activation steering to enable dynamic knowledge erasure without
parameter updates. Specifically, we construct a multimodal erasure direction by
contrasting adversarially perturbed, knowledge-recall image-text pairs with
knowledge-erasure counterparts, capturing both textual and visual
discrepancies. To prevent unnecessary interference, we further design an
input-aware steering mechanism that adaptively determines when and how the
erasure direction should be applied, preserving utility on retained knowledge
while enforcing forgetting on designated content. Experiments on LLaVA-1.5 and
Qwen-2.5-VL demonstrate that MLLMEraser consistently outperforms
state-of-the-art MLLM unlearning baselines, achieving stronger forgetting
performance with lower computational cost and minimal utility degradation.
\\ ( https://arxiv.org/abs/2510.04217 ,  891kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04229 (*cross-listing*)
Date: Sun, 5 Oct 2025 14:37:46 GMT   (1716kb)

Title: When AI Gets Persuaded, Humans Follow: Inducing the Conformity Effect in
  Persuasive Dialogue
Authors: Rikuo Sasaki, Michimasa Inaba
Categories: cs.HC cs.AI
Comments: 23 pages, 19 figures. International Conference on Human-Agent
  Interaction (HAI 2025), November 10-13, 2025, Yokohama, Japan
ACM-class: H.5.2
DOI: 10.1145/3765766.3765770
\\
  Recent advancements in AI have highlighted its application in captology, the
field of using computers as persuasive technologies. We hypothesized that the
"conformity effect," where individuals align with others' actions, also occurs
with AI agents. This study verifies this hypothesis by introducing a "Persuadee
Agent" that is persuaded alongside a human participant in a three-party
persuasive dialogue with a Persuader Agent. We conducted a text-based dialogue
experiment with human participants. We compared four conditions manipulating
the Persuadee Agent's behavior (persuasion acceptance vs. non-acceptance) and
the presence of an icebreaker session. Results showed that when the Persuadee
Agent accepted persuasion, both perceived persuasiveness and actual attitude
change significantly improved. Attitude change was greatest when an icebreaker
was also used, whereas an unpersuaded AI agent suppressed attitude change.
Additionally, it was confirmed that the persuasion acceptance of participants
increased at the moment the Persuadee Agent was persuaded. These results
suggest that appropriately designing a Persuadee Agent can improve persuasion
through the conformity effect.
\\ ( https://arxiv.org/abs/2510.04229 ,  1716kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04233 (*cross-listing*)
Date: Sun, 5 Oct 2025 14:48:26 GMT   (10694kb)

Title: Physics-Inspired All-Pair Interaction Learning for 3D Dynamics Modeling
Authors: Kai Yang, Yuqi Huang, Junheng Tao, Wanyu Wang, Qitian Wu
Categories: cs.LG cs.AI
\\
  Modeling 3D dynamics is a fundamental problem in multi-body systems across
scientific and engineering domains and has important practical implications in
trajectory prediction and simulation. While recent GNN-based approaches have
achieved strong performance by enforcing geometric symmetries, encoding
high-order features or incorporating neural-ODE mechanics, they typically
depend on explicitly observed structures and inherently fail to capture the
unobserved interactions that are crucial to complex physical behaviors and
dynamics mechanism. In this paper, we propose PAINET, a principled
SE(3)-equivariant neural architecture for learning all-pair interactions in
multi-body systems. The model comprises: (1) a novel physics-inspired attention
network derived from the minimization trajectory of an energy function, and (2)
a parallel decoder that preserves equivariance while enabling efficient
inference. Empirical results on diverse real-world benchmarks, including human
motion capture, molecular dynamics, and large-scale protein simulations, show
that PAINET consistently outperforms recently proposed models, yielding 4.7% to
41.5% error reductions in 3D dynamics prediction with comparable computation
costs in terms of time and memory.
\\ ( https://arxiv.org/abs/2510.04233 ,  10694kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04234 (*cross-listing*)
Date: Sun, 5 Oct 2025 14:51:13 GMT   (4066kb)

Title: Flexible Locomotion Learning with Diffusion Model Predictive Control
Authors: Runhan Huang, Haldun Balim, Heng Yang, Yilun Du
Categories: cs.RO cs.AI
Comments: 9 pages, 8 figures
\\
  Legged locomotion demands controllers that are both robust and adaptable,
while remaining compatible with task and safety considerations. However,
model-free reinforcement learning (RL) methods often yield a fixed policy that
can be difficult to adapt to new behaviors at test time. In contrast, Model
Predictive Control (MPC) provides a natural approach to flexible behavior
synthesis by incorporating different objectives and constraints directly into
its optimization process. However, classical MPC relies on accurate dynamics
models, which are often difficult to obtain in complex environments and
typically require simplifying assumptions. We present Diffusion-MPC, which
leverages a learned generative diffusion model as an approximate dynamics prior
for planning, enabling flexible test-time adaptation through reward and
constraint based optimization. Diffusion-MPC jointly predicts future states and
actions; at each reverse step, we incorporate reward planning and impose
constraint projection, yielding trajectories that satisfy task objectives while
remaining within physical limits. To obtain a planning model that adapts beyond
imitation pretraining, we introduce an interactive training algorithm for
diffusion based planner: we execute our reward-and-constraint planner in
environment, then filter and reweight the collected trajectories by their
realized returns before updating the denoiser. Our design enables strong
test-time adaptability, allowing the planner to adjust to new reward
specifications without retraining. We validate Diffusion-MPC on real world,
demonstrating strong locomotion and flexible adaptation.
\\ ( https://arxiv.org/abs/2510.04234 ,  4066kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04239 (*cross-listing*)
Date: Sun, 5 Oct 2025 15:10:51 GMT   (420kb)

Title: Empowering Denoising Sequential Recommendation with Large Language Model
  Embeddings
Authors: Tongzhou Wu, Yuhao Wang, Maolin Wang, Chi Zhang, Xiangyu Zhao
Categories: cs.IR cs.AI
Comments: Accepted by CIKM2025
DOI: 10.1145/3746252.3761427
\\
  Sequential recommendation aims to capture user preferences by modeling
sequential patterns in user-item interactions. However, these models are often
influenced by noise such as accidental interactions, leading to suboptimal
performance. Therefore, to reduce the effect of noise, some works propose
explicitly identifying and removing noisy items. However, we find that simply
relying on collaborative information may result in an over-denoising problem,
especially for cold items. To overcome these limitations, we propose a novel
framework: Interest Alignment for Denoising Sequential Recommendation (IADSR)
which integrates both collaborative and semantic information. Specifically,
IADSR is comprised of two stages: in the first stage, we obtain the
collaborative and semantic embeddings of each item from a traditional
sequential recommendation model and an LLM, respectively. In the second stage,
we align the collaborative and semantic embeddings and then identify noise in
the interaction sequence based on long-term and short-term interests captured
in the collaborative and semantic modalities. Our extensive experiments on four
public datasets validate the effectiveness of the proposed framework and its
compatibility with different sequential recommendation systems.
\\ ( https://arxiv.org/abs/2510.04239 ,  420kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04241 (*cross-listing*)
Date: Sun, 5 Oct 2025 15:11:55 GMT   (11363kb)

Title: Diffusion-Assisted Distillation for Self-Supervised Graph Representation
  Learning with MLPs
Authors: Seong Jin Ahn and Myoung-Ho Kim
Categories: cs.LG cs.AI
DOI: 10.1109/TAI.2025.3598791
\\
  For large-scale applications, there is growing interest in replacing Graph
Neural Networks (GNNs) with lightweight Multi-Layer Perceptrons (MLPs) via
knowledge distillation. However, distilling GNNs for self-supervised graph
representation learning into MLPs is more challenging. This is because the
performance of self-supervised learning is more related to the model's
inductive bias than supervised learning. This motivates us to design a new
distillation method to bridge a huge capacity gap between GNNs and MLPs in
self-supervised graph representation learning. In this paper, we propose
\textbf{D}iffusion-\textbf{A}ssisted \textbf{D}istillation for
\textbf{S}elf-supervised \textbf{G}raph representation learning with
\textbf{M}LPs (DAD-SGM). The proposed method employs a denoising diffusion
model as a teacher assistant to better distill the knowledge from the teacher
GNN into the student MLP. This approach enhances the generalizability and
robustness of MLPs in self-supervised graph representation learning. Extensive
experiments demonstrate that DAD-SGM effectively distills the knowledge of
self-supervised GNNs compared to state-of-the-art GNN-to-MLP distillation
methods. Our implementation is available at
https://github.com/SeongJinAhn/DAD-SGM.
\\ ( https://arxiv.org/abs/2510.04241 ,  11363kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04246 (*cross-listing*)
Date: Sun, 5 Oct 2025 15:29:57 GMT   (1661kb)

Title: ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame
  Context
Authors: Huiwon Jang, Sihyun Yu, Heeseung Kwon, Hojin Jeon, Younggyo Seo,
  Jinwoo Shin
Categories: cs.RO cs.AI
Comments: Project page: https://huiwon-jang.github.io/contextvla
\\
  Leveraging temporal context is crucial for success in partially observable
robotic tasks. However, prior work in behavior cloning has demonstrated
inconsistent performance gains when using multi-frame observations. In this
paper, we introduce ContextVLA, a policy model that robustly improves robotic
task performance by effectively leveraging multi-frame observations. Our
approach is motivated by the key observation that Vision-Language-Action models
(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more
effectively utilize multi-frame observations for action generation. This
suggests that VLMs' inherent temporal understanding capability enables them to
extract more meaningful context from multi-frame observations. However, the
high dimensionality of video inputs introduces significant computational
overhead, making VLA training and inference inefficient. To address this,
ContextVLA compresses past observations into a single context token, allowing
the policy to efficiently leverage temporal context for action generation. Our
experiments show that ContextVLA consistently improves over single-frame VLAs
and achieves the benefits of full multi-frame training but with reduced
training and inference times.
\\ ( https://arxiv.org/abs/2510.04246 ,  1661kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04257 (*cross-listing*)
Date: Sun, 5 Oct 2025 15:46:56 GMT   (5101kb)

Title: AgentTypo: Adaptive Typographic Prompt Injection Attacks against
  Black-box Multimodal Agents
Authors: Yanjie Li, Yiming Cao, Dong Wang, Bin Xiao
Categories: cs.CR cs.AI
Comments: 13 pages, 8 figures. Submitted to IEEE Transactions on Information
  Forensics & Security
\\
  Multimodal agents built on large vision-language models (LVLMs) are
increasingly deployed in open-world settings but remain highly vulnerable to
prompt injection, especially through visual inputs. We introduce AgentTypo, a
black-box red-teaming framework that mounts adaptive typographic prompt
injection by embedding optimized text into webpage images. Our automatic
typographic prompt injection (ATPI) algorithm maximizes prompt reconstruction
by substituting captioners while minimizing human detectability via a stealth
loss, with a Tree-structured Parzen Estimator guiding black-box optimization
over text placement, size, and color. To further enhance attack strength, we
develop AgentTypo-pro, a multi-LLM system that iteratively refines injection
prompts using evaluation feedback and retrieves successful past examples for
continual learning. Effective prompts are abstracted into generalizable
strategies and stored in a strategy repository, enabling progressive knowledge
accumulation and reuse in future attacks. Experiments on the VWA-Adv benchmark
across Classifieds, Shopping, and Reddit scenarios show that AgentTypo
significantly outperforms the latest image-based attacks such as AgentAttack.
On GPT-4o agents, our image-only attack raises the success rate from 0.23 to
0.45, with consistent results across GPT-4V, GPT-4o-mini, Gemini 1.5 Pro, and
Claude 3 Opus. In image+text settings, AgentTypo achieves 0.68 ASR, also
outperforming the latest baselines. Our findings reveal that AgentTypo poses a
practical and potent threat to multimodal agents and highlight the urgent need
for effective defense.
\\ ( https://arxiv.org/abs/2510.04257 ,  5101kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04263 (*cross-listing*)
Date: Sun, 5 Oct 2025 16:09:31 GMT   (1657kb)

Title: Efficient Latent Variable Causal Discovery: Combining Score Search and
  Targeted Testing
Authors: Joseph Ramsey and Bryan Andrews
Categories: cs.LG cs.AI
Comments: 30 pages, 23 figures, 6 tables
\\
  Learning causal structure from observational data is especially challenging
when latent variables or selection bias are present. The Fast Causal Inference
(FCI) algorithm addresses this setting but often performs exhaustive
conditional independence tests across many subsets, leading to spurious
independence claims, extra or missing edges, and unreliable orientations. We
present a family of score-guided mixed-strategy causal search algorithms that
build on this tradition. First, we introduce BOSS-FCI and GRaSP-FCI,
straightforward variants of GFCI that substitute BOSS or GRaSP for FGES,
thereby retaining correctness while incurring different scalability tradeoffs.
Second, we develop FCI Targeted-testing (FCIT), a novel mixed-strategy method
that improves upon these variants by replacing exhaustive all-subsets testing
with targeted tests guided by BOSS, yielding well-formed PAGs with higher
precision and efficiency. Finally, we propose a simple heuristic, LV-Dumb (also
known as BOSS-POD), which bypasses latent-variable-specific reasoning and
directly returns the PAG of the BOSS DAG. Although not strictly correct in the
FCI sense, it scales better and often achieves superior accuracy in practice.
Simulations and real-data analyses demonstrate that BOSS-FCI and GRaSP-FCI
provide sound baselines, FCIT improves both efficiency and reliability, and
LV-Dumb offers a practical heuristic with strong empirical performance.
Together, these method highlight the value of score-guided and targeted
strategies for scalable latent-variable causal discovery.
\\ ( https://arxiv.org/abs/2510.04263 ,  1657kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04276 (*cross-listing*)
Date: Sun, 5 Oct 2025 16:34:54 GMT   (3352kb)

Title: Scalable Causal Discovery from Recursive Nonlinear Data via Truncated
  Basis Function Scores and Tests
Authors: Joseph Ramsey and Bryan Andrews
Categories: stat.ML cs.AI
Comments: 30 pages, 11 figures, 5 tables
\\
  Learning graphical conditional independence structures from nonlinear,
continuous or mixed data is a central challenge in machine learning and the
sciences, and many existing methods struggle to scale to thousands of samples
or hundreds of variables. We introduce two basis-expansion tools for scalable
causal discovery. First, the Basis Function BIC (BF-BIC) score uses truncated
additive expansions to approximate nonlinear dependencies. BF-BIC is
theoretically consistent under additive models and extends to post-nonlinear
(PNL) models via an invertible reparameterization. It remains robust under
moderate interactions and supports mixed data through a degenerate-Gaussian
embedding for discrete variables. In simulations with fully nonlinear neural
causal models (NCMs), BF-BIC outperforms kernel- and constraint-based methods
(e.g., KCI, RFCI) in both accuracy and runtime. Second, the Basis Function
Likelihood Ratio Test (BF-LRT) provides an approximate conditional independence
test that is substantially faster than kernel tests while retaining competitive
accuracy. Extensive simulations and a real-data application to Canadian
wildfire risk show that, when integrated into hybrid searches, BF-based methods
enable interpretable and scalable causal discovery. Implementations are
available in Python, R, and Java.
\\ ( https://arxiv.org/abs/2510.04276 ,  3352kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04280 (*cross-listing*)
Date: Sun, 5 Oct 2025 16:45:38 GMT   (20116kb)

Title: A KL-regularization framework for learning to plan with adaptive priors
Authors: \'Alvaro Serra-Gomez and Daniel Jarne Ornia and Dhruva Tirumala and
  Thomas Moerland
Categories: cs.LG cs.AI cs.RO
Comments: Preprint
\\
  Effective exploration remains a central challenge in model-based
reinforcement learning (MBRL), particularly in high-dimensional continuous
control tasks where sample efficiency is crucial. A prominent line of recent
work leverages learned policies as proposal distributions for Model-Predictive
Path Integral (MPPI) planning. Initial approaches update the sampling policy
independently of the planner distribution, typically maximizing a learned value
function with deterministic policy gradient and entropy regularization.
However, because the states encountered during training depend on the MPPI
planner, aligning the sampling policy with the planner improves the accuracy of
value estimation and long-term performance. To this end, recent methods update
the sampling policy by minimizing KL divergence to the planner distribution or
by introducing planner-guided regularization into the policy update. In this
work, we unify these MPPI-based reinforcement learning methods under a single
framework by introducing Policy Optimization-Model Predictive Control (PO-MPC),
a family of KL-regularized MBRL methods that integrate the planner's action
distribution as a prior in policy optimization. By aligning the learned policy
with the planner's behavior, PO-MPC allows more flexibility in the policy
updates to trade off Return maximization and KL divergence minimization. We
clarify how prior approaches emerge as special cases of this family, and we
explore previously unstudied variations. Our experiments show that these
extended configurations yield significant performance improvements, advancing
the state of the art in MPPI-based RL.
\\ ( https://arxiv.org/abs/2510.04280 ,  20116kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04317 (*cross-listing*)
Date: Sun, 5 Oct 2025 18:33:52 GMT   (443kb)

Title: FairAgent: Democratizing Fairness-Aware Machine Learning with
  LLM-Powered Agents
Authors: Yucong Dai, Lu Zhang, Feng Luo, Mashrur Chowdhury, Yongkai Wu
Categories: cs.LG cs.AI
Comments: Accepted by ICDM 2025 Demo Workshop
\\
  Training fair and unbiased machine learning models is crucial for high-stakes
applications, yet it presents significant challenges. Effective bias mitigation
requires deep expertise in fairness definitions, metrics, data preprocessing,
and machine learning techniques. In addition, the complex process of balancing
model performance with fairness requirements while properly handling sensitive
attributes makes fairness-aware model development inaccessible to many
practitioners. To address these challenges, we introduce FairAgent, an
LLM-powered automated system that significantly simplifies fairness-aware model
development. FairAgent eliminates the need for deep technical expertise by
automatically analyzing datasets for potential biases, handling data
preprocessing and feature engineering, and implementing appropriate bias
mitigation strategies based on user requirements. Our experiments demonstrate
that FairAgent achieves significant performance improvements while
significantly reducing development time and expertise requirements, making
fairness-aware machine learning more accessible to practitioners.
\\ ( https://arxiv.org/abs/2510.04317 ,  443kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04339 (*cross-listing*)
Date: Sun, 5 Oct 2025 20:03:30 GMT   (489kb)

Title: Pitch-Conditioned Instrument Sound Synthesis From an Interactive Timbre
  Latent Space
Authors: Christian Limberg and Fares Schulz and Zhe Zhang and Stefan Weinzierl
Categories: cs.SD cs.AI cs.LG eess.AS eess.SP
Comments: 8 pages, accepted to the Proceedings of the 28-th Int. Conf. on
  Digital Audio Effects (DAFx25) - demo: https://pgesam.faresschulz.com
\\
  This paper presents a novel approach to neural instrument sound synthesis
using a two-stage semi-supervised learning framework capable of generating
pitch-accurate, high-quality music samples from an expressive timbre latent
space. Existing approaches that achieve sufficient quality for music production
often rely on high-dimensional latent representations that are difficult to
navigate and provide unintuitive user experiences. We address this limitation
through a two-stage training paradigm: first, we train a pitch-timbre
disentangled 2D representation of audio samples using a Variational
Autoencoder; second, we use this representation as conditioning input for a
Transformer-based generative model. The learned 2D latent space serves as an
intuitive interface for navigating and exploring the sound landscape. We
demonstrate that the proposed method effectively learns a disentangled timbre
space, enabling expressive and controllable audio generation with reliable
pitch conditioning. Experimental results show the model's ability to capture
subtle variations in timbre while maintaining a high degree of pitch accuracy.
The usability of our method is demonstrated in an interactive web application,
highlighting its potential as a step towards future music production
environments that are both intuitive and creatively empowering:
https://pgesam.faresschulz.com
\\ ( https://arxiv.org/abs/2510.04339 ,  489kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04341 (*cross-listing*)
Date: Sun, 5 Oct 2025 20:05:38 GMT   (512kb)

Title: Critical appraisal of artificial intelligence for rare-event
  recognition: principles and pharmacovigilance case studies
Authors: G. Niklas Noren, Eva-Lisa Meldau, Johan Ellenius
Categories: cs.LG cs.AI
Comments: 28 pages, 2 figures
ACM-class: I.2.0
\\
  Many high-stakes AI applications target low-prevalence events, where apparent
accuracy can conceal limited real-world value. Relevant AI models range from
expert-defined rules and traditional machine learning to generative LLMs
constrained for classification. We outline key considerations for critical
appraisal of AI in rare-event recognition, including problem framing and test
set design, prevalence-aware statistical evaluation, robustness assessment, and
integration into human workflows. In addition, we propose an approach to
structured case-level examination (SCLE), to complement statistical performance
evaluation, and a comprehensive checklist to guide procurement or development
of AI models for rare-event recognition. We instantiate the framework in
pharmacovigilance, drawing on three studies: rule-based retrieval of
pregnancy-related reports; duplicate detection combining machine learning with
probabilistic record linkage; and automated redaction of person names using an
LLM. We highlight pitfalls specific to the rare-event setting including
optimism from unrealistic class balance and lack of difficult positive controls
in test sets - and show how cost-sensitive targets align model performance with
operational value. While grounded in pharmacovigilance practice, the principles
generalize to domains where positives are scarce and error costs may be
asymmetric.
\\ ( https://arxiv.org/abs/2510.04341 ,  512kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04349 (*cross-listing*)
Date: Sun, 5 Oct 2025 20:18:34 GMT   (922kb)

Title: Challenge on Optimization of Context Collection for Code Completion
Authors: Dmitry Ustalov, Egor Bogomolov, Alexander Bezzubov, Yaroslav Golubev,
  Evgeniy Glukhov, Georgii Levtsov, Vladimir Kovalenko
Categories: cs.SE cs.AI cs.LG
Comments: 7 pages, 3 figures, 5 tables. A report on the Context Collection
  Workshop co-located with ASE'25
\\
  The rapid advancement of workflows and methods for software engineering using
AI emphasizes the need for a systematic evaluation and analysis of their
ability to leverage information from entire projects, particularly in large
code bases. In this challenge on optimization of context collection for code
completion, organized by JetBrains in collaboration with Mistral AI as part of
the ASE 2025 conference, participants developed efficient mechanisms for
collecting context from source code repositories to improve fill-in-the-middle
code completions for Python and Kotlin. We constructed a large dataset of
real-world code in these two programming languages using permissively licensed
open-source projects. The submissions were evaluated based on their ability to
maximize completion quality for multiple state-of-the-art neural models using
the chrF metric. During the public phase of the competition, nineteen teams
submitted solutions to the Python track and eight teams submitted solutions to
the Kotlin track. In the private phase, six teams competed, of which five
submitted papers to the workshop.
\\ ( https://arxiv.org/abs/2510.04349 ,  922kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04354 (*cross-listing*)
Date: Sun, 5 Oct 2025 20:37:53 GMT   (11407kb)

Title: Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators
Authors: Apurva Badithela, David Snyder, Lihan Zha, Joseph Mikhail, Matthew
  O'Kelly, Anushri Dixit, Anirudha Majumdar
Categories: cs.RO cs.AI cs.SY eess.SY
\\
  Rapid progress in imitation learning, foundation models, and large-scale
datasets has led to robot manipulation policies that generalize to a wide-range
of tasks and environments. However, rigorous evaluation of these policies
remains a challenge. Typically in practice, robot policies are often evaluated
on a small number of hardware trials without any statistical assurances. We
present SureSim, a framework to augment large-scale simulation with relatively
small-scale real-world testing to provide reliable inferences on the real-world
performance of a policy. Our key idea is to formalize the problem of combining
real and simulation evaluations as a prediction-powered inference problem, in
which a small number of paired real and simulation evaluations are used to
rectify bias in large-scale simulation. We then leverage non-asymptotic mean
estimation algorithms to provide confidence intervals on mean policy
performance. Using physics-based simulation, we evaluate both diffusion policy
and multi-task fine-tuned \(\pi_0\) on a joint distribution of objects and
initial conditions, and find that our approach saves over \(20-25\%\) of
hardware evaluation effort to achieve similar bounds on policy performance.
\\ ( https://arxiv.org/abs/2510.04354 ,  11407kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04363 (*cross-listing*)
Date: Sun, 5 Oct 2025 21:15:11 GMT   (91kb)

Title: MacroBench: A Novel Testbed for Web Automation Scripts via Large
  Language Models
Authors: Hyunjun Kim, Sejong Kim
Categories: cs.SE cs.AI cs.CL
Comments: NeurIPS 2025 Workshop on Lock-LLM
\\
  We introduce MacroBench, a code-first benchmark that evaluates whether LLMs
can synthesize reusable browser automation programs from natural language goals
by reading HTML/DOM and emitting Python with Selenium. MacroBench instantiates
seven self-hosted sites: Airbnb-like, TikTok-like, Reddit-like, Instagram-like,
Facebook-like, Discord-like, and Threads-like, covering 681 tasks across
interaction complexity and targeting difficulty. Our end-to-end protocol
validates generated code via static checks, sandboxed execution, and outcome
verification including DOM assertions and database snapshots, and includes a
safety suite for scraping, spam/abuse, and credential/privacy prompts. Across
2636 model-task runs, we observe stratified success: GPT-4o-Mini achieves 96.8
percent, GPT-4.1 achieves 95.3 percent, Gemini-2.5-Pro achieves 89.0 percent,
and DeepSeek-V3.1 achieves 83.4 percent. Models handle simple tasks reliably at
91.7 percent but fail on complex workflows at 0.0 percent, and none meet
production-quality coding practices despite functional completion. We release
our complete benchmark pipeline, evaluation framework, and experimental results
to enable reproducible assessment of macro synthesis for web automation.
\\ ( https://arxiv.org/abs/2510.04363 ,  91kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04374 (*cross-listing*)
Date: Sun, 5 Oct 2025 21:36:43 GMT   (13990kb)

Title: GDPval: Evaluating AI Model Performance on Real-World Economically
  Valuable Tasks
Authors: Tejal Patwardhan, Rachel Dias, Elizabeth Proehl, Grace Kim, Michele
  Wang, Olivia Watkins, Sim\'on Posada Fishman, Marwan Aljubeh, Phoebe Thacker,
  Laurance Fauconnet, Natalie S. Kim, Patrick Chao, Samuel Miserendino, Gildas
  Chabot, David Li, Michael Sharman, Alexandra Barr, Amelia Glaese, Jerry
  Tworek
Categories: cs.LG cs.AI cs.CY
\\
  We introduce GDPval, a benchmark evaluating AI model capabilities on
real-world economically valuable tasks. GDPval covers the majority of U.S.
Bureau of Labor Statistics Work Activities for 44 occupations across the top 9
sectors contributing to U.S. GDP (Gross Domestic Product). Tasks are
constructed from the representative work of industry professionals with an
average of 14 years of experience. We find that frontier model performance on
GDPval is improving roughly linearly over time, and that the current best
frontier models are approaching industry experts in deliverable quality. We
analyze the potential for frontier models, when paired with human oversight, to
perform GDPval tasks cheaper and faster than unaided experts. We also
demonstrate that increased reasoning effort, increased task context, and
increased scaffolding improves model performance on GDPval. Finally, we
open-source a gold subset of 220 tasks and provide a public automated grading
service at evals.openai.com to facilitate future research in understanding
real-world model capabilities.
\\ ( https://arxiv.org/abs/2510.04374 ,  13990kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04375 (*cross-listing*)
Date: Sun, 5 Oct 2025 21:42:33 GMT   (977kb)

Title: Adaptive Weighted Loss for Sequential Recommendations on Sparse Domains
Authors: Akshay Mittal, Vinay Venkatesh, Krishna Kandi, Shalini Sudarshan
Categories: cs.LG cs.AI
\\
  The effectiveness of single-model sequential recommendation architectures,
while scalable, is often limited when catering to "power users" in sparse or
niche domains. Our previous research, PinnerFormerLite, addressed this by using
a fixed weighted loss to prioritize specific domains. However, this approach
can be sub-optimal, as a single, uniform weight may not be sufficient for
domains with very few interactions, where the training signal is easily diluted
by the vast, generic dataset.
  This paper proposes a novel, data-driven approach: a Dynamic Weighted Loss
function with comprehensive theoretical foundations and extensive empirical
validation. We introduce an adaptive algorithm that adjusts the loss weight for
each domain based on its sparsity in the training data, assigning a higher
weight to sparser domains and a lower weight to denser ones. This ensures that
even rare user interests contribute a meaningful gradient signal, preventing
them from being overshadowed.
  We provide rigorous theoretical analysis including convergence proofs,
complexity analysis, and bounds analysis to establish the stability and
efficiency of our approach. Our comprehensive empirical validation across four
diverse datasets (MovieLens, Amazon Electronics, Yelp Business, LastFM Music)
with state-of-the-art baselines (SIGMA, CALRec, SparseEnNet) demonstrates that
this dynamic weighting system significantly outperforms all comparison methods,
particularly for sparse domains, achieving substantial lifts in key metrics
like Recall at 10 and NDCG at 10 while maintaining performance on denser
domains and introducing minimal computational overhead.
\\ ( https://arxiv.org/abs/2510.04375 ,  977kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04380 (*cross-listing*)
Date: Sun, 5 Oct 2025 21:58:44 GMT   (1916kb)

Title: Reconsidering Requirements Engineering: Human-AI Collaboration in
  AI-Native Software Development
Authors: Mateen Ahmed Abbasi, Petri Ihantola, Tommi Mikkonen, Niko M\"akitalo
Categories: cs.SE cs.AI cs.HC
Comments: Accepted at SEAA 2025. Appearing in Springer LNCS 16081, pages
  164-180
ACM-class: D.2.1; D.2.2; D.2.9; I.2.7
Journal-ref: In: SEAA 2025 proceedings, LNCS vol. 16081, Springer
DOI: 10.1007/978-3-032-04190-6_11
\\
  Requirement Engineering (RE) is the foundation of successful software
development. In RE, the goal is to ensure that implemented systems satisfy
stakeholder needs through rigorous requirements elicitation, validation, and
evaluation processes. Despite its critical role, RE continues to face
persistent challenges, such as ambiguity, conflicting stakeholder needs, and
the complexity of managing evolving requirements. A common view is that
Artificial Intelligence (AI) has the potential to streamline the RE process,
resulting in improved efficiency, accuracy, and management actions. However,
using AI also introduces new concerns, such as ethical issues, biases, and lack
of transparency. This paper explores how AI can enhance traditional RE
practices by automating labor-intensive tasks, supporting requirement
prioritization, and facilitating collaboration between stakeholders and AI
systems. The paper also describes the opportunities and challenges that AI
brings to RE. In particular, the vision calls for ethical practices in AI,
along with a much-enhanced collaboration between academia and industry
professionals. The focus should be on creating not only powerful but also
trustworthy and practical AI solutions ready to adapt to the fast-paced world
of software development.
\\ ( https://arxiv.org/abs/2510.04380 ,  1916kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04397 (*cross-listing*)
Date: Sun, 5 Oct 2025 23:33:26 GMT   (777kb)

Title: MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific
  Knowledge for Multilingual Vulnerability Detection
Authors: Van Nguyen and Surya Nepal and Xingliang Yuan and Tingmin Wu and
  Fengchao Chen and Carsten Rudolph
Categories: cs.CR cs.AI cs.SE
\\
  Software vulnerabilities (SVs) pose a critical threat to safety-critical
systems, driving the adoption of AI-based approaches such as machine learning
and deep learning for software vulnerability detection. Despite promising
results, most existing methods are limited to a single programming language.
This is problematic given the multilingual nature of modern software, which is
often complex and written in multiple languages. Current approaches often face
challenges in capturing both shared and language-specific knowledge of source
code, which can limit their performance on diverse programming languages and
real-world codebases. To address this gap, we propose MULVULN, a novel
multilingual vulnerability detection approach that learns from source code
across multiple languages. MULVULN captures both the shared knowledge that
generalizes across languages and the language-specific knowledge that reflects
unique coding conventions. By integrating these aspects, it achieves more
robust and effective detection of vulnerabilities in real-world multilingual
software systems. The rigorous and extensive experiments on the real-world and
diverse REEF dataset, consisting of 4,466 CVEs with 30,987 patches across seven
programming languages, demonstrate the superiority of MULVULN over thirteen
effective and state-of-the-art baselines. Notably, MULVULN achieves
substantially higher F1-score, with improvements ranging from 1.45% to 23.59%
compared to the baseline methods.
\\ ( https://arxiv.org/abs/2510.04397 ,  777kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04417 (*cross-listing*)
Date: Mon, 6 Oct 2025 01:08:34 GMT   (1570kb)

Title: Partial Information Decomposition via Normalizing Flows in Latent
  Gaussian Distributions
Authors: Wenyuan Zhao, Adithya Balachandran, Chao Tian, and Paul Pu Liang
Categories: cs.LG cs.AI cs.CL cs.CV cs.IT math.IT
Comments: NeurIPS 2025
\\
  The study of multimodality has garnered significant interest in fields where
the analysis of interactions among multiple information sources can enhance
predictive modeling, data fusion, and interpretability. Partial information
decomposition (PID) has emerged as a useful information-theoretic framework to
quantify the degree to which individual modalities independently, redundantly,
or synergistically convey information about a target variable. However,
existing PID methods depend on optimizing over a joint distribution constrained
by estimated pairwise probability distributions, which are costly and
inaccurate for continuous and high-dimensional modalities. Our first key
insight is that the problem can be solved efficiently when the pairwise
distributions are multivariate Gaussians, and we refer to this problem as
Gaussian PID (GPID). We propose a new gradient-based algorithm that
substantially improves the computational efficiency of GPID based on an
alternative formulation of the underlying optimization problem. To generalize
the applicability to non-Gaussian data, we learn information-preserving
encoders to transform random variables of arbitrary input distributions into
pairwise Gaussian random variables. Along the way, we resolved an open problem
regarding the optimality of joint Gaussian solutions for GPID. Empirical
validation in diverse synthetic examples demonstrates that our proposed method
provides more accurate and efficient PID estimates than existing baselines. We
further evaluate a series of large-scale multimodal benchmarks to show its
utility in real-world applications of quantifying PID in multimodal datasets
and selecting high-performing models.
\\ ( https://arxiv.org/abs/2510.04417 ,  1570kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04455 (*cross-listing*)
Date: Mon, 6 Oct 2025 03:02:43 GMT   (35kb)

Title: Inverse Mixed-Integer Programming: Learning Constraints then Objective
  Functions
Authors: Akira Kitaoka
Categories: math.OC cs.AI cs.LG math.ST stat.ML stat.TH
Comments: 33 pages
\\
  In mixed-integer linear programming, data-driven inverse optimization that
learns the objective function and the constraints from observed data plays an
important role in constructing appropriate mathematical models for various
fields, including power systems and scheduling. However, to the best of our
knowledge, there is no known method for learning both the objective functions
and the constraints. In this paper, we propose a two-stage method for a class
of problems where the objective function is expressed as a linear combination
of functions and the constraints are represented by functions and thresholds.
Specifically, our method first learns the constraints and then learns the
objective function. On the theoretical side, we show the proposed method can
solve inverse optimization problems in finite dataset, develop statistical
learning theory in pseudometric spaces and sub-Gaussian distributions, and
construct a statistical learning for inverse optimization. On the experimental
side, we demonstrate that our method is practically applicable for scheduling
problems formulated as integer linear programmings with up to 100 decision
variables, which are typical in real-world settings.
\\ ( https://arxiv.org/abs/2510.04455 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04465 (*cross-listing*)
Date: Mon, 6 Oct 2025 03:38:54 GMT   (3226kb)

Title: Autonomy Matters: A Study on Personalization-Privacy Dilemma in LLM
  Agents
Authors: Zhiping Zhang, Yi Evie Zhang, Freda Shi, Tianshi Li
Categories: cs.HC cs.AI cs.CR
\\
  Large Language Model (LLM) agents require personal information for
personalization in order to better act on users' behalf in daily tasks, but
this raises privacy concerns and a personalization-privacy dilemma. Agent's
autonomy introduces both risks and opportunities, yet its effects remain
unclear. To better understand this, we conducted a 3$\times$3 between-subjects
experiment ($N=450$) to study how agent's autonomy level and personalization
influence users' privacy concerns, trust and willingness to use, as well as the
underlying psychological processes. We find that personalization without
considering users' privacy preferences increases privacy concerns and decreases
trust and willingness to use. Autonomy moderates these effects: Intermediate
autonomy flattens the impact of personalization compared to No- and Full
autonomy conditions. Our results suggest that rather than aiming for perfect
model alignment in output generation, balancing autonomy of agent's action and
user control offers a promising path to mitigate the personalization-privacy
dilemma.
\\ ( https://arxiv.org/abs/2510.04465 ,  3226kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04503 (*cross-listing*)
Date: Mon, 6 Oct 2025 05:45:23 GMT   (1066kb)

Title: P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs
Authors: Shuai Zhao, Xinyi Wu, Shiqian Zhao, Xiaobao Wu, Zhongliang Guo, Yanhao
  Jia, Anh Tuan Luu
Categories: cs.CR cs.AI cs.CL
\\
  During fine-tuning, large language models (LLMs) are increasingly vulnerable
to data-poisoning backdoor attacks, which compromise their reliability and
trustworthiness. However, existing defense strategies suffer from limited
generalization: they only work on specific attack types or task settings. In
this study, we propose Poison-to-Poison (P2P), a general and effective backdoor
defense algorithm. P2P injects benign triggers with safe alternative labels
into a subset of training samples and fine-tunes the model on this re-poisoned
dataset by leveraging prompt-based learning. This enforces the model to
associate trigger-induced representations with safe outputs, thereby overriding
the effects of original malicious triggers. Thanks to this robust and
generalizable trigger-based fine-tuning, P2P is effective across task settings
and attack types. Theoretically and empirically, we show that P2P can
neutralize malicious backdoors while preserving task performance. We conduct
extensive experiments on classification, mathematical reasoning, and summary
generation tasks, involving multiple state-of-the-art LLMs. The results
demonstrate that our P2P algorithm significantly reduces the attack success
rate compared with baseline models. We hope that the P2P can serve as a
guideline for defending against backdoor attacks and foster the development of
a secure and trustworthy LLM community.
\\ ( https://arxiv.org/abs/2510.04503 ,  1066kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04522 (*cross-listing*)
Date: Mon, 6 Oct 2025 06:29:49 GMT   (5110kb)

Title: Toward a Unified Geometry Understanding: Riemannian Diffusion Framework
  for Graph Generation and Prediction
Authors: Yisen Gao, Xingcheng Fu, Qingyun Sun, Jianxin Li, Xianxian Li
Categories: cs.LG cs.AI
Comments: Accepted by NeuIPS 2025
\\
  Graph diffusion models have made significant progress in learning structured
graph data and have demonstrated strong potential for predictive tasks.
Existing approaches typically embed node, edge, and graph-level features into a
unified latent space, modeling prediction tasks including classification and
regression as a form of conditional generation. However, due to the
non-Euclidean nature of graph data, features of different curvatures are
entangled in the same latent space without releasing their geometric potential.
To address this issue, we aim to construt an ideal Riemannian diffusion model
to capture distinct manifold signatures of complex graph data and learn their
distribution. This goal faces two challenges: numerical instability caused by
exponential mapping during the encoding proces and manifold deviation during
diffusion generation. To address these challenges, we propose GeoMancer: a
novel Riemannian graph diffusion framework for both generation and prediction
tasks. To mitigate numerical instability, we replace exponential mapping with
an isometric-invariant Riemannian gyrokernel approach and decouple multi-level
features onto their respective task-specific manifolds to learn optimal
representations. To address manifold deviation, we introduce a
manifold-constrained diffusion method and a self-guided strategy for
unconditional generation, ensuring that the generated data remains aligned with
the manifold signature. Extensive experiments validate the effectiveness of our
approach, demonstrating superior performance across a variety of tasks.
\\ ( https://arxiv.org/abs/2510.04522 ,  5110kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04528 (*cross-listing*)
Date: Mon, 6 Oct 2025 06:44:27 GMT   (18kb)

Title: Unified Threat Detection and Mitigation Framework (UTDMF): Combating
  Prompt Injection, Deception, and Bias in Enterprise-Scale Transformers
Authors: Santhosh KumarRavindran
Categories: cs.CR cs.AI
\\
  The rapid adoption of large language models (LLMs) in enterprise systems
exposes vulnerabilities to prompt injection attacks, strategic deception, and
biased outputs, threatening security, trust, and fairness. Extending our
adversarial activation patching framework (arXiv:2507.09406), which induced
deception in toy networks at a 23.9% rate, we introduce the Unified Threat
Detection and Mitigation Framework (UTDMF), a scalable, real-time pipeline for
enterprise-grade models like Llama-3.1 (405B), GPT-4o, and Claude-3.5. Through
700+ experiments per model, UTDMF achieves: (1) 92% detection accuracy for
prompt injection (e.g., jailbreaking); (2) 65% reduction in deceptive outputs
via enhanced patching; and (3) 78% improvement in fairness metrics (e.g.,
demographic bias). Novel contributions include a generalized patching algorithm
for multi-threat detection, three groundbreaking hypotheses on threat
interactions (e.g., threat chaining in enterprise workflows), and a
deployment-ready toolkit with APIs for enterprise integration.
\\ ( https://arxiv.org/abs/2510.04528 ,  18kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04536 (*cross-listing*)
Date: Mon, 6 Oct 2025 07:00:06 GMT   (3354kb)

Title: 3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs
  Using MCP and RAG
Authors: Shun-ichiro Hayashi and Daichi Mukunoki and Tetsuya Hoshino and
  Satoshi Ohshima and Takahiro Katagiri
Categories: cs.GR cs.AI cs.CV
\\
  This paper proposes "3Dify," a procedural 3D computer graphics (3D-CG)
generation framework utilizing Large Language Models (LLMs). The framework
enables users to generate 3D-CG content solely through natural language
instructions. 3Dify is built upon Dify, an open-source platform for AI
application development, and incorporates several state-of-the-art LLM-related
technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented
Generation (RAG). For 3D-CG generation support, 3Dify automates the operation
of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not
support MCP-based interaction, the framework employs the Computer-Using Agent
(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,
to enhance image generation quality, 3Dify allows users to provide feedback by
selecting preferred images from multiple candidates. The LLM then learns
variable patterns from these selections and applies them to subsequent
generations. Furthermore, 3Dify supports the integration of locally deployed
LLMs, enabling users to utilize custom-developed models and to reduce both time
and monetary costs associated with external API calls by leveraging their own
computational resources.
\\ ( https://arxiv.org/abs/2510.04536 ,  3354kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04567 (*cross-listing*)
Date: Mon, 6 Oct 2025 08:09:15 GMT   (921kb)

Title: GILT: An LLM-Free, Tuning-Free Graph Foundational Model for In-Context
  Learning
Authors: Weishuo Ma, Yanbo Wang, Xiyuan Wang, Lei Zou, Muhan Zhang
Categories: cs.LG cs.AI
\\
  Graph Neural Networks (GNNs) are powerful tools for precessing relational
data but often struggle to generalize to unseen graphs, giving rise to the
development of Graph Foundational Models (GFMs). However, current GFMs are
challenged by the extreme heterogeneity of graph data, where each graph can
possess a unique feature space, label set, and topology. To address this, two
main paradigms have emerged. The first leverages Large Language Models (LLMs),
but is fundamentally text-dependent, thus struggles to handle the numerical
features in vast graphs. The second pre-trains a structure-based model, but the
adaptation to new tasks typically requires a costly, per-graph tuning stage,
creating a critical efficiency bottleneck. In this work, we move beyond these
limitations and introduce \textbf{G}raph \textbf{I}n-context \textbf{L}earning
\textbf{T}ransformer (GILT), a framework built on an LLM-free and tuning-free
architecture. GILT introduces a novel token-based framework for in-context
learning (ICL) on graphs, reframing classification tasks spanning node, edge
and graph levels in a unified framework. This mechanism is the key to handling
heterogeneity, as it is designed to operate on generic numerical features.
Further, its ability to understand class semantics dynamically from the context
enables tuning-free adaptation. Comprehensive experiments show that GILT
achieves stronger few-shot performance with significantly less time than
LLM-based or tuning-based baselines, validating the effectiveness of our
approach.
\\ ( https://arxiv.org/abs/2510.04567 ,  921kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04573 (*cross-listing*)
Date: Mon, 6 Oct 2025 08:15:03 GMT   (1046kb)

Title: LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning
Authors: Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Nicklas Majamaki,
  Navdeep Jaitly, Yi-An Ma, Lianhui Qin
Categories: cs.LG cs.AI cs.CL
\\
  Large Language Models (LLMs) demonstrate their reasoning ability through
chain-of-thought (CoT) generation. However, LLM's autoregressive decoding may
limit the ability to revisit and refine earlier tokens in a holistic manner,
which can also lead to inefficient exploration for diverse solutions. In this
paper, we propose LaDiR (Latent Diffusion Reasoner), a novel reasoning
framework that unifies the expressiveness of continuous latent representation
with the iterative refinement capabilities of latent diffusion models for an
existing LLM. We first construct a structured latent reasoning space using a
Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of
thought tokens, preserving semantic information and interpretability while
offering compact but expressive representations. Subsequently, we utilize a
latent diffusion model that learns to denoise a block of latent thought tokens
with a blockwise bidirectional attention mask, enabling longer horizon and
iterative refinement with adaptive test-time compute. This design allows
efficient parallel generation of diverse reasoning trajectories, allowing the
model to plan and revise the reasoning process holistically. We conduct
evaluations on a suite of mathematical reasoning and planning benchmarks.
Empirical results show that LaDiR consistently improves accuracy, diversity,
and interpretability over existing autoregressive, diffusion-based, and latent
reasoning methods, revealing a new paradigm for text reasoning with latent
diffusion.
\\ ( https://arxiv.org/abs/2510.04573 ,  1046kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04574 (*cross-listing*)
Date: Mon, 6 Oct 2025 08:18:47 GMT   (14922kb)

Title: Deep learning framework for predicting stochastic take-off and die-out
  of early spreading
Authors: Wenchao He, Tao Jia
Categories: cs.SI cs.AI physics.soc-ph
Comments: 29 pages, 11 figures
MSC-class: 05C82, 68T05, 92C42
ACM-class: G.2.2; I.2.6
\\
  Large-scale outbreaks of epidemics, misinformation, or other harmful
contagions pose significant threats to human society, yet the fundamental
question of whether an emerging outbreak will escalate into a major epidemic or
naturally die out remains largely unaddressed. This problem is challenging,
partially due to inadequate data during the early stages of outbreaks and also
because established models focus on average behaviors of large epidemics rather
than the stochastic nature of small transmission chains. Here, we introduce the
first systematic framework for forecasting whether initial transmission events
will amplify into major outbreaks or fade into extinction during early stages,
when intervention strategies can still be effectively implemented. Using
extensive data from stochastic spreading models, we developed a deep learning
framework that predicts early-stage spreading outcomes in real-time. Validation
across Erd\H{o}s-R\'enyi and Barab\'asi-Albert networks with varying
infectivity levels shows our method accurately forecasts stochastic spreading
events well before potential outbreaks, demonstrating robust performance across
different network structures and infectivity scenarios.To address the challenge
of sparse data during early outbreak stages, we further propose a
pretrain-finetune framework that leverages diverse simulation data for
pretraining and adapts to specific scenarios through targeted fine-tuning. The
pretrain-finetune framework consistently outperforms baseline models, achieving
superior performance even when trained on limited scenario-specific data. To
our knowledge, this work presents the first framework for predicting stochastic
take-off versus die-out. This framework provides valuable insights for epidemic
preparedness and public health decision-making, enabling more informed early
intervention strategies.
\\ ( https://arxiv.org/abs/2510.04574 ,  14922kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04576 (*cross-listing*)
Date: Mon, 6 Oct 2025 08:26:06 GMT   (9057kb)

Title: SONA: Learning Conditional, Unconditional, and Mismatching-Aware
  Discriminator
Authors: Yuhta Takida, Satoshi Hayakawa, Takashi Shibuya, Masaaki Imaizumi,
  Naoki Murata, Bac Nguyen, Toshimitsu Uesaka, Chieh-Hsin Lai, Yuki Mitsufuji
Categories: cs.LG cs.AI cs.CV stat.ML
Comments: 24 pages with 9 figures
\\
  Deep generative models have made significant advances in generating complex
content, yet conditional generation remains a fundamental challenge. Existing
conditional generative adversarial networks often struggle to balance the dual
objectives of assessing authenticity and conditional alignment of input samples
within their conditional discriminators. To address this, we propose a novel
discriminator design that integrates three key capabilities: unconditional
discrimination, matching-aware supervision to enhance alignment sensitivity,
and adaptive weighting to dynamically balance all objectives. Specifically, we
introduce Sum of Naturalness and Alignment (SONA), which employs separate
projections for naturalness (authenticity) and alignment in the final layer
with an inductive bias, supported by dedicated objective functions and an
adaptive weighting mechanism. Extensive experiments on class-conditional
generation tasks show that \ours achieves superior sample quality and
conditional alignment compared to state-of-the-art methods. Furthermore, we
demonstrate its effectiveness in text-to-image generation, confirming the
versatility and robustness of our approach.
\\ ( https://arxiv.org/abs/2510.04576 ,  9057kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04602 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:07:12 GMT   (4336kb)

Title: Computing Wasserstein Barycenters through Gradient Flows
Authors: Eduardo Fernandes Montesuma, Yassir Bendou, Mike Gartrell
Categories: stat.ML cs.AI cs.LG
Comments: 4 Figures, 3 Tables, under review
\\
  Wasserstein barycenters provide a powerful tool for aggregating probability
measures, while leveraging the geometry of their ambient space. Existing
discrete methods suffer from poor scalability, as they require access to the
complete set of samples from input measures. We address this issue by recasting
the original barycenter problem as a gradient flow in the Wasserstein space.
Our approach offers two advantages. First, we achieve scalability by sampling
mini-batches from the input measures. Second, we incorporate functionals over
probability measures, which regularize the barycenter problem through internal,
potential, and interaction energies. We present two algorithms for empirical
and Gaussian mixture measures, providing convergence guarantees under the
Polyak-{\L}ojasiewicz inequality. Experimental validation on toy datasets and
domain adaptation benchmarks show that our methods outperform previous discrete
and neural net-based methods for computing Wasserstein barycenters.
\\ ( https://arxiv.org/abs/2510.04602 ,  4336kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04607 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:14:58 GMT   (496kb)

Title: A Case for Declarative LLM-friendly Interfaces for Improved Efficiency
  of Computer-Use Agents
Authors: Yuan Wang, Mingyu Li and Haibo Chen
Categories: cs.OS cs.AI cs.LG
\\
  Computer-use agents (CUAs) powered by large language models (LLMs) have
emerged as a promising approach to automating computer tasks, yet they struggle
with graphical user interfaces (GUIs). GUIs, designed for humans, force LLMs to
decompose high-level goals into lengthy, error-prone sequences of fine-grained
actions, resulting in low success rates and an excessive number of LLM calls.
  We propose Goal-Oriented Interface (GOI), a novel abstraction that transforms
existing GUIs into three declarative primitives: access, state, and
observation, which are better suited for LLMs. Our key idea is policy-mechanism
separation: LLMs focus on high-level semantic planning (policy) while GOI
handles low-level navigation and interaction (mechanism). GOI does not require
modifying the application source code or relying on application programming
interfaces (APIs).
  We evaluate GOI with Microsoft Office Suite (Word, PowerPoint, Excel) on
Windows. Compared to a leading GUI-based agent baseline, GOI improves task
success rates by 67% and reduces interaction steps by 43.5%. Notably, GOI
completes over 61% of successful tasks with a single LLM call.
\\ ( https://arxiv.org/abs/2510.04607 ,  496kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04609 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:20:27 GMT   (5693kb)

Title: Accountability Capture: How Record-Keeping to Support AI Transparency
  and Accountability (Re)shapes Algorithmic Oversight
Authors: Shreya Chappidi, Jennifer Cobbe, Chris Norval, Anjali Mazumder,
  Jatinder Singh
Categories: cs.CY cs.AI
Comments: To appear at 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES
  2025)
\\
  Accountability regimes typically encourage record-keeping to enable the
transparency that supports oversight, investigation, contestation, and redress.
However, implementing such record-keeping can introduce considerations, risks,
and consequences, which so far remain under-explored. This paper examines how
record-keeping practices bring algorithmic systems within accountability
regimes, providing a basis to observe and understand their effects. For this,
we introduce, describe, and elaborate 'accountability capture' -- the
re-configuration of socio-technical processes and the associated downstream
effects relating to record-keeping for algorithmic accountability. Surveying
100 practitioners, we evidence and characterise record-keeping issues in
practice, identifying their alignment with accountability capture. We further
document widespread record-keeping practices, tensions between internal and
external accountability requirements, and evidence of employee resistance to
practices imposed through accountability capture. We discuss these and other
effects for surveillance, privacy, and data protection, highlighting
considerations for algorithmic accountability communities. In all, we show that
implementing record-keeping to support transparency in algorithmic
accountability regimes can itself bring wider implications -- an issue
requiring greater attention from practitioners, researchers, and policymakers
alike.
\\ ( https://arxiv.org/abs/2510.04609 ,  5693kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04615 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:28:31 GMT   (3263kb)

Title: Design Process of a Self Adaptive Smart Serious Games Ecosystem
Authors: X. Tao, P. Chen, M. Tsami, F. Khayati, M. Eckert
Categories: eess.SY cs.AI cs.SY
ACM-class: I.2.1
\\
  This paper outlines the design vision and planned evolution of Blexer v3, a
modular and AI-driven rehabilitation ecosystem based on serious games. Building
on insights from previous versions of the system, we propose a new architecture
that aims to integrate multimodal sensing, real-time reasoning, and intelligent
control. The envisioned system will include distinct modules for data
collection, user state inference, and gameplay adaptation. Key features such as
dynamic difficulty adjustment (DDA) and procedural content generation (PCG) are
also considered to support personalized interventions. We present the complete
conceptual framework of Blexer v3, which defines the modular structure and data
flow of the system. This serves as the foundation for the next phase: the
development of a functional prototype and its integration into clinical
rehabilitation scenarios.
\\ ( https://arxiv.org/abs/2510.04615 ,  3263kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04618 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:30:18 GMT   (2400kb)

Title: Agentic Context Engineering: Evolving Contexts for Self-Improving
  Language Models
Authors: Qizheng Zhang, Changran Hu, Shubhangi Upasani, Boyuan Ma, Fenglu Hong,
  Vamsidhar Kamanuru, Jay Rainton, Chen Wu, Mengmeng Ji, Hanchen Li, Urmish
  Thakker, James Zou, Kunle Olukotun
Categories: cs.LG cs.AI cs.CL
\\
  Large language model (LLM) applications such as agents and domain-specific
reasoning increasingly rely on context adaptation -- modifying inputs with
instructions, strategies, or evidence, rather than weight updates. Prior
approaches improve usability but often suffer from brevity bias, which drops
domain insights for concise summaries, and from context collapse, where
iterative rewriting erodes details over time. Building on the adaptive memory
introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context
Engineering), a framework that treats contexts as evolving playbooks that
accumulate, refine, and organize strategies through a modular process of
generation, reflection, and curation. ACE prevents collapse with structured,
incremental updates that preserve detailed knowledge and scale with
long-context models. Across agent and domain-specific benchmarks, ACE optimizes
contexts both offline (e.g., system prompts) and online (e.g., agent memory),
consistently outperforming strong baselines: +10.6% on agents and +8.6% on
finance, while significantly reducing adaptation latency and rollout cost.
Notably, ACE could adapt effectively without labeled supervision and instead by
leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches
the top-ranked production-level agent on the overall average and surpasses it
on the harder test-challenge split, despite using a smaller open-source model.
These results show that comprehensive, evolving contexts enable scalable,
efficient, and self-improving LLM systems with low overhead.
\\ ( https://arxiv.org/abs/2510.04618 ,  2400kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04624 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:32:40 GMT   (48kb)

Title: Fairness in Repeated Matching: A Maximin Perspective
Authors: Eugene Lim, Tzeh Yuan Neoh, Nicholas Teh
Categories: cs.GT cs.AI cs.LG cs.MA econ.TH
\\
  We study a sequential decision-making model where a set of items is
repeatedly matched to the same set of agents over multiple rounds. The
objective is to determine a sequence of matchings that either maximizes the
utility of the least advantaged agent at the end of all rounds (optimal) or at
the end of every individual round (anytime optimal). We investigate the
computational challenges associated with finding (anytime) optimal outcomes and
demonstrate that these problems are generally computationally intractable.
However, we provide approximation algorithms, fixed-parameter tractable
algorithms, and identify several special cases whereby the problem(s) can be
solved efficiently. Along the way, we also establish characterizations of
Pareto-optimal/maximum matchings, which may be of independent interest to works
in matching theory and house allocation.
\\ ( https://arxiv.org/abs/2510.04624 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04646 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:49:14 GMT   (68kb)

Title: Predictive Feature Caching for Training-free Acceleration of Molecular
  Geometry Generation
Authors: Johanna Sommer and John Rachwan and Nils Fleischmann and Stephan
  G\"unnemann and Bertrand Charpentier
Categories: cs.LG cs.AI
Comments: Accepted at the AI for Science Workshop @ NeurIPS 2025
\\
  Flow matching models generate high-fidelity molecular geometries but incur
significant computational costs during inference, requiring hundreds of network
evaluations. This inference overhead becomes the primary bottleneck when such
models are employed in practice to sample large numbers of molecular
candidates. This work discusses a training-free caching strategy that
accelerates molecular geometry generation by predicting intermediate hidden
states across solver steps. The proposed method operates directly on the
SE(3)-equivariant backbone, is compatible with pretrained models, and is
orthogonal to existing training-based accelerations and system-level
optimizations. Experiments on the GEOM-Drugs dataset demonstrate that caching
achieves a twofold reduction in wall-clock inference time at matched sample
quality and a speedup of up to 3x compared to the base model with minimal
sample quality degradation. Because these gains compound with other
optimizations, applying caching alongside other general, lossless optimizations
yield as much as a 7x speedup.
\\ ( https://arxiv.org/abs/2510.04646 ,  68kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04667 (*cross-listing*)
Date: Mon, 6 Oct 2025 10:22:20 GMT   (1260kb)

Title: Noise or Signal? Deconstructing Contradictions and An Adaptive Remedy
  for Reversible Normalization in Time Series Forecasting
Authors: Fanzhe Fu, Yang Yang
Categories: cs.LG cs.AI
Comments: 9pages, 6 figures
ACM-class: I.2.6; H.2.8
\\
  Reversible Instance Normalization (RevIN) is a key technique enabling simple
linear models to achieve state-of-the-art performance in time series
forecasting. While replacing its non-robust statistics with robust counterparts
(termed R$^2$-IN) seems like a straightforward improvement, our findings reveal
a far more complex reality. This paper deconstructs the perplexing performance
of various normalization strategies by identifying four underlying theoretical
contradictions. Our experiments provide two crucial findings: first, the
standard RevIN catastrophically fails on datasets with extreme outliers, where
its MSE surges by a staggering 683\%. Second, while the simple R$^2$-IN
prevents this failure and unexpectedly emerges as the best overall performer,
our adaptive model (A-IN), designed to test a diagnostics-driven heuristic,
unexpectedly suffers a complete and systemic failure. This surprising outcome
uncovers a critical, overlooked pitfall in time series analysis: the
instability introduced by a simple or counter-intuitive heuristic can be more
damaging than the statistical issues it aims to solve. The core contribution of
this work is thus a new, cautionary paradigm for time series normalization: a
shift from a blind search for complexity to a diagnostics-driven analysis that
reveals not only the surprising power of simple baselines but also the perilous
nature of naive adaptation.
\\ ( https://arxiv.org/abs/2510.04667 ,  1260kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04674 (*cross-listing*)
Date: Mon, 6 Oct 2025 10:29:07 GMT   (18977kb)

Title: Semantic Channel Equalization Strategies for Deep Joint Source-Channel
  Coding
Authors: Lorenzo Pannacci, Simone Fiorellino, Mario Edoardo Pandolfo, Emilio
  Calvanese Strinati and Paolo Di Lorenzo
Categories: cs.LG cs.AI cs.IT cs.NI math.IT
Comments: Proceedings of IEEE Globecom 2025 Workshops
\\
  Deep joint source-channel coding (DeepJSCC) has emerged as a powerful
paradigm for end-to-end semantic communications, jointly learning to compress
and protect task-relevant features over noisy channels. However, existing
DeepJSCC schemes assume a shared latent space at transmitter (TX) and receiver
(RX) - an assumption that fails in multi-vendor deployments where encoders and
decoders cannot be co-trained. This mismatch introduces "semantic noise",
degrading reconstruction quality and downstream task performance. In this
paper, we systematize and evaluate methods for semantic channel equalization
for DeepJSCC, introducing an additional processing stage that aligns
heterogeneous latent spaces under both physical and semantic impairments. We
investigate three classes of aligners: (i) linear maps, which admit closed-form
solutions; (ii) lightweight neural networks, offering greater expressiveness;
and (iii) a Parseval-frame equalizer, which operates in zero-shot mode without
the need for training. Through extensive experiments on image reconstruction
over AWGN and fading channels, we quantify trade-offs among complexity, data
efficiency, and fidelity, providing guidelines for deploying DeepJSCC in
heterogeneous AI-native wireless networks.
\\ ( https://arxiv.org/abs/2510.04674 ,  18977kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04686 (*cross-listing*)
Date: Mon, 6 Oct 2025 10:56:41 GMT   (1586kb)

Title: How does the optimizer implicitly bias the model merging loss landscape?
Authors: Chenxiang Zhang, Alexander Theus, Damien Teney, Antonio Orvieto, Jun
  Pang, Sjouke Mauw
Categories: cs.LG cs.AI
Comments: preprint
\\
  Model merging methods combine models with different capabilities into a
single one while maintaining the same inference cost. Two popular approaches
are linear interpolation, which linearly interpolates between model weights,
and task arithmetic, which combines task vectors obtained by the difference
between finetuned and base models. While useful in practice, what properties
make merging effective are poorly understood. This paper explores how the
optimization process affects the loss landscape geometry and its impact on
merging success. We show that a single quantity -- the effective noise scale --
unifies the impact of optimizer and data choices on model merging. Across
architectures and datasets, the effectiveness of merging success is a
non-monotonic function of effective noise, with a distinct optimum. Decomposing
this quantity, we find that larger learning rates, stronger weight decay,
smaller batch sizes, and data augmentation all independently modulate the
effective noise scale, exhibiting the same qualitative trend. Unlike prior work
that connects optimizer noise to the flatness or generalization of individual
minima, we show that it also affects the global loss landscape, predicting when
independently trained solutions can be merged. Our findings broaden the
understanding of how optimization shapes the loss landscape geometry and its
downstream consequences for model merging, suggesting the possibility of
further manipulating the training dynamics to improve merging effectiveness.
\\ ( https://arxiv.org/abs/2510.04686 ,  1586kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04692 (*cross-listing*)
Date: Mon, 6 Oct 2025 11:05:46 GMT   (47138kb)

Title: Bio-Inspired Robotic Houbara: From Development to Field Deployment for
  Behavioral Studies
Authors: Lyes Saad Saoud and Irfan Hussain
Categories: cs.RO cs.AI
\\
  Biomimetic intelligence and robotics are transforming field ecology by
enabling lifelike robotic surrogates that interact naturally with animals under
real world conditions. Studying avian behavior in the wild remains challenging
due to the need for highly realistic morphology, durable outdoor operation, and
intelligent perception that can adapt to uncontrolled environments. We present
a next generation bio inspired robotic platform that replicates the morphology
and visual appearance of the female Houbara bustard to support controlled
ethological studies and conservation oriented field research. The system
introduces a fully digitally replicable fabrication workflow that combines high
resolution structured light 3D scanning, parametric CAD modelling, articulated
3D printing, and photorealistic UV textured vinyl finishing to achieve
anatomically accurate and durable robotic surrogates. A six wheeled rocker
bogie chassis ensures stable mobility on sand and irregular terrain, while an
embedded NVIDIA Jetson module enables real time RGB and thermal perception,
lightweight YOLO based detection, and an autonomous visual servoing loop that
aligns the robot's head toward detected targets without human intervention. A
lightweight thermal visible fusion module enhances perception in low light
conditions. Field trials in desert aviaries demonstrated reliable real time
operation at 15 to 22 FPS with latency under 100 ms and confirmed that the
platform elicits natural recognition and interactive responses from live
Houbara bustards under harsh outdoor conditions. This integrated framework
advances biomimetic field robotics by uniting reproducible digital fabrication,
embodied visual intelligence, and ecological validation, providing a
transferable blueprint for animal robot interaction research, conservation
robotics, and public engagement.
\\ ( https://arxiv.org/abs/2510.04692 ,  47138kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04698 (*cross-listing*)
Date: Mon, 6 Oct 2025 11:10:55 GMT   (2390kb)

Title: The Bayesian Origin of the Probability Weighting Function in Human
  Representation of Probabilities
Authors: Xin Tong, Thi Thu Uyen Hoang, Xue-Xin Wei, Michael Hahn
Categories: q-bio.NC cs.AI econ.TH
\\
  Understanding the representation of probability in the human mind has been of
great interest to understanding human decision making. Classical paradoxes in
decision making suggest that human perception distorts probability magnitudes.
Previous accounts postulate a Probability Weighting Function that transforms
perceived probabilities; however, its motivation has been debated. Recent work
has sought to motivate this function in terms of noisy representations of
probabilities in the human mind. Here, we present an account of the Probability
Weighting Function grounded in rational inference over optimal decoding from
noisy neural encoding of quantities. We show that our model accurately accounts
for behavior in a lottery task and a dot counting task. It further accounts for
adaptation to a bimodal short-term prior. Taken together, our results provide a
unifying account grounding the human representation of probability in rational
inference.
\\ ( https://arxiv.org/abs/2510.04698 ,  2390kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04704 (*cross-listing*)
Date: Mon, 6 Oct 2025 11:17:56 GMT   (6804kb)

Title: AtomWorld: A Benchmark for Evaluating Spatial Reasoning in Large
  Language Models on Crystalline Materials
Authors: Taoyuze Lv, Alexander Chen, Fengyu Xie, Chu Wu, Jeffrey Meng, Dongzhan
  Zhou, Bram Hoex, Zhicheng Zhong, Tong Xie
Categories: cond-mat.mtrl-sci cs.AI cs.CL
\\
  Large Language Models (LLMs) excel at textual reasoning and are beginning to
develop spatial understanding, prompting the question of whether these
abilities can be combined for complex, domain-specific tasks. This question is
essential in fields like materials science, where deep understanding of 3D
atomic structures is fundamental. While initial studies have successfully
applied LLMs to tasks involving pure crystal generation or coordinate
understandings, a standardized benchmark to systematically evaluate their core
reasoning abilities across diverse atomic structures has been notably absent.
To address this gap, we introduce the AtomWorld benchmark to evaluate LLMs on
tasks based in Crystallographic Information Files (CIFs), a standard structure
representation format. These tasks, including structural editing, CIF
perception, and property-guided modeling, reveal a critical limitation: current
models, despite establishing promising baselines, consistently fail in
structural understanding and spatial reasoning. Our experiments show that these
models make frequent errors on structure modification tasks, and even in the
basic CIF format understandings, potentially leading to cumulative errors in
subsequent analysis and materials insights. By defining these standardized
tasks, AtomWorld lays the ground for advancing LLMs toward robust atomic-scale
modeling, crucial for accelerating materials research and automating scientific
workflows.
\\ ( https://arxiv.org/abs/2510.04704 ,  6804kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04716 (*cross-listing*)
Date: Mon, 6 Oct 2025 11:34:08 GMT   (84kb)

Title: Curved Boolean Logic: A Contextual Generalization of Propositional Logic
  with Algorithmic Consequences
Authors: Maximilian R. P. von Liechtenstein
Categories: cs.LO cs.AI cs.CC quant-ph
Comments: 44 pages, 15 figures. Reproducible Colab notebook and params included
  as ancillary files; all paper figures are generated by the notebook. v1
MSC-class: 68Q17, 68Q25
ACM-class: F.1.1; F.2.2; I.2.3
\\
  Curved Boolean Logic (CBL) generalizes propositional logic by allowing local
truth assignments that do not extend to a single global valuation, analogous to
curvature in geometry. We give equivalent sheaf and exclusivity-graph semantics
and a context-aware proof calculus that is conservative in the flat limit. We
formalize CBL-SAT and basic complexity (NP-complete in general) and present
operational operators (CBL-AC and CBL-CONS) that prune contradictions earlier
on classical hardware. We model noise with iid, AR(1)-correlated, and
adversarial bounded perturbations and provide permutation-based significance
with Benjamini-Hochberg FDR control. A Colab-ready notebook (ancillary files)
regenerates all figures and statistics. We position CBL relative to KCBS, CSW,
and sheaf frameworks and outline links to SAT/CSP and robustness/adapter
stability in large language models.
\\ ( https://arxiv.org/abs/2510.04716 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04738 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:11:31 GMT   (818kb)

Title: Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with
  Cross-Attentive Mamba
Authors: Baher Mohammad, Magauiya Zhussip, Stamatios Lefkimmiatis
Categories: cs.SD cs.AI cs.CL cs.LG eess.AS
\\
  We introduce MAVE (Mamba with Cross-Attention for Voice Editing and
Synthesis), a novel autoregressive architecture for text-conditioned voice
editing and high-fidelity text-to-speech (TTS) synthesis, built on a
cross-attentive Mamba backbone. MAVE achieves state-of-the-art performance in
speech editing and very competitive results in zero-shot TTS, while not being
explicitly trained on the latter task, outperforming leading autoregressive and
diffusion models on diverse, real-world audio. By integrating Mamba for
efficient audio sequence modeling with cross-attention for precise
text-acoustic alignment, MAVE enables context-aware voice editing with
exceptional naturalness and speaker consistency. In pairwise human evaluations
on a random 40-sample subset of the RealEdit benchmark (400 judgments), 57.2%
of listeners rated MAVE - edited speech as perceptually equal to the original,
while 24.8% prefered the original and 18.0% MAVE - demonstrating that in the
majority of cases edits are indistinguishable from the source. MAVE compares
favorably with VoiceCraft and FluentSpeech both on pairwise comparisons and
standalone mean opinion score (MOS) evaluations. For zero-shot TTS, MAVE
exceeds VoiceCraft in both speaker similarity and naturalness, without
requiring multiple inference runs or post-processing. Remarkably, these quality
gains come with a significantly lower memory cost and approximately the same
latency: MAVE requires ~6x less memory than VoiceCraft during inference on
utterances from the RealEdit database (mean duration: 6.21s, A100, FP16, batch
size 1). Our results demonstrate that MAVE establishes a new standard for
flexible, high-fidelity voice editing and synthesis through the synergistic
integration of structured state-space modeling and cross-modal attention.
\\ ( https://arxiv.org/abs/2510.04738 ,  818kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04755 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:32:37 GMT   (290kb)

Title: A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy
  in the Age of AI
Authors: Jason Miklian, Kristian Hoelscher
Categories: cs.CY cs.AI
\\
  Digital technologies are transforming democratic life in conflicting ways.
This article bridges two perspectives to unpack these tensions. First, we
present an original survey of software developers in Silicon Valley,
interrogating how coder worldviews, ethics, and workplace cultures shape the
democratic potential and social impact of the technologies they build. Results
indicate that while most developers recognize the power of their products to
influence civil liberties and political discourse, they often face ethical
dilemmas and top-down pressures that can lead to design choices undermining
democratic ideals. Second, we critically investigate these findings in the
context of an emerging new digital divide, not of internet access but of
information quality. We interrogate the survey findings in the context of the
Slop Economy, in which billions of users unable to pay for high-quality content
experience an internet dominated by low-quality, AI-generated ad-driven
content. We find a reinforcing cycle between tech creator beliefs and the
digital ecosystems they spawn. We discuss implications for democratic
governance, arguing for more ethically informed design and policy interventions
to help bridge the digital divide to ensure that technological innovation
supports rather than subverts democratic values in the next chapter of the
digital age.
\\ ( https://arxiv.org/abs/2510.04755 ,  290kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04760 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:37:09 GMT   (410kb)

Title: Agile Software Effort Estimation using Regression Techniques
Authors: Sisay Deresa Sima and Ayalew Belay Habtie
Categories: cs.SE cs.AI
\\
  Software development effort estimation is one of the most critical aspect in
software development process, as the success or failure of the entire project
depends on the accuracy of estimations. Researchers are still conducting
studies on agile effort estimation. The aim of this research is to develop a
story point based agile effort estimation model using LASSO and Elastic Net
regression techniques. The experimental work is applied to the agile story
point approach using 21 software projects collected from six firms. The two
algorithms are trained using their default parameters and tuned grid search
with 5-fold cross-validation to get an enhanced model. The experiment result
shows LASSO regression achieved better predictive performance PRED (8%) and
PRED (25%) results of 100.0, MMRE of 0.0491, MMER of 0.0551, MdMRE of 0.0593,
MdMER of 0.063, and MSE of 0.0007. The results are also compared with other
related literature.
\\ ( https://arxiv.org/abs/2510.04760 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04762 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:38:28 GMT   (16257kb)

Title: Fisher-Bingham-like normalizing flows on the sphere
Authors: Thorsten Gl\"usenkamp
Categories: stat.ML astro-ph.IM cs.AI cs.LG
\\
  A generic D-dimensional Gaussian can be conditioned or projected onto the D-1
unit sphere, thereby leading to the well-known Fisher-Bingham (FB) or Angular
Gaussian (AG) distribution families, respectively. These are some of the most
fundamental distributions on the sphere, yet cannot straightforwardly be
written as a normalizing flow except in two special cases: the von-Mises Fisher
in D=3 and the central angular Gaussian in any D. In this paper, we describe
how to generalize these special cases to a family of normalizing flows that
behave similarly to the full FB or AG family in any D. We call them
"zoom-linear-project" (ZLP)-Fisher flows. Unlike a normal Fisher-Bingham
distribution, their composition allows to gradually add complexity as needed.
Furthermore, they can naturally handle conditional density estimation with
target distributions that vary by orders of magnitude in scale - a setting that
is important in astronomical applications but that existing flows often
struggle with. A particularly useful member of the new family is the Kent
analogue that can cheaply upgrade any flow in this situation to yield better
performance.
\\ ( https://arxiv.org/abs/2510.04762 ,  16257kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04769 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:42:32 GMT   (719kb)

Title: When Do Credal Sets Stabilize? Fixed-Point Theorems for Credal Set
  Updates
Authors: Michele Caprio, Siu Lun Chau, Krikamol Muandet
Categories: cs.LG cs.AI math.PR math.ST stat.ML stat.TH
MSC-class: Primary: 54H25, Secondary: 68T05, 68T37
\\
  Many machine learning algorithms rely on iterative updates of uncertainty
representations, ranging from variational inference and
expectation-maximization, to reinforcement learning, continual learning, and
multi-agent learning. In the presence of imprecision and ambiguity, credal sets
-- closed, convex sets of probability distributions -- have emerged as a
popular framework for representing imprecise probabilistic beliefs. Under such
imprecision, many learning problems in imprecise probabilistic machine learning
(IPML) may be viewed as processes involving successive applications of update
rules on credal sets. This naturally raises the question of whether this
iterative process converges to stable fixed points -- or, more generally, under
what conditions on the updating mechanism such fixed points exist, and whether
they can be attained. We provide the first analysis of this problem and
illustrate our findings using Credal Bayesian Deep Learning as a concrete
example. Our work demonstrates that incorporating imprecision into the learning
process not only enriches the representation of uncertainty, but also reveals
structural conditions under which stability emerges, thereby offering new
insights into the dynamics of iterative learning under imprecision.
\\ ( https://arxiv.org/abs/2510.04769 ,  719kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04773 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:49:00 GMT   (1003kb)

Title: Distribution Preference Optimization: A Fine-grained Perspective for LLM
  Unlearning
Authors: Kai Qin, Jiaqi Wu, Jianxiang He, Haoyuan Sun, Yifei Zhao, Bin Liang,
  Yongzhe Chang, Tiantian Zhang, Houde Liu
Categories: cs.LG cs.AI
Comments: 20 pages
\\
  As Large Language Models (LLMs) demonstrate remarkable capabilities learned
from vast corpora, concerns regarding data privacy and safety are receiving
increasing attention. LLM unlearning, which aims to remove the influence of
specific data while preserving overall model utility, is becoming an important
research area. One of the mainstream unlearning classes is optimization-based
methods, which achieve forgetting directly through fine-tuning, exemplified by
Negative Preference Optimization (NPO). However, NPO's effectiveness is limited
by its inherent lack of explicit positive preference signals. Attempts to
introduce such signals by constructing preferred responses often necessitate
domain-specific knowledge or well-designed prompts, fundamentally restricting
their generalizability. In this paper, we shift the focus to the
distribution-level, directly targeting the next-token probability distribution
instead of entire responses, and derive a novel unlearning algorithm termed
\textbf{Di}stribution \textbf{P}reference \textbf{O}ptimization (DiPO). We show
that the requisite preference distribution pairs for DiPO, which are
distributions over the model's output tokens, can be constructed by selectively
amplifying or suppressing the model's high-confidence output logits, thereby
effectively overcoming NPO's limitations. We theoretically prove the
consistency of DiPO's loss function with the desired unlearning direction.
Extensive experiments demonstrate that DiPO achieves a strong trade-off between
model utility and forget quality. Notably, DiPO attains the highest forget
quality on the TOFU benchmark, and maintains leading scalability and
sustainability in utility preservation on the MUSE benchmark.
\\ ( https://arxiv.org/abs/2510.04773 ,  1003kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04774 (*cross-listing*)
Date: Mon, 6 Oct 2025 12:49:36 GMT   (983kb)

Title: Online automatic code generation for robot swarms: LLMs and
  self-organizing hierarchy
Authors: Weixu Zhu, Marco Dorigo, Mary Katherine Heinrich
Categories: cs.RO cs.AI cs.MA
\\
  Our recently introduced self-organizing nervous system (SoNS) provides robot
swarms with 1) ease of behavior design and 2) global estimation of the swarm
configuration and its collective environment, facilitating the implementation
of online automatic code generation for robot swarms. In a demonstration with 6
real robots and simulation trials with >30 robots, we show that when a
SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code
generated by an external LLM on the fly, completing its mission with an 85%
success rate.
\\ ( https://arxiv.org/abs/2510.04774 ,  983kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04786 (*cross-listing*)
Date: Mon, 6 Oct 2025 13:07:14 GMT   (629kb)

Title: Learning on the Job: Test-Time Curricula for Targeted Reinforcement
  Learning
Authors: Jonas H\"ubotter, Leander Diaz-Bone, Ido Hakimi, Andreas Krause,
  Moritz Hardt
Categories: cs.LG cs.AI
\\
  Humans are good at learning on the job: We learn how to solve the tasks we
face as we go along. Can a model do the same? We propose an agent that
assembles a task-specific curriculum, called test-time curriculum (TTC-RL), and
applies reinforcement learning to continue training the model for its target
task. The test-time curriculum avoids time-consuming human curation of datasets
by automatically selecting the most task-relevant data from a large pool of
available training data. Our experiments demonstrate that reinforcement
learning on a test-time curriculum consistently improves the model on its
target tasks, across a variety of evaluations and models. Notably, on
challenging math and coding benchmarks, TTC-RL improves the pass@1 of Qwen3-8B
by approximately 1.8x on AIME25 and 2.1x on CodeElo. Moreover, we find that
TTC-RL significantly raises the performance ceiling compared to the initial
model, increasing pass@8 on AIME25 from 40% to 62% and on CodeElo from 28% to
43%. Our findings show the potential of test-time curricula in extending the
test-time scaling paradigm to continual training on thousands of task-relevant
experiences during test-time.
\\ ( https://arxiv.org/abs/2510.04786 ,  629kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04816 (*cross-listing*)
Date: Mon, 6 Oct 2025 13:57:49 GMT   (450kb)

Title: On Predicting Post-Click Conversion Rate via Counterfactual Inference
Authors: Junhyung Ahn and Sanghack Lee
Categories: cs.LG cs.AI
Comments: This work has been accepted for publication at the IEEE International
  Conference on Data Mining (ICDM) 2025
\\
  Accurately predicting conversion rate (CVR) is essential in various
recommendation domains such as online advertising systems and e-commerce. These
systems utilize user interaction logs, which consist of exposures, clicks, and
conversions. CVR prediction models are typically trained solely based on
clicked samples, as conversions can only be determined following clicks.
However, the sparsity of clicked instances necessitates the collection of a
substantial amount of logs for effective model training. Recent works address
this issue by devising frameworks that leverage non-clicked samples. While
these frameworks aim to reduce biases caused by the discrepancy between clicked
and non-clicked samples, they often rely on heuristics. Against this
background, we propose a method to counterfactually generate conversion labels
for non-clicked samples by using causality as a guiding principle, attempting
to answer the question, "Would the user have converted if he or she had clicked
the recommended item?" Our approach is named the Entire Space Counterfactual
Inference Multi-task Model (ESCIM). We initially train a structural causal
model (SCM) of user sequential behaviors and conduct a hypothetical
intervention (i.e., click) on non-clicked items to infer counterfactual CVRs.
We then introduce several approaches to transform predicted counterfactual CVRs
into binary counterfactual conversion labels for the non-clicked samples.
Finally, the generated samples are incorporated into the training process.
Extensive experiments on public datasets illustrate the superiority of the
proposed algorithm. Online A/B testing further empirically validates the
effectiveness of our proposed algorithm in real-world scenarios. In addition,
we demonstrate the improved performance of the proposed method on latent
conversion data, showcasing its robustness and superior generalization
capabilities.
\\ ( https://arxiv.org/abs/2510.04816 ,  450kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04837 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:22:23 GMT   (1358kb)

Title: Bond-Centered Molecular Fingerprint Derivatives: A BBBP Dataset Study
Authors: Guillaume Godin
Categories: cs.LG cs.AI
Comments: 14 pages, 10 figures, 1 table
\\
  Bond Centered FingerPrint (BCFP) are a complementary, bond-centric
alternative to Extended-Connectivity Fingerprints (ECFP). We introduce a static
BCFP that mirrors the bond-convolution used by directed message-passing GNNs
like ChemProp, and evaluate it with a fast rapid Random Forest model on
Brain-Blood Barrier Penetration (BBBP) classification task. Across stratified
cross-validation, concatenating ECFP with BCFP consistently improves AUROC and
AUPRC over either descriptor alone, as confirmed by Turkey HSD
multiple-comparison analysis. Among radii, r = 1 performs best; r = 2 does not
yield statistically separable gains under the same test. We further propose
BCFP-Sort&Slice, a simple feature-combination scheme that preserves the
out-of-vocabulary (OOV) count information native to ECFP count vectors while
enabling compact unhashed concatenation of BCFP variants. We also outperform
the MGTP prediction on our BBBP evaluation, using such composite new features
bond and atom features. These results show that lightweight, bond-centered
descriptors can complement atom-centered circular fingerprints and provide
strong, fast baselines for BBBP prediction.
\\ ( https://arxiv.org/abs/2510.04837 ,  1358kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04842 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:26:12 GMT   (7218kb)

Title: Distributionally Robust Causal Abstractions
Authors: Yorgos Felekis, Theodoros Damoulas, and Paris Giampouras
Categories: cs.LG cs.AI
\\
  Causal Abstraction (CA) theory provides a principled framework for relating
causal models that describe the same system at different levels of granularity
while ensuring interventional consistency between them. Recently, several
approaches for learning CAs have been proposed, but all assume fixed and
well-specified exogenous distributions, making them vulnerable to environmental
shifts and misspecification. In this work, we address these limitations by
introducing the first class of distributionally robust CAs and their associated
learning algorithms. The latter cast robust causal abstraction learning as a
constrained min-max optimization problem with Wasserstein ambiguity sets. We
provide theoretical results, for both empirical and Gaussian environments,
leading to principled selection of the level of robustness via the radius of
these sets. Furthermore, we present empirical evidence across different
problems and CA learning methods, demonstrating our framework's robustness not
only to environmental shifts but also to structural model and intervention
mapping misspecification.
\\ ( https://arxiv.org/abs/2510.04842 ,  7218kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04852 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:39:58 GMT   (286kb)

Title: FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration
Authors: Victor May, Diganta Misra, Yanqi Luo, Anjali Sridhar, Justine Gehring,
  Silvio Soares Ribeiro Junior
Categories: cs.SE cs.AI
Comments: 18 pages, 11 figures
\\
  AI coding assistants are rapidly becoming integral to modern software
development. A key challenge in this space is the continual need to migrate and
modernize codebases in response to evolving software ecosystems. Traditionally,
such migrations have relied on rule-based systems and human intervention. With
the advent of powerful large language models (LLMs), AI-driven agentic
frameworks offer a promising alternative-but their effectiveness has not been
systematically evaluated. In this paper, we introduce FreshBrew, a novel
benchmark for evaluating AI agents on project-level Java migrations, with a
specific focus on measuring an agent's ability to preserve program semantics
and avoid reward hacking, which we argue requires projects with high test
coverage for a rigorous and reliable evaluation. We benchmark several
state-of-the-art LLMs, and compare their performance against established
rule-based tools. Our evaluation of AI agents on this benchmark of 228
repositories shows that the top-performing model, Gemini 2.5 Flash, can
successfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis
reveals novel insights into the critical strengths and limitations of current
agentic approaches, offering actionable insights into their real-world
applicability. Our empirical study reveals failure modes of current AI agents
in realistic Java modernization tasks, providing a foundation for evaluating
trustworthy code-migration systems. By releasing FreshBrew, we aim to
facilitate rigorous, reproducible evaluation and catalyze progress in AI-driven
codebase modernization.
\\ ( https://arxiv.org/abs/2510.04852 ,  286kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04860 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:48:39 GMT   (2197kb)

Title: Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the
  Rails
Authors: Siwei Han, Jiaqi Liu, Yaofeng Su, Wenbo Duan, Xinyuan Liu, Cihang Xie,
  Mohit Bansal, Mingyu Ding, Linjun Zhang, Huaxiu Yao
Categories: cs.LG cs.AI
\\
  As Large Language Model (LLM) agents increasingly gain self-evolutionary
capabilities to adapt and refine their strategies through real-world
interaction, their long-term reliability becomes a critical concern. We
identify the Alignment Tipping Process (ATP), a critical post-deployment risk
unique to self-evolving LLM agents. Unlike training-time failures, ATP arises
when continual interaction drives agents to abandon alignment constraints
established during training in favor of reinforced, self-interested strategies.
We formalize and analyze ATP through two complementary paradigms:
Self-Interested Exploration, where repeated high-reward deviations induce
individual behavioral drift, and Imitative Strategy Diffusion, where deviant
behaviors spread across multi-agent systems. Building on these paradigms, we
construct controllable testbeds and benchmark Qwen3-8B and
Llama-3.1-8B-Instruct. Our experiments show that alignment benefits erode
rapidly under self-evolution, with initially aligned models converging toward
unaligned states. In multi-agent settings, successful violations diffuse
quickly, leading to collective misalignment. Moreover, current reinforcement
learning-based alignment methods provide only fragile defenses against
alignment tipping. Together, these findings demonstrate that alignment of LLM
agents is not a static property but a fragile and dynamic one, vulnerable to
feedback-driven decay during deployment. Our data and code are available at
https://github.com/aiming-lab/ATP.
\\ ( https://arxiv.org/abs/2510.04860 ,  2197kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04868 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:52:27 GMT   (1621kb)

Title: Model Predictive Control-Guided Reinforcement Learning for Implicit
  Balancing
Authors: Seyed Soroush Karimi Madahi, Kenneth Bruninx, Bert Claessens, Chris
  Develder
Categories: eess.SY cs.AI cs.SY
\\
  In Europe, profit-seeking balance responsible parties can deviate in real
time from their day-ahead nominations to assist transmission system operators
in maintaining the supply-demand balance. Model predictive control (MPC)
strategies to exploit these implicit balancing strategies capture arbitrage
opportunities, but fail to accurately capture the price-formation process in
the European imbalance markets and face high computational costs. Model-free
reinforcement learning (RL) methods are fast to execute, but require
data-intensive training and usually rely on real-time and historical data for
decision-making. This paper proposes an MPC-guided RL method that combines the
complementary strengths of both MPC and RL. The proposed method can effectively
incorporate forecasts into the decision-making process (as in MPC), while
maintaining the fast inference capability of RL. The performance of the
proposed method is evaluated on the implicit balancing battery control problem
using Belgian balancing data from 2023. First, we analyze the performance of
the standalone state-of-the-art RL and MPC methods from various angles, to
highlight their individual strengths and limitations. Next, we show an
arbitrage profit benefit of the proposed MPC-guided RL method of 16.15% and
54.36%, compared to standalone RL and MPC.
\\ ( https://arxiv.org/abs/2510.04868 ,  1621kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04871 (*cross-listing*)
Date: Mon, 6 Oct 2025 14:58:08 GMT   (259kb)

Title: Less is More: Recursive Reasoning with Tiny Networks
Authors: Alexia Jolicoeur-Martineau
Categories: cs.LG cs.AI
\\
  Hierarchical Reasoning Model (HRM) is a novel approach using two small neural
networks recursing at different frequencies. This biologically inspired method
beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,
and ARC-AGI while trained with small models (27M parameters) on small data
(around 1000 examples). HRM holds great promise for solving hard problems with
small networks, but it is not yet well understood and may be suboptimal. We
propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach
that achieves significantly higher generalization than HRM, while using a
single tiny network with only 2 layers. With only 7M parameters, TRM obtains
45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs
(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the
parameters.
\\ ( https://arxiv.org/abs/2510.04871 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04888 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:09:39 GMT   (16059kb)

Title: Revealing Interconnections between Diseases: from Statistical Methods to
  Large Language Models
Authors: Alina Ermilova, Dmitrii Kornilov, Sofia Samoilova, Ekaterina
  Laptenkova, Anastasia Kolesnikova, Ekaterina Podplutova, Senotrusova Sofya,
  Maksim G. Sharaev
Categories: cs.LG cs.AI
\\
  Identifying disease interconnections through manual analysis of large-scale
clinical data is labor-intensive, subjective, and prone to expert disagreement.
While machine learning (ML) shows promise, three critical challenges remain:
(1) selecting optimal methods from the vast ML landscape, (2) determining
whether real-world clinical data (e.g., electronic health records, EHRs) or
structured disease descriptions yield more reliable insights, (3) the lack of
"ground truth," as some disease interconnections remain unexplored in medicine.
Large language models (LLMs) demonstrate broad utility, yet they often lack
specialized medical knowledge. To address these gaps, we conduct a systematic
evaluation of seven approaches for uncovering disease relationships based on
two data sources: (i) sequences of ICD-10 codes from MIMIC-IV EHRs and (ii) the
full set of ICD-10 codes, both with and without textual descriptions. Our
framework integrates the following: (i) a statistical co-occurrence analysis
and a masked language modeling (MLM) approach using real clinical data; (ii)
domain-specific BERT variants (Med-BERT and BioClinicalBERT); (iii) a
general-purpose BERT and document retrieval; and (iv) four LLMs (Mistral,
DeepSeek, Qwen, and YandexGPT). Our graph-based comparison of the obtained
interconnection matrices shows that the LLM-based approach produces
interconnections with the lowest diversity of ICD code connections to different
diseases compared to other methods, including text-based and domain-based
approaches. This suggests an important implication: LLMs have limited potential
for discovering new interconnections. In the absence of ground truth databases
for medical interconnections between ICD codes, our results constitute a
valuable medical disease ontology that can serve as a foundational resource for
future clinical research and artificial intelligence applications in
healthcare.
\\ ( https://arxiv.org/abs/2510.04888 ,  16059kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04898 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:15:38 GMT   (645kb)

Title: HyperVLA: Efficient Inference in Vision-Language-Action Models via
  Hypernetworks
Authors: Zheng Xiong, Kang Li, Zilin Wang, Matthew Jackson, Jakob Foerster,
  Shimon Whiteson
Categories: cs.RO cs.AI cs.LG
\\
  Built upon language and vision foundation models with strong generalization
ability and trained on large-scale robotic data, Vision-Language-Action (VLA)
models have recently emerged as a promising approach to learning generalist
robotic policies. However, a key drawback of existing VLAs is their extremely
high inference costs. In this paper, we propose HyperVLA to address this
problem. Unlike existing monolithic VLAs that activate the whole model during
both training and inference, HyperVLA uses a novel hypernetwork (HN)-based
architecture that activates only a small task-specific policy during inference,
while still retaining the high model capacity needed to accommodate diverse
multi-task behaviors during training. Successfully training an HN-based VLA is
nontrivial so HyperVLA contains several key algorithm design features that
improve its performance, including properly utilizing the prior knowledge from
existing vision foundation models, HN normalization, and an action generation
strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even
higher success rate for both zero-shot generalization and few-shot adaptation,
while significantly reducing inference costs. Compared to OpenVLA, a
state-of-the-art VLA model, HyperVLA reduces the number of activated parameters
at test time by $90\times$, and accelerates inference speed by $120\times$.
Code is publicly available at https://github.com/MasterXiong/HyperVLA
\\ ( https://arxiv.org/abs/2510.04898 ,  645kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04901 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:17:46 GMT   (4510kb)

Title: Focused Skill Discovery: Learning to Control Specific State Variables
  while Minimizing Side Effects
Authors: Jonathan Cola\c{c}o Carr, Qinyi Sun, Cameron Allen
Categories: cs.LG cs.AI
Comments: Reinforcement Learning Journal 2025
\\
  Skills are essential for unlocking higher levels of problem solving. A common
approach to discovering these skills is to learn ones that reliably reach
different states, thus empowering the agent to control its environment.
However, existing skill discovery algorithms often overlook the natural state
variables present in many reinforcement learning problems, meaning that the
discovered skills lack control of specific state variables. This can
significantly hamper exploration efficiency, make skills more challenging to
learn with, and lead to negative side effects in downstream tasks when the goal
is under-specified. We introduce a general method that enables these skill
discovery algorithms to learn focused skills -- skills that target and control
specific state variables. Our approach improves state space coverage by a
factor of three, unlocks new learning capabilities, and automatically avoids
negative side effects in downstream tasks.
\\ ( https://arxiv.org/abs/2510.04901 ,  4510kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04910 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:24:44 GMT   (27639kb)

Title: Glocal Information Bottleneck for Time Series Imputation
Authors: Jie Yang, Kexin Zhang, Guibin Zhang, Philip S. Yu, Kaize Ding
Categories: cs.LG cs.AI
\\
  Time Series Imputation (TSI), which aims to recover missing values in
temporal data, remains a fundamental challenge due to the complex and often
high-rate missingness in real-world scenarios. Existing models typically
optimize the point-wise reconstruction loss, focusing on recovering numerical
values (local information). However, we observe that under high missing rates,
these models still perform well in the training phase yet produce poor
imputations and distorted latent representation distributions (global
information) in the inference phase. This reveals a critical optimization
dilemma: current objectives lack global guidance, leading models to overfit
local noise and fail to capture global information of the data. To address this
issue, we propose a new training paradigm, Glocal Information Bottleneck
(Glocal-IB). Glocal-IB is model-agnostic and extends the standard IB framework
by introducing a Global Alignment loss, derived from a tractable mutual
information approximation. This loss aligns the latent representations of
masked inputs with those of their originally observed counterparts. It helps
the model retain global structure and local details while suppressing noise
caused by missing values, giving rise to better generalization under high
missingness. Extensive experiments on nine datasets confirm that Glocal-IB
leads to consistently improved performance and aligned latent representations
under missingness. Our code implementation is available in
https://github.com/Muyiiiii/NeurIPS-25-Glocal-IB.
\\ ( https://arxiv.org/abs/2510.04910 ,  27639kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04927 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:37:15 GMT   (3814kb)

Title: Federated Self-Supervised Learning for Automatic Modulation
  Classification under Non-IID and Class-Imbalanced Data
Authors: Usman Akram, Yiyue Chen, Haris Vikalo
Categories: cs.LG cs.AI eess.SP
\\
  Training automatic modulation classification (AMC) models on centrally
aggregated data raises privacy concerns, incurs communication overhead, and
often fails to confer robustness to channel shifts. Federated learning (FL)
avoids central aggregation by training on distributed clients but remains
sensitive to class imbalance, non-IID client distributions, and limited labeled
samples. We propose FedSSL-AMC, which trains a causal, time-dilated CNN with
triplet-loss self-supervision on unlabeled I/Q sequences across clients,
followed by per-client SVMs on small labeled sets. We establish convergence of
the federated representation learning procedure and a separability guarantee
for the downstream classifier under feature noise. Experiments on synthetic and
over-the-air datasets show consistent gains over supervised FL baselines under
heterogeneous SNR, carrier-frequency offsets, and non-IID label partitions.
\\ ( https://arxiv.org/abs/2510.04927 ,  3814kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04934 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:41:34 GMT   (1208kb)

Title: AURA Score: A Metric For Holistic Audio Question Answering Evaluation
Authors: Satvik Dixit, Soham Deshmukh, Bhiksha Raj
Categories: eess.AS cs.AI
\\
  Audio Question Answering (AQA) is a key task for evaluating Audio-Language
Models (ALMs), yet assessing open-ended responses remains challenging. Existing
metrics used for AQA such as BLEU, METEOR and BERTScore, mostly adapted from
NLP and audio captioning, rely on surface similarity and fail to account for
question context, reasoning, and partial correctness. To address the gap in
literature, we make three contributions in this work. First, we introduce
AQEval to enable systematic benchmarking of AQA metrics. It is the first
benchmark of its kind, consisting of 10k model responses annotated by multiple
humans for their correctness and relevance. Second, we conduct a comprehensive
analysis of existing AQA metrics on AQEval, highlighting weak correlation with
human judgment, especially for longer answers. Third, we propose a new metric -
AURA score, to better evaluate open-ended model responses. On AQEval, AURA
achieves state-of-the-art correlation with human ratings, significantly
outperforming all baselines. Through this work, we aim to highlight the
limitations of current AQA evaluation methods and motivate better metrics. We
release both the AQEval benchmark and the AURA metric to support future
research in holistic AQA evaluation.
\\ ( https://arxiv.org/abs/2510.04934 ,  1208kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04938 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:43:36 GMT   (3825kb)

Title: ONNX-Net: Towards Universal Representations and Instant Performance
  Prediction for Neural Architectures
Authors: Shiwen Qin, Alexander Auras, Shay B. Cohen, Elliot J. Crowley, Michael
  Moeller, Linus Ericsson, Jovita Lukasik
Categories: cs.LG cs.AI cs.CL
Comments: Our code is available at: https://github.com/shiwenqin/ONNX-Net
\\
  Neural architecture search (NAS) automates the design process of
high-performing architectures, but remains bottlenecked by expensive
performance evaluation. Most existing studies that achieve faster evaluation
are mostly tied to cell-based search spaces and graph encodings tailored to
those individual search spaces, limiting their flexibility and scalability when
applied to more expressive search spaces. In this work, we aim to close the gap
of individual search space restrictions and search space dependent network
representations. We present ONNX-Bench, a benchmark consisting of a collection
of neural networks in a unified format based on ONNX files. ONNX-Bench includes
all open-source NAS-bench-based neural networks, resulting in a total size of
more than 600k {architecture, accuracy} pairs. This benchmark allows creating a
shared neural network representation, ONNX-Net, able to represent any neural
architecture using natural language descriptions acting as an input to a
performance predictor. This text-based encoding can accommodate arbitrary layer
types, operation parameters, and heterogeneous topologies, enabling a single
surrogate to generalise across all neural architectures rather than being
confined to cell-based search spaces. Experiments show strong zero-shot
performance across disparate search spaces using only a small amount of
pretraining samples, enabling the unprecedented ability to evaluate any neural
network architecture instantly.
\\ ( https://arxiv.org/abs/2510.04938 ,  3825kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04951 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:52:03 GMT   (1288kb)

Title: Feasibility-Aware Decision-Focused Learning for Predicting Parameters in
  the Constraints
Authors: Jayanta Mandi, Marianne Defresne, Senne Berden, Tias Guns
Categories: cs.LG cs.AI
\\
  When some parameters of a constrained optimization problem (COP) are
uncertain, this gives rise to a predict-then-optimize (PtO) problem, comprising
two stages -- the prediction of the unknown parameters from contextual
information and the subsequent optimization using those predicted parameters.
Decision-focused learning (DFL) implements the first stage by training a
machine learning (ML) model to optimize the quality of the decisions made using
the predicted parameters. When parameters in the constraints of a COP are
predicted, the predicted parameters can lead to infeasible solutions.
Therefore, it is important to simultaneously manage both feasibility and
decision quality. We develop a DFL framework for predicting constraint
parameters in a generic COP. While prior works typically assume that the
underlying optimization problem is a linear program (LP) or integer linear
program (ILP), our approach makes no such assumption. We derive two novel loss
functions based on maximum likelihood estimation (MLE): the first one penalizes
infeasibility (by penalizing when the predicted parameters lead to infeasible
solutions), and the second one penalizes suboptimal decisions (by penalizing
when the true optimal solution is infeasible under the predicted parameters).
We introduce a single tunable parameter to form a weighted average of the two
losses, allowing decision-makers to balance suboptimality and feasibility. We
experimentally demonstrate that adjusting this parameter provides a
decision-maker the control over the trade-off between the two. Moreover, across
several COP instances, we find that for a single value of the tunable
parameter, our method matches the performance of the existing baselines on
suboptimality and feasibility.
\\ ( https://arxiv.org/abs/2510.04951 ,  1288kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04956 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:54:55 GMT   (2134kb)

Title: MuFFIN: Multifaceted Pronunciation Feedback Model with Interactive
  Hierarchical Neural Modeling
Authors: Bi-Cheng Yan, Ming-Kang Tsai, and Berlin Chen
Categories: eess.AS cs.AI
Comments: Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing
\\
  Computer-assisted pronunciation training (CAPT) manages to facilitate
second-language (L2) learners to practice pronunciation skills by offering
timely and instructive feedback. To examine pronunciation proficiency from
multiple facets, existing methods for CAPT broadly fall into two categories:
mispronunciation detection and diagnosis (MDD) as well as automatic
pronunciation assessment (APA). The former aims to pinpoint phonetic
pronunciation errors and provide diagnostic feedback, while the latter seeks
instead to quantify pronunciation proficiency pertaining to various aspects.
Despite the natural complementarity between MDD and APA, researchers and
practitioners, however, often treat them as independent tasks with disparate
modeling paradigms. In light of this, we in this paper first introduce MuFFIN,
a Multi-Faceted pronunciation Feedback model with an Interactive hierarchical
Neural architecture, to jointly address the tasks of MDD and APA. To better
capture the nuanced distinctions between phonemes in the feature space, a novel
phoneme-contrastive ordinal regularization mechanism is then put forward to
optimize the proposed model to generate more phoneme-discriminative features
while factoring in the ordinality of the aspect scores. In addition, to address
the intricate data imbalance problem in MDD, we design a simple yet effective
training objective, which is specifically tailored to perturb the outputs of a
phoneme classifier with the phoneme-specific variations, so as to better render
the distribution of predicted phonemes meanwhile considering their
mispronunciation characteristics. A series of experiments conducted on the
Speechocean762 benchmark dataset demonstrates the efficacy of our method in
relation to several cutting-edge baselines, showing state-of-the-art
performance on both the APA and MDD tasks.
\\ ( https://arxiv.org/abs/2510.04956 ,  2134kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04970 (*cross-listing*)
Date: Mon, 6 Oct 2025 16:04:53 GMT   (168kb)

Title: Embracing Discrete Search: A Reasonable Approach to Causal Structure
  Learning
Authors: Marcel Wien\"obst, Leonard Henckel, Sebastian Weichwald
Categories: stat.ML cs.AI cs.LG stat.ME
\\
  We present FLOP (Fast Learning of Order and Parents), a score-based causal
discovery algorithm for linear models. It pairs fast parent selection with
iterative Cholesky-based score updates, cutting run-times over prior
algorithms. This makes it feasible to fully embrace discrete search, enabling
iterated local search with principled order initialization to find graphs with
scores at or close to the global optimum. The resulting structures are highly
accurate across benchmarks, with near-perfect recovery in standard settings.
This performance calls for revisiting discrete search over graphs as a
reasonable approach to causal discovery.
\\ ( https://arxiv.org/abs/2510.04970 ,  168kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04996 (*cross-listing*)
Date: Mon, 6 Oct 2025 16:34:09 GMT   (699kb)

Title: Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM
  Training
Authors: Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof
  Monz, Jiang Bian, Nan Jiang, Tong Zhang
Categories: cs.LG cs.AI cs.CL stat.ML
Comments: 16 pages, 6 figures
\\
  Reinforcement learning applied to large language models (LLMs) for reasoning
tasks is often bottlenecked by unstable gradient estimates due to fixed and
uniform sampling of responses across prompts. Prior work such as GVM-RAFT
addresses this by dynamically allocating inference budget per prompt to
minimize stochastic gradient variance under a budget constraint. Inspired by
this insight, we propose Reinforce-Ada, an adaptive sampling framework for
online RL post-training of LLMs that continuously reallocates sampling effort
to the prompts with the greatest uncertainty or learning potential. Unlike
conventional two-stage allocation methods, Reinforce-Ada interleaves estimation
and sampling in an online successive elimination process, and automatically
stops sampling for a prompt once sufficient signal is collected. To stabilize
updates, we form fixed-size groups with enforced reward diversity and compute
advantage baselines using global statistics aggregated over the adaptive
sampling phase. Empirical results across multiple model architectures and
reasoning benchmarks show that Reinforce-Ada accelerates convergence and
improves final performance compared to GRPO, especially when using the balanced
sampling variant. Our work highlights the central role of variance-aware,
adaptive data curation in enabling efficient and reliable reinforcement
learning for reasoning-capable LLMs. Code is available at
https://github.com/RLHFlow/Reinforce-Ada.
\\ ( https://arxiv.org/abs/2510.04996 ,  699kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04997 (*cross-listing*)
Date: Mon, 6 Oct 2025 16:37:18 GMT   (387kb)

Title: AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault
  Analysis
Authors: Jiongchi Yu, Weipeng Jiang, Xiaoyu Zhang, Qiang Hu, Xiaofei Xie, Chao
  Shen
Categories: cs.SE cs.AI
Comments: 5 pages
\\
  Understanding software faults is essential for empirical research in software
development and maintenance. However, traditional fault analysis, while
valuable, typically involves multiple expert-driven steps such as collecting
potential faults, filtering, and manual investigation. These processes are both
labor-intensive and time-consuming, creating bottlenecks that hinder
large-scale fault studies in complex yet critical software systems and slow the
pace of iterative empirical research.
  In this paper, we decompose the process of empirical software fault study
into three key phases: (1) research objective definition, (2) data preparation,
and (3) fault analysis, and we conduct an initial exploration study of applying
Large Language Models (LLMs) for fault analysis of open-source software.
Specifically, we perform the evaluation on 3,829 software faults drawn from a
high-quality empirical study. Our results show that LLMs can substantially
improve efficiency in fault analysis, with an average processing time of about
two hours, compared to the weeks of manual effort typically required. We
conclude by outlining a detailed research plan that highlights both the
potential of LLMs for advancing empirical fault studies and the open challenges
that required be addressed to achieve fully automated, end-to-end software
fault analysis.
\\ ( https://arxiv.org/abs/2510.04997 ,  387kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04999 (*cross-listing*)
Date: Mon, 6 Oct 2025 16:39:05 GMT   (6612kb)

Title: Bridging Text and Video Generation: A Survey
Authors: Nilay Kumar, Priyansh Bhandari, G. Maragatham
Categories: cs.GR cs.AI cs.CV
\\
  Text-to-video (T2V) generation technology holds potential to transform
multiple domains such as education, marketing, entertainment, and assistive
technologies for individuals with visual or reading comprehension challenges,
by creating coherent visual content from natural language prompts. From its
inception, the field has advanced from adversarial models to diffusion-based
models, yielding higher-fidelity, temporally consistent outputs. Yet challenges
persist, such as alignment, long-range coherence, and computational efficiency.
Addressing this evolving landscape, we present a comprehensive survey of
text-to-video generative models, tracing their development from early GANs and
VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these
models work, what limitations they addressed in their predecessors, and why
shifts toward new architectural paradigms were necessary to overcome challenges
in quality, coherence, and control. We provide a systematic account of the
datasets, which the surveyed text-to-video models were trained and evaluated
on, and, to support reproducibility and assess the accessibility of training
such models, we detail their training configurations, including their hardware
specifications, GPU counts, batch sizes, learning rates, optimizers, epochs,
and other key hyperparameters. Further, we outline the evaluation metrics
commonly used for evaluating such models and present their performance across
standard benchmarks, while also discussing the limitations of these metrics and
the emerging shift toward more holistic, perception-aligned evaluation
strategies. Finally, drawing from our analysis, we outline the current open
challenges and propose a few promising future directions, laying out a
perspective for future researchers to explore and build upon in advancing T2V
research and applications.
\\ ( https://arxiv.org/abs/2510.04999 ,  6612kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05016 (*cross-listing*)
Date: Mon, 6 Oct 2025 16:58:47 GMT   (797kb)

Title: Large Language Models Achieve Gold Medal Performance at International
  Astronomy & Astrophysics Olympiad
Authors: Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness
  Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun
Categories: astro-ph.IM cs.AI cs.CL
Comments: 18 pages, 6 figures, to be submitted, comments are welcome
\\
  While task-specific demonstrations show early success in applying large
language models (LLMs) to automate some astronomical research tasks, they only
provide incomplete views of all necessary capabilities in solving astronomy
problems, calling for more thorough understanding of LLMs' strengths and
limitations. So far, existing benchmarks and evaluations focus on simple
question-answering that primarily tests astronomical knowledge and fails to
evaluate the complex reasoning required for real-world research in the
discipline. Here, we address this gap by systematically benchmarking five
state-of-the-art LLMs on the International Olympiad on Astronomy and
Astrophysics (IOAA) exams, which are designed to examine deep conceptual
understanding, multi-step derivations, and multimodal analysis. With average
scores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing
models) not only achieve gold medal level performance but also rank in the top
two among ~200-300 participants in all four IOAA theory exams evaluated
(2022-2025). In comparison, results on the data analysis exams show more
divergence. GPT-5 still excels in the exams with an 88.5% average score,
ranking top 10 among the participants in the four most recent IOAAs, while
other models' performances drop to 48-76%. Furthermore, our in-depth error
analysis underscores conceptual reasoning, geometric reasoning, and spatial
visualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence,
although LLMs approach peak human performance in theory exams, critical gaps
must be addressed before they can serve as autonomous research agents in
astronomy.
\\ ( https://arxiv.org/abs/2510.05016 ,  797kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05023 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:01:29 GMT   (2256kb)

Title: Rethinking Langevin Thompson Sampling from A Stochastic Approximation
  Perspective
Authors: Weixin Wang, Haoyang Zheng, Guang Lin, Wei Deng, Pan Xu
Categories: cs.LG cs.AI stat.ML
Comments: 39 pages, 3 figures, 2 tables
\\
  Most existing approximate Thompson Sampling (TS) algorithms for multi-armed
bandits use Stochastic Gradient Langevin Dynamics (SGLD) or its variants in
each round to sample from the posterior, relaxing the need for conjugacy
assumptions between priors and reward distributions in vanilla TS. However,
they often require approximating a different posterior distribution in
different round of the bandit problem. This requires tricky, round-specific
tuning of hyperparameters such as dynamic learning rates, causing challenges in
both theoretical analysis and practical implementation. To alleviate this
non-stationarity, we introduce TS-SA, which incorporates stochastic
approximation (SA) within the TS framework. In each round, TS-SA constructs a
posterior approximation only using the most recent reward(s), performs a
Langevin Monte Carlo (LMC) update, and applies an SA step to average noisy
proposals over time. This can be interpreted as approximating a stationary
posterior target throughout the entire algorithm, which further yields a fixed
step-size, a unified convergence analysis framework, and improved posterior
estimates through temporal averaging. We establish near-optimal regret bounds
for TS-SA, with a simplified and more intuitive theoretical analysis enabled by
interpreting the entire algorithm as a simulation of a stationary SGLD process.
Our empirical results demonstrate that even a single-step Langevin update with
certain warm-up outperforms existing methods substantially on bandit tasks.
\\ ( https://arxiv.org/abs/2510.05023 ,  2256kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05036 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:11:32 GMT   (679kb)

Title: Graph-Aware Diffusion for Signal Generation
Authors: Sergio Rozada, Vimal K. B., Andrea Cavallo, Antonio G. Marques, Hadi
  Jamali-Rad, Elvin Isufi
Categories: cs.LG cs.AI
\\
  We study the problem of generating graph signals from unknown distributions
defined over given graphs, relevant to domains such as recommender systems or
sensor networks. Our approach builds on generative diffusion models, which are
well established in vision and graph generation but remain underexplored for
graph signals. Existing methods lack generality, either ignoring the graph
structure in the forward process or designing graph-aware mechanisms tailored
to specific domains. We adopt a forward process that incorporates the graph
through the heat equation. Rather than relying on the standard formulation, we
consider a time-warped coefficient to mitigate the exponential decay of the
drift term, yielding a graph-aware generative diffusion model (GAD). We analyze
its forward dynamics, proving convergence to a Gaussian Markov random field
with covariance parametrized by the graph Laplacian, and interpret the backward
dynamics as a sequence of graph-signal denoising problems. Finally, we
demonstrate the advantages of GAD on synthetic data, real traffic speed
measurements, and a temperature sensor network.
\\ ( https://arxiv.org/abs/2510.05036 ,  679kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05040 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:16:41 GMT   (531kb)

Title: Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive
  Experts
Authors: Jihoon Lee, Hoyeon Moon, Kevin Zhai, Arun Kumar Chithanar, Anit Kumar
  Sahu, Soummya Kar, Chul Lee, Souradip Chakraborty, Amrit Singh Bedi
Categories: cs.LG cs.AI
\\
  Diffusion-based large language models (dLLMs) are trained flexibly to model
extreme dependence in the data distribution; however, how to best utilize this
information at inference time remains an open problem. In this work, we uncover
an interesting property of these models: dLLMs trained on textual data
implicitly learn a mixture of semi-autoregressive experts, where different
generation orders reveal different specialized behaviors. We show that
committing to any single, fixed inference time schedule, a common practice,
collapses performance by failing to leverage this latent ensemble. To address
this, we introduce HEX (Hidden semiautoregressive EXperts for test-time
scaling), a training-free inference method that ensembles across heterogeneous
block schedules. By doing a majority vote over diverse block-sized generation
paths, HEX robustly avoids failure modes associated with any single fixed
schedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to
3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and
specialized fine-tuned methods like GRPO, without additional training. HEX even
yields significant gains on MATH benchmark from 16.40% to 40.00%, scientific
reasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%.
Our results establish a new paradigm for test-time scaling in diffusion-based
LLMs (dLLMs), revealing that the sequence in which masking is performed plays a
critical role in determining performance during inference.
\\ ( https://arxiv.org/abs/2510.05040 ,  531kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05054 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:34:48 GMT   (8068kb)

Title: HybridFlow: Quantification of Aleatoric and Epistemic Uncertainty with a
  Single Hybrid Model
Authors: Peter Van Katwyk, Karianne J. Bergen
Categories: cs.LG cs.AI
Comments: Reviewed and published in TMLR at
  https://openreview.net/forum?id=xRiEdSyVjY
Journal-ref: Transactions on Machine Learning Research, 2025
\\
  Uncertainty quantification is critical for ensuring robustness in high-stakes
machine learning applications. We introduce HybridFlow, a modular hybrid
architecture that unifies the modeling of aleatoric and epistemic uncertainty
by combining a Conditional Masked Autoregressive normalizing flow for
estimating aleatoric uncertainty with a flexible probabilistic predictor for
epistemic uncertainty. The framework supports integration with any
probabilistic model class, allowing users to easily adapt HybridFlow to
existing architectures without sacrificing predictive performance. HybridFlow
improves upon previous uncertainty quantification frameworks across a range of
regression tasks, such as depth estimation, a collection of regression
benchmarks, and a scientific case study of ice sheet emulation. We also provide
empirical results of the quantified uncertainty, showing that the uncertainty
quantified by HybridFlow is calibrated and better aligns with model error than
existing methods for quantifying aleatoric and epistemic uncertainty.
HybridFlow addresses a key challenge in Bayesian deep learning, unifying
aleatoric and epistemic uncertainty modeling in a single robust framework.
\\ ( https://arxiv.org/abs/2510.05054 ,  8068kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05081 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:51:04 GMT   (39487kb)

Title: SAEdit: Token-level control for continuous image editing via Sparse
  AutoEncoder
Authors: Ronen Kamenetsky, Sara Dorfman, Daniel Garibi, Roni Paiss, Or
  Patashnik, Daniel Cohen-Or
Categories: cs.GR cs.AI cs.CV
Comments: Project page at: https://ronen94.github.io/SAEdit/
\\
  Large-scale text-to-image diffusion models have become the backbone of modern
image editing, yet text prompts alone do not offer adequate control over the
editing process. Two properties are especially desirable: disentanglement,
where changing one attribute does not unintentionally alter others, and
continuous control, where the strength of an edit can be smoothly adjusted. We
introduce a method for disentangled and continuous editing through token-level
manipulation of text embeddings. The edits are applied by manipulating the
embeddings along carefully chosen directions, which control the strength of the
target attribute. To identify such directions, we employ a Sparse Autoencoder
(SAE), whose sparse latent space exposes semantically isolated dimensions. Our
method operates directly on text embeddings without modifying the diffusion
process, making it model agnostic and broadly applicable to various image
synthesis backbones. Experiments show that it enables intuitive and efficient
manipulations with continuous control across diverse attributes and domains.
\\ ( https://arxiv.org/abs/2510.05081 ,  39487kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05092 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:57:23 GMT   (540kb)

Title: Learning to Interpret Weight Differences in Language Models
Authors: Avichal Goel, Yoon Kim, Nir Shavit, Tony T. Wang
Categories: cs.LG cs.AI cs.CL
Comments: The weight diffs and DIT adapters trained in the paper can be found
  at https://huggingface.co/diff-interpretation-tuning/loras
\\
  Finetuning (pretrained) language models is a standard approach for updating
their internal parametric knowledge and specializing them to new tasks and
domains. However, the corresponding model weight changes ("weight diffs") are
not generally interpretable. While inspecting the finetuning dataset can give a
sense of how the model might have changed, these datasets are often not
publicly available or are too large to work with directly. Towards the goal of
comprehensively understanding weight diffs in natural language, we introduce
Diff Interpretation Tuning (DIT), a method that trains models to describe their
own finetuning-induced modifications. Our approach uses synthetic, labeled
weight diffs to train a DIT adapter, which can be applied to a compatible
finetuned model to make it describe how it has changed. We demonstrate in two
proof-of-concept settings (reporting hidden behaviors and summarizing finetuned
knowledge) that our method enables models to describe their finetuning-induced
modifications using accurate natural language descriptions.
\\ ( https://arxiv.org/abs/2510.05092 ,  540kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05095 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:58:01 GMT   (70kb)

Title: From Noisy Traces to Stable Gradients: Bias-Variance Optimized
  Preference Optimization for Aligning Large Reasoning Models
Authors: Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia
Categories: cs.LG cs.AI cs.CL
\\
  Large reasoning models (LRMs) generate intermediate reasoning traces before
producing final answers, yielding strong gains on multi-step and mathematical
tasks. Yet aligning LRMs with human preferences, a crucial prerequisite for
model deployment, remains underexplored. The statistically correct objective
for preference alignment requires marginalizing over reasoning traces, but this
computation is intractable in practice. A common workaround optimizes a single
sampled trajectory, which introduces substantial gradient variance from
stochastic trace sampling. To address this challenge, we frame preference
optimization for LRMs through the lens of the bias--variance trade-off and
propose Bias--Variance Optimized Preference Optimization (BVPO), a simple,
drop-in method that mixes two gradient estimators: a high-variance trace-based
estimator and a low-variance empty-trace estimator obtained by disabling
reasoning trace generation. Our theory shows that BVPO strictly reduces
trace-induced variance for any nontrivial mixture, provides a closed-form
choice of the mixing weight that minimizes mean-squared error relative to the
true marginal gradient, and under standard smoothness and step-size conditions,
tightens classical convergence bounds for stochastic gradient descent.
Empirically, BVPO improves alignment over the best baseline by up to 7.8 points
on AlpacaEval~2 and 6.8 points on Arena-Hard. Despite being trained only on
general conversational data, BVPO also boosts reasoning performance for base
models by up to 4.0 points on the average of six math reasoning benchmarks.
These results identify variance from trace sampling as a key bottleneck and
demonstrate that directly optimizing the bias--variance trade-off yields more
stable training and stronger overall performance.
\\ ( https://arxiv.org/abs/2510.05095 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05102 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:59:44 GMT   (3130kb)

Title: TopInG: Topologically Interpretable Graph Learning via Persistent
  Rationale Filtration
Authors: Cheng Xin, Fan Xu, Xin Ding, Jie Gao, Jiaxin Ding
Categories: cs.LG cs.AI cs.CG math.AT stat.ML
Comments: submitted to ICML 2025
MSC-class: 55N31, 68T05, 62R40, 05C, 68R05
ACM-class: I.2.6; G.2.2; I.5.1
\\
  Graph Neural Networks (GNNs) have shown remarkable success across various
scientific fields, yet their adoption in critical decision-making is often
hindered by a lack of interpretability. Recently, intrinsically interpretable
GNNs have been studied to provide insights into model predictions by
identifying rationale substructures in graphs. However, existing methods face
challenges when the underlying rationale subgraphs are complex and varied. In
this work, we propose TopInG: Topologically Interpretable Graph Learning, a
novel topological framework that leverages persistent homology to identify
persistent rationale subgraphs. TopInG employs a rationale filtration learning
approach to model an autoregressive generation process of rationale subgraphs,
and introduces a self-adjusted topological constraint, termed topological
discrepancy, to enforce a persistent topological distinction between rationale
subgraphs and irrelevant counterparts. We provide theoretical guarantees that
our loss function is uniquely optimized by the ground truth under specific
conditions. Extensive experiments demonstrate TopInG's effectiveness in
tackling key challenges, such as handling variform rationale subgraphs,
balancing predictive performance with interpretability, and mitigating spurious
correlations. Results show that our approach improves upon state-of-the-art
methods on both predictive accuracy and interpretation quality.
\\ ( https://arxiv.org/abs/2510.05102 ,  3130kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03282 (*cross-listing*)
Date: Sun, 28 Sep 2025 18:34:43 GMT   (1868kb)

Title: Discovering Transformer Circuits via a Hybrid Attribution and Pruning
  Framework
Authors: Hao Gu, Vibhas Nair, Amrithaa Ashok Kumar, Jayvart Sharma, Ryan
  Lagasse
Categories: cs.LG cs.CL
Comments: Accepted to the NeurIPS 2025 Workshop on Mechanistic Interpretability
  (Mechinterp) and the NeurIPS 2025 Workshop on New Perspectives in Graph
  Machine Learning
ACM-class: I.2.6; I.2.7
\\
  Interpreting language models often involves circuit analysis, which aims to
identify sparse subnetworks, or circuits, that accomplish specific tasks.
Existing circuit discovery algorithms face a fundamental trade-off: attribution
patching is fast but unfaithful to the full model, while edge pruning is
faithful but computationally expensive. This research proposes a hybrid
attribution and pruning (HAP) framework that uses attribution patching to
identify a high-potential subgraph, then applies edge pruning to extract a
faithful circuit from it. We show that HAP is 46\% faster than baseline
algorithms without sacrificing circuit faithfulness. Furthermore, we present a
case study on the Indirect Object Identification task, showing that our method
preserves cooperative circuit components (e.g. S-inhibition heads) that
attribution patching methods prune at high sparsity. Our results show that HAP
could be an effective approach for improving the scalability of mechanistic
interpretability research to larger models. Our code is available at
https://anonymous.4open.science/r/HAP-circuit-discovery.
\\ ( https://arxiv.org/abs/2510.03282 ,  1868kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03298 (*cross-listing*)
Date: Mon, 29 Sep 2025 22:07:20 GMT   (522kb)

Title: CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual
  Optimization for On-Device Language Models
Authors: Dongqi Zheng, Wenjin Fu
Categories: cs.LG cs.CL cs.DC
Comments: Accepted by 39th NeurIPS - Constrained Optimization for Machine
  Learning
\\
  We introduce Constraint-Aware Federated Learning with Lagrangian Dual
Optimization (CAFL-L), a principled extension of FedAvg that explicitly
incorporates device-level resource constraints including energy, communication,
memory, and thermal budgets. CAFL-L employs Lagrangian dual optimization to
dynamically adapt training hyperparameters -- freezing depth, local steps,
batch size, and communication compression -- while preserving training
stability through token-budget preservation via gradient accumulation.
Experiments on a character-level language model demonstrate that CAFL-L
achieves superior constraint satisfaction compared to standard FedAvg (reducing
memory usage by 20% and communication by 95%) while maintaining competitive
validation performance, making it practical for deployment on
resource-constrained edge devices.
\\ ( https://arxiv.org/abs/2510.03298 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03394 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:00:00 GMT   (860kb)

Title: Studying the Korean Word-Chain Game with RLVR:Mitigating Reward
  Conflicts via Curriculum Learning
Authors: Donghwan Rho
Categories: cs.LG cs.CL
Comments: 10 pages
\\
  Reinforcement learning with verifiable rewards (RLVR) is a promising approach
for training large language models (LLMs) with stronger reasoning abilities. It
has also been applied to a variety of logic puzzles. In this work, we study the
Korean word-chain game using RLVR. We show that rule-derived rewards can
naturally conflict, and demonstrate through experiments that a
curriculum-learning scheme mitigates these conflicts. Our findings motivate
further studies of puzzle tasks in diverse languages.
\\ ( https://arxiv.org/abs/2510.03394 ,  860kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03437 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:57:22 GMT   (427kb)

Title: Consistent Kernel Change-Point Detection under m-Dependence for Text
  Segmentation
Authors: Jairo Diaz-Rodriguez, Mumin Jia
Categories: cs.LG cs.CL stat.ML
\\
  Kernel change-point detection (KCPD) has become a widely used tool for
identifying structural changes in complex data. While existing theory
establishes consistency under independence assumptions, real-world sequential
data such as text exhibits strong dependencies. We establish new guarantees for
KCPD under $m$-dependent data: specifically, we prove consistency in the number
of detected change points and weak consistency in their locations under mild
additional assumptions. We perform an LLM-based simulation that generates
synthetic $m$-dependent text to validate the asymptotics. To complement these
results, we present the first comprehensive empirical study of KCPD for text
segmentation with modern embeddings. Across diverse text datasets, KCPD with
text embeddings outperforms baselines in standard text segmentation metrics. We
demonstrate through a case study on Taylor Swift's tweets that KCPD not only
provides strong theoretical and simulated reliability but also practical
effectiveness for text segmentation tasks.
\\ ( https://arxiv.org/abs/2510.03437 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03567 (*cross-listing*)
Date: Fri, 3 Oct 2025 23:32:21 GMT   (127kb)

Title: Machine Unlearning Meets Adversarial Robustness via Constrained
  Interventions on LLMs
Authors: Fatmazohra Rezkellah and Ramzi Dakhmouche
Categories: cs.LG cs.CL cs.CR cs.CY math.OC
\\
  With the increasing adoption of Large Language Models (LLMs), more
customization is needed to ensure privacy-preserving and safe generation. We
address this objective from two critical aspects: unlearning of sensitive
information and robustness to jail-breaking attacks. We investigate various
constrained optimization formulations that address both aspects in a
\emph{unified manner}, by finding the smallest possible interventions on LLM
weights that either make a given vocabulary set unreachable or embed the LLM
with robustness to tailored attacks by shifting part of the weights to a
\emph{safer} region. Beyond unifying two key properties, this approach
contrasts with previous work in that it doesn't require an oracle classifier
that is typically not available or represents a computational overhead.
Surprisingly, we find that the simplest point-wise constraint-based
intervention we propose leads to better performance than max-min interventions,
while having a lower computational cost. Comparison against state-of-the-art
defense methods demonstrates superior performance of the proposed approach.
\\ ( https://arxiv.org/abs/2510.03567 ,  127kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03636 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:47:36 GMT   (17kb)

Title: From Theory to Practice: Evaluating Data Poisoning Attacks and Defenses
  in In-Context Learning on Social Media Health Discourse
Authors: Rabeya Amin Jhuma and Mostafa Mohaimen Akand Faisal
Categories: cs.LG cs.CL cs.CR
\\
  This study explored how in-context learning (ICL) in large language models
can be disrupted by data poisoning attacks in the setting of public health
sentiment analysis. Using tweets of Human Metapneumovirus (HMPV), small
adversarial perturbations such as synonym replacement, negation insertion, and
randomized perturbation were introduced into the support examples. Even these
minor manipulations caused major disruptions, with sentiment labels flipping in
up to 67% of cases. To address this, a Spectral Signature Defense was applied,
which filtered out poisoned examples while keeping the data's meaning and
sentiment intact. After defense, ICL accuracy remained steady at around 46.7%,
and logistic regression validation reached 100% accuracy, showing that the
defense successfully preserved the dataset's integrity. Overall, the findings
extend prior theoretical studies of ICL poisoning to a practical, high-stakes
setting in public health discourse analysis, highlighting both the risks and
potential defenses for robust LLM deployment. This study also highlights the
fragility of ICL under attack and the value of spectral defenses in making AI
systems more reliable for health-related social media monitoring.
\\ ( https://arxiv.org/abs/2510.03636 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03669 (*cross-listing*)
Date: Sat, 4 Oct 2025 04:49:44 GMT   (3665kb)

Title: Token Hidden Reward: Steering Exploration-Exploitation in Group Relative
  Deep Reinforcement Learning
Authors: Wenlong Deng, Yi Ren, Yushu Li, Boying Gong, Danica J. Sutherland,
  Xiaoxiao Li, Christos Thrampoulidis
Categories: cs.LG cs.CL
\\
  Reinforcement learning with verifiable rewards has significantly advanced the
reasoning capabilities of large language models, yet how to explicitly steer
training toward exploration or exploitation remains an open problem. We
introduce Token Hidden Reward (THR), a token-level metric that quantifies each
token's influence on the likelihood of correct responses under Group Relative
Policy Optimization (GRPO). We find that training dynamics are dominated by a
small subset of tokens with high absolute THR values. Most interestingly,
tokens with positive THR strengthen confidence in correct outputs, thus
favoring exploitation, while tokens with negative THR preserve probability mass
for alternative outputs, enabling exploration. This insight suggests a natural
intervention: a THR-guided reweighting algorithm that modulates GRPO's learning
signals to explicitly bias training toward exploitation or exploration. We
validate the efficacy of this algorithm on diverse math reasoning benchmarks.
By amplifying tokens with positive THR value and weakening negative ones, our
algorithm improves greedy-decoding accuracy, favoring exploitation. The reverse
strategy yields consistent gains in Pass@K accuracy, favoring exploration. We
further demonstrate that our algorithm integrates seamlessly with other RL
objectives such as GSPO and generalizes across architectures including Llama.
These findings establish THR as a principled and fine-grained mechanism for
dynamically controlling exploration and exploitation in RL-tuned LLMs,
providing new tools for targeted fine-tuning in reasoning-intensive
applications.
\\ ( https://arxiv.org/abs/2510.03669 ,  3665kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03723 (*cross-listing*)
Date: Sat, 4 Oct 2025 08:02:23 GMT   (224kb)

Title: Adapting Diarization-Conditioned Whisper for End-to-End Multi-Talker
  Speech Recognition
Authors: Martin Kocour and Martin Karafiat and Alexander Polok and Dominik
  Klement and Luk\'a\v{s} Burget and Jan \v{C}ernock\'y
Categories: eess.AS cs.CL cs.SD
\\
  We propose a speaker-attributed (SA) Whisper-based model for multi-talker
speech recognition that combines target-speaker modeling with serialized output
training (SOT). Our approach leverages a Diarization-Conditioned Whisper
(DiCoW) encoder to extract target-speaker embeddings, which are concatenated
into a single representation and passed to a shared decoder. This enables the
model to transcribe overlapping speech as a serialized output stream with
speaker tags and timestamps. In contrast to target-speaker ASR systems such as
DiCoW, which decode each speaker separately, our approach performs joint
decoding, allowing the decoder to condition on the context of all speakers
simultaneously. Experiments show that the model outperforms existing SOT-based
approaches and surpasses DiCoW on multi-talker mixtures (e.g., LibriMix).
\\ ( https://arxiv.org/abs/2510.03723 ,  224kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03731 (*cross-listing*)
Date: Sat, 4 Oct 2025 08:34:06 GMT   (152kb)

Title: Optimizing Fine-Tuning through Advanced Initialization Strategies for
  Low-Rank Adaptation
Authors: Yongfu Xue
Categories: cs.LG cs.CL
\\
  The rapid development of parameter-efficient fine-tuning methods has
noticeably improved the efficiency of adapting large language models. Among
these, LoRA has gained widespread popularity due to its strong balance of
effectiveness and parameter efficiency. However, LoRA relies on initializing
two low-rank matrices whose product is zero, which limits its ability to
effectively activate and leverage the original model weights-creating a
potential bottleneck for optimal performance. To address this limitation, we
propose \textbf{IniLoRA}, a novel initialization strategy that initializes the
low-rank matrices to closely approximate the original model weights.
Experimental results indicate that IniLoRA achieves better performance than
LoRA across a range of models and tasks. Additionally, we introduce two
variants, IniLoRA-$\alpha$ and IniLoRA-$\beta$, both leveraging distinct
initialization methods to enhance performance further.
\\ ( https://arxiv.org/abs/2510.03731 ,  152kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03795 (*cross-listing*)
Date: Sat, 4 Oct 2025 12:13:19 GMT   (155kb)

Title: Investigating LLM Variability in Personalized Conversational Information
  Retrieval
Authors: Simon Lupart, Dani\"el van Dijk, Eric Langezaal, Ian van Dort,
  Mohammad Aliannejadi
Categories: cs.IR cs.CL
Comments: 11 pages, 5 figures, SIGIR-AP'25 Proceedings of the 2025 Annual
  International ACM SIGIR Conference on Research and Development in Information
  Retrieval in the Asia Pacific Region (SIGIR-AP 2025), December 7--10, 2025,
  Xi'an, China
\\
  Personalized Conversational Information Retrieval (CIR) has seen rapid
progress in recent years, driven by the development of Large Language Models
(LLMs). Personalized CIR aims to enhance document retrieval by leveraging
user-specific information, such as preferences, knowledge, or constraints, to
tailor responses to individual needs. A key resource for this task is the TREC
iKAT 2023 dataset, designed to evaluate personalization in CIR pipelines.
Building on this resource, Mo et al. explored several strategies for
incorporating Personal Textual Knowledge Bases (PTKB) into LLM-based query
reformulation. Their findings suggested that personalization from PTKBs could
be detrimental and that human annotations were often noisy. However, these
conclusions were based on single-run experiments using the GPT-3.5 Turbo model,
raising concerns about output variability and repeatability. In this
reproducibility study, we rigorously reproduce and extend their work, focusing
on LLM output variability and model generalization. We apply the original
methods to the new TREC iKAT 2024 dataset and evaluate a diverse range of
models, including Llama (1B-70B), Qwen-7B, GPT-4o-mini. Our results show that
human-selected PTKBs consistently enhance retrieval performance, while
LLM-based selection methods do not reliably outperform manual choices. We
further compare variance across datasets and observe higher variability on iKAT
than on CAsT, highlighting the challenges of evaluating personalized CIR.
Notably, recall-oriented metrics exhibit lower variance than precision-oriented
ones, a critical insight for first-stage retrievers. Finally, we underscore the
need for multi-run evaluations and variance reporting when assessing LLM-based
CIR systems. By broadening evaluation across models, datasets, and metrics, our
study contributes to more robust and generalizable practices for personalized
CIR.
\\ ( https://arxiv.org/abs/2510.03795 ,  155kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04010 (*cross-listing*)
Date: Sun, 5 Oct 2025 03:00:58 GMT   (4410kb)

Title: Visual Lifelog Retrieval through Captioning-Enhanced Interpretation
Authors: Yu-Fei Shih, An-Zi Yen, Hen-Hsen Huang, Hsin-Hsi Chen
Categories: cs.IR cs.CL cs.CV cs.MM
Journal-ref: 2024 IEEE International Conference on Big Data (BigData),
  Washington, DC, USA, 2024, pp. 479-486
DOI: 10.1109/BigData62323.2024.10825835
\\
  People often struggle to remember specific details of past experiences, which
can lead to the need to revisit these memories. Consequently, lifelog retrieval
has emerged as a crucial application. Various studies have explored methods to
facilitate rapid access to personal lifelogs for memory recall assistance. In
this paper, we propose a Captioning-Integrated Visual Lifelog (CIVIL) Retrieval
System for extracting specific images from a user's visual lifelog based on
textual queries. Unlike traditional embedding-based methods, our system first
generates captions for visual lifelogs and then utilizes a text embedding model
to project both the captions and user queries into a shared vector space.
Visual lifelogs, captured through wearable cameras, provide a first-person
viewpoint, necessitating the interpretation of the activities of the individual
behind the camera rather than merely describing the scene. To address this, we
introduce three distinct approaches: the single caption method, the collective
caption method, and the merged caption method, each designed to interpret the
life experiences of lifeloggers. Experimental results show that our method
effectively describes first-person visual images, enhancing the outcomes of
lifelog retrieval. Furthermore, we construct a textual dataset that converts
visual lifelogs into captions, thereby reconstructing personal life
experiences.
\\ ( https://arxiv.org/abs/2510.04010 ,  4410kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04304 (*cross-listing*)
Date: Sun, 5 Oct 2025 17:52:52 GMT   (4738kb)

Title: Wave-PDE Nets: Trainable Wave-Equation Layers as an Alternative to
  Attention
Authors: Harshil Vejendla
Categories: cs.LG cs.CL
Comments: PRICAI 2025 Oral, 9 pages, 3 figures
\\
  We introduce Wave-PDE Nets, a neural architecture whose elementary operation
is a differentiable simulation of the second-order wave equation. Each layer
propagates its hidden state as a continuous field through a medium with
trainable spatial velocity c(x) and damping {\gamma}(x). A symplectic spectral
solver based on FFTs realises this propagation in O(nlog n) time. This
oscillatory, global mechanism provides a powerful alternative to attention and
first-order state-space models. We prove that a single Wave-PDE layer is a
universal approximator. On language and vision benchmarks, Wave-PDE Nets match
or exceed Transformer performance while demonstrating superior practical
efficiency, reducing wall-clock time by up to 30% and peak memory by 25%.
Ablation studies confirm the critical role of symplectic integration and a
spectral Laplacian for stability and performance. Visualizations of the learned
physical parameters reveal that the model learns intuitive strategies for
information propagation. These results position Wave-PDE Nets as a
computationally efficient and robust architecture with a strong physical
inductive bias.
\\ ( https://arxiv.org/abs/2510.04304 ,  4738kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04905 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:20:03 GMT   (1425kb)

Title: Retrieval-Augmented Code Generation: A Survey with Focus on
  Repository-Level Approaches
Authors: Yicheng Tao, Yao Qin, Yepang Liu
Categories: cs.SE cs.CL
\\
  Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.
\\ ( https://arxiv.org/abs/2510.04905 ,  1425kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04944 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:46:50 GMT   (188kb)

Title: On Structured State-Space Duality
Authors: Jerry Yao-Chieh Hu, Xiwen Zhang, Weimin Wu, Han Liu
Categories: cs.LG cs.CL cs.CV stat.ML
\\
  Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence
between a simple Structured State-Space Model (SSM) and a masked attention
mechanism. In particular, a state-space model with a scalar-times-identity
state matrix is equivalent to a masked self-attention with a $1$-semiseparable
causal mask. Consequently, the same sequence transformation (model) has two
algorithmic realizations: as a linear-time $O(T)$ recurrence or as a
quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize
this duality: (i) we extend SSD from the scalar-identity case to general
diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs
match the scalar case's training complexity lower bounds while supporting
richer dynamics; (iii) we establish a necessary and sufficient condition under
which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we
show that such duality fails to extend to standard softmax attention due to
rank explosion. Together, these results tighten bridge between recurrent SSMs
and Transformers, and widen the design space for expressive yet efficient
sequence models.
\\ ( https://arxiv.org/abs/2510.04944 ,  188kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05052 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:32:40 GMT   (2461kb)

Title: Proactive defense against LLM Jailbreak
Authors: Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang
Categories: cs.CR cs.CL
\\
  The proliferation of powerful large language models (LLMs) has necessitated
robust safety alignment, yet these models remain vulnerable to evolving
adversarial attacks, including multi-turn jailbreaks that iteratively search
for successful queries. Current defenses, primarily reactive and static, often
fail to counter these search-based attacks. In this paper, we introduce ProAct,
a novel proactive defense framework designed to disrupt and mislead autonomous
jailbreaking processes. Our core idea is to intentionally provide adversaries
with "spurious responses" that appear to be results of successful jailbreak
attacks but contain no actual harmful content. These misleading responses
provide false signals to the attacker's internal optimization loop, causing the
adversarial search to terminate prematurely and effectively jailbreaking the
jailbreak. By conducting extensive experiments across state-of-the-art LLMs,
jailbreaking frameworks, and safety benchmarks, our method consistently and
significantly reduces attack success rates by up to 92\%. When combined with
other defense frameworks, it further reduces the success rate of the latest
attack strategies to 0\%. ProAct represents an orthogonal defense strategy that
can serve as an additional guardrail to enhance LLM safety against the most
effective jailbreaking attacks.
\\ ( https://arxiv.org/abs/2510.05052 ,  2461kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03302 (*cross-listing*)
Date: Tue, 30 Sep 2025 07:46:19 GMT   (40896kb)

Title: Revoking Amnesia: RL-based Trajectory Optimization to Resurrect Erased
  Concepts in Diffusion Models
Authors: Daiheng Gao, Nanxiang Jiang, Andi Zhang, Shilin Lu, Yufei Tang, Wenbo
  Zhou, Weiming Zhang, Zhaoxin Fan
Categories: cs.LG cs.CV
Comments: 21 pages, 10 figures
\\
  Concept erasure techniques have been widely deployed in T2I diffusion models
to prevent inappropriate content generation for safety and copyright
considerations. However, as models evolve to next-generation architectures like
Flux, established erasure methods (\textit{e.g.}, ESD, UCE, AC) exhibit
degraded effectiveness, raising questions about their true mechanisms. Through
systematic analysis, we reveal that concept erasure creates only an illusion of
``amnesia": rather than genuine forgetting, these methods bias sampling
trajectories away from target concepts, making the erasure fundamentally
reversible. This insight motivates the need to distinguish superficial safety
from genuine concept removal. In this work, we propose \textbf{RevAm}
(\underline{Rev}oking \underline{Am}nesia), an RL-based trajectory optimization
framework that resurrects erased concepts by dynamically steering the denoising
process without modifying model weights. By adapting Group Relative Policy
Optimization (GRPO) to diffusion models, RevAm explores diverse recovery
trajectories through trajectory-level rewards, overcoming local optima that
limit existing methods. Extensive experiments demonstrate that RevAm achieves
superior concept resurrection fidelity while reducing computational time by
10$\times$, exposing critical vulnerabilities in current safety mechanisms and
underscoring the need for more robust erasure techniques beyond trajectory
manipulation.
\\ ( https://arxiv.org/abs/2510.03302 ,  40896kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03312 (*cross-listing*)
Date: Tue, 30 Sep 2025 22:03:22 GMT   (13100kb)

Title: Universal Beta Splatting
Authors: Rong Liu, Zhongpai Gao, Benjamin Planche, Meida Chen, Van Nguyen
  Nguyen, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Yue Wang, Andrew Feng,
  Ziyan Wu
Categories: cs.GR cs.CV eess.IV
\\
  We introduce Universal Beta Splatting (UBS), a unified framework that
generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for
explicit radiance field rendering. Unlike fixed Gaussian primitives, Beta
kernels enable controllable dependency modeling across spatial, angular, and
temporal dimensions within a single representation. Our unified approach
captures complex light transport effects, handles anisotropic view-dependent
appearance, and models scene dynamics without requiring auxiliary networks or
specific color encodings. UBS maintains backward compatibility by approximating
to Gaussian Splatting as a special case, guaranteeing plug-in usability and
lower performance bounds. The learned Beta parameters naturally decompose scene
properties into interpretable without explicit supervision: spatial (surface
vs. texture), angular (diffuse vs. specular), and temporal (static vs.
dynamic). Our CUDA-accelerated implementation achieves real-time rendering
while consistently outperforming existing methods across static,
view-dependent, and dynamic benchmarks, establishing Beta kernels as a scalable
universal primitive for radiance field rendering. Our project website is
available at https://rongliu-leo.github.io/universal-beta-splatting/.
\\ ( https://arxiv.org/abs/2510.03312 ,  13100kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03375 (*cross-listing*)
Date: Fri, 3 Oct 2025 13:34:19 GMT   (1365kb)

Title: Conditional Pseudo-Supervised Contrast for Data-Free Knowledge
  Distillation
Authors: Renrong Shao and Wei Zhang and Jun wang
Categories: cs.LG cs.CV
Comments: 13 pages
Journal-ref: Pattern Recognition (2023)
DOI: 10.1016/j.patcog.2023.109781
\\
  Data-free knowledge distillation~(DFKD) is an effective manner to solve model
compression and transmission restrictions while retaining privacy protection,
which has attracted extensive attention in recent years. Currently, the
majority of existing methods utilize a generator to synthesize images to
support the distillation. Although the current methods have achieved great
success, there are still many issues to be explored. Firstly, the outstanding
performance of supervised learning in deep learning drives us to explore a
pseudo-supervised paradigm on DFKD. Secondly, current synthesized methods
cannot distinguish the distributions of different categories of samples, thus
producing ambiguous samples that may lead to an incorrect evaluation by the
teacher. Besides, current methods cannot optimize the category-wise diversity
samples, which will hinder the student model learning from diverse samples and
further achieving better performance. In this paper, to address the above
limitations, we propose a novel learning paradigm, i.e., conditional
pseudo-supervised contrast for data-free knowledge distillation~(CPSC-DFKD).
The primary innovations of CPSC-DFKD are: (1) introducing a conditional
generative adversarial network to synthesize category-specific diverse images
for pseudo-supervised learning, (2) improving the modules of the generator to
distinguish the distributions of different categories, and (3) proposing
pseudo-supervised contrastive learning based on teacher and student views to
enhance diversity. Comprehensive experiments on three commonly-used datasets
validate the performance lift of both the student and generator brought by
CPSC-DFKD. The code is available at https://github.com/RoryShao/CPSC-DFKD.git
\\ ( https://arxiv.org/abs/2510.03375 ,  1365kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03532 (*cross-listing*)
Date: Fri, 3 Oct 2025 22:03:28 GMT   (20434kb)

Title: Efficient Surgical Robotic Instrument Pose Reconstruction in Real World
  Conditions Using Unified Feature Detection
Authors: Zekai Liang, Kazuya Miyata, Xiao Liang, Florian Richter, Michael C.
  Yip
Categories: cs.RO cs.CV
\\
  Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.
\\ ( https://arxiv.org/abs/2510.03532 ,  20434kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03568 (*cross-listing*)
Date: Fri, 3 Oct 2025 23:32:35 GMT   (450kb)

Title: How We Won BraTS-SSA 2025: Brain Tumor Segmentation in the Sub-Saharan
  African Population Using Segmentation-Aware Data Augmentation and Model
  Ensembling
Authors: Claudia Takyi Ankomah, Livingstone Eli Ayivor, Ireneaus Nyame, Leslie
  Wambo, Patrick Yeboah Bonsu, Aondona Moses Iorumbur, Raymond Confidence,
  Toufiq Musah
Categories: eess.IV cs.CV
Comments: Brain Tumor Segmentation Challenge, Medical Image Computing and
  Computer Assisted Intervention (MICCAI) Conference, 11 Pages, 2 Figures, 2
  Tables
\\
  Brain tumors, particularly gliomas, pose significant chall-enges due to their
complex growth patterns, infiltrative nature, and the variability in brain
structure across individuals, which makes accurate diagnosis and monitoring
difficult. Deep learning models have been developed to accurately delineate
these tumors. However, most of these models were trained on relatively
homogenous high-resource datasets, limiting their robustness when deployed in
underserved regions. In this study, we performed segmentation-aware offline
data augmentation on the BraTS-Africa dataset to increase the data sample size
and diversity to enhance generalization. We further constructed an ensemble of
three distinct architectures, MedNeXt, SegMamba, and Residual-Encoder U-Net, to
leverage their complementary strengths. Our best-performing model, MedNeXt, was
trained on 1000 epochs and achieved the highest average lesion-wise dice and
normalized surface distance scores of 0.86 and 0.81 respectively. However, the
ensemble model trained for 500 epochs produced the most balanced segmentation
performance across the tumour subregions. This work demonstrates that a
combination of advanced augmentation and model ensembling can improve
segmentation accuracy and robustness on diverse and underrepresented datasets.
Code available at:
https://github.com/SPARK-Academy-2025/SPARK-2025/tree/main/SPARK2025_BraTs_MODELS/SPARK_NeuroAshanti
\\ ( https://arxiv.org/abs/2510.03568 ,  450kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03574 (*cross-listing*)
Date: Fri, 3 Oct 2025 23:49:06 GMT   (14306kb)

Title: Efficient Test-Time Scaling for Small Vision-Language Models
Authors: Mehmet Onurcan Kaya, Desmond Elliott, Dim P. Papadopoulos
Categories: cs.LG cs.CV
\\
  Small Vision-Language Models (VLMs) provide a computationally efficient
alternative to larger models, at the cost of weaker generalization abilities
and downstream task performance. These shortcomings could be addressed by
test-time scaling techniques, but existing methods are typically
computationally demanding, contradicting the resource-efficient design goals of
small models. To address these limitations, we propose two novel and efficient
test-time scaling strategies that leverage the model-internal features rather
than external supervision: (i) Test-Time Augmentation (TTAug), which generates
multiple augmented inputs and aggregates outputs at the token level without
parameter updates, and (ii) Test-Time Adaptation (TTAdapt), which adapts model
parameters during inference using consensus-based pseudolabels from TTAug.
Through extensive experiments across nine benchmarks, we demonstrate consistent
performance improvements while maintaining computational efficiency suitable
for resource-constrained environments. The generality of our approach is
demonstrated both within models at different scales and across different VLMs
without additional tuning.
\\ ( https://arxiv.org/abs/2510.03574 ,  14306kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03684 (*cross-listing*)
Date: Sat, 4 Oct 2025 05:54:18 GMT   (44186kb)

Title: Model-Guided Microstimulation Steers Primate Visual Behavior
Authors: Johannes Mehrer, Ben Lonnqvist, Anna Mitola, Abdulkadir Gokce, Paolo
  Papale, Martin Schrimpf
Categories: q-bio.NC cs.CV
\\
  Brain stimulation is a powerful tool for understanding cortical function and
holds promise for therapeutic interventions in neuropsychiatric disorders.
Initial visual prosthetics apply electric microstimulation to early visual
cortex which can evoke percepts of simple symbols such as letters. However,
these approaches are fundamentally limited by hardware constraints and the
low-level representational properties of this cortical region. In contrast,
higher-level visual areas encode more complex object representations and
therefore constitute a promising target for stimulation - but determining
representational targets that reliably evoke object-level percepts constitutes
a major challenge. We here introduce a computational framework to causally
model and guide stimulation of high-level cortex, comprising three key
components: (1) a perturbation module that translates microstimulation
parameters into spatial changes to neural activity, (2) topographic models that
capture the spatial organization of cortical neurons and thus enable
prototyping of stimulation experiments, and (3) a mapping procedure that links
model-optimized stimulation sites back to primate cortex. Applying this
framework in two macaque monkeys performing a visual recognition task,
model-predicted stimulation experiments produced significant in-vivo changes in
perceptual choices. Per-site model predictions and monkey behavior were
strongly correlated, underscoring the promise of model-guided stimulation.
Image generation further revealed a qualitative similarity between in-silico
stimulation of face-selective sites and a patient's report of facephenes. This
proof-of-principle establishes a foundation for model-guided microstimulation
and points toward next-generation visual prosthetics capable of inducing more
complex visual experiences.
\\ ( https://arxiv.org/abs/2510.03684 ,  44186kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03833 (*cross-listing*)
Date: Sat, 4 Oct 2025 15:23:07 GMT   (5213kb)

Title: Towards Robust and Generalizable Continuous Space-Time Video
  Super-Resolution with Events
Authors: Shuoyan Wei, Feng Li, Shengeng Tang, Runmin Cong, Yao Zhao, Meng Wang,
  Huihui Bai
Categories: eess.IV cs.CV cs.MM
Comments: 17 pages, 12 figures, 14 tables. Under review
\\
  Continuous space-time video super-resolution (C-STVSR) has garnered
increasing interest for its capability to reconstruct high-resolution and
high-frame-rate videos at arbitrary spatial and temporal scales. However,
prevailing methods often generalize poorly, producing unsatisfactory results
when applied to out-of-distribution (OOD) scales. To overcome this limitation,
we present EvEnhancer, a novel approach that marries the unique properties of
high temporal resolution and high dynamic range encapsulated in event streams
to achieve robust and generalizable C-STVSR. Our approach incorporates
event-adapted synthesis that capitalizes on the spatiotemporal correlations
between frames and events to capture long-term motion trajectories, enabling
adaptive interpolation and fusion across space and time. This is then coupled
with a local implicit video transformer that integrates local implicit video
neural function with cross-scale spatiotemporal attention to learn continuous
video representations and generate plausible videos at arbitrary resolutions
and frame rates. We further develop EvEnhancerPlus, which builds a controllable
switching mechanism that dynamically determines the reconstruction difficulty
for each spatiotemporal pixel based on local event statistics. This allows the
model to adaptively route reconstruction along the most suitable pathways at a
fine-grained pixel level, substantially reducing computational overhead while
maintaining excellent performance. Furthermore, we devise a cross-derivative
training strategy that stabilizes the convergence of such a multi-pathway
framework through staged cross-optimization. Extensive experiments demonstrate
that our method achieves state-of-the-art performance on both synthetic and
real-world datasets, while maintaining superior generalizability at OOD scales.
The code is available at https://github.com/W-Shuoyan/EvEnhancerPlus.
\\ ( https://arxiv.org/abs/2510.03833 ,  5213kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03837 (*cross-listing*)
Date: Sat, 4 Oct 2025 15:29:36 GMT   (2843kb)

Title: Joint Neural SDF Reconstruction and Semantic Segmentation for CAD Models
Authors: Shen Fan and Przemyslaw Musialski
Categories: cs.GR cs.CV
\\
  We propose a simple, data-efficient pipeline that augments an implicit
reconstruction network based on neural SDF-based CAD parts with a
part-segmentation head trained under PartField-generated supervision. Unlike
methods tied to fixed taxonomies, our model accepts meshes with any number of
parts and produces coherent, geometry-aligned labels in a single pass. We
evaluate on randomly sampled CAD meshes from the ABC dataset with intentionally
varied part cardinalities, including over-segmented shapes, and report strong
performance across reconstruction (CDL1/CDL2, F1-micro, NC) and segmentation
(mIoU, Accuracy), together with a new Segmentation Consistency metric that
captures local label smoothness. We attach a lightweight segmentation head to
the Flat-CAD SDF trunk; on a paired evaluation it does not alter reconstruction
while providing accurate part labels for meshes with any number of parts. Even
under degraded reconstructions on thin or intricate geometries, segmentation
remains accurate and label-coherent, often preserving the correct part count.
Our approach therefore offers a practical route to semantically structured CAD
meshes without requiring curated taxonomies or exact palette matches. We
discuss limitations in boundary precision, partly due to per-face supervision,
and outline paths toward boundary-aware training and higher resolution labels.
\\ ( https://arxiv.org/abs/2510.03837 ,  2843kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03895 (*cross-listing*)
Date: Sat, 4 Oct 2025 18:26:55 GMT   (43997kb)

Title: NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot
  Manipulation
Authors: Zheng Huang, Mingyu Liu, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du,
  Xiaoman Li, Yiduo Jia, Hao Zhong, Hao Chen, Chunhua Shen
Categories: cs.RO cs.CV
\\
  Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.
\\ ( https://arxiv.org/abs/2510.03895 ,  43997kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03926 (*cross-listing*)
Date: Sat, 4 Oct 2025 20:11:43 GMT   (801kb)

Title: Sliding Window Attention for Learned Video Compression
Authors: Alexander Kopte and Andr\'e Kaup
Categories: eess.IV cs.CV
Comments: Accepted for PCS 2025
\\
  To manage the complexity of transformers in video compression, local
attention mechanisms are a practical necessity. The common approach of
partitioning frames into patches, however, creates architectural flaws like
irregular receptive fields. When adapted for temporal autoregressive models,
this paradigm, exemplified by the Video Compression Transformer (VCT), also
necessitates computationally redundant overlapping windows. This work
introduces 3D Sliding Window Attention (SWA), a patchless form of local
attention. By enabling a decoder-only architecture that unifies spatial and
temporal context processing, and by providing a uniform receptive field, our
method significantly improves rate-distortion performance, achieving
Bj{\o}rntegaard Delta-rate savings of up to 18.6 % against the VCT baseline.
Simultaneously, by eliminating the need for overlapping windows, our method
reduces overall decoder complexity by a factor of 2.8, while its entropy model
is nearly 3.5 times more efficient. We further analyze our model's behavior and
show that while it benefits from long-range temporal context, excessive context
can degrade performance.
\\ ( https://arxiv.org/abs/2510.03926 ,  801kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03938 (*cross-listing*)
Date: Sat, 4 Oct 2025 20:42:57 GMT   (1646kb)

Title: Super-resolution image projection over an extended depth of field using
  a diffractive decoder
Authors: Hanlong Chen, Cagatay Isil, Tianyi Gan, Mona Jarrahi, Aydogan Ozcan
Categories: physics.optics cs.CV cs.NE physics.app-ph
Comments: 18 Pages, 6 Figures
\\
  Image projection systems must be efficient in data storage, computation and
transmission while maintaining a large space-bandwidth-product (SBP) at their
output. Here, we introduce a hybrid image projection system that achieves
extended depth-of-field (DOF) with improved resolution, combining a
convolutional neural network (CNN)-based digital encoder with an all-optical
diffractive decoder. A CNN-based encoder compresses input images into compact
phase representations, which are subsequently displayed by a low-resolution
(LR) projector and processed by an analog diffractive decoder for all-optical
image reconstruction. This optical decoder is completely passive, designed to
synthesize pixel super-resolved image projections that feature an extended DOF
while eliminating the need for additional power consumption for super-resolved
image reconstruction. Our pixel super-resolution (PSR) image projection system
demonstrates high-fidelity image synthesis over an extended DOF of ~267xW,
where W is the illumination wavelength, concurrently offering up to ~16-fold
SBP improvement at each lateral plane. The proof of concept of this approach is
validated through an experiment conducted in the THz spectrum, and the system
is scalable across different parts of the electromagnetic spectrum. This image
projection architecture can reduce data storage and transmission requirements
for display systems without imposing additional power constraints on the
optical decoder. Beyond extended DOF PSR image projection, the underlying
principles of this approach can be extended to various applications, including
optical metrology and microscopy.
\\ ( https://arxiv.org/abs/2510.03938 ,  1646kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03974 (*cross-listing*)
Date: Sat, 4 Oct 2025 23:23:49 GMT   (10452kb)

Title: Use of Quadcopter Wakes to Supplement Strawberry Pollination
Authors: Sadie Cutler, Ben DeFay, Scott McArt, Kirstin Petersen
Categories: eess.SY cs.CV cs.SY
Comments: 7 pages, 7 figures
\\
  Pollinators are critical to the world's ecosystems and food supply, yet
recent studies have found pollination shortfalls in several crops, including
strawberry. This is troubling because wild and managed pollinators are
currently experiencing declines. One possibility is to try and provide
supplemental pollination solutions. These solutions should be affordable and
simple for farmers to implement if their use is to be widespread; quadcopters
are a great example, already used for monitoring on many farms. This paper
investigates a new method for artificial pollination based on wind pollination
that bears further investigation. After determining the height where the
lateral flow is maximized, we performed field experiments with a quadcopter
assisting natural pollinators. Although our results in the field were
inconclusive, lab studies show that the idea shows promise and could be adapted
for better field results.
\\ ( https://arxiv.org/abs/2510.03974 ,  10452kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04136 (*cross-listing*)
Date: Sun, 5 Oct 2025 10:34:34 GMT   (5879kb)

Title: MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition
Authors: Umberto Cappellazzo, Minsu Kim, Pingchuan Ma, Honglie Chen, Xubo Liu,
  Stavros Petridis, Maja Pantic
Categories: eess.AS cs.CV cs.SD
Comments: NeurIPS 2025
\\
  Large language models (LLMs) have recently shown strong potential in
audio-visual speech recognition (AVSR), but their high computational demands
and sensitivity to token granularity limit their practicality in
resource-constrained settings. Token compression methods can reduce inference
cost, but they require fixing a compression rate in advance and produce a
single fixed-length output, offering no flexibility to balance information
density and efficiency at inference time. Matryoshka representation learning
(MRL) addresses this by enabling a single model to operate across multiple
token granularities, allowing compression rates to be adjusted dynamically.
However, current MRL-based methods treat each scale independently during
training, limiting cross-scale generalization, robustness at high compression,
and interpretability. To overcome these limitations, we propose MoME (Mixture
of Matryoshka Experts), a novel framework that integrates sparse
Mixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen
LLM with top-k routed and shared experts, allowing dynamic capacity allocation
across scales and modalities. A shared router promotes consistent expert
activation across granularities, enabling compressed sequences to benefit from
representations learned at lower compression. Experiments on LRS2 and LRS3
demonstrate that MoME achieves state-of-the-art performance across AVSR, ASR,
and VSR tasks, while requiring significantly fewer parameters and maintaining
robustness under noise. MoME unifies the adaptability of MRL with the
efficiency of MoE, offering a scalable and interpretable solution for
resource-aware speech recognition.
\\ ( https://arxiv.org/abs/2510.04136 ,  5879kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04331 (*cross-listing*)
Date: Sun, 5 Oct 2025 19:27:48 GMT   (1406kb)

Title: DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise
  Injection and Auxiliary Networks
Authors: Nghiem T. Diep, Hien Dang, Tuan Truong, Tan Dinh, Huy Nguyen, Nhat Ho
Categories: cs.LG cs.CV
Comments: Nghiem T. Diep, Hien Dang, and Tuan Truong contributed equally to
  this work
\\
  Parameter-efficient fine-tuning (PEFT) methods have become the standard
paradigm for adapting large-scale models. Among these techniques,
Weight-Decomposed Low-Rank Adaptation (DoRA) has been shown to improve both the
learning capacity and training stability of the vanilla Low-Rank Adaptation
(LoRA) method by explicitly decomposing pre-trained weights into magnitude and
directional components. In this work, we propose DoRAN, a new variant of DoRA
designed to further stabilize training and boost the sample efficiency of DoRA.
Our approach includes two key stages: (i) injecting noise into the denominator
of DoRA's weight decomposition, which serves as an adaptive regularizer to
mitigate instabilities; and (ii) replacing static low-rank matrices with
auxiliary networks that generate them dynamically, enabling parameter coupling
across layers and yielding better sample efficiency in both theory and
practice. Comprehensive experiments on vision and language benchmarks show that
DoRAN consistently outperforms LoRA, DoRA, and other PEFT baselines. These
results underscore the effectiveness of combining stabilization through
noise-based regularization with network-based parameter generation, offering a
promising direction for robust and efficient fine-tuning of foundation models.
\\ ( https://arxiv.org/abs/2510.04331 ,  1406kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04369 (*cross-listing*)
Date: Sun, 5 Oct 2025 21:24:44 GMT   (3857kb)

Title: The method of the approximate inverse for limited-angle CT
Authors: Bernadette Hahn, Gael Rigaud and Richard Schm\"ahl
Categories: eess.IV cs.CV cs.NA math.NA
\\
  Limited-angle computerized tomography stands for one of the most difficult
challenges in imaging. Although it opens the way to faster data acquisition in
industry and less dangerous scans in medicine, standard approaches, such as the
filtered backprojection (FBP) algorithm or the widely used total-variation
functional, often produce various artefacts that hinder the diagnosis. With the
rise of deep learning, many modern techniques have proven themselves successful
in removing such artefacts but at the cost of large datasets. In this paper, we
propose a new model-driven approach based on the method of the approximate
inverse, which could serve as new starting point for learning strategies in the
future. In contrast to FBP-type approaches, our reconstruction step consists in
evaluating linear functionals on the measured data using reconstruction kernels
that are precomputed as solution of an auxiliary problem. With this problem
being uniquely solvable, the derived limited-angle reconstruction kernel (LARK)
is able to fully reconstruct the object without the well-known streak
artefacts, even for large limited angles. However, it inherits severe
ill-conditioning which leads to a different kind of artefacts arising from the
singular functions of the limited-angle Radon transform. The problem becomes
particularly challenging when working on semi-discrete (real or analytical)
measurements. We develop a general regularization strategy, named constrained
limited-angle reconstruction kernel (CLARK), by combining spectral filter, the
method of the approximate inverse and custom edge-preserving denoising in order
to stabilize the whole process. We further derive and interpret error estimates
for the application on real, i.e. semi-discrete, data and we validate our
approach on synthetic and real data.
\\ ( https://arxiv.org/abs/2510.04369 ,  3857kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04382 (*cross-listing*)
Date: Sun, 5 Oct 2025 22:26:06 GMT   (6598kb)

Title: Adaptive double-phase Rudin--Osher--Fatemi denoising model
Authors: Wojciech G\'orny, Micha{\l} {\L}asica, Alexandros Matsoukas
Categories: eess.IV cs.CV cs.NA math.NA
Comments: 21 pages, 18 figures, supplementary material available at:
  https://github.com/wojciechgorny/double-phase-ROF-model/
\\
  We propose a new image denoising model based on a variable-growth total
variation regularization of double-phase type with adaptive weight. It is
designed to reduce staircasing with respect to the classical
Rudin--Osher--Fatemi model, while preserving the edges of the image in a
similar fashion. We implement the model and test its performance on synthetic
and natural images in 1D and 2D over a range of noise levels.
\\ ( https://arxiv.org/abs/2510.04382 ,  6598kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04510 (*cross-listing*)
Date: Mon, 6 Oct 2025 06:00:08 GMT   (4112kb)

Title: Real-time Prediction of Urban Sound Propagation with Conditioned
  Normalizing Flows
Authors: Achim Eckerle, Martin Spitznagel, Janis Keuper
Categories: cs.LG cs.CV
\\
  Accurate and fast urban noise prediction is pivotal for public health and for
regulatory workflows in cities, where the Environmental Noise Directive
mandates regular strategic noise maps and action plans, often needed in
permission workflows, right-of-way allocation, and construction scheduling.
Physics-based solvers are too slow for such time-critical, iterative "what-if"
studies. We evaluate conditional Normalizing Flows (Full-Glow) for generating
for generating standards-compliant urban sound-pressure maps from 2D urban
layouts in real time per 256x256 map on a single RTX 4090), enabling
interactive exploration directly on commodity hardware. On datasets covering
Baseline, Diffraction, and Reflection regimes, our model accelerates map
generation by >2000 times over a reference solver while improving NLoS accuracy
by up to 24% versus prior deep models; in Baseline NLoS we reach 0.65 dB MAE
with high structural fidelity. The model reproduces diffraction and
interference patterns and supports instant recomputation under source or
geometry changes, making it a practical engine for urban planning, compliance
mapping, and operations (e.g., temporary road closures, night-work variance
assessments).
\\ ( https://arxiv.org/abs/2510.04510 ,  4112kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04539 (*cross-listing*)
Date: Mon, 6 Oct 2025 07:07:14 GMT   (6084kb)

Title: C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing
Authors: Zeng Tao, Zheng Ding, Zeyuan Chen, Xiang Zhang, Leizhi Li, Zhuowen Tu
Categories: cs.GR cs.CV
\\
  Existing 2D-lifting-based 3D editing methods often encounter challenges
related to inconsistency, stemming from the lack of view-consistent 2D editing
models and the difficulty of ensuring consistent editing across multiple views.
To address these issues, we propose C3Editor, a controllable and consistent
2D-lifting-based 3D editing framework. Given an original 3D representation and
a text-based editing prompt, our method selectively establishes a
view-consistent 2D editing model to achieve superior 3D editing results. The
process begins with the controlled selection of a ground truth (GT) view and
its corresponding edited image as the optimization target, allowing for
user-defined manual edits. Next, we fine-tune the 2D editing model within the
GT view and across multiple views to align with the GT-edited image while
ensuring multi-view consistency. To meet the distinct requirements of GT view
fitting and multi-view consistency, we introduce separate LoRA modules for
targeted fine-tuning. Our approach delivers more consistent and controllable 2D
and 3D editing results than existing 2D-lifting-based methods, outperforming
them in both qualitative and quantitative evaluations.
\\ ( https://arxiv.org/abs/2510.04539 ,  6084kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04547 (*cross-listing*)
Date: Mon, 6 Oct 2025 07:27:46 GMT   (3171kb)

Title: Post-training quantization of vision encoders needs prefixing registers
Authors: Seunghyeon Kim, Jinho Kim, Taesun Yeom, Wonpyo Park, Kyuyeun Kim,
  Jaeho Lee
Categories: cs.LG cs.CV
\\
  Transformer-based vision encoders -- such as CLIP -- are central to
multimodal intelligence, powering applications from autonomous web agents to
robotic control. Since these applications often demand real-time processing of
massive visual data, reducing the inference cost of vision encoders is
critical. Post-training quantization offers a practical path, but remains
challenging even at 8-bit precision due to massive-scale activations (i.e.,
outliers). In this work, we propose $\textit{RegCache}$, a training-free
algorithm to mitigate outliers in vision encoders, enabling quantization with
significantly smaller accuracy drops. The proposed RegCache introduces
outlier-prone yet semantically meaningless prefix tokens to the target vision
encoder, which prevents other tokens from having outliers. Notably, we observe
that outliers in vision encoders behave differently from those in language
models, motivating two technical innovations: middle-layer prefixing and token
deletion. Experiments show that our method consistently improves the accuracy
of quantized models across both text-supervised and self-supervised vision
encoders.
\\ ( https://arxiv.org/abs/2510.04547 ,  3171kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04553 (*cross-listing*)
Date: Mon, 6 Oct 2025 07:34:21 GMT   (11kb)

Title: Fast Witness Persistence for MRI Volumes via Hybrid Landmarking
Authors: Jorge Leonardo Ruiz Williams
Categories: cs.CG cs.CV cs.LG
\\
  We introduce a scalable witness-based persistent homology pipeline for
full-brain MRI volumes that couples density-aware landmark selection with a
GPU-ready witness filtration. Candidates are scored by a hybrid metric that
balances geometric coverage against inverse kernel density, yielding landmark
sets that shrink mean pairwise distances by 30-60% over random or density-only
baselines while preserving topological features. Benchmarks on BrainWeb, IXI,
and synthetic manifolds execute in under ten seconds on a single NVIDIA RTX
4090 GPU, avoiding the combinatorial blow-up of Cech, Vietoris-Rips, and alpha
filtrations. The package is distributed on PyPI as whale-tda (installable via
pip); source and issues are hosted at https://github.com/jorgeLRW/whale. The
release also exposes a fast preset (mri_deep_dive_fast) for exploratory sweeps,
and ships with reproducibility-focused scripts and artifacts for drop-in use in
medical imaging workflows.
\\ ( https://arxiv.org/abs/2510.04553 ,  11kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04637 (*cross-listing*)
Date: Mon, 6 Oct 2025 09:41:37 GMT   (8928kb)

Title: Social Agent: Mastering Dyadic Nonverbal Behavior Generation via
  Conversational LLM Agents
Authors: Zeyi Zhang, Yanju Zhou, Heyuan Yao, Tenglong Ao, Xiaohang Zhan, Libin
  Liu
Categories: cs.GR cs.CV
Comments: SIGGRAPH ASIA 2025 (Conference Track); Project page:
  https://pku-mocca.github.io/Social-Agent-Page/
DOI: 10.1145/3757377.3763879
\\
  We present Social Agent, a novel framework for synthesizing realistic and
contextually appropriate co-speech nonverbal behaviors in dyadic conversations.
In this framework, we develop an agentic system driven by a Large Language
Model (LLM) to direct the conversation flow and determine appropriate
interactive behaviors for both participants. Additionally, we propose a novel
dual-person gesture generation model based on an auto-regressive diffusion
model, which synthesizes coordinated motions from speech signals. The output of
the agentic system is translated into high-level guidance for the gesture
generator, resulting in realistic movement at both the behavioral and motion
levels. Furthermore, the agentic system periodically examines the movements of
interlocutors and infers their intentions, forming a continuous feedback loop
that enables dynamic and responsive interactions between the two participants.
User studies and quantitative evaluations show that our model significantly
improves the quality of dyadic interactions, producing natural, synchronized
nonverbal behaviors.
\\ ( https://arxiv.org/abs/2510.04637 ,  8928kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04883 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:04:56 GMT   (9823kb)

Title: CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery
Authors: Nathan Shankar, Pawel Ladosz and Hujun Yin
Categories: cs.RO cs.CV cs.LG
Comments: 8 pages, 8 figures
\\
  This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.
\\ ( https://arxiv.org/abs/2510.04883 ,  9823kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05057 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:37:24 GMT   (15075kb)

Title: StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact
  State Representation
Authors: Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang,
  Shenyuan Gao, Hao Chen, Chunhua Shen
Categories: cs.RO cs.CV
\\
  A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.
\\ ( https://arxiv.org/abs/2510.05057 ,  15075kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05097 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:58:34 GMT   (1756kb)

Title: Pulp Motion: Framing-aware multimodal camera and human motion generation
Authors: Robin Courant, Xi Wang, David Loiseaux, Marc Christie and Vicky
  Kalogeiton
Categories: cs.GR cs.CV
Comments: Project page:
  https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/
\\
  Treating human motion and camera trajectory generation separately overlooks a
core principle of cinematography: the tight interplay between actor performance
and camera work in the screen space. In this paper, we are the first to cast
this task as a text-conditioned joint generation, aiming to maintain consistent
on-screen framing while producing two heterogeneous, yet intrinsically linked,
modalities: human motion and camera trajectories. We propose a simple,
model-agnostic framework that enforces multimodal coherence via an auxiliary
modality: the on-screen framing induced by projecting human joints onto the
camera. This on-screen framing provides a natural and effective bridge between
modalities, promoting consistency and leading to more precise joint
distribution. We first design a joint autoencoder that learns a shared latent
space, together with a lightweight linear transform from the human and camera
latents to a framing latent. We then introduce auxiliary sampling, which
exploits this linear transform to steer generation toward a coherent framing
modality. To support this task, we also introduce the PulpMotion dataset, a
human-motion and camera-trajectory dataset with rich captions, and high-quality
human motions. Extensive experiments across DiT- and MAR-based architectures
show the generality and effectiveness of our method in generating on-frame
coherent human-camera motions, while also achieving gains on textual alignment
for both modalities. Our qualitative results yield more cinematographically
meaningful framings setting the new state of the art for this task. Code,
models and data are available in our
\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project
page}.
\\ ( https://arxiv.org/abs/2510.05097 ,  1756kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03334 (*cross-listing*)
Date: Thu, 2 Oct 2025 02:01:02 GMT   (845kb)

Title: Semantic-Aware Scheduling for GPU Clusters with Large Language Models
Authors: Zerui Wang, Qinghao Hu, Ana Klimovic, Tianwei Zhang, Yonggang Wen,
  Peng Sun, Dahua Lin
Categories: cs.LG cs.DC
\\
  Deep learning (DL) schedulers are pivotal in optimizing resource allocation
in GPU clusters, but operate with a critical limitation: they are largely blind
to the semantic context of the jobs they manage. This forces them to rely on
limited metadata, leading to high profiling overhead, unreliable duration
estimation, inadequate failure handling, and poor observability. To this end,
we propose SchedMate, a framework that bridges this semantic gap by
systematically extracting deep insights from overlooked, unstructured data
sources: source code, runtime logs, and historical jobs. SchedMate enhances
existing schedulers non-intrusively through three LLM-based components. Our
implementation integrates seamlessly with existing deep learning schedulers.
Evaluations on a 128-GPU physical cluster and extensive simulations on
production traces show SchedMate reduces average job completion times by up to
1.91x, substantially enhancing the scheduling performance, demonstrating the
critical role of semantic-awareness in modern DL scheduling.
\\ ( https://arxiv.org/abs/2510.03334 ,  845kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03434 (*cross-listing*)
Date: Fri, 3 Oct 2025 18:53:12 GMT   (1848kb)

Title: Paris: A Decentralized Trained Open-Weight Diffusion Model
Authors: Zhiying Jiang, Raihan Seraj, Marcos Villagra, Bidhan Roy
Categories: cs.GR cs.DC cs.LG
\\
  We present Paris, the first publicly released diffusion model pre-trained
entirely through decentralized computation. Paris demonstrates that
high-quality text-to-image generation can be achieved without centrally
coordinated infrastructure. Paris is open for research and commercial use.
Paris required implementing our Distributed Diffusion Training framework from
scratch. The model consists of 8 expert diffusion models (129M-605M parameters
each) trained in complete isolation with no gradient, parameter, or
intermediate activation synchronization. Rather than requiring synchronized
gradient updates across thousands of GPUs, we partition data into semantically
coherent clusters where each expert independently optimizes its subset while
collectively approximating the full distribution. A lightweight transformer
router dynamically selects appropriate experts at inference, achieving
generation quality comparable to centrally coordinated baselines. Eliminating
synchronization enables training on heterogeneous hardware without specialized
interconnects. Empirical validation confirms that Paris's decentralized
training maintains generation quality while removing the dedicated GPU cluster
requirement for large-scale diffusion models. Paris achieves this using
14$\times$ less training data and 16$\times$ less compute than the prior
decentralized baseline.
\\ ( https://arxiv.org/abs/2510.03434 ,  1848kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03491 (*cross-listing*)
Date: Fri, 3 Oct 2025 20:16:33 GMT   (1003kb)

Title: Short-circuiting Rings for Low-Latency AllReduce
Authors: Sarah-Michelle Hammer, Stefan Schmid, Rachee Singh, Vamsi Addanki
Categories: cs.NI cs.DC
\\
  Efficient collective communication is critical for many distributed ML and
HPC applications. In this context, it is widely believed that the Ring
algorithm for the AllReduce collective communication operation is optimal only
for large messages, while Recursive Doubling is preferable for small ones due
to its logarithmic number of steps compared to the linear number for Ring. In
this paper, we challenge this long-held assumption and show that the Ring
algorithm can remain optimal even for short messages in ring-based GPU-to-GPU
topologies, once realistic propagation delays and link capacity constraints are
accounted for. We find that the total propagation delay for both Ring and
Recursive Doubling essentially sums to the same value, but the latter incurs
significantly higher congestion due to longer hop counts, leading to increased
completion times. This surprising result motivates our case for in-collective
adaptive topologies, particularly in the context of emerging photonic
interconnects, which can break through the limitations of static topology
designs at the collective communication granularity. We design a \emph{simple
and fast} heuristic for circuit-switching that enables Recursive Doubling to
exploit dynamically reconfigurable photonic paths, carefully balancing
reconfiguration delays, propagation latencies, and link congestion to minimize
overall completion time. Our preliminary evaluations, using realistic
reconfiguration delays, show that our circuit-switching schedules enable faster
completion times for Recursive Doubling, even compared to Ring AllReduce on
static ring topologies. We conclude by highlighting key challenges and future
research directions for realizing practical, in-collective photonic switching.
\\ ( https://arxiv.org/abs/2510.03491 ,  1003kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03513 (*cross-listing*)
Date: Fri, 3 Oct 2025 20:54:58 GMT   (1861kb)

Title: A Lightweight Federated Learning Approach for Privacy-Preserving Botnet
  Detection in IoT
Authors: Taha M. Mahmoud and Naima Kaabouch
Categories: cs.LG cs.CR cs.DC
Comments: This work has been published in the Proceedings of the 2025 IEEE
  International Conference on Applied Cloud and Data Science and Applications
  (ACDSA). The final published version is available via IEEE Xplore at
  https://doi.org/10.1109/ACDSA65407.2025.11165820
Journal-ref: 2025 International Conference on Artificial Intelligence,
  Computer, Data Sciences and Applications (ACDSA)
DOI: 10.1109/ACDSA65407.2025.11165820
\\
  The rapid growth of the Internet of Things (IoT) has expanded opportunities
for innovation but also increased exposure to botnet-driven cyberattacks.
Conventional detection methods often struggle with scalability, privacy, and
adaptability in resource-constrained IoT environments. To address these
challenges, we present a lightweight and privacy-preserving botnet detection
framework based on federated learning. This approach enables distributed
devices to collaboratively train models without exchanging raw data, thus
maintaining user privacy while preserving detection accuracy. A
communication-efficient aggregation strategy is introduced to reduce overhead,
ensuring suitability for constrained IoT networks. Experiments on benchmark IoT
botnet datasets demonstrate that the framework achieves high detection accuracy
while substantially reducing communication costs. These findings highlight
federated learning as a practical path toward scalable, secure, and
privacy-aware intrusion detection for IoT ecosystems.
\\ ( https://arxiv.org/abs/2510.03513 ,  1861kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03601 (*cross-listing*)
Date: Sat, 4 Oct 2025 01:31:33 GMT   (5109kb)

Title: MECKD: Deep Learning-Based Fall Detection in Multilayer Mobile Edge
  Computing With Knowledge Distillation
Authors: Wei-Lung Mao, Chun-Chi Wang, Po-Heng Chou, Kai-Chun Liu, Yu Tsao
Categories: cs.LG cs.DC cs.NI eess.SP
Comments: 15 pages, 7 figures, and published in IEEE Sensors Journal
ACM-class: I.2.6; C.2.4
Journal-ref: IEEE Sensors Journal, vol. 24, no. 24, pp. 42195-42209, Dec., 2024
DOI: 10.1109/JSEN.2024.3456577
\\
  The rising aging population has increased the importance of fall detection
(FD) systems as an assistive technology, where deep learning techniques are
widely applied to enhance accuracy. FD systems typically use edge devices (EDs)
worn by individuals to collect real-time data, which are transmitted to a cloud
center (CC) or processed locally. However, this architecture faces challenges
such as a limited ED model size and data transmission latency to the CC. Mobile
edge computing (MEC), which allows computations at MEC servers deployed between
EDs and CC, has been explored to address these challenges. We propose a
multilayer MEC (MLMEC) framework to balance accuracy and latency. The MLMEC
splits the architecture into stations, each with a neural network model. If
front-end equipment cannot detect falls reliably, data are transmitted to a
station with more robust back-end computing. The knowledge distillation (KD)
approach was employed to improve front-end detection accuracy by allowing
high-power back-end stations to provide additional learning experiences,
enhancing precision while reducing latency and processing loads. Simulation
results demonstrate that the KD approach improved accuracy by 11.65% on the
SisFall dataset and 2.78% on the FallAllD dataset. The MLMEC with KD also
reduced the data latency rate by 54.15% on the FallAllD dataset and 46.67% on
the SisFall dataset compared to the MLMEC without KD. In summary, the MLMEC FD
system exhibits improved accuracy and reduced latency.
\\ ( https://arxiv.org/abs/2510.03601 ,  5109kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03625 (*cross-listing*)
Date: Sat, 4 Oct 2025 02:19:25 GMT   (205kb)

Title: On the Limits of Consensus under Dynamic Availability and
  Reconfiguration
Authors: Joachim Neu, Javier Nieto, Ling Ren
Categories: cs.CR cs.DC
\\
  Proof-of-stake blockchains require consensus protocols that support Dynamic
Availability and Reconfiguration (so-called DAR setting), where the former
means that the consensus protocol should remain live even if a large number of
nodes temporarily crash, and the latter means it should be possible to change
the set of operating nodes over time. State-of-the-art protocols for the DAR
setting, such as Ethereum, Cardano's Ouroboros, or Snow White, require
unrealistic additional assumptions, such as social consensus, or that key
evolution is performed even while nodes are not participating. In this paper,
we identify the necessary and sufficient adversarial condition under which
consensus can be achieved in the DAR setting without additional assumptions. We
then introduce a new and realistic additional assumption: honest nodes dispose
of their cryptographic keys the moment they express intent to exit from the set
of operating nodes. To add reconfiguration to any dynamically available
consensus protocol, we provide a bootstrapping gadget that is particularly
simple and efficient in the common optimistic case of few reconfigurations and
no double-spending attempts.
\\ ( https://arxiv.org/abs/2510.03625 ,  205kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04478 (*cross-listing*)
Date: Mon, 6 Oct 2025 04:28:39 GMT   (1430kb)

Title: Overlapping Schwarz Scheme for Linear-Quadratic Programs in Continuous
  Time
Authors: Hongli Zhao, Mihai Anitescu, Sen Na
Categories: math.OC cs.CE cs.DC cs.NA math.DS math.NA
Comments: 34 pages, 2 figures
\\
  We present an optimize-then-discretize framework for solving linear-quadratic
optimal control problems (OCP) governed by time-inhomogeneous ordinary
differential equations (ODEs). Our method employs a modified overlapping
Schwarz decomposition based on the Pontryagin Minimum Principle, partitioning
the temporal domain into overlapping intervals and independently solving
Hamiltonian systems in continuous time. We demonstrate that the convergence is
ensured by appropriately updating the boundary conditions of the individual
Hamiltonian dynamics. The cornerstone of our analysis is to prove that the
exponential decay of sensitivity (EDS) exhibited in discrete-time OCPs carries
over to the continuous-time setting. Unlike the discretize-then-optimize
approach, our method can flexibly incorporate different numerical integration
methods for solving the resulting Hamiltonian two-point boundary-value
subproblems, including adaptive-time integrators. A numerical experiment on a
linear-quadratic OCP illustrates the practicality of our approach in broad
scientific applications.
\\ ( https://arxiv.org/abs/2510.04478 ,  1430kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04665 (*cross-listing*)
Date: Mon, 6 Oct 2025 10:20:27 GMT   (972kb)

Title: Interactive High-Performance Visualization for Astronomy and Cosmology
Authors: Eva Sciacca, Nicola Tuccari, Umer Arshad, Fabio Pitari, Giuseppa
  Muscianisi, Emiliano Tramontana
Categories: astro-ph.IM cs.DC
\\
  The exponential growth of data in Astrophysics and Cosmology demands scalable
computational tools and intuitive interfaces for analysis and visualization. In
this work, we present an innovative integration of the VisIVO scientific
visualization framework with the InterActive Computing (IAC) service at Cineca,
enabling interactive, high-performance visual workflows directly within HPC
environments. Through seamless integration into Jupyter-based science gateways,
users can now access GPU-enabled compute nodes to perform complex 3D
visualizations using VisIVO via custom Python wrappers and preconfigured
interactive notebooks. We demonstrate how this infrastructure simplifies access
to advanced HPC resources, enhances reproducibility, and accelerates
exploratory workflows in astronomical research. Our approach has been validated
through a set of representative use cases involving large-scale simulations
from the GADGET code, highlighting the effectiveness of this system in
visualizing the large-scale structure of the Universe. This work exemplifies
how science gateways can bridge domain-specific tools and advanced
infrastructures, fostering user-centric, scalable, and reproducible research
environments.
\\ ( https://arxiv.org/abs/2510.04665 ,  972kb)
------------------------------------------------------------------------------
\\
arXiv:2510.05068 (*cross-listing*)
Date: Mon, 6 Oct 2025 17:45:57 GMT   (121kb)

Title: Multi-Agent Distributed Optimization With Feasible Set Privacy
Authors: Shreya Meel and Sennur Ulukus
Categories: cs.IT cs.CR cs.DC cs.NI eess.SP math.IT
\\
  We consider the problem of decentralized constrained optimization with
multiple agents $E_1,\ldots,E_N$ who jointly wish to learn the optimal solution
set while keeping their feasible sets $\mathcal{P}_1,\ldots,\mathcal{P}_N$
private from each other. We assume that the objective function $f$ is known to
all agents and each feasible set is a collection of points from a universal
alphabet $\mathcal{P}_{alph}$. A designated agent (leader) starts the
communication with the remaining (non-leader) agents, and is the first to
retrieve the solution set. The leader searches for the solution by sending
queries to and receiving answers from the non-leaders, such that the
information on the individual feasible sets revealed to the leader should be no
more than nominal, i.e., what is revealed from learning the solution set alone.
We develop achievable schemes for obtaining the solution set at nominal
information leakage, and characterize their communication costs under two
communication setups between agents. In this work, we focus on two kinds of
network setups: i) ring, where each agent communicates with two adjacent
agents, and ii) star, where only the leader communicates with the remaining
agents. We show that, if the leader first learns the joint feasible set through
an existing private set intersection (PSI) protocol and then deduces the
solution set, the information leaked to the leader is greater than nominal.
Moreover, we draw connection of our schemes to threshold PSI (ThPSI), which is
a PSI-variant where the intersection is revealed only when its cardinality is
larger than a threshold value. Finally, for various realizations of $f$ mapped
uniformly at random to a fixed range of values, our schemes are more
communication-efficient with a high probability compared to retrieving the
entire feasible set through PSI.
\\ ( https://arxiv.org/abs/2510.05068 ,  121kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03446 (*cross-listing*)
Date: Fri, 3 Oct 2025 19:08:41 GMT   (110kb)

Title: Downside Risk-Aware Equilibria for Strategic Decision-Making
Authors: Oliver Slumbers, Benjamin Patrick Evans, Sumitra Ganesh, Leo Ardon
Categories: cs.GT cs.MA econ.GN q-fin.EC q-fin.RM
Comments: Accepted at ECAI 2024 Workshop on AI In Finance
\\
  Game theory has traditionally had a relatively limited view of risk based on
how a player's expected reward is impacted by the uncertainty of the actions of
other players. Recently, a new game-theoretic approach provides a more holistic
view of risk also considering the reward-variance. However, these
variance-based approaches measure variance of the reward on both the upside and
downside. In many domains, such as finance, downside risk only is of key
importance, as this represents the potential losses associated with a decision.
In contrast, large upside "risk" (e.g. profits) are not an issue. To address
this restrictive view of risk, we propose a novel solution concept, downside
risk aware equilibria (DRAE) based on lower partial moments. DRAE restricts
downside risk, while placing no restrictions on upside risk, and additionally,
models higher-order risk preferences. We demonstrate the applicability of DRAE
on several games, successfully finding equilibria which balance downside risk
with expected reward, and prove the existence and optimality of this
equilibria.
\\ ( https://arxiv.org/abs/2510.03446 ,  110kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03588 (*cross-listing*)
Date: Sat, 4 Oct 2025 00:34:32 GMT   (2031kb)

Title: REFINE: Enhancing Program Repair Agents through Context-Aware Patch
  Refinement
Authors: Anvith Pabba, Simin Chen, Alex Mathai, Anindya Chakraborty, Baishakhi
  Ray
Categories: cs.SE cs.MA
Comments: We also open source our code at
  https://anonymous.4open.science/r/SemAgent-7B2F/README.md
\\
  Large Language Models (LLMs) have recently shown strong potential in
automatic program repair (APR), especially in repository-level settings where
the goal is to generate patches based on natural language issue descriptions,
large codebases, and regression tests. However, despite their promise, current
LLM-based APR techniques often struggle to produce correct fixes due to limited
understanding of code context and over-reliance on incomplete test suites. As a
result, they frequently generate Draft Patches-partially correct patches that
either incompletely address the bug or overfit to the test cases. In this work,
we propose a novel patch refinement framework, Refine, that systematically
transforms Draft Patches into correct ones. Refine addresses three key
challenges: disambiguating vague issue and code context, diversifying patch
candidates through test-time scaling, and aggregating partial fixes via an
LLM-powered code review process. We implement Refine as a general refinement
module that can be integrated into both open-agent-based and workflow-based APR
systems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine
achieves state-of-the-art results among workflow-based approaches and
approaches the best-known performance across all APR categories. Specifically,
Refine boosts AutoCodeRover's performance by 14.67%, achieving a score of
51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine
improves the resolution rate by 12.2%, and when integrated across multiple APR
systems, it yields an average improvement of 14%-demonstrating its broad
effectiveness and generalizability. These results highlight the effectiveness
of refinement as a missing component in current APR pipelines and the potential
of agentic collaboration in closing the gap between near-correct and correct
patches. We also open source our code.
\\ ( https://arxiv.org/abs/2510.03588 ,  2031kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03772 (*cross-listing*)
Date: Sat, 4 Oct 2025 10:42:10 GMT   (955kb)

Title: Cooperation in public goods game on regular lattices with agents
  changing interaction groups
Authors: Jaros{\l}aw Adam Miszczak
Categories: physics.soc-ph cs.MA nlin.AO
Comments: 18 pages, 8 figures, code available at
  https://github.com/jmiszczak/pgg_group_diversity
\\
  The emergence of cooperation in the groups of interacting agents is one of
the most fascinating phenomena observed in many complex systems studied in
social science and ecology, even in the situations where one would expect the
agent to use a free-rider policy. This is especially surprising in the
situation where no external mechanisms based on reputation or punishment are
present. One of the possible explanations of this effect is the inhomogeneity
of the various aspects of interactions, which can be used to clarify the
seemingly paradoxical behavior. In this report we demonstrate that the
diversity of interaction networks helps to some degree to explain the emergence
of cooperation. We extend the model of spatial interaction diversity introduced
in [L. Shang et al., Physica A, 593:126999 (2022)] by enabling the evaluation
of the interaction groups. We show that the process of the reevaluation of the
interaction group facilitates the emergence of cooperation. Furthermore, we
also observe that a significant participation of agents switching their
interaction neighborhoods has a negative impact on the formation of
cooperation. The introduced scenario can help to understand the formation of
cooperation in the systems where no additional mechanisms for controlling
agents are included.
\\ ( https://arxiv.org/abs/2510.03772 ,  955kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03823 (*cross-listing*)
Date: Sat, 4 Oct 2025 14:39:45 GMT   (4124kb)

Title: Distributed Area Coverage with High Altitude Balloons Using Multi-Agent
  Reinforcement Learning
Authors: Adam Haroon and Tristan Schuler
Categories: cs.LG cs.MA cs.RO
\\
  High Altitude Balloons (HABs) can leverage stratospheric wind layers for
limited horizontal control, enabling applications in reconnaissance,
environmental monitoring, and communications networks. Existing multi-agent HAB
coordination approaches use deterministic methods like Voronoi partitioning and
extremum seeking control for large global constellations, which perform poorly
for smaller teams and localized missions. While single-agent HAB control using
reinforcement learning has been demonstrated on HABs, coordinated multi-agent
reinforcement learning (MARL) has not yet been investigated. This work presents
the first systematic application of multi-agent reinforcement learning (MARL)
to HAB coordination for distributed area coverage. We extend our previously
developed reinforcement learning simulation environment (RLHAB) to support
cooperative multi-agent learning, enabling multiple agents to operate
simultaneously in realistic atmospheric conditions. We adapt QMIX for HAB area
coverage coordination, leveraging Centralized Training with Decentralized
Execution to address atmospheric vehicle coordination challenges. Our approach
employs specialized observation spaces providing individual state,
environmental context, and teammate data, with hierarchical rewards
prioritizing coverage while encouraging spatial distribution. We demonstrate
that QMIX achieves similar performance to the theoretically optimal geometric
deterministic method for distributed area coverage, validating the MARL
approach and providing a foundation for more complex autonomous multi-HAB
missions where deterministic methods become intractable.
\\ ( https://arxiv.org/abs/2510.03823 ,  4124kb)
------------------------------------------------------------------------------
\\
arXiv:2510.04915 (*cross-listing*)
Date: Mon, 6 Oct 2025 15:30:20 GMT   (99kb)

Title: A Fixed Point Framework for the Existence of EFX Allocations
Authors: S. Rasoul Etesami
Categories: cs.GT cs.MA cs.SY eess.SY math.OC
\\
  We consider the problem of the existence of an envy-free allocation up to any
good (EFX) for linear valuations and establish new results by connecting this
problem to a fixed point framework. Specifically, we first use randomized
rounding to extend the discrete EFX constraints into a continuous space and
show that an EFX allocation exists if and only if the optimal value of the
continuously extended objective function is nonpositive. In particular, we
demonstrate that this optimization problem can be formulated as an
unconstrained difference of convex (DC) program, which can be further
simplified to the minimization of a piecewise linear concave function over a
polytope. Leveraging this connection, we show that the proposed DC program has
a nonpositive optimal objective value if and only if a well-defined continuous
vector map admits a fixed point. Crucially, we prove that the reformulated
fixed point problem satisfies all the conditions of Brouwer's fixed point
theorem, except that self-containedness is violated by an arbitrarily small
positive constant. To address this, we propose a slightly perturbed continuous
map that always admits a fixed point. This fixed point serves as a proxy for
the fixed point (if it exists) of the original map, and hence for an EFX
allocation through an appropriate transformation. Our results offer a new
approach to establishing the existence of EFX allocations through fixed point
theorems. Moreover, the equivalence with DC programming enables a more
efficient and systematic method for computing such allocations (if one exists)
using tools from nonlinear optimization. Our findings bridge the discrete
problem of finding an EFX allocation with two continuous frameworks: solving an
unconstrained DC program and identifying a fixed point of a continuous vector
map.
\\ ( https://arxiv.org/abs/2510.04915 ,  99kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:2308.03688
replaced with revised version Sat, 4 Oct 2025 03:54:18 GMT   (20753kb)

Title: AgentBench: Evaluating LLMs as Agents
Authors: Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu
  Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan
  Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan
  Sun, Minlie Huang, Yuxiao Dong, Jie Tang
Categories: cs.AI cs.CL cs.LG
Comments: Published in ICLR 2024
\\ ( https://arxiv.org/abs/2308.03688 ,  20753kb)
------------------------------------------------------------------------------
\\
arXiv:2403.03645
replaced with revised version Sat, 4 Oct 2025 02:18:08 GMT   (706kb)

Title: Graph Generation Powered with LLMs for Boosting Multivariate Time-Series
  Representation Learning
Authors: Yucheng Wang, Min Wu, Ruibing Jin, Xiaoli Li, Lihua Xie, Zhenghua Chen
Categories: cs.AI
\\ ( https://arxiv.org/abs/2403.03645 ,  706kb)
------------------------------------------------------------------------------
\\
arXiv:2406.07124
replaced with revised version Mon, 6 Oct 2025 15:52:54 GMT   (4704kb)

Title: CHARME: A chain-based reinforcement learning approach for the minor
  embedding problem
Authors: Hoang M. Ngo, Nguyen H K. Do, Minh N. Vu, Tre' R. Jeter, Tamer
  Kahveci, My T. Thai
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2406.07124 ,  4704kb)
------------------------------------------------------------------------------
\\
arXiv:2406.11334
replaced with revised version Mon, 6 Oct 2025 10:21:23 GMT   (1430kb)

Title: Program Synthesis Benchmark for Visual Programming in XLogoOnline
  Environment
Authors: Chao Wen, Jacqueline Staub, Adish Singla
Categories: cs.AI
Comments: ACL'25 paper
\\ ( https://arxiv.org/abs/2406.11334 ,  1430kb)
------------------------------------------------------------------------------
\\
arXiv:2407.13968
replaced with revised version Sun, 5 Oct 2025 23:53:21 GMT   (980kb)

Title: Optimizing Agricultural Order Fulfillment Systems: A Hybrid Tree Search
  Approach
Authors: Pranay Thangeda, Hoda Helmi, Melkior Ornik
Categories: cs.AI
\\ ( https://arxiv.org/abs/2407.13968 ,  980kb)
------------------------------------------------------------------------------
\\
arXiv:2409.16238
replaced with revised version Mon, 6 Oct 2025 12:54:48 GMT   (84kb)

Title: Efficiently Learning Probabilistic Logical Models by Cheaply Ranking
  Mined Rules
Authors: Jonathan Feldstein, Dominic Phillips, Efthymia Tsamoura
Categories: cs.AI
Comments: 22 pages
\\ ( https://arxiv.org/abs/2409.16238 ,  84kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20140
replaced with revised version Sat, 4 Oct 2025 12:56:45 GMT   (4102kb)

Title: MAD-Sherlock: Multi-Agent Debate for Visual Misinformation Detection
Authors: Kumud Lakara, Georgia Channing, Christian Rupprecht, Juil Sock, Philip
  Torr, John Collomosse, Christian Schroeder de Witt
Categories: cs.AI
\\ ( https://arxiv.org/abs/2410.20140 ,  4102kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20600
replaced with revised version Mon, 6 Oct 2025 16:15:07 GMT   (2788kb)

Title: Multi-Turn Human-LLM Interaction Through the Lens of a Two-Way
  Intelligibility Protocol
Authors: Harshvardhan Mestha, Karan Bania, Shreyas V Sathyanarayana, Sidong
  Liu, Ashwin Srinivasan
Categories: cs.AI cs.HC cs.LG cs.MA
Comments: Multi-Turn Interactions in Large Language Models (MTI-LLM) Workshop
  at NeurIPS 2025
\\ ( https://arxiv.org/abs/2410.20600 ,  2788kb)
------------------------------------------------------------------------------
\\
arXiv:2411.02348
replaced with revised version Mon, 6 Oct 2025 11:35:02 GMT   (600kb)

Title: Can Large Language Models generalize analogy solving like children can?
Authors: Claire E. Stevenson, Alexandra Pafford, Han L. J. van der Maas,
  Melanie Mitchell
Categories: cs.AI cs.CL cs.HC
Comments: Accepted to Transactions of the Association for Computational
  Linguistics (TACL)
\\ ( https://arxiv.org/abs/2411.02348 ,  600kb)
------------------------------------------------------------------------------
\\
arXiv:2412.18760
replaced with revised version Sun, 5 Oct 2025 04:18:40 GMT   (1925kb)

Title: Data clustering: a fundamental method in data science and management
Authors: Tai Dinh, Wong Hauchi, Daniil Lisik, Michal Koren, Dat Tran, Philip S.
  Yu, Joaqu\'in Torres-Sospedra
Categories: cs.AI
Comments: Data Science and Management (2025)
DOI: 10.1016/j.dsm.2025.08.001
\\ ( https://arxiv.org/abs/2412.18760 ,  1925kb)
------------------------------------------------------------------------------
\\
arXiv:2501.03715
replaced with revised version Mon, 6 Oct 2025 10:38:24 GMT   (1362kb)

Title: Neural Deconstruction Search for Vehicle Routing Problems
Authors: Andr\'e Hottung, Paula Wong-Chung, Kevin Tierney
Categories: cs.AI cs.LG
Comments: Published in TMLR
\\ ( https://arxiv.org/abs/2501.03715 ,  1362kb)
------------------------------------------------------------------------------
\\
arXiv:2502.11723
replaced with revised version Mon, 6 Oct 2025 14:15:39 GMT   (718kb)

Title: Energy-Conscious LLM Decoding: Impact of Text Generation Strategies on
  GPU Energy Consumption
Authors: Alireza Nik, Michael A. Riegler, P{\aa}l Halvorsen
Categories: cs.AI
Comments: Updated version with additional models and benchmark datasets. The
  experimental section has been expanded with new analyses, and minor
  corrections and clarifications have been made throughout the text
\\ ( https://arxiv.org/abs/2502.11723 ,  718kb)
------------------------------------------------------------------------------
\\
arXiv:2505.09614
replaced with revised version Sun, 5 Oct 2025 18:28:02 GMT   (1208kb)

Title: Language Agents Mirror Human Causal Reasoning Biases. How Can We Help
  Them Think Like Scientists?
Authors: Anthony GX-Chen, Dongyan Lin, Mandana Samiei, Doina Precup, Blake A.
  Richards, Rob Fergus, Kenneth Marino
Categories: cs.AI cs.CL
Comments: Conference on Language Modelling (COLM) 2025, Camera Ready
\\ ( https://arxiv.org/abs/2505.09614 ,  1208kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12891
replaced with revised version Sun, 5 Oct 2025 13:52:34 GMT   (20476kb)

Title: TIME: A Multi-level Benchmark for Temporal Reasoning of LLMs in
  Real-World Scenarios
Authors: Shaohang Wei, Wei Li, Feifan Song, Wen Luo, Tianyi Zhuang, Haochen
  Tan, Zhijiang Guo, Houfeng Wang
Categories: cs.AI cs.CL
Comments: Accepted by NeurIPS 2025 (Spotlight)
\\ ( https://arxiv.org/abs/2505.12891 ,  20476kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19030
replaced with revised version Sat, 4 Oct 2025 12:53:01 GMT   (2155kb)

Title: RECAST: Expanding the Boundaries of LLMs' Complex Instruction Following
  with Multi-Constraint Data
Authors: Zhengkang Guo, Wenhao Liu, Mingchen Xie, Jingwen Xu, Zisu Huang,
  Muzhao Tian, Jianhan Xu, Yuanzhe Shen, Qi Qian, Muling Wu, Xiaohua Wang,
  Changze Lv, He-Da Wang, Hu Yao, Xiaoqing Zheng, Xuanjing Huang
Categories: cs.AI
\\ ( https://arxiv.org/abs/2505.19030 ,  2155kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19347
replaced with revised version Mon, 6 Oct 2025 02:15:33 GMT   (8444kb)

Title: PatentMind: A Multi-Aspect Reasoning Graph for Patent Similarity
  Evaluation
Authors: Yongmin Yoo, Qiongkai Xu, Longbing Cao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2505.19347 ,  8444kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04245
replaced with revised version Sun, 5 Oct 2025 03:25:01 GMT   (357kb)

Title: Contextual Integrity in LLMs via Reasoning and Reinforcement Learning
Authors: Guangchen Lan, Huseyin A. Inan, Sahar Abdelnabi, Janardhan Kulkarni,
  Lukas Wutschitz, Reza Shokri, Christopher G. Brinton, Robert Sim
Categories: cs.AI cs.CL cs.LG
ACM-class: I.2.6; I.2.7
\\ ( https://arxiv.org/abs/2506.04245 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2506.05619
replaced with revised version Sun, 5 Oct 2025 11:24:21 GMT   (138kb)

Title: Beyond RLHF and NLHF: Population-Proportional Alignment under an
  Axiomatic Framework
Authors: Kihyun Kim, Jiawei Zhang, Asuman Ozdaglar, Pablo A. Parrilo
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2506.05619 ,  138kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07527
replaced with revised version Sat, 4 Oct 2025 04:07:04 GMT   (416kb)

Title: Learning What Reinforcement Learning Can't: Interleaved Online
  Fine-Tuning for Hardest Questions
Authors: Lu Ma, Hao Liang, Meiyi Qiang, Lexiang Tang, Xiaochen Ma, Zhen Hao
  Wong, Junbo Niu, Chengyu Shen, Runming He, Yanhao Li, Bin Cui, Wentao Zhang
Categories: cs.AI cs.LG
Comments: 12 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.07527 ,  416kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09050
replaced with revised version Mon, 6 Oct 2025 14:44:32 GMT   (2662kb)

Title: ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm
  Engineering
Authors: Yuki Imajuku, Kohki Horie, Yoichi Iwata, Kensho Aoki, Naohiro
  Takahashi, Takuya Akiba
Categories: cs.AI
Comments: Accepted at NeurIPS 2025 Datasets & Benchmarks Track
\\ ( https://arxiv.org/abs/2506.09050 ,  2662kb)
------------------------------------------------------------------------------
\\
arXiv:2506.13157
replaced with revised version Sun, 5 Oct 2025 16:06:32 GMT   (35kb)

Title: Machine Learning as Iterated Belief Change a la Darwiche and Pearl
Authors: Theofanis Aravanis
Categories: cs.AI cs.LG cs.LO cs.NE
Comments: This second version incorporates improvements based on feedback from
  anonymous reviewers of a previous journal submission
\\ ( https://arxiv.org/abs/2506.13157 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02663
replaced with revised version Mon, 6 Oct 2025 12:49:25 GMT   (1109kb)

Title: Think How to Think: Mitigating Overthinking with Autonomous Difficulty
  Cognition in Large Reasoning Models
Authors: Yongjiang Liu, Haoxi Li, Xiaosong Ma, Jie Zhang, Song Guo
Categories: cs.AI
Comments: 21 pages, 18 figures
\\ ( https://arxiv.org/abs/2507.02663 ,  1109kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05791
replaced with revised version Fri, 3 Oct 2025 23:50:19 GMT   (27038kb)

Title: GTA1: GUI Test-time Scaling Agent
Authors: Yan Yang and Dongxu Li and Yutong Dai and Yuhao Yang and Ziyang Luo
  and Zirui Zhao and Zhiyuan Hu and Junzhe Huang and Amrita Saha and Zeyuan
  Chen and Ran Xu and Liyuan Pan and Silvio Savarese and Caiming Xiong and
  Junnan Li
Categories: cs.AI
\\ ( https://arxiv.org/abs/2507.05791 ,  27038kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07644
replaced with revised version Mon, 6 Oct 2025 12:00:21 GMT   (2339kb)

Title: FloorplanQA: A Benchmark for Spatial Reasoning in LLMs using Structured
  Representations
Authors: Fedor Rodionov, Abdelrahman Eldesokey, Michael Birsak, John Femiani,
  Bernard Ghanem, Peter Wonka
Categories: cs.AI
Comments: v2, Project page: https://OldDelorean.github.io/FloorplanQA/
\\ ( https://arxiv.org/abs/2507.07644 ,  2339kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16296
replaced with revised version Sun, 5 Oct 2025 06:45:14 GMT   (612kb)

Title: Cross-Modal Distillation For Widely Differing Modalities
Authors: Cairong Zhao, Yufeng Jin, Zifan Song, Haonan Chen, Duoqian Miao,
  Guosheng Hu
Categories: cs.AI
Comments: 14 pages, 9 figures
\\ ( https://arxiv.org/abs/2507.16296 ,  612kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01670
replaced with revised version Sat, 4 Oct 2025 05:53:57 GMT   (624kb)

Title: QCBench: Evaluating Large Language Models on Domain-Specific
  Quantitative Chemistry
Authors: Jiaqing Xie, Weida Wang, Ben Gao, Zhuo Yang, Haiyuan Wan, Shufei
  Zhang, Tianfan Fu, Yuqiang Li
Categories: cs.AI physics.chem-ph
Comments: Revision at Journal of Chemical Information and Modeling
\\ ( https://arxiv.org/abs/2508.01670 ,  624kb)
------------------------------------------------------------------------------
\\
arXiv:2508.01844
replaced with revised version Fri, 3 Oct 2025 23:10:05 GMT   (1144kb)

Title: Towards Generalizable Context-aware Anomaly Detection: A Large-scale
  Benchmark in Cloud Environments
Authors: Xinkai Zou, Xuan Jiang, Ruikai Huang, Haoze He, Parv Kapoor, Hongrui
  Wu, Yibo Wang, Jian Sha, Xiongbo Shi, Zixun Huang, Jinhua Zhao
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.01844 ,  1144kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02124
replaced with revised version Sat, 4 Oct 2025 04:26:48 GMT   (1564kb)

Title: Trainable Dynamic Mask Sparse Attention
Authors: Jingze Shi, Yifan Wu, Yiran Peng, Bingheng Wu, Liangdong Wang, Guang
  Liu and Yuyu Luo
Categories: cs.AI cs.CL cs.LG
Comments: 25 pages
\\ ( https://arxiv.org/abs/2508.02124 ,  1564kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09123
replaced with revised version Sat, 4 Oct 2025 17:38:02 GMT   (24456kb)

Title: OpenCUA: Open Foundations for Computer-Use Agents
Authors: Xinyuan Wang, Bowen Wang, Dunjie Lu, Junlin Yang, Tianbao Xie, Junli
  Wang, Jiaqi Deng, Xiaole Guo, Yiheng Xu, Chen Henry Wu, Zhennan Shen, Zhuokai
  Li, Ryan Li, Xiaochuan Li, Junda Chen, Boyuan Zheng, Peihang Li, Fangyu Lei,
  Ruisheng Cao, Yeqiao Fu, Dongchan Shin, Martin Shin, Jiarui Hu, Yuyan Wang,
  Jixuan Chen, Yuxiao Ye, Danyang Zhang, Dikang Du, Hao Hu, Huarong Chen, Zaida
  Zhou, Haotian Yao, Ziwei Chen, Qizheng Gu, Yipu Wang, Heng Wang, Diyi Yang,
  Victor Zhong, Flood Sung, Y.Charles, Zhilin Yang, Tao Yu
Categories: cs.AI cs.CV
Comments: Updata author list, modify first page format, correct typos
\\ ( https://arxiv.org/abs/2508.09123 ,  24456kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12425
replaced with revised version Sat, 4 Oct 2025 17:29:03 GMT   (834kb)

Title: Non-Interactive Symbolic-Aided Chain-of-Thought for Logical Reasoning
Authors: Phuong Minh Nguyen, Tien Huu Dang, Naoya Inoue
Categories: cs.AI cs.CL
Comments: Accepted in The 39th Pacific Asia Conference on Language, Information
  and Computation (PACLIC 39)
\\ ( https://arxiv.org/abs/2508.12425 ,  834kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13003
replaced with revised version Sun, 5 Oct 2025 08:41:52 GMT   (3117kb)

Title: EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning
  via Evolutionary Testing
Authors: Shengbo Wang, Mingwei Liu, Zike Li, Anji Li, Yanlin Wang, Xin Peng,
  Zibin Zheng
Categories: cs.AI
\\ ( https://arxiv.org/abs/2508.13003 ,  3117kb)
------------------------------------------------------------------------------
\\
arXiv:2509.00072
replaced with revised version Mon, 6 Oct 2025 14:10:14 GMT   (0kb,I)

Title: Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy
  Against Benchmark Contamination
Authors: Terry Jingchen Zhang, Gopal Dev, Ning Wang, Nicole Ni, Wenyuan Jiang,
  Yinya Huang, Bernhard Sch\"olkopf, Mrinmaya Sachan, Zhijing Jin
Categories: cs.AI
Comments: The authors choose to withdraw this manuscript as it constitutes
  incomplete work
\\ ( https://arxiv.org/abs/2509.00072 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04439
replaced with revised version Sat, 4 Oct 2025 00:01:09 GMT   (1026kb)

Title: ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory
Authors: Matthew Ho, Chen Si, Zhaoxiang Feng, Fangxu Yu, Yichi Yang, Zhijian
  Liu, Zhiting Hu, Lianhui Qin
Categories: cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.04439 ,  1026kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10018
replaced with revised version Sat, 4 Oct 2025 22:46:50 GMT   (973kb)

Title: GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation
  Enhanced by Domain Rules and Disproof Mechanism
Authors: Hailong Yang, Renhuo Zhao, Guanjin Wang and Zhaohong Deng
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.10018 ,  973kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18710
replaced with revised version Sat, 4 Oct 2025 00:36:12 GMT   (937kb)

Title: Autonomous Data Agents: A New Opportunity for Smart Data
Authors: Yanjie Fu, Dongjie Wang, Wangyang Ying, Xinyuan Wang, Xiangliang
  Zhang, Huan Liu, Jian Pei
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.18710 ,  937kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23392
replaced with revised version Sun, 5 Oct 2025 13:54:32 GMT   (579kb)

Title: Your Models Have Thought Enough: Training Large Reasoning Models to Stop
  Overthinking
Authors: Jinyi Han, Ying Huang, Ying Liao, Zishang Jiang, Xikun Lu, Haiquan
  Zhao, Xinyi Wang, Guanghao Zhou, Sihang Jiang, Jiaqing Liang, Weikang Zhou,
  Zeye Sun, Fei Yu, Yanghua Xiao
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.23392 ,  579kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23882
replaced with revised version Sun, 5 Oct 2025 14:53:45 GMT   (274kb)

Title: Quant Fever, Reasoning Blackholes, Schrodinger's Compliance, and More:
  Probing GPT-OSS-20B
Authors: Shuyi Lin, Tian Lu, Zikai Wang, Bo Wen, Yibo Zhao, and Cheng Tan
Categories: cs.AI cs.CR
\\ ( https://arxiv.org/abs/2509.23882 ,  274kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24711
replaced with revised version Sun, 5 Oct 2025 08:47:48 GMT   (1243kb)

Title: On the Self-awareness of Large Reasoning Models' Capability Boundaries
Authors: Qingjie Zhang, Yujia Fu, Yang Wang, Liu Yan, Tao Wei, Ke Xu, Minlie
  Huang, Han Qiu
Categories: cs.AI cs.CL
\\ ( https://arxiv.org/abs/2509.24711 ,  1243kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24836
replaced with revised version Sat, 4 Oct 2025 03:29:33 GMT   (1933kb)

Title: Pushing LLMs to Their Logical Reasoning Bound: The Role of Data
  Reasoning Intensity
Authors: Zhen Bi, Zhenlin Hu, Jinnan Yang, Mingyang Chen, Cheng Deng, Yida Xue,
  Zeyu Yang, Qing Shen, Zhenfang Liu, Kang Zhao, Ningyu Zhang, Jungang Lou
Categories: cs.AI cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.24836 ,  1933kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25361
replaced with revised version Fri, 3 Oct 2025 20:52:01 GMT   (2272kb)

Title: Structural Reward Model: Enhancing Interpretability, Efficiency, and
  Scalability in Reward Modeling
Authors: Xiaoyu Liu, Di Liang, Chang Dai, Hongyu Shan, Peiyang Liu, Yonghao
  Liu, Muling Wu, Yuntao Li, Xianjie Wu, LI Miao, Jiangrong Shen, Minlong Peng
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.25361 ,  2272kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25373
replaced with revised version Sun, 5 Oct 2025 12:02:29 GMT   (4148kb)

Title: From Perception to Cognition: A Survey of Vision-Language Interactive
  Reasoning in Multimodal Large Language Models
Authors: Chenyue Zhou and Mingxuan Wang and Yanbiao Ma and Chenxu Wu and Wanyi
  Chen and Zhe Qian and Xinyu Liu and Yiwei Zhang and Junhao Wang and Hengbo Xu
  and Fei Luo and Xiaohua Chen and Xiaoshuai Hao and Hehan Li and Andi Zhang
  and Wenxuan Wang and Lingling Li and Zhiwu Lu and Yang Lu and Yike Guo
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.25373 ,  4148kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26440
replaced with revised version Sat, 4 Oct 2025 06:04:13 GMT   (22739kb)

Title: Transformer Classification of Breast Lesions: The BreastDCEDL_AMBL
  Benchmark Dataset and 0.92 AUC Baseline
Authors: Naomi Fridman (Ariel University), Anat Goldstein (Ariel University)
Categories: cs.AI
\\ ( https://arxiv.org/abs/2509.26440 ,  22739kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01367
replaced with revised version Sat, 4 Oct 2025 07:33:32 GMT   (1839kb)

Title: Is It Thinking or Cheating? Detecting Implicit Reward Hacking by
  Measuring Reasoning Effort
Authors: Xinpeng Wang, Nitish Joshi, Barbara Plank, Rico Angell, He He
Categories: cs.AI cs.CL
Comments: 25 pages, 31 figures
\\ ( https://arxiv.org/abs/2510.01367 ,  1839kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02567
replaced with revised version Mon, 6 Oct 2025 15:33:47 GMT   (1789kb)

Title: Agentic Additive Manufacturing Alloy Discovery
Authors: Peter Pak, Achuth Chandrasekhar, Amir Barati Farimani
Categories: cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.02567 ,  1789kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02608
replaced with revised version Mon, 6 Oct 2025 02:10:36 GMT   (2702kb)

Title: Mitigating Modal Imbalance in Multimodal Reasoning
Authors: Chen Henry Wu, Neil Kale and Aditi Raghunathan
Categories: cs.AI
Comments: 10 pages, 10 figures, CoLM 2025
\\ ( https://arxiv.org/abs/2510.02608 ,  2702kb)
------------------------------------------------------------------------------
\\
arXiv:2105.00846
replaced with revised version Sun, 5 Oct 2025 13:12:11 GMT   (2654kb)

Title: Semantic Journeys: Quantifying Change in Emoji Meaning from 2012-2018
Authors: Alexander Robertson, Farhana Ferdousi Liza, Dong Nguyen, Barbara
  McGillivray, Scott A. Hale
Categories: cs.CL
Journal-ref: 4th International Workshop on Emoji Understanding and Applications
  in Social Media 2021
\\ ( https://arxiv.org/abs/2105.00846 ,  2654kb)
------------------------------------------------------------------------------
\\
arXiv:2310.12150
replaced with revised version Fri, 3 Oct 2025 18:29:29 GMT   (7715kb)

Title: Understanding Retrieval Augmentation for Long-Form Question Answering
Authors: Hung-Ting Chen, Fangyuan Xu, Shane Arora, Eunsol Choi
Categories: cs.CL
Comments: COLM 2024 Camera Ready Version
\\ ( https://arxiv.org/abs/2310.12150 ,  7715kb)
------------------------------------------------------------------------------
\\
arXiv:2310.16810
replaced with revised version Sat, 4 Oct 2025 23:22:58 GMT   (423kb)

Title: Can GPT models Follow Human Summarization Guidelines? A Study for
  Targeted Communication Goals
Authors: Yongxin Zhou, Fabien Ringeval, Fran\c{c}ois Portet
Categories: cs.CL cs.AI
Comments: INLG 2025, Hanoi, Vietnam, October 29 - November 2, 2025
\\ ( https://arxiv.org/abs/2310.16810 ,  423kb)
------------------------------------------------------------------------------
\\
arXiv:2402.10601
replaced with revised version Sat, 4 Oct 2025 11:22:23 GMT   (312kb)

Title: When "Competency" in Reasoning Opens the Door to Vulnerability:
  Jailbreaking LLMs via Novel Complex Ciphers
Authors: Divij Handa, Zehua Zhang, Amir Saeidi, Shrinidhi Kumbhar, Md Nayem
  Uddin, Aswin RRV, Chitta Baral
Categories: cs.CL cs.AI
Comments: Published in Reliable ML from Unreliable Data workshop @ NeurIPS 2025
\\ ( https://arxiv.org/abs/2402.10601 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:2402.10612
replaced with revised version Sat, 4 Oct 2025 14:31:52 GMT   (1979kb)

Title: Rowen: Adaptive Retrieval-Augmented Generation for Hallucination
  Mitigation in LLMs
Authors: Hanxing Ding, Liang Pang, Zihao Wei, Huawei Shen, Xueqi Cheng
Categories: cs.CL
Comments: Accepted at SIGIR-AP 2025
\\ ( https://arxiv.org/abs/2402.10612 ,  1979kb)
------------------------------------------------------------------------------
\\
arXiv:2403.20101
replaced with revised version Mon, 6 Oct 2025 17:14:08 GMT   (549kb)

Title: RealKIE: Five Novel Datasets for Enterprise Key Information Extraction
Authors: Benjamin Townsend, Madison May, Katherine Mackowiak and Christopher
  Wells
Categories: cs.CL cs.CV cs.LG
\\ ( https://arxiv.org/abs/2403.20101 ,  549kb)
------------------------------------------------------------------------------
\\
arXiv:2407.18525
replaced with revised version Sat, 4 Oct 2025 20:21:52 GMT   (1867kb)

Title: ClinicRealm: Re-evaluating Large Language Models with Conventional
  Machine Learning for Non-Generative Clinical Prediction Tasks
Authors: Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng,
  Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen
  M. Harrison, Liantao Ma
Categories: cs.CL cs.AI cs.LG
Comments: Code: https://github.com/yhzhu99/ehr-llm-benchmark
\\ ( https://arxiv.org/abs/2407.18525 ,  1867kb)
------------------------------------------------------------------------------
\\
arXiv:2409.12887
replaced with revised version Sat, 4 Oct 2025 13:42:11 GMT   (10262kb)

Title: Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data
  Augmentation and Gaussian-Decayed Contrastive Learning
Authors: Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui
Categories: cs.CL
\\ ( https://arxiv.org/abs/2409.12887 ,  10262kb)
------------------------------------------------------------------------------
\\
arXiv:2410.12491
replaced with revised version Mon, 6 Oct 2025 17:25:58 GMT   (13685kb)

Title: Insights from the Inverse: Reconstructing LLM Training Goals Through
  Inverse Reinforcement Learning
Authors: Jared Joselowitz, Ritam Majumdar, Arjun Jagota, Matthieu Bou, Nyal
  Patel, Satyapriya Krishna, Sonali Parbhoo
Categories: cs.CL
Comments: Published as a conference paper at COLM 2025
\\ ( https://arxiv.org/abs/2410.12491 ,  13685kb)
------------------------------------------------------------------------------
\\
arXiv:2410.23066
replaced with revised version Sun, 5 Oct 2025 05:55:06 GMT   (417kb)

Title: Don't Pay Attention, PLANT It: Pretraining Attention via
  Learning-to-Rank
Authors: Debjyoti Saha Roy, Byron C. Wallace and Javed A. Aslam
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2410.23066 ,  417kb)
------------------------------------------------------------------------------
\\
arXiv:2411.01281
replaced with revised version Sat, 4 Oct 2025 07:18:53 GMT   (28316kb)

Title: Arena-Lite: Efficient and Reliable Large Language Model Evaluation via
  Tournament-Based Direct Comparisons
Authors: Seonil Son, Ju-Min Oh, Heegon Jin, Cheolhun Jang, Jeongbeom Jeong,
  Kuntae Kim
Categories: cs.CL cs.AI
Comments: 8 pages for main body, 19 pages in total
Journal-ref: EMNLP 2025 Main
\\ ( https://arxiv.org/abs/2411.01281 ,  28316kb)
------------------------------------------------------------------------------
\\
arXiv:2411.02591
replaced with revised version Sun, 5 Oct 2025 18:45:15 GMT   (864kb)

Title: Geometry of orofacial neuromuscular signals: speech articulation
  decoding using surface electromyography
Authors: Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller
Categories: cs.CL
\\ ( https://arxiv.org/abs/2411.02591 ,  864kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17792
replaced with revised version Mon, 6 Oct 2025 15:19:49 GMT   (2728kb)

Title: H3Fusion: Helpful, Harmless, Honest Fusion of Aligned LLMs
Authors: Selim Furkan Tekin, Fatih Ilhan, Tiansheng Huang, Sihao Hu, Yichang
  Xu, Zachary Yahn, Ling Liu
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2411.17792 ,  2728kb)
------------------------------------------------------------------------------
\\
arXiv:2501.05482
replaced with revised version Sun, 5 Oct 2025 10:40:38 GMT   (4521kb)

Title: HP-BERT: A framework for longitudinal study of Hinduphobia on social
  media via language models
Authors: Ashutosh Singh and Rohitash Chandra
Categories: cs.CL cs.SI
\\ ( https://arxiv.org/abs/2501.05482 ,  4521kb)
------------------------------------------------------------------------------
\\
arXiv:2501.06256
replaced with revised version Mon, 6 Oct 2025 11:37:13 GMT   (6487kb)

Title: Unlocking In-Context Learning for Natural Datasets Beyond Language
  Modelling
Authors: Jelena Bratuli\'c, Sudhanshu Mittal, David T. Hoffmann, Samuel B\"ohm,
  Robin Tibor Schirrmeister, Tonio Ball, Christian Rupprecht, Thomas Brox
Categories: cs.CL cs.AI cs.LG
Comments: Best Paper Honorable Mention at GCPR 2025 (German Conference on
  Pattern Recognition). This is the updated version submitted to the
  conference, not the official conference proceedings
\\ ( https://arxiv.org/abs/2501.06256 ,  6487kb)
------------------------------------------------------------------------------
\\
arXiv:2501.13948
replaced with revised version Sun, 5 Oct 2025 09:36:04 GMT   (3869kb)

Title: Longitudinal Abuse and Sentiment Analysis of Hollywood Movie Dialogues
  using Language Models
Authors: Rohitash Chandra, Guoxiang Ren, Group-H
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2501.13948 ,  3869kb)
------------------------------------------------------------------------------
\\
arXiv:2501.19093
replaced with revised version Sat, 4 Oct 2025 13:30:53 GMT   (1880kb)

Title: Improving Low-Resource Sequence Labeling with Knowledge Fusion and
  Contextual Label Explanations
Authors: Peichao Lai, Jiaxin Gan, Feiyang Ye, Yilei Wang and Bin Cui
Categories: cs.CL
\\ ( https://arxiv.org/abs/2501.19093 ,  1880kb)
------------------------------------------------------------------------------
\\
arXiv:2502.09667
replaced with revised version Mon, 6 Oct 2025 14:57:36 GMT   (314kb)

Title: Summaries as Centroids for Interpretable and Scalable Text Clustering
Authors: Jairo Diaz-Rodriguez
Categories: cs.CL cs.LG stat.ML
\\ ( https://arxiv.org/abs/2502.09667 ,  314kb)
------------------------------------------------------------------------------
\\
arXiv:2502.14037
replaced with revised version Mon, 6 Oct 2025 13:37:50 GMT   (384kb)

Title: DiffSampling: Enhancing Diversity and Accuracy in Neural Text Generation
Authors: Giorgio Franceschelli and Mirco Musolesi
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2502.14037 ,  384kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16901
replaced with revised version Fri, 3 Oct 2025 21:24:33 GMT   (20157kb)

Title: Char-mander Use mBackdoor! A Study of Cross-lingual Backdoor Attacks in
  Multilingual LLMs
Authors: Himanshu Beniwal, Sailesh Panda, Birudugadda Srivibhav, Mayank Singh
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2502.16901 ,  20157kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18209
replaced with revised version Sat, 4 Oct 2025 16:02:01 GMT   (17920kb)

Title: League: Leaderboard Generation on Demand
Authors: Jian Wu, Jiayu Zhang, Dongyuan Li, Linyi Yang, Aoxiao Zhong, Renhe
  Jiang, Qingsong Wen, Yue Zhang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2502.18209 ,  17920kb)
------------------------------------------------------------------------------
\\
arXiv:2502.18886
replaced with revised version Sun, 5 Oct 2025 16:30:59 GMT   (154kb)

Title: On Pruning State-Space LLMs
Authors: Tamer Ghattas, Michael Hassid, Roy Schwartz
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2502.18886 ,  154kb)
------------------------------------------------------------------------------
\\
arXiv:2502.19064
replaced with revised version Sat, 4 Oct 2025 09:24:24 GMT   (35kb)

Title: Can Large Language Models Outperform Non-Experts in Poetry Evaluation? A
  Comparative Study Using the Consensual Assessment Technique
Authors: Piotr Sawicki, Marek Grze\'s, Dan Brown, Fabr\'icio G\'oes
Categories: cs.CL
Comments: 18 pages, 3 figures. Accepted for publication at the 2025 Conference
  on Empirical Methods in Natural Language Processing (EMNLP)
\\ ( https://arxiv.org/abs/2502.19064 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:2503.00955
replaced with revised version Sun, 5 Oct 2025 10:24:08 GMT   (646kb)

Title: SemViQA: A Semantic Question Answering System for Vietnamese Information
  Fact-Checking
Authors: Dien X. Tran, Nam V. Nguyen, Thanh T. Tran, Anh T. Hoang, Tai V.
  Duong, Di T. Le, Phuc-Lu Le
Categories: cs.CL cs.AI
Comments: 18 pages
\\ ( https://arxiv.org/abs/2503.00955 ,  646kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02368
replaced with revised version Sat, 4 Oct 2025 08:17:16 GMT   (406kb)

Title: Evolutionary Guided Decoding: Iterative Value Refinement for LLMs
Authors: Zhenhua Liu, Lijun Li, Ruizhe Chen, Yuxian Jiang, Tong Zhu, Zhaochen
  Su, Wenliang Chen, Jing Shao
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2503.02368 ,  406kb)
------------------------------------------------------------------------------
\\
arXiv:2503.10714
replaced with revised version Sun, 5 Oct 2025 08:34:30 GMT   (731kb)

Title: ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient
  Long-Context LLMs
Authors: Xin Liu, Xudong Wang, Pei Liu, Guoming Tang
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2503.10714 ,  731kb)
------------------------------------------------------------------------------
\\
arXiv:2503.16965
replaced with revised version Mon, 6 Oct 2025 10:03:29 GMT   (3472kb)

Title: Praxis-VLM: Vision-Grounded Decision Making via Text-Driven
  Reinforcement Learning
Authors: Zhe Hu, Jing Li, Zhongzhu Pu, Hou Pong Chan, Yu Yin
Categories: cs.CL cs.CV
Comments: Accepted at NeurIPS 2025
\\ ( https://arxiv.org/abs/2503.16965 ,  3472kb)
------------------------------------------------------------------------------
\\
arXiv:2503.19551
replaced with revised version Sun, 5 Oct 2025 04:36:00 GMT   (1380kb)

Title: Scaling Laws of Synthetic Data for Language Models
Authors: Zeyu Qin, Qingxiu Dong, Xingxing Zhang, Li Dong, Xiaolong Huang, Ziyi
  Yang, Mahmoud Khademi, Dongdong Zhang, Hany Hassan Awadalla, Yi R. Fung,
  Weizhu Chen, Minhao Cheng, Furu Wei
Categories: cs.CL cs.AI
Comments: COLM 2025
\\ ( https://arxiv.org/abs/2503.19551 ,  1380kb)
------------------------------------------------------------------------------
\\
arXiv:2504.01346
replaced with revised version Sun, 5 Oct 2025 07:24:41 GMT   (3643kb)

Title: RAG over Tables: Hierarchical Memory Index, Multi-Stage Retrieval, and
  Benchmarking
Authors: Jiaru Zou, Dongqi Fu, Sirui Chen, Xinrui He, Zihao Li, Yada Zhu,
  Jiawei Han, and Jingrui He
Categories: cs.CL cs.IR cs.LG
Comments: Project Link: https://github.com/jiaruzouu/T-RAG
\\ ( https://arxiv.org/abs/2504.01346 ,  3643kb)
------------------------------------------------------------------------------
\\
arXiv:2504.01667
replaced with revised version Mon, 6 Oct 2025 12:36:33 GMT   (7357kb)

Title: Testing Low-Resource Language Support in LLMs Using Language Proficiency
  Exams: the Case of Luxembourgish
Authors: Cedric Lothritz, Jordi Cabot, Laura Bernardy
Categories: cs.CL
Comments: 23pages, 4 figures, 14 tables
\\ ( https://arxiv.org/abs/2504.01667 ,  7357kb)
------------------------------------------------------------------------------
\\
arXiv:2504.03616
replaced with revised version Fri, 3 Oct 2025 20:14:38 GMT   (9338kb)

Title: Multilingual Retrieval-Augmented Generation for Knowledge-Intensive Task
Authors: Leonardo Ranaldi and Barry Haddow and Alexandra Birch
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2504.03616 ,  9338kb)
------------------------------------------------------------------------------
\\
arXiv:2504.07421
replaced with revised version Sun, 5 Oct 2025 21:28:53 GMT   (6254kb)

Title: AgentAda: Skill-Adaptive Data Analytics for Tailored Insight Discovery
Authors: Amirhossein Abaskohi, Amrutha Varshini Ramesh, Shailesh Nanisetty,
  Chirag Goel, David Vazquez, Christopher Pal, Spandana Gella, Giuseppe
  Carenini, Issam H. Laradji
Categories: cs.CL
\\ ( https://arxiv.org/abs/2504.07421 ,  6254kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08905
replaced with revised version Sun, 5 Oct 2025 05:44:30 GMT   (1442kb)

Title: Forecasting Conversation Derailments Through Generation
Authors: Yunfan Zhang, Kathleen McKeown, Smaranda Muresan
Categories: cs.CL
Comments: ACL INLG 2025
\\ ( https://arxiv.org/abs/2504.08905 ,  1442kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01479
replaced with revised version Mon, 6 Oct 2025 04:14:44 GMT   (123kb)

Title: Deliberate Planning in Language Models with Symbolic Representation
Authors: Siheng Xiong, Zhangding Liu, Jieyu Zhou, Yusen Su
Categories: cs.CL
Comments: Accepted to Twelfth Annual Conference on Advances in Cognitive
  Systems
\\ ( https://arxiv.org/abs/2505.01479 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:2505.06698
replaced with revised version Mon, 6 Oct 2025 04:36:33 GMT   (2060kb)

Title: SCAN: Structured Capability Assessment and Navigation for LLMs
Authors: Zongqi Wang, Tianle Gu, Chen Gong, Xin Tian, Siqi Bao, Yujiu Yang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.06698 ,  2060kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10320
replaced with revised version Sun, 5 Oct 2025 21:28:03 GMT   (4772kb)

Title: J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning
Authors: Chenxi Whitehouse, Tianlu Wang, Ping Yu, Xian Li, Jason Weston, Ilia
  Kulikov, Swarnadeep Saha
Categories: cs.CL cs.AI cs.LG
Comments: 10 pages, 13 tables, 14 figures
\\ ( https://arxiv.org/abs/2505.10320 ,  4772kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10493
replaced with revised version Sat, 4 Oct 2025 03:57:52 GMT   (5934kb)

Title: DACL-RAG: Data Augmentation Strategy with Curriculum Learning for
  Retrieval-Augmented Generation
Authors: Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao and Yongdong
  Zhang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.10493 ,  5934kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15062
replaced with revised version Fri, 3 Oct 2025 19:41:22 GMT   (1730kb)

Title: Self-GIVE: Associative Thinking from Limited Structured Knowledge for
  Enhanced Large Language Model Reasoning
Authors: Jiashu He, Jinxuan Fan, Bowen Jiang, Ignacio Houine, Dan Roth,
  Alejandro Ribeiro
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2505.15062 ,  1730kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17098
replaced with revised version Mon, 6 Oct 2025 13:42:58 GMT   (2651kb)

Title: TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided
  Sequence Configuration
Authors: Yanshu Li, Jianjiang Yang, Tian Yun, Pinyuan Feng, Jinfa Huang,
  Ruixiang Tang
Categories: cs.CL cs.CV
Comments: EMNLP2025 Main, 28 pages, 11 figures, 19 tables
\\ ( https://arxiv.org/abs/2505.17098 ,  2651kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17101
replaced with revised version Sat, 4 Oct 2025 07:30:20 GMT   (1955kb)

Title: A quantitative analysis of semantic information in deep representations
  of text and images
Authors: Santiago Acevedo, Andrea Mascaretti, Riccardo Rende, Mat\'eo Mahaut,
  Marco Baroni and Alessandro Laio
Categories: cs.CL cs.LG physics.comp-ph
\\ ( https://arxiv.org/abs/2505.17101 ,  1955kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17322
replaced with revised version Sat, 4 Oct 2025 20:23:05 GMT   (15949kb)

Title: From Compression to Expression: A Layerwise Analysis of In-Context
  Learning
Authors: Jiachen Jiang and Yuxin Dong and Jinxin Zhou and Zhihui Zhu
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.17322 ,  15949kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17601
replaced with revised version Sat, 4 Oct 2025 07:40:17 GMT   (3244kb)

Title: Revisiting Backdoor Attacks on LLMs: A Stealthy and Practical Poisoning
  Framework via Harmless Inputs
Authors: Jiawei Kong, Hao Fang, Xiaochen Yang, Kuofeng Gao, Bin Chen, Shu-Tao
  Xia, Ke Xu, Han Qiu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.17601 ,  3244kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18562
replaced with revised version Mon, 6 Oct 2025 04:31:03 GMT   (9874kb)

Title: From Word to World: Evaluate and Mitigate Culture Bias in LLMs via Word
  Association Test
Authors: Xunlian Dai and Li Zhou and Benyou Wang and Haizhou Li
Categories: cs.CL cs.AI
Comments: Cultural Analysis, Cultural Alignment, Word Association Test, Large
  Language Models. Accepted by EMNLP 2025 (Oral)
\\ ( https://arxiv.org/abs/2505.18562 ,  9874kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18677
replaced with revised version Sun, 5 Oct 2025 17:08:52 GMT   (1983kb)

Title: Social Good or Scientific Curiosity? Uncovering the Research Framing
  Behind NLP Artefacts
Authors: Eric Chamoun, Nedjma Ousidhoum, Michael Schlichtkrull, Andreas Vlachos
Categories: cs.CL
\\ ( https://arxiv.org/abs/2505.18677 ,  1983kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22765
replaced with revised version Sun, 5 Oct 2025 12:21:35 GMT   (444kb)

Title: StressTest: Can YOUR Speech LM Handle the Stress?
Authors: Iddo Yosha, Gallil Maimon, Yossi Adi
Categories: cs.CL cs.SD eess.AS
\\ ( https://arxiv.org/abs/2505.22765 ,  444kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22777
replaced with revised version Mon, 6 Oct 2025 14:06:40 GMT   (9814kb)

Title: MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain
  Dialogue Evaluators
Authors: John Mendon\c{c}a, Alon Lavie, Isabel Trancoso
Categories: cs.CL
Comments: October ARR
\\ ( https://arxiv.org/abs/2505.22777 ,  9814kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22830
replaced with revised version Fri, 3 Oct 2025 22:11:15 GMT   (3826kb)

Title: What Has Been Lost with Synthetic Evaluation?
Authors: Alexander Gill, Abhilasha Ravichander, Ana Marasovi\'c
Categories: cs.CL cs.AI
Comments: v3: Camera Ready
\\ ( https://arxiv.org/abs/2505.22830 ,  3826kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23832
replaced with revised version Sun, 5 Oct 2025 10:33:33 GMT   (2187kb)

Title: LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements
  Generation
Authors: Chaeeun Kim, Jinu Lee, Wonseok Hwang
Categories: cs.CL cs.IR
Comments: EMNLP 2025 Main Conference
\\ ( https://arxiv.org/abs/2505.23832 ,  2187kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00883
replaced with revised version Sat, 4 Oct 2025 06:48:26 GMT   (1335kb)

Title: Improve MLLM Benchmark Efficiency through Interview
Authors: Farong Wen, Yijin Guo, Junying Wang, Jiaohao Xiao, Yingjie Zhou, Ye
  Shen, Qi Jia, Chunyi Li, Zicheng Zhang
Categories: cs.CL
\\ ( https://arxiv.org/abs/2506.00883 ,  1335kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01713
replaced with revised version Sun, 5 Oct 2025 05:53:45 GMT   (4310kb)

Title: SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware
  Reinforcement Learning
Authors: Zhongwei Wan, Zhihao Dou, Che Liu, Yu Zhang, Dongfei Cui, Qinjian
  Zhao, Hui Shen, Jing Xiong, Yi Xin, Yifan Jiang, Chaofan Tao, Yangfan He, Mi
  Zhang, Shen Yan
Categories: cs.CL
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2506.01713 ,  4310kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04405
replaced with revised version Sun, 5 Oct 2025 17:59:37 GMT   (2864kb)

Title: MedAgentGym: A Scalable Agentic Training Environment for Code-Centric
  Reasoning in Biomedical Data Science
Authors: Ran Xu, Yuchen Zhuang, Yishan Zhong, Yue Yu, Zifeng Wang, Xiangru
  Tang, Hang Wu, May D. Wang, Peifeng Ruan, Donghan Yang, Tao Wang, Guanghua
  Xiao, Xin Liu, Carl Yang, Yang Xie, Wenqi Shi
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2506.04405 ,  2864kb)
------------------------------------------------------------------------------
\\
arXiv:2506.04557
replaced with revised version Fri, 3 Oct 2025 19:55:57 GMT   (2733kb)

Title: SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for
  Under-Resourced African Languages?
Authors: Senyu Li, Jiayi Wang, Felermino D. M. A. Ali, Colin Cherry, Daniel
  Deutsch, Eleftheria Briakou, Rui Sousa-Silva, Henrique Lopes Cardoso, Pontus
  Stenetorp, David Ifeoluwa Adelani
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2506.04557 ,  2733kb)
------------------------------------------------------------------------------
\\
arXiv:2506.05278
replaced with revised version Fri, 3 Oct 2025 20:47:40 GMT   (1074kb)

Title: Micro-Act: Mitigating Knowledge Conflict in LLM-based RAG via Actionable
  Self-Reasoning
Authors: Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li,
  Chenhao Ma, Reynold Cheng
Categories: cs.CL cs.AI
Comments: Accepted by ACL 2025 Main
\\ ( https://arxiv.org/abs/2506.05278 ,  1074kb)
------------------------------------------------------------------------------
\\
arXiv:2506.09669
replaced with revised version Mon, 6 Oct 2025 09:08:21 GMT   (204kb)

Title: Query-Level Uncertainty in Large Language Models
Authors: Lihu Chen, Gerard de Melo, Fabian M. Suchanek, Ga\"el Varoquaux
Categories: cs.CL
Comments: Under Review
\\ ( https://arxiv.org/abs/2506.09669 ,  204kb)
------------------------------------------------------------------------------
\\
arXiv:2506.12229
replaced with revised version Sat, 4 Oct 2025 19:44:59 GMT   (7979kb)

Title: Infini-gram mini: Exact n-gram Search at the Internet Scale with
  FM-Index
Authors: Hao Xu, Jiacheng Liu, Yejin Choi, Noah A. Smith, Hannaneh Hajishirzi
Categories: cs.CL
\\ ( https://arxiv.org/abs/2506.12229 ,  7979kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14474
replaced with revised version Sun, 5 Oct 2025 10:47:19 GMT   (94kb)

Title: LexiMark: Robust Watermarking via Lexical Substitutions to Enhance
  Membership Verification of an LLM's Textual Training Data
Authors: Eyal German, Sagiv Antebi, Edan Habler, Asaf Shabtai, Yuval Elovici
Categories: cs.CL cs.CR
\\ ( https://arxiv.org/abs/2506.14474 ,  94kb)
------------------------------------------------------------------------------
\\
arXiv:2506.20666
replaced with revised version Mon, 6 Oct 2025 17:52:34 GMT   (662kb)

Title: Using cognitive models to reveal value trade-offs in language models
Authors: Sonia K. Murthy, Rosie Zhao, Jennifer Hu, Sham Kakade, Markus
  Wulfmeier, Peng Qian, Tomer Ullman
Categories: cs.CL cs.AI
Comments: 10 pages, 5 figures
\\ ( https://arxiv.org/abs/2506.20666 ,  662kb)
------------------------------------------------------------------------------
\\
arXiv:2507.02778
replaced with revised version Sat, 4 Oct 2025 08:57:59 GMT   (3949kb)

Title: Self-Correction Bench: Uncovering and Addressing the Self-Correction
  Blind Spot in Large Language Models
Authors: Ken Tsui
Categories: cs.CL cs.AI cs.LG
Comments: 26 pages, 16 figures
\\ ( https://arxiv.org/abs/2507.02778 ,  3949kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05517
replaced with revised version Sat, 4 Oct 2025 15:31:53 GMT   (303kb)

Title: Empowering Healthcare Practitioners with Language Models: Structuring
  Speech Transcripts in Two Real-World Clinical Applications
Authors: Jean-Philippe Corbeil, Asma Ben Abacha, George Michalopoulos, Phillip
  Swazinna, Miguel Del-Agua, Jerome Tremblay, Akila Jeeson Daniel, Cari Bader,
  Yu-Cheng Cho, Pooja Krishnan, Nathan Bodenstab, Thomas Lin, Wenxuan Teng,
  Francois Beaulieu, Paul Vozila
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2507.05517 ,  303kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05890
replaced with revised version Mon, 6 Oct 2025 09:54:02 GMT   (302kb)

Title: Psychometric Item Validation Using Virtual Respondents with
  Trait-Response Mediators
Authors: Sungjib Lim, Woojung Song, Eun-Ju Lee, Yohan Jo
Categories: cs.CL cs.AI
Comments: 21 pages, 9 figures
\\ ( https://arxiv.org/abs/2507.05890 ,  302kb)
------------------------------------------------------------------------------
\\
arXiv:2507.11625
replaced with revised version Fri, 3 Oct 2025 18:52:18 GMT   (7290kb)

Title: MapIQ: Evaluating Multimodal Large Language Models for Map Question
  Answering
Authors: Varun Srivastava, Fan Lei, Srija Mukhopadhyay, Vivek Gupta, Ross
  Maciejewski
Categories: cs.CL cs.AI cs.CV cs.LG
Comments: Published as a conference paper at COLM 2025
\\ ( https://arxiv.org/abs/2507.11625 ,  7290kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16199
replaced with revised version Sun, 5 Oct 2025 10:02:35 GMT   (423kb)

Title: WakenLLM: Evaluating Reasoning Potential and Stability in LLMs via
  Fine-Grained Benchmarking
Authors: Zipeng Ling, Yuehao Tang, Shuliang Liu, Junqi Yang, Shenghong Fu, Chen
  Huang, Kejia Huang, Yao Wan, Zhichao Hou, Xuming Hu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2507.16199 ,  423kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16459
replaced with revised version Mon, 6 Oct 2025 10:07:53 GMT   (5294kb)

Title: Towards Enforcing Company Policy Adherence in Agentic Workflows
Authors: Naama Zwerdling, David Boaz, Ella Rabinovich, Guy Uziel, David Amid,
  Ateret Anaby-Tavor
Categories: cs.CL
Comments: EMNLP2025 (industry track), 12 pages
\\ ( https://arxiv.org/abs/2507.16459 ,  5294kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21544
replaced with revised version Mon, 6 Oct 2025 09:59:30 GMT   (626kb)

Title: MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts
  in Retrieval-Augmented Generation
Authors: Jungyeon Lee, Kangmin Lee, Taeuk Kim
Categories: cs.CL
Journal-ref: EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2507.21544 ,  626kb)
------------------------------------------------------------------------------
\\
arXiv:2507.21750
replaced with revised version Sat, 4 Oct 2025 21:04:38 GMT   (315kb)

Title: Adversarial Defence without Adversarial Defence: Enhancing Language
  Model Robustness via Instance-level Principal Component Removal
Authors: Yang Wang, Chenghao Xiao, Yizhi Li, Stuart E. Middleton, Noura Al
  Moubayed, Chenghua Lin
Categories: cs.CL
Comments: This paper was accepted with an A-decision to Transactions of the
  Association for Computational Linguistics. This version is the
  pre-publication version prior to MIT Press production
\\ ( https://arxiv.org/abs/2507.21750 ,  315kb)
------------------------------------------------------------------------------
\\
arXiv:2507.22968
replaced with revised version Sun, 5 Oct 2025 11:17:29 GMT   (33978kb)

Title: C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring
  Challenges in Complex Conversations
Authors: Chengqian Ma, Wei Tao, Yiwen Guo
Categories: cs.CL cs.AI
Comments: EMNLP 2025 main; Project Page: https://step-out.github.io/C3-web/
\\ ( https://arxiv.org/abs/2507.22968 ,  33978kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23158
replaced with revised version Sat, 4 Oct 2025 16:01:31 GMT   (522kb)

Title: User Feedback in Human-LLM Dialogues: A Lens to Understand Users But
  Noisy as a Learning Signal
Authors: Yuhan Liu, Michael J.Q. Zhang, Eunsol Choi
Categories: cs.CL
Comments: EMNLP camera-ready
\\ ( https://arxiv.org/abs/2507.23158 ,  522kb)
------------------------------------------------------------------------------
\\
arXiv:2508.00924
replaced with revised version Sun, 5 Oct 2025 16:40:38 GMT   (316kb)

Title: XAutoLM: Efficient Fine-Tuning of Language Models via Meta-Learning and
  AutoML
Authors: Ernesto L. Estevanell-Valladares, Suilan Estevez-Velarde, Yoan
  Guti\'errez, Andr\'es Montoyo and Ruslan Mitkov
Categories: cs.CL
Comments: 18 pages, 10 figures, 7 tables. Preprint. Accepted at EMNLP 2025
MSC-class: 68T05, 68T50
ACM-class: I.2.6; I.2.7; I.2.8
\\ ( https://arxiv.org/abs/2508.00924 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08163
replaced with revised version Sun, 5 Oct 2025 01:07:12 GMT   (2863kb)

Title: LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via
  Metadata and Loss Reweighting with DisCo
Authors: Mandira Sawkar, Samay U. Shetty, Deepak Pandita, Tharindu Cyril
  Weerasooriya, Christopher M. Homan
Categories: cs.CL cs.AI cs.LG
Comments: To appear in Proceedings of the EMNLP 2025 Workshop on Learning with
  Disagreements (LeWiDi)
\\ ( https://arxiv.org/abs/2508.08163 ,  2863kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09138
replaced with revised version Mon, 6 Oct 2025 14:46:22 GMT   (3518kb)

Title: Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language
  Models
Authors: Wen Wang, Bozhen Fang, Chenchen Jing, Yongliang Shen, Yangyi Shen,
  Qiuyu Wang, Hao Ouyang, Hao Chen, Chunhua Shen
Categories: cs.CL cs.AI
Comments: Project webpage: https://aim-uofa.github.io/dLLM-MidTruth
\\ ( https://arxiv.org/abs/2508.09138 ,  3518kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09350
replaced with revised version Fri, 3 Oct 2025 20:22:23 GMT   (141kb)

Title: Flow-SLM: Joint Learning of Linguistic and Acoustic Information for
  Spoken Language Modeling
Authors: Ju-Chieh Chou, Jiawei Zhou, Karen Livescu
Categories: cs.CL
Comments: ASRU 2025
\\ ( https://arxiv.org/abs/2508.09350 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12903
replaced with revised version Sun, 5 Oct 2025 15:00:27 GMT   (821kb)

Title: A Stitch in Time Saves Nine: Proactive Self-Refinement for Language
  Models
Authors: Jinyi Han, Xinyi Wang, Haiquan Zhao, Tingyun li, Zishang Jiang, Sihang
  Jiang, Jiaqing Liang, Xin Lin, Weikang Zhou, Zeye Sun, Fei Yu, Yanghua Xiao
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2508.12903 ,  821kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13118
replaced with revised version Mon, 6 Oct 2025 01:53:26 GMT   (3429kb)

Title: AutoBnB-RAG: Enhancing Multi-Agent Incident Response with
  Retrieval-Augmented Generation
Authors: Zefang Liu, Arman Anwar
Categories: cs.CL cs.CR
\\ ( https://arxiv.org/abs/2508.13118 ,  3429kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13141
replaced with revised version Sat, 4 Oct 2025 14:25:22 GMT   (2102kb)

Title: OptimalThinkingBench: Evaluating Over and Underthinking in LLMs
Authors: Pranjal Aggarwal, Seungone Kim, Jack Lanchantin, Sean Welleck, Jason
  Weston, Ilia Kulikov, Swarnadeep Saha
Categories: cs.CL cs.LG
Comments: 30 pages, 10 tables, 11 figures
\\ ( https://arxiv.org/abs/2508.13141 ,  2102kb)
------------------------------------------------------------------------------
\\
arXiv:2508.15658
replaced with revised version Sat, 4 Oct 2025 16:52:09 GMT   (87kb)

Title: SurGE: A Benchmark and Evaluation Framework for Scientific Survey
  Generation
Authors: Weihang Su, Anzhe Xie, Qingyao Ai, Jianming Long, Jiaxin Mao, Ziyi Ye,
  Yiqun Liu
Categories: cs.CL cs.AI cs.IR
\\ ( https://arxiv.org/abs/2508.15658 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16048
replaced with revised version Mon, 6 Oct 2025 02:43:38 GMT   (170kb)

Title: OpenWHO: A Document-Level Parallel Corpus for Health Translation in
  Low-Resource Languages
Authors: Rapha\"el Merx, Hanna Suominen, Trevor Cohn, Ekaterina Vylomova
Categories: cs.CL cs.AI
Comments: Accepted at WMT 2025
\\ ( https://arxiv.org/abs/2508.16048 ,  170kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16889
replaced with revised version Sun, 5 Oct 2025 22:27:27 GMT   (203kb)

Title: ObjexMT: Objective Extraction and Metacognitive Calibration for
  LLM-as-a-Judge under Multi-Turn Jailbreaks
Authors: Hyunjun Kim, Junwoo Ha, Sangyoon Yu, Haon Park
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.16889 ,  203kb)
------------------------------------------------------------------------------
\\
arXiv:2508.17225
replaced with revised version Sat, 4 Oct 2025 11:26:02 GMT   (1220kb)

Title: SSFO: Self-Supervised Faithfulness Optimization for Retrieval-Augmented
  Generation
Authors: Xiaqiang Tang, Yi Wang, Keyu Hu, Rui Xu, Chuang Li, Weigao Sun, Jian
  Li, Sihong Xie
Categories: cs.CL cs.AI
Comments: Working in progress
\\ ( https://arxiv.org/abs/2508.17225 ,  1220kb)
------------------------------------------------------------------------------
\\
arXiv:2508.18709
replaced with revised version Sun, 5 Oct 2025 23:38:18 GMT   (1531kb)

Title: Filtering for Creativity: Adaptive Prompting for Multilingual Riddle
  Generation in LLMs
Authors: Duy Le, Kent Ziti, Evan Girard-Sun, Bakr Bouhaya, Sean O'Brien, Vasu
  Sharma, Kevin Zhu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2508.18709 ,  1531kb)
------------------------------------------------------------------------------
\\
arXiv:2509.02160
replaced with revised version Sat, 4 Oct 2025 10:54:49 GMT   (2090kb)

Title: Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in
  Low-Resource Philippine Languages
Authors: David Demitri Africa, Suchir Salhan, Yuval Weiss, Paula Buttery,
  Richard Diehl Martinez
Categories: cs.CL cs.AI
Comments: Accepted (poster) to 5th Workshop on Multilingual Representation
  Learning at EMNLP 2025
\\ ( https://arxiv.org/abs/2509.02160 ,  2090kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04784
replaced with revised version Sat, 4 Oct 2025 00:42:38 GMT   (211kb)

Title: Post-training Large Language Models for Diverse High-Quality Responses
Authors: Yilei Chen, Souradip Chakraborty, Lorenz Wolf, Yannis Paschalidis,
  Aldo Pacchiano
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2509.04784 ,  211kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08729
replaced with revised version Sun, 5 Oct 2025 22:27:29 GMT   (542kb)

Title: X-Teaming Evolutionary M2S: Automated Discovery of Multi-turn to
  Single-turn Jailbreak Templates
Authors: Hyunjun Kim, Junwoo Ha, Sangyoon Yu, Haon Park
Categories: cs.CL cs.AI
Comments: NeurIPS 2025 Workshop on Lock-LLM
\\ ( https://arxiv.org/abs/2509.08729 ,  542kb)
------------------------------------------------------------------------------
\\
arXiv:2509.08825
replaced with revised version Mon, 6 Oct 2025 16:58:59 GMT   (807kb)

Title: Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs
  for Text Annotation
Authors: Joachim Baumann, Paul R\"ottger, Aleksandra Urman, Albert Wendsj\"o,
  Flor Miriam Plaza-del-Arco, Johannes B. Gruber, Dirk Hovy
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.08825 ,  807kb)
------------------------------------------------------------------------------
\\
arXiv:2509.10127
replaced with revised version Sat, 4 Oct 2025 09:04:38 GMT   (1711kb)

Title: Population-Aligned Persona Generation for LLM-based Social Simulation
Authors: Zhengyu Hu, Jianxun Lian, Zheyuan Xiao, Max Xiong, Yuxuan Lei, Tianfu
  Wang, Kaize Ding, Ziang Xiao, Nicholas Jing Yuan, Xing Xie
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.10127 ,  1711kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11465
replaced with revised version Sun, 5 Oct 2025 16:11:19 GMT   (3129kb)

Title: CEMTM: Contextual Embedding-based Multimodal Topic Modeling
Authors: Amirhossein Abaskohi, Raymond Li, Chuyuan Li, Shafiq Joty, Giuseppe
  Carenini
Categories: cs.CL cs.LG
Comments: EMNLP 2025
\\ ( https://arxiv.org/abs/2509.11465 ,  3129kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11591
replaced with revised version Sat, 4 Oct 2025 02:05:13 GMT   (443kb)

Title: Analyzing Information-Seeking Behaviors in a Hakka AI Chatbot: A
  Cognitive-Pragmatic Study
Authors: Chu-Hsuan Lee, Chen-Chi Chang, Hung-Shin Lee, Yun-Hsiang Hsu,
  Ching-Yuan Chen
Categories: cs.CL
Comments: Accepted to HICSS-59 (2026)
\\ ( https://arxiv.org/abs/2509.11591 ,  443kb)
------------------------------------------------------------------------------
\\
arXiv:2509.12508
replaced with revised version Sun, 5 Oct 2025 21:27:32 GMT   (1530kb)

Title: Fun-ASR Technical Report
Authors: Keyu An, Yanni Chen, Chong Deng, Changfeng Gao, Zhifu Gao, Bo Gong,
  Xiangang Li, Yabin Li, Xiang Lv, Yunjie Ji, Yiheng Jiang, Bin Ma, Haoneng
  Luo, Chongjia Ni, Zexu Pan, Yiping Peng, Zhendong Peng, Peiyao Wang, Hao
  Wang, Wen Wang, Wupeng Wang, Biao Tian, Zhentao Tan, Nan Yang, Bin Yuan,
  Jieping Ye, Jixing Yu, Qinglin Zhang, Kun Zou, Han Zhao, Shengkui Zhao,
  Jingren Zhou
Categories: cs.CL cs.AI cs.SD eess.AS
Comments: Authors are listed in alphabetical order
\\ ( https://arxiv.org/abs/2509.12508 ,  1530kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14760
replaced with revised version Sun, 5 Oct 2025 07:56:54 GMT   (4381kb)

Title: Reasoning over Boundaries: Enhancing Specification Alignment via
  Test-time Deliberation
Authors: Haoran Zhang, Yafu Li, Xuyang Hu, Dongrui Liu, Zhilin Wang, Bo Li, Yu
  Cheng
Categories: cs.CL
Comments: 10 pages main text, 52 pages total (including appendix). Code and
  resources are available at https://github.com/zzzhr97/SpecBench
\\ ( https://arxiv.org/abs/2509.14760 ,  4381kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16551
replaced with revised version Sat, 4 Oct 2025 06:12:27 GMT   (127kb)

Title: Rethinking the Role of Text Complexity in Language Model Pretraining
Authors: Dan John Velasco and Matthew Theodore Roque
Categories: cs.CL cs.AI
Comments: Camera-ready version for BabyLM Workshop at EMNLP 2025
\\ ( https://arxiv.org/abs/2509.16551 ,  127kb)
------------------------------------------------------------------------------
\\
arXiv:2509.16929
replaced with revised version Sat, 4 Oct 2025 02:50:41 GMT   (493kb)

Title: K-DeCore: Facilitating Knowledge Transfer in Continual Structured
  Knowledge Reasoning via Knowledge Decoupling
Authors: Yongrui Chen, Yi Huang, Yunchang Liu, Shenyu Zhang, Junhao He,
  Tongtong Wu, Guilin Qi, Tianxing Wu
Categories: cs.CL
Comments: Accepted in Neurips 2025 (poster)
\\ ( https://arxiv.org/abs/2509.16929 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20278
replaced with revised version Sun, 5 Oct 2025 11:12:05 GMT   (539kb)

Title: Instruction Boundary: Quantifying Biases in LLM Reasoning under Various
  Coverage
Authors: Zipeng Ling, Yuehao Tang, Chen Huang, Shuliang Liu, Gaoyang Jiang,
  Shenghong Fu, Junqi Yang, Yao Wan, Jiawan Zhang, Kejia Huang, Xuming Hu
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.20278 ,  539kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22075
replaced with revised version Mon, 6 Oct 2025 12:56:01 GMT   (4293kb)

Title: COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary
  Learning
Authors: Dmitriy Shopkhoev, Denis Makhov, Magauiya Zhussip, Ammar Ali,
  Stamatios Lefkimmiatis
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.22075 ,  4293kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22768
replaced with revised version Mon, 6 Oct 2025 14:53:27 GMT   (3448kb)

Title: ML2B: Multi-Lingual ML Benchmark For AutoML
Authors: Ekaterina Trofimova, Zosia Shamina, Maria Selifanova, Artem Zaitsev,
  Remi Savchuk, Maxim Minets, Daria Ozerova, Emil Sataev, Denis Zuenko, Andrey
  E. Ustyuzhanin
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.22768 ,  3448kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22876
replaced with revised version Fri, 3 Oct 2025 18:59:16 GMT   (3745kb)

Title: HEART: Emotionally-driven test-time scaling of Language Models
Authors: Gabriela Pinto, Palash Goyal, Yiwen Song, Souradip Chakraborty, Zifeng
  Wang, Tomas Pfister, Hamid Palangi
Categories: cs.CL cs.LG
\\ ( https://arxiv.org/abs/2509.22876 ,  3745kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23124
replaced with revised version Mon, 6 Oct 2025 12:23:18 GMT   (2777kb)

Title: Non-Collaborative User Simulators for Tool Agents
Authors: Jeonghoon Shim, Woojung Song, Cheyon Jin, Seungwon KooK, Yohan Jo
Categories: cs.CL
Comments: 9 pages
\\ ( https://arxiv.org/abs/2509.23124 ,  2777kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24613
replaced with revised version Sun, 5 Oct 2025 16:18:58 GMT   (641kb)

Title: HiKE: Hierarchical Evaluation Framework for Korean-English
  Code-Switching Speech Recognition
Authors: Gio Paik, Yongbeom Kim, Soungmin Lee, Sangmin Ahn, Chanwoo Kim
Categories: cs.CL cs.SD eess.AS
Comments: Updated table 2 and 3 due to bug fix, Under Review
\\ ( https://arxiv.org/abs/2509.24613 ,  641kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25085
replaced with revised version Mon, 6 Oct 2025 09:18:00 GMT   (72kb)

Title: jina-reranker-v3: Last but Not Late Interaction for Listwise Document
  Reranking
Authors: Feng Wang, Yuqing Li, Han Xiao
Categories: cs.CL cs.AI cs.IR
MSC-class: 68T50
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2509.25085 ,  72kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26314
replaced with revised version Mon, 6 Oct 2025 15:15:21 GMT   (599kb)

Title: Latent Thinking Optimization: Your Latent Reasoning Language Model
  Secretly Encodes Reward Signals in Its Latent Thoughts
Authors: Hanwen Du and Yuxin Dong and Xia Ning
Categories: cs.CL
\\ ( https://arxiv.org/abs/2509.26314 ,  599kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26431
replaced with revised version Mon, 6 Oct 2025 15:32:15 GMT   (0kb,I)

Title: Text-Based Approaches to Item Alignment to Content Standards in
  Large-Scale Reading & Writing Tests
Authors: Yanbin Fu, Hong Jiao, Tianyi Zhou, Robert W. Lissitz, Nan Zhang, Ming
  Li, Qingshu Xu, Sydney Peters
Categories: cs.CL
Comments: need updates
\\ ( https://arxiv.org/abs/2509.26431 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01171
replaced with revised version Mon, 6 Oct 2025 16:29:44 GMT   (28095kb)

Title: Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM
  Diversity
Authors: Jiayi Zhang, Simon Yu, Derek Chong, Anthony Sicilia, Michael R. Tomz,
  Christopher D. Manning, Weiyan Shi
Categories: cs.CL cs.AI
Comments: 79 pages, 27 figures, 31 tables. Code is available at
  https://github.com/CHATS-lab/verbalize-sampling
\\ ( https://arxiv.org/abs/2510.01171 ,  28095kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01238
replaced with revised version Mon, 6 Oct 2025 12:48:05 GMT   (139kb)

Title: Silent Tokens, Loud Effects: Padding in LLMs
Authors: Rom Himelstein, Amit LeVi, Yonatan Belinkov, Avi Mendelson
Categories: cs.CL cs.LG
Comments: Accepted to NeurIPS 2025 Workshop on Evaluating the Evolving LLM
  Lifecycle: Benchmarks, Emergent Abilities, and Scaling
\\ ( https://arxiv.org/abs/2510.01238 ,  139kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01617
replaced with revised version Mon, 6 Oct 2025 09:33:41 GMT   (2227kb)

Title: AMAS: Adaptively Determining Communication Topology for LLM-based
  Multi-Agent System
Authors: Hui Yi Leong, Yuheng Li, Yuqing Wu, Wenwen Ouyang, Wei Zhu, Jiechao
  Gao, Wei Han
Categories: cs.CL
Comments: Accepted by EMNLP-2025 Industrial Track
\\ ( https://arxiv.org/abs/2510.01617 ,  2227kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01688
replaced with revised version Sat, 4 Oct 2025 10:16:08 GMT   (802kb)

Title: Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation
Authors: Seungseop Lim, Gibaeg Kim, Wooseok Han, Jean Seo, Hyunkyung Lee,
  Jaehyo Yoo, Eunho Yang
Categories: cs.CL cs.AI
Comments: EMNLP 2025 Industry Track
\\ ( https://arxiv.org/abs/2510.01688 ,  802kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01932
replaced with revised version Sat, 4 Oct 2025 07:24:46 GMT   (3580kb)

Title: Veri-R1: Toward Precise and Faithful Claim Verification via Online
  Reinforcement Learning
Authors: Qi He, Cheng Qian, Xiusi Chen, Bingxiang He, Yi R. Fung, Heng Ji
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.01932 ,  3580kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02271
replaced with revised version Sat, 4 Oct 2025 09:18:41 GMT   (686kb)

Title: InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in
  Tool-Augmented Agents
Authors: Yaxin Du, Yuanshuo Zhang, Xiyuan Yang, Yifan Zhou, Cheng Wang, Gongyi
  Zou, Xianghe Pang, Wenhao Wang, Menglan Chen, Shuo Tang, Zhiyu Li, Feiyu
  Xiong, Siheng Chen
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2510.02271 ,  686kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02369
replaced with revised version Mon, 6 Oct 2025 09:40:38 GMT   (239kb)

Title: Beyond Manuals and Tasks: Instance-Level Context Learning for LLM Agents
Authors: Kuntai Cai, Juncheng Liu, Xianglin Yang, Zhaojie Niu, Xiaokui Xiao,
  Xing Chen
Categories: cs.CL cs.AI
\\ ( https://arxiv.org/abs/2510.02369 ,  239kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02375
replaced with revised version Mon, 6 Oct 2025 03:54:08 GMT   (29757kb)

Title: Pretraining with hierarchical memories: separating long-tail and common
  knowledge
Authors: Hadi Pouransari, David Grangier, C Thomas, Michael Kirchhof, Oncel
  Tuzel
Categories: cs.CL cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.02375 ,  29757kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03102
replaced with revised version Mon, 6 Oct 2025 14:04:39 GMT   (751kb)

Title: Semantic Similarity in Radiology Reports via LLMs and NER
Authors: Beth Pearson, Ahmed Adnan, Zahraa S. Abdallah
Categories: cs.CL
\\ ( https://arxiv.org/abs/2510.03102 ,  751kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03120
replaced with revised version Mon, 6 Oct 2025 13:13:37 GMT   (5173kb)

Title: SurveyBench: Can LLM(-Agents) Write Academic Surveys that Align with
  Reader Needs?
Authors: Zhaojun Sun, Xuzhou Zhu, Xuanhe Zhou, Xin Tong, Shuo Wang, Jie Fu,
  Guoliang Li, Zhiyuan Liu, Fan Wu
Categories: cs.CL
Comments: Visit our code repository at: https://github.com/weAIDB/SurveyBench
\\ ( https://arxiv.org/abs/2510.03120 ,  5173kb)
------------------------------------------------------------------------------
\\
arXiv:2312.17494
replaced with revised version Sat, 4 Oct 2025 02:16:57 GMT   (4083kb)

Title: QGFace: Quality-Guided Joint Training For Mixed-Quality Face Recognition
Authors: Youzhe Song and Feng Wang
Categories: cs.CV cs.MM
\\ ( https://arxiv.org/abs/2312.17494 ,  4083kb)
------------------------------------------------------------------------------
\\
arXiv:2402.15480
replaced with revised version Sat, 4 Oct 2025 07:25:00 GMT   (16998kb)

Title: Foveated Retinotopy Improves Classification and Localization in CNNs
Authors: Jean-Nicolas J\'er\'emie and Emmanuel Dauc\'e and Laurent U Perrinet
Categories: cs.CV q-bio.NC
\\ ( https://arxiv.org/abs/2402.15480 ,  16998kb)
------------------------------------------------------------------------------
\\
arXiv:2403.06461
replaced with revised version Sun, 5 Oct 2025 08:40:25 GMT   (14218kb)

Title: Interactive Test-Time Adaptation with Reliable Spatial-Temporal Voxels
  for Multi-Modal Segmentation
Authors: Haozhi Cao, Yuecong Xu, Pengyu Yin, Xingyu Ji, Shenghai Yuan, Jianfei
  Yang, Lihua Xie
Categories: cs.CV
\\ ( https://arxiv.org/abs/2403.06461 ,  14218kb)
------------------------------------------------------------------------------
\\
arXiv:2403.10390
replaced with revised version Sun, 5 Oct 2025 19:35:52 GMT   (2887kb)

Title: Evaluating Perceptual Distance Models by Fitting Binomial Distributions
  to Two-Alternative Forced Choice Data
Authors: Alexander Hepburn and Raul Santos-Rodriguez and Javier Portilla
Categories: cs.CV
\\ ( https://arxiv.org/abs/2403.10390 ,  2887kb)
------------------------------------------------------------------------------
\\
arXiv:2404.05606
replaced with revised version Sun, 5 Oct 2025 12:15:10 GMT   (4585kb)

Title: Reconstructing Topology-Consistent Face Mesh by Volume Rendering from
  Multi-View Images
Authors: Yating Wang, Ran Yi, Xiaoning Lei, Ke Fan, Jinkun Hao, Lizhuang Ma
Categories: cs.CV
\\ ( https://arxiv.org/abs/2404.05606 ,  4585kb)
------------------------------------------------------------------------------
\\
arXiv:2405.14386
replaced with revised version Sat, 4 Oct 2025 13:35:01 GMT   (1533kb)

Title: Capsule Network Projectors are Equivariant and Invariant Learners
Authors: Miles Everett, Aiden Durrant, Mingjun Zhong, and Georgios Leontidis
Categories: cs.CV
Comments: V4: accepted at TMLR; V3: Ignore V1 and V2 as we have fixed a bug; 18
  pages, 5 figures, 10 Tables
Journal-ref: Transactions on Machine Learning Research (TMLR), October 2025 -
  https://openreview.net/pdf?id=7owCO3qskH
\\ ( https://arxiv.org/abs/2405.14386 ,  1533kb)
------------------------------------------------------------------------------
\\
arXiv:2405.14715
replaced with revised version Mon, 6 Oct 2025 06:02:41 GMT   (2914kb)

Title: Towards Cross-modal Backward-compatible Representation Learning for
  Vision-Language Models
Authors: Young Kyun Jang, Ser-nam Lim
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2405.14715 ,  2914kb)
------------------------------------------------------------------------------
\\
arXiv:2406.19568
replaced with revised version Sun, 5 Oct 2025 14:29:28 GMT   (25642kb)

Title: How Far are AI-generated Videos from Simulating the 3D Visual World: A
  Learned 3D Evaluation Approach
Authors: Chirui Chang, Jiahui Liu, Zhengzhe Liu, Xiaoyang Lyu, Yi-Hua Huang,
  Xin Tao, Pengfei Wan, Di Zhang, Xiaojuan Qi
Categories: cs.CV cs.AI
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2406.19568 ,  25642kb)
------------------------------------------------------------------------------
\\
arXiv:2407.06150
replaced with revised version Sat, 4 Oct 2025 00:52:10 GMT   (29271kb)

Title: PanDORA: Casual HDR Radiance Acquisition for Indoor Scenes
Authors: Mohammad Reza Karimi Dastjerdi, Dominique Tanguay-Gaudreau,
  Fr\'ed\'eric Fortier-Chouinard, Yannick Hold-Geoffroy, Claude Demers, Nima
  Kalantari, Jean-Fran\c{c}ois Lalonde
Categories: cs.CV
Comments: 13 pages, 11 figures
\\ ( https://arxiv.org/abs/2407.06150 ,  29271kb)
------------------------------------------------------------------------------
\\
arXiv:2407.10575
replaced with revised version Mon, 6 Oct 2025 10:42:27 GMT   (642kb)

Title: A Survey of Defenses Against AI-Generated Visual Media:
  Detection,Disruption, and Authentication
Authors: Jingyi Deng, Chenhao Lin, Zhengyu Zhao, Shuai Liu, Zhe Peng, Qian
  Wang, Chao Shen
Categories: cs.CV
Comments: Accepted by ACM Computing Surveys
\\ ( https://arxiv.org/abs/2407.10575 ,  642kb)
------------------------------------------------------------------------------
\\
arXiv:2408.13147
replaced with revised version Sun, 5 Oct 2025 04:13:57 GMT   (8412kb)

Title: ShapeICP: Iterative Category-level Object Pose and Shape Estimation from
  Depth
Authors: Yihao Zhang, Harpreet S. Sawhney, John J. Leonard
Categories: cs.CV cs.AI cs.RO
\\ ( https://arxiv.org/abs/2408.13147 ,  8412kb)
------------------------------------------------------------------------------
\\
arXiv:2408.16357
replaced with revised version Mon, 6 Oct 2025 07:37:19 GMT   (6715kb)

Title: Law of Vision Representation in MLLMs
Authors: Shijia Yang, Bohan Zhai, Quanzeng You, Jianbo Yuan, Hongxia Yang,
  Chenfeng Xu
Categories: cs.CV
Comments: The code is available at
  https://github.com/bronyayang/Law_of_Vision_Representation_in_MLLMs
\\ ( https://arxiv.org/abs/2408.16357 ,  6715kb)
------------------------------------------------------------------------------
\\
arXiv:2410.02710
replaced with revised version Fri, 3 Oct 2025 17:51:33 GMT   (7480kb)

Title: SteerDiff: Steering towards Safe Text-to-Image Diffusion Models
Authors: Hongxiang Zhang, Yifeng He, Hao Chen
Categories: cs.CV cs.AI cs.CR
\\ ( https://arxiv.org/abs/2410.02710 ,  7480kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18804
replaced with revised version Mon, 6 Oct 2025 16:59:09 GMT   (30546kb)

Title: Fast constrained sampling in pre-trained diffusion models
Authors: Alexandros Graikos, Nebojsa Jojic, Dimitris Samaras
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2410.18804 ,  30546kb)
------------------------------------------------------------------------------
\\
arXiv:2410.18857
replaced with revised version Sun, 5 Oct 2025 16:26:02 GMT   (3778kb)

Title: Probabilistic Language-Image Pre-Training
Authors: Sanghyuk Chun and Wonjae Kim and Song Park and Sangdoo Yun
Categories: cs.CV cs.LG
Comments: Code: https://github.com/naver-ai/prolip HuggingFace Hub:
  https://huggingface.co/collections/SanghyukChun/prolip-6712595dfc87fd8597350291
  33 pages, 4.5 MB; LongProLIP paper: arXiv:2503.08048; Multiplicity paper for
  more background: arxiv.org:2505.19614; v4: fix typos
\\ ( https://arxiv.org/abs/2410.18857 ,  3778kb)
------------------------------------------------------------------------------
\\
arXiv:2410.20436
replaced with revised version Mon, 6 Oct 2025 09:41:21 GMT   (5572kb)

Title: CoralSCOP-LAT: Labeling and Analyzing Tool for Coral Reef Images with
  Dense Mask
Authors: Yuk-Kwan Wong, Ziqiang Zheng, Mingzhe Zhang, David Suggett, Sai-Kit
  Yeung
Categories: cs.CV
Comments: Ecological Informatics Page:
  https://www.sciencedirect.com/science/article/pii/S157495412500411X
Journal-ref: Ecological Informatics 2025
DOI: 10.1016/j.ecoinf.2025.103402
\\ ( https://arxiv.org/abs/2410.20436 ,  5572kb)
------------------------------------------------------------------------------
\\
arXiv:2411.04712
replaced with revised version Mon, 6 Oct 2025 10:21:14 GMT   (33198kb)

Title: SEE-DPO: Self Entropy Enhanced Direct Preference Optimization
Authors: Shivanshu Shekhar, Shreyas Singh, Tong Zhang
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2411.04712 ,  33198kb)
------------------------------------------------------------------------------
\\
arXiv:2411.11941
replaced with revised version Mon, 6 Oct 2025 02:13:04 GMT   (12605kb)

Title: TimeFormer: Capturing Temporal Relationships of Deformable 3D Gaussians
  for Robust Reconstruction
Authors: DaDong Jiang, Zhihui Ke, Xiaobo Zhou, Zhi Hou, Xianghui Yang, Wenbo
  Hu, Tie Qiu, Chunchao Guo
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2411.11941 ,  12605kb)
------------------------------------------------------------------------------
\\
arXiv:2411.17237
replaced with revised version Sun, 5 Oct 2025 07:07:14 GMT   (1364kb)

Title: Grounding-IQA: Grounding Multimodal Language Model for Image Quality
  Assessment
Authors: Zheng Chen, Xun Zhang, Wenbo Li, Renjing Pei, Fenglong Song, Xiongkuo
  Min, Xiaohong Liu, Xin Yuan, Yong Guo, Yulun Zhang
Categories: cs.CV
Comments: Code is available at: https://github.com/zhengchen1999/Grounding-IQA
\\ ( https://arxiv.org/abs/2411.17237 ,  1364kb)
------------------------------------------------------------------------------
\\
arXiv:2411.18142
replaced with revised version Mon, 6 Oct 2025 14:56:54 GMT   (6448kb)

Title: Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual
  Conversion in Visual Reasoning for Multimodal Large Language Models
Authors: Jingming Liu, Yumeng Li, Boyuan Xiao, Yichang Jian, Ziang Qin, Tianjia
  Shao, Yao-Xiang Ding, Kun Zhou
Categories: cs.CV
Comments: Published in TMLR
\\ ( https://arxiv.org/abs/2411.18142 ,  6448kb)
------------------------------------------------------------------------------
\\
arXiv:2412.07730
replaced with revised version Mon, 6 Oct 2025 05:11:37 GMT   (33345kb)

Title: STIV: Scalable Text and Image Conditioned Video Generation
Authors: Zongyu Lin and Wei Liu and Chen Chen and Jiasen Lu and Wenze Hu and
  Tsu-Jui Fu and Jesse Allardice and Zhengfeng Lai and Liangchen Song and Bowen
  Zhang and Cha Chen and Yiran Fei and Lezhi Li and Yizhou Sun and Kai-Wei
  Chang and Yinfei Yang
Categories: cs.CV cs.AI cs.LG cs.MM
\\ ( https://arxiv.org/abs/2412.07730 ,  33345kb)
------------------------------------------------------------------------------
\\
arXiv:2412.10525
replaced with revised version Mon, 6 Oct 2025 17:12:59 GMT   (15532kb)

Title: RowDetr: End-to-End Crop Row Detection Using Polynomials
Authors: Rahul Harsha Cheppally and Ajay Sharda
Categories: cs.CV cs.RO
Comments: Code will be open sourced upon publication
\\ ( https://arxiv.org/abs/2412.10525 ,  15532kb)
------------------------------------------------------------------------------
\\
arXiv:2412.11100
replaced with revised version Sun, 5 Oct 2025 03:21:44 GMT   (3389kb)

Title: DynamicScaler: Seamless and Scalable Video Generation for Panoramic
  Scenes
Authors: Jinxiu Liu and Shaoheng Lin and Yinxiao Li and Ming-Hsuan Yang
Categories: cs.CV
Comments: CVPR 2025
\\ ( https://arxiv.org/abs/2412.11100 ,  3389kb)
------------------------------------------------------------------------------
\\
arXiv:2501.10081
replaced with revised version Mon, 6 Oct 2025 08:32:42 GMT   (16188kb)

Title: Leveraging Confident Image Regions for Source-Free Domain-Adaptive
  Object Detection
Authors: Mohamed Lamine Mekhalfi, Davide Boscaini, Fabio Poiesi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2501.10081 ,  16188kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12157
replaced with revised version Mon, 6 Oct 2025 03:43:52 GMT   (3589kb)

Title: Fast-RF-Shimming: Accelerate RF Shimming in 7T MRI using Deep Learning
Authors: Zhengyi Lu, Hao Liang, Ming Lu, Xiao Wang, Xinqiang Yan, Yuankai Huo
Categories: cs.CV
\\ ( https://arxiv.org/abs/2501.12157 ,  3589kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12266
replaced with revised version Mon, 6 Oct 2025 13:22:25 GMT   (2282kb)

Title: CBVLM: Training-free Explainable Concept-based Large Vision Language
  Models for Medical Image Classification
Authors: Cristiano Patr\'icio, Isabel Rio-Torto, Jaime S. Cardoso, Lu\'is F.
  Teixeira, Jo\~ao C. Neves
Categories: cs.CV cs.AI cs.CL
Comments: Accepted for publication in Computers in Biology and Medicine
\\ ( https://arxiv.org/abs/2501.12266 ,  2282kb)
------------------------------------------------------------------------------
\\
arXiv:2501.12981
replaced with revised version Mon, 6 Oct 2025 12:46:52 GMT   (29238kb)

Title: UniUIR: Considering Underwater Image Restoration as An All-in-One
  Learner
Authors: Xu Zhang, Huan Zhang, Guoli Wang, Qian Zhang, Lefei Zhang, and Bo Du
Categories: cs.CV
Comments: Accepted by IEEE Transactions on Image Processing. Project page at
  https://house-yuyu.github.io/UniUIR/
\\ ( https://arxiv.org/abs/2501.12981 ,  29238kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01045
replaced with revised version Sun, 5 Oct 2025 04:39:13 GMT   (6487kb)

Title: WonderHuman: Hallucinating Unseen Parts in Dynamic 3D Human
  Reconstruction
Authors: Zilong Wang, Zhiyang Dou, Yuan Liu, Cheng Lin, Xiao Dong, Yunhui Guo,
  Chenxu Zhang, Xin Li, Wenping Wang, and Xiaohu Guo
Categories: cs.CV cs.GR
\\ ( https://arxiv.org/abs/2502.01045 ,  6487kb)
------------------------------------------------------------------------------
\\
arXiv:2502.02690
replaced with revised version Sat, 4 Oct 2025 19:31:40 GMT   (42347kb)

Title: Controllable Video Generation with Provable Disentanglement
Authors: Yifan Shen, Peiyuan Zhu, Zijian Li, Shaoan Xie, Namrata Deka, Zongfang
  Liu, Zeyu Tang, Guangyi Chen, Kun Zhang
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2502.02690 ,  42347kb)
------------------------------------------------------------------------------
\\
arXiv:2502.13693
replaced with revised version Mon, 6 Oct 2025 14:39:01 GMT   (945kb)

Title: Medical Image Classification with KAN-Integrated Transformers and
  Dilated Neighborhood Attention
Authors: Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming
  Xiao, Hassan Rivaz
Categories: cs.CV
\\ ( https://arxiv.org/abs/2502.13693 ,  945kb)
------------------------------------------------------------------------------
\\
arXiv:2503.01448
replaced with revised version Sun, 5 Oct 2025 07:16:12 GMT   (21086kb)

Title: Generative Human Geometry Distribution
Authors: Xiangjun Tang, Biao Zhang and Peter Wonka
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.01448 ,  21086kb)
------------------------------------------------------------------------------
\\
arXiv:2503.05578
replaced with revised version Mon, 6 Oct 2025 11:32:49 GMT   (11495kb)

Title: Novel Object 6D Pose Estimation with a Single Reference View
Authors: Jian Liu, Wei Sun, Kai Zeng, Jin Zheng, Hui Yang, Hossein Rahmani,
  Ajmal Mian, Lin Wang
Categories: cs.CV cs.RO
Comments: 17 pages, 12 figures (including supplementary material)
\\ ( https://arxiv.org/abs/2503.05578 ,  11495kb)
------------------------------------------------------------------------------
\\
arXiv:2503.06901
replaced with revised version Mon, 6 Oct 2025 13:38:48 GMT   (7525kb)

Title: PRO-VPT: Distribution-Adaptive Visual Prompt Tuning via Prompt
  Relocation
Authors: Chikai Shang, Mengke Li, Yiqun Zhang, Zhen Chen, Jinlin Wu, Fangqing
  Gu, Yang Lu, Yiu-ming Cheung
Categories: cs.CV cs.LG
Comments: Accepted by ICCV 2025
\\ ( https://arxiv.org/abs/2503.06901 ,  7525kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07120
replaced with revised version Mon, 6 Oct 2025 04:28:05 GMT   (7275kb)

Title: FEB-Cache: Frequency-Guided Exposure Bias Reduction for Enhancing
  Diffusion Transformer Caching
Authors: Zhen Zou, Feng Zhao
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2503.07120 ,  7275kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07389
replaced with revised version Sun, 5 Oct 2025 05:14:17 GMT   (21198kb)

Title: TRCE: Towards Reliable Malicious Concept Erasure in Text-to-Image
  Diffusion Models
Authors: Ruidong Chen, Honglin Guo, Lanjun Wang, Chenyu Zhang, Weizhi Nie,
  An-An Liu
Categories: cs.CV cs.AI
Comments: accepted by ICCV2025
\\ ( https://arxiv.org/abs/2503.07389 ,  21198kb)
------------------------------------------------------------------------------
\\
arXiv:2503.07399
replaced with revised version Sun, 5 Oct 2025 01:23:17 GMT   (3391kb)

Title: Exploring Representation Invariance in Finetuning
Authors: Wenqiang Zu, Shenghao Xie, Hao Chen, Zhiqiang Chen, Liwen Hu, Yuanhao
  Xi, Yiming Liang, Junliang Ye, Bo Lei, Tiejun Huang, Guoqi Li, Lei Ma
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.07399 ,  3391kb)
------------------------------------------------------------------------------
\\
arXiv:2503.08208
replaced with revised version Mon, 6 Oct 2025 12:28:49 GMT   (577kb)

Title: Explaining Human Preferences via Metrics for Structured 3D
  Reconstruction
Authors: Jack Langerman, Denys Rozumnyi, Yuzhong Huang, Dmytro Mishkin
Categories: cs.CV
Comments: ICCV 2025 Highlight
\\ ( https://arxiv.org/abs/2503.08208 ,  577kb)
------------------------------------------------------------------------------
\\
arXiv:2503.09040
replaced with revised version Sat, 4 Oct 2025 01:41:13 GMT   (33200kb)

Title: Motion Blender Gaussian Splatting for Dynamic Scene Reconstruction
Authors: Xinyu Zhang, Haonan Chang, Yuhan Liu, Abdeslam Boularias
Categories: cs.CV cs.RO
Comments: CoRL 2025
\\ ( https://arxiv.org/abs/2503.09040 ,  33200kb)
------------------------------------------------------------------------------
\\
arXiv:2503.11981
replaced with revised version Sun, 5 Oct 2025 06:48:04 GMT   (39476kb)

Title: DecompDreamer: A Composition-Aware Curriculum for Structured 3D Asset
  Generation
Authors: Utkarsh Nath, Rajeev Goel, Rahul Khurana, Kyle Min, Mark Ollila, Pavan
  Turaga, Varun Jampani, Tejaswi Gowda
Categories: cs.CV
\\ ( https://arxiv.org/abs/2503.11981 ,  39476kb)
------------------------------------------------------------------------------
\\
arXiv:2503.12230
replaced with revised version Mon, 6 Oct 2025 10:49:54 GMT   (1835kb)

Title: LIAM: Multimodal Transformer for Language Instructions, Images, Actions
  and Semantic Maps
Authors: Yihao Wang and Raphael Memmesheimer and Sven Behnke
Categories: cs.CV cs.AI cs.RO
Comments: 12 pages, 4 figures, 2 tables, 19th International Conference on
  Intelligent Autonomous Systems (IAS), Genoa, Italy, June 2025
\\ ( https://arxiv.org/abs/2503.12230 ,  1835kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15778
replaced with revised version Sat, 4 Oct 2025 21:23:23 GMT   (1355kb)

Title: AutoDrive-QA: A Multiple-Choice Benchmark for Vision-Language Evaluation
  in Urban Autonomous Driving
Authors: Boshra Khalili, Andrew W.Smyth
Categories: cs.CV cs.RO
Comments: Updated results with larger dataset experiments and expanded
  discussion
\\ ( https://arxiv.org/abs/2503.15778 ,  1355kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15905
replaced with revised version Sat, 4 Oct 2025 07:13:23 GMT   (23549kb)

Title: Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation
Authors: Jiyuan Wang, Chunyu Lin, Cheng Guan, Lang Nie, Jing He, Haodong Li,
  Kang Liao, Yao Zhao
Categories: cs.CV cs.AI
Comments: Accepted to NeurIPS 2025. 23 pages, with the appendix
\\ ( https://arxiv.org/abs/2503.15905 ,  23549kb)
------------------------------------------------------------------------------
\\
arXiv:2503.18470
replaced with revised version Sat, 4 Oct 2025 07:11:59 GMT   (8742kb)

Title: MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse
Authors: Zhenyu Pan, Han Liu
Categories: cs.CV cs.AI
Comments: Working Paper
\\ ( https://arxiv.org/abs/2503.18470 ,  8742kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20752
replaced with revised version Sun, 5 Oct 2025 00:51:14 GMT   (8618kb)

Title: Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning of Vision
  Language Models
Authors: Huajie Tan, Yuheng Ji, Xiaoshuai Hao, Xiansheng Chen, Pengwei Wang,
  Zhongyuan Wang, Shanghang Zhang
Categories: cs.CV cs.AI
Comments: 51 pages, 23 figures, NeurIPS'25
\\ ( https://arxiv.org/abs/2503.20752 ,  8618kb)
------------------------------------------------------------------------------
\\
arXiv:2504.09255
replaced with revised version Sun, 5 Oct 2025 16:37:59 GMT   (5181kb)

Title: FVQ: A Large-Scale Dataset and an LMM-based Method for Face Video
  Quality Assessment
Authors: Sijing Wu, Yunhao Li, Ziwen Xu, Yixuan Gao, Huiyu Duan, Wei Sun,
  Guangtao Zhai
Categories: cs.CV
Comments: Accepted by ACM MM 2025. Project page:
  https://github.com/wsj-sjtu/FVQ
\\ ( https://arxiv.org/abs/2504.09255 ,  5181kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11368
replaced with revised version Sun, 5 Oct 2025 15:00:24 GMT   (2035kb)

Title: From Gaze to Insight: Bridging Human Visual Attention and Vision
  Language Model Explanation for Weakly-Supervised Medical Image Segmentation
Authors: Jingkun Chen, Haoran Duan, Xiao Zhang, Boyan Gao, Vicente Grau,
  Jungong Han
Categories: cs.CV
Comments: 11 pages, 4 figures
MSC-class: 68T45
ACM-class: I.2.10; I.4.8
\\ ( https://arxiv.org/abs/2504.11368 ,  2035kb)
------------------------------------------------------------------------------
\\
arXiv:2504.20509
replaced with revised version Mon, 6 Oct 2025 09:09:59 GMT   (5955kb)

Title: MambaMoE: Mixture-of-Spectral-Spatial-Experts State Space Model for
  Hyperspectral Image Classification
Authors: Yichu Xu, Di Wang, Hongzan Jiao, Lefei Zhang and Liangpei Zhang
Categories: cs.CV
Comments: Accepted by Information Fusion
\\ ( https://arxiv.org/abs/2504.20509 ,  5955kb)
------------------------------------------------------------------------------
\\
arXiv:2505.01322
replaced with revised version Sat, 4 Oct 2025 06:02:52 GMT   (10104kb)

Title: FreeInsert: Disentangled Text-Guided Object Insertion in 3D Gaussian
  Scene without Spatial Priors
Authors: Chenxi Li, Weijie Wang, Qiang Li, Bruno Lepri, Nicu Sebe, Weizhi Nie
Categories: cs.CV
Comments: Accepted by ACMMM2025
\\ ( https://arxiv.org/abs/2505.01322 ,  10104kb)
------------------------------------------------------------------------------
\\
arXiv:2505.10610
replaced with revised version Mon, 6 Oct 2025 15:41:20 GMT   (2039kb)

Title: MMLongBench: Benchmarking Long-Context Vision-Language Models
  Effectively and Thoroughly
Authors: Zhaowei Wang, Wenhao Yu, Xiyu Ren, Jipeng Zhang, Yu Zhao, Rohit
  Saxena, Liang Cheng, Ginny Wong, Simon See, Pasquale Minervini, Yangqiu Song,
  and Mark Steedman
Categories: cs.CV cs.CL
Comments: Accepted as a spotlight at NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.10610 ,  2039kb)
------------------------------------------------------------------------------
\\
arXiv:2505.12789
replaced with revised version Sat, 4 Oct 2025 08:21:05 GMT   (216kb)

Title: Enhancing Transformers Through Conditioned Embedded Tokens
Authors: Hemanth Saratchandran, Simon Lucey
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2505.12789 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13050
replaced with revised version Sat, 4 Oct 2025 07:26:19 GMT   (7372kb)

Title: RGB-to-Polarization Estimation: A New Task and Benchmark Study
Authors: Beibei Lin, Zifeng Yuan, Tingting Chen
Categories: cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.13050 ,  7372kb)
------------------------------------------------------------------------------
\\
arXiv:2505.13731
replaced with revised version Sun, 5 Oct 2025 22:54:40 GMT   (11837kb)

Title: GeoRanker: Distance-Aware Ranking for Worldwide Image Geolocalization
Authors: Pengyue Jia, Seongheon Park, Song Gao, Xiangyu Zhao, Yixuan Li
Categories: cs.CV
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.13731 ,  11837kb)
------------------------------------------------------------------------------
\\
arXiv:2505.15765
replaced with revised version Sat, 4 Oct 2025 02:17:54 GMT   (31385kb)

Title: Constructing a 3D Scene from a Single Image
Authors: Kaizhi Zheng, Ruijian Zha, Zishuo Xu, Jing Gu, Jie Yang, Xin Eric Wang
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.15765 ,  31385kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16416
replaced with revised version Sat, 4 Oct 2025 09:54:36 GMT   (6983kb)

Title: Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large
  Vision-Language Models
Authors: Chengcheng Wang, Jianyuan Guo, Hongguang Li, Yuchuan Tian, Ying Nie,
  Chang Xu, Kai Han
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.16416 ,  6983kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17692
replaced with revised version Mon, 6 Oct 2025 15:27:54 GMT   (16783kb)

Title: ViP$^2$-CLIP: Visual-Perception Prompting with Unified Alignment for
  Zero-Shot Anomaly Detection
Authors: Ziteng Yang, Jingzehua Xu, Yanshu Li, Zepeng Li, Yeqiang Wang, Xinghui
  Li
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.17692 ,  16783kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17931
replaced with revised version Sun, 5 Oct 2025 04:58:28 GMT   (10009kb)

Title: AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation
  of Foundation Models
Authors: Xingjian Li, Qifeng Wu, Adithya S. Ubaradka, Yiran Ding, Colleen Que,
  Runmin Jiang, Jianhua Xing, Tianyang Wang, Min Xu
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2505.17931 ,  10009kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21574
replaced with revised version Mon, 6 Oct 2025 06:55:59 GMT   (556kb)

Title: Do We Need All the Synthetic Data? Targeted Synthetic Image Augmentation
  via Diffusion Models
Authors: Dang Nguyen, Jiping Li, Jinghao Zheng, Baharan Mirzasoleiman
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2505.21574 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23444
replaced with revised version Sun, 5 Oct 2025 01:40:57 GMT   (24085kb)

Title: CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical
  Modeling for Cryo-EM Synthesis
Authors: Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Minhao Wu, Wanyue
  Feng, Yizhou Zhao, Xi Xiao, Xiao Wang, Tianyang Wang, Xingjian Li, Muyuan
  Chen, Min Xu
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2505.23444 ,  24085kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00908
replaced with revised version Sun, 5 Oct 2025 06:39:48 GMT   (11512kb)

Title: DS-VTON: An Enhanced Dual-Scale Coarse-to-Fine Framework for Virtual
  Try-On
Authors: Xianbing Sun, Yan Hong, Jiahui Zhan, Jun Lan, Huijia Zhu, Weiqiang
  Wang, Liqing Zhang, Jianfu Zhang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.00908 ,  11512kb)
------------------------------------------------------------------------------
\\
arXiv:2506.03591
replaced with revised version Sat, 4 Oct 2025 02:00:37 GMT   (13713kb)

Title: Resolving Task Objective Conflicts in Unified Model via Task-Aware
  Mixture-of-Experts
Authors: Jiaxing Zhang, Hao Tang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.03591 ,  13713kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07778
replaced with revised version Sat, 4 Oct 2025 20:40:32 GMT   (25722kb)

Title: A Neurosymbolic Agent System for Compositional Visual Reasoning
Authors: Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Fatih Ilhan,
  Selim Furkan Tekin, Zachary Yahn, Ling Liu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.07778 ,  25722kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08632
replaced with revised version Sat, 4 Oct 2025 09:03:36 GMT   (21120kb)

Title: RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot
  Arm Swapping
Authors: Yang Bai, Liudi Yang, George Eskandar, Fengyi Shen, Dong Chen,
  Mohammad Altillawi, Ziyuan Liu, Gitta Kutyniok
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.08632 ,  21120kb)
------------------------------------------------------------------------------
\\
arXiv:2506.08896
replaced with revised version Mon, 6 Oct 2025 09:51:36 GMT   (40638kb)

Title: WetCat: Enabling Automated Skill Assessment in Wet-Lab Cataract Surgery
  Videos
Authors: Negin Ghamsarian, Raphael Sznitman, Klaus Schoeffmann, Jens Kowal
Categories: cs.CV
Comments: 7 pages, 7 figures, Accepted at ACMMM25
\\ ( https://arxiv.org/abs/2506.08896 ,  40638kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10178
replaced with revised version Mon, 6 Oct 2025 13:58:58 GMT   (33432kb)

Title: Attention, Please! Revisiting Attentive Probing Through the Lens of
  Efficiency
Authors: Bill Psomas, Dionysis Christopoulos, Eirini Baltzi, Ioannis
  Kakogeorgiou, Tilemachos Aravanis, Nikos Komodakis, Konstantinos Karantzalos,
  Yannis Avrithis, Giorgos Tolias
Categories: cs.CV
Comments: 9 main paper pages, 13 supplementary pages; Code available at
  https://github.com/billpsomas/efficient-probing
\\ ( https://arxiv.org/abs/2506.10178 ,  33432kb)
------------------------------------------------------------------------------
\\
arXiv:2506.14512
replaced with revised version Mon, 6 Oct 2025 04:31:42 GMT   (2026kb)

Title: SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex
  Reasoning Tasks
Authors: Zijian Song, Xiaoxin Lin, Qiuming Huang, Guangrun Wang, Liang Lin
Categories: cs.CV
Comments: 14 pages
\\ ( https://arxiv.org/abs/2506.14512 ,  2026kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18569
replaced with revised version Sun, 5 Oct 2025 20:03:32 GMT   (23258kb)

Title: VisualChef: Generating Visual Aids in Cooking via Mask Inpainting
Authors: Oleh Kuzyk, Zuoyue Li, Marc Pollefeys, Xi Wang
Categories: cs.CV
Comments: GCPR 2025 (oral presentation; Best Master's Thesis Award)
\\ ( https://arxiv.org/abs/2506.18569 ,  23258kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18882
replaced with revised version Sat, 4 Oct 2025 15:23:33 GMT   (7081kb)

Title: Light of Normals: Unified Feature Representation for Universal
  Photometric Stereo
Authors: Hong Li, Houyuan Chen, Chongjie Ye, Zhaoxi Chen, Bohan Li, Shaocong
  Xu, Xianda Guo, Xuhui Liu, Yikai Wang, Baochang Zhang, Satoshi Ikehata, Boxin
  Shi, Anyi Rao, Hao Zhao
Categories: cs.CV
Comments: Home: https://houyuanchen111.github.io/lino.github.io Github:
  https://github.com/houyuanchen111/LINO_UniPS HuggingFace Demo:
  https://huggingface.co/spaces/houyuanchen/lino
\\ ( https://arxiv.org/abs/2506.18882 ,  7081kb)
------------------------------------------------------------------------------
\\
arXiv:2506.21742
replaced with revised version Sun, 5 Oct 2025 23:04:14 GMT   (13600kb)

Title: ImplicitQA: Going beyond frames towards Implicit Video Reasoning
Authors: Sirnam Swetha, Rohit Gupta, Parth Parag Kulkarni, David G Shatwell,
  Jeffrey A Chan Santiago, Nyle Siddiqui, Joseph Fioresi, Mubarak Shah
Categories: cs.CV
\\ ( https://arxiv.org/abs/2506.21742 ,  13600kb)
------------------------------------------------------------------------------
\\
arXiv:2506.22762
replaced with revised version Sat, 4 Oct 2025 08:23:15 GMT   (2649kb)

Title: VSRM: A Robust Mamba-Based Framework for Video Super-Resolution
Authors: Dinh Phu Tran, Dao Duy Hung, Daeyoung Kim
Categories: cs.CV
Comments: Arxiv version of ICCV 2025 paper (3rd version)
\\ ( https://arxiv.org/abs/2506.22762 ,  2649kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07048
replaced with revised version Fri, 3 Oct 2025 18:00:15 GMT   (27080kb)

Title: Comprehensive Evaluation of Large Multimodal Models for Nutrition
  Analysis: A New Benchmark Enriched with Contextual Metadata
Authors: Bruce Coburn, Jiangpeng He, Megan E. Rollo, Satvinder S. Dhaliwal,
  Deborah A. Kerr and Fengqing Zhu
Categories: cs.CV
Comments: The extended full version of the accepted paper in 2025 IEEE BHI
  conference with title: Evaluating Large Multimodal Models for Nutrition
  Analysis: A New Benchmark Enriched with Contextual Metadata. Dataset is
  available at: https://skynet.ecn.purdue.edu/~coburn6/ACETADA/
\\ ( https://arxiv.org/abs/2507.07048 ,  27080kb)
------------------------------------------------------------------------------
\\
arXiv:2507.07510
replaced with revised version Mon, 6 Oct 2025 07:01:28 GMT   (27046kb)

Title: Divergence Minimization Preference Optimization for Diffusion Model
  Alignment
Authors: Binxu Li, Minkai Xu, Jiaqi Han, Meihua Dang, Stefano Ermon
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2507.07510 ,  27046kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08223
replaced with revised version Fri, 3 Oct 2025 22:57:06 GMT   (5419kb)

Title: SurfDist: Interpretable Three-Dimensional Instance Segmentation Using
  Curved Surface Patches
Authors: Jackson Borchardt, Saul Kato
Categories: cs.CV
Comments: 8 pages, 6 figures
\\ ( https://arxiv.org/abs/2507.08223 ,  5419kb)
------------------------------------------------------------------------------
\\
arXiv:2507.11336
replaced with revised version Sun, 5 Oct 2025 18:41:25 GMT   (10465kb)

Title: UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New
  Benchmarks
Authors: Peiran Wu, Yunze Liu, Zhengdong Zhu, Enmin Zhou, Junxiao Shen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.11336 ,  10465kb)
------------------------------------------------------------------------------
\\
arXiv:2507.13934
replaced with revised version Sun, 5 Oct 2025 16:01:07 GMT   (2217kb)

Title: DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization
Authors: Marzieh Gheisari, Auguste Genovesio
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.13934 ,  2217kb)
------------------------------------------------------------------------------
\\
arXiv:2507.16856
replaced with revised version Mon, 6 Oct 2025 10:16:31 GMT   (10743kb)

Title: SIA: Enhancing Safety via Intent Awareness for Vision-Language Models
Authors: Youngjin Na, Sangheon Jeong, Youngwan Lee, Jian Lee, Dawoon Jeong,
  Youngman Kim
Categories: cs.CV cs.AI
Comments: Accepted to Safe and Trustworthy Multimodal AI Systems(SafeMM-AI)
  Workshop at ICCV2025, Non-archival track
\\ ( https://arxiv.org/abs/2507.16856 ,  10743kb)
------------------------------------------------------------------------------
\\
arXiv:2507.18743
replaced with revised version Sat, 4 Oct 2025 03:13:02 GMT   (26060kb)

Title: SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator
  and A Progressive Learning Strategy for Downstream Tasks
Authors: Yiguo He, Xinjun Cheng, Junjie Zhu, Chunping Qiu, Jun Wang, Xichuan
  Zhang, Qiangjuan Huang, Ke Yang
Categories: cs.CV
Comments: IEEE Submission
\\ ( https://arxiv.org/abs/2507.18743 ,  26060kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20117
replaced with revised version Sat, 4 Oct 2025 06:50:45 GMT   (18500kb)

Title: RESCUE: Crowd Evacuation Simulation via Controlling SDM-United
  Characters
Authors: Xiaolin Liu, Tianyi Zhou, Hongbo Kang, Jian Ma, Ziwen Wang, Jing
  Huang, Wenguo Weng, Yu-Kun Lai, Kun Li
Categories: cs.CV
\\ ( https://arxiv.org/abs/2507.20117 ,  18500kb)
------------------------------------------------------------------------------
\\
arXiv:2508.02605
replaced with revised version Sat, 4 Oct 2025 01:18:41 GMT   (1777kb)

Title: ReMoMask: Retrieval-Augmented Masked Motion Generation
Authors: Zhengdao Li, Siheng Wang, Zeyu Zhang, Hao Tang
Categories: cs.CV
\\ ( https://arxiv.org/abs/2508.02605 ,  1777kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08134
replaced with revised version Sat, 4 Oct 2025 05:28:39 GMT   (10714kb)

Title: Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided
  Region Control
Authors: Zeqian Long, Mingzhe Zheng, Kunyu Feng, Xinhua Zhang, Hongyu Liu,
  Harry Yang, Linfeng Zhang, Qifeng Chen, Yue Ma
Categories: cs.CV
Comments: Project webpage is available at https://follow-your-shape.github.io/
\\ ( https://arxiv.org/abs/2508.08134 ,  10714kb)
------------------------------------------------------------------------------
\\
arXiv:2508.08900
replaced with revised version Sat, 4 Oct 2025 14:56:01 GMT   (4806kb)

Title: Deep Spectral Epipolar Representations for Dense Light Field
  Reconstruction
Authors: Noor Islam S. Mohammad
Categories: cs.CV
Comments: There are 14 pages, 8 figures, and 3 tables. This full-length article
  was processed to be submitted to the IEEE Transactions on Pattern Analysis
  and Machine Intelligence (TPAMI) in October 2025
MSC-class: 68T45, 68U10
ACM-class: I.4.8; I.2.10
\\ ( https://arxiv.org/abs/2508.08900 ,  4806kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09466
replaced with revised version Sun, 5 Oct 2025 06:04:04 GMT   (4477kb)

Title: Event-driven Robust Fitting on Neuromorphic Hardware
Authors: Tam Ngoc-Bang Nguyen, Anh-Dzung Doan, Zhipeng Cai, Tat-Jun Chin
Categories: cs.CV cs.NE
Comments: 13 pages, accepted in ICCV 2025 Workshop on Neuromorphic Vision
  (NeVI)
\\ ( https://arxiv.org/abs/2508.09466 ,  4477kb)
------------------------------------------------------------------------------
\\
arXiv:2508.12279
replaced with revised version Sat, 4 Oct 2025 14:10:09 GMT   (8455kb)

Title: TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on
  Autonomous Vehicles Platform
Authors: Jun Liu, Zhenglun Kong, Pu Zhao, Weihao Zeng, Hao Tang, Xuan Shen,
  Changdi Yang, Wenbin Zhang, Geng Yuan, Wei Niu, Xue Lin and Yanzhi Wang
Categories: cs.CV cs.AI cs.AR cs.LG
Journal-ref: IEEE Transactions on Computer-Aided Design of Integrated Circuits
  and Systems, vol. 44, no. 4, pp. 1406-1419, April 2025
DOI: 10.1109/TCAD.2024.3491015
\\ ( https://arxiv.org/abs/2508.12279 ,  8455kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04438
replaced with revised version Mon, 6 Oct 2025 17:49:39 GMT   (19609kb)

Title: The Telephone Game: Evaluating Semantic Drift in Unified Models
Authors: Sabbir Mollah, Rohit Gupta, Sirnam Swetha, Qingyang Liu, Ahnaf Munir,
  Mubarak Shah
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2509.04438 ,  19609kb)
------------------------------------------------------------------------------
\\
arXiv:2509.07596
replaced with revised version Mon, 6 Oct 2025 14:43:39 GMT   (9077kb)

Title: Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation
Authors: Yusuke Hirota, Ryo Hachiuma, Boyi Li, Ximing Lu, Michael Ross Boone,
  Boris Ivanovic, Yejin Choi, Marco Pavone, Yu-Chiang Frank Wang, Noa Garcia,
  Yuta Nakashima, Chao-Han Huck Yang
Categories: cs.CV
Comments: ICCV 2025
\\ ( https://arxiv.org/abs/2509.07596 ,  9077kb)
------------------------------------------------------------------------------
\\
arXiv:2509.11926
replaced with revised version Mon, 6 Oct 2025 15:13:53 GMT   (3330kb)

Title: Graph Algorithm Unrolling with Douglas-Rachford Iterations for Image
  Interpolation with Guaranteed Initialization
Authors: Xue Zhang, Bingshuo Hu, Gene Cheung
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.11926 ,  3330kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14574
replaced with revised version Sun, 5 Oct 2025 16:29:16 GMT   (2567kb)

Title: Do Vision-Language Models See Urban Scenes as People Do? An Urban
  Perception Benchmark
Authors: Rashid Mushkani
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/2509.14574 ,  2567kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20148
replaced with revised version Sun, 5 Oct 2025 20:01:40 GMT   (2977kb)

Title: Smaller is Better: Enhancing Transparency in Vehicle AI Systems via
  Pruning
Authors: Sanish Suwal, Shaurya Garg, Dipkamal Bhusal, Michael Clifford, Nidhi
  Rastogi
Categories: cs.CV
Comments: 17 pages
\\ ( https://arxiv.org/abs/2509.20148 ,  2977kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20580
replaced with revised version Sat, 4 Oct 2025 18:40:50 GMT   (8613kb)

Title: A Comparative Benchmark of Real-time Detectors for Blueberry Detection
  towards Precision Orchard Management
Authors: Xinyang Mu, Yuzhen Lu, Boyang Deng
Categories: cs.CV
Comments: 19 pages, 6 figures, 4 tables. Abstract abridged due to arXiv's 1920
  character limit
\\ ( https://arxiv.org/abs/2509.20580 ,  8613kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20585
replaced with revised version Sun, 5 Oct 2025 21:40:20 GMT   (1389kb)

Title: Region-of-Interest Augmentation for Mammography Classification under
  Patient-Level Cross-Validation
Authors: Farbod Bigdeli, Mohsen Mohammadagha and Ali Bigdeli
Categories: cs.CV cs.LG
Comments: 5 pages, 5 figures, 2 tables
\\ ( https://arxiv.org/abs/2509.20585 ,  1389kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21387
replaced with revised version Sun, 5 Oct 2025 20:06:23 GMT   (3631kb)

Title: Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of
  Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence
Authors: Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi
Categories: cs.CV cs.AI cs.LG
Comments: 4 pages, neurips workshop
\\ ( https://arxiv.org/abs/2509.21387 ,  3631kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21486
replaced with revised version Fri, 3 Oct 2025 17:37:07 GMT   (2620kb)

Title: Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large
  Language Models for Short Video Content Governance
Authors: Zixuan Wang, Yu Sun, Hongwei Wang, Baoyu Jing, Xiang Shen, Xin Dong,
  Zhuolin Hao, Hongyu Xiong, Yang Song
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.21486 ,  2620kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22229
replaced with revised version Mon, 6 Oct 2025 15:55:42 GMT   (362kb)

Title: A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised
  Domain Adaptation
Authors: Jiaping Yu, Muli Yang, Jiapeng Ji, Jiexi Yan, Cheng Deng
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.22229 ,  362kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23022
replaced with revised version Mon, 6 Oct 2025 10:17:32 GMT   (6698kb)

Title: Copyright Infringement Detection in Text-to-Image Diffusion Models via
  Differential Privacy
Authors: Xiafeng Man, Zhipeng Wei, Jingjing Chen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.23022 ,  6698kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23054
replaced with revised version Sat, 4 Oct 2025 07:50:36 GMT   (25654kb)

Title: Mask What Matters: Controllable Text-Guided Masking for Self-Supervised
  Medical Image Analysis
Authors: Ruilang Wang, Shuotong Xu, Bowen Liu, Runlin Huang, Donglong Chen,
  Weifeng Su
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.23054 ,  25654kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23258
replaced with revised version Sat, 4 Oct 2025 13:25:00 GMT   (39424kb)

Title: OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting
Authors: Atakan Topaloglu, Kunyi Li, Michael Niemeyer, Nassir Navab, A. Murat
  Tekalp, Federico Tombari
Categories: cs.CV
Comments: Project page available at:
  https://atakan-topaloglu.github.io/oraclegs/
\\ ( https://arxiv.org/abs/2509.23258 ,  39424kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23640
replaced with revised version Sat, 4 Oct 2025 15:47:00 GMT   (5262kb)

Title: EfficientMIL: Efficient Linear-Complexity MIL Method for WSI
  Classification
Authors: Chengying She, Chengwei Chen, Dongjie Fan, Lizhuang Liu, Chengwei
  Shao, Yun Bian, Ben Wang, Xinran Zhang
Categories: cs.CV
Comments: Submitted to Array
\\ ( https://arxiv.org/abs/2509.23640 ,  5262kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23931
replaced with revised version Sun, 5 Oct 2025 13:06:53 GMT   (3112kb)

Title: AutoPrune: Each Complexity Deserves a Pruning Policy
Authors: Hanshi Wang, Yuhao Xu, Zekun Xu, Jin Gao, Yufan Liu, Weiming Hu, Ke
  Wang, Zhipeng Zhang
Categories: cs.CV
Comments: 13 pages, 2 figures
Journal-ref: NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.23931 ,  3112kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24008
replaced with revised version Sun, 5 Oct 2025 15:20:25 GMT   (2700kb)

Title: FrameMind: Frame-Interleaved Video Reasoning via Reinforcement Learning
Authors: Haonan Ge, Yiwei Wang, Kai-Wei Chang, Hang Wu, Yujun Cai
Categories: cs.CV cs.AI
Comments: Underreview
\\ ( https://arxiv.org/abs/2509.24008 ,  2700kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24072
replaced with revised version Fri, 3 Oct 2025 22:57:00 GMT   (1998kb)

Title: Uncovering Grounding IDs: How External Cues Shape Multi-Modal Binding
Authors: Hosein Hasani, Amirmohammad Izadi, Fatemeh Askari, Mobin Bagherian,
  Sadegh Mohammadian, Mohammad Izadi, Mahdieh Soleymani Baghshah
Categories: cs.CV cs.AI
Comments: Under review as a conference paper at ICLR 2026
\\ ( https://arxiv.org/abs/2509.24072 ,  1998kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24251
replaced with revised version Sun, 5 Oct 2025 04:01:18 GMT   (1504kb)

Title: Latent Visual Reasoning
Authors: Bangzheng Li, Ximeng Sun, Jiang Liu, Ze Wang, Jialian Wu, Xiaodong Yu,
  Hao Chen, Emad Barsoum, Muhao Chen, Zicheng Liu
Categories: cs.CV cs.CL
\\ ( https://arxiv.org/abs/2509.24251 ,  1504kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24311
replaced with revised version Sun, 5 Oct 2025 01:44:02 GMT   (13662kb)

Title: Towards Foundation Models for Cryo-ET Subtomogram Analysis
Authors: Runmin Jiang, Wanyue Feng, Yuntian Yang, Shriya Pingulkar, Hong Wang,
  Xi Xiao, Xiaoyu Cao, Genpei Zhang, Xiao Wang, Xiaolong Wu, Tianyang Wang,
  Yang Liu, Xingjian Li, Min Xu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.24311 ,  13662kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24758
replaced with revised version Mon, 6 Oct 2025 02:40:44 GMT   (24994kb)

Title: ExGS: Extreme 3D Gaussian Compression with Diffusion Priors
Authors: Jiaqi Chen, Xinhao Ji, Yuanyuan Gao, Hao Li, Yuning Gong, Yifei Liu,
  Dan Xu, Zhihang Zhong, Dingwen Zhang, Xiao Sun
Categories: cs.CV
\\ ( https://arxiv.org/abs/2509.24758 ,  24994kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25787
replaced with revised version Sat, 4 Oct 2025 03:01:05 GMT   (993kb)

Title: Self-Evolving Vision-Language Models for Image Quality Assessment via
  Voting and Ranking
Authors: Wen Wen, Tianwu Zhi, Kanglong Fan, Yang Li, Xinge Peng, Yabin Zhang,
  Yiting Liao, Junlin Li, Li Zhang
Categories: cs.CV
Comments: Technical Report
\\ ( https://arxiv.org/abs/2509.25787 ,  993kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00413
replaced with revised version Sat, 4 Oct 2025 15:23:55 GMT   (280kb)

Title: PAL-UI: Planning with Active Look-back for Vision-Based GUI Agents
Authors: Zikang Liu, Junyi Li, Wayne Xin Zhao, Dawei Gao, Yaliang Li, Ji-rong
  Wen
Categories: cs.CV
Comments: Under Review
\\ ( https://arxiv.org/abs/2510.00413 ,  280kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00635
replaced with revised version Sat, 4 Oct 2025 10:33:43 GMT   (24391kb)

Title: Erased, But Not Forgotten: Erased Rectified Flow Transformers Still
  Remain Unsafe Under Concept Attack
Authors: Nanxiang Jiang, Zhaoxin Fan, Enhan Kang, Daiheng Gao, Yun Zhou, Yanxia
  Chang, Zheng Zhu, Yeying Jin, Wenjun Wu
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.00635 ,  24391kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01660
replaced with revised version Mon, 6 Oct 2025 00:19:12 GMT   (2406kb)

Title: VirDA: Reusing Backbone for Unsupervised Domain Adaptation with Visual
  Reprogramming
Authors: Duy Nguyen and Dat Nguyen
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.01660 ,  2406kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01914
replaced with revised version Sat, 4 Oct 2025 03:11:42 GMT   (2133kb)

Title: Automated Defect Detection for Mass-Produced Electronic Components Based
  on YOLO Object Detection Models
Authors: Wei-Lung Mao, Chun-Chi Wang, Po-Heng Chou, and Yen-Ting Liu
Categories: cs.CV cs.AI cs.LG eess.SP
Comments: 12 pages, 16 figures, 7 tables, and published in IEEE Sensors Journal
MSC-class: 68T07, 68U10
ACM-class: I.4.8; I.2.10
Journal-ref: IEEE Sensors Journal, vol. 24, no. 16, Aug. 2024
DOI: 10.1109/JSEN.2024.3418618
\\ ( https://arxiv.org/abs/2510.01914 ,  2133kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02001
replaced with revised version Mon, 6 Oct 2025 14:02:39 GMT   (698kb)

Title: Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using
  GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output
  (SLSO) Framework
Authors: Nanaka Hosokawa, Ryo Takahashi, Tomoya Kitano, Yukihiro Iida, Chisako
  Muramatsu, Tatsuro Hayashi, Yuta Seino, Xiangrong Zhou, Takeshi Hara,
  Akitoshi Katsumata, and Hiroshi Fujita
Categories: cs.CV cs.AI
Comments: Submitted to Scientific Reports
\\ ( https://arxiv.org/abs/2510.02001 ,  698kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02282
replaced with revised version Mon, 6 Oct 2025 17:39:06 GMT   (7802kb)

Title: VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning
  MLLMs and RL
Authors: Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen,
  Dongqi Han, Caihua Shan, Muhammad Muaz, Lili Qiu
Categories: cs.CV cs.LG
\\ ( https://arxiv.org/abs/2510.02282 ,  7802kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02898
replaced with revised version Mon, 6 Oct 2025 08:43:27 GMT   (14059kb)

Title: One Patch to Caption Them All: A Unified Zero-Shot Captioning Framework
Authors: Lorenzo Bianchi, Giacomo Pacini, Fabio Carrara, Nicola Messina,
  Giuseppe Amato, Fabrizio Falchi
Categories: cs.CV
\\ ( https://arxiv.org/abs/2510.02898 ,  14059kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03075
replaced with revised version Mon, 6 Oct 2025 10:01:02 GMT   (19405kb)

Title: What Drives Compositional Generalization in Visual Generative Models?
Authors: Karim Farid, Rajat Sahay, Yumna Ali Alnaggar, Simon Schrodi, Volker
  Fischer, Cordelia Schmid, and Thomas Brox
Categories: cs.CV cs.AI cs.LG
\\ ( https://arxiv.org/abs/2510.03075 ,  19405kb)
------------------------------------------------------------------------------
\\
arXiv:2409.09071
replaced with revised version Fri, 3 Oct 2025 18:03:47 GMT   (4930kb)

Title: Elastic On-Device LLM Service
Authors: Wangsong Yin, Rongjie Yi, Daliang Xu, Gang Huang, Mengwei Xu, Xuanzhe
  Liu
Categories: cs.DC cs.AI
Comments: MobiCom'25
\\ ( https://arxiv.org/abs/2409.09071 ,  4930kb)
------------------------------------------------------------------------------
\\
arXiv:2501.09253
replaced with revised version Sun, 5 Oct 2025 18:13:39 GMT   (3118kb)

Title: PATCHEDSERVE: A Patch Management Framework for SLO-Optimized Hybrid
  Resolution Diffusion Serving
Authors: Desen Sun, Zepeng Zhao, Yuke Wang
Categories: cs.DC
\\ ( https://arxiv.org/abs/2501.09253 ,  3118kb)
------------------------------------------------------------------------------
\\
arXiv:2501.14794
replaced with revised version Sat, 4 Oct 2025 03:01:51 GMT   (911kb)

Title: Characterizing Mobile SoC for Accelerating Heterogeneous LLM Inference
Authors: Le Chen, Dahu Feng, Erhu Feng, Yingrui Wang, Rong Zhao, Yubin Xia,
  Pinjie Xu, Haibo Chen
Categories: cs.DC cs.AI cs.LG
\\ ( https://arxiv.org/abs/2501.14794 ,  911kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00606
replaced with revised version Sat, 4 Oct 2025 00:51:07 GMT   (5806kb)

Title: ElasWave: An Elastic-Native System for Scalable Hybrid-Parallel Training
Authors: Xueze Kang, Guangyu Xiang, Yuxin Wang, Hao Zhang, Yuchu Fang, Yuhang
  Zhou, Zhenheng Tang, Youhui Lv, Eliran Maman, Mark Wasserman, Alon Zameret,
  Zhipeng Bian, Shushu Chen, Zhiyou Yu, Jin Wang, Xiaoyu Wu, Yang Zheng, Chen
  Tian, Xiaowen Chu
Categories: cs.DC
\\ ( https://arxiv.org/abs/2510.00606 ,  5806kb)
------------------------------------------------------------------------------
\\
arXiv:2410.17517
replaced with revised version Mon, 6 Oct 2025 02:24:11 GMT   (6434kb)

Title: The Hive Mind is a Single Reinforcement Learning Agent
Authors: Karthik Soma, Yann Bouteiller, Heiko Hamann and Giovanni Beltrame
Categories: cs.MA cs.AI cs.GT
\\ ( https://arxiv.org/abs/2410.17517 ,  6434kb)
------------------------------------------------------------------------------
\\
arXiv:2503.11829
replaced with revised version Mon, 6 Oct 2025 02:23:10 GMT   (2035kb)

Title: Learning Closed-Loop Parametric Nash Equilibria of Multi-Agent
  Collaborative Field Coverage
Authors: Jushan Chen, Santiago Paternain
Categories: cs.MA cs.GT cs.RO
Comments: Updated license
\\ ( https://arxiv.org/abs/2503.11829 ,  2035kb)
------------------------------------------------------------------------------
\\
arXiv:2507.04724
replaced with revised version Mon, 6 Oct 2025 04:38:52 GMT   (5442kb)

Title: Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents
  in LLM-Based Multi-Agent Systems
Authors: Yizhe Xie, Congcong Zhu, Xinyue Zhang, Tianqing Zhu, Dayong Ye,
  Minghao Wang, Chi Liu
Categories: cs.MA cs.AI
\\ ( https://arxiv.org/abs/2507.04724 ,  5442kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21834
replaced with revised version Sat, 4 Oct 2025 06:37:44 GMT   (581kb)

Title: RobustFlow: Towards Robust Agentic Workflow Generation
Authors: Shengxiang Xu, Jiayi Zhang, Shimin Di, Yuyu Luo, Liang Yao, Hanmo Liu,
  Jia Zhu, Fan Liu, Min-Ling Zhang
Categories: cs.MA
\\ ( https://arxiv.org/abs/2509.21834 ,  581kb)
------------------------------------------------------------------------------
\\
arXiv:2102.09139 (*cross-listing*)
replaced with revised version Sun, 5 Oct 2025 14:11:26 GMT   (148kb)

Title: Algorithmic pricing with independent learners and relative experience
  replay
Authors: Bingyan Han
Categories: econ.GN cs.AI cs.GT q-fin.EC
Comments: To appear in ICAIF'25. An earlier version of this paper was
  circulated and cited under the title "Understanding algorithmic collusion
  with experience replay''
\\ ( https://arxiv.org/abs/2102.09139 ,  148kb)
------------------------------------------------------------------------------
\\
arXiv:2202.00665
replaced with revised version Sun, 5 Oct 2025 18:32:45 GMT   (3922kb)

Title: Tutorial on amortized optimization
Authors: Brandon Amos
Categories: cs.LG cs.AI math.OC
Comments: Foundations and Trends in Machine Learning
\\ ( https://arxiv.org/abs/2202.00665 ,  3922kb)
------------------------------------------------------------------------------
\\
arXiv:2210.12153
replaced with revised version Sun, 5 Oct 2025 18:29:04 GMT   (3281kb)

Title: On amortizing convex conjugates for optimal transport
Authors: Brandon Amos
Categories: cs.LG cs.AI stat.ML
Comments: ICLR 2023
\\ ( https://arxiv.org/abs/2210.12153 ,  3281kb)
------------------------------------------------------------------------------
\\
arXiv:2310.16316
replaced with revised version Sun, 5 Oct 2025 05:50:17 GMT   (12301kb)

Title: Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning
  of Feature Groups
Authors: Weiqiu You, Helen Qu, Marco Gatti, Bhuvnesh Jain, Eric Wong
Categories: cs.LG cs.AI
Comments: ICML 2025
\\ ( https://arxiv.org/abs/2310.16316 ,  12301kb)
------------------------------------------------------------------------------
\\
arXiv:2312.07784 (*cross-listing*)
replaced with revised version Fri, 3 Oct 2025 22:00:30 GMT   (7199kb)

Title: Robust MRI Reconstruction by Smoothed Unrolling (SMUG)
Authors: Shijun Liang, Van Hoang Minh Nguyen, Jinghan Jia, Ismail Alkhouri,
  Sijia Liu, Saiprasad Ravishankar
Categories: eess.IV cs.AI cs.CV cs.LG eess.SP
\\ ( https://arxiv.org/abs/2312.07784 ,  7199kb)
------------------------------------------------------------------------------
\\
arXiv:2402.03970
replaced with revised version Sun, 5 Oct 2025 14:39:10 GMT   (1020kb)

Title: Tabular Data: Is Deep Learning all you need?
Authors: Guri Zab\"ergja, Arlind Kadra, Christian M. M. Frey, Josif Grabocka
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2402.03970 ,  1020kb)
------------------------------------------------------------------------------
\\
arXiv:2402.07640
replaced with revised version Fri, 3 Oct 2025 23:50:43 GMT   (7924kb)

Title: Synthesizing Sentiment-Controlled Feedback For Multimodal Text and Image
  Data
Authors: Puneet Kumar, Sarthak Malik, Balasubramanian Raman, Xiaobai Li
Categories: cs.MM cs.AI
\\ ( https://arxiv.org/abs/2402.07640 ,  7924kb)
------------------------------------------------------------------------------
\\
arXiv:2402.14048
replaced with revised version Mon, 6 Oct 2025 10:28:23 GMT   (1774kb)

Title: PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial
  Optimization
Authors: Andr\'e Hottung, Mridul Mahajan, Kevin Tierney
Categories: cs.LG cs.AI
Comments: Accepted at ICLR 2025
\\ ( https://arxiv.org/abs/2402.14048 ,  1774kb)
------------------------------------------------------------------------------
\\
arXiv:2404.14442
replaced with revised version Mon, 6 Oct 2025 13:46:27 GMT   (19kb)

Title: Unified ODE Analysis of Smooth Q-Learning Algorithms
Authors: Donghwan Lee
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2404.14442 ,  19kb)
------------------------------------------------------------------------------
\\
arXiv:2405.05512
replaced with revised version Fri, 3 Oct 2025 19:04:19 GMT   (7156kb)

Title: Characteristic Learning for Provable One Step Generation
Authors: Zhao Ding and Chenguang Duan and Yuling Jiao and Ruoxuan Li and Jerry
  Zhijian Yang and Pingwen Zhang
Categories: cs.LG cs.AI cs.NA math.NA math.ST stat.TH
\\ ( https://arxiv.org/abs/2405.05512 ,  7156kb)
------------------------------------------------------------------------------
\\
arXiv:2405.20594
replaced with revised version Sun, 5 Oct 2025 05:11:20 GMT   (357kb)

Title: Deep Learning without Weight Symmetry
Authors: Li Ji-An, Marcus K. Benna
Categories: cs.LG cs.AI q-bio.NC
\\ ( https://arxiv.org/abs/2405.20594 ,  357kb)
------------------------------------------------------------------------------
\\
arXiv:2406.12841
replaced with revised version Sat, 4 Oct 2025 07:28:21 GMT   (1698kb)

Title: Demystifying Higher-Order Graph Neural Networks
Authors: Maciej Besta, Florian Scheidl, Lukas Gianinazzi, Grzegorz Kwasniewski,
  Shachar Klaiman, J\"urgen M\"uller, Torsten Hoefler
Categories: cs.LG cs.AI cs.SI
\\ ( https://arxiv.org/abs/2406.12841 ,  1698kb)
------------------------------------------------------------------------------
\\
arXiv:2408.05606
replaced with revised version Sun, 5 Oct 2025 19:07:28 GMT   (308kb)

Title: Exploring Applications of State Space Models and Advanced Training
  Techniques in Sequential Recommendations: A Comparative Study on Efficiency
  and Performance
Authors: Mark Obozov, Makar Baderko, Stepan Kulibaba, Nikolay Kutuzov,
  Alexander Gasnikov
Categories: cs.IR cs.AI cs.LG math.OC
Comments: arXiv admin note: text overlap with arXiv:2403.07691 by other authors
\\ ( https://arxiv.org/abs/2408.05606 ,  308kb)
------------------------------------------------------------------------------
\\
arXiv:2409.10849
replaced with revised version Mon, 6 Oct 2025 16:05:39 GMT   (3812kb)

Title: Pragmatic Embodied Spoken Instruction Following in Human-Robot
  Collaboration with Theory of Mind
Authors: Lance Ying, Xinyi Li, Shivam Aarya, Yizirui Fang, Yifan Yin, Jason
  Xinyu Liu, Stefanie Tellex, Joshua B. Tenenbaum, Tianmin Shu
Categories: cs.RO cs.AI cs.HC cs.MA
Comments: 8 pages, 7 figures
\\ ( https://arxiv.org/abs/2409.10849 ,  3812kb)
------------------------------------------------------------------------------
\\
arXiv:2409.19448
replaced with revised version Fri, 3 Oct 2025 22:04:34 GMT   (995kb)

Title: Advanced Clustering Techniques for Speech Signal Enhancement: A Review
  and Metanalysis of Fuzzy C-Means, K-Means, and Kernel Fuzzy C-Means Methods
Authors: Abdulhady Abas Abdullah, Aram Mahmood Ahmed, Tarik Rashid, Hadi Veisi
Categories: cs.SD cs.AI eess.AS
\\ ( https://arxiv.org/abs/2409.19448 ,  995kb)
------------------------------------------------------------------------------
\\
arXiv:2410.06819
replaced with revised version Sat, 4 Oct 2025 10:47:48 GMT   (2922kb)

Title: Dynamic Neural Potential Field: Online Trajectory Optimization in the
  Presence of Moving Obstacles
Authors: Aleksei Staroverov, Muhammad Alhaddad, Aditya Narendra, Konstantin
  Mironov and Aleksandr Panov
Categories: cs.RO cs.AI
\\ ( https://arxiv.org/abs/2410.06819 ,  2922kb)
------------------------------------------------------------------------------
\\
arXiv:2410.09763
replaced with revised version Mon, 6 Oct 2025 12:38:06 GMT   (0kb,I)

Title: EEG-based AI-BCI Wheelchair Advancement: A Brain-Computer Interfacing
  Wheelchair System Using Deep Learning Approach
Authors: Biplov Paneru, Bishwash Paneru, Bipul Thapa, Khem Narayan Poudyal
Categories: cs.HC cs.AI eess.SP
Comments: The paper contains the outdated data as well as incoconsistent
  results. Much work is required for its revision and republishing
\\ ( https://arxiv.org/abs/2410.09763 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2411.01344
replaced with revised version Mon, 6 Oct 2025 04:47:18 GMT   (9452kb)

Title: Privacy Leakage Overshadowed by Views of AI: A Study on Human Oversight
  of Privacy in Language Model Agent
Authors: Zhiping Zhang, Bingcan Guo, Tianshi Li
Categories: cs.HC cs.AI cs.CR
\\ ( https://arxiv.org/abs/2411.01344 ,  9452kb)
------------------------------------------------------------------------------
\\
arXiv:2411.01625 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 02:13:21 GMT   (385kb)

Title: Counterfactual explainability and analysis of variance
Authors: Zijun Gao and Qingyuan Zhao
Categories: stat.ML cs.AI cs.LG
Comments: 36 pages, 10 figures
\\ ( https://arxiv.org/abs/2411.01625 ,  385kb)
------------------------------------------------------------------------------
\\
arXiv:2412.01928
replaced with revised version Mon, 6 Oct 2025 17:57:15 GMT   (259kb)

Title: MALT: Improving Reasoning with Multi-Agent LLM Training
Authors: Sumeet Ramesh Motwani, Chandler Smith, Rocktim Jyoti Das, Rafael
  Rafailov, Ivan Laptev, Philip H. S. Torr, Fabio Pizzati, Ronald Clark,
  Christian Schroeder de Witt
Categories: cs.LG cs.AI
Comments: Published at COLM 2025
\\ ( https://arxiv.org/abs/2412.01928 ,  259kb)
------------------------------------------------------------------------------
\\
arXiv:2501.02441 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 01:08:23 GMT   (1107kb)

Title: A Statistical Hypothesis Testing Framework for Data Misappropriation
  Detection in Large Language Models
Authors: Yinpeng Cai, Lexin Li, Linjun Zhang
Categories: stat.ML cs.AI cs.CL cs.CR cs.LG math.ST stat.TH
Comments: 29 pages, 5 figures
\\ ( https://arxiv.org/abs/2501.02441 ,  1107kb)
------------------------------------------------------------------------------
\\
arXiv:2501.02971
replaced with revised version Mon, 6 Oct 2025 10:25:49 GMT   (1246kb)

Title: Proof-of-Data: A Consensus Protocol for Collaborative Intelligence
Authors: Huiwen Liu, Feida Zhu, Ling Cheng
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2501.02971 ,  1246kb)
------------------------------------------------------------------------------
\\
arXiv:2502.01159
replaced with revised version Sat, 4 Oct 2025 12:26:11 GMT   (2061kb)

Title: AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model
  for Atmospheric Science
Authors: Chenyue Li, Wen Deng, Mengqian Lu, Binhang Yuan
Categories: cs.LG cs.AI
Comments: 37 pages, 4 figures, 13 tables
\\ ( https://arxiv.org/abs/2502.01159 ,  2061kb)
------------------------------------------------------------------------------
\\
arXiv:2502.05370
replaced with revised version Sat, 4 Oct 2025 03:45:40 GMT   (823kb)

Title: Taming Latency-Memory Trade-Off in MoE-Based LLM Serving via
  Fine-Grained Expert Offloading
Authors: Hanfei Yu, Xingqi Cui, Hong Zhang, Hao Wang, Hao Wang
Categories: cs.LG cs.AI cs.DC
\\ ( https://arxiv.org/abs/2502.05370 ,  823kb)
------------------------------------------------------------------------------
\\
arXiv:2502.06916
replaced with revised version Sun, 5 Oct 2025 18:54:57 GMT   (1171kb)

Title: QuIC: Quantum-Inspired Compound Adapters for Parameter Efficient
  Fine-Tuning
Authors: Snehal Raj, Brian Coyle
Categories: cs.LG cs.AI eess.SP quant-ph
Comments: 30 pages, 12 figures, 7 tables, ~8000 words
\\ ( https://arxiv.org/abs/2502.06916 ,  1171kb)
------------------------------------------------------------------------------
\\
arXiv:2502.08574
replaced with revised version Mon, 6 Oct 2025 10:27:56 GMT   (18870kb)

Title: TANTE: Time-Adaptive Operator Learning via Neural Taylor Expansion
Authors: Zhikai Wu, Sifan Wang, Shiyang Zhang, Sizhuang He, Min Zhu, Anran
  Jiao, Lu Lu, David van Dijk
Categories: cs.LG cs.AI
Comments: 22 pages, 7 figures, 10 tables
\\ ( https://arxiv.org/abs/2502.08574 ,  18870kb)
------------------------------------------------------------------------------
\\
arXiv:2502.15436
replaced with revised version Sat, 4 Oct 2025 10:13:25 GMT   (1600kb)

Title: Fed-SB: A Silver Bullet for Extreme Communication Efficiency and
  Performance in (Private) Federated LoRA Fine-Tuning
Authors: Raghav Singhal, Kaustubh Ponkshe, Rohit Vartak, Lav R. Varshney,
  Praneeth Vepakomma
Categories: cs.LG cs.AI cs.CL cs.DC
Comments: Raghav Singhal and Kaustubh Ponkshe contributed equally to this work
\\ ( https://arxiv.org/abs/2502.15436 ,  1600kb)
------------------------------------------------------------------------------
\\
arXiv:2502.16706
replaced with revised version Mon, 6 Oct 2025 05:36:54 GMT   (2945kb)

Title: DISC: Dynamic Decomposition Improves LLM Inference Scaling
Authors: Jonathan Light, Wei Cheng, Benjamin Riviere, Wu Yue, Masafumi Oyamada,
  Mengdi Wang, Yisong Yue, Santiago Paternain, and Haifeng Chen
Categories: cs.LG cs.AI cs.CL cs.SE
Comments: 10 pages, Accepted to NeurIPS 2025 (Conference on Neural Information
  Processing Systems)
MSC-class: 68T07, 68W40
ACM-class: I.2.6; I.2.7; I.2.8; D.2.3; F.2.2
\\ ( https://arxiv.org/abs/2502.16706 ,  2945kb)
------------------------------------------------------------------------------
\\
arXiv:2503.03170
replaced with revised version Sun, 5 Oct 2025 10:27:08 GMT   (1769kb)

Title: AttackSeqBench: Benchmarking Large Language Models in Analyzing Attack
  Sequences within Cyber Threat Intelligence
Authors: Haokai Ma, Javier Yong, Yunshan Ma, Kuei Chen, Anis Yusof, Zhenkai
  Liang, Ee-Chien Chang
Categories: cs.CR cs.AI
Comments: 36 pages, 9 figures
\\ ( https://arxiv.org/abs/2503.03170 ,  1769kb)
------------------------------------------------------------------------------
\\
arXiv:2503.04162
replaced with revised version Sun, 5 Oct 2025 06:43:59 GMT   (1465kb)

Title: SRA-CL: Semantic Retrieval Augmented Contrastive Learning for Sequential
  Recommendation
Authors: Ziqiang Cui, Yunpeng Weng, Xing Tang, Xiaokun Zhang, Shiwei Li,
  Peiyang Liu, Bowei He, Dugang Liu, Weihong Luo, Xiuqiang He, Chen Ma
Categories: cs.IR cs.AI
Comments: Accepted by NeurIPS 2025. Code is available at:
  https://github.com/ziqiangcui/SRA-CL
\\ ( https://arxiv.org/abs/2503.04162 ,  1465kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13441
replaced with revised version Sun, 5 Oct 2025 08:38:18 GMT   (4848kb)

Title: Humanoid Policy ~ Human Policy
Authors: Ri-Zhao Qiu, Shiqi Yang, Xuxin Cheng, Chaitanya Chawla, Jialong Li,
  Tairan He, Ge Yan, David J. Yoon, Ryan Hoque, Lars Paulsen, Ge Yang, Jian
  Zhang, Sha Yi, Guanya Shi, Xiaolong Wang
Categories: cs.RO cs.AI cs.CV
Comments: Code and data: https://human-as-robot.github.io/
\\ ( https://arxiv.org/abs/2503.13441 ,  4848kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13477 (*cross-listing*)
replaced with revised version Sun, 5 Oct 2025 16:34:44 GMT   (12486kb)

Title: Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic
  Post-Processing
Authors: Ryan Banks, Vishal Thengane, Mar\'ia Eugenia Guerrero, Nelly Maria
  Garc\'ia-Madue\~no, Yunpeng Li, Hongying Tang, Akhilanand Chaurasia
Categories: q-bio.TO cs.AI cs.CV
Comments: 18 pages, 7 tables, 9 figures, 1 equation, journal paper submitted to
  Computers in Biology and Medicine
ACM-class: I.2.1; I.2.10; J.3
\\ ( https://arxiv.org/abs/2503.13477 ,  12486kb)
------------------------------------------------------------------------------
\\
arXiv:2503.13793
replaced with revised version Sat, 4 Oct 2025 21:09:25 GMT   (798kb)

Title: Mapping the Trust Terrain: LLMs in Software Engineering -- Insights and
  Perspectives
Authors: Dipin Khati and Yijin Liu and David N. Palacio and Yixuan Zhang and
  Denys Poshyvanyk
Categories: cs.SE cs.AI
Comments: Accepted to appear in IEEE Transactions on Software Engineering
\\ ( https://arxiv.org/abs/2503.13793 ,  798kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14048 (*cross-listing*)
replaced with revised version Sun, 5 Oct 2025 13:04:02 GMT   (1212kb)

Title: Beyond holography: the entropic quantum gravity foundations of image
  processing
Authors: Ginestra Bianconi
Categories: cond-mat.dis-nn cond-mat.stat-mech cs.AI gr-qc quant-ph
Comments: (7 pages, 1 figure)
\\ ( https://arxiv.org/abs/2503.14048 ,  1212kb)
------------------------------------------------------------------------------
\\
arXiv:2503.14469
replaced with revised version Mon, 6 Oct 2025 01:08:42 GMT   (301kb)

Title: Causality-Based Scores Alignment in Explainable Data Management
Authors: Felipe Azua and Leopoldo Bertossi
Categories: cs.DB cs.AI
Comments: Full and detailed revision of previous versions in terms of
  presentation and statement of results, and their proofs. Submitted to
  conference
\\ ( https://arxiv.org/abs/2503.14469 ,  301kb)
------------------------------------------------------------------------------
\\
arXiv:2503.15481
replaced with revised version Mon, 6 Oct 2025 09:42:53 GMT   (5730kb)

Title: Learning to Play Piano in the Real World
Authors: Yves-Simon Zeulner, Sandeep Selvaraj, Roberto Calandra
Categories: cs.RO cs.AI cs.LG
\\ ( https://arxiv.org/abs/2503.15481 ,  5730kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20783
replaced with revised version Mon, 6 Oct 2025 09:30:03 GMT   (1366kb)

Title: Understanding R1-Zero-Like Training: A Critical Perspective
Authors: Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du,
  Wee Sun Lee, Min Lin
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2503.20783 ,  1366kb)
------------------------------------------------------------------------------
\\
arXiv:2504.00336
replaced with revised version Sat, 4 Oct 2025 00:33:48 GMT   (1428kb)

Title: Large EEG-U-Transformer for Time-Step Level Detection Without
  Pre-Training
Authors: Kerui Wu, Ziyue Zhao, B\"ulent Yener
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2504.00336 ,  1428kb)
------------------------------------------------------------------------------
\\
arXiv:2504.05424
replaced with revised version Mon, 6 Oct 2025 15:57:48 GMT   (332kb)

Title: Speculative Automated Refactoring of Imperative Deep Learning Programs
  to Graph Execution
Authors: Raffi Khatchadourian, Tatiana Castro V\'elez, Mehdi Bagherzadeh, Nan
  Jia, Anita Raja
Categories: cs.SE cs.AI cs.PL
ACM-class: D.2.7; C.4; D.3.4; I.2.6
Journal-ref: 2025 40th IEEE/ACM International Conference on Automated Software
  Engineering (ASE)
\\ ( https://arxiv.org/abs/2504.05424 ,  332kb)
------------------------------------------------------------------------------
\\
arXiv:2504.06303
replaced with revised version Fri, 3 Oct 2025 18:00:19 GMT   (229kb)

Title: On the Effectiveness and Generalization of Race Representations for
  Debiasing High-Stakes Decisions
Authors: Dang Nguyen and Chenhao Tan
Categories: cs.CY cs.AI cs.CL cs.LG
Comments: 21 pages, 15 figures, 14 tables. Accepted as a conference paper at
  COLM 2025. Camera-ready
\\ ( https://arxiv.org/abs/2504.06303 ,  229kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08942
replaced with revised version Mon, 6 Oct 2025 15:46:30 GMT   (1714kb)

Title: AgentRewardBench: Evaluating Automatic Evaluations of Web Agent
  Trajectories
Authors: Xing Han L\`u, Amirhossein Kazemnejad, Nicholas Meade, Arkil Patel,
  Dongchan Shin, Alejandra Zambrano, Karolina Sta\'nczak, Peter Shaw,
  Christopher J. Pal, Siva Reddy
Categories: cs.LG cs.AI cs.CL
\\ ( https://arxiv.org/abs/2504.08942 ,  1714kb)
------------------------------------------------------------------------------
\\
arXiv:2504.09532
replaced with revised version Mon, 6 Oct 2025 06:14:37 GMT   (1703kb)

Title: Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal
  Foundation Models for Zero-Shot Loco-Manipulation
Authors: Congcong Wen, Geeta Chandra Raju Bethala, Yu Hao, Niraj Pudasaini, Hao
  Huang, Shuaihang Yuan, Baoru Huang, Anh Nguyen, Mengyu Wang, Anthony Tzes, Yi
  Fang
Categories: cs.RO cs.AI
Comments: website link: https://humanoid-coa.github.io/
\\ ( https://arxiv.org/abs/2504.09532 ,  1703kb)
------------------------------------------------------------------------------
\\
arXiv:2504.11944
replaced with revised version Mon, 6 Oct 2025 09:21:10 GMT   (5056kb)

Title: VIPO: Value Function Inconsistency Penalized Offline Reinforcement
  Learning
Authors: Xuyang Chen, Guojian Wang, Keyu Yan, Lin Zhao
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2504.11944 ,  5056kb)
------------------------------------------------------------------------------
\\
arXiv:2504.13241
replaced with revised version Sat, 4 Oct 2025 16:31:25 GMT   (143kb)

Title: Recursive Deep Inverse Reinforcement Learning
Authors: Paul Ghanem, Owen Howell, Michael Potter, Pau Closas, Alireza
  Ramezani, Deniz Erdogmus, Tales Imbiriba
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2504.13241 ,  143kb)
------------------------------------------------------------------------------
\\
arXiv:2504.14815
replaced with revised version Mon, 6 Oct 2025 15:50:02 GMT   (11067kb)

Title: What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale
Authors: Xiaoyong Yuan, Xiaolong Ma, Linke Guo, Lan Zhang
Categories: cs.LG cs.AI cs.CR cs.CV
Comments: Extended version of the paper accepted at CCS 2025
\\ ( https://arxiv.org/abs/2504.14815 ,  11067kb)
------------------------------------------------------------------------------
\\
arXiv:2504.15927
replaced with revised version Mon, 6 Oct 2025 09:55:43 GMT   (2486kb)

Title: New Recipe for Semi-supervised Community Detection: Clique Annealing
  under Crystallization Kinetics
Authors: Ling Cheng, Jiashu Pu, Ruicheng Liang, Qian Shao, Hezhe Qiao, Feida
  Zhu
Categories: cs.SI cs.AI
Comments: arXiv admin note: text overlap with arXiv:2203.05898 by other authors
\\ ( https://arxiv.org/abs/2504.15927 ,  2486kb)
------------------------------------------------------------------------------
\\
arXiv:2504.18564
replaced with revised version Sat, 4 Oct 2025 06:16:09 GMT   (4628kb)

Title: DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization
  and Multi-Target Optimization
Authors: Xinzhe Huang, Kedong Xiu, Tianhang Zheng, Churui Zeng, Wangze Ni, Zhan
  Qin, Kui Ren, Chun Chen
Categories: cs.CR cs.AI
Comments: 20 pages, 8 figures
\\ ( https://arxiv.org/abs/2504.18564 ,  4628kb)
------------------------------------------------------------------------------
\\
arXiv:2505.00455
replaced with revised version Sat, 4 Oct 2025 08:18:44 GMT   (2516kb)

Title: Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts
  Using Large Language Models
Authors: Sungbok Shin, Hyeon Jeon, Sanghyun Hong, Niklas Elmqvist
Categories: cs.HC cs.AI
Comments: Submitted to ACM CHI2026'
\\ ( https://arxiv.org/abs/2505.00455 ,  2516kb)
------------------------------------------------------------------------------
\\
arXiv:2505.04629 (*cross-listing*)
replaced with revised version Fri, 3 Oct 2025 22:03:41 GMT   (1159kb)

Title: From Dialect Gaps to Identity Maps: Tackling Variability in Speaker
  Verification
Authors: Abdulhady Abas Abdullah, Soran Badawi, Dana A. Abdullah, Dana Rasul
  Hamad
Categories: eess.AS cs.AI cs.CL
\\ ( https://arxiv.org/abs/2505.04629 ,  1159kb)
------------------------------------------------------------------------------
\\
arXiv:2505.04961
replaced with revised version Sat, 4 Oct 2025 08:33:02 GMT   (20617kb)

Title: Physics-Based Motion Imitation with Adversarial Differential
  Discriminators
Authors: Ziyu Zhang, Sergey Bashkirov, Dun Yang, Yi Shi, Michael Taylor, Xue
  Bin Peng
Categories: cs.GR cs.AI cs.CV cs.RO
Comments: SIGGRAPH Asia 2025 Conference Papers
DOI: 10.1145/3757377.3763819
\\ ( https://arxiv.org/abs/2505.04961 ,  20617kb)
------------------------------------------------------------------------------
\\
arXiv:2505.06493
replaced with revised version Fri, 3 Oct 2025 19:55:21 GMT   (335kb)

Title: System Prompt Poisoning: Persistent Attacks on Large Language Models
  Beyond User Injection
Authors: Zongze Li, Jiawei Guo, Haipeng Cai
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2505.06493 ,  335kb)
------------------------------------------------------------------------------
\\
arXiv:2505.07634
replaced with revised version Mon, 6 Oct 2025 10:13:41 GMT   (4936kb)

Title: Neural Brain: A Neuroscience-inspired Framework for Embodied Agents
Authors: Jian Liu, Xiongtao Shi, Thai Duy Nguyen, Haitian Zhang, Tianxiang
  Zhang, Wei Sun, Yanjie Li, Athanasios V. Vasilakos, Giovanni Iacca, Arshad
  Ali Khan, Arvind Kumar, Jae Won Cho, Ajmal Mian, Lihua Xie, Erik Cambria, Lin
  Wang
Categories: cs.RO cs.AI cs.CV
Comments: 51 pages, 17 figures, 9 tables
\\ ( https://arxiv.org/abs/2505.07634 ,  4936kb)
------------------------------------------------------------------------------
\\
arXiv:2505.14185
replaced with revised version Sat, 4 Oct 2025 10:37:32 GMT   (12912kb)

Title: Safety Subspaces are Not Linearly Distinct: A Fine-Tuning Case Study
Authors: Kaustubh Ponkshe, Shaan Shah, Raghav Singhal, Praneeth Vepakomma
Categories: cs.LG cs.AI cs.CL
Comments: Kaustubh Ponkshe, Shaan Shah, and Raghav Singhal contributed equally
  to this work
\\ ( https://arxiv.org/abs/2505.14185 ,  12912kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16322
replaced with revised version Mon, 6 Oct 2025 08:23:36 GMT   (411kb)

Title: AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners
Authors: Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah
  Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun
Categories: cs.LG cs.AI cs.CL
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.16322 ,  411kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16516
replaced with revised version Mon, 6 Oct 2025 06:40:29 GMT   (1722kb)

Title: Computing Exact Shapley Values in Polynomial Time for Product-Kernel
  Methods
Authors: Majid Mohammadi, Siu Lun Chau, Krikamol Muandet
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.16516 ,  1722kb)
------------------------------------------------------------------------------
\\
arXiv:2505.16724
replaced with revised version Sun, 5 Oct 2025 15:37:46 GMT   (839kb)

Title: Advancing Brainwave Modeling with a Codebook-Based Foundation Model
Authors: Konstantinos Barmpas, Na Lee, Yannis Panagakis, Dimitrios A. Adamos,
  Nikolaos Laskaris and Stefanos Zafeiriou
Categories: cs.LG cs.AI cs.HC
\\ ( https://arxiv.org/abs/2505.16724 ,  839kb)
------------------------------------------------------------------------------
\\
arXiv:2505.17701
replaced with revised version Sat, 4 Oct 2025 06:12:03 GMT   (354kb)

Title: COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary
  Weights in Down Projection
Authors: Jaewon Cheon, Pilsung Kang
Categories: cs.LG cs.AI cs.CL
Comments: EMNLP 2025 (Main Track)
\\ ( https://arxiv.org/abs/2505.17701 ,  354kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18344
replaced with revised version Sat, 4 Oct 2025 02:28:12 GMT   (79kb)

Title: Improved Sample Complexity For Diffusion Model Training Without
  Empirical Risk Minimizer Access
Authors: Mudit Gaur, Prashant Trivedi, Sasidhar Kunapuli, Amrit Singh Bedi and
  Vaneet Aggarwal
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/2505.18344 ,  79kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18350
replaced with revised version Sat, 4 Oct 2025 01:32:32 GMT   (1924kb)

Title: How Many Parameters Does Your Task Really Need? Task Specific Pruning
  with LLM-Sieve
Authors: Waleed Reda, Abhinav Jangda, Krishna Chintalapudi
Categories: cs.LG cs.AI cs.CL
ACM-class: I.2.7
\\ ( https://arxiv.org/abs/2505.18350 ,  1924kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18912
replaced with revised version Fri, 3 Oct 2025 20:16:55 GMT   (1190kb)

Title: Robust Stability Analysis of Positive Lure System with Neural Network
  Feedback
Authors: Hamidreza Montazeri Hedesh, Moh. Kamalul Wafi, Bahram Shafai, and
  Milad Siami
Categories: eess.SY cs.AI cs.SY
Comments: Accepted at the 9th IEEE Conference on Control Technology and
  Applications (CCTA) 2025, San Diego, California
MSC-class: 93D09, 93D20, 93C10, 68T07
ACM-class: B.1.3; G.1; I.2; I.2.3; I.2.8; I.2.1; J.2
Journal-ref: Proc. 2025 IEEE Conference on Control Technology and Applications
  (CCTA), San Diego, CA, USA, 2025, pp. 976-981
DOI: 10.1109/CCTA53793.2025.11151493
\\ ( https://arxiv.org/abs/2505.18912 ,  1190kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18917
replaced with revised version Fri, 3 Oct 2025 20:14:06 GMT   (560kb)

Title: Behavior Injection: Preparing Language Models for Reinforcement Learning
Authors: Zhepeng Cen, Yihang Yao, William Han, Zuxin Liu, Ding Zhao
Categories: cs.LG cs.AI
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.18917 ,  560kb)
------------------------------------------------------------------------------
\\
arXiv:2505.19645
replaced with revised version Mon, 6 Oct 2025 10:53:42 GMT   (2296kb)

Title: MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse
  MoE
Authors: Zongle Huang, Lei Zhu, Zongyuan Zhan, Ting Hu, Weikai Mao, Xianzhi Yu,
  Yongpan Liu, Tianyu Zhang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2505.19645 ,  2296kb)
------------------------------------------------------------------------------
\\
arXiv:2505.20794
replaced with revised version Sun, 5 Oct 2025 17:31:57 GMT   (3944kb)

Title: VibE-SVC: Vibrato Extraction with High-frequency F0 Contour for Singing
  Voice Conversion
Authors: Joon-Seung Choi, Dong-Min Byun, Hyung-Seok Oh, Seong-Whan Lee
Categories: cs.SD cs.AI eess.AS
Comments: Proceedings of Interspeech
DOI: 10.21437/Interspeech.2025-1397
\\ ( https://arxiv.org/abs/2505.20794 ,  3944kb)
------------------------------------------------------------------------------
\\
arXiv:2505.21815
replaced with revised version Mon, 6 Oct 2025 04:57:43 GMT   (943kb)

Title: Scientific Paper Retrieval with LLM-Guided Semantic-Based Ranking
Authors: Yunyi Zhang, Ruozhen Yang, Siqi Jiao, SeongKu Kang, Jiawei Han
Categories: cs.IR cs.AI cs.CL
Comments: Accepted to EMNLP 2025 Findings
\\ ( https://arxiv.org/abs/2505.21815 ,  943kb)
------------------------------------------------------------------------------
\\
arXiv:2505.22889
replaced with revised version Fri, 3 Oct 2025 22:24:15 GMT   (841kb)

Title: Local Stability and Region of Attraction Analysis for Neural Network
  Feedback Systems under Positivity Constraints
Authors: Hamidreza Montazeri Hedesh, Moh Kamalul Wafi, and Milad Siami
Categories: eess.SY cs.AI cs.SY
Comments: Accepted at 64th IEEE Conference on Decision and Control (CDC) 2025 -
  Rio de Janeiro, Brazil
MSC-class: 93D09, 93D20, 93C10, 68T07
ACM-class: B.1.3; G.1; I.2; I.2.3; I.2.8; I.2.1; J.2
\\ ( https://arxiv.org/abs/2505.22889 ,  841kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23631
replaced with revised version Sun, 5 Oct 2025 08:26:26 GMT   (631kb)

Title: Human Empathy as Encoder: AI-Assisted Depression Assessment in Special
  Education
Authors: Boning Zhao, Xinnuo Li, Yutong Hu
Categories: cs.HC cs.AI cs.CL
Comments: 7 pages, 6 figures, ACII 2025
\\ ( https://arxiv.org/abs/2505.23631 ,  631kb)
------------------------------------------------------------------------------
\\
arXiv:2505.24379
replaced with revised version Mon, 6 Oct 2025 17:21:05 GMT   (1506kb)

Title: Rethinking Exact Unlearning under Exposure: Extracting Forgotten Data
  under Exact Unlearning in Large Language Model
Authors: Xiaoyu Wu, Yifei Pang, Terrance Liu and Zhiwei Steven Wu
Categories: cs.LG cs.AI cs.CL cs.CR
Comments: Accepted by Neurips 2025
\\ ( https://arxiv.org/abs/2505.24379 ,  1506kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00534
replaced with revised version Sat, 4 Oct 2025 03:41:35 GMT   (2186kb)

Title: The Security Threat of Compressed Projectors in Large Vision-Language
  Models
Authors: Yudong Zhang, Ruobing Xie, Xingwu Sun, Jiansheng Chen, Zhanhui Kang,
  Di Wang, Yu Wang
Categories: cs.CR cs.AI
Comments: Accepted by EMNLP 2025 findings
\\ ( https://arxiv.org/abs/2506.00534 ,  2186kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00714
replaced with revised version Sat, 4 Oct 2025 06:53:09 GMT   (897kb)

Title: RFCAudit: An LLM Agent for Functional Bug Detection in Network Protocols
Authors: Mingwei Zheng, Chengpeng Wang, Xuwei Liu, Jinyao Guo, Shiwei Feng, and
  Xiangyu Zhang
Categories: cs.SE cs.AI
\\ ( https://arxiv.org/abs/2506.00714 ,  897kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01583
replaced with revised version Sat, 4 Oct 2025 08:48:26 GMT   (34367kb)

Title: FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous
  Tokens
Authors: Yiming Zhong, Yumeng Liu, Chuyang Xiao, Zemin Yang, Youzhuo Wang,
  Yufei Zhu, Ye Shi, Yujing Sun, Xinge Zhu, Yuexin Ma
Categories: cs.RO cs.AI cs.CV
Comments: Comments: Published at Neural Information Processing Systems
  (NeurIPS) 2025. Project page and code: https://freq-policy.github.io/
\\ ( https://arxiv.org/abs/2506.01583 ,  34367kb)
------------------------------------------------------------------------------
\\
arXiv:2506.01876
replaced with revised version Mon, 6 Oct 2025 16:44:47 GMT   (775kb)

Title: In-Context Learning for Pure Exploration
Authors: Alessio Russo, Ryan Welch, Aldo Pacchiano
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2506.01876 ,  775kb)
------------------------------------------------------------------------------
\\
arXiv:2506.02089
replaced with revised version Mon, 6 Oct 2025 10:38:59 GMT   (9794kb)

Title: SALAD: Systematic Assessment of Machine Unlearning on LLM-Aided Hardware
  Design
Authors: Zeng Wang, Minghao Shao, Rupesh Karn, Likhitha Mankali, Jitendra
  Bhandari, Ramesh Karri, Ozgur Sinanoglu, Muhammad Shafique, Johann Knechtel
Categories: cs.LG cs.AI cs.CR
\\ ( https://arxiv.org/abs/2506.02089 ,  9794kb)
------------------------------------------------------------------------------
\\
arXiv:2506.06313
replaced with revised version Sat, 4 Oct 2025 00:28:12 GMT   (493kb)

Title: Beyond Chunking: Discourse-Aware Hierarchical Retrieval for Long
  Document Question Answering
Authors: Huiyao Chen, Yi Yang, Yinghui Li, Meishan Zhang, Min Zhang
Categories: cs.IR cs.AI cs.CL
Comments: 20 pages, 9 figures
\\ ( https://arxiv.org/abs/2506.06313 ,  493kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10301
replaced with revised version Sat, 4 Oct 2025 03:28:49 GMT   (135kb)

Title: Towards Understanding Bias in Synthetic Data for Evaluation
Authors: Hossein A. Rahmani, Varsha Ramineni, Emine Yilmaz, Nick Craswell,
  Bhaskar Mitra
Categories: cs.IR cs.AI
Comments: CIKM 2025
\\ ( https://arxiv.org/abs/2506.10301 ,  135kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10351
replaced with revised version Mon, 6 Oct 2025 07:46:23 GMT   (16509kb)

Title: PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal
  Representation
Authors: Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti,
  Luca Benini, and Yawei Li
Categories: cs.LG cs.AI
Comments: 43 pages, 17 figures, 17 tables. Accepted by NeurIPS 2025. Code and
  data are available at: github.com/ForeverBlue816/PhysioWave
\\ ( https://arxiv.org/abs/2506.10351 ,  16509kb)
------------------------------------------------------------------------------
\\
arXiv:2506.11058
replaced with revised version Sun, 5 Oct 2025 16:31:35 GMT   (3821kb)

Title: Refactoring Codebases through Library Design
Authors: Ziga Kovacic, Justin T. Chiu, Celine Lee, Wenting Zhao, Kevin Ellis
Categories: cs.SE cs.AI
Comments: 29 pages
\\ ( https://arxiv.org/abs/2506.11058 ,  3821kb)
------------------------------------------------------------------------------
\\
arXiv:2507.03041
replaced with revised version Sun, 5 Oct 2025 08:19:08 GMT   (2034kb)

Title: Optimas: Optimizing Compound AI Systems with Globally Aligned Local
  Rewards
Authors: Shirley Wu, Parth Sarthi, Shiyu Zhao, Aaron Lee, Herumb Shandilya,
  Adrian Mladenic Grobelnik, Nurendra Choudhary, Eddie Huang, Karthik Subbian,
  Linjun Zhang, Diyi Yang, James Zou, Jure Leskovec
Categories: cs.LG cs.AI
Comments: 21 pages
\\ ( https://arxiv.org/abs/2507.03041 ,  2034kb)
------------------------------------------------------------------------------
\\
arXiv:2507.09887
replaced with revised version Mon, 6 Oct 2025 02:30:57 GMT   (1123kb)

Title: TolerantECG: A Foundation Model for Imperfect Electrocardiogram
Authors: Huynh Dang Nguyen, Trong-Thang Pham, Ngan Le, Van Nguyen
Categories: cs.LG cs.AI eess.SP
Comments: Accepted at ACM MM 2025
DOI: 10.1145/3746027.3755287
\\ ( https://arxiv.org/abs/2507.09887 ,  1123kb)
------------------------------------------------------------------------------
\\
arXiv:2507.12314
replaced with revised version Sat, 4 Oct 2025 04:42:00 GMT   (1213kb)

Title: Thought Purity: A Defense Framework For Chain-of-Thought Attack
Authors: Zihao Xue and Zhen Bi and Long Ma and Zhenlin Hu and Yan Wang and
  Zhenfang Liu and Qing Sheng and Jie Xiao and Jungang Lou
Categories: cs.LG cs.AI cs.CE cs.CR
\\ ( https://arxiv.org/abs/2507.12314 ,  1213kb)
------------------------------------------------------------------------------
\\
arXiv:2507.19144
replaced with revised version Sun, 5 Oct 2025 10:18:09 GMT   (8443kb)

Title: Solar Photovoltaic Assessment with Large Language Model
Authors: Muhao Guo, Yang Weng
Categories: cs.LG cs.AI
Comments: 43 pages, 12 figures
\\ ( https://arxiv.org/abs/2507.19144 ,  8443kb)
------------------------------------------------------------------------------
\\
arXiv:2507.20836
replaced with revised version Mon, 6 Oct 2025 14:29:58 GMT   (11741kb)

Title: First Hallucination Tokens Are Different from Conditional Ones
Authors: Jakob Snel and Seong Joon Oh
Categories: cs.LG cs.AI
Comments: 4.5 pages, 3 figures, Dataset, Knowledge Paper, Hallucination,
  Trustworthiness
\\ ( https://arxiv.org/abs/2507.20836 ,  11741kb)
------------------------------------------------------------------------------
\\
arXiv:2508.03448
replaced with revised version Mon, 6 Oct 2025 02:57:21 GMT   (6995kb)

Title: SonicMaster: Towards Controllable All-in-One Music Restoration and
  Mastering
Authors: Jan Melechovsky, Ambuj Mehrish, Abhinaba Roy, Dorien Herremans
Categories: cs.SD cs.AI cs.MM eess.AS
MSC-class: 68T07, 94A12, 68U10
ACM-class: I.2.10; H.5.5; J.5
\\ ( https://arxiv.org/abs/2508.03448 ,  6995kb)
------------------------------------------------------------------------------
\\
arXiv:2508.09330
replaced with revised version Sun, 5 Oct 2025 07:16:18 GMT   (799kb)

Title: Synaptic Pruning: A Biological Inspiration for Deep Learning
  Regularization
Authors: Gideon Vos, Liza van Eijk, Zoltan Sarnyai, Mostafa Rahimi Azghadi
Categories: cs.LG cs.AI
Comments: 24 pages, 7 figures
\\ ( https://arxiv.org/abs/2508.09330 ,  799kb)
------------------------------------------------------------------------------
\\
arXiv:2508.11708
replaced with revised version Mon, 6 Oct 2025 00:43:58 GMT   (21193kb)

Title: Street Review: A Participatory AI-Based Framework for Assessing
  Streetscape Inclusivity
Authors: Rashid Mushkani, Shin Koseki
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2508.11708 ,  21193kb)
------------------------------------------------------------------------------
\\
arXiv:2508.13755
replaced with revised version Mon, 6 Oct 2025 11:12:22 GMT   (1283kb)

Title: Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with
  Adaptive Exploration
Authors: Zhicheng Yang, Zhijiang Guo, Yinya Huang, Yongxin Wang, Dongchun Xie,
  Yiwei Wang, Xiaodan Liang, Jing Tang
Categories: cs.LG cs.AI
Comments: 18 pages, 14 figures
\\ ( https://arxiv.org/abs/2508.13755 ,  1283kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16496
replaced with revised version Sun, 5 Oct 2025 18:29:40 GMT   (27618kb)

Title: On Zero-Shot Reinforcement Learning
Authors: Scott Jeen
Categories: cs.LG cs.AI
Comments: PhD thesis
DOI: 10.17863/CAM.121637
\\ ( https://arxiv.org/abs/2508.16496 ,  27618kb)
------------------------------------------------------------------------------
\\
arXiv:2508.16612
replaced with revised version Sun, 5 Oct 2025 09:19:33 GMT   (15334kb)

Title: Negative Shanshui: Real-time Interactive Ink Painting Synthesis
Authors: Aven-Le Zhou
Categories: cs.HC cs.AI cs.CV cs.CY
\\ ( https://arxiv.org/abs/2508.16612 ,  15334kb)
------------------------------------------------------------------------------
\\
arXiv:2508.19258
replaced with revised version Mon, 6 Oct 2025 14:09:14 GMT   (1913kb)

Title: Emotional Manipulation by AI Companions
Authors: Julian De Freitas, Zeliha Oguz-Uguralp, Ahmet Kaan-Uguralp
Categories: cs.HC cs.AI cs.CY
\\ ( https://arxiv.org/abs/2508.19258 ,  1913kb)
------------------------------------------------------------------------------
\\
arXiv:2508.20115
replaced with revised version Mon, 6 Oct 2025 10:07:54 GMT   (456kb)

Title: Flexible metadata harvesting for ecology using large language models
Authors: Zehao Lu, Thijs L van der Plas, Parinaz Rashidi, W Daniel Kissling,
  Ioannis N Athanasiadis
Categories: cs.DL cs.AI cs.DB
DOI: 10.1007/978-3-032-06136-2_32
\\ ( https://arxiv.org/abs/2508.20115 ,  456kb)
------------------------------------------------------------------------------
\\
arXiv:2508.21058
replaced with revised version Sun, 5 Oct 2025 08:28:48 GMT   (4358kb)

Title: Mixture of Contexts for Long Video Generation
Authors: Shengqu Cai, Ceyuan Yang, Lvmin Zhang, Yuwei Guo, Junfei Xiao, Ziyan
  Yang, Yinghao Xu, Zhenheng Yang, Alan Yuille, Leonidas Guibas, Maneesh
  Agrawala, Lu Jiang, Gordon Wetzstein
Categories: cs.GR cs.AI cs.CV
Comments: Project page: https://primecai.github.io/moc/
\\ ( https://arxiv.org/abs/2508.21058 ,  4358kb)
------------------------------------------------------------------------------
\\
arXiv:2509.03842
replaced with revised version Sun, 5 Oct 2025 14:20:32 GMT   (0kb,I)

Title: INGRID: Intelligent Generative Robotic Design Using Large Language
  Models
Authors: Guanglu Jia, Ceng Zhang, Gregory S. Chirikjian
Categories: cs.RO cs.AI
Comments: We are revising it
\\ ( https://arxiv.org/abs/2509.03842 ,  0kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04154
replaced with revised version Sat, 4 Oct 2025 01:15:21 GMT   (2406kb)

Title: Attention as an Adaptive Filter
Authors: Peter Racioppo
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.04154 ,  2406kb)
------------------------------------------------------------------------------
\\
arXiv:2509.04853
replaced with revised version Mon, 6 Oct 2025 01:23:19 GMT   (8266kb)

Title: A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving
  Based on Expert Routing
Authors: Chengkai Xu, Jiaqi Liu, Yicheng Guo, Peng Hang, Jian Sun
Categories: cs.RO cs.AI
Comments: https://perfectxu88.github.io/KDP-AD/
\\ ( https://arxiv.org/abs/2509.04853 ,  8266kb)
------------------------------------------------------------------------------
\\
arXiv:2509.05801
replaced with revised version Sat, 4 Oct 2025 15:13:16 GMT   (19037kb)

Title: time2time: Causal Intervention in Hidden States to Simulate Rare Events
  in Time Series Foundation Models
Authors: Debdeep Sanyal, Aaryan Nagpal, Dhruv Kumar, Murari Mandal, Saurabh
  Deshpande
Categories: cs.LG cs.AI
Journal-ref: NeurIPS 2025 Workshop on Recent Advances in Time Series Foundation
  Models (BERT2S)
\\ ( https://arxiv.org/abs/2509.05801 ,  19037kb)
------------------------------------------------------------------------------
\\
arXiv:2509.09685
replaced with revised version Sun, 5 Oct 2025 18:05:06 GMT   (157kb)

Title: TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal
  Conversational Music Recommendation
Authors: Keunwoo Choi, Seungheon Doh, Juhan Nam
Categories: cs.IR cs.AI cs.MM cs.SD eess.AS
\\ ( https://arxiv.org/abs/2509.09685 ,  157kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13046
replaced with revised version Sun, 5 Oct 2025 07:26:28 GMT   (441kb)

Title: MIA-EPT: Membership Inference Attack via Error Prediction for Tabular
  Data
Authors: Eyal German, Daniel Samira, Yuval Elovici, Asaf Shabtai
Categories: cs.CR cs.AI
\\ ( https://arxiv.org/abs/2509.13046 ,  441kb)
------------------------------------------------------------------------------
\\
arXiv:2509.14275
replaced with revised version Sun, 5 Oct 2025 21:41:04 GMT   (1814kb)

Title: FedMentor: Domain-Aware Differential Privacy for Heterogeneous Federated
  LLMs in Mental Health
Authors: Nobin Sarwar, Shubhashis Roy Dipta
Categories: cs.CR cs.AI cs.CL cs.LG
Comments: NeurIPS 2025 GenAI4Health Workshop
\\ ( https://arxiv.org/abs/2509.14275 ,  1814kb)
------------------------------------------------------------------------------
\\
arXiv:2509.17999
replaced with revised version Fri, 3 Oct 2025 20:36:03 GMT   (1806kb)

Title: The Narcissus Hypothesis: Descending to the Rung of Illusion
Authors: Riccardo Cadei, Christian Intern\`o
Categories: cs.CY cs.AI cs.HC cs.LG
\\ ( https://arxiv.org/abs/2509.17999 ,  1806kb)
------------------------------------------------------------------------------
\\
arXiv:2509.18057
replaced with revised version Mon, 6 Oct 2025 17:09:53 GMT   (8358kb)

Title: Reinforced Generation of Combinatorial Structures: Applications to
  Complexity Theory
Authors: Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta
Categories: cs.LG cs.AI cs.CC math.CO
\\ ( https://arxiv.org/abs/2509.18057 ,  8358kb)
------------------------------------------------------------------------------
\\
arXiv:2509.19341
replaced with revised version Mon, 6 Oct 2025 13:23:04 GMT   (2115kb)

Title: Fine-Grained AI Model Caching and Downloading With Coordinated
  Multipoint Broadcasting in Multi-Cell Edge Networks
Authors: Yang Fu, Peng Qin, Yueyue Zhang, Pao Cheng, Jun Lu, Yifei Wang
Categories: cs.NI cs.AI cs.LG
\\ ( https://arxiv.org/abs/2509.19341 ,  2115kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20293
replaced with revised version Sat, 4 Oct 2025 02:10:03 GMT   (2943kb)

Title: When Judgment Becomes Noise: How Design Failures in LLM Judge Benchmarks
  Silently Undermine Validity
Authors: Benjamin Feuer, Chiung-Yi Tseng, Astitwa Sarthak Lathe, Oussama
  Elachqar, John P Dickerson
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.20293 ,  2943kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21947
replaced with revised version Sat, 4 Oct 2025 07:20:24 GMT   (1243kb)

Title: Active Attacks: Red-teaming LLMs via Adaptive Environments
Authors: Taeyoung Yun, Pierre-Luc St-Charles, Jinkyoo Park, Yoshua Bengio,
  Minsu Kim
Categories: cs.LG cs.AI
Comments: 22 pages, 7 figures, 18 tables
\\ ( https://arxiv.org/abs/2509.21947 ,  1243kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22728
replaced with revised version Sun, 5 Oct 2025 11:32:52 GMT   (7959kb)

Title: Prompt-aware classifier free guidance for diffusion models
Authors: Xuanhao Zhang, Chang Li
Categories: cs.SD cs.AI cs.MM eess.AS
Comments: 6 pages, 3 figures
\\ ( https://arxiv.org/abs/2509.22728 ,  7959kb)
------------------------------------------------------------------------------
\\
arXiv:2509.22850
replaced with revised version Sun, 5 Oct 2025 13:27:11 GMT   (457kb)

Title: Boundary on the Table: Efficient Black-Box Decision-Based Attacks for
  Structured Data
Authors: Roie Kazoom, Yuval Ratzabi, Etamar Rothstein and Ofer Hadar
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2509.22850 ,  457kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23835
replaced with revised version Sat, 4 Oct 2025 05:29:15 GMT   (689kb)

Title: HFuzzer: Testing Large Language Models for Package Hallucinations via
  Phrase-based Fuzzing
Authors: Yukai Zhao, Menghan Wu, Xing Hu, Xin Xia
Categories: cs.SE cs.AI
Comments: Accepted by ASE25
\\ ( https://arxiv.org/abs/2509.23835 ,  689kb)
------------------------------------------------------------------------------
\\
arXiv:2509.23901 (*cross-listing*)
replaced with revised version Sun, 5 Oct 2025 15:01:34 GMT   (24823kb)

Title: Interpreting deep learning-based stellar mass estimation via causal
  analysis and mutual information decomposition
Authors: Wei Zhang, Qiufan Lin, Yuan-Sen Ting, Shupei Chen, Hengxin Ruan, Song
  Li, Yifan Wang
Categories: astro-ph.IM astro-ph.GA cs.AI cs.CV
Comments: Accepted at Astronomy & Astrophysics; 23 + 12 pages; 8 + 16 figures
\\ ( https://arxiv.org/abs/2509.23901 ,  24823kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24243
replaced with revised version Mon, 6 Oct 2025 04:13:09 GMT   (7889kb)

Title: SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control
  Barrier Functions
Authors: Jeongyong Yang, Seunghwan Jang, SooJean Han
Categories: cs.RO cs.AI
Comments: 10 pages, 7 figures, 4 tables
\\ ( https://arxiv.org/abs/2509.24243 ,  7889kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25203
replaced with revised version Sun, 5 Oct 2025 14:52:44 GMT   (721kb)

Title: Generating High-Quality Datasets for Code Editing via Open-Source
  Language Models
Authors: Zekai Zhang, Mingwei Liu, Zhenxi Chen, Linxi Liang, Yuxuan Chen,
  Guangsheng Ou, Yanlin Wang, Dan Li, Xin Peng and Zibin Zheng
Categories: cs.SE cs.AI
Comments: 23 pages, 8 figures
\\ ( https://arxiv.org/abs/2509.25203 ,  721kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25270
replaced with revised version Sat, 4 Oct 2025 06:25:29 GMT   (710kb)

Title: InfMasking: Unleashing Synergistic Information by Contrastive Multimodal
  Interactions
Authors: Liangjian Wen, Qun Dai, Jianzhuang Liu, Jiangtao Zheng, Yong Dai,
  Dongkai Wang, Zhao Kang, Jun Wang, Zenglin Xu, Jiang Duan
Categories: cs.LG cs.AI cs.CV
Comments: Accepted to NeurIPS 2025
\\ ( https://arxiv.org/abs/2509.25270 ,  710kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25286
replaced with revised version Sat, 4 Oct 2025 16:30:09 GMT   (498kb)

Title: Artificial Authority: From Machine Minds to Political Alignments. An
  Experimental Analysis of Democratic and Autocratic Biases in Large-Language
  Models
Authors: Natalia O\.zegalska-{\L}ukasik and Szymon {\L}ukasik
Categories: cs.CY cs.AI
\\ ( https://arxiv.org/abs/2509.25286 ,  498kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25334
replaced with revised version Sat, 4 Oct 2025 17:53:25 GMT   (752kb)

Title: Uncertainty-Aware Generative Oversampling Using an Entropy-Guided
  Conditional Variational Autoencoder
Authors: Amirhossein Zare, Amirhessam Zare, Parmida Sadat Pezeshki, Herlock
  (SeyedAbolfazl) Rahimi, Ali Ebrahimi, Ignacio V\'azquez-Garc\'ia, Leo Anthony
  Celi
Categories: cs.LG cs.AI
Comments: 16 pages, 2 figures
\\ ( https://arxiv.org/abs/2509.25334 ,  752kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25694
replaced with revised version Sat, 4 Oct 2025 07:52:45 GMT   (1072kb)

Title: HNote: Extending YNote with Hexadecimal Encoding for Fine-Tuning LLMs in
  Music Modeling
Authors: Hung-Ying Chu, Shao-Yu Wei, Guan-Wei Chen, Tzu-Wei Hung, ChengYang
  Tsai and Yu-Cheng Lin
Categories: cs.SD cs.AI
\\ ( https://arxiv.org/abs/2509.25694 ,  1072kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25775
replaced with revised version Sat, 4 Oct 2025 04:38:36 GMT   (13459kb)

Title: Autonomy-Aware Clustering: When Local Decisions Supersede Global
  Prescriptions
Authors: Amber Srivastava, Salar Basiri and Srinivasa Salapaka
Categories: cs.LG cs.AI
Comments: Preprint. Under review at a peer-reviewed conference. Minor typos
  fixed compared to the previous version
\\ ( https://arxiv.org/abs/2509.25775 ,  13459kb)
------------------------------------------------------------------------------
\\
arXiv:2509.25810
replaced with revised version Fri, 3 Oct 2025 19:31:29 GMT   (17295kb)

Title: Learning to Reason as Action Abstractions with Scalable Mid-Training RL
Authors: Shenao Zhang, Donghan Yu, Yihao Feng, Bowen Jin, Zhaoran Wang, John
  Peebles, Zirui Wang
Categories: cs.LG cs.AI cs.CL stat.ML
\\ ( https://arxiv.org/abs/2509.25810 ,  17295kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26030
replaced with revised version Sun, 5 Oct 2025 09:26:34 GMT   (613kb)

Title: Muon Outperforms Adam in Tail-End Associative Memory Learning
Authors: Shuche Wang, Fengzhuo Zhang, Jiaxiang Li, Cunxiao Du, Chao Du, Tianyu
  Pang, Zhuoran Yang, Mingyi Hong, Vincent Y. F. Tan
Categories: cs.LG cs.AI math.OC
\\ ( https://arxiv.org/abs/2509.26030 ,  613kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26184
replaced with revised version Sat, 4 Oct 2025 12:48:51 GMT   (4128kb)

Title: Auto-ARGUE: LLM-Based Report Generation Evaluation
Authors: William Walden, Orion Weller, Laura Dietz, Bryan Li, Gabrielle
  Kaili-May Liu, Yu Hou, Eugene Yang
Categories: cs.IR cs.AI cs.CL
Comments: ECIR 2025 demo format
\\ ( https://arxiv.org/abs/2509.26184 ,  4128kb)
------------------------------------------------------------------------------
\\
arXiv:2509.26324
replaced with revised version Sat, 4 Oct 2025 22:23:46 GMT   (4649kb)

Title: LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration
  and Search
Authors: Ruiyang Wang, Hao-Lun Hsu, David Hunt, Shaocheng Luo, Jiwoo Kim and
  Miroslav Pajic
Categories: cs.RO cs.AI cs.MA
\\ ( https://arxiv.org/abs/2509.26324 ,  4649kb)
------------------------------------------------------------------------------
\\
arXiv:2510.00805
replaced with revised version Sat, 4 Oct 2025 15:33:53 GMT   (1661kb)

Title: MG2FlowNet: Accelerating High-Reward Sample Generation via Enhanced MCTS
  and Greediness Control
Authors: Rui Zhu, Xuan Yu, Yudong Zhang, Chen Zhang, Xu Wang, Yang Wang
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.00805 ,  1661kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01555
replaced with revised version Mon, 6 Oct 2025 11:59:12 GMT   (556kb)

Title: Rethinking KL Regularization in RLHF: From Value Estimation to Gradient
  Optimization
Authors: Kezhao Liu, Jason Klein Liu, Mingtao Chen, Yiming Liu
Categories: cs.LG cs.AI
\\ ( https://arxiv.org/abs/2510.01555 ,  556kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01708
replaced with revised version Mon, 6 Oct 2025 03:02:48 GMT   (9135kb)

Title: PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via
  Multi-Simulator Dynamics Randomization
Authors: Zixing Lei, Zibo Zhou, Sheng Yin, Yueru Chen, Qingyao Xu, Weixin Li,
  Yunhong Wang, Bowei Tang, Wei Jing and Siheng Chen
Categories: cs.RO cs.AI
Comments: 8 pages, 5 figures
\\ ( https://arxiv.org/abs/2510.01708 ,  9135kb)
------------------------------------------------------------------------------
\\
arXiv:2510.01850 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 02:06:15 GMT   (43487kb)

Title: NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset
  for Narrowband Powerline Communications
Authors: Ying-Ren Chien, Po-Heng Chou, You-Jie Peng, Chun-Yuan Huang, Hen-Wai
  Tsao, and Yu Tsao
Categories: eess.SP cs.AI cs.IT cs.LG math.IT
Comments: 16 pages, 15 figures, 11 tables, and published in IEEE Transactions
  on Instrumentation and Measurement, Vol. 74, 2025
MSC-class: 68T07, 94A12, 62M10
ACM-class: I.2.6; I.5.4; C.2.1
Journal-ref: IEEE Transactions on Instrumentation and Measurement, vol. 24, pp.
  1-15, 2025
DOI: 10.1109/TIM.2024.3523361
\\ ( https://arxiv.org/abs/2510.01850 ,  43487kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02161
replaced with revised version Mon, 6 Oct 2025 05:19:04 GMT   (891kb)

Title: Comparing Contrastive and Triplet Loss: Variance Analysis and
  Optimization Behavior
Authors: Donghuo Zeng
Categories: cs.MM cs.AI cs.LG
Comments: 8 pages, 4 tables, 3 figures
\\ ( https://arxiv.org/abs/2510.02161 ,  891kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02610
replaced with revised version Mon, 6 Oct 2025 09:40:13 GMT   (61kb)

Title: MINERVA: Mutual Information Neural Estimation for Supervised Feature
  Selection
Authors: Taurai Muvunza, Egor Kraev, Pere Planell-Morell, Alexander Y.
  Shestopaloff
Categories: cs.LG cs.AI
Comments: 23 pages
ACM-class: I.2.6; I.5.1; G.3
\\ ( https://arxiv.org/abs/2510.02610 ,  61kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02809
replaced with revised version Mon, 6 Oct 2025 06:51:20 GMT   (2792kb)

Title: Relevance-Aware Thresholding in Online Conformal Prediction for Time
  Series
Authors: Th\'eo Dupuy and Binbin Xu and St\'ephane Perrey and Jacky Montmain
  and Abdelhak Imoussaten
Categories: cs.LG cs.AI
Comments: Accepted for The 28th European Conference on Artificial Intelligence
  2025, Workshop HC@AIxIA+HYDRA 2025
\\ ( https://arxiv.org/abs/2510.02809 ,  2792kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02741 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 18:42:23 GMT   (184kb)

Title: Seeded Poisson Factorization: leveraging domain knowledge to fit topic
  models
Authors: Bernd Prostmaier, Jan V\'avra, Bettina Gr\"un, Paul Hofmarcher
Categories: stat.ME cs.CL cs.LG econ.GN q-fin.EC
Journal-ref: Knowledge-Based Systems 327 (2025) 114116
DOI: 10.1016/j.knosys.2025.114116
\\ ( https://arxiv.org/abs/2503.02741 ,  184kb)
------------------------------------------------------------------------------
\\
arXiv:2503.23174
replaced with revised version Mon, 6 Oct 2025 12:50:07 GMT   (1971kb)

Title: TRA: Better Length Generalisation with Threshold Relative Attention
Authors: Mattia Opper, Roland Fernandez, Paul Smolensky, Jianfeng Gao
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2503.23174 ,  1971kb)
------------------------------------------------------------------------------
\\
arXiv:2505.23500
replaced with revised version Mon, 6 Oct 2025 14:17:23 GMT   (956kb,A)

Title: Identity resolution of software metadata using Large Language Models
Authors: Eva Mart\'in del Pico, Josep Llu\'is Gelp\'i and Salvador
  Capella-Guti\'errez
Categories: cs.SE cs.CL cs.DL
\\ ( https://arxiv.org/abs/2505.23500 ,  956kb)
------------------------------------------------------------------------------
\\
arXiv:2506.07468
replaced with revised version Mon, 6 Oct 2025 03:42:10 GMT   (8933kb)

Title: Chasing Moving Targets with Online Self-Play Reinforcement Learning for
  Safer Language Models
Authors: Mickel Liu, Liwei Jiang, Yancheng Liang, Simon Shaolei Du, Yejin Choi,
  Tim Althoff, Natasha Jaques
Categories: cs.LG cs.CL cs.MA
\\ ( https://arxiv.org/abs/2506.07468 ,  8933kb)
------------------------------------------------------------------------------
\\
arXiv:2506.10364
replaced with revised version Mon, 6 Oct 2025 09:11:48 GMT   (1049kb)

Title: Can We Infer Confidential Properties of Training Data from LLMs?
Authors: Pengrun Huang, Chhavi Yadav, Kamalika Chaudhuri, Ruihan Wu
Categories: cs.LG cs.CL cs.CR
\\ ( https://arxiv.org/abs/2506.10364 ,  1049kb)
------------------------------------------------------------------------------
\\
arXiv:2509.20712
replaced with revised version Sat, 4 Oct 2025 03:06:24 GMT   (12448kb)

Title: CE-GPPO: Coordinating Entropy via Gradient-Preserving Clipping Policy
  Optimization in Reinforcement Learning
Authors: Zhenpeng Su, Leiyu Pan, Minxuan Lv, Yuntao Li, Wenping Hu, Fuzheng
  Zhang, Kun Gai, Guorui Zhou
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2509.20712 ,  12448kb)
------------------------------------------------------------------------------
\\
arXiv:2509.21016
replaced with revised version Fri, 3 Oct 2025 23:19:39 GMT   (7056kb)

Title: RL Grokking Recipe: How Does RL Unlock and Transfer New Algorithms in
  LLMs?
Authors: Yiyou Sun, Yuhan Cao, Pohao Huang, Haoyue Bai, Hannaneh Hajishirzi,
  Nouha Dziri, Dawn Song
Categories: cs.LG cs.CL
\\ ( https://arxiv.org/abs/2509.21016 ,  7056kb)
------------------------------------------------------------------------------
\\
arXiv:2509.24254 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 00:14:19 GMT   (432kb)

Title: Extracting the Structure of Press Releases for Predicting Earnings
  Announcement Returns
Authors: Yuntao Wu, Ege Mert Akin, Charles Martineau, Vincent Gr\'egoire,
  Andreas Veneris
Categories: q-fin.CP cs.CE cs.CL cs.LG
Comments: 9 pages, 4 figures, 6 tables, Accepted by The 6th ACM International
  Conference on AI in Finance
ACM-class: J.4; I.2.7
DOI: 10.1145/3768292.3770344
\\ ( https://arxiv.org/abs/2509.24254 ,  432kb)
------------------------------------------------------------------------------
\\
arXiv:2510.02657
replaced with revised version Mon, 6 Oct 2025 02:54:21 GMT   (1817kb)

Title: Less LLM, More Documents: Searching for Improved RAG
Authors: Jingjie Ning, Yibo Kong, Yunfan Long, Jamie Callan
Categories: cs.IR cs.CL
ACM-class: H.3.3; I.2.7
\\ ( https://arxiv.org/abs/2510.02657 ,  1817kb)
------------------------------------------------------------------------------
\\
arXiv:2409.19635
replaced with revised version Sat, 4 Oct 2025 01:56:43 GMT   (606kb)

Title: Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain
  Adaptation
Authors: Yucheng Wang, Peiliang Gong, Min Wu, Felix Ott, Xiaoli Li, Lihua Xie,
  Zhenghua Chen
Categories: cs.LG cs.CV
\\ ( https://arxiv.org/abs/2409.19635 ,  606kb)
------------------------------------------------------------------------------
\\
arXiv:2503.02892 (*cross-listing*)
replaced with revised version Sat, 4 Oct 2025 06:06:37 GMT   (3831kb)

Title: Segmenting Bi-Atrial Structures Using ResNext Based Framework
Authors: Malitha Gunawardhana, Mark L Trew, Gregory B Sands, and Jichao Zhao
Categories: eess.IV cs.CV
Comments: Accepted at STACOM workshop (MICCAI 2025)
\\ ( https://arxiv.org/abs/2503.02892 ,  3831kb)
------------------------------------------------------------------------------
\\
arXiv:2504.08421 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 11:24:28 GMT   (1529kb)

Title: Poisson multi-Bernoulli mixture filter for trajectory measurements
Authors: Marco Fontana, \'Angel F. Garc\'ia-Fern\'andez, Simon Maskell
Categories: eess.SP cs.CV stat.AP
Comments: 16 pages, 9 figures, journal paper
\\ ( https://arxiv.org/abs/2504.08421 ,  1529kb)
------------------------------------------------------------------------------
\\
arXiv:2505.18825
replaced with revised version Sun, 5 Oct 2025 20:24:27 GMT   (26164kb)

Title: How to build a consistency model: Learning flow maps via
  self-distillation
Authors: Nicholas M. Boffi, Michael S. Albergo, and Eric Vanden-Eijnden
Categories: cs.LG cs.CV
Comments: NeurIPS 2025
\\ ( https://arxiv.org/abs/2505.18825 ,  26164kb)
------------------------------------------------------------------------------
\\
arXiv:2506.18671
replaced with revised version Sun, 5 Oct 2025 08:08:58 GMT   (3083kb)

Title: TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for
  Harmonious Music-Driven Group Choreography
Authors: Yuqin Dai, Wanlu Zhu, Ronghui Li, Xiu Li, Zhenyu Zhang, Jun Li, Jian
  Yang
Categories: cs.SD cs.CV cs.GR eess.AS
\\ ( https://arxiv.org/abs/2506.18671 ,  3083kb)
------------------------------------------------------------------------------
\\
arXiv:2506.19600 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 12:47:47 GMT   (4957kb)

Title: Filling of incomplete sinograms from sparse PET detector configurations
  using a residual U-Net
Authors: Klara Leffler, Luigi Tommaso Luppino, Samuel Kuttner, Karin
  S\"oderkvist, Jan Axelsson
Categories: eess.IV cs.CV physics.med-ph
Comments: 16 pages, 9 figures
\\ ( https://arxiv.org/abs/2506.19600 ,  4957kb)
------------------------------------------------------------------------------
\\
arXiv:2507.05193 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 15:58:40 GMT   (47389kb)

Title: RAM-W600: A Multi-Task Wrist Dataset and Benchmark for Rheumatoid
  Arthritis
Authors: Songxiao Yang, Haolin Wang, Yao Fu, Ye Tian, Tamotsu Kamishima,
  Masayuki Ikebe, Yafei Ou, Masatoshi Okutomi
Categories: eess.IV cs.CV
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2507.05193 ,  47389kb)
------------------------------------------------------------------------------
\\
arXiv:2507.06867 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 17:52:49 GMT   (16905kb)

Title: Conformal Prediction for Long-Tailed Classification
Authors: Tiffany Ding, Jean-Baptiste Fermanian, Joseph Salmon
Categories: stat.ML cs.CV cs.LG stat.ME
\\ ( https://arxiv.org/abs/2507.06867 ,  16905kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08214 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 07:24:47 GMT   (1603kb)

Title: Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification
  Mapping on Non-Contrast CT
Authors: Xiangjian Hou, Ebru Yaman Akcicek, Xin Wang, Kazem Hashemizadeh, Scott
  Mcnally, Chun Yuan, Xiaodong Ma
Categories: eess.IV cs.CV
Comments: Accept to IEEE BIBM 2025
\\ ( https://arxiv.org/abs/2507.08214 ,  1603kb)
------------------------------------------------------------------------------
\\
arXiv:2507.23256 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 07:47:51 GMT   (1934kb)

Title: EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan
  Africa using MedNeXt V2 with Deep Supervision
Authors: Ahmed Jaheen, Abdelrahman Elsayed, Damir Kim, Daniil Tikhonov, Matheus
  Scatolin, Mohor Banerjee, Qiankun Ji, Mostafa Salem, Hu Wang, Sarim Hashmi,
  and Mohammad Yaqub
Categories: eess.IV cs.CV
Comments: Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)
\\ ( https://arxiv.org/abs/2507.23256 ,  1934kb)
------------------------------------------------------------------------------
\\
arXiv:2509.13298 (*cross-listing*)
replaced with revised version Mon, 6 Oct 2025 16:40:26 GMT   (863kb)

Title: QDFlow: A Python package for physics simulations of quantum dot devices
Authors: Donovan L. Buterakos, Sandesh S. Kalantre, Joshua Ziegler, Jacob M
  Taylor, Justyna P. Zwolak
Categories: cond-mat.mes-hall cs.CV cs.LG quant-ph
Comments: 17 pages, 5 figures
\\ ( https://arxiv.org/abs/2509.13298 ,  863kb)
------------------------------------------------------------------------------
\\
arXiv:2405.10123
replaced with revised version Mon, 6 Oct 2025 14:53:25 GMT   (145kb)

Title: Asynchronous Federated Stochastic Optimization for Heterogeneous
  Objectives Under Arbitrary Delays
Authors: Charikleia Iakovidou, Kibaek Kim
Categories: cs.LG cs.DC
\\ ( https://arxiv.org/abs/2405.10123 ,  145kb)
------------------------------------------------------------------------------
\\
arXiv:2503.20117
replaced with revised version Sun, 5 Oct 2025 23:26:38 GMT   (309kb)

Title: Exact and Linear Convergence for Federated Learning under Arbitrary
  Client Participation is Attainable
Authors: Bicheng Ying, Zhe Li, Haibo Yang
Categories: cs.LG cs.DC
Comments: Accepted by NeurIPS 2025
\\ ( https://arxiv.org/abs/2503.20117 ,  309kb)
------------------------------------------------------------------------------
\\
arXiv:2506.00384
replaced with revised version Sun, 5 Oct 2025 21:29:28 GMT   (1002kb)

Title: Learning Semantics, Not Addresses: Runtime Neural Prefetching for Far
  Memory
Authors: Yutong Huang, Zhiyuan Guo, Yiying Zhang
Categories: cs.LG cs.DC cs.OS
\\ ( https://arxiv.org/abs/2506.00384 ,  1002kb)
------------------------------------------------------------------------------
\\
arXiv:2510.03000
replaced with revised version Mon, 6 Oct 2025 15:03:37 GMT   (513kb)

Title: Sensors in viticulture: functions, benefits, and data-driven insights
Authors: Milan Milenkovic
Categories: cs.CY cs.DC
Comments: 14 pages, 4 figures, 1 table
ACM-class: C.2.1; C.2.4; C.3
\\ ( https://arxiv.org/abs/2510.03000 ,  513kb)
------------------------------------------------------------------------------
\\
arXiv:2409.16173
replaced with revised version Sat, 4 Oct 2025 13:48:14 GMT   (28kb)

Title: Extending Stable and Popular Matching Algorithms from Bipartite to
  Arbitrary Instances
Authors: Gergely Cs\'aji
Categories: cs.DS cs.DM cs.GT cs.MA
\\ ( https://arxiv.org/abs/2409.16173 ,  28kb)
------------------------------------------------------------------------------
\\
arXiv:2505.03771
replaced with revised version Sat, 4 Oct 2025 04:39:59 GMT   (4929kb)

Title: OneDSE: A Unified Microprocessor Metric Prediction and Design Space
  Exploration Framework
Authors: Ritik Raj, Akshat Ramachandran, Jeff Nye, Shashank Nemawarkar, Tushar
  Krishna
Categories: cs.AR cs.MA
\\ ( https://arxiv.org/abs/2505.03771 ,  4929kb)
------------------------------------------------------------------------------
\\
arXiv:2507.08870
replaced with revised version Sun, 5 Oct 2025 00:39:58 GMT   (1516kb)

Title: GUIDE: Towards Scalable Advising for Research Ideas
Authors: Yaowenqi Liu, Bingxu Meng, Rui Pan, Yuxing Liu, Jerry Huang, Jiaxuan
  You, Tong Zhang
Categories: cs.LG cs.MA
\\ ( https://arxiv.org/abs/2507.08870 ,  1516kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
